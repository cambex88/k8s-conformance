I1113 10:20:00.217423      20 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-258392779
I1113 10:20:00.217597      20 test_context.go:419] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I1113 10:20:00.217715      20 e2e.go:109] Starting e2e run "3e525414-31f7-47c2-b550-1ec4879dbf9e" on Ginkgo node 1
{"msg":"Test Suite starting","total":278,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1605262799 - Will randomize all specs
Will run 278 of 4843 specs

Nov 13 10:20:00.270: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:20:00.272: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
E1113 10:20:00.275513      20 progress.go:119] Failed to post progress update to http://localhost:8099/progress: Post http://localhost:8099/progress: dial tcp 127.0.0.1:8099: connect: connection refused
Nov 13 10:20:00.279: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov 13 10:20:00.298: INFO: 6 / 6 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov 13 10:20:00.298: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Nov 13 10:20:00.298: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov 13 10:20:00.305: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'filebeat' (0 seconds elapsed)
Nov 13 10:20:00.305: INFO: e2e test version: v1.17.9
Nov 13 10:20:00.306: INFO: kube-apiserver version: v1.17.9
Nov 13 10:20:00.306: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:20:00.310: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:20:00.311: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename configmap
Nov 13 10:20:00.335: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Nov 13 10:20:00.344: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7753
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-fee7a1ab-39f8-48ae-a43f-cc989de37024
STEP: Creating a pod to test consume configMaps
Nov 13 10:20:00.467: INFO: Waiting up to 5m0s for pod "pod-configmaps-98bb41b9-d879-4303-92e1-3e4625fafd72" in namespace "configmap-7753" to be "success or failure"
Nov 13 10:20:00.469: INFO: Pod "pod-configmaps-98bb41b9-d879-4303-92e1-3e4625fafd72": Phase="Pending", Reason="", readiness=false. Elapsed: 1.159861ms
Nov 13 10:20:02.474: INFO: Pod "pod-configmaps-98bb41b9-d879-4303-92e1-3e4625fafd72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00626261s
Nov 13 10:20:04.477: INFO: Pod "pod-configmaps-98bb41b9-d879-4303-92e1-3e4625fafd72": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009450194s
Nov 13 10:20:06.479: INFO: Pod "pod-configmaps-98bb41b9-d879-4303-92e1-3e4625fafd72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011415441s
STEP: Saw pod success
Nov 13 10:20:06.479: INFO: Pod "pod-configmaps-98bb41b9-d879-4303-92e1-3e4625fafd72" satisfied condition "success or failure"
Nov 13 10:20:06.480: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-configmaps-98bb41b9-d879-4303-92e1-3e4625fafd72 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:20:06.495: INFO: Waiting for pod pod-configmaps-98bb41b9-d879-4303-92e1-3e4625fafd72 to disappear
Nov 13 10:20:06.500: INFO: Pod pod-configmaps-98bb41b9-d879-4303-92e1-3e4625fafd72 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:20:06.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7753" for this suite.

• [SLOW TEST:6.193 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":278,"completed":1,"skipped":16,"failed":0}
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:20:06.504: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8641
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1113 10:20:07.194354      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 13 10:20:07.194: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:20:07.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8641" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":278,"completed":2,"skipped":16,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:20:07.199: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5676
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 13 10:20:11.345: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:20:11.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5676" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":278,"completed":3,"skipped":24,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:20:11.363: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-73
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:20:11.699: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 13 10:20:13.705: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859611, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859611, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859611, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859611, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:20:15.706: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859611, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859611, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859611, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859611, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:20:17.707: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859611, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859611, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859611, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859611, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:20:20.712: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:20:20.713: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1503-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:20:22.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-73" for this suite.
STEP: Destroying namespace "webhook-73-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:11.057 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":278,"completed":4,"skipped":49,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:20:22.420: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7633
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov 13 10:20:22.555: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7633 /api/v1/namespaces/watch-7633/configmaps/e2e-watch-test-label-changed cdaf3483-d028-443f-bfaa-7ab921e9d085 294829 0 2020-11-13 10:20:22 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 13 10:20:22.555: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7633 /api/v1/namespaces/watch-7633/configmaps/e2e-watch-test-label-changed cdaf3483-d028-443f-bfaa-7ab921e9d085 294830 0 2020-11-13 10:20:22 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov 13 10:20:22.555: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7633 /api/v1/namespaces/watch-7633/configmaps/e2e-watch-test-label-changed cdaf3483-d028-443f-bfaa-7ab921e9d085 294831 0 2020-11-13 10:20:22 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov 13 10:20:32.567: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7633 /api/v1/namespaces/watch-7633/configmaps/e2e-watch-test-label-changed cdaf3483-d028-443f-bfaa-7ab921e9d085 294877 0 2020-11-13 10:20:22 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 13 10:20:32.567: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7633 /api/v1/namespaces/watch-7633/configmaps/e2e-watch-test-label-changed cdaf3483-d028-443f-bfaa-7ab921e9d085 294878 0 2020-11-13 10:20:22 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov 13 10:20:32.567: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7633 /api/v1/namespaces/watch-7633/configmaps/e2e-watch-test-label-changed cdaf3483-d028-443f-bfaa-7ab921e9d085 294879 0 2020-11-13 10:20:22 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:20:32.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7633" for this suite.

• [SLOW TEST:10.151 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":278,"completed":5,"skipped":67,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:20:32.575: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1512
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov 13 10:20:32.752: INFO: Waiting up to 5m0s for pod "pod-7a6f7659-4683-4225-a694-c5dbd525c6ac" in namespace "emptydir-1512" to be "success or failure"
Nov 13 10:20:32.761: INFO: Pod "pod-7a6f7659-4683-4225-a694-c5dbd525c6ac": Phase="Pending", Reason="", readiness=false. Elapsed: 8.309536ms
Nov 13 10:20:34.763: INFO: Pod "pod-7a6f7659-4683-4225-a694-c5dbd525c6ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010422236s
STEP: Saw pod success
Nov 13 10:20:34.763: INFO: Pod "pod-7a6f7659-4683-4225-a694-c5dbd525c6ac" satisfied condition "success or failure"
Nov 13 10:20:34.764: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-7a6f7659-4683-4225-a694-c5dbd525c6ac container test-container: <nil>
STEP: delete the pod
Nov 13 10:20:34.773: INFO: Waiting for pod pod-7a6f7659-4683-4225-a694-c5dbd525c6ac to disappear
Nov 13 10:20:34.774: INFO: Pod pod-7a6f7659-4683-4225-a694-c5dbd525c6ac no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:20:34.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1512" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":6,"skipped":84,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:20:34.781: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6033
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6033 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6033;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6033 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6033;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6033.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6033.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6033.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6033.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6033.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6033.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6033.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6033.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6033.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6033.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6033.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6033.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6033.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 73.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.73_udp@PTR;check="$$(dig +tcp +noall +answer +search 73.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.73_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6033 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6033;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6033 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6033;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6033.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6033.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6033.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6033.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6033.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6033.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6033.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6033.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6033.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6033.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6033.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6033.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6033.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 73.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.73_udp@PTR;check="$$(dig +tcp +noall +answer +search 73.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.73_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 13 10:20:52.947: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.949: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.950: INFO: Unable to read wheezy_udp@dns-test-service.dns-6033 from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.952: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6033 from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.954: INFO: Unable to read wheezy_udp@dns-test-service.dns-6033.svc from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.956: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6033.svc from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.957: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6033.svc from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.959: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6033.svc from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.970: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.972: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.973: INFO: Unable to read jessie_udp@dns-test-service.dns-6033 from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.975: INFO: Unable to read jessie_tcp@dns-test-service.dns-6033 from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.976: INFO: Unable to read jessie_udp@dns-test-service.dns-6033.svc from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.978: INFO: Unable to read jessie_tcp@dns-test-service.dns-6033.svc from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.980: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6033.svc from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.981: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6033.svc from pod dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff: the server could not find the requested resource (get pods dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff)
Nov 13 10:20:52.991: INFO: Lookups using dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6033 wheezy_tcp@dns-test-service.dns-6033 wheezy_udp@dns-test-service.dns-6033.svc wheezy_tcp@dns-test-service.dns-6033.svc wheezy_udp@_http._tcp.dns-test-service.dns-6033.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6033.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6033 jessie_tcp@dns-test-service.dns-6033 jessie_udp@dns-test-service.dns-6033.svc jessie_tcp@dns-test-service.dns-6033.svc jessie_udp@_http._tcp.dns-test-service.dns-6033.svc jessie_tcp@_http._tcp.dns-test-service.dns-6033.svc]

Nov 13 10:20:58.045: INFO: DNS probes using dns-6033/dns-test-e54e93fb-bbaa-4074-9a56-a79df1b448ff succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:20:58.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6033" for this suite.

• [SLOW TEST:23.320 seconds]
[sig-network] DNS
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":278,"completed":7,"skipped":103,"failed":0}
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:20:58.102: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7354
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov 13 10:21:02.246: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 10:21:02.247: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 10:21:04.248: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 10:21:04.250: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 13 10:21:06.248: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 13 10:21:06.249: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:21:06.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7354" for this suite.

• [SLOW TEST:8.155 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":278,"completed":8,"skipped":104,"failed":0}
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:21:06.258: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2232
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating Agnhost RC
Nov 13 10:21:06.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 create -f - --namespace=kubectl-2232'
Nov 13 10:21:07.227: INFO: stderr: ""
Nov 13 10:21:07.227: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Nov 13 10:21:08.229: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 13 10:21:08.229: INFO: Found 0 / 1
Nov 13 10:21:09.229: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 13 10:21:09.229: INFO: Found 1 / 1
Nov 13 10:21:09.229: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov 13 10:21:09.231: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 13 10:21:09.231: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 13 10:21:09.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 patch pod agnhost-master-ks7mh --namespace=kubectl-2232 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov 13 10:21:09.284: INFO: stderr: ""
Nov 13 10:21:09.284: INFO: stdout: "pod/agnhost-master-ks7mh patched\n"
STEP: checking annotations
Nov 13 10:21:09.286: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 13 10:21:09.286: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:21:09.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2232" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":278,"completed":9,"skipped":104,"failed":0}
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:21:09.290: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-971
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-6ea347b7-a71c-447d-8142-787cf3959074
STEP: Creating a pod to test consume configMaps
Nov 13 10:21:09.468: INFO: Waiting up to 5m0s for pod "pod-configmaps-01b89af9-23b7-469b-98de-8ee001bb0101" in namespace "configmap-971" to be "success or failure"
Nov 13 10:21:09.479: INFO: Pod "pod-configmaps-01b89af9-23b7-469b-98de-8ee001bb0101": Phase="Pending", Reason="", readiness=false. Elapsed: 10.930851ms
Nov 13 10:21:11.481: INFO: Pod "pod-configmaps-01b89af9-23b7-469b-98de-8ee001bb0101": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012820521s
Nov 13 10:21:13.483: INFO: Pod "pod-configmaps-01b89af9-23b7-469b-98de-8ee001bb0101": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014626003s
STEP: Saw pod success
Nov 13 10:21:13.483: INFO: Pod "pod-configmaps-01b89af9-23b7-469b-98de-8ee001bb0101" satisfied condition "success or failure"
Nov 13 10:21:13.484: INFO: Trying to get logs from node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c pod pod-configmaps-01b89af9-23b7-469b-98de-8ee001bb0101 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:21:13.501: INFO: Waiting for pod pod-configmaps-01b89af9-23b7-469b-98de-8ee001bb0101 to disappear
Nov 13 10:21:13.507: INFO: Pod pod-configmaps-01b89af9-23b7-469b-98de-8ee001bb0101 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:21:13.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-971" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":10,"skipped":111,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:21:13.511: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3337
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:21:13.903: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 13 10:21:15.916: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859673, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859673, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859673, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859673, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:21:17.918: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859673, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859673, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859673, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859673, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:21:19.918: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859673, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859673, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859673, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859673, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:21:22.923: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:21:22.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3337" for this suite.
STEP: Destroying namespace "webhook-3337-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:9.496 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":278,"completed":11,"skipped":119,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:21:23.008: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6810
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov 13 10:21:23.142: INFO: Waiting up to 5m0s for pod "pod-955a15b3-3028-4305-a156-edc47af12a48" in namespace "emptydir-6810" to be "success or failure"
Nov 13 10:21:23.145: INFO: Pod "pod-955a15b3-3028-4305-a156-edc47af12a48": Phase="Pending", Reason="", readiness=false. Elapsed: 3.427305ms
Nov 13 10:21:25.147: INFO: Pod "pod-955a15b3-3028-4305-a156-edc47af12a48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005444291s
Nov 13 10:21:27.150: INFO: Pod "pod-955a15b3-3028-4305-a156-edc47af12a48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00762381s
STEP: Saw pod success
Nov 13 10:21:27.150: INFO: Pod "pod-955a15b3-3028-4305-a156-edc47af12a48" satisfied condition "success or failure"
Nov 13 10:21:27.151: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-955a15b3-3028-4305-a156-edc47af12a48 container test-container: <nil>
STEP: delete the pod
Nov 13 10:21:27.163: INFO: Waiting for pod pod-955a15b3-3028-4305-a156-edc47af12a48 to disappear
Nov 13 10:21:27.168: INFO: Pod pod-955a15b3-3028-4305-a156-edc47af12a48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:21:27.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6810" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":12,"skipped":125,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:21:27.176: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9292
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov 13 10:21:33.818: INFO: Successfully updated pod "pod-update-activedeadlineseconds-83670470-82c6-40fc-b637-ae1e212f7611"
Nov 13 10:21:33.818: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-83670470-82c6-40fc-b637-ae1e212f7611" in namespace "pods-9292" to be "terminated due to deadline exceeded"
Nov 13 10:21:33.820: INFO: Pod "pod-update-activedeadlineseconds-83670470-82c6-40fc-b637-ae1e212f7611": Phase="Running", Reason="", readiness=true. Elapsed: 1.387354ms
Nov 13 10:21:35.822: INFO: Pod "pod-update-activedeadlineseconds-83670470-82c6-40fc-b637-ae1e212f7611": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.003421995s
Nov 13 10:21:35.822: INFO: Pod "pod-update-activedeadlineseconds-83670470-82c6-40fc-b637-ae1e212f7611" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:21:35.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9292" for this suite.

• [SLOW TEST:8.650 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":278,"completed":13,"skipped":142,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:21:35.826: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5420
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:21:36.362: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 13 10:21:38.366: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859696, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859696, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859696, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859696, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:21:41.374: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:21:41.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5420" for this suite.
STEP: Destroying namespace "webhook-5420-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.703 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":278,"completed":14,"skipped":154,"failed":0}
S
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:21:41.529: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-3703
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov 13 10:21:45.689: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3703 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:21:45.689: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:21:45.762: INFO: Exec stderr: ""
Nov 13 10:21:45.762: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3703 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:21:45.762: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:21:45.834: INFO: Exec stderr: ""
Nov 13 10:21:45.834: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3703 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:21:45.834: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:21:45.908: INFO: Exec stderr: ""
Nov 13 10:21:45.908: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3703 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:21:45.908: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:21:45.981: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov 13 10:21:45.981: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3703 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:21:45.981: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:21:46.055: INFO: Exec stderr: ""
Nov 13 10:21:46.055: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3703 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:21:46.055: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:21:46.154: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov 13 10:21:46.154: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3703 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:21:46.154: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:21:46.237: INFO: Exec stderr: ""
Nov 13 10:21:46.237: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3703 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:21:46.237: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:21:46.332: INFO: Exec stderr: ""
Nov 13 10:21:46.332: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3703 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:21:46.332: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:21:46.411: INFO: Exec stderr: ""
Nov 13 10:21:46.411: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3703 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:21:46.411: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:21:46.476: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:21:46.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3703" for this suite.
•{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":15,"skipped":155,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:21:46.481: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-704
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:21:51.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-704" for this suite.

• [SLOW TEST:5.127 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":278,"completed":16,"skipped":177,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:21:51.613: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-5054
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:21:51.750: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:21:58.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5054" for this suite.

• [SLOW TEST:6.475 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:47
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":278,"completed":17,"skipped":179,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:21:58.088: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:21:58.438: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 13 10:22:00.443: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859718, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859718, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859718, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740859718, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:22:03.450: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:22:03.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8583" for this suite.
STEP: Destroying namespace "webhook-8583-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.411 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":278,"completed":18,"skipped":182,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:22:03.501: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7286
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Nov 13 10:22:03.635: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov 13 10:22:10.660: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:22:10.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7286" for this suite.

• [SLOW TEST:7.165 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":278,"completed":19,"skipped":194,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:22:10.667: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5601
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:22:36.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5601" for this suite.

• [SLOW TEST:26.314 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  blackbox test
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":278,"completed":20,"skipped":214,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:22:36.983: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5019
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov 13 10:22:41.192: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:22:41.193: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:22:43.194: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:22:43.196: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:22:45.194: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:22:45.196: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:22:47.194: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:22:47.196: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 13 10:22:49.193: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 13 10:22:49.195: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:22:49.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5019" for this suite.

• [SLOW TEST:12.217 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":278,"completed":21,"skipped":240,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:22:49.200: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4122
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap that has name configmap-test-emptyKey-f70b10a9-592c-40e9-b08b-c90a57aac897
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:22:49.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4122" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":278,"completed":22,"skipped":312,"failed":0}
SS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:22:49.326: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2711
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:22:49.451: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:22:51.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2711" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":278,"completed":23,"skipped":314,"failed":0}
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:22:51.537: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-340
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1585
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 13 10:22:51.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-340'
Nov 13 10:22:51.725: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 13 10:22:51.725: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: rolling-update to same image controller
Nov 13 10:22:51.739: INFO: scanned /root for discovery docs: <nil>
Nov 13 10:22:51.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-340'
Nov 13 10:23:12.657: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov 13 10:23:12.657: INFO: stdout: "Created e2e-test-httpd-rc-ad2d8c1f757dc97cbae6ca026ebd2338\nScaling up e2e-test-httpd-rc-ad2d8c1f757dc97cbae6ca026ebd2338 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-ad2d8c1f757dc97cbae6ca026ebd2338 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-ad2d8c1f757dc97cbae6ca026ebd2338 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Nov 13 10:23:12.657: INFO: stdout: "Created e2e-test-httpd-rc-ad2d8c1f757dc97cbae6ca026ebd2338\nScaling up e2e-test-httpd-rc-ad2d8c1f757dc97cbae6ca026ebd2338 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-ad2d8c1f757dc97cbae6ca026ebd2338 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-ad2d8c1f757dc97cbae6ca026ebd2338 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Nov 13 10:23:12.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-340'
Nov 13 10:23:12.705: INFO: stderr: ""
Nov 13 10:23:12.705: INFO: stdout: "e2e-test-httpd-rc-ad2d8c1f757dc97cbae6ca026ebd2338-g4m6f "
Nov 13 10:23:12.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods e2e-test-httpd-rc-ad2d8c1f757dc97cbae6ca026ebd2338-g4m6f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-340'
Nov 13 10:23:12.750: INFO: stderr: ""
Nov 13 10:23:12.750: INFO: stdout: "true"
Nov 13 10:23:12.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods e2e-test-httpd-rc-ad2d8c1f757dc97cbae6ca026ebd2338-g4m6f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-340'
Nov 13 10:23:12.798: INFO: stderr: ""
Nov 13 10:23:12.798: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Nov 13 10:23:12.798: INFO: e2e-test-httpd-rc-ad2d8c1f757dc97cbae6ca026ebd2338-g4m6f is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
Nov 13 10:23:12.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete rc e2e-test-httpd-rc --namespace=kubectl-340'
Nov 13 10:23:12.848: INFO: stderr: ""
Nov 13 10:23:12.849: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:23:12.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-340" for this suite.

• [SLOW TEST:21.323 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1580
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl rolling-update should support rolling-update to same image  [Conformance]","total":278,"completed":24,"skipped":321,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:23:12.860: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7430
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Starting the proxy
Nov 13 10:23:12.983: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-258392779 proxy --unix-socket=/tmp/kubectl-proxy-unix225034110/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:23:13.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7430" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":278,"completed":25,"skipped":365,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:23:13.039: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5600
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-b0bc8295-c6ad-4f61-80a1-0dd23b0d9b96
STEP: Creating a pod to test consume configMaps
Nov 13 10:23:13.172: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0cebe427-99e0-4204-87f6-28aab719f4b4" in namespace "projected-5600" to be "success or failure"
Nov 13 10:23:13.175: INFO: Pod "pod-projected-configmaps-0cebe427-99e0-4204-87f6-28aab719f4b4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.512247ms
Nov 13 10:23:15.177: INFO: Pod "pod-projected-configmaps-0cebe427-99e0-4204-87f6-28aab719f4b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005465161s
STEP: Saw pod success
Nov 13 10:23:15.177: INFO: Pod "pod-projected-configmaps-0cebe427-99e0-4204-87f6-28aab719f4b4" satisfied condition "success or failure"
Nov 13 10:23:15.178: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-projected-configmaps-0cebe427-99e0-4204-87f6-28aab719f4b4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:23:15.192: INFO: Waiting for pod pod-projected-configmaps-0cebe427-99e0-4204-87f6-28aab719f4b4 to disappear
Nov 13 10:23:15.193: INFO: Pod pod-projected-configmaps-0cebe427-99e0-4204-87f6-28aab719f4b4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:23:15.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5600" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":278,"completed":26,"skipped":385,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:23:15.201: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5344
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:23:15.327: INFO: Waiting up to 5m0s for pod "downwardapi-volume-83e5f955-904b-4e7c-a38d-d3e6e289d506" in namespace "projected-5344" to be "success or failure"
Nov 13 10:23:15.335: INFO: Pod "downwardapi-volume-83e5f955-904b-4e7c-a38d-d3e6e289d506": Phase="Pending", Reason="", readiness=false. Elapsed: 8.072661ms
Nov 13 10:23:17.337: INFO: Pod "downwardapi-volume-83e5f955-904b-4e7c-a38d-d3e6e289d506": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010085443s
STEP: Saw pod success
Nov 13 10:23:17.337: INFO: Pod "downwardapi-volume-83e5f955-904b-4e7c-a38d-d3e6e289d506" satisfied condition "success or failure"
Nov 13 10:23:17.338: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-83e5f955-904b-4e7c-a38d-d3e6e289d506 container client-container: <nil>
STEP: delete the pod
Nov 13 10:23:17.348: INFO: Waiting for pod downwardapi-volume-83e5f955-904b-4e7c-a38d-d3e6e289d506 to disappear
Nov 13 10:23:17.353: INFO: Pod downwardapi-volume-83e5f955-904b-4e7c-a38d-d3e6e289d506 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:23:17.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5344" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":27,"skipped":438,"failed":0}

------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:23:17.358: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9233
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov 13 10:23:17.485: INFO: Waiting up to 5m0s for pod "pod-6c26598d-51c8-44d8-91a8-c3901e01b34a" in namespace "emptydir-9233" to be "success or failure"
Nov 13 10:23:17.489: INFO: Pod "pod-6c26598d-51c8-44d8-91a8-c3901e01b34a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.488826ms
Nov 13 10:23:19.492: INFO: Pod "pod-6c26598d-51c8-44d8-91a8-c3901e01b34a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006876715s
STEP: Saw pod success
Nov 13 10:23:19.492: INFO: Pod "pod-6c26598d-51c8-44d8-91a8-c3901e01b34a" satisfied condition "success or failure"
Nov 13 10:23:19.495: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-6c26598d-51c8-44d8-91a8-c3901e01b34a container test-container: <nil>
STEP: delete the pod
Nov 13 10:23:19.504: INFO: Waiting for pod pod-6c26598d-51c8-44d8-91a8-c3901e01b34a to disappear
Nov 13 10:23:19.510: INFO: Pod pod-6c26598d-51c8-44d8-91a8-c3901e01b34a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:23:19.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9233" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":28,"skipped":438,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:23:19.518: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4085
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name cm-test-opt-del-a71424b3-106b-4388-b0b4-0359a05d7f4e
STEP: Creating configMap with name cm-test-opt-upd-1aaa36f1-2f91-4011-9142-bde54fbe7416
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a71424b3-106b-4388-b0b4-0359a05d7f4e
STEP: Updating configmap cm-test-opt-upd-1aaa36f1-2f91-4011-9142-bde54fbe7416
STEP: Creating configMap with name cm-test-opt-create-b20be477-0364-4436-a06b-9e9a1678001c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:23:23.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4085" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":278,"completed":29,"skipped":459,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:23:23.702: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5507
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: set up a multi version CRD
Nov 13 10:23:23.826: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:23:36.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5507" for this suite.

• [SLOW TEST:13.124 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":278,"completed":30,"skipped":486,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:23:36.827: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8435
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-2e86c238-567b-4779-9da0-b6b2f5c091b2
STEP: Creating a pod to test consume secrets
Nov 13 10:23:36.965: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9e3afe2f-f9f7-4cc6-80e9-4e1e564ba8c4" in namespace "projected-8435" to be "success or failure"
Nov 13 10:23:36.970: INFO: Pod "pod-projected-secrets-9e3afe2f-f9f7-4cc6-80e9-4e1e564ba8c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.861635ms
Nov 13 10:23:38.972: INFO: Pod "pod-projected-secrets-9e3afe2f-f9f7-4cc6-80e9-4e1e564ba8c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006712763s
STEP: Saw pod success
Nov 13 10:23:38.972: INFO: Pod "pod-projected-secrets-9e3afe2f-f9f7-4cc6-80e9-4e1e564ba8c4" satisfied condition "success or failure"
Nov 13 10:23:38.973: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-projected-secrets-9e3afe2f-f9f7-4cc6-80e9-4e1e564ba8c4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 13 10:23:38.982: INFO: Waiting for pod pod-projected-secrets-9e3afe2f-f9f7-4cc6-80e9-4e1e564ba8c4 to disappear
Nov 13 10:23:38.987: INFO: Pod pod-projected-secrets-9e3afe2f-f9f7-4cc6-80e9-4e1e564ba8c4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:23:38.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8435" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":31,"skipped":505,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:23:38.991: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9785
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:23:39.172: INFO: Waiting up to 5m0s for pod "downwardapi-volume-481d7e1b-f778-4bb9-8aab-9e1a890f4066" in namespace "projected-9785" to be "success or failure"
Nov 13 10:23:39.179: INFO: Pod "downwardapi-volume-481d7e1b-f778-4bb9-8aab-9e1a890f4066": Phase="Pending", Reason="", readiness=false. Elapsed: 7.301841ms
Nov 13 10:23:41.181: INFO: Pod "downwardapi-volume-481d7e1b-f778-4bb9-8aab-9e1a890f4066": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009388152s
STEP: Saw pod success
Nov 13 10:23:41.181: INFO: Pod "downwardapi-volume-481d7e1b-f778-4bb9-8aab-9e1a890f4066" satisfied condition "success or failure"
Nov 13 10:23:41.183: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-481d7e1b-f778-4bb9-8aab-9e1a890f4066 container client-container: <nil>
STEP: delete the pod
Nov 13 10:23:41.193: INFO: Waiting for pod downwardapi-volume-481d7e1b-f778-4bb9-8aab-9e1a890f4066 to disappear
Nov 13 10:23:41.198: INFO: Pod downwardapi-volume-481d7e1b-f778-4bb9-8aab-9e1a890f4066 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:23:41.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9785" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":278,"completed":32,"skipped":548,"failed":0}
SS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:23:41.204: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3172
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3172.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-3172.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3172.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3172.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-3172.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3172.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 13 10:23:43.369: INFO: DNS probes using dns-3172/dns-test-aa436481-6024-4f82-a86b-1845576b304f succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:23:43.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3172" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":278,"completed":33,"skipped":550,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:23:43.402: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6230
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:23:43.535: INFO: Create a RollingUpdate DaemonSet
Nov 13 10:23:43.538: INFO: Check that daemon pods launch on every node of the cluster
Nov 13 10:23:43.548: INFO: Number of nodes with available pods: 0
Nov 13 10:23:43.548: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:23:44.552: INFO: Number of nodes with available pods: 0
Nov 13 10:23:44.552: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:23:45.552: INFO: Number of nodes with available pods: 1
Nov 13 10:23:45.552: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:23:46.553: INFO: Number of nodes with available pods: 1
Nov 13 10:23:46.553: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:23:47.553: INFO: Number of nodes with available pods: 1
Nov 13 10:23:47.553: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:23:48.552: INFO: Number of nodes with available pods: 1
Nov 13 10:23:48.552: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:23:49.552: INFO: Number of nodes with available pods: 1
Nov 13 10:23:49.552: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:23:50.552: INFO: Number of nodes with available pods: 1
Nov 13 10:23:50.552: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:23:51.552: INFO: Number of nodes with available pods: 1
Nov 13 10:23:51.552: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:23:52.552: INFO: Number of nodes with available pods: 1
Nov 13 10:23:52.552: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:23:53.552: INFO: Number of nodes with available pods: 2
Nov 13 10:23:53.552: INFO: Number of running nodes: 2, number of available pods: 2
Nov 13 10:23:53.552: INFO: Update the DaemonSet to trigger a rollout
Nov 13 10:23:53.556: INFO: Updating DaemonSet daemon-set
Nov 13 10:23:57.571: INFO: Roll back the DaemonSet before rollout is complete
Nov 13 10:23:57.574: INFO: Updating DaemonSet daemon-set
Nov 13 10:23:57.574: INFO: Make sure DaemonSet rollback is complete
Nov 13 10:23:57.578: INFO: Wrong image for pod: daemon-set-l6wq5. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 13 10:23:57.578: INFO: Pod daemon-set-l6wq5 is not available
Nov 13 10:23:58.582: INFO: Wrong image for pod: daemon-set-l6wq5. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 13 10:23:58.582: INFO: Pod daemon-set-l6wq5 is not available
Nov 13 10:23:59.582: INFO: Wrong image for pod: daemon-set-l6wq5. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 13 10:23:59.582: INFO: Pod daemon-set-l6wq5 is not available
Nov 13 10:24:00.583: INFO: Pod daemon-set-sjs62 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6230, will wait for the garbage collector to delete the pods
Nov 13 10:24:00.643: INFO: Deleting DaemonSet.extensions daemon-set took: 4.502993ms
Nov 13 10:24:01.044: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.249313ms
Nov 13 10:24:03.045: INFO: Number of nodes with available pods: 0
Nov 13 10:24:03.045: INFO: Number of running nodes: 0, number of available pods: 0
Nov 13 10:24:03.048: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6230/daemonsets","resourceVersion":"296753"},"items":null}

Nov 13 10:24:03.049: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6230/pods","resourceVersion":"296753"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:24:03.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6230" for this suite.

• [SLOW TEST:19.654 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":278,"completed":34,"skipped":566,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:24:03.057: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-958
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-03008e8d-90f7-4f9c-a28e-96d473077cd4
STEP: Creating a pod to test consume configMaps
Nov 13 10:24:03.188: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-55cf8087-b26c-4706-9710-4a3d5ba9bf64" in namespace "projected-958" to be "success or failure"
Nov 13 10:24:03.193: INFO: Pod "pod-projected-configmaps-55cf8087-b26c-4706-9710-4a3d5ba9bf64": Phase="Pending", Reason="", readiness=false. Elapsed: 5.100654ms
Nov 13 10:24:05.195: INFO: Pod "pod-projected-configmaps-55cf8087-b26c-4706-9710-4a3d5ba9bf64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007045216s
STEP: Saw pod success
Nov 13 10:24:05.195: INFO: Pod "pod-projected-configmaps-55cf8087-b26c-4706-9710-4a3d5ba9bf64" satisfied condition "success or failure"
Nov 13 10:24:05.196: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-projected-configmaps-55cf8087-b26c-4706-9710-4a3d5ba9bf64 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:24:05.205: INFO: Waiting for pod pod-projected-configmaps-55cf8087-b26c-4706-9710-4a3d5ba9bf64 to disappear
Nov 13 10:24:05.211: INFO: Pod pod-projected-configmaps-55cf8087-b26c-4706-9710-4a3d5ba9bf64 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:24:05.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-958" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":278,"completed":35,"skipped":579,"failed":0}
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:24:05.216: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8341
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-9e02acd2-1e5e-480f-b2de-9ff00bd621d8
STEP: Creating a pod to test consume secrets
Nov 13 10:24:05.351: INFO: Waiting up to 5m0s for pod "pod-secrets-14a02270-f01c-4e66-a139-2413e8f3dd0c" in namespace "secrets-8341" to be "success or failure"
Nov 13 10:24:05.361: INFO: Pod "pod-secrets-14a02270-f01c-4e66-a139-2413e8f3dd0c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.238763ms
Nov 13 10:24:07.363: INFO: Pod "pod-secrets-14a02270-f01c-4e66-a139-2413e8f3dd0c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011333506s
STEP: Saw pod success
Nov 13 10:24:07.363: INFO: Pod "pod-secrets-14a02270-f01c-4e66-a139-2413e8f3dd0c" satisfied condition "success or failure"
Nov 13 10:24:07.365: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-secrets-14a02270-f01c-4e66-a139-2413e8f3dd0c container secret-env-test: <nil>
STEP: delete the pod
Nov 13 10:24:07.376: INFO: Waiting for pod pod-secrets-14a02270-f01c-4e66-a139-2413e8f3dd0c to disappear
Nov 13 10:24:07.381: INFO: Pod pod-secrets-14a02270-f01c-4e66-a139-2413e8f3dd0c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:24:07.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8341" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":278,"completed":36,"skipped":580,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:24:07.386: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2234
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov 13 10:24:07.511: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2234 /api/v1/namespaces/watch-2234/configmaps/e2e-watch-test-watch-closed e185474d-120b-4cb2-9d3f-7bb0efc147d4 296809 0 2020-11-13 10:24:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 13 10:24:07.511: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2234 /api/v1/namespaces/watch-2234/configmaps/e2e-watch-test-watch-closed e185474d-120b-4cb2-9d3f-7bb0efc147d4 296810 0 2020-11-13 10:24:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov 13 10:24:07.517: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2234 /api/v1/namespaces/watch-2234/configmaps/e2e-watch-test-watch-closed e185474d-120b-4cb2-9d3f-7bb0efc147d4 296811 0 2020-11-13 10:24:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 13 10:24:07.517: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2234 /api/v1/namespaces/watch-2234/configmaps/e2e-watch-test-watch-closed e185474d-120b-4cb2-9d3f-7bb0efc147d4 296812 0 2020-11-13 10:24:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:24:07.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2234" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":278,"completed":37,"skipped":590,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:24:07.524: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-113
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:24:07.651: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2d9b237e-9096-48fa-9635-87c660955d87" in namespace "downward-api-113" to be "success or failure"
Nov 13 10:24:07.654: INFO: Pod "downwardapi-volume-2d9b237e-9096-48fa-9635-87c660955d87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.273725ms
Nov 13 10:24:09.655: INFO: Pod "downwardapi-volume-2d9b237e-9096-48fa-9635-87c660955d87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003981941s
STEP: Saw pod success
Nov 13 10:24:09.655: INFO: Pod "downwardapi-volume-2d9b237e-9096-48fa-9635-87c660955d87" satisfied condition "success or failure"
Nov 13 10:24:09.657: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-2d9b237e-9096-48fa-9635-87c660955d87 container client-container: <nil>
STEP: delete the pod
Nov 13 10:24:09.666: INFO: Waiting for pod downwardapi-volume-2d9b237e-9096-48fa-9635-87c660955d87 to disappear
Nov 13 10:24:09.671: INFO: Pod downwardapi-volume-2d9b237e-9096-48fa-9635-87c660955d87 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:24:09.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-113" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":278,"completed":38,"skipped":617,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:24:09.675: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3518
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov 13 10:24:09.805: INFO: Waiting up to 5m0s for pod "pod-3090d76b-19e5-46bd-90d3-f5e4e133bf30" in namespace "emptydir-3518" to be "success or failure"
Nov 13 10:24:09.808: INFO: Pod "pod-3090d76b-19e5-46bd-90d3-f5e4e133bf30": Phase="Pending", Reason="", readiness=false. Elapsed: 3.830915ms
Nov 13 10:24:11.810: INFO: Pod "pod-3090d76b-19e5-46bd-90d3-f5e4e133bf30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005757313s
STEP: Saw pod success
Nov 13 10:24:11.810: INFO: Pod "pod-3090d76b-19e5-46bd-90d3-f5e4e133bf30" satisfied condition "success or failure"
Nov 13 10:24:11.811: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-3090d76b-19e5-46bd-90d3-f5e4e133bf30 container test-container: <nil>
STEP: delete the pod
Nov 13 10:24:11.821: INFO: Waiting for pod pod-3090d76b-19e5-46bd-90d3-f5e4e133bf30 to disappear
Nov 13 10:24:11.826: INFO: Pod pod-3090d76b-19e5-46bd-90d3-f5e4e133bf30 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:24:11.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3518" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":39,"skipped":623,"failed":0}
SSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:24:11.831: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4061
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:24:13.975: INFO: Waiting up to 5m0s for pod "client-envvars-31b5fe87-d7b3-4cab-a887-5c4514c49843" in namespace "pods-4061" to be "success or failure"
Nov 13 10:24:13.977: INFO: Pod "client-envvars-31b5fe87-d7b3-4cab-a887-5c4514c49843": Phase="Pending", Reason="", readiness=false. Elapsed: 2.250355ms
Nov 13 10:24:15.980: INFO: Pod "client-envvars-31b5fe87-d7b3-4cab-a887-5c4514c49843": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004778013s
STEP: Saw pod success
Nov 13 10:24:15.980: INFO: Pod "client-envvars-31b5fe87-d7b3-4cab-a887-5c4514c49843" satisfied condition "success or failure"
Nov 13 10:24:15.981: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod client-envvars-31b5fe87-d7b3-4cab-a887-5c4514c49843 container env3cont: <nil>
STEP: delete the pod
Nov 13 10:24:15.991: INFO: Waiting for pod client-envvars-31b5fe87-d7b3-4cab-a887-5c4514c49843 to disappear
Nov 13 10:24:15.992: INFO: Pod client-envvars-31b5fe87-d7b3-4cab-a887-5c4514c49843 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:24:15.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4061" for this suite.
•{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":278,"completed":40,"skipped":629,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:24:15.998: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3215
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov 13 10:24:16.125: INFO: Waiting up to 5m0s for pod "pod-4eedc940-796b-4342-b626-3c68fe78a6d6" in namespace "emptydir-3215" to be "success or failure"
Nov 13 10:24:16.127: INFO: Pod "pod-4eedc940-796b-4342-b626-3c68fe78a6d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.361577ms
Nov 13 10:24:18.131: INFO: Pod "pod-4eedc940-796b-4342-b626-3c68fe78a6d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005641564s
STEP: Saw pod success
Nov 13 10:24:18.131: INFO: Pod "pod-4eedc940-796b-4342-b626-3c68fe78a6d6" satisfied condition "success or failure"
Nov 13 10:24:18.132: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-4eedc940-796b-4342-b626-3c68fe78a6d6 container test-container: <nil>
STEP: delete the pod
Nov 13 10:24:18.140: INFO: Waiting for pod pod-4eedc940-796b-4342-b626-3c68fe78a6d6 to disappear
Nov 13 10:24:18.142: INFO: Pod pod-4eedc940-796b-4342-b626-3c68fe78a6d6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:24:18.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3215" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":41,"skipped":641,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:24:18.147: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8506
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:24:18.270: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov 13 10:24:20.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-8506 create -f -'
Nov 13 10:24:21.674: INFO: stderr: ""
Nov 13 10:24:21.674: INFO: stdout: "e2e-test-crd-publish-openapi-8859-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov 13 10:24:21.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-8506 delete e2e-test-crd-publish-openapi-8859-crds test-cr'
Nov 13 10:24:21.723: INFO: stderr: ""
Nov 13 10:24:21.723: INFO: stdout: "e2e-test-crd-publish-openapi-8859-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Nov 13 10:24:21.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-8506 apply -f -'
Nov 13 10:24:21.903: INFO: stderr: ""
Nov 13 10:24:21.903: INFO: stdout: "e2e-test-crd-publish-openapi-8859-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov 13 10:24:21.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-8506 delete e2e-test-crd-publish-openapi-8859-crds test-cr'
Nov 13 10:24:21.954: INFO: stderr: ""
Nov 13 10:24:21.954: INFO: stdout: "e2e-test-crd-publish-openapi-8859-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov 13 10:24:21.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 explain e2e-test-crd-publish-openapi-8859-crds'
Nov 13 10:24:22.088: INFO: stderr: ""
Nov 13 10:24:22.088: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8859-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:24:23.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8506" for this suite.

• [SLOW TEST:5.586 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":278,"completed":42,"skipped":643,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:24:23.734: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4022
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:24:23.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4022" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":278,"completed":43,"skipped":654,"failed":0}
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:24:23.880: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-178
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:46
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Nov 13 10:24:26.021: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-258392779 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov 13 10:24:31.086: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:24:31.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-178" for this suite.

• [SLOW TEST:7.211 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should be submitted and removed [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period should be submitted and removed [Conformance]","total":278,"completed":44,"skipped":657,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:24:31.091: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2013
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Nov 13 10:24:31.469: INFO: Pod name wrapped-volume-race-7520b80b-8be7-4233-a87b-a348e2f22af2: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7520b80b-8be7-4233-a87b-a348e2f22af2 in namespace emptydir-wrapper-2013, will wait for the garbage collector to delete the pods
Nov 13 10:24:47.559: INFO: Deleting ReplicationController wrapped-volume-race-7520b80b-8be7-4233-a87b-a348e2f22af2 took: 4.658941ms
Nov 13 10:24:47.959: INFO: Terminating ReplicationController wrapped-volume-race-7520b80b-8be7-4233-a87b-a348e2f22af2 pods took: 400.243656ms
STEP: Creating RC which spawns configmap-volume pods
Nov 13 10:24:57.878: INFO: Pod name wrapped-volume-race-7f9157ef-5cab-4d09-9a09-a43df2401c74: Found 1 pods out of 5
Nov 13 10:25:02.882: INFO: Pod name wrapped-volume-race-7f9157ef-5cab-4d09-9a09-a43df2401c74: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7f9157ef-5cab-4d09-9a09-a43df2401c74 in namespace emptydir-wrapper-2013, will wait for the garbage collector to delete the pods
Nov 13 10:25:12.946: INFO: Deleting ReplicationController wrapped-volume-race-7f9157ef-5cab-4d09-9a09-a43df2401c74 took: 4.136139ms
Nov 13 10:25:13.346: INFO: Terminating ReplicationController wrapped-volume-race-7f9157ef-5cab-4d09-9a09-a43df2401c74 pods took: 400.261126ms
STEP: Creating RC which spawns configmap-volume pods
Nov 13 10:25:20.456: INFO: Pod name wrapped-volume-race-3fdc20a5-3dcc-4046-8d10-b2138b497476: Found 0 pods out of 5
Nov 13 10:25:25.459: INFO: Pod name wrapped-volume-race-3fdc20a5-3dcc-4046-8d10-b2138b497476: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3fdc20a5-3dcc-4046-8d10-b2138b497476 in namespace emptydir-wrapper-2013, will wait for the garbage collector to delete the pods
Nov 13 10:25:35.530: INFO: Deleting ReplicationController wrapped-volume-race-3fdc20a5-3dcc-4046-8d10-b2138b497476 took: 6.57282ms
Nov 13 10:25:35.931: INFO: Terminating ReplicationController wrapped-volume-race-3fdc20a5-3dcc-4046-8d10-b2138b497476 pods took: 400.996516ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:25:49.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2013" for this suite.

• [SLOW TEST:77.985 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":278,"completed":45,"skipped":669,"failed":0}
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:25:49.077: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2968
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-map-a7d9c239-7d43-4642-9418-a4c663250144
STEP: Creating a pod to test consume secrets
Nov 13 10:25:49.214: INFO: Waiting up to 5m0s for pod "pod-secrets-5f2972c7-81ca-404a-9ee5-6fcbe51bb1d3" in namespace "secrets-2968" to be "success or failure"
Nov 13 10:25:49.217: INFO: Pod "pod-secrets-5f2972c7-81ca-404a-9ee5-6fcbe51bb1d3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.145974ms
Nov 13 10:25:51.219: INFO: Pod "pod-secrets-5f2972c7-81ca-404a-9ee5-6fcbe51bb1d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005247852s
STEP: Saw pod success
Nov 13 10:25:51.219: INFO: Pod "pod-secrets-5f2972c7-81ca-404a-9ee5-6fcbe51bb1d3" satisfied condition "success or failure"
Nov 13 10:25:51.220: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-secrets-5f2972c7-81ca-404a-9ee5-6fcbe51bb1d3 container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 10:25:51.231: INFO: Waiting for pod pod-secrets-5f2972c7-81ca-404a-9ee5-6fcbe51bb1d3 to disappear
Nov 13 10:25:51.236: INFO: Pod pod-secrets-5f2972c7-81ca-404a-9ee5-6fcbe51bb1d3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:25:51.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2968" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":46,"skipped":669,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:25:51.240: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1949
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name s-test-opt-del-a02f0b84-9029-46fd-aff4-62fb7c3167cc
STEP: Creating secret with name s-test-opt-upd-6975d940-3755-4031-a5a5-23ad2643dfd8
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a02f0b84-9029-46fd-aff4-62fb7c3167cc
STEP: Updating secret s-test-opt-upd-6975d940-3755-4031-a5a5-23ad2643dfd8
STEP: Creating secret with name s-test-opt-create-fb1d5c66-5182-4a2a-8649-4ac83258ca69
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:26:57.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1949" for this suite.

• [SLOW TEST:66.346 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":278,"completed":47,"skipped":677,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:26:57.587: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7904
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:26:57.717: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov 13 10:26:57.733: INFO: Number of nodes with available pods: 0
Nov 13 10:26:57.733: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:26:58.738: INFO: Number of nodes with available pods: 0
Nov 13 10:26:58.739: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:26:59.737: INFO: Number of nodes with available pods: 1
Nov 13 10:26:59.737: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:27:00.738: INFO: Number of nodes with available pods: 2
Nov 13 10:27:00.738: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov 13 10:27:00.762: INFO: Wrong image for pod: daemon-set-7mwc4. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:00.762: INFO: Wrong image for pod: daemon-set-cxnzm. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:01.766: INFO: Wrong image for pod: daemon-set-7mwc4. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:01.766: INFO: Wrong image for pod: daemon-set-cxnzm. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:02.771: INFO: Wrong image for pod: daemon-set-7mwc4. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:02.771: INFO: Pod daemon-set-7mwc4 is not available
Nov 13 10:27:02.771: INFO: Wrong image for pod: daemon-set-cxnzm. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:03.766: INFO: Wrong image for pod: daemon-set-7mwc4. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:03.766: INFO: Pod daemon-set-7mwc4 is not available
Nov 13 10:27:03.766: INFO: Wrong image for pod: daemon-set-cxnzm. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:04.767: INFO: Wrong image for pod: daemon-set-7mwc4. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:04.767: INFO: Pod daemon-set-7mwc4 is not available
Nov 13 10:27:04.767: INFO: Wrong image for pod: daemon-set-cxnzm. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:05.766: INFO: Wrong image for pod: daemon-set-7mwc4. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:05.766: INFO: Pod daemon-set-7mwc4 is not available
Nov 13 10:27:05.766: INFO: Wrong image for pod: daemon-set-cxnzm. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:06.766: INFO: Wrong image for pod: daemon-set-7mwc4. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:06.766: INFO: Pod daemon-set-7mwc4 is not available
Nov 13 10:27:06.766: INFO: Wrong image for pod: daemon-set-cxnzm. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:07.766: INFO: Pod daemon-set-cgpx5 is not available
Nov 13 10:27:07.766: INFO: Wrong image for pod: daemon-set-cxnzm. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:08.766: INFO: Pod daemon-set-cgpx5 is not available
Nov 13 10:27:08.766: INFO: Wrong image for pod: daemon-set-cxnzm. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:09.766: INFO: Wrong image for pod: daemon-set-cxnzm. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:10.766: INFO: Wrong image for pod: daemon-set-cxnzm. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov 13 10:27:10.766: INFO: Pod daemon-set-cxnzm is not available
Nov 13 10:27:11.766: INFO: Pod daemon-set-tk9fh is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Nov 13 10:27:11.770: INFO: Number of nodes with available pods: 1
Nov 13 10:27:11.770: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:27:12.773: INFO: Number of nodes with available pods: 2
Nov 13 10:27:12.773: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7904, will wait for the garbage collector to delete the pods
Nov 13 10:27:12.833: INFO: Deleting DaemonSet.extensions daemon-set took: 3.563802ms
Nov 13 10:27:13.234: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.504734ms
Nov 13 10:27:18.836: INFO: Number of nodes with available pods: 0
Nov 13 10:27:18.836: INFO: Number of running nodes: 0, number of available pods: 0
Nov 13 10:27:18.837: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7904/daemonsets","resourceVersion":"298514"},"items":null}

Nov 13 10:27:18.837: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7904/pods","resourceVersion":"298514"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:27:18.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7904" for this suite.

• [SLOW TEST:21.257 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":278,"completed":48,"skipped":685,"failed":0}
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:27:18.845: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7800
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: getting the auto-created API token
STEP: reading a file in the container
Nov 13 10:27:21.482: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7800 pod-service-account-f1059cc1-b340-4d8e-b0b9-b208a6d74aa1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Nov 13 10:27:21.608: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7800 pod-service-account-f1059cc1-b340-4d8e-b0b9-b208a6d74aa1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Nov 13 10:27:21.747: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7800 pod-service-account-f1059cc1-b340-4d8e-b0b9-b208a6d74aa1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:27:21.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7800" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":278,"completed":49,"skipped":693,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:27:21.869: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6894
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: validating api versions
Nov 13 10:27:21.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 api-versions'
Nov 13 10:27:22.059: INFO: stderr: ""
Nov 13 10:27:22.059: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\ntraefik.containo.us/v1alpha1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:27:22.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6894" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":278,"completed":50,"skipped":695,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:27:22.063: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-9024
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:27:24.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9024" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":278,"completed":51,"skipped":697,"failed":0}
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:27:24.220: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1546
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:27:24.405: INFO: Waiting up to 5m0s for pod "downwardapi-volume-afddb085-1090-404f-bfcd-153a2a8fb1ce" in namespace "downward-api-1546" to be "success or failure"
Nov 13 10:27:24.409: INFO: Pod "downwardapi-volume-afddb085-1090-404f-bfcd-153a2a8fb1ce": Phase="Pending", Reason="", readiness=false. Elapsed: 3.838494ms
Nov 13 10:27:26.411: INFO: Pod "downwardapi-volume-afddb085-1090-404f-bfcd-153a2a8fb1ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006543612s
STEP: Saw pod success
Nov 13 10:27:26.411: INFO: Pod "downwardapi-volume-afddb085-1090-404f-bfcd-153a2a8fb1ce" satisfied condition "success or failure"
Nov 13 10:27:26.413: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-afddb085-1090-404f-bfcd-153a2a8fb1ce container client-container: <nil>
STEP: delete the pod
Nov 13 10:27:26.427: INFO: Waiting for pod downwardapi-volume-afddb085-1090-404f-bfcd-153a2a8fb1ce to disappear
Nov 13 10:27:26.432: INFO: Pod downwardapi-volume-afddb085-1090-404f-bfcd-153a2a8fb1ce no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:27:26.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1546" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":278,"completed":52,"skipped":701,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:27:26.437: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9503
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod liveness-602ba23c-3570-4ff4-8292-915da4f7b14d in namespace container-probe-9503
Nov 13 10:27:28.577: INFO: Started pod liveness-602ba23c-3570-4ff4-8292-915da4f7b14d in namespace container-probe-9503
STEP: checking the pod's current state and verifying that restartCount is present
Nov 13 10:27:28.578: INFO: Initial restart count of pod liveness-602ba23c-3570-4ff4-8292-915da4f7b14d is 0
Nov 13 10:27:40.590: INFO: Restart count of pod container-probe-9503/liveness-602ba23c-3570-4ff4-8292-915da4f7b14d is now 1 (12.011973593s elapsed)
Nov 13 10:28:00.610: INFO: Restart count of pod container-probe-9503/liveness-602ba23c-3570-4ff4-8292-915da4f7b14d is now 2 (32.031661044s elapsed)
Nov 13 10:28:22.630: INFO: Restart count of pod container-probe-9503/liveness-602ba23c-3570-4ff4-8292-915da4f7b14d is now 3 (54.052285093s elapsed)
Nov 13 10:28:42.652: INFO: Restart count of pod container-probe-9503/liveness-602ba23c-3570-4ff4-8292-915da4f7b14d is now 4 (1m14.074123667s elapsed)
Nov 13 10:29:54.723: INFO: Restart count of pod container-probe-9503/liveness-602ba23c-3570-4ff4-8292-915da4f7b14d is now 5 (2m26.145342464s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:29:54.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9503" for this suite.

• [SLOW TEST:148.308 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":278,"completed":53,"skipped":712,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:29:54.746: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-519
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-444f5d0d-3ea0-4db4-9730-09f54fc310b5
STEP: Creating a pod to test consume configMaps
Nov 13 10:29:54.877: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dffa1fff-9920-4eee-857c-7971a5f973c4" in namespace "projected-519" to be "success or failure"
Nov 13 10:29:54.885: INFO: Pod "pod-projected-configmaps-dffa1fff-9920-4eee-857c-7971a5f973c4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.15103ms
Nov 13 10:29:56.886: INFO: Pod "pod-projected-configmaps-dffa1fff-9920-4eee-857c-7971a5f973c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008994257s
STEP: Saw pod success
Nov 13 10:29:56.886: INFO: Pod "pod-projected-configmaps-dffa1fff-9920-4eee-857c-7971a5f973c4" satisfied condition "success or failure"
Nov 13 10:29:56.888: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-projected-configmaps-dffa1fff-9920-4eee-857c-7971a5f973c4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:29:56.901: INFO: Waiting for pod pod-projected-configmaps-dffa1fff-9920-4eee-857c-7971a5f973c4 to disappear
Nov 13 10:29:56.907: INFO: Pod pod-projected-configmaps-dffa1fff-9920-4eee-857c-7971a5f973c4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:29:56.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-519" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":54,"skipped":739,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:29:56.912: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8799
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod busybox-7799648f-e2f8-42c9-bca8-535d22fa452e in namespace container-probe-8799
Nov 13 10:29:59.061: INFO: Started pod busybox-7799648f-e2f8-42c9-bca8-535d22fa452e in namespace container-probe-8799
STEP: checking the pod's current state and verifying that restartCount is present
Nov 13 10:29:59.062: INFO: Initial restart count of pod busybox-7799648f-e2f8-42c9-bca8-535d22fa452e is 0
Nov 13 10:30:45.110: INFO: Restart count of pod container-probe-8799/busybox-7799648f-e2f8-42c9-bca8-535d22fa452e is now 1 (46.048541522s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:30:45.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8799" for this suite.

• [SLOW TEST:48.214 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":278,"completed":55,"skipped":766,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:30:45.127: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1022
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod busybox-fcfde617-9e86-409d-87b9-a0f8b52478c1 in namespace container-probe-1022
Nov 13 10:30:47.310: INFO: Started pod busybox-fcfde617-9e86-409d-87b9-a0f8b52478c1 in namespace container-probe-1022
STEP: checking the pod's current state and verifying that restartCount is present
Nov 13 10:30:47.312: INFO: Initial restart count of pod busybox-fcfde617-9e86-409d-87b9-a0f8b52478c1 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:34:47.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1022" for this suite.

• [SLOW TEST:242.595 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":278,"completed":56,"skipped":797,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:34:47.722: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3702
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run default
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1489
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 13 10:34:47.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-3702'
Nov 13 10:34:48.481: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 13 10:34:48.481: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1495
Nov 13 10:34:50.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete deployment e2e-test-httpd-deployment --namespace=kubectl-3702'
Nov 13 10:34:50.538: INFO: stderr: ""
Nov 13 10:34:50.538: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:34:50.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3702" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run default should create an rc or deployment from an image  [Conformance]","total":278,"completed":57,"skipped":833,"failed":0}

------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:34:50.543: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3444
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Nov 13 10:34:50.669: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:34:53.417: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:35:01.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3444" for this suite.

• [SLOW TEST:11.256 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":278,"completed":58,"skipped":833,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:35:01.799: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4517
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:35:01.929: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af88f672-21b7-46f4-81b4-5ea0b32162a0" in namespace "projected-4517" to be "success or failure"
Nov 13 10:35:01.933: INFO: Pod "downwardapi-volume-af88f672-21b7-46f4-81b4-5ea0b32162a0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.123869ms
Nov 13 10:35:03.936: INFO: Pod "downwardapi-volume-af88f672-21b7-46f4-81b4-5ea0b32162a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006391305s
STEP: Saw pod success
Nov 13 10:35:03.936: INFO: Pod "downwardapi-volume-af88f672-21b7-46f4-81b4-5ea0b32162a0" satisfied condition "success or failure"
Nov 13 10:35:03.937: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-af88f672-21b7-46f4-81b4-5ea0b32162a0 container client-container: <nil>
STEP: delete the pod
Nov 13 10:35:03.956: INFO: Waiting for pod downwardapi-volume-af88f672-21b7-46f4-81b4-5ea0b32162a0 to disappear
Nov 13 10:35:03.961: INFO: Pod downwardapi-volume-af88f672-21b7-46f4-81b4-5ea0b32162a0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:35:03.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4517" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":278,"completed":59,"skipped":835,"failed":0}
SS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:35:03.967: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8567
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8567.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8567.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8567.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8567.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 13 10:35:06.114: INFO: DNS probes using dns-test-ab35403e-ef82-4965-978d-58b87321c481 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8567.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8567.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8567.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8567.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 13 10:35:08.147: INFO: File wheezy_udp@dns-test-service-3.dns-8567.svc.cluster.local from pod  dns-8567/dns-test-4b02b4c0-a6ba-4e9b-b5af-e89979ac9e1a contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 13 10:35:08.149: INFO: Lookups using dns-8567/dns-test-4b02b4c0-a6ba-4e9b-b5af-e89979ac9e1a failed for: [wheezy_udp@dns-test-service-3.dns-8567.svc.cluster.local]

Nov 13 10:35:13.153: INFO: DNS probes using dns-test-4b02b4c0-a6ba-4e9b-b5af-e89979ac9e1a succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8567.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8567.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8567.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8567.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 13 10:35:15.189: INFO: DNS probes using dns-test-808f677c-c0c0-46b2-b2df-c37dc04fd7f1 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:35:15.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8567" for this suite.

• [SLOW TEST:11.268 seconds]
[sig-network] DNS
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":278,"completed":60,"skipped":837,"failed":0}
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:35:15.235: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8022
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-configmap-8fw7
STEP: Creating a pod to test atomic-volume-subpath
Nov 13 10:35:15.371: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-8fw7" in namespace "subpath-8022" to be "success or failure"
Nov 13 10:35:15.375: INFO: Pod "pod-subpath-test-configmap-8fw7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.803215ms
Nov 13 10:35:17.377: INFO: Pod "pod-subpath-test-configmap-8fw7": Phase="Running", Reason="", readiness=true. Elapsed: 2.006006141s
Nov 13 10:35:19.379: INFO: Pod "pod-subpath-test-configmap-8fw7": Phase="Running", Reason="", readiness=true. Elapsed: 4.008128472s
Nov 13 10:35:21.381: INFO: Pod "pod-subpath-test-configmap-8fw7": Phase="Running", Reason="", readiness=true. Elapsed: 6.01008468s
Nov 13 10:35:23.383: INFO: Pod "pod-subpath-test-configmap-8fw7": Phase="Running", Reason="", readiness=true. Elapsed: 8.011932591s
Nov 13 10:35:25.385: INFO: Pod "pod-subpath-test-configmap-8fw7": Phase="Running", Reason="", readiness=true. Elapsed: 10.014129006s
Nov 13 10:35:27.387: INFO: Pod "pod-subpath-test-configmap-8fw7": Phase="Running", Reason="", readiness=true. Elapsed: 12.016172086s
Nov 13 10:35:29.390: INFO: Pod "pod-subpath-test-configmap-8fw7": Phase="Running", Reason="", readiness=true. Elapsed: 14.018510101s
Nov 13 10:35:31.392: INFO: Pod "pod-subpath-test-configmap-8fw7": Phase="Running", Reason="", readiness=true. Elapsed: 16.020520839s
Nov 13 10:35:33.394: INFO: Pod "pod-subpath-test-configmap-8fw7": Phase="Running", Reason="", readiness=true. Elapsed: 18.02246088s
Nov 13 10:35:35.396: INFO: Pod "pod-subpath-test-configmap-8fw7": Phase="Running", Reason="", readiness=true. Elapsed: 20.024715993s
Nov 13 10:35:37.399: INFO: Pod "pod-subpath-test-configmap-8fw7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.02735938s
STEP: Saw pod success
Nov 13 10:35:37.399: INFO: Pod "pod-subpath-test-configmap-8fw7" satisfied condition "success or failure"
Nov 13 10:35:37.400: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-subpath-test-configmap-8fw7 container test-container-subpath-configmap-8fw7: <nil>
STEP: delete the pod
Nov 13 10:35:37.412: INFO: Waiting for pod pod-subpath-test-configmap-8fw7 to disappear
Nov 13 10:35:37.418: INFO: Pod pod-subpath-test-configmap-8fw7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-8fw7
Nov 13 10:35:37.418: INFO: Deleting pod "pod-subpath-test-configmap-8fw7" in namespace "subpath-8022"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:35:37.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8022" for this suite.

• [SLOW TEST:22.190 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":278,"completed":61,"skipped":839,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:35:37.428: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-673
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:35:45.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-673" for this suite.

• [SLOW TEST:8.146 seconds]
[sig-apps] Job
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":278,"completed":62,"skipped":852,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:35:45.574: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6140
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 13 10:35:47.710: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:35:47.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6140" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":278,"completed":63,"skipped":881,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:35:47.722: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2081
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov 13 10:35:47.855: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2081 /api/v1/namespaces/watch-2081/configmaps/e2e-watch-test-resource-version 4910e7be-5b0a-495f-8afc-9bf25c281dcc 300492 0 2020-11-13 10:35:47 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 13 10:35:47.855: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2081 /api/v1/namespaces/watch-2081/configmaps/e2e-watch-test-resource-version 4910e7be-5b0a-495f-8afc-9bf25c281dcc 300493 0 2020-11-13 10:35:47 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:35:47.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2081" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":278,"completed":64,"skipped":897,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:35:47.859: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2815
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-df6524d0-e36a-46e6-8983-84b8e2f2117d
STEP: Creating a pod to test consume configMaps
Nov 13 10:35:47.988: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c7c18a25-c8d1-4fdd-b083-4af009ac2a49" in namespace "projected-2815" to be "success or failure"
Nov 13 10:35:47.996: INFO: Pod "pod-projected-configmaps-c7c18a25-c8d1-4fdd-b083-4af009ac2a49": Phase="Pending", Reason="", readiness=false. Elapsed: 8.150668ms
Nov 13 10:35:49.998: INFO: Pod "pod-projected-configmaps-c7c18a25-c8d1-4fdd-b083-4af009ac2a49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010152843s
STEP: Saw pod success
Nov 13 10:35:49.998: INFO: Pod "pod-projected-configmaps-c7c18a25-c8d1-4fdd-b083-4af009ac2a49" satisfied condition "success or failure"
Nov 13 10:35:49.999: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-projected-configmaps-c7c18a25-c8d1-4fdd-b083-4af009ac2a49 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:35:50.009: INFO: Waiting for pod pod-projected-configmaps-c7c18a25-c8d1-4fdd-b083-4af009ac2a49 to disappear
Nov 13 10:35:50.014: INFO: Pod pod-projected-configmaps-c7c18a25-c8d1-4fdd-b083-4af009ac2a49 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:35:50.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2815" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":278,"completed":65,"skipped":920,"failed":0}
SSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:35:50.019: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4389
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Nov 13 10:35:50.142: INFO: Created pod &Pod{ObjectMeta:{dns-4389  dns-4389 /api/v1/namespaces/dns-4389/pods/dns-4389 6755e262-11fb-4912-916f-6bbc2e14944a 300522 0 2020-11-13 10:35:50 +0000 UTC <nil> <nil> map[] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4xzx8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4xzx8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4xzx8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
STEP: Verifying customized DNS suffix list is configured on pod...
Nov 13 10:35:52.146: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-4389 PodName:dns-4389 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:35:52.146: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Verifying customized DNS server is configured on pod...
Nov 13 10:35:52.217: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-4389 PodName:dns-4389 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:35:52.217: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:35:52.287: INFO: Deleting pod dns-4389...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:35:52.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4389" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":278,"completed":66,"skipped":928,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:35:52.307: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4235
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:36:03.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4235" for this suite.

• [SLOW TEST:11.192 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":278,"completed":67,"skipped":984,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:36:03.500: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1113
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:36:03.679: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e944b477-a43f-44b0-9cf3-5ab2e3b44095" in namespace "projected-1113" to be "success or failure"
Nov 13 10:36:03.684: INFO: Pod "downwardapi-volume-e944b477-a43f-44b0-9cf3-5ab2e3b44095": Phase="Pending", Reason="", readiness=false. Elapsed: 4.180064ms
Nov 13 10:36:05.686: INFO: Pod "downwardapi-volume-e944b477-a43f-44b0-9cf3-5ab2e3b44095": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006580853s
STEP: Saw pod success
Nov 13 10:36:05.686: INFO: Pod "downwardapi-volume-e944b477-a43f-44b0-9cf3-5ab2e3b44095" satisfied condition "success or failure"
Nov 13 10:36:05.687: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-e944b477-a43f-44b0-9cf3-5ab2e3b44095 container client-container: <nil>
STEP: delete the pod
Nov 13 10:36:05.699: INFO: Waiting for pod downwardapi-volume-e944b477-a43f-44b0-9cf3-5ab2e3b44095 to disappear
Nov 13 10:36:05.700: INFO: Pod downwardapi-volume-e944b477-a43f-44b0-9cf3-5ab2e3b44095 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:36:05.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1113" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":278,"completed":68,"skipped":997,"failed":0}
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:36:05.705: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3001
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-3001
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 13 10:36:05.827: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 13 10:36:25.880: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.5.53:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3001 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:36:25.880: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:36:25.967: INFO: Found all expected endpoints: [netserver-0]
Nov 13 10:36:25.970: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.43.186:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3001 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:36:25.970: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:36:26.055: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:36:26.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3001" for this suite.

• [SLOW TEST:20.355 seconds]
[sig-network] Networking
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":69,"skipped":999,"failed":0}
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:36:26.060: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap configmap-8240/configmap-test-ee2afee3-ce34-427e-ad0c-4e922426b9fc
STEP: Creating a pod to test consume configMaps
Nov 13 10:36:26.191: INFO: Waiting up to 5m0s for pod "pod-configmaps-615a637a-283a-4e12-8778-cf575dbc57a5" in namespace "configmap-8240" to be "success or failure"
Nov 13 10:36:26.199: INFO: Pod "pod-configmaps-615a637a-283a-4e12-8778-cf575dbc57a5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.446321ms
Nov 13 10:36:28.200: INFO: Pod "pod-configmaps-615a637a-283a-4e12-8778-cf575dbc57a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009279556s
STEP: Saw pod success
Nov 13 10:36:28.201: INFO: Pod "pod-configmaps-615a637a-283a-4e12-8778-cf575dbc57a5" satisfied condition "success or failure"
Nov 13 10:36:28.202: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-configmaps-615a637a-283a-4e12-8778-cf575dbc57a5 container env-test: <nil>
STEP: delete the pod
Nov 13 10:36:28.211: INFO: Waiting for pod pod-configmaps-615a637a-283a-4e12-8778-cf575dbc57a5 to disappear
Nov 13 10:36:28.217: INFO: Pod pod-configmaps-615a637a-283a-4e12-8778-cf575dbc57a5 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:36:28.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8240" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":278,"completed":70,"skipped":1000,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:36:28.222: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3169
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:36:28.345: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Nov 13 10:36:29.363: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:36:29.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3169" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":278,"completed":71,"skipped":1016,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:36:29.370: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2269
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Nov 13 10:36:34.017: INFO: Successfully updated pod "annotationupdate46f41c1a-8afd-4e90-9073-566645cbc41b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:36:38.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2269" for this suite.

• [SLOW TEST:8.667 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":278,"completed":72,"skipped":1035,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:36:38.038: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7168
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:36:38.696: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:36:41.706: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:36:41.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7168" for this suite.
STEP: Destroying namespace "webhook-7168-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":278,"completed":73,"skipped":1042,"failed":0}
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:36:41.786: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2346
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 13 10:36:43.923: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:36:43.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2346" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":278,"completed":74,"skipped":1044,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:36:43.938: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3592
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov 13 10:36:44.075: INFO: Number of nodes with available pods: 0
Nov 13 10:36:44.075: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:36:45.078: INFO: Number of nodes with available pods: 0
Nov 13 10:36:45.078: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:36:46.079: INFO: Number of nodes with available pods: 2
Nov 13 10:36:46.079: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov 13 10:36:46.105: INFO: Number of nodes with available pods: 1
Nov 13 10:36:46.105: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:36:47.109: INFO: Number of nodes with available pods: 1
Nov 13 10:36:47.109: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:36:48.110: INFO: Number of nodes with available pods: 2
Nov 13 10:36:48.110: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3592, will wait for the garbage collector to delete the pods
Nov 13 10:36:48.168: INFO: Deleting DaemonSet.extensions daemon-set took: 3.508479ms
Nov 13 10:36:48.268: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.228182ms
Nov 13 10:36:51.370: INFO: Number of nodes with available pods: 0
Nov 13 10:36:51.370: INFO: Number of running nodes: 0, number of available pods: 0
Nov 13 10:36:51.371: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3592/daemonsets","resourceVersion":"301158"},"items":null}

Nov 13 10:36:51.372: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3592/pods","resourceVersion":"301158"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:36:51.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3592" for this suite.

• [SLOW TEST:7.441 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":278,"completed":75,"skipped":1064,"failed":0}
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:36:51.380: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9943
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-09c41294-db7c-4a15-ac9e-fac48ffc46cc
STEP: Creating a pod to test consume secrets
Nov 13 10:36:51.513: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cac0896f-808e-4525-b16d-edce03c6f568" in namespace "projected-9943" to be "success or failure"
Nov 13 10:36:51.521: INFO: Pod "pod-projected-secrets-cac0896f-808e-4525-b16d-edce03c6f568": Phase="Pending", Reason="", readiness=false. Elapsed: 7.680849ms
Nov 13 10:36:53.523: INFO: Pod "pod-projected-secrets-cac0896f-808e-4525-b16d-edce03c6f568": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009742641s
STEP: Saw pod success
Nov 13 10:36:53.523: INFO: Pod "pod-projected-secrets-cac0896f-808e-4525-b16d-edce03c6f568" satisfied condition "success or failure"
Nov 13 10:36:53.525: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-projected-secrets-cac0896f-808e-4525-b16d-edce03c6f568 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 13 10:36:53.534: INFO: Waiting for pod pod-projected-secrets-cac0896f-808e-4525-b16d-edce03c6f568 to disappear
Nov 13 10:36:53.540: INFO: Pod pod-projected-secrets-cac0896f-808e-4525-b16d-edce03c6f568 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:36:53.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9943" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":76,"skipped":1068,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:36:53.545: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4669
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Nov 13 10:36:53.668: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Nov 13 10:37:02.620: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:37:04.315: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:37:14.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4669" for this suite.

• [SLOW TEST:20.976 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":278,"completed":77,"skipped":1071,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:37:14.521: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-3209
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-3209, will wait for the garbage collector to delete the pods
Nov 13 10:37:18.705: INFO: Deleting Job.batch foo took: 3.305742ms
Nov 13 10:37:21.005: INFO: Terminating Job.batch foo pods took: 2.30019256s
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:37:57.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3209" for this suite.

• [SLOW TEST:42.990 seconds]
[sig-apps] Job
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":278,"completed":78,"skipped":1081,"failed":0}
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:37:57.511: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-325
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:37:57.639: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov 13 10:38:02.641: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 13 10:38:02.641: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Nov 13 10:38:04.661: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-325 /apis/apps/v1/namespaces/deployment-325/deployments/test-cleanup-deployment 71bba9dc-89a1-4be7-a18f-ced621a7ab64 301517 1 2020-11-13 10:38:02 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005c714b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-11-13 10:38:02 +0000 UTC,LastTransitionTime:2020-11-13 10:38:02 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-55ffc6b7b6" has successfully progressed.,LastUpdateTime:2020-11-13 10:38:04 +0000 UTC,LastTransitionTime:2020-11-13 10:38:02 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 13 10:38:04.662: INFO: New ReplicaSet "test-cleanup-deployment-55ffc6b7b6" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-55ffc6b7b6  deployment-325 /apis/apps/v1/namespaces/deployment-325/replicasets/test-cleanup-deployment-55ffc6b7b6 86837d40-e3b1-43be-b400-605e8fa9f7e2 301507 1 2020-11-13 10:38:02 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 71bba9dc-89a1-4be7-a18f-ced621a7ab64 0xc005cbca07 0xc005cbca08}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55ffc6b7b6,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005cbca78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 13 10:38:04.664: INFO: Pod "test-cleanup-deployment-55ffc6b7b6-wrngl" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-55ffc6b7b6-wrngl test-cleanup-deployment-55ffc6b7b6- deployment-325 /api/v1/namespaces/deployment-325/pods/test-cleanup-deployment-55ffc6b7b6-wrngl b3e7ff64-400a-46af-a5e4-b59d6e680430 301506 0 2020-11-13 10:38:02 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-55ffc6b7b6 86837d40-e3b1-43be-b400-605e8fa9f7e2 0xc005cbcec7 0xc005cbcec8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jxn5r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jxn5r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jxn5r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 10:38:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 10:38:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 10:38:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 10:38:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:10.200.5.65,StartTime:2020-11-13 10:38:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-13 10:38:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5,ContainerID:docker://d4e5bf0728b34a5d2512f53a14bb80c859725aa51bd868bf756ed1c8370879c2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.5.65,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:38:04.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-325" for this suite.

• [SLOW TEST:7.158 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":278,"completed":79,"skipped":1083,"failed":0}
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:38:04.669: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-3625
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: getting the auto-created API token
Nov 13 10:38:05.311: INFO: created pod pod-service-account-defaultsa
Nov 13 10:38:05.311: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov 13 10:38:05.315: INFO: created pod pod-service-account-mountsa
Nov 13 10:38:05.316: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov 13 10:38:05.322: INFO: created pod pod-service-account-nomountsa
Nov 13 10:38:05.322: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov 13 10:38:05.332: INFO: created pod pod-service-account-defaultsa-mountspec
Nov 13 10:38:05.332: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov 13 10:38:05.339: INFO: created pod pod-service-account-mountsa-mountspec
Nov 13 10:38:05.339: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov 13 10:38:05.348: INFO: created pod pod-service-account-nomountsa-mountspec
Nov 13 10:38:05.349: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov 13 10:38:05.357: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov 13 10:38:05.357: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov 13 10:38:05.366: INFO: created pod pod-service-account-mountsa-nomountspec
Nov 13 10:38:05.366: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov 13 10:38:05.374: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov 13 10:38:05.374: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:38:05.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3625" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":278,"completed":80,"skipped":1090,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:38:05.399: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6192
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-6192
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating statefulset ss in namespace statefulset-6192
Nov 13 10:38:05.543: INFO: Found 0 stateful pods, waiting for 1
Nov 13 10:38:15.545: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Nov 13 10:38:15.557: INFO: Deleting all statefulset in ns statefulset-6192
Nov 13 10:38:15.570: INFO: Scaling statefulset ss to 0
Nov 13 10:38:35.591: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 10:38:35.592: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:38:35.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6192" for this suite.

• [SLOW TEST:30.211 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":278,"completed":81,"skipped":1132,"failed":0}
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:38:35.611: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2307
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:38:35.751: INFO: (0) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.831922ms)
Nov 13 10:38:35.754: INFO: (1) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.693209ms)
Nov 13 10:38:35.757: INFO: (2) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.729756ms)
Nov 13 10:38:35.759: INFO: (3) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.44841ms)
Nov 13 10:38:35.761: INFO: (4) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.155624ms)
Nov 13 10:38:35.763: INFO: (5) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.89669ms)
Nov 13 10:38:35.765: INFO: (6) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.934688ms)
Nov 13 10:38:35.768: INFO: (7) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.258057ms)
Nov 13 10:38:35.770: INFO: (8) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.19082ms)
Nov 13 10:38:35.772: INFO: (9) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.273146ms)
Nov 13 10:38:35.775: INFO: (10) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.491596ms)
Nov 13 10:38:35.778: INFO: (11) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.41674ms)
Nov 13 10:38:35.781: INFO: (12) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.400607ms)
Nov 13 10:38:35.783: INFO: (13) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.064338ms)
Nov 13 10:38:35.785: INFO: (14) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.946349ms)
Nov 13 10:38:35.787: INFO: (15) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.908747ms)
Nov 13 10:38:35.789: INFO: (16) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.130084ms)
Nov 13 10:38:35.791: INFO: (17) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.090961ms)
Nov 13 10:38:35.793: INFO: (18) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.109552ms)
Nov 13 10:38:35.796: INFO: (19) /api/v1/nodes/53f793a7-f5c9-4f32-8dff-29ce2b6c347c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.725633ms)
[AfterEach] version v1
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:38:35.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2307" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":278,"completed":82,"skipped":1137,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:38:35.802: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override command
Nov 13 10:38:35.933: INFO: Waiting up to 5m0s for pod "client-containers-5ccb5ae2-960c-4205-93db-4b44dc5e31cc" in namespace "containers-2915" to be "success or failure"
Nov 13 10:38:35.939: INFO: Pod "client-containers-5ccb5ae2-960c-4205-93db-4b44dc5e31cc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.270422ms
Nov 13 10:38:37.941: INFO: Pod "client-containers-5ccb5ae2-960c-4205-93db-4b44dc5e31cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007400511s
STEP: Saw pod success
Nov 13 10:38:37.941: INFO: Pod "client-containers-5ccb5ae2-960c-4205-93db-4b44dc5e31cc" satisfied condition "success or failure"
Nov 13 10:38:37.942: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod client-containers-5ccb5ae2-960c-4205-93db-4b44dc5e31cc container test-container: <nil>
STEP: delete the pod
Nov 13 10:38:37.958: INFO: Waiting for pod client-containers-5ccb5ae2-960c-4205-93db-4b44dc5e31cc to disappear
Nov 13 10:38:37.963: INFO: Pod client-containers-5ccb5ae2-960c-4205-93db-4b44dc5e31cc no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:38:37.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2915" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":278,"completed":83,"skipped":1149,"failed":0}
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:38:37.969: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1376
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-1376
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a new StatefulSet
Nov 13 10:38:38.108: INFO: Found 0 stateful pods, waiting for 3
Nov 13 10:38:48.110: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:38:48.110: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:38:48.110: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov 13 10:38:48.128: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov 13 10:38:58.153: INFO: Updating stateful set ss2
Nov 13 10:38:58.164: INFO: Waiting for Pod statefulset-1376/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Nov 13 10:39:08.203: INFO: Found 1 stateful pods, waiting for 3
Nov 13 10:39:18.206: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:39:18.206: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:39:18.206: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov 13 10:39:18.224: INFO: Updating stateful set ss2
Nov 13 10:39:18.242: INFO: Waiting for Pod statefulset-1376/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 13 10:39:28.245: INFO: Waiting for Pod statefulset-1376/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 13 10:39:38.260: INFO: Updating stateful set ss2
Nov 13 10:39:38.265: INFO: Waiting for StatefulSet statefulset-1376/ss2 to complete update
Nov 13 10:39:38.265: INFO: Waiting for Pod statefulset-1376/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 13 10:39:48.269: INFO: Waiting for StatefulSet statefulset-1376/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Nov 13 10:39:58.269: INFO: Deleting all statefulset in ns statefulset-1376
Nov 13 10:39:58.270: INFO: Scaling statefulset ss2 to 0
Nov 13 10:40:08.279: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 10:40:08.281: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:40:08.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1376" for this suite.

• [SLOW TEST:90.328 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":278,"completed":84,"skipped":1151,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:40:08.299: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3664
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a replication controller
Nov 13 10:40:08.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 create -f - --namespace=kubectl-3664'
Nov 13 10:40:08.634: INFO: stderr: ""
Nov 13 10:40:08.634: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 13 10:40:08.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3664'
Nov 13 10:40:08.695: INFO: stderr: ""
Nov 13 10:40:08.695: INFO: stdout: "update-demo-nautilus-6zmz9 update-demo-nautilus-b4scn "
Nov 13 10:40:08.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-6zmz9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3664'
Nov 13 10:40:08.744: INFO: stderr: ""
Nov 13 10:40:08.744: INFO: stdout: ""
Nov 13 10:40:08.744: INFO: update-demo-nautilus-6zmz9 is created but not running
Nov 13 10:40:13.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3664'
Nov 13 10:40:13.792: INFO: stderr: ""
Nov 13 10:40:13.792: INFO: stdout: "update-demo-nautilus-6zmz9 update-demo-nautilus-b4scn "
Nov 13 10:40:13.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-6zmz9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3664'
Nov 13 10:40:13.837: INFO: stderr: ""
Nov 13 10:40:13.837: INFO: stdout: "true"
Nov 13 10:40:13.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-6zmz9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3664'
Nov 13 10:40:13.888: INFO: stderr: ""
Nov 13 10:40:13.888: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 10:40:13.888: INFO: validating pod update-demo-nautilus-6zmz9
Nov 13 10:40:13.890: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 10:40:13.890: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 10:40:13.890: INFO: update-demo-nautilus-6zmz9 is verified up and running
Nov 13 10:40:13.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-b4scn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3664'
Nov 13 10:40:13.934: INFO: stderr: ""
Nov 13 10:40:13.934: INFO: stdout: "true"
Nov 13 10:40:13.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-b4scn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3664'
Nov 13 10:40:13.984: INFO: stderr: ""
Nov 13 10:40:13.984: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 10:40:13.984: INFO: validating pod update-demo-nautilus-b4scn
Nov 13 10:40:13.987: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 10:40:13.987: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 10:40:13.987: INFO: update-demo-nautilus-b4scn is verified up and running
STEP: using delete to clean up resources
Nov 13 10:40:13.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete --grace-period=0 --force -f - --namespace=kubectl-3664'
Nov 13 10:40:14.036: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 10:40:14.036: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 13 10:40:14.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3664'
Nov 13 10:40:14.093: INFO: stderr: "No resources found in kubectl-3664 namespace.\n"
Nov 13 10:40:14.093: INFO: stdout: ""
Nov 13 10:40:14.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -l name=update-demo --namespace=kubectl-3664 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 13 10:40:14.148: INFO: stderr: ""
Nov 13 10:40:14.148: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:40:14.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3664" for this suite.

• [SLOW TEST:5.853 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":278,"completed":85,"skipped":1172,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:40:14.152: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5172
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Nov 13 10:40:16.289: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-5172 PodName:pod-sharedvolume-6a3c8f7f-a40b-4f45-8ea5-cbb4a0760da1 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 10:40:16.289: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 10:40:16.373: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:40:16.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5172" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":278,"completed":86,"skipped":1180,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:40:16.380: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8738
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: set up a multi version CRD
Nov 13 10:40:16.508: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:40:29.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8738" for this suite.

• [SLOW TEST:13.309 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":278,"completed":87,"skipped":1182,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:40:29.691: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4533
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1113 10:41:09.830679      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 13 10:41:09.830: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:41:09.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4533" for this suite.

• [SLOW TEST:40.143 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":278,"completed":88,"skipped":1199,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:41:09.836: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6525
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod test-webserver-6f66d066-f632-4456-ae3f-e73b68eb100e in namespace container-probe-6525
Nov 13 10:41:11.975: INFO: Started pod test-webserver-6f66d066-f632-4456-ae3f-e73b68eb100e in namespace container-probe-6525
STEP: checking the pod's current state and verifying that restartCount is present
Nov 13 10:41:11.976: INFO: Initial restart count of pod test-webserver-6f66d066-f632-4456-ae3f-e73b68eb100e is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:45:12.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6525" for this suite.

• [SLOW TEST:242.404 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":278,"completed":89,"skipped":1212,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:45:12.241: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5592
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-map-9e8bf203-b31d-4c35-8178-b57eaf6b4568
STEP: Creating a pod to test consume secrets
Nov 13 10:45:12.374: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0242d7c8-9bdd-4be0-911a-398be6438e10" in namespace "projected-5592" to be "success or failure"
Nov 13 10:45:12.382: INFO: Pod "pod-projected-secrets-0242d7c8-9bdd-4be0-911a-398be6438e10": Phase="Pending", Reason="", readiness=false. Elapsed: 7.714388ms
Nov 13 10:45:14.384: INFO: Pod "pod-projected-secrets-0242d7c8-9bdd-4be0-911a-398be6438e10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00960693s
STEP: Saw pod success
Nov 13 10:45:14.384: INFO: Pod "pod-projected-secrets-0242d7c8-9bdd-4be0-911a-398be6438e10" satisfied condition "success or failure"
Nov 13 10:45:14.385: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-projected-secrets-0242d7c8-9bdd-4be0-911a-398be6438e10 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 13 10:45:14.400: INFO: Waiting for pod pod-projected-secrets-0242d7c8-9bdd-4be0-911a-398be6438e10 to disappear
Nov 13 10:45:14.405: INFO: Pod pod-projected-secrets-0242d7c8-9bdd-4be0-911a-398be6438e10 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:45:14.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5592" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":90,"skipped":1221,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:45:14.411: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2544
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov 13 10:45:18.610: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 13 10:45:18.612: INFO: Pod pod-with-poststart-http-hook still exists
Nov 13 10:45:20.612: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 13 10:45:20.614: INFO: Pod pod-with-poststart-http-hook still exists
Nov 13 10:45:22.612: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 13 10:45:22.614: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:45:22.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2544" for this suite.

• [SLOW TEST:8.207 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":278,"completed":91,"skipped":1240,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:45:22.618: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6942
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:45:33.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6942" for this suite.

• [SLOW TEST:11.200 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":278,"completed":92,"skipped":1248,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:45:33.818: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-383
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:45:33.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-383" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":278,"completed":93,"skipped":1254,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:45:33.963: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3279
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9381
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8063
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:45:40.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3279" for this suite.
STEP: Destroying namespace "nsdeletetest-9381" for this suite.
Nov 13 10:45:40.395: INFO: Namespace nsdeletetest-9381 was already deleted
STEP: Destroying namespace "nsdeletetest-8063" for this suite.

• [SLOW TEST:6.434 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":278,"completed":94,"skipped":1259,"failed":0}
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:45:40.399: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8081
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating replication controller my-hostname-basic-a0456490-e905-4c7a-b6a0-668bc6a698f1
Nov 13 10:45:40.526: INFO: Pod name my-hostname-basic-a0456490-e905-4c7a-b6a0-668bc6a698f1: Found 0 pods out of 1
Nov 13 10:45:45.529: INFO: Pod name my-hostname-basic-a0456490-e905-4c7a-b6a0-668bc6a698f1: Found 1 pods out of 1
Nov 13 10:45:45.529: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-a0456490-e905-4c7a-b6a0-668bc6a698f1" are running
Nov 13 10:45:45.531: INFO: Pod "my-hostname-basic-a0456490-e905-4c7a-b6a0-668bc6a698f1-s7pt7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-13 10:45:40 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-13 10:45:41 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-13 10:45:41 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-13 10:45:40 +0000 UTC Reason: Message:}])
Nov 13 10:45:45.531: INFO: Trying to dial the pod
Nov 13 10:45:50.537: INFO: Controller my-hostname-basic-a0456490-e905-4c7a-b6a0-668bc6a698f1: Got expected result from replica 1 [my-hostname-basic-a0456490-e905-4c7a-b6a0-668bc6a698f1-s7pt7]: "my-hostname-basic-a0456490-e905-4c7a-b6a0-668bc6a698f1-s7pt7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:45:50.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8081" for this suite.

• [SLOW TEST:10.143 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":278,"completed":95,"skipped":1259,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:45:50.542: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3446
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3446
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-3446
I1113 10:45:50.683310      20 runners.go:189] Created replication controller with name: externalname-service, namespace: services-3446, replica count: 2
Nov 13 10:45:53.733: INFO: Creating new exec pod
I1113 10:45:53.733653      20 runners.go:189] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 13 10:45:56.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-3446 execpodllhhh -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov 13 10:45:57.543: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 13 10:45:57.543: INFO: stdout: ""
Nov 13 10:45:57.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-3446 execpodllhhh -- /bin/sh -x -c nc -zv -t -w 2 10.100.200.159 80'
Nov 13 10:45:57.667: INFO: stderr: "+ nc -zv -t -w 2 10.100.200.159 80\nConnection to 10.100.200.159 80 port [tcp/http] succeeded!\n"
Nov 13 10:45:57.667: INFO: stdout: ""
Nov 13 10:45:57.667: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:45:57.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3446" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:7.142 seconds]
[sig-network] Services
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":278,"completed":96,"skipped":1270,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:45:57.683: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8832
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Nov 13 10:45:57.865: INFO: Pod name pod-release: Found 0 pods out of 1
Nov 13 10:46:02.869: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:46:02.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8832" for this suite.

• [SLOW TEST:5.221 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":278,"completed":97,"skipped":1300,"failed":0}
SSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:46:02.905: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6439
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:46:03.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6439" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":278,"completed":98,"skipped":1306,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:46:03.053: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4628
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:46:03.198: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov 13 10:46:08.200: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 13 10:46:08.200: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov 13 10:46:10.204: INFO: Creating deployment "test-rollover-deployment"
Nov 13 10:46:10.211: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov 13 10:46:12.217: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov 13 10:46:12.219: INFO: Ensure that both replica sets have 1 created replica
Nov 13 10:46:12.221: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov 13 10:46:12.225: INFO: Updating deployment test-rollover-deployment
Nov 13 10:46:12.225: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov 13 10:46:14.230: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov 13 10:46:14.233: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov 13 10:46:14.236: INFO: all replica sets need to contain the pod-template-hash label
Nov 13 10:46:14.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861173, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:46:16.239: INFO: all replica sets need to contain the pod-template-hash label
Nov 13 10:46:16.239: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861173, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:46:18.240: INFO: all replica sets need to contain the pod-template-hash label
Nov 13 10:46:18.240: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861173, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:46:20.240: INFO: all replica sets need to contain the pod-template-hash label
Nov 13 10:46:20.240: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861173, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:46:22.239: INFO: all replica sets need to contain the pod-template-hash label
Nov 13 10:46:22.240: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861173, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861170, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 10:46:24.240: INFO: 
Nov 13 10:46:24.240: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Nov 13 10:46:24.244: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-4628 /apis/apps/v1/namespaces/deployment-4628/deployments/test-rollover-deployment 4fad56e9-7ee0-4bb5-ae04-7d4eff17cc7c 303937 2 2020-11-13 10:46:10 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00308d678 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-11-13 10:46:10 +0000 UTC,LastTransitionTime:2020-11-13 10:46:10 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-574d6dfbff" has successfully progressed.,LastUpdateTime:2020-11-13 10:46:23 +0000 UTC,LastTransitionTime:2020-11-13 10:46:10 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 13 10:46:24.245: INFO: New ReplicaSet "test-rollover-deployment-574d6dfbff" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-574d6dfbff  deployment-4628 /apis/apps/v1/namespaces/deployment-4628/replicasets/test-rollover-deployment-574d6dfbff a292aa2d-2d9d-45dc-945c-b9488771deff 303926 2 2020-11-13 10:46:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 4fad56e9-7ee0-4bb5-ae04-7d4eff17cc7c 0xc00115bf37 0xc00115bf38}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 574d6dfbff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00115bfa8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 13 10:46:24.245: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov 13 10:46:24.245: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-4628 /apis/apps/v1/namespaces/deployment-4628/replicasets/test-rollover-controller a46347b6-3f16-4f6f-bd44-a7d8aaf932a0 303935 2 2020-11-13 10:46:03 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 4fad56e9-7ee0-4bb5-ae04-7d4eff17cc7c 0xc00115be67 0xc00115be68}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00115bec8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 13 10:46:24.246: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-4628 /apis/apps/v1/namespaces/deployment-4628/replicasets/test-rollover-deployment-f6c94f66c dd1e349d-040d-4a11-8f41-82e2b6304ad2 303881 2 2020-11-13 10:46:10 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 4fad56e9-7ee0-4bb5-ae04-7d4eff17cc7c 0xc0020d6010 0xc0020d6011}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0020d60e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 13 10:46:24.247: INFO: Pod "test-rollover-deployment-574d6dfbff-xzdqd" is available:
&Pod{ObjectMeta:{test-rollover-deployment-574d6dfbff-xzdqd test-rollover-deployment-574d6dfbff- deployment-4628 /api/v1/namespaces/deployment-4628/pods/test-rollover-deployment-574d6dfbff-xzdqd c754d3a3-e2ff-4d38-8394-c84944602532 303900 0 2020-11-13 10:46:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[] [{apps/v1 ReplicaSet test-rollover-deployment-574d6dfbff a292aa2d-2d9d-45dc-945c-b9488771deff 0xc00308da47 0xc00308da48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8n9qg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8n9qg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8n9qg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 10:46:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 10:46:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 10:46:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 10:46:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:10.200.5.96,StartTime:2020-11-13 10:46:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-13 10:46:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5,ContainerID:docker://ed6ff62e98995a9a084debfa5872e44eb1dacdb3014f57c903664ab60334dc7d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.5.96,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:46:24.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4628" for this suite.

• [SLOW TEST:21.198 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":278,"completed":99,"skipped":1366,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:46:24.251: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-882
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:46:24.375: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Creating first CR 
Nov 13 10:46:24.925: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-13T10:46:24Z generation:1 name:name1 resourceVersion:303954 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:8b7a7b0b-5d19-4970-a6ea-5e443eeb8ed9] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Nov 13 10:46:34.928: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-13T10:46:34Z generation:1 name:name2 resourceVersion:304031 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:6a1dfef7-37fd-49d7-9f92-06ea7f87c464] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Nov 13 10:46:44.932: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-13T10:46:24Z generation:2 name:name1 resourceVersion:304162 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:8b7a7b0b-5d19-4970-a6ea-5e443eeb8ed9] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Nov 13 10:46:54.935: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-13T10:46:34Z generation:2 name:name2 resourceVersion:304242 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:6a1dfef7-37fd-49d7-9f92-06ea7f87c464] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Nov 13 10:47:04.939: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-13T10:46:24Z generation:2 name:name1 resourceVersion:304266 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:8b7a7b0b-5d19-4970-a6ea-5e443eeb8ed9] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Nov 13 10:47:14.943: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-13T10:46:34Z generation:2 name:name2 resourceVersion:304291 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:6a1dfef7-37fd-49d7-9f92-06ea7f87c464] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:47:25.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-882" for this suite.

• [SLOW TEST:61.205 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:41
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":278,"completed":100,"skipped":1368,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:47:25.457: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9318
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov 13 10:47:28.108: INFO: Successfully updated pod "pod-update-2cc1d763-b62f-44a0-bffc-56841df5aa1f"
STEP: verifying the updated pod is in kubernetes
Nov 13 10:47:28.111: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:47:28.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9318" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":278,"completed":101,"skipped":1420,"failed":0}
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:47:28.117: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-548
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-f916910f-4a12-4ab5-925c-5f7a0b61add0
STEP: Creating a pod to test consume secrets
Nov 13 10:47:28.251: INFO: Waiting up to 5m0s for pod "pod-secrets-ae54bd52-dfc7-4403-a741-0d92fee47a04" in namespace "secrets-548" to be "success or failure"
Nov 13 10:47:28.258: INFO: Pod "pod-secrets-ae54bd52-dfc7-4403-a741-0d92fee47a04": Phase="Pending", Reason="", readiness=false. Elapsed: 7.354621ms
Nov 13 10:47:30.260: INFO: Pod "pod-secrets-ae54bd52-dfc7-4403-a741-0d92fee47a04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009415358s
STEP: Saw pod success
Nov 13 10:47:30.260: INFO: Pod "pod-secrets-ae54bd52-dfc7-4403-a741-0d92fee47a04" satisfied condition "success or failure"
Nov 13 10:47:30.262: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-secrets-ae54bd52-dfc7-4403-a741-0d92fee47a04 container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 10:47:30.271: INFO: Waiting for pod pod-secrets-ae54bd52-dfc7-4403-a741-0d92fee47a04 to disappear
Nov 13 10:47:30.276: INFO: Pod pod-secrets-ae54bd52-dfc7-4403-a741-0d92fee47a04 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:47:30.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-548" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":102,"skipped":1422,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:47:30.281: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6869
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-6869
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6869
STEP: Creating statefulset with conflicting port in namespace statefulset-6869
STEP: Waiting until pod test-pod will start running in namespace statefulset-6869
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6869
Nov 13 10:47:34.426: INFO: Observed stateful pod in namespace: statefulset-6869, name: ss-0, uid: f2454471-81e5-4249-8e09-6259856fa3db, status phase: Pending. Waiting for statefulset controller to delete.
Nov 13 10:47:35.203: INFO: Observed stateful pod in namespace: statefulset-6869, name: ss-0, uid: f2454471-81e5-4249-8e09-6259856fa3db, status phase: Failed. Waiting for statefulset controller to delete.
Nov 13 10:47:35.206: INFO: Observed stateful pod in namespace: statefulset-6869, name: ss-0, uid: f2454471-81e5-4249-8e09-6259856fa3db, status phase: Failed. Waiting for statefulset controller to delete.
Nov 13 10:47:35.212: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6869
STEP: Removing pod with conflicting port in namespace statefulset-6869
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6869 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Nov 13 10:47:39.239: INFO: Deleting all statefulset in ns statefulset-6869
Nov 13 10:47:39.241: INFO: Scaling statefulset ss to 0
Nov 13 10:47:49.250: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 10:47:49.251: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:47:49.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6869" for this suite.

• [SLOW TEST:18.981 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":278,"completed":103,"skipped":1454,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:47:49.263: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2866
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:47:49.801: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 13 10:47:51.805: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861269, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861269, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861269, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861269, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:47:54.821: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Nov 13 10:47:54.835: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:47:54.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2866" for this suite.
STEP: Destroying namespace "webhook-2866-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.642 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":278,"completed":104,"skipped":1481,"failed":0}
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:47:54.906: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6464
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap configmap-6464/configmap-test-80dcefdf-e8da-481e-8324-e9f8bf4aaa1c
STEP: Creating a pod to test consume configMaps
Nov 13 10:47:55.087: INFO: Waiting up to 5m0s for pod "pod-configmaps-d5918954-0c76-4a08-9b42-de1a546d2609" in namespace "configmap-6464" to be "success or failure"
Nov 13 10:47:55.091: INFO: Pod "pod-configmaps-d5918954-0c76-4a08-9b42-de1a546d2609": Phase="Pending", Reason="", readiness=false. Elapsed: 3.843004ms
Nov 13 10:47:57.093: INFO: Pod "pod-configmaps-d5918954-0c76-4a08-9b42-de1a546d2609": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006016881s
STEP: Saw pod success
Nov 13 10:47:57.093: INFO: Pod "pod-configmaps-d5918954-0c76-4a08-9b42-de1a546d2609" satisfied condition "success or failure"
Nov 13 10:47:57.094: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-configmaps-d5918954-0c76-4a08-9b42-de1a546d2609 container env-test: <nil>
STEP: delete the pod
Nov 13 10:47:57.104: INFO: Waiting for pod pod-configmaps-d5918954-0c76-4a08-9b42-de1a546d2609 to disappear
Nov 13 10:47:57.109: INFO: Pod pod-configmaps-d5918954-0c76-4a08-9b42-de1a546d2609 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:47:57.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6464" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":278,"completed":105,"skipped":1489,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:47:57.115: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5677
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:47:57.238: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Nov 13 10:47:58.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-5677 create -f -'
Nov 13 10:47:59.825: INFO: stderr: ""
Nov 13 10:47:59.825: INFO: stdout: "e2e-test-crd-publish-openapi-1906-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov 13 10:47:59.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-5677 delete e2e-test-crd-publish-openapi-1906-crds test-foo'
Nov 13 10:47:59.887: INFO: stderr: ""
Nov 13 10:47:59.887: INFO: stdout: "e2e-test-crd-publish-openapi-1906-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Nov 13 10:47:59.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-5677 apply -f -'
Nov 13 10:48:00.012: INFO: stderr: ""
Nov 13 10:48:00.012: INFO: stdout: "e2e-test-crd-publish-openapi-1906-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov 13 10:48:00.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-5677 delete e2e-test-crd-publish-openapi-1906-crds test-foo'
Nov 13 10:48:00.077: INFO: stderr: ""
Nov 13 10:48:00.077: INFO: stdout: "e2e-test-crd-publish-openapi-1906-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Nov 13 10:48:00.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-5677 create -f -'
Nov 13 10:48:00.185: INFO: rc: 1
Nov 13 10:48:00.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-5677 apply -f -'
Nov 13 10:48:00.286: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Nov 13 10:48:00.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-5677 create -f -'
Nov 13 10:48:00.389: INFO: rc: 1
Nov 13 10:48:00.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-5677 apply -f -'
Nov 13 10:48:00.481: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Nov 13 10:48:00.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 explain e2e-test-crd-publish-openapi-1906-crds'
Nov 13 10:48:00.577: INFO: stderr: ""
Nov 13 10:48:00.577: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1906-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Nov 13 10:48:00.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 explain e2e-test-crd-publish-openapi-1906-crds.metadata'
Nov 13 10:48:00.686: INFO: stderr: ""
Nov 13 10:48:00.686: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1906-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Nov 13 10:48:00.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 explain e2e-test-crd-publish-openapi-1906-crds.spec'
Nov 13 10:48:00.787: INFO: stderr: ""
Nov 13 10:48:00.787: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1906-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Nov 13 10:48:00.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 explain e2e-test-crd-publish-openapi-1906-crds.spec.bars'
Nov 13 10:48:00.895: INFO: stderr: ""
Nov 13 10:48:00.895: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1906-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Nov 13 10:48:00.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 explain e2e-test-crd-publish-openapi-1906-crds.spec.bars2'
Nov 13 10:48:01.011: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:48:03.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5677" for this suite.

• [SLOW TEST:6.505 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":278,"completed":106,"skipped":1491,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:48:03.620: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1439
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Nov 13 10:48:03.743: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 13 10:48:03.747: INFO: Waiting for terminating namespaces to be deleted...
Nov 13 10:48:03.748: INFO: 
Logging pods the kubelet thinks is on node 29607307-5497-41cc-a8d5-c2f7d9a90e41 before test
Nov 13 10:48:03.752: INFO: traefik-ingress-controller-v48l8 from traefik-ingress started at 2020-11-12 01:09:03 +0000 UTC (1 container statuses recorded)
Nov 13 10:48:03.752: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov 13 10:48:03.752: INFO: sonobuoy-systemd-logs-daemon-set-294e69fb102c4fcf-tncdk from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 10:48:03.752: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 10:48:03.752: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 13 10:48:03.752: INFO: coredns-54b9777bfc-nhhjt from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 10:48:03.752: INFO: 	Container coredns ready: true, restart count 0
Nov 13 10:48:03.752: INFO: metrics-server-5df78f85b-kzd6m from kube-system started at 2020-11-12 01:07:27 +0000 UTC (1 container statuses recorded)
Nov 13 10:48:03.752: INFO: 	Container metrics-server ready: true, restart count 0
Nov 13 10:48:03.752: INFO: filebeat-chjmw from kube-system started at 2020-11-12 01:08:33 +0000 UTC (1 container statuses recorded)
Nov 13 10:48:03.752: INFO: 	Container filebeat ready: true, restart count 0
Nov 13 10:48:03.752: INFO: sonobuoy from sonobuoy started at 2020-11-13 09:37:07 +0000 UTC (1 container statuses recorded)
Nov 13 10:48:03.752: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 13 10:48:03.752: INFO: 
Logging pods the kubelet thinks is on node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c before test
Nov 13 10:48:03.761: INFO: coredns-54b9777bfc-jj6kl from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 10:48:03.761: INFO: 	Container coredns ready: true, restart count 0
Nov 13 10:48:03.761: INFO: filebeat-zxtp6 from kube-system started at 2020-11-12 01:08:33 +0000 UTC (1 container statuses recorded)
Nov 13 10:48:03.761: INFO: 	Container filebeat ready: true, restart count 0
Nov 13 10:48:03.761: INFO: sonobuoy-e2e-job-b8fa8fc01c7d4f11 from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 10:48:03.761: INFO: 	Container e2e ready: true, restart count 0
Nov 13 10:48:03.761: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 10:48:03.761: INFO: coredns-54b9777bfc-q6tzp from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 10:48:03.761: INFO: 	Container coredns ready: true, restart count 0
Nov 13 10:48:03.761: INFO: traefik-ingress-controller-xbfqn from traefik-ingress started at 2020-11-12 01:09:03 +0000 UTC (1 container statuses recorded)
Nov 13 10:48:03.761: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov 13 10:48:03.761: INFO: sonobuoy-systemd-logs-daemon-set-294e69fb102c4fcf-fk6ph from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 10:48:03.761: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 10:48:03.761: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: verifying the node has the label node 29607307-5497-41cc-a8d5-c2f7d9a90e41
STEP: verifying the node has the label node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c
Nov 13 10:48:03.779: INFO: Pod coredns-54b9777bfc-jj6kl requesting resource cpu=100m on Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c
Nov 13 10:48:03.779: INFO: Pod coredns-54b9777bfc-nhhjt requesting resource cpu=100m on Node 29607307-5497-41cc-a8d5-c2f7d9a90e41
Nov 13 10:48:03.779: INFO: Pod coredns-54b9777bfc-q6tzp requesting resource cpu=100m on Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c
Nov 13 10:48:03.779: INFO: Pod filebeat-chjmw requesting resource cpu=200m on Node 29607307-5497-41cc-a8d5-c2f7d9a90e41
Nov 13 10:48:03.779: INFO: Pod filebeat-zxtp6 requesting resource cpu=200m on Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c
Nov 13 10:48:03.779: INFO: Pod metrics-server-5df78f85b-kzd6m requesting resource cpu=0m on Node 29607307-5497-41cc-a8d5-c2f7d9a90e41
Nov 13 10:48:03.779: INFO: Pod sonobuoy requesting resource cpu=0m on Node 29607307-5497-41cc-a8d5-c2f7d9a90e41
Nov 13 10:48:03.779: INFO: Pod sonobuoy-e2e-job-b8fa8fc01c7d4f11 requesting resource cpu=0m on Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c
Nov 13 10:48:03.779: INFO: Pod sonobuoy-systemd-logs-daemon-set-294e69fb102c4fcf-fk6ph requesting resource cpu=0m on Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c
Nov 13 10:48:03.779: INFO: Pod sonobuoy-systemd-logs-daemon-set-294e69fb102c4fcf-tncdk requesting resource cpu=0m on Node 29607307-5497-41cc-a8d5-c2f7d9a90e41
Nov 13 10:48:03.779: INFO: Pod traefik-ingress-controller-v48l8 requesting resource cpu=0m on Node 29607307-5497-41cc-a8d5-c2f7d9a90e41
Nov 13 10:48:03.779: INFO: Pod traefik-ingress-controller-xbfqn requesting resource cpu=0m on Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c
STEP: Starting Pods to consume most of the cluster CPU.
Nov 13 10:48:03.779: INFO: Creating a pod which consumes cpu=1190m on Node 29607307-5497-41cc-a8d5-c2f7d9a90e41
Nov 13 10:48:03.786: INFO: Creating a pod which consumes cpu=1120m on Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ba4dd34d-5a19-4fba-94d2-c09271b42ae2.16470b8aff28f701], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1439/filler-pod-ba4dd34d-5a19-4fba-94d2-c09271b42ae2 to 29607307-5497-41cc-a8d5-c2f7d9a90e41]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ba4dd34d-5a19-4fba-94d2-c09271b42ae2.16470b8b2f0fdb5e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ba4dd34d-5a19-4fba-94d2-c09271b42ae2.16470b8b316ea840], Reason = [Created], Message = [Created container filler-pod-ba4dd34d-5a19-4fba-94d2-c09271b42ae2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ba4dd34d-5a19-4fba-94d2-c09271b42ae2.16470b8b39246b06], Reason = [Started], Message = [Started container filler-pod-ba4dd34d-5a19-4fba-94d2-c09271b42ae2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ec955279-587d-447c-a8c1-80f88e58f3ff.16470b8aff2c07ec], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1439/filler-pod-ec955279-587d-447c-a8c1-80f88e58f3ff to 53f793a7-f5c9-4f32-8dff-29ce2b6c347c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ec955279-587d-447c-a8c1-80f88e58f3ff.16470b8b2d13b39a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ec955279-587d-447c-a8c1-80f88e58f3ff.16470b8b3003fc65], Reason = [Created], Message = [Created container filler-pod-ec955279-587d-447c-a8c1-80f88e58f3ff]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ec955279-587d-447c-a8c1-80f88e58f3ff.16470b8b378c104f], Reason = [Started], Message = [Started container filler-pod-ec955279-587d-447c-a8c1-80f88e58f3ff]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.16470b8b76f43e43], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node 29607307-5497-41cc-a8d5-c2f7d9a90e41
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:48:06.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1439" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":278,"completed":107,"skipped":1507,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:48:06.825: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5903
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:48:07.294: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 13 10:48:09.298: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861287, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861287, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861287, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861287, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:48:12.306: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:48:12.307: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:48:13.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5903" for this suite.
STEP: Destroying namespace "webhook-5903-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.794 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":278,"completed":108,"skipped":1564,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:48:13.623: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-6668
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test hostPath mode
Nov 13 10:48:13.754: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-6668" to be "success or failure"
Nov 13 10:48:13.758: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.468578ms
Nov 13 10:48:15.760: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005398361s
STEP: Saw pod success
Nov 13 10:48:15.760: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov 13 10:48:15.761: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov 13 10:48:15.771: INFO: Waiting for pod pod-host-path-test to disappear
Nov 13 10:48:15.776: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:48:15.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-6668" for this suite.
•{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":109,"skipped":1587,"failed":0}
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:48:15.780: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4696
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test env composition
Nov 13 10:48:15.910: INFO: Waiting up to 5m0s for pod "var-expansion-444a01e0-e48f-4100-b6ec-50a0ac82f593" in namespace "var-expansion-4696" to be "success or failure"
Nov 13 10:48:15.914: INFO: Pod "var-expansion-444a01e0-e48f-4100-b6ec-50a0ac82f593": Phase="Pending", Reason="", readiness=false. Elapsed: 3.824016ms
Nov 13 10:48:17.916: INFO: Pod "var-expansion-444a01e0-e48f-4100-b6ec-50a0ac82f593": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00598162s
STEP: Saw pod success
Nov 13 10:48:17.916: INFO: Pod "var-expansion-444a01e0-e48f-4100-b6ec-50a0ac82f593" satisfied condition "success or failure"
Nov 13 10:48:17.917: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod var-expansion-444a01e0-e48f-4100-b6ec-50a0ac82f593 container dapi-container: <nil>
STEP: delete the pod
Nov 13 10:48:17.931: INFO: Waiting for pod var-expansion-444a01e0-e48f-4100-b6ec-50a0ac82f593 to disappear
Nov 13 10:48:17.933: INFO: Pod var-expansion-444a01e0-e48f-4100-b6ec-50a0ac82f593 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:48:17.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4696" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":278,"completed":110,"skipped":1590,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:48:17.940: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6300
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-8z68c in namespace proxy-6300
I1113 10:48:18.073945      20 runners.go:189] Created replication controller with name: proxy-service-8z68c, namespace: proxy-6300, replica count: 1
I1113 10:48:19.125093      20 runners.go:189] proxy-service-8z68c Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1113 10:48:20.125270      20 runners.go:189] proxy-service-8z68c Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1113 10:48:21.125423      20 runners.go:189] proxy-service-8z68c Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1113 10:48:22.125569      20 runners.go:189] proxy-service-8z68c Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1113 10:48:23.125955      20 runners.go:189] proxy-service-8z68c Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1113 10:48:24.126131      20 runners.go:189] proxy-service-8z68c Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1113 10:48:25.126279      20 runners.go:189] proxy-service-8z68c Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 13 10:48:25.128: INFO: setup took 7.063777478s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov 13 10:48:25.135: INFO: (0) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 6.840302ms)
Nov 13 10:48:25.141: INFO: (0) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 13.366715ms)
Nov 13 10:48:25.142: INFO: (0) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 13.632728ms)
Nov 13 10:48:25.142: INFO: (0) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 13.960652ms)
Nov 13 10:48:25.148: INFO: (0) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 19.92341ms)
Nov 13 10:48:25.148: INFO: (0) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 20.011895ms)
Nov 13 10:48:25.148: INFO: (0) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 20.073234ms)
Nov 13 10:48:25.148: INFO: (0) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 20.024475ms)
Nov 13 10:48:25.148: INFO: (0) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 20.021719ms)
Nov 13 10:48:25.148: INFO: (0) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 20.151264ms)
Nov 13 10:48:25.148: INFO: (0) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 20.570204ms)
Nov 13 10:48:25.149: INFO: (0) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 20.8454ms)
Nov 13 10:48:25.149: INFO: (0) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 20.803256ms)
Nov 13 10:48:25.149: INFO: (0) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 20.793059ms)
Nov 13 10:48:25.149: INFO: (0) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 20.990897ms)
Nov 13 10:48:25.149: INFO: (0) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 21.063234ms)
Nov 13 10:48:25.157: INFO: (1) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 7.579021ms)
Nov 13 10:48:25.157: INFO: (1) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 7.954136ms)
Nov 13 10:48:25.158: INFO: (1) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 9.339605ms)
Nov 13 10:48:25.161: INFO: (1) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 11.653046ms)
Nov 13 10:48:25.161: INFO: (1) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 11.890983ms)
Nov 13 10:48:25.161: INFO: (1) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 11.802492ms)
Nov 13 10:48:25.161: INFO: (1) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 11.860617ms)
Nov 13 10:48:25.161: INFO: (1) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 12.362225ms)
Nov 13 10:48:25.161: INFO: (1) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 12.100027ms)
Nov 13 10:48:25.162: INFO: (1) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 12.320453ms)
Nov 13 10:48:25.162: INFO: (1) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 12.477185ms)
Nov 13 10:48:25.162: INFO: (1) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 12.484797ms)
Nov 13 10:48:25.162: INFO: (1) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 12.630229ms)
Nov 13 10:48:25.162: INFO: (1) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 12.901516ms)
Nov 13 10:48:25.162: INFO: (1) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 12.83261ms)
Nov 13 10:48:25.162: INFO: (1) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 12.752166ms)
Nov 13 10:48:25.169: INFO: (2) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 6.854178ms)
Nov 13 10:48:25.170: INFO: (2) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 7.250694ms)
Nov 13 10:48:25.170: INFO: (2) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 7.731741ms)
Nov 13 10:48:25.172: INFO: (2) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 9.654813ms)
Nov 13 10:48:25.173: INFO: (2) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 10.749352ms)
Nov 13 10:48:25.173: INFO: (2) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 10.74853ms)
Nov 13 10:48:25.173: INFO: (2) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 10.91301ms)
Nov 13 10:48:25.173: INFO: (2) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 10.847663ms)
Nov 13 10:48:25.173: INFO: (2) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 10.965849ms)
Nov 13 10:48:25.173: INFO: (2) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 11.077054ms)
Nov 13 10:48:25.173: INFO: (2) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 11.046487ms)
Nov 13 10:48:25.174: INFO: (2) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 11.767338ms)
Nov 13 10:48:25.174: INFO: (2) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 11.797ms)
Nov 13 10:48:25.174: INFO: (2) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 11.91565ms)
Nov 13 10:48:25.175: INFO: (2) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 12.245863ms)
Nov 13 10:48:25.175: INFO: (2) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 12.397469ms)
Nov 13 10:48:25.180: INFO: (3) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 5.763951ms)
Nov 13 10:48:25.183: INFO: (3) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 8.125545ms)
Nov 13 10:48:25.183: INFO: (3) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 7.821582ms)
Nov 13 10:48:25.184: INFO: (3) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 8.198916ms)
Nov 13 10:48:25.184: INFO: (3) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 8.701334ms)
Nov 13 10:48:25.184: INFO: (3) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 9.221072ms)
Nov 13 10:48:25.184: INFO: (3) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 8.907569ms)
Nov 13 10:48:25.186: INFO: (3) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 10.496088ms)
Nov 13 10:48:25.186: INFO: (3) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 11.469135ms)
Nov 13 10:48:25.187: INFO: (3) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 10.608343ms)
Nov 13 10:48:25.187: INFO: (3) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 11.183836ms)
Nov 13 10:48:25.187: INFO: (3) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 11.153799ms)
Nov 13 10:48:25.187: INFO: (3) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 11.8565ms)
Nov 13 10:48:25.187: INFO: (3) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 11.695521ms)
Nov 13 10:48:25.187: INFO: (3) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 11.353119ms)
Nov 13 10:48:25.187: INFO: (3) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 11.561534ms)
Nov 13 10:48:25.195: INFO: (4) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 7.515622ms)
Nov 13 10:48:25.196: INFO: (4) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 8.01102ms)
Nov 13 10:48:25.197: INFO: (4) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 8.902494ms)
Nov 13 10:48:25.197: INFO: (4) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 8.964621ms)
Nov 13 10:48:25.197: INFO: (4) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 9.398591ms)
Nov 13 10:48:25.197: INFO: (4) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 9.370907ms)
Nov 13 10:48:25.197: INFO: (4) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 9.503483ms)
Nov 13 10:48:25.197: INFO: (4) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 9.253623ms)
Nov 13 10:48:25.199: INFO: (4) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 11.649832ms)
Nov 13 10:48:25.199: INFO: (4) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 11.464092ms)
Nov 13 10:48:25.200: INFO: (4) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 11.831857ms)
Nov 13 10:48:25.200: INFO: (4) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 12.050984ms)
Nov 13 10:48:25.200: INFO: (4) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 11.860648ms)
Nov 13 10:48:25.200: INFO: (4) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 11.832717ms)
Nov 13 10:48:25.200: INFO: (4) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 11.985017ms)
Nov 13 10:48:25.200: INFO: (4) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 12.715446ms)
Nov 13 10:48:25.208: INFO: (5) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 7.446254ms)
Nov 13 10:48:25.210: INFO: (5) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 8.404341ms)
Nov 13 10:48:25.211: INFO: (5) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 9.253877ms)
Nov 13 10:48:25.211: INFO: (5) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 9.556692ms)
Nov 13 10:48:25.211: INFO: (5) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 9.299384ms)
Nov 13 10:48:25.211: INFO: (5) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 9.914923ms)
Nov 13 10:48:25.211: INFO: (5) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 10.047257ms)
Nov 13 10:48:25.211: INFO: (5) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 9.883171ms)
Nov 13 10:48:25.211: INFO: (5) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 9.372071ms)
Nov 13 10:48:25.212: INFO: (5) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 11.635861ms)
Nov 13 10:48:25.212: INFO: (5) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 11.171958ms)
Nov 13 10:48:25.212: INFO: (5) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 11.275043ms)
Nov 13 10:48:25.212: INFO: (5) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 10.971731ms)
Nov 13 10:48:25.212: INFO: (5) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 11.226008ms)
Nov 13 10:48:25.213: INFO: (5) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 11.351243ms)
Nov 13 10:48:25.213: INFO: (5) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 12.205672ms)
Nov 13 10:48:25.221: INFO: (6) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 8.333914ms)
Nov 13 10:48:25.225: INFO: (6) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 10.786135ms)
Nov 13 10:48:25.225: INFO: (6) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 11.425854ms)
Nov 13 10:48:25.226: INFO: (6) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 11.812181ms)
Nov 13 10:48:25.226: INFO: (6) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 12.80347ms)
Nov 13 10:48:25.226: INFO: (6) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 12.656413ms)
Nov 13 10:48:25.226: INFO: (6) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 12.705258ms)
Nov 13 10:48:25.226: INFO: (6) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 12.671763ms)
Nov 13 10:48:25.226: INFO: (6) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 12.82666ms)
Nov 13 10:48:25.227: INFO: (6) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 12.85919ms)
Nov 13 10:48:25.229: INFO: (6) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 15.704578ms)
Nov 13 10:48:25.230: INFO: (6) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 16.634958ms)
Nov 13 10:48:25.231: INFO: (6) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 17.731318ms)
Nov 13 10:48:25.232: INFO: (6) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 19.138634ms)
Nov 13 10:48:25.233: INFO: (6) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 19.539247ms)
Nov 13 10:48:25.233: INFO: (6) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 19.09601ms)
Nov 13 10:48:25.247: INFO: (7) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 14.238756ms)
Nov 13 10:48:25.248: INFO: (7) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 14.351687ms)
Nov 13 10:48:25.251: INFO: (7) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 17.579446ms)
Nov 13 10:48:25.252: INFO: (7) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 18.459337ms)
Nov 13 10:48:25.253: INFO: (7) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 19.701224ms)
Nov 13 10:48:25.253: INFO: (7) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 19.811819ms)
Nov 13 10:48:25.257: INFO: (7) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 23.224978ms)
Nov 13 10:48:25.257: INFO: (7) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 22.932311ms)
Nov 13 10:48:25.257: INFO: (7) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 23.029425ms)
Nov 13 10:48:25.257: INFO: (7) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 23.024151ms)
Nov 13 10:48:25.257: INFO: (7) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 23.105162ms)
Nov 13 10:48:25.258: INFO: (7) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 24.754096ms)
Nov 13 10:48:25.266: INFO: (7) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 32.655759ms)
Nov 13 10:48:25.272: INFO: (7) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 39.060807ms)
Nov 13 10:48:25.273: INFO: (7) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 39.045797ms)
Nov 13 10:48:25.274: INFO: (7) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 40.92572ms)
Nov 13 10:48:25.295: INFO: (8) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 20.20279ms)
Nov 13 10:48:25.295: INFO: (8) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 20.068347ms)
Nov 13 10:48:25.295: INFO: (8) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 20.411469ms)
Nov 13 10:48:25.296: INFO: (8) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 21.759381ms)
Nov 13 10:48:25.301: INFO: (8) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 26.179512ms)
Nov 13 10:48:25.301: INFO: (8) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 26.422992ms)
Nov 13 10:48:25.301: INFO: (8) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 26.27021ms)
Nov 13 10:48:25.301: INFO: (8) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 26.289727ms)
Nov 13 10:48:25.305: INFO: (8) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 30.250113ms)
Nov 13 10:48:25.305: INFO: (8) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 30.203102ms)
Nov 13 10:48:25.306: INFO: (8) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 31.405231ms)
Nov 13 10:48:25.307: INFO: (8) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 32.118368ms)
Nov 13 10:48:25.307: INFO: (8) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 32.022988ms)
Nov 13 10:48:25.307: INFO: (8) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 32.166601ms)
Nov 13 10:48:25.307: INFO: (8) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 32.341618ms)
Nov 13 10:48:25.307: INFO: (8) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 32.323733ms)
Nov 13 10:48:25.322: INFO: (9) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 14.497683ms)
Nov 13 10:48:25.322: INFO: (9) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 14.264437ms)
Nov 13 10:48:25.322: INFO: (9) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 14.671091ms)
Nov 13 10:48:25.326: INFO: (9) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 17.915628ms)
Nov 13 10:48:25.326: INFO: (9) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 18.021748ms)
Nov 13 10:48:25.326: INFO: (9) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 18.37152ms)
Nov 13 10:48:25.327: INFO: (9) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 18.541353ms)
Nov 13 10:48:25.327: INFO: (9) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 18.349691ms)
Nov 13 10:48:25.327: INFO: (9) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 18.860106ms)
Nov 13 10:48:25.327: INFO: (9) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 19.30623ms)
Nov 13 10:48:25.327: INFO: (9) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 18.656367ms)
Nov 13 10:48:25.328: INFO: (9) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 20.306248ms)
Nov 13 10:48:25.328: INFO: (9) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 20.874675ms)
Nov 13 10:48:25.329: INFO: (9) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 20.634609ms)
Nov 13 10:48:25.329: INFO: (9) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 20.9201ms)
Nov 13 10:48:25.329: INFO: (9) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 21.616534ms)
Nov 13 10:48:25.347: INFO: (10) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 17.000562ms)
Nov 13 10:48:25.348: INFO: (10) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 18.513854ms)
Nov 13 10:48:25.348: INFO: (10) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 18.578005ms)
Nov 13 10:48:25.348: INFO: (10) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 18.71208ms)
Nov 13 10:48:25.348: INFO: (10) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 18.763866ms)
Nov 13 10:48:25.348: INFO: (10) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 18.549322ms)
Nov 13 10:48:25.348: INFO: (10) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 19.121283ms)
Nov 13 10:48:25.348: INFO: (10) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 18.140934ms)
Nov 13 10:48:25.348: INFO: (10) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 18.829881ms)
Nov 13 10:48:25.349: INFO: (10) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 19.715727ms)
Nov 13 10:48:25.350: INFO: (10) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 21.248043ms)
Nov 13 10:48:25.350: INFO: (10) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 20.696325ms)
Nov 13 10:48:25.350: INFO: (10) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 20.967013ms)
Nov 13 10:48:25.351: INFO: (10) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 21.491224ms)
Nov 13 10:48:25.351: INFO: (10) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 21.04548ms)
Nov 13 10:48:25.351: INFO: (10) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 21.29285ms)
Nov 13 10:48:25.368: INFO: (11) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 17.008657ms)
Nov 13 10:48:25.370: INFO: (11) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 18.25464ms)
Nov 13 10:48:25.370: INFO: (11) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 18.286991ms)
Nov 13 10:48:25.370: INFO: (11) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 18.669168ms)
Nov 13 10:48:25.370: INFO: (11) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 18.622677ms)
Nov 13 10:48:25.370: INFO: (11) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 18.636958ms)
Nov 13 10:48:25.370: INFO: (11) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 18.791138ms)
Nov 13 10:48:25.370: INFO: (11) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 18.969441ms)
Nov 13 10:48:25.370: INFO: (11) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 19.263372ms)
Nov 13 10:48:25.372: INFO: (11) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 20.438214ms)
Nov 13 10:48:25.373: INFO: (11) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 21.526123ms)
Nov 13 10:48:25.374: INFO: (11) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 22.243192ms)
Nov 13 10:48:25.374: INFO: (11) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 22.317835ms)
Nov 13 10:48:25.374: INFO: (11) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 22.309381ms)
Nov 13 10:48:25.374: INFO: (11) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 22.395222ms)
Nov 13 10:48:25.374: INFO: (11) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 22.589343ms)
Nov 13 10:48:25.396: INFO: (12) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 21.64525ms)
Nov 13 10:48:25.396: INFO: (12) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 21.627129ms)
Nov 13 10:48:25.396: INFO: (12) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 21.984328ms)
Nov 13 10:48:25.396: INFO: (12) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 21.823552ms)
Nov 13 10:48:25.396: INFO: (12) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 21.980037ms)
Nov 13 10:48:25.396: INFO: (12) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 21.893018ms)
Nov 13 10:48:25.396: INFO: (12) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 22.153484ms)
Nov 13 10:48:25.398: INFO: (12) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 23.413173ms)
Nov 13 10:48:25.398: INFO: (12) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 23.674739ms)
Nov 13 10:48:25.398: INFO: (12) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 23.520939ms)
Nov 13 10:48:25.398: INFO: (12) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 23.54901ms)
Nov 13 10:48:25.398: INFO: (12) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 23.684911ms)
Nov 13 10:48:25.398: INFO: (12) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 24.000428ms)
Nov 13 10:48:25.399: INFO: (12) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 24.349801ms)
Nov 13 10:48:25.399: INFO: (12) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 24.607207ms)
Nov 13 10:48:25.399: INFO: (12) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 24.840885ms)
Nov 13 10:48:25.408: INFO: (13) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 8.491161ms)
Nov 13 10:48:25.408: INFO: (13) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 9.232485ms)
Nov 13 10:48:25.409: INFO: (13) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 9.465446ms)
Nov 13 10:48:25.409: INFO: (13) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 9.756177ms)
Nov 13 10:48:25.413: INFO: (13) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 13.732811ms)
Nov 13 10:48:25.413: INFO: (13) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 13.912052ms)
Nov 13 10:48:25.414: INFO: (13) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 14.336298ms)
Nov 13 10:48:25.414: INFO: (13) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 14.351189ms)
Nov 13 10:48:25.414: INFO: (13) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 14.351763ms)
Nov 13 10:48:25.414: INFO: (13) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 14.544035ms)
Nov 13 10:48:25.414: INFO: (13) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 14.527134ms)
Nov 13 10:48:25.414: INFO: (13) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 14.50984ms)
Nov 13 10:48:25.415: INFO: (13) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 15.898381ms)
Nov 13 10:48:25.415: INFO: (13) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 16.161078ms)
Nov 13 10:48:25.415: INFO: (13) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 15.990005ms)
Nov 13 10:48:25.415: INFO: (13) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 16.288258ms)
Nov 13 10:48:25.436: INFO: (14) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 20.440075ms)
Nov 13 10:48:25.438: INFO: (14) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 22.294062ms)
Nov 13 10:48:25.439: INFO: (14) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 23.687001ms)
Nov 13 10:48:25.441: INFO: (14) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 24.836684ms)
Nov 13 10:48:25.441: INFO: (14) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 25.155072ms)
Nov 13 10:48:25.443: INFO: (14) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 26.437593ms)
Nov 13 10:48:25.443: INFO: (14) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 26.664581ms)
Nov 13 10:48:25.443: INFO: (14) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 26.72211ms)
Nov 13 10:48:25.443: INFO: (14) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 27.12788ms)
Nov 13 10:48:25.443: INFO: (14) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 27.309343ms)
Nov 13 10:48:25.443: INFO: (14) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 27.609435ms)
Nov 13 10:48:25.443: INFO: (14) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 27.479647ms)
Nov 13 10:48:25.443: INFO: (14) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 27.586707ms)
Nov 13 10:48:25.443: INFO: (14) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 27.136109ms)
Nov 13 10:48:25.443: INFO: (14) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 27.178648ms)
Nov 13 10:48:25.444: INFO: (14) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 27.605689ms)
Nov 13 10:48:25.455: INFO: (15) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 10.402671ms)
Nov 13 10:48:25.455: INFO: (15) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 10.569319ms)
Nov 13 10:48:25.455: INFO: (15) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 10.325698ms)
Nov 13 10:48:25.456: INFO: (15) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 11.599969ms)
Nov 13 10:48:25.456: INFO: (15) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 11.62115ms)
Nov 13 10:48:25.457: INFO: (15) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 11.831701ms)
Nov 13 10:48:25.457: INFO: (15) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 12.288838ms)
Nov 13 10:48:25.457: INFO: (15) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 12.28054ms)
Nov 13 10:48:25.457: INFO: (15) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 12.707686ms)
Nov 13 10:48:25.457: INFO: (15) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 13.059093ms)
Nov 13 10:48:25.457: INFO: (15) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 12.547281ms)
Nov 13 10:48:25.457: INFO: (15) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 12.66098ms)
Nov 13 10:48:25.459: INFO: (15) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 14.840284ms)
Nov 13 10:48:25.460: INFO: (15) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 15.002608ms)
Nov 13 10:48:25.460: INFO: (15) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 15.27748ms)
Nov 13 10:48:25.460: INFO: (15) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 15.638083ms)
Nov 13 10:48:25.482: INFO: (16) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 21.400762ms)
Nov 13 10:48:25.482: INFO: (16) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 21.310493ms)
Nov 13 10:48:25.482: INFO: (16) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 21.600789ms)
Nov 13 10:48:25.482: INFO: (16) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 21.806005ms)
Nov 13 10:48:25.487: INFO: (16) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 26.378914ms)
Nov 13 10:48:25.487: INFO: (16) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 26.770054ms)
Nov 13 10:48:25.487: INFO: (16) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 27.026582ms)
Nov 13 10:48:25.487: INFO: (16) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 26.998517ms)
Nov 13 10:48:25.488: INFO: (16) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 27.163491ms)
Nov 13 10:48:25.488: INFO: (16) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 27.342161ms)
Nov 13 10:48:25.488: INFO: (16) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 27.395897ms)
Nov 13 10:48:25.488: INFO: (16) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 27.512092ms)
Nov 13 10:48:25.488: INFO: (16) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 27.371305ms)
Nov 13 10:48:25.488: INFO: (16) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 28.28753ms)
Nov 13 10:48:25.488: INFO: (16) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 27.934398ms)
Nov 13 10:48:25.488: INFO: (16) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 27.87414ms)
Nov 13 10:48:25.502: INFO: (17) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 12.504953ms)
Nov 13 10:48:25.502: INFO: (17) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 12.757843ms)
Nov 13 10:48:25.502: INFO: (17) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 12.596495ms)
Nov 13 10:48:25.502: INFO: (17) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 12.938812ms)
Nov 13 10:48:25.502: INFO: (17) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 12.798109ms)
Nov 13 10:48:25.502: INFO: (17) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 12.648927ms)
Nov 13 10:48:25.502: INFO: (17) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 12.737946ms)
Nov 13 10:48:25.504: INFO: (17) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 14.261254ms)
Nov 13 10:48:25.504: INFO: (17) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 14.336668ms)
Nov 13 10:48:25.504: INFO: (17) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 14.435532ms)
Nov 13 10:48:25.504: INFO: (17) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 14.526871ms)
Nov 13 10:48:25.504: INFO: (17) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 14.95981ms)
Nov 13 10:48:25.504: INFO: (17) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 14.574454ms)
Nov 13 10:48:25.504: INFO: (17) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 15.277876ms)
Nov 13 10:48:25.505: INFO: (17) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 14.972682ms)
Nov 13 10:48:25.505: INFO: (17) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 15.070613ms)
Nov 13 10:48:25.531: INFO: (18) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 25.956544ms)
Nov 13 10:48:25.531: INFO: (18) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 26.014518ms)
Nov 13 10:48:25.531: INFO: (18) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 26.312712ms)
Nov 13 10:48:25.531: INFO: (18) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 26.135267ms)
Nov 13 10:48:25.532: INFO: (18) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 26.540607ms)
Nov 13 10:48:25.537: INFO: (18) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 31.246555ms)
Nov 13 10:48:25.537: INFO: (18) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 31.683ms)
Nov 13 10:48:25.537: INFO: (18) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 31.626136ms)
Nov 13 10:48:25.537: INFO: (18) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 31.665835ms)
Nov 13 10:48:25.537: INFO: (18) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 31.962828ms)
Nov 13 10:48:25.537: INFO: (18) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 32.161613ms)
Nov 13 10:48:25.537: INFO: (18) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 32.121354ms)
Nov 13 10:48:25.537: INFO: (18) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 32.213636ms)
Nov 13 10:48:25.538: INFO: (18) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 32.696569ms)
Nov 13 10:48:25.538: INFO: (18) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 32.747215ms)
Nov 13 10:48:25.538: INFO: (18) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 32.966524ms)
Nov 13 10:48:25.552: INFO: (19) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2/proxy/rewriteme">test</a> (200; 13.609223ms)
Nov 13 10:48:25.553: INFO: (19) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:460/proxy/: tls baz (200; 14.805493ms)
Nov 13 10:48:25.553: INFO: (19) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 14.913274ms)
Nov 13 10:48:25.553: INFO: (19) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">... (200; 15.222764ms)
Nov 13 10:48:25.554: INFO: (19) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:443/proxy/tlsrewritem... (200; 15.44327ms)
Nov 13 10:48:25.554: INFO: (19) /api/v1/namespaces/proxy-6300/pods/http:proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 15.477287ms)
Nov 13 10:48:25.554: INFO: (19) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:162/proxy/: bar (200; 15.240974ms)
Nov 13 10:48:25.554: INFO: (19) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:160/proxy/: foo (200; 15.192192ms)
Nov 13 10:48:25.554: INFO: (19) /api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6300/pods/proxy-service-8z68c-t8kd2:1080/proxy/rewriteme">test<... (200; 15.516139ms)
Nov 13 10:48:25.554: INFO: (19) /api/v1/namespaces/proxy-6300/pods/https:proxy-service-8z68c-t8kd2:462/proxy/: tls qux (200; 15.351879ms)
Nov 13 10:48:25.557: INFO: (19) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname2/proxy/: bar (200; 18.519356ms)
Nov 13 10:48:25.557: INFO: (19) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname2/proxy/: bar (200; 18.415807ms)
Nov 13 10:48:25.557: INFO: (19) /api/v1/namespaces/proxy-6300/services/http:proxy-service-8z68c:portname1/proxy/: foo (200; 18.451368ms)
Nov 13 10:48:25.557: INFO: (19) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname1/proxy/: tls baz (200; 19.085142ms)
Nov 13 10:48:25.557: INFO: (19) /api/v1/namespaces/proxy-6300/services/https:proxy-service-8z68c:tlsportname2/proxy/: tls qux (200; 18.804034ms)
Nov 13 10:48:25.557: INFO: (19) /api/v1/namespaces/proxy-6300/services/proxy-service-8z68c:portname1/proxy/: foo (200; 18.996031ms)
STEP: deleting ReplicationController proxy-service-8z68c in namespace proxy-6300, will wait for the garbage collector to delete the pods
Nov 13 10:48:25.613: INFO: Deleting ReplicationController proxy-service-8z68c took: 3.653929ms
Nov 13 10:48:26.015: INFO: Terminating ReplicationController proxy-service-8z68c pods took: 401.407802ms
[AfterEach] version v1
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:48:27.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6300" for this suite.

• [SLOW TEST:9.979 seconds]
[sig-network] Proxy
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":278,"completed":111,"skipped":1604,"failed":0}
SSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:48:27.919: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4733
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:48:28.044: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-b4826555-9189-4dc9-8264-79b4e780e9b1" in namespace "security-context-test-4733" to be "success or failure"
Nov 13 10:48:28.048: INFO: Pod "alpine-nnp-false-b4826555-9189-4dc9-8264-79b4e780e9b1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.085787ms
Nov 13 10:48:30.049: INFO: Pod "alpine-nnp-false-b4826555-9189-4dc9-8264-79b4e780e9b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005053866s
Nov 13 10:48:32.051: INFO: Pod "alpine-nnp-false-b4826555-9189-4dc9-8264-79b4e780e9b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006804989s
Nov 13 10:48:32.051: INFO: Pod "alpine-nnp-false-b4826555-9189-4dc9-8264-79b4e780e9b1" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:48:32.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4733" for this suite.
•{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":112,"skipped":1609,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:48:32.059: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-4937
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:48:32.189: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:48:32.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4937" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":278,"completed":113,"skipped":1612,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:48:32.913: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-12
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating all guestbook components
Nov 13 10:48:33.073: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Nov 13 10:48:33.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 create -f - --namespace=kubectl-12'
Nov 13 10:48:33.233: INFO: stderr: ""
Nov 13 10:48:33.233: INFO: stdout: "service/agnhost-slave created\n"
Nov 13 10:48:33.233: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Nov 13 10:48:33.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 create -f - --namespace=kubectl-12'
Nov 13 10:48:33.372: INFO: stderr: ""
Nov 13 10:48:33.372: INFO: stdout: "service/agnhost-master created\n"
Nov 13 10:48:33.372: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov 13 10:48:33.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 create -f - --namespace=kubectl-12'
Nov 13 10:48:33.501: INFO: stderr: ""
Nov 13 10:48:33.501: INFO: stdout: "service/frontend created\n"
Nov 13 10:48:33.501: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Nov 13 10:48:33.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 create -f - --namespace=kubectl-12'
Nov 13 10:48:33.622: INFO: stderr: ""
Nov 13 10:48:33.622: INFO: stdout: "deployment.apps/frontend created\n"
Nov 13 10:48:33.622: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 13 10:48:33.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 create -f - --namespace=kubectl-12'
Nov 13 10:48:33.747: INFO: stderr: ""
Nov 13 10:48:33.747: INFO: stdout: "deployment.apps/agnhost-master created\n"
Nov 13 10:48:33.747: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 13 10:48:33.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 create -f - --namespace=kubectl-12'
Nov 13 10:48:34.002: INFO: stderr: ""
Nov 13 10:48:34.002: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Nov 13 10:48:34.002: INFO: Waiting for all frontend pods to be Running.
Nov 13 10:48:39.052: INFO: Waiting for frontend to serve content.
Nov 13 10:48:39.057: INFO: Trying to add a new entry to the guestbook.
Nov 13 10:48:39.062: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Nov 13 10:48:39.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete --grace-period=0 --force -f - --namespace=kubectl-12'
Nov 13 10:48:39.131: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 10:48:39.131: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov 13 10:48:39.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete --grace-period=0 --force -f - --namespace=kubectl-12'
Nov 13 10:48:39.213: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 10:48:39.213: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Nov 13 10:48:39.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete --grace-period=0 --force -f - --namespace=kubectl-12'
Nov 13 10:48:39.297: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 10:48:39.297: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov 13 10:48:39.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete --grace-period=0 --force -f - --namespace=kubectl-12'
Nov 13 10:48:39.367: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 10:48:39.367: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov 13 10:48:39.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete --grace-period=0 --force -f - --namespace=kubectl-12'
Nov 13 10:48:39.432: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 10:48:39.432: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Nov 13 10:48:39.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete --grace-period=0 --force -f - --namespace=kubectl-12'
Nov 13 10:48:39.578: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 10:48:39.578: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:48:39.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-12" for this suite.

• [SLOW TEST:6.674 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:380
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":278,"completed":114,"skipped":1613,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:48:39.588: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8905
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8216
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5671
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:49:08.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8905" for this suite.
STEP: Destroying namespace "nsdeletetest-8216" for this suite.
Nov 13 10:49:08.985: INFO: Namespace nsdeletetest-8216 was already deleted
STEP: Destroying namespace "nsdeletetest-5671" for this suite.

• [SLOW TEST:29.399 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":278,"completed":115,"skipped":1620,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:49:08.988: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6290
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:49:09.119: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov 13 10:49:10.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-6290 create -f -'
Nov 13 10:49:11.609: INFO: stderr: ""
Nov 13 10:49:11.609: INFO: stdout: "e2e-test-crd-publish-openapi-1114-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov 13 10:49:11.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-6290 delete e2e-test-crd-publish-openapi-1114-crds test-cr'
Nov 13 10:49:11.671: INFO: stderr: ""
Nov 13 10:49:11.671: INFO: stdout: "e2e-test-crd-publish-openapi-1114-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Nov 13 10:49:11.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-6290 apply -f -'
Nov 13 10:49:11.775: INFO: stderr: ""
Nov 13 10:49:11.775: INFO: stdout: "e2e-test-crd-publish-openapi-1114-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov 13 10:49:11.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-6290 delete e2e-test-crd-publish-openapi-1114-crds test-cr'
Nov 13 10:49:11.825: INFO: stderr: ""
Nov 13 10:49:11.825: INFO: stdout: "e2e-test-crd-publish-openapi-1114-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Nov 13 10:49:11.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 explain e2e-test-crd-publish-openapi-1114-crds'
Nov 13 10:49:11.931: INFO: stderr: ""
Nov 13 10:49:11.931: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1114-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:49:14.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6290" for this suite.

• [SLOW TEST:5.581 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":278,"completed":116,"skipped":1630,"failed":0}
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:49:14.569: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6143
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-ce65bae7-21d9-425a-aa6d-077ee6482530
STEP: Creating a pod to test consume configMaps
Nov 13 10:49:14.699: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-26932ab6-3a77-48be-9ef8-e41d3407e6e4" in namespace "projected-6143" to be "success or failure"
Nov 13 10:49:14.708: INFO: Pod "pod-projected-configmaps-26932ab6-3a77-48be-9ef8-e41d3407e6e4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.330852ms
Nov 13 10:49:16.710: INFO: Pod "pod-projected-configmaps-26932ab6-3a77-48be-9ef8-e41d3407e6e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011502448s
STEP: Saw pod success
Nov 13 10:49:16.710: INFO: Pod "pod-projected-configmaps-26932ab6-3a77-48be-9ef8-e41d3407e6e4" satisfied condition "success or failure"
Nov 13 10:49:16.711: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-projected-configmaps-26932ab6-3a77-48be-9ef8-e41d3407e6e4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:49:16.720: INFO: Waiting for pod pod-projected-configmaps-26932ab6-3a77-48be-9ef8-e41d3407e6e4 to disappear
Nov 13 10:49:16.721: INFO: Pod pod-projected-configmaps-26932ab6-3a77-48be-9ef8-e41d3407e6e4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:49:16.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6143" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":117,"skipped":1632,"failed":0}
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:49:16.727: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3795
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:49:16.854: INFO: (0) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.722772ms)
Nov 13 10:49:16.856: INFO: (1) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.639286ms)
Nov 13 10:49:16.858: INFO: (2) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.093903ms)
Nov 13 10:49:16.860: INFO: (3) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.925503ms)
Nov 13 10:49:16.861: INFO: (4) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.603701ms)
Nov 13 10:49:16.863: INFO: (5) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.68006ms)
Nov 13 10:49:16.865: INFO: (6) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.600658ms)
Nov 13 10:49:16.867: INFO: (7) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.421366ms)
Nov 13 10:49:16.869: INFO: (8) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.849552ms)
Nov 13 10:49:16.871: INFO: (9) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.661073ms)
Nov 13 10:49:16.873: INFO: (10) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.129184ms)
Nov 13 10:49:16.875: INFO: (11) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.793557ms)
Nov 13 10:49:16.877: INFO: (12) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.915042ms)
Nov 13 10:49:16.879: INFO: (13) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.811477ms)
Nov 13 10:49:16.881: INFO: (14) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.241562ms)
Nov 13 10:49:16.883: INFO: (15) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.568556ms)
Nov 13 10:49:16.884: INFO: (16) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.545797ms)
Nov 13 10:49:16.886: INFO: (17) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.556527ms)
Nov 13 10:49:16.888: INFO: (18) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.633202ms)
Nov 13 10:49:16.889: INFO: (19) /api/v1/nodes/29607307-5497-41cc-a8d5-c2f7d9a90e41/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.677135ms)
[AfterEach] version v1
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:49:16.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3795" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":278,"completed":118,"skipped":1634,"failed":0}
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:49:16.894: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3790
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Nov 13 10:49:19.539: INFO: Successfully updated pod "labelsupdate6351cb03-e571-43c0-96b0-607413082736"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:49:21.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3790" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":278,"completed":119,"skipped":1635,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:49:21.555: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7648
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov 13 10:49:21.682: INFO: Waiting up to 5m0s for pod "pod-112f54f9-2501-4ce3-b601-40924e6cb935" in namespace "emptydir-7648" to be "success or failure"
Nov 13 10:49:21.686: INFO: Pod "pod-112f54f9-2501-4ce3-b601-40924e6cb935": Phase="Pending", Reason="", readiness=false. Elapsed: 3.371373ms
Nov 13 10:49:23.688: INFO: Pod "pod-112f54f9-2501-4ce3-b601-40924e6cb935": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005290763s
STEP: Saw pod success
Nov 13 10:49:23.688: INFO: Pod "pod-112f54f9-2501-4ce3-b601-40924e6cb935" satisfied condition "success or failure"
Nov 13 10:49:23.689: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-112f54f9-2501-4ce3-b601-40924e6cb935 container test-container: <nil>
STEP: delete the pod
Nov 13 10:49:23.699: INFO: Waiting for pod pod-112f54f9-2501-4ce3-b601-40924e6cb935 to disappear
Nov 13 10:49:23.704: INFO: Pod pod-112f54f9-2501-4ce3-b601-40924e6cb935 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:49:23.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7648" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":120,"skipped":1641,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:49:23.708: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-63
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1113 10:49:33.880531      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 13 10:49:33.880: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:49:33.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-63" for this suite.

• [SLOW TEST:10.176 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":278,"completed":121,"skipped":1661,"failed":0}
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:49:33.886: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4662
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod liveness-3ff14707-58fb-4462-b982-cfe71a58774f in namespace container-probe-4662
Nov 13 10:49:36.024: INFO: Started pod liveness-3ff14707-58fb-4462-b982-cfe71a58774f in namespace container-probe-4662
STEP: checking the pod's current state and verifying that restartCount is present
Nov 13 10:49:36.025: INFO: Initial restart count of pod liveness-3ff14707-58fb-4462-b982-cfe71a58774f is 0
Nov 13 10:50:00.051: INFO: Restart count of pod container-probe-4662/liveness-3ff14707-58fb-4462-b982-cfe71a58774f is now 1 (24.025672214s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:50:00.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4662" for this suite.

• [SLOW TEST:26.180 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":278,"completed":122,"skipped":1666,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:50:00.066: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-3410
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:50:00.188: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3410
I1113 10:50:00.201938      20 runners.go:189] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3410, replica count: 1
I1113 10:50:01.252331      20 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1113 10:50:02.252481      20 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 13 10:50:02.358: INFO: Created: latency-svc-74dr5
Nov 13 10:50:02.361: INFO: Got endpoints: latency-svc-74dr5 [8.372613ms]
Nov 13 10:50:02.370: INFO: Created: latency-svc-wldwc
Nov 13 10:50:02.376: INFO: Got endpoints: latency-svc-wldwc [13.766771ms]
Nov 13 10:50:02.377: INFO: Created: latency-svc-c7gfm
Nov 13 10:50:02.378: INFO: Got endpoints: latency-svc-c7gfm [15.286458ms]
Nov 13 10:50:02.383: INFO: Created: latency-svc-wrzkg
Nov 13 10:50:02.386: INFO: Got endpoints: latency-svc-wrzkg [22.154923ms]
Nov 13 10:50:02.389: INFO: Created: latency-svc-b8fqd
Nov 13 10:50:02.393: INFO: Created: latency-svc-pcdmr
Nov 13 10:50:02.396: INFO: Got endpoints: latency-svc-b8fqd [33.624201ms]
Nov 13 10:50:02.400: INFO: Created: latency-svc-psv7l
Nov 13 10:50:02.403: INFO: Got endpoints: latency-svc-pcdmr [39.907755ms]
Nov 13 10:50:02.407: INFO: Created: latency-svc-5p9v5
Nov 13 10:50:02.413: INFO: Got endpoints: latency-svc-psv7l [49.486352ms]
Nov 13 10:50:02.414: INFO: Created: latency-svc-qx5kv
Nov 13 10:50:02.417: INFO: Got endpoints: latency-svc-5p9v5 [53.218152ms]
Nov 13 10:50:02.422: INFO: Created: latency-svc-k8fl7
Nov 13 10:50:02.423: INFO: Got endpoints: latency-svc-qx5kv [59.150927ms]
Nov 13 10:50:02.427: INFO: Created: latency-svc-hdwtv
Nov 13 10:50:02.430: INFO: Got endpoints: latency-svc-hdwtv [66.613575ms]
Nov 13 10:50:02.435: INFO: Got endpoints: latency-svc-k8fl7 [69.877097ms]
Nov 13 10:50:02.438: INFO: Created: latency-svc-txwcd
Nov 13 10:50:02.439: INFO: Got endpoints: latency-svc-txwcd [75.237063ms]
Nov 13 10:50:02.440: INFO: Created: latency-svc-xq8b7
Nov 13 10:50:02.445: INFO: Got endpoints: latency-svc-xq8b7 [81.110377ms]
Nov 13 10:50:02.449: INFO: Created: latency-svc-88qwz
Nov 13 10:50:02.451: INFO: Created: latency-svc-qq2dw
Nov 13 10:50:02.453: INFO: Got endpoints: latency-svc-88qwz [88.452952ms]
Nov 13 10:50:02.458: INFO: Got endpoints: latency-svc-qq2dw [93.761758ms]
Nov 13 10:50:02.464: INFO: Created: latency-svc-p97wc
Nov 13 10:50:02.464: INFO: Created: latency-svc-bglgm
Nov 13 10:50:02.467: INFO: Created: latency-svc-lr6bk
Nov 13 10:50:02.477: INFO: Got endpoints: latency-svc-lr6bk [101.07094ms]
Nov 13 10:50:02.479: INFO: Got endpoints: latency-svc-bglgm [33.325031ms]
Nov 13 10:50:02.479: INFO: Got endpoints: latency-svc-p97wc [114.573829ms]
Nov 13 10:50:02.480: INFO: Created: latency-svc-4n2kh
Nov 13 10:50:02.484: INFO: Created: latency-svc-xlk8x
Nov 13 10:50:02.488: INFO: Got endpoints: latency-svc-4n2kh [106.615635ms]
Nov 13 10:50:02.490: INFO: Got endpoints: latency-svc-xlk8x [101.475307ms]
Nov 13 10:50:02.492: INFO: Created: latency-svc-xrhkh
Nov 13 10:50:02.494: INFO: Got endpoints: latency-svc-xrhkh [97.821898ms]
Nov 13 10:50:02.508: INFO: Created: latency-svc-2xw5l
Nov 13 10:50:02.508: INFO: Got endpoints: latency-svc-2xw5l [105.0311ms]
Nov 13 10:50:02.513: INFO: Created: latency-svc-prt26
Nov 13 10:50:02.514: INFO: Got endpoints: latency-svc-prt26 [101.161296ms]
Nov 13 10:50:02.514: INFO: Created: latency-svc-svm5b
Nov 13 10:50:02.518: INFO: Got endpoints: latency-svc-svm5b [99.335587ms]
Nov 13 10:50:02.521: INFO: Created: latency-svc-r5jpl
Nov 13 10:50:02.525: INFO: Got endpoints: latency-svc-r5jpl [98.987403ms]
Nov 13 10:50:02.527: INFO: Created: latency-svc-5h7xm
Nov 13 10:50:02.532: INFO: Got endpoints: latency-svc-5h7xm [97.87879ms]
Nov 13 10:50:02.537: INFO: Created: latency-svc-hc68z
Nov 13 10:50:02.539: INFO: Got endpoints: latency-svc-hc68z [104.136804ms]
Nov 13 10:50:02.543: INFO: Created: latency-svc-54mss
Nov 13 10:50:02.549: INFO: Got endpoints: latency-svc-54mss [109.489036ms]
Nov 13 10:50:02.552: INFO: Created: latency-svc-cf5kr
Nov 13 10:50:02.556: INFO: Created: latency-svc-qzxmt
Nov 13 10:50:02.558: INFO: Got endpoints: latency-svc-cf5kr [104.574745ms]
Nov 13 10:50:02.566: INFO: Created: latency-svc-ndnx6
Nov 13 10:50:02.569: INFO: Got endpoints: latency-svc-qzxmt [106.345147ms]
Nov 13 10:50:02.571: INFO: Created: latency-svc-srbb4
Nov 13 10:50:02.572: INFO: Got endpoints: latency-svc-ndnx6 [94.211005ms]
Nov 13 10:50:02.576: INFO: Created: latency-svc-bkdgd
Nov 13 10:50:02.580: INFO: Got endpoints: latency-svc-srbb4 [101.080689ms]
Nov 13 10:50:02.583: INFO: Got endpoints: latency-svc-bkdgd [102.933552ms]
Nov 13 10:50:02.586: INFO: Created: latency-svc-9v7w2
Nov 13 10:50:02.588: INFO: Got endpoints: latency-svc-9v7w2 [99.641251ms]
Nov 13 10:50:02.596: INFO: Created: latency-svc-kxm4q
Nov 13 10:50:02.603: INFO: Created: latency-svc-qcdrx
Nov 13 10:50:02.606: INFO: Created: latency-svc-hr4gc
Nov 13 10:50:02.614: INFO: Got endpoints: latency-svc-kxm4q [123.453207ms]
Nov 13 10:50:02.624: INFO: Created: latency-svc-sslwt
Nov 13 10:50:02.625: INFO: Created: latency-svc-x4f9z
Nov 13 10:50:02.625: INFO: Created: latency-svc-gtqrf
Nov 13 10:50:02.629: INFO: Created: latency-svc-pck47
Nov 13 10:50:02.632: INFO: Created: latency-svc-xrdm9
Nov 13 10:50:02.634: INFO: Created: latency-svc-g8gg2
Nov 13 10:50:02.636: INFO: Created: latency-svc-f4t99
Nov 13 10:50:02.645: INFO: Created: latency-svc-plmp5
Nov 13 10:50:02.648: INFO: Created: latency-svc-tdplk
Nov 13 10:50:02.650: INFO: Created: latency-svc-wj97p
Nov 13 10:50:02.658: INFO: Created: latency-svc-vz8xr
Nov 13 10:50:02.661: INFO: Got endpoints: latency-svc-qcdrx [164.854936ms]
Nov 13 10:50:02.664: INFO: Created: latency-svc-qsn45
Nov 13 10:50:02.668: INFO: Created: latency-svc-rn7cc
Nov 13 10:50:02.668: INFO: Created: latency-svc-rhf8h
Nov 13 10:50:02.709: INFO: Got endpoints: latency-svc-hr4gc [196.663484ms]
Nov 13 10:50:02.713: INFO: Created: latency-svc-czlrf
Nov 13 10:50:02.759: INFO: Got endpoints: latency-svc-sslwt [244.356797ms]
Nov 13 10:50:02.764: INFO: Created: latency-svc-vjrxt
Nov 13 10:50:02.809: INFO: Got endpoints: latency-svc-gtqrf [290.259225ms]
Nov 13 10:50:02.813: INFO: Created: latency-svc-2xzgj
Nov 13 10:50:02.859: INFO: Got endpoints: latency-svc-x4f9z [333.539444ms]
Nov 13 10:50:02.864: INFO: Created: latency-svc-vfwc9
Nov 13 10:50:02.909: INFO: Got endpoints: latency-svc-pck47 [376.111039ms]
Nov 13 10:50:02.913: INFO: Created: latency-svc-jhjtl
Nov 13 10:50:02.959: INFO: Got endpoints: latency-svc-xrdm9 [419.457124ms]
Nov 13 10:50:02.963: INFO: Created: latency-svc-xvp65
Nov 13 10:50:03.009: INFO: Got endpoints: latency-svc-g8gg2 [460.482781ms]
Nov 13 10:50:03.014: INFO: Created: latency-svc-5j8r9
Nov 13 10:50:03.059: INFO: Got endpoints: latency-svc-f4t99 [501.107659ms]
Nov 13 10:50:03.063: INFO: Created: latency-svc-8wtvd
Nov 13 10:50:03.109: INFO: Got endpoints: latency-svc-plmp5 [539.295969ms]
Nov 13 10:50:03.118: INFO: Created: latency-svc-jzjjr
Nov 13 10:50:03.160: INFO: Got endpoints: latency-svc-tdplk [586.610609ms]
Nov 13 10:50:03.164: INFO: Created: latency-svc-txq6f
Nov 13 10:50:03.210: INFO: Got endpoints: latency-svc-wj97p [629.395689ms]
Nov 13 10:50:03.218: INFO: Created: latency-svc-4gtkp
Nov 13 10:50:03.261: INFO: Got endpoints: latency-svc-vz8xr [677.742746ms]
Nov 13 10:50:03.265: INFO: Created: latency-svc-wwdb9
Nov 13 10:50:03.309: INFO: Got endpoints: latency-svc-qsn45 [720.591099ms]
Nov 13 10:50:03.314: INFO: Created: latency-svc-c9pb7
Nov 13 10:50:03.359: INFO: Got endpoints: latency-svc-rn7cc [735.400879ms]
Nov 13 10:50:03.363: INFO: Created: latency-svc-qms98
Nov 13 10:50:03.409: INFO: Got endpoints: latency-svc-rhf8h [748.157878ms]
Nov 13 10:50:03.414: INFO: Created: latency-svc-d8lpt
Nov 13 10:50:03.459: INFO: Got endpoints: latency-svc-czlrf [749.698674ms]
Nov 13 10:50:03.463: INFO: Created: latency-svc-h6l8p
Nov 13 10:50:03.509: INFO: Got endpoints: latency-svc-vjrxt [749.303993ms]
Nov 13 10:50:03.513: INFO: Created: latency-svc-6bw8w
Nov 13 10:50:03.559: INFO: Got endpoints: latency-svc-2xzgj [750.118233ms]
Nov 13 10:50:03.564: INFO: Created: latency-svc-vpbgc
Nov 13 10:50:03.614: INFO: Got endpoints: latency-svc-vfwc9 [755.046836ms]
Nov 13 10:50:03.619: INFO: Created: latency-svc-2xkh5
Nov 13 10:50:03.659: INFO: Got endpoints: latency-svc-jhjtl [750.453898ms]
Nov 13 10:50:03.663: INFO: Created: latency-svc-7lbmm
Nov 13 10:50:03.709: INFO: Got endpoints: latency-svc-xvp65 [750.212961ms]
Nov 13 10:50:03.713: INFO: Created: latency-svc-zxt8m
Nov 13 10:50:03.759: INFO: Got endpoints: latency-svc-5j8r9 [749.930608ms]
Nov 13 10:50:03.768: INFO: Created: latency-svc-2z26d
Nov 13 10:50:03.809: INFO: Got endpoints: latency-svc-8wtvd [750.197089ms]
Nov 13 10:50:03.813: INFO: Created: latency-svc-pg8jp
Nov 13 10:50:03.860: INFO: Got endpoints: latency-svc-jzjjr [750.716637ms]
Nov 13 10:50:03.868: INFO: Created: latency-svc-c29qh
Nov 13 10:50:03.909: INFO: Got endpoints: latency-svc-txq6f [749.43629ms]
Nov 13 10:50:03.913: INFO: Created: latency-svc-jwb74
Nov 13 10:50:03.960: INFO: Got endpoints: latency-svc-4gtkp [750.414431ms]
Nov 13 10:50:03.964: INFO: Created: latency-svc-46tq7
Nov 13 10:50:04.009: INFO: Got endpoints: latency-svc-wwdb9 [748.281606ms]
Nov 13 10:50:04.013: INFO: Created: latency-svc-t9ds7
Nov 13 10:50:04.059: INFO: Got endpoints: latency-svc-c9pb7 [749.504409ms]
Nov 13 10:50:04.064: INFO: Created: latency-svc-4cvz9
Nov 13 10:50:04.109: INFO: Got endpoints: latency-svc-qms98 [749.617916ms]
Nov 13 10:50:04.114: INFO: Created: latency-svc-2cfjq
Nov 13 10:50:04.160: INFO: Got endpoints: latency-svc-d8lpt [750.062065ms]
Nov 13 10:50:04.165: INFO: Created: latency-svc-m54l5
Nov 13 10:50:04.211: INFO: Got endpoints: latency-svc-h6l8p [751.159659ms]
Nov 13 10:50:04.221: INFO: Created: latency-svc-psncm
Nov 13 10:50:04.260: INFO: Got endpoints: latency-svc-6bw8w [750.74216ms]
Nov 13 10:50:04.269: INFO: Created: latency-svc-hhfx5
Nov 13 10:50:04.310: INFO: Got endpoints: latency-svc-vpbgc [750.056296ms]
Nov 13 10:50:04.316: INFO: Created: latency-svc-nptvf
Nov 13 10:50:04.360: INFO: Got endpoints: latency-svc-2xkh5 [745.005563ms]
Nov 13 10:50:04.372: INFO: Created: latency-svc-mkxst
Nov 13 10:50:04.410: INFO: Got endpoints: latency-svc-7lbmm [750.343742ms]
Nov 13 10:50:04.414: INFO: Created: latency-svc-prx26
Nov 13 10:50:04.460: INFO: Got endpoints: latency-svc-zxt8m [750.618776ms]
Nov 13 10:50:04.464: INFO: Created: latency-svc-m6n7l
Nov 13 10:50:04.509: INFO: Got endpoints: latency-svc-2z26d [749.788666ms]
Nov 13 10:50:04.514: INFO: Created: latency-svc-wshsw
Nov 13 10:50:04.559: INFO: Got endpoints: latency-svc-pg8jp [750.029238ms]
Nov 13 10:50:04.563: INFO: Created: latency-svc-6g8gx
Nov 13 10:50:04.611: INFO: Got endpoints: latency-svc-c29qh [751.310831ms]
Nov 13 10:50:04.618: INFO: Created: latency-svc-tbv77
Nov 13 10:50:04.663: INFO: Got endpoints: latency-svc-jwb74 [753.552768ms]
Nov 13 10:50:04.668: INFO: Created: latency-svc-7cgcs
Nov 13 10:50:04.709: INFO: Got endpoints: latency-svc-46tq7 [749.351974ms]
Nov 13 10:50:04.714: INFO: Created: latency-svc-kj59s
Nov 13 10:50:04.760: INFO: Got endpoints: latency-svc-t9ds7 [750.375965ms]
Nov 13 10:50:04.768: INFO: Created: latency-svc-prbww
Nov 13 10:50:04.810: INFO: Got endpoints: latency-svc-4cvz9 [750.775703ms]
Nov 13 10:50:04.814: INFO: Created: latency-svc-b9wjh
Nov 13 10:50:04.860: INFO: Got endpoints: latency-svc-2cfjq [751.033911ms]
Nov 13 10:50:04.869: INFO: Created: latency-svc-8fllw
Nov 13 10:50:04.909: INFO: Got endpoints: latency-svc-m54l5 [749.250124ms]
Nov 13 10:50:04.914: INFO: Created: latency-svc-k58gf
Nov 13 10:50:04.960: INFO: Got endpoints: latency-svc-psncm [748.855687ms]
Nov 13 10:50:04.964: INFO: Created: latency-svc-2wbx4
Nov 13 10:50:05.010: INFO: Got endpoints: latency-svc-hhfx5 [749.803807ms]
Nov 13 10:50:05.014: INFO: Created: latency-svc-tqnpw
Nov 13 10:50:05.060: INFO: Got endpoints: latency-svc-nptvf [749.523414ms]
Nov 13 10:50:05.064: INFO: Created: latency-svc-6hd5t
Nov 13 10:50:05.111: INFO: Got endpoints: latency-svc-mkxst [750.753908ms]
Nov 13 10:50:05.123: INFO: Created: latency-svc-gkrxk
Nov 13 10:50:05.160: INFO: Got endpoints: latency-svc-prx26 [750.545889ms]
Nov 13 10:50:05.169: INFO: Created: latency-svc-pzxzh
Nov 13 10:50:05.210: INFO: Got endpoints: latency-svc-m6n7l [750.301744ms]
Nov 13 10:50:05.216: INFO: Created: latency-svc-xk5nl
Nov 13 10:50:05.260: INFO: Got endpoints: latency-svc-wshsw [750.503433ms]
Nov 13 10:50:05.270: INFO: Created: latency-svc-r4fdx
Nov 13 10:50:05.310: INFO: Got endpoints: latency-svc-6g8gx [750.364955ms]
Nov 13 10:50:05.314: INFO: Created: latency-svc-jcwlj
Nov 13 10:50:05.358: INFO: Got endpoints: latency-svc-tbv77 [746.797965ms]
Nov 13 10:50:05.369: INFO: Created: latency-svc-vgsg5
Nov 13 10:50:05.410: INFO: Got endpoints: latency-svc-7cgcs [747.182168ms]
Nov 13 10:50:05.415: INFO: Created: latency-svc-p9gxr
Nov 13 10:50:05.460: INFO: Got endpoints: latency-svc-kj59s [750.221105ms]
Nov 13 10:50:05.468: INFO: Created: latency-svc-lbrkc
Nov 13 10:50:05.509: INFO: Got endpoints: latency-svc-prbww [749.792875ms]
Nov 13 10:50:05.514: INFO: Created: latency-svc-8wmkt
Nov 13 10:50:05.559: INFO: Got endpoints: latency-svc-b9wjh [749.383535ms]
Nov 13 10:50:05.563: INFO: Created: latency-svc-mxhqd
Nov 13 10:50:05.610: INFO: Got endpoints: latency-svc-8fllw [749.639683ms]
Nov 13 10:50:05.614: INFO: Created: latency-svc-t2vr7
Nov 13 10:50:05.659: INFO: Got endpoints: latency-svc-k58gf [749.884591ms]
Nov 13 10:50:05.663: INFO: Created: latency-svc-rrv9v
Nov 13 10:50:05.709: INFO: Got endpoints: latency-svc-2wbx4 [749.610879ms]
Nov 13 10:50:05.714: INFO: Created: latency-svc-rwqw5
Nov 13 10:50:05.759: INFO: Got endpoints: latency-svc-tqnpw [749.170072ms]
Nov 13 10:50:05.764: INFO: Created: latency-svc-86krb
Nov 13 10:50:05.810: INFO: Got endpoints: latency-svc-6hd5t [749.652752ms]
Nov 13 10:50:05.814: INFO: Created: latency-svc-t7lwk
Nov 13 10:50:05.860: INFO: Got endpoints: latency-svc-gkrxk [749.65225ms]
Nov 13 10:50:05.864: INFO: Created: latency-svc-qwj96
Nov 13 10:50:05.909: INFO: Got endpoints: latency-svc-pzxzh [748.131506ms]
Nov 13 10:50:05.919: INFO: Created: latency-svc-4qh54
Nov 13 10:50:05.960: INFO: Got endpoints: latency-svc-xk5nl [748.982987ms]
Nov 13 10:50:05.963: INFO: Created: latency-svc-lvx5g
Nov 13 10:50:06.009: INFO: Got endpoints: latency-svc-r4fdx [749.296433ms]
Nov 13 10:50:06.014: INFO: Created: latency-svc-69t5k
Nov 13 10:50:06.060: INFO: Got endpoints: latency-svc-jcwlj [749.585074ms]
Nov 13 10:50:06.064: INFO: Created: latency-svc-nxxfv
Nov 13 10:50:06.110: INFO: Got endpoints: latency-svc-vgsg5 [751.026775ms]
Nov 13 10:50:06.114: INFO: Created: latency-svc-mnftl
Nov 13 10:50:06.159: INFO: Got endpoints: latency-svc-p9gxr [749.247328ms]
Nov 13 10:50:06.163: INFO: Created: latency-svc-2skrj
Nov 13 10:50:06.209: INFO: Got endpoints: latency-svc-lbrkc [749.633639ms]
Nov 13 10:50:06.213: INFO: Created: latency-svc-87pzz
Nov 13 10:50:06.260: INFO: Got endpoints: latency-svc-8wmkt [750.577886ms]
Nov 13 10:50:06.265: INFO: Created: latency-svc-x28s2
Nov 13 10:50:06.310: INFO: Got endpoints: latency-svc-mxhqd [751.035785ms]
Nov 13 10:50:06.316: INFO: Created: latency-svc-kpd7x
Nov 13 10:50:06.358: INFO: Got endpoints: latency-svc-t2vr7 [748.261998ms]
Nov 13 10:50:06.363: INFO: Created: latency-svc-cqcj6
Nov 13 10:50:06.409: INFO: Got endpoints: latency-svc-rrv9v [750.323358ms]
Nov 13 10:50:06.418: INFO: Created: latency-svc-fgqxf
Nov 13 10:50:06.459: INFO: Got endpoints: latency-svc-rwqw5 [750.319118ms]
Nov 13 10:50:06.464: INFO: Created: latency-svc-hxrmk
Nov 13 10:50:06.509: INFO: Got endpoints: latency-svc-86krb [750.193721ms]
Nov 13 10:50:06.518: INFO: Created: latency-svc-lslfr
Nov 13 10:50:06.560: INFO: Got endpoints: latency-svc-t7lwk [749.954165ms]
Nov 13 10:50:06.563: INFO: Created: latency-svc-tfrrw
Nov 13 10:50:06.609: INFO: Got endpoints: latency-svc-qwj96 [749.002951ms]
Nov 13 10:50:06.618: INFO: Created: latency-svc-mhnjd
Nov 13 10:50:06.662: INFO: Got endpoints: latency-svc-4qh54 [752.230763ms]
Nov 13 10:50:06.667: INFO: Created: latency-svc-fx7fw
Nov 13 10:50:06.709: INFO: Got endpoints: latency-svc-lvx5g [749.353129ms]
Nov 13 10:50:06.713: INFO: Created: latency-svc-w9st7
Nov 13 10:50:06.759: INFO: Got endpoints: latency-svc-69t5k [749.780734ms]
Nov 13 10:50:06.764: INFO: Created: latency-svc-4r47t
Nov 13 10:50:06.811: INFO: Got endpoints: latency-svc-nxxfv [751.119064ms]
Nov 13 10:50:06.815: INFO: Created: latency-svc-xdl9c
Nov 13 10:50:06.859: INFO: Got endpoints: latency-svc-mnftl [749.701772ms]
Nov 13 10:50:06.863: INFO: Created: latency-svc-nzgnf
Nov 13 10:50:06.910: INFO: Got endpoints: latency-svc-2skrj [750.086709ms]
Nov 13 10:50:06.918: INFO: Created: latency-svc-58xhx
Nov 13 10:50:06.959: INFO: Got endpoints: latency-svc-87pzz [749.495365ms]
Nov 13 10:50:06.963: INFO: Created: latency-svc-d5646
Nov 13 10:50:07.010: INFO: Got endpoints: latency-svc-x28s2 [750.356011ms]
Nov 13 10:50:07.015: INFO: Created: latency-svc-7dl2f
Nov 13 10:50:07.059: INFO: Got endpoints: latency-svc-kpd7x [748.518907ms]
Nov 13 10:50:07.063: INFO: Created: latency-svc-svn5k
Nov 13 10:50:07.109: INFO: Got endpoints: latency-svc-cqcj6 [750.635433ms]
Nov 13 10:50:07.113: INFO: Created: latency-svc-79t9p
Nov 13 10:50:07.159: INFO: Got endpoints: latency-svc-fgqxf [749.425366ms]
Nov 13 10:50:07.164: INFO: Created: latency-svc-7rkmn
Nov 13 10:50:07.210: INFO: Got endpoints: latency-svc-hxrmk [750.008315ms]
Nov 13 10:50:07.214: INFO: Created: latency-svc-fg7pb
Nov 13 10:50:07.260: INFO: Got endpoints: latency-svc-lslfr [750.640274ms]
Nov 13 10:50:07.264: INFO: Created: latency-svc-bslhn
Nov 13 10:50:07.310: INFO: Got endpoints: latency-svc-tfrrw [750.049062ms]
Nov 13 10:50:07.318: INFO: Created: latency-svc-h6c4d
Nov 13 10:50:07.360: INFO: Got endpoints: latency-svc-mhnjd [750.652688ms]
Nov 13 10:50:07.365: INFO: Created: latency-svc-55tfr
Nov 13 10:50:07.410: INFO: Got endpoints: latency-svc-fx7fw [747.947135ms]
Nov 13 10:50:07.414: INFO: Created: latency-svc-6446k
Nov 13 10:50:07.460: INFO: Got endpoints: latency-svc-w9st7 [750.901515ms]
Nov 13 10:50:07.464: INFO: Created: latency-svc-f5f4r
Nov 13 10:50:07.510: INFO: Got endpoints: latency-svc-4r47t [750.193922ms]
Nov 13 10:50:07.514: INFO: Created: latency-svc-69szs
Nov 13 10:50:07.562: INFO: Got endpoints: latency-svc-xdl9c [751.543851ms]
Nov 13 10:50:07.567: INFO: Created: latency-svc-8vdcw
Nov 13 10:50:07.610: INFO: Got endpoints: latency-svc-nzgnf [750.72519ms]
Nov 13 10:50:07.619: INFO: Created: latency-svc-zx55j
Nov 13 10:50:07.658: INFO: Got endpoints: latency-svc-58xhx [748.837311ms]
Nov 13 10:50:07.663: INFO: Created: latency-svc-llwjs
Nov 13 10:50:07.710: INFO: Got endpoints: latency-svc-d5646 [750.571517ms]
Nov 13 10:50:07.718: INFO: Created: latency-svc-q56l6
Nov 13 10:50:07.759: INFO: Got endpoints: latency-svc-7dl2f [749.048802ms]
Nov 13 10:50:07.764: INFO: Created: latency-svc-b9lnz
Nov 13 10:50:07.809: INFO: Got endpoints: latency-svc-svn5k [750.260344ms]
Nov 13 10:50:07.814: INFO: Created: latency-svc-k7frb
Nov 13 10:50:07.859: INFO: Got endpoints: latency-svc-79t9p [750.370714ms]
Nov 13 10:50:07.863: INFO: Created: latency-svc-xxz6k
Nov 13 10:50:07.910: INFO: Got endpoints: latency-svc-7rkmn [750.365523ms]
Nov 13 10:50:07.913: INFO: Created: latency-svc-7prpw
Nov 13 10:50:07.959: INFO: Got endpoints: latency-svc-fg7pb [749.655674ms]
Nov 13 10:50:07.963: INFO: Created: latency-svc-4bdns
Nov 13 10:50:08.009: INFO: Got endpoints: latency-svc-bslhn [748.605628ms]
Nov 13 10:50:08.014: INFO: Created: latency-svc-p6bn9
Nov 13 10:50:08.060: INFO: Got endpoints: latency-svc-h6c4d [750.196479ms]
Nov 13 10:50:08.064: INFO: Created: latency-svc-kvj9f
Nov 13 10:50:08.109: INFO: Got endpoints: latency-svc-55tfr [747.834759ms]
Nov 13 10:50:08.113: INFO: Created: latency-svc-2jnv4
Nov 13 10:50:08.159: INFO: Got endpoints: latency-svc-6446k [749.409826ms]
Nov 13 10:50:08.163: INFO: Created: latency-svc-xg8r2
Nov 13 10:50:08.210: INFO: Got endpoints: latency-svc-f5f4r [749.563608ms]
Nov 13 10:50:08.218: INFO: Created: latency-svc-x8j5m
Nov 13 10:50:08.261: INFO: Got endpoints: latency-svc-69szs [751.337767ms]
Nov 13 10:50:08.265: INFO: Created: latency-svc-p9mx8
Nov 13 10:50:08.310: INFO: Got endpoints: latency-svc-8vdcw [747.740606ms]
Nov 13 10:50:08.318: INFO: Created: latency-svc-zmrzf
Nov 13 10:50:08.359: INFO: Got endpoints: latency-svc-zx55j [748.854426ms]
Nov 13 10:50:08.363: INFO: Created: latency-svc-j4xt2
Nov 13 10:50:08.410: INFO: Got endpoints: latency-svc-llwjs [751.696129ms]
Nov 13 10:50:08.418: INFO: Created: latency-svc-4ml6c
Nov 13 10:50:08.459: INFO: Got endpoints: latency-svc-q56l6 [749.658512ms]
Nov 13 10:50:08.463: INFO: Created: latency-svc-xs42w
Nov 13 10:50:08.510: INFO: Got endpoints: latency-svc-b9lnz [749.894197ms]
Nov 13 10:50:08.514: INFO: Created: latency-svc-42gkf
Nov 13 10:50:08.559: INFO: Got endpoints: latency-svc-k7frb [749.992406ms]
Nov 13 10:50:08.563: INFO: Created: latency-svc-5tcz6
Nov 13 10:50:08.613: INFO: Got endpoints: latency-svc-xxz6k [753.753111ms]
Nov 13 10:50:08.620: INFO: Created: latency-svc-xxd86
Nov 13 10:50:08.660: INFO: Got endpoints: latency-svc-7prpw [749.985662ms]
Nov 13 10:50:08.664: INFO: Created: latency-svc-j5xkf
Nov 13 10:50:08.709: INFO: Got endpoints: latency-svc-4bdns [750.203768ms]
Nov 13 10:50:08.718: INFO: Created: latency-svc-9mgth
Nov 13 10:50:08.758: INFO: Got endpoints: latency-svc-p6bn9 [749.028736ms]
Nov 13 10:50:08.763: INFO: Created: latency-svc-54jfk
Nov 13 10:50:08.810: INFO: Got endpoints: latency-svc-kvj9f [749.436182ms]
Nov 13 10:50:08.819: INFO: Created: latency-svc-rqp4l
Nov 13 10:50:08.860: INFO: Got endpoints: latency-svc-2jnv4 [750.95163ms]
Nov 13 10:50:08.865: INFO: Created: latency-svc-z55nj
Nov 13 10:50:08.910: INFO: Got endpoints: latency-svc-xg8r2 [750.810014ms]
Nov 13 10:50:08.918: INFO: Created: latency-svc-skbbx
Nov 13 10:50:08.960: INFO: Got endpoints: latency-svc-x8j5m [750.119444ms]
Nov 13 10:50:08.964: INFO: Created: latency-svc-8ck24
Nov 13 10:50:09.009: INFO: Got endpoints: latency-svc-p9mx8 [747.983321ms]
Nov 13 10:50:09.014: INFO: Created: latency-svc-jnh2r
Nov 13 10:50:09.060: INFO: Got endpoints: latency-svc-zmrzf [748.178225ms]
Nov 13 10:50:09.064: INFO: Created: latency-svc-4bn8b
Nov 13 10:50:09.110: INFO: Got endpoints: latency-svc-j4xt2 [750.514274ms]
Nov 13 10:50:09.114: INFO: Created: latency-svc-j7cst
Nov 13 10:50:09.159: INFO: Got endpoints: latency-svc-4ml6c [749.090426ms]
Nov 13 10:50:09.164: INFO: Created: latency-svc-g47n9
Nov 13 10:50:09.209: INFO: Got endpoints: latency-svc-xs42w [749.738122ms]
Nov 13 10:50:09.214: INFO: Created: latency-svc-twxf7
Nov 13 10:50:09.260: INFO: Got endpoints: latency-svc-42gkf [750.082291ms]
Nov 13 10:50:09.264: INFO: Created: latency-svc-cvzvq
Nov 13 10:50:09.310: INFO: Got endpoints: latency-svc-5tcz6 [750.059932ms]
Nov 13 10:50:09.314: INFO: Created: latency-svc-m42vj
Nov 13 10:50:09.359: INFO: Got endpoints: latency-svc-xxd86 [746.127718ms]
Nov 13 10:50:09.364: INFO: Created: latency-svc-8p8m6
Nov 13 10:50:09.409: INFO: Got endpoints: latency-svc-j5xkf [749.745438ms]
Nov 13 10:50:09.414: INFO: Created: latency-svc-hxb4b
Nov 13 10:50:09.459: INFO: Got endpoints: latency-svc-9mgth [749.657247ms]
Nov 13 10:50:09.468: INFO: Created: latency-svc-4n297
Nov 13 10:50:09.509: INFO: Got endpoints: latency-svc-54jfk [750.945614ms]
Nov 13 10:50:09.513: INFO: Created: latency-svc-j7l74
Nov 13 10:50:09.560: INFO: Got endpoints: latency-svc-rqp4l [750.109239ms]
Nov 13 10:50:09.571: INFO: Created: latency-svc-9tf8c
Nov 13 10:50:09.610: INFO: Got endpoints: latency-svc-z55nj [749.755126ms]
Nov 13 10:50:09.614: INFO: Created: latency-svc-6xzz2
Nov 13 10:50:09.660: INFO: Got endpoints: latency-svc-skbbx [749.239432ms]
Nov 13 10:50:09.668: INFO: Created: latency-svc-xp89s
Nov 13 10:50:09.709: INFO: Got endpoints: latency-svc-8ck24 [749.252403ms]
Nov 13 10:50:09.713: INFO: Created: latency-svc-l6mzv
Nov 13 10:50:09.759: INFO: Got endpoints: latency-svc-jnh2r [750.132185ms]
Nov 13 10:50:09.765: INFO: Created: latency-svc-vg6sp
Nov 13 10:50:09.809: INFO: Got endpoints: latency-svc-4bn8b [748.666733ms]
Nov 13 10:50:09.814: INFO: Created: latency-svc-6zq8g
Nov 13 10:50:09.860: INFO: Got endpoints: latency-svc-j7cst [749.861244ms]
Nov 13 10:50:09.865: INFO: Created: latency-svc-52l5p
Nov 13 10:50:09.910: INFO: Got endpoints: latency-svc-g47n9 [750.253307ms]
Nov 13 10:50:09.914: INFO: Created: latency-svc-sxp86
Nov 13 10:50:09.959: INFO: Got endpoints: latency-svc-twxf7 [749.833943ms]
Nov 13 10:50:09.964: INFO: Created: latency-svc-k8j5h
Nov 13 10:50:10.011: INFO: Got endpoints: latency-svc-cvzvq [750.75377ms]
Nov 13 10:50:10.017: INFO: Created: latency-svc-lcp82
Nov 13 10:50:10.060: INFO: Got endpoints: latency-svc-m42vj [750.141782ms]
Nov 13 10:50:10.068: INFO: Created: latency-svc-tgt9c
Nov 13 10:50:10.109: INFO: Got endpoints: latency-svc-8p8m6 [749.76506ms]
Nov 13 10:50:10.114: INFO: Created: latency-svc-cf5qq
Nov 13 10:50:10.158: INFO: Got endpoints: latency-svc-hxb4b [748.926703ms]
Nov 13 10:50:10.168: INFO: Created: latency-svc-pz859
Nov 13 10:50:10.210: INFO: Got endpoints: latency-svc-4n297 [750.111663ms]
Nov 13 10:50:10.259: INFO: Got endpoints: latency-svc-j7l74 [749.734163ms]
Nov 13 10:50:10.310: INFO: Got endpoints: latency-svc-9tf8c [749.952798ms]
Nov 13 10:50:10.360: INFO: Got endpoints: latency-svc-6xzz2 [749.858395ms]
Nov 13 10:50:10.410: INFO: Got endpoints: latency-svc-xp89s [749.931609ms]
Nov 13 10:50:10.460: INFO: Got endpoints: latency-svc-l6mzv [750.714058ms]
Nov 13 10:50:10.509: INFO: Got endpoints: latency-svc-vg6sp [749.560565ms]
Nov 13 10:50:10.560: INFO: Got endpoints: latency-svc-6zq8g [751.032242ms]
Nov 13 10:50:10.609: INFO: Got endpoints: latency-svc-52l5p [748.754455ms]
Nov 13 10:50:10.659: INFO: Got endpoints: latency-svc-sxp86 [749.02182ms]
Nov 13 10:50:10.709: INFO: Got endpoints: latency-svc-k8j5h [749.426719ms]
Nov 13 10:50:10.759: INFO: Got endpoints: latency-svc-lcp82 [747.943864ms]
Nov 13 10:50:10.809: INFO: Got endpoints: latency-svc-tgt9c [749.01156ms]
Nov 13 10:50:10.859: INFO: Got endpoints: latency-svc-cf5qq [749.838556ms]
Nov 13 10:50:10.909: INFO: Got endpoints: latency-svc-pz859 [750.496906ms]
Nov 13 10:50:10.909: INFO: Latencies: [13.766771ms 15.286458ms 22.154923ms 33.325031ms 33.624201ms 39.907755ms 49.486352ms 53.218152ms 59.150927ms 66.613575ms 69.877097ms 75.237063ms 81.110377ms 88.452952ms 93.761758ms 94.211005ms 97.821898ms 97.87879ms 98.987403ms 99.335587ms 99.641251ms 101.07094ms 101.080689ms 101.161296ms 101.475307ms 102.933552ms 104.136804ms 104.574745ms 105.0311ms 106.345147ms 106.615635ms 109.489036ms 114.573829ms 123.453207ms 164.854936ms 196.663484ms 244.356797ms 290.259225ms 333.539444ms 376.111039ms 419.457124ms 460.482781ms 501.107659ms 539.295969ms 586.610609ms 629.395689ms 677.742746ms 720.591099ms 735.400879ms 745.005563ms 746.127718ms 746.797965ms 747.182168ms 747.740606ms 747.834759ms 747.943864ms 747.947135ms 747.983321ms 748.131506ms 748.157878ms 748.178225ms 748.261998ms 748.281606ms 748.518907ms 748.605628ms 748.666733ms 748.754455ms 748.837311ms 748.854426ms 748.855687ms 748.926703ms 748.982987ms 749.002951ms 749.01156ms 749.02182ms 749.028736ms 749.048802ms 749.090426ms 749.170072ms 749.239432ms 749.247328ms 749.250124ms 749.252403ms 749.296433ms 749.303993ms 749.351974ms 749.353129ms 749.383535ms 749.409826ms 749.425366ms 749.426719ms 749.436182ms 749.43629ms 749.495365ms 749.504409ms 749.523414ms 749.560565ms 749.563608ms 749.585074ms 749.610879ms 749.617916ms 749.633639ms 749.639683ms 749.65225ms 749.652752ms 749.655674ms 749.657247ms 749.658512ms 749.698674ms 749.701772ms 749.734163ms 749.738122ms 749.745438ms 749.755126ms 749.76506ms 749.780734ms 749.788666ms 749.792875ms 749.803807ms 749.833943ms 749.838556ms 749.858395ms 749.861244ms 749.884591ms 749.894197ms 749.930608ms 749.931609ms 749.952798ms 749.954165ms 749.985662ms 749.992406ms 750.008315ms 750.029238ms 750.049062ms 750.056296ms 750.059932ms 750.062065ms 750.082291ms 750.086709ms 750.109239ms 750.111663ms 750.118233ms 750.119444ms 750.132185ms 750.141782ms 750.193721ms 750.193922ms 750.196479ms 750.197089ms 750.203768ms 750.212961ms 750.221105ms 750.253307ms 750.260344ms 750.301744ms 750.319118ms 750.323358ms 750.343742ms 750.356011ms 750.364955ms 750.365523ms 750.370714ms 750.375965ms 750.414431ms 750.453898ms 750.496906ms 750.503433ms 750.514274ms 750.545889ms 750.571517ms 750.577886ms 750.618776ms 750.635433ms 750.640274ms 750.652688ms 750.714058ms 750.716637ms 750.72519ms 750.74216ms 750.75377ms 750.753908ms 750.775703ms 750.810014ms 750.901515ms 750.945614ms 750.95163ms 751.026775ms 751.032242ms 751.033911ms 751.035785ms 751.119064ms 751.159659ms 751.310831ms 751.337767ms 751.543851ms 751.696129ms 752.230763ms 753.552768ms 753.753111ms 755.046836ms]
Nov 13 10:50:10.909: INFO: 50 %ile: 749.617916ms
Nov 13 10:50:10.909: INFO: 90 %ile: 750.753908ms
Nov 13 10:50:10.909: INFO: 99 %ile: 753.753111ms
Nov 13 10:50:10.909: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:50:10.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3410" for this suite.

• [SLOW TEST:10.848 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":278,"completed":123,"skipped":1679,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:50:10.914: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1572
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: validating cluster-info
Nov 13 10:50:11.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 cluster-info'
Nov 13 10:50:11.111: INFO: stderr: ""
Nov 13 10:50:11.111: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:50:11.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1572" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":278,"completed":124,"skipped":1691,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:50:11.120: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2204
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-map-c594a42e-4e67-4c8a-83da-cc38f1aeb775
STEP: Creating a pod to test consume secrets
Nov 13 10:50:11.253: INFO: Waiting up to 5m0s for pod "pod-secrets-170d765a-f7d1-4196-9b16-40ed34e453ed" in namespace "secrets-2204" to be "success or failure"
Nov 13 10:50:11.261: INFO: Pod "pod-secrets-170d765a-f7d1-4196-9b16-40ed34e453ed": Phase="Pending", Reason="", readiness=false. Elapsed: 7.861953ms
Nov 13 10:50:13.263: INFO: Pod "pod-secrets-170d765a-f7d1-4196-9b16-40ed34e453ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009773335s
STEP: Saw pod success
Nov 13 10:50:13.263: INFO: Pod "pod-secrets-170d765a-f7d1-4196-9b16-40ed34e453ed" satisfied condition "success or failure"
Nov 13 10:50:13.264: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-secrets-170d765a-f7d1-4196-9b16-40ed34e453ed container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 10:50:13.275: INFO: Waiting for pod pod-secrets-170d765a-f7d1-4196-9b16-40ed34e453ed to disappear
Nov 13 10:50:13.280: INFO: Pod pod-secrets-170d765a-f7d1-4196-9b16-40ed34e453ed no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:50:13.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2204" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":278,"completed":125,"skipped":1726,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:50:13.286: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1171
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov 13 10:50:17.450: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 13 10:50:17.458: INFO: Pod pod-with-prestop-http-hook still exists
Nov 13 10:50:19.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 13 10:50:19.460: INFO: Pod pod-with-prestop-http-hook still exists
Nov 13 10:50:21.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 13 10:50:21.460: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:50:21.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1171" for this suite.

• [SLOW TEST:8.184 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":278,"completed":126,"skipped":1755,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:50:21.470: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1731
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Nov 13 10:50:21.602: INFO: Waiting up to 5m0s for pod "downward-api-391ef76f-5198-4147-9c3e-b256e06fdc68" in namespace "downward-api-1731" to be "success or failure"
Nov 13 10:50:21.606: INFO: Pod "downward-api-391ef76f-5198-4147-9c3e-b256e06fdc68": Phase="Pending", Reason="", readiness=false. Elapsed: 3.900016ms
Nov 13 10:50:23.608: INFO: Pod "downward-api-391ef76f-5198-4147-9c3e-b256e06fdc68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005591102s
STEP: Saw pod success
Nov 13 10:50:23.608: INFO: Pod "downward-api-391ef76f-5198-4147-9c3e-b256e06fdc68" satisfied condition "success or failure"
Nov 13 10:50:23.609: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downward-api-391ef76f-5198-4147-9c3e-b256e06fdc68 container dapi-container: <nil>
STEP: delete the pod
Nov 13 10:50:23.620: INFO: Waiting for pod downward-api-391ef76f-5198-4147-9c3e-b256e06fdc68 to disappear
Nov 13 10:50:23.626: INFO: Pod downward-api-391ef76f-5198-4147-9c3e-b256e06fdc68 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:50:23.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1731" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":278,"completed":127,"skipped":1795,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:50:23.642: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8142
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 13 10:50:25.790: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:50:25.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8142" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":278,"completed":128,"skipped":1826,"failed":0}
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:50:25.807: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6715
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6715.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6715.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 13 10:50:27.965: INFO: DNS probes using dns-6715/dns-test-31996d9f-0049-4501-93bd-7dd83a3b6299 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:50:27.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6715" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":278,"completed":129,"skipped":1833,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:50:27.984: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4829
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-downwardapi-wmjb
STEP: Creating a pod to test atomic-volume-subpath
Nov 13 10:50:28.115: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-wmjb" in namespace "subpath-4829" to be "success or failure"
Nov 13 10:50:28.123: INFO: Pod "pod-subpath-test-downwardapi-wmjb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.86948ms
Nov 13 10:50:30.125: INFO: Pod "pod-subpath-test-downwardapi-wmjb": Phase="Running", Reason="", readiness=true. Elapsed: 2.009554481s
Nov 13 10:50:32.126: INFO: Pod "pod-subpath-test-downwardapi-wmjb": Phase="Running", Reason="", readiness=true. Elapsed: 4.011143753s
Nov 13 10:50:34.129: INFO: Pod "pod-subpath-test-downwardapi-wmjb": Phase="Running", Reason="", readiness=true. Elapsed: 6.014014826s
Nov 13 10:50:36.131: INFO: Pod "pod-subpath-test-downwardapi-wmjb": Phase="Running", Reason="", readiness=true. Elapsed: 8.016073667s
Nov 13 10:50:38.133: INFO: Pod "pod-subpath-test-downwardapi-wmjb": Phase="Running", Reason="", readiness=true. Elapsed: 10.018044914s
Nov 13 10:50:40.135: INFO: Pod "pod-subpath-test-downwardapi-wmjb": Phase="Running", Reason="", readiness=true. Elapsed: 12.020043984s
Nov 13 10:50:42.137: INFO: Pod "pod-subpath-test-downwardapi-wmjb": Phase="Running", Reason="", readiness=true. Elapsed: 14.021924056s
Nov 13 10:50:44.139: INFO: Pod "pod-subpath-test-downwardapi-wmjb": Phase="Running", Reason="", readiness=true. Elapsed: 16.023810494s
Nov 13 10:50:46.141: INFO: Pod "pod-subpath-test-downwardapi-wmjb": Phase="Running", Reason="", readiness=true. Elapsed: 18.025765019s
Nov 13 10:50:48.143: INFO: Pod "pod-subpath-test-downwardapi-wmjb": Phase="Running", Reason="", readiness=true. Elapsed: 20.027538117s
Nov 13 10:50:50.145: INFO: Pod "pod-subpath-test-downwardapi-wmjb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.029801986s
STEP: Saw pod success
Nov 13 10:50:50.145: INFO: Pod "pod-subpath-test-downwardapi-wmjb" satisfied condition "success or failure"
Nov 13 10:50:50.151: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-subpath-test-downwardapi-wmjb container test-container-subpath-downwardapi-wmjb: <nil>
STEP: delete the pod
Nov 13 10:50:50.172: INFO: Waiting for pod pod-subpath-test-downwardapi-wmjb to disappear
Nov 13 10:50:50.174: INFO: Pod pod-subpath-test-downwardapi-wmjb no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-wmjb
Nov 13 10:50:50.174: INFO: Deleting pod "pod-subpath-test-downwardapi-wmjb" in namespace "subpath-4829"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:50:50.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4829" for this suite.

• [SLOW TEST:22.199 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":278,"completed":130,"skipped":1850,"failed":0}
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:50:50.184: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-1365
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:172
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating server pod server in namespace prestop-1365
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-1365
STEP: Deleting pre-stop pod
Nov 13 10:50:59.348: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:50:59.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-1365" for this suite.

• [SLOW TEST:9.177 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":278,"completed":131,"skipped":1853,"failed":0}
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:50:59.361: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9412
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov 13 10:50:59.505: INFO: Number of nodes with available pods: 0
Nov 13 10:50:59.505: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:51:00.510: INFO: Number of nodes with available pods: 0
Nov 13 10:51:00.510: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:51:01.510: INFO: Number of nodes with available pods: 2
Nov 13 10:51:01.510: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov 13 10:51:01.528: INFO: Number of nodes with available pods: 1
Nov 13 10:51:01.528: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:51:02.532: INFO: Number of nodes with available pods: 1
Nov 13 10:51:02.532: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:51:03.532: INFO: Number of nodes with available pods: 1
Nov 13 10:51:03.532: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:51:04.532: INFO: Number of nodes with available pods: 1
Nov 13 10:51:04.532: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:51:05.532: INFO: Number of nodes with available pods: 1
Nov 13 10:51:05.532: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:51:06.533: INFO: Number of nodes with available pods: 1
Nov 13 10:51:06.533: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:51:07.532: INFO: Number of nodes with available pods: 1
Nov 13 10:51:07.532: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:51:08.532: INFO: Number of nodes with available pods: 1
Nov 13 10:51:08.532: INFO: Node 29607307-5497-41cc-a8d5-c2f7d9a90e41 is running more than one daemon pod
Nov 13 10:51:09.533: INFO: Number of nodes with available pods: 2
Nov 13 10:51:09.533: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9412, will wait for the garbage collector to delete the pods
Nov 13 10:51:09.594: INFO: Deleting DaemonSet.extensions daemon-set took: 7.426558ms
Nov 13 10:51:09.995: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.190864ms
Nov 13 10:51:13.496: INFO: Number of nodes with available pods: 0
Nov 13 10:51:13.496: INFO: Number of running nodes: 0, number of available pods: 0
Nov 13 10:51:13.497: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9412/daemonsets","resourceVersion":"307640"},"items":null}

Nov 13 10:51:13.498: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9412/pods","resourceVersion":"307640"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:51:13.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9412" for this suite.

• [SLOW TEST:14.145 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":278,"completed":132,"skipped":1856,"failed":0}
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:51:13.506: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4699
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Nov 13 10:51:16.163: INFO: Successfully updated pod "labelsupdatea728e68f-49b8-49a6-9fe1-3e69d8136abf"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:51:20.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4699" for this suite.

• [SLOW TEST:6.676 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":278,"completed":133,"skipped":1859,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:51:20.183: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1060
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1525
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 13 10:51:20.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-1060'
Nov 13 10:51:20.363: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 13 10:51:20.363: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Nov 13 10:51:20.377: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-7pr8l]
Nov 13 10:51:20.378: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-7pr8l" in namespace "kubectl-1060" to be "running and ready"
Nov 13 10:51:20.380: INFO: Pod "e2e-test-httpd-rc-7pr8l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.252317ms
Nov 13 10:51:22.382: INFO: Pod "e2e-test-httpd-rc-7pr8l": Phase="Running", Reason="", readiness=true. Elapsed: 2.004081507s
Nov 13 10:51:22.382: INFO: Pod "e2e-test-httpd-rc-7pr8l" satisfied condition "running and ready"
Nov 13 10:51:22.382: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-7pr8l]
Nov 13 10:51:22.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 logs rc/e2e-test-httpd-rc --namespace=kubectl-1060'
Nov 13 10:51:22.442: INFO: stderr: ""
Nov 13 10:51:22.442: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.200.43.217. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.200.43.217. Set the 'ServerName' directive globally to suppress this message\n[Fri Nov 13 10:51:21.362819 2020] [mpm_event:notice] [pid 1:tid 139692782127976] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Fri Nov 13 10:51:21.362862 2020] [core:notice] [pid 1:tid 139692782127976] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1530
Nov 13 10:51:22.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete rc e2e-test-httpd-rc --namespace=kubectl-1060'
Nov 13 10:51:22.490: INFO: stderr: ""
Nov 13 10:51:22.490: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:51:22.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1060" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run rc should create an rc from an image  [Conformance]","total":278,"completed":134,"skipped":1893,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:51:22.496: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1936
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov 13 10:51:22.629: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1936 /api/v1/namespaces/watch-1936/configmaps/e2e-watch-test-configmap-a ce22fafc-2d55-4a78-bfa5-7bfc1d690907 307727 0 2020-11-13 10:51:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 13 10:51:22.629: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1936 /api/v1/namespaces/watch-1936/configmaps/e2e-watch-test-configmap-a ce22fafc-2d55-4a78-bfa5-7bfc1d690907 307727 0 2020-11-13 10:51:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov 13 10:51:32.634: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1936 /api/v1/namespaces/watch-1936/configmaps/e2e-watch-test-configmap-a ce22fafc-2d55-4a78-bfa5-7bfc1d690907 307779 0 2020-11-13 10:51:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov 13 10:51:32.634: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1936 /api/v1/namespaces/watch-1936/configmaps/e2e-watch-test-configmap-a ce22fafc-2d55-4a78-bfa5-7bfc1d690907 307779 0 2020-11-13 10:51:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov 13 10:51:42.638: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1936 /api/v1/namespaces/watch-1936/configmaps/e2e-watch-test-configmap-a ce22fafc-2d55-4a78-bfa5-7bfc1d690907 307813 0 2020-11-13 10:51:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 13 10:51:42.638: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1936 /api/v1/namespaces/watch-1936/configmaps/e2e-watch-test-configmap-a ce22fafc-2d55-4a78-bfa5-7bfc1d690907 307813 0 2020-11-13 10:51:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov 13 10:51:52.641: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1936 /api/v1/namespaces/watch-1936/configmaps/e2e-watch-test-configmap-a ce22fafc-2d55-4a78-bfa5-7bfc1d690907 307837 0 2020-11-13 10:51:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 13 10:51:52.642: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1936 /api/v1/namespaces/watch-1936/configmaps/e2e-watch-test-configmap-a ce22fafc-2d55-4a78-bfa5-7bfc1d690907 307837 0 2020-11-13 10:51:22 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov 13 10:52:02.645: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1936 /api/v1/namespaces/watch-1936/configmaps/e2e-watch-test-configmap-b e63f5f43-cf5a-4112-ba12-a155872e9de4 307861 0 2020-11-13 10:52:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 13 10:52:02.646: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1936 /api/v1/namespaces/watch-1936/configmaps/e2e-watch-test-configmap-b e63f5f43-cf5a-4112-ba12-a155872e9de4 307861 0 2020-11-13 10:52:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov 13 10:52:12.649: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1936 /api/v1/namespaces/watch-1936/configmaps/e2e-watch-test-configmap-b e63f5f43-cf5a-4112-ba12-a155872e9de4 307885 0 2020-11-13 10:52:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 13 10:52:12.649: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1936 /api/v1/namespaces/watch-1936/configmaps/e2e-watch-test-configmap-b e63f5f43-cf5a-4112-ba12-a155872e9de4 307885 0 2020-11-13 10:52:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:52:22.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1936" for this suite.

• [SLOW TEST:60.158 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":278,"completed":135,"skipped":1907,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:52:22.655: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1210
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Nov 13 10:52:22.778: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 13 10:52:22.782: INFO: Waiting for terminating namespaces to be deleted...
Nov 13 10:52:22.784: INFO: 
Logging pods the kubelet thinks is on node 29607307-5497-41cc-a8d5-c2f7d9a90e41 before test
Nov 13 10:52:22.787: INFO: coredns-54b9777bfc-nhhjt from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 10:52:22.787: INFO: 	Container coredns ready: true, restart count 0
Nov 13 10:52:22.787: INFO: metrics-server-5df78f85b-kzd6m from kube-system started at 2020-11-12 01:07:27 +0000 UTC (1 container statuses recorded)
Nov 13 10:52:22.787: INFO: 	Container metrics-server ready: true, restart count 0
Nov 13 10:52:22.787: INFO: filebeat-chjmw from kube-system started at 2020-11-12 01:08:33 +0000 UTC (1 container statuses recorded)
Nov 13 10:52:22.787: INFO: 	Container filebeat ready: true, restart count 0
Nov 13 10:52:22.787: INFO: sonobuoy from sonobuoy started at 2020-11-13 09:37:07 +0000 UTC (1 container statuses recorded)
Nov 13 10:52:22.787: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 13 10:52:22.787: INFO: traefik-ingress-controller-v48l8 from traefik-ingress started at 2020-11-12 01:09:03 +0000 UTC (1 container statuses recorded)
Nov 13 10:52:22.787: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov 13 10:52:22.787: INFO: sonobuoy-systemd-logs-daemon-set-294e69fb102c4fcf-tncdk from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 10:52:22.787: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 10:52:22.787: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 13 10:52:22.787: INFO: 
Logging pods the kubelet thinks is on node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c before test
Nov 13 10:52:22.797: INFO: coredns-54b9777bfc-q6tzp from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 10:52:22.797: INFO: 	Container coredns ready: true, restart count 0
Nov 13 10:52:22.797: INFO: traefik-ingress-controller-xbfqn from traefik-ingress started at 2020-11-12 01:09:03 +0000 UTC (1 container statuses recorded)
Nov 13 10:52:22.797: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov 13 10:52:22.797: INFO: sonobuoy-systemd-logs-daemon-set-294e69fb102c4fcf-fk6ph from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 10:52:22.798: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 10:52:22.798: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 13 10:52:22.798: INFO: coredns-54b9777bfc-jj6kl from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 10:52:22.798: INFO: 	Container coredns ready: true, restart count 0
Nov 13 10:52:22.798: INFO: filebeat-zxtp6 from kube-system started at 2020-11-12 01:08:33 +0000 UTC (1 container statuses recorded)
Nov 13 10:52:22.798: INFO: 	Container filebeat ready: true, restart count 0
Nov 13 10:52:22.798: INFO: sonobuoy-e2e-job-b8fa8fc01c7d4f11 from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 10:52:22.798: INFO: 	Container e2e ready: true, restart count 0
Nov 13 10:52:22.798: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-460ed326-22c2-4f05-9541-fb139805b437 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-460ed326-22c2-4f05-9541-fb139805b437 off the node 29607307-5497-41cc-a8d5-c2f7d9a90e41
STEP: verifying the node doesn't have the label kubernetes.io/e2e-460ed326-22c2-4f05-9541-fb139805b437
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:52:30.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1210" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77

• [SLOW TEST:8.219 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":278,"completed":136,"skipped":1949,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:52:30.875: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-159
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:52:31.348: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 13 10:52:33.352: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861551, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861551, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861551, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861551, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:52:36.361: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the webhook via the AdmissionRegistration API
Nov 13 10:52:36.389: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:52:46.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-159" for this suite.
STEP: Destroying namespace "webhook-159-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.707 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":278,"completed":137,"skipped":1961,"failed":0}
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:52:46.582: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1651
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1651.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1651.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1651.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1651.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1651.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1651.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1651.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1651.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1651.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1651.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1651.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1651.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1651.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 152.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.152_udp@PTR;check="$$(dig +tcp +noall +answer +search 152.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.152_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1651.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1651.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1651.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1651.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1651.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1651.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1651.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1651.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1651.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1651.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1651.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1651.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1651.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 152.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.152_udp@PTR;check="$$(dig +tcp +noall +answer +search 152.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.152_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 13 10:52:48.763: INFO: Unable to read wheezy_udp@dns-test-service.dns-1651.svc.cluster.local from pod dns-1651/dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96: the server could not find the requested resource (get pods dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96)
Nov 13 10:52:48.764: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1651.svc.cluster.local from pod dns-1651/dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96: the server could not find the requested resource (get pods dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96)
Nov 13 10:52:48.766: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1651.svc.cluster.local from pod dns-1651/dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96: the server could not find the requested resource (get pods dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96)
Nov 13 10:52:48.768: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1651.svc.cluster.local from pod dns-1651/dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96: the server could not find the requested resource (get pods dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96)
Nov 13 10:52:48.778: INFO: Unable to read jessie_udp@dns-test-service.dns-1651.svc.cluster.local from pod dns-1651/dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96: the server could not find the requested resource (get pods dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96)
Nov 13 10:52:48.780: INFO: Unable to read jessie_tcp@dns-test-service.dns-1651.svc.cluster.local from pod dns-1651/dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96: the server could not find the requested resource (get pods dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96)
Nov 13 10:52:48.782: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1651.svc.cluster.local from pod dns-1651/dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96: the server could not find the requested resource (get pods dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96)
Nov 13 10:52:48.783: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1651.svc.cluster.local from pod dns-1651/dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96: the server could not find the requested resource (get pods dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96)
Nov 13 10:52:48.795: INFO: Lookups using dns-1651/dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96 failed for: [wheezy_udp@dns-test-service.dns-1651.svc.cluster.local wheezy_tcp@dns-test-service.dns-1651.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1651.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1651.svc.cluster.local jessie_udp@dns-test-service.dns-1651.svc.cluster.local jessie_tcp@dns-test-service.dns-1651.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1651.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1651.svc.cluster.local]

Nov 13 10:52:53.829: INFO: DNS probes using dns-1651/dns-test-407f9c9c-2990-446c-9d18-70b3d69cba96 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:52:53.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1651" for this suite.

• [SLOW TEST:7.298 seconds]
[sig-network] DNS
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":278,"completed":138,"skipped":1968,"failed":0}
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:52:53.883: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1026
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:52:54.010: INFO: Creating ReplicaSet my-hostname-basic-7879f0d9-0eb7-4742-9d6d-719c9743c25e
Nov 13 10:52:54.015: INFO: Pod name my-hostname-basic-7879f0d9-0eb7-4742-9d6d-719c9743c25e: Found 0 pods out of 1
Nov 13 10:52:59.017: INFO: Pod name my-hostname-basic-7879f0d9-0eb7-4742-9d6d-719c9743c25e: Found 1 pods out of 1
Nov 13 10:52:59.017: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-7879f0d9-0eb7-4742-9d6d-719c9743c25e" is running
Nov 13 10:52:59.018: INFO: Pod "my-hostname-basic-7879f0d9-0eb7-4742-9d6d-719c9743c25e-q8md7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-13 10:52:54 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-13 10:52:55 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-13 10:52:55 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-13 10:52:54 +0000 UTC Reason: Message:}])
Nov 13 10:52:59.018: INFO: Trying to dial the pod
Nov 13 10:53:04.024: INFO: Controller my-hostname-basic-7879f0d9-0eb7-4742-9d6d-719c9743c25e: Got expected result from replica 1 [my-hostname-basic-7879f0d9-0eb7-4742-9d6d-719c9743c25e-q8md7]: "my-hostname-basic-7879f0d9-0eb7-4742-9d6d-719c9743c25e-q8md7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:53:04.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1026" for this suite.

• [SLOW TEST:10.145 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":278,"completed":139,"skipped":1971,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:53:04.028: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-72d97222-de69-464c-8058-3064e183e1f7
STEP: Creating a pod to test consume configMaps
Nov 13 10:53:04.156: INFO: Waiting up to 5m0s for pod "pod-configmaps-9693e142-1c0b-4102-bb2e-c53362ad57a9" in namespace "configmap-6834" to be "success or failure"
Nov 13 10:53:04.160: INFO: Pod "pod-configmaps-9693e142-1c0b-4102-bb2e-c53362ad57a9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.729038ms
Nov 13 10:53:06.162: INFO: Pod "pod-configmaps-9693e142-1c0b-4102-bb2e-c53362ad57a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005708379s
STEP: Saw pod success
Nov 13 10:53:06.162: INFO: Pod "pod-configmaps-9693e142-1c0b-4102-bb2e-c53362ad57a9" satisfied condition "success or failure"
Nov 13 10:53:06.163: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-configmaps-9693e142-1c0b-4102-bb2e-c53362ad57a9 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:53:06.173: INFO: Waiting for pod pod-configmaps-9693e142-1c0b-4102-bb2e-c53362ad57a9 to disappear
Nov 13 10:53:06.178: INFO: Pod pod-configmaps-9693e142-1c0b-4102-bb2e-c53362ad57a9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:53:06.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6834" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":140,"skipped":1981,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:53:06.183: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4602
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-02b65fd1-2f3f-449a-95bf-8e631ba14f95
STEP: Creating a pod to test consume configMaps
Nov 13 10:53:06.311: INFO: Waiting up to 5m0s for pod "pod-configmaps-60757338-94a1-472f-bc2a-abae1f0319ab" in namespace "configmap-4602" to be "success or failure"
Nov 13 10:53:06.316: INFO: Pod "pod-configmaps-60757338-94a1-472f-bc2a-abae1f0319ab": Phase="Pending", Reason="", readiness=false. Elapsed: 5.645583ms
Nov 13 10:53:08.318: INFO: Pod "pod-configmaps-60757338-94a1-472f-bc2a-abae1f0319ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007450532s
STEP: Saw pod success
Nov 13 10:53:08.318: INFO: Pod "pod-configmaps-60757338-94a1-472f-bc2a-abae1f0319ab" satisfied condition "success or failure"
Nov 13 10:53:08.319: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-configmaps-60757338-94a1-472f-bc2a-abae1f0319ab container configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:53:08.328: INFO: Waiting for pod pod-configmaps-60757338-94a1-472f-bc2a-abae1f0319ab to disappear
Nov 13 10:53:08.333: INFO: Pod pod-configmaps-60757338-94a1-472f-bc2a-abae1f0319ab no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:53:08.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4602" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":278,"completed":141,"skipped":1982,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:53:08.337: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7567
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service multi-endpoint-test in namespace services-7567
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7567 to expose endpoints map[]
Nov 13 10:53:08.467: INFO: successfully validated that service multi-endpoint-test in namespace services-7567 exposes endpoints map[] (4.131884ms elapsed)
STEP: Creating pod pod1 in namespace services-7567
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7567 to expose endpoints map[pod1:[100]]
Nov 13 10:53:10.488: INFO: successfully validated that service multi-endpoint-test in namespace services-7567 exposes endpoints map[pod1:[100]] (2.012760555s elapsed)
STEP: Creating pod pod2 in namespace services-7567
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7567 to expose endpoints map[pod1:[100] pod2:[101]]
Nov 13 10:53:12.515: INFO: successfully validated that service multi-endpoint-test in namespace services-7567 exposes endpoints map[pod1:[100] pod2:[101]] (2.022406185s elapsed)
STEP: Deleting pod pod1 in namespace services-7567
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7567 to expose endpoints map[pod2:[101]]
Nov 13 10:53:12.527: INFO: successfully validated that service multi-endpoint-test in namespace services-7567 exposes endpoints map[pod2:[101]] (9.038935ms elapsed)
STEP: Deleting pod pod2 in namespace services-7567
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7567 to expose endpoints map[]
Nov 13 10:53:12.539: INFO: successfully validated that service multi-endpoint-test in namespace services-7567 exposes endpoints map[] (7.08304ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:53:12.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7567" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143
•{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":278,"completed":142,"skipped":1992,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:53:12.553: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8977
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:53:13.041: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:53:16.050: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:53:16.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8977" for this suite.
STEP: Destroying namespace "webhook-8977-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":278,"completed":143,"skipped":2002,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:53:16.247: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2563
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:53:16.664: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 13 10:53:18.668: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861596, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861596, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861596, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861596, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:53:21.675: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:53:21.677: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4126-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:53:23.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2563" for this suite.
STEP: Destroying namespace "webhook-2563-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.016 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":278,"completed":144,"skipped":2027,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:53:23.264: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3090
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov 13 10:53:23.396: INFO: Waiting up to 5m0s for pod "pod-1055f070-b0fe-471b-930b-ccc24a6fd928" in namespace "emptydir-3090" to be "success or failure"
Nov 13 10:53:23.399: INFO: Pod "pod-1055f070-b0fe-471b-930b-ccc24a6fd928": Phase="Pending", Reason="", readiness=false. Elapsed: 2.681407ms
Nov 13 10:53:25.401: INFO: Pod "pod-1055f070-b0fe-471b-930b-ccc24a6fd928": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004577209s
STEP: Saw pod success
Nov 13 10:53:25.401: INFO: Pod "pod-1055f070-b0fe-471b-930b-ccc24a6fd928" satisfied condition "success or failure"
Nov 13 10:53:25.402: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-1055f070-b0fe-471b-930b-ccc24a6fd928 container test-container: <nil>
STEP: delete the pod
Nov 13 10:53:25.412: INFO: Waiting for pod pod-1055f070-b0fe-471b-930b-ccc24a6fd928 to disappear
Nov 13 10:53:25.417: INFO: Pod pod-1055f070-b0fe-471b-930b-ccc24a6fd928 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:53:25.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3090" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":145,"skipped":2049,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:53:25.424: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9061
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:53:25.575: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"3a516cd2-8655-43f6-a3c6-1e0dbedc95cb", Controller:(*bool)(0xc004789692), BlockOwnerDeletion:(*bool)(0xc004789693)}}
Nov 13 10:53:25.587: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"ae20984c-105c-4bdc-8392-e4c431610d84", Controller:(*bool)(0xc004807672), BlockOwnerDeletion:(*bool)(0xc004807673)}}
Nov 13 10:53:25.603: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"79bd3ce8-148f-4cd1-8eac-6260590d1fc0", Controller:(*bool)(0xc004789892), BlockOwnerDeletion:(*bool)(0xc004789893)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:53:30.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9061" for this suite.

• [SLOW TEST:5.195 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":278,"completed":146,"skipped":2071,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:53:30.619: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7171
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with configMap that has name projected-configmap-test-upd-67203188-43ca-4e43-9fd3-d78ba4424e23
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-67203188-43ca-4e43-9fd3-d78ba4424e23
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:53:34.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7171" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":278,"completed":147,"skipped":2093,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:53:34.831: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1727
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1357
STEP: creating an pod
Nov 13 10:53:34.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.8 --namespace=kubectl-1727 -- logs-generator --log-lines-total 100 --run-duration 20s'
Nov 13 10:53:35.019: INFO: stderr: ""
Nov 13 10:53:35.019: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Waiting for log generator to start.
Nov 13 10:53:35.019: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Nov 13 10:53:35.019: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1727" to be "running and ready, or succeeded"
Nov 13 10:53:35.021: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.672413ms
Nov 13 10:53:37.023: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.004563902s
Nov 13 10:53:37.023: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Nov 13 10:53:37.023: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Nov 13 10:53:37.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 logs logs-generator logs-generator --namespace=kubectl-1727'
Nov 13 10:53:37.075: INFO: stderr: ""
Nov 13 10:53:37.075: INFO: stdout: "I1113 10:53:35.991241       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/sxl 512\nI1113 10:53:36.191584       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/6rz 444\nI1113 10:53:36.391473       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/n6w 356\nI1113 10:53:36.591405       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/vzl 231\nI1113 10:53:36.791393       1 logs_generator.go:76] 4 POST /api/v1/namespaces/default/pods/g7s 374\nI1113 10:53:36.991367       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/vb6 343\n"
STEP: limiting log lines
Nov 13 10:53:37.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 logs logs-generator logs-generator --namespace=kubectl-1727 --tail=1'
Nov 13 10:53:37.130: INFO: stderr: ""
Nov 13 10:53:37.130: INFO: stdout: "I1113 10:53:36.991367       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/vb6 343\n"
Nov 13 10:53:37.130: INFO: got output "I1113 10:53:36.991367       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/vb6 343\n"
STEP: limiting log bytes
Nov 13 10:53:37.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 logs logs-generator logs-generator --namespace=kubectl-1727 --limit-bytes=1'
Nov 13 10:53:37.187: INFO: stderr: ""
Nov 13 10:53:37.187: INFO: stdout: "I"
Nov 13 10:53:37.187: INFO: got output "I"
STEP: exposing timestamps
Nov 13 10:53:37.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 logs logs-generator logs-generator --namespace=kubectl-1727 --tail=1 --timestamps'
Nov 13 10:53:37.241: INFO: stderr: ""
Nov 13 10:53:37.241: INFO: stdout: "2020-11-13T10:53:37.191487831Z I1113 10:53:37.191390       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/mhr 431\n"
Nov 13 10:53:37.241: INFO: got output "2020-11-13T10:53:37.191487831Z I1113 10:53:37.191390       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/mhr 431\n"
STEP: restricting to a time range
Nov 13 10:53:39.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 logs logs-generator logs-generator --namespace=kubectl-1727 --since=1s'
Nov 13 10:53:39.797: INFO: stderr: ""
Nov 13 10:53:39.797: INFO: stdout: "I1113 10:53:38.991393       1 logs_generator.go:76] 15 POST /api/v1/namespaces/kube-system/pods/bcq 570\nI1113 10:53:39.191379       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/jwdx 301\nI1113 10:53:39.391394       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/5tff 306\nI1113 10:53:39.591389       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/b28g 560\nI1113 10:53:39.791411       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/xd2p 422\n"
Nov 13 10:53:39.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 logs logs-generator logs-generator --namespace=kubectl-1727 --since=24h'
Nov 13 10:53:39.865: INFO: stderr: ""
Nov 13 10:53:39.865: INFO: stdout: "I1113 10:53:35.991241       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/sxl 512\nI1113 10:53:36.191584       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/6rz 444\nI1113 10:53:36.391473       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/n6w 356\nI1113 10:53:36.591405       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/vzl 231\nI1113 10:53:36.791393       1 logs_generator.go:76] 4 POST /api/v1/namespaces/default/pods/g7s 374\nI1113 10:53:36.991367       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/vb6 343\nI1113 10:53:37.191390       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/mhr 431\nI1113 10:53:37.391371       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/gxh 265\nI1113 10:53:37.591486       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/xgts 208\nI1113 10:53:37.791408       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/mhjl 535\nI1113 10:53:37.991427       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/gc4 520\nI1113 10:53:38.191499       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/srv8 568\nI1113 10:53:38.391377       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/f5g 261\nI1113 10:53:38.591450       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/4h2 522\nI1113 10:53:38.791438       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/n5c 277\nI1113 10:53:38.991393       1 logs_generator.go:76] 15 POST /api/v1/namespaces/kube-system/pods/bcq 570\nI1113 10:53:39.191379       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/jwdx 301\nI1113 10:53:39.391394       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/5tff 306\nI1113 10:53:39.591389       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/b28g 560\nI1113 10:53:39.791411       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/xd2p 422\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1363
Nov 13 10:53:39.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete pod logs-generator --namespace=kubectl-1727'
Nov 13 10:53:47.430: INFO: stderr: ""
Nov 13 10:53:47.430: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:53:47.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1727" for this suite.

• [SLOW TEST:12.607 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1353
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":278,"completed":148,"skipped":2102,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:53:47.438: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6965
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:53:47.560: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:53:49.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6965" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":278,"completed":149,"skipped":2144,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:53:49.589: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-838
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Nov 13 10:53:49.716: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:53:52.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-838" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":278,"completed":150,"skipped":2186,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:53:52.485: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8017
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:53:53.052: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 13 10:53:55.056: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861633, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861633, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861633, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861633, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:53:58.063: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:53:58.065: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5523-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:53:59.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8017" for this suite.
STEP: Destroying namespace "webhook-8017-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.972 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":278,"completed":151,"skipped":2191,"failed":0}
SS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:53:59.458: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-7816
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:53:59.593: INFO: Waiting up to 5m0s for pod "busybox-user-65534-5dd3fab9-7cbf-4db1-99da-1f02f1562a62" in namespace "security-context-test-7816" to be "success or failure"
Nov 13 10:53:59.603: INFO: Pod "busybox-user-65534-5dd3fab9-7cbf-4db1-99da-1f02f1562a62": Phase="Pending", Reason="", readiness=false. Elapsed: 10.416749ms
Nov 13 10:54:01.605: INFO: Pod "busybox-user-65534-5dd3fab9-7cbf-4db1-99da-1f02f1562a62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012405415s
Nov 13 10:54:03.607: INFO: Pod "busybox-user-65534-5dd3fab9-7cbf-4db1-99da-1f02f1562a62": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014250805s
Nov 13 10:54:05.609: INFO: Pod "busybox-user-65534-5dd3fab9-7cbf-4db1-99da-1f02f1562a62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016246962s
Nov 13 10:54:05.609: INFO: Pod "busybox-user-65534-5dd3fab9-7cbf-4db1-99da-1f02f1562a62" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:54:05.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7816" for this suite.

• [SLOW TEST:6.156 seconds]
[k8s.io] Security Context
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  When creating a container with runAsUser
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:43
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":152,"skipped":2193,"failed":0}
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:54:05.614: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-43
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:54:12.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-43" for this suite.

• [SLOW TEST:7.136 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":278,"completed":153,"skipped":2197,"failed":0}
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:54:12.750: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4894
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-projected-27jz
STEP: Creating a pod to test atomic-volume-subpath
Nov 13 10:54:12.884: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-27jz" in namespace "subpath-4894" to be "success or failure"
Nov 13 10:54:12.888: INFO: Pod "pod-subpath-test-projected-27jz": Phase="Pending", Reason="", readiness=false. Elapsed: 3.486006ms
Nov 13 10:54:14.890: INFO: Pod "pod-subpath-test-projected-27jz": Phase="Running", Reason="", readiness=true. Elapsed: 2.005567828s
Nov 13 10:54:16.892: INFO: Pod "pod-subpath-test-projected-27jz": Phase="Running", Reason="", readiness=true. Elapsed: 4.00791866s
Nov 13 10:54:18.896: INFO: Pod "pod-subpath-test-projected-27jz": Phase="Running", Reason="", readiness=true. Elapsed: 6.011453005s
Nov 13 10:54:20.898: INFO: Pod "pod-subpath-test-projected-27jz": Phase="Running", Reason="", readiness=true. Elapsed: 8.014123132s
Nov 13 10:54:22.900: INFO: Pod "pod-subpath-test-projected-27jz": Phase="Running", Reason="", readiness=true. Elapsed: 10.016033002s
Nov 13 10:54:24.902: INFO: Pod "pod-subpath-test-projected-27jz": Phase="Running", Reason="", readiness=true. Elapsed: 12.018235073s
Nov 13 10:54:26.905: INFO: Pod "pod-subpath-test-projected-27jz": Phase="Running", Reason="", readiness=true. Elapsed: 14.020318879s
Nov 13 10:54:28.906: INFO: Pod "pod-subpath-test-projected-27jz": Phase="Running", Reason="", readiness=true. Elapsed: 16.022076932s
Nov 13 10:54:30.908: INFO: Pod "pod-subpath-test-projected-27jz": Phase="Running", Reason="", readiness=true. Elapsed: 18.024064807s
Nov 13 10:54:32.910: INFO: Pod "pod-subpath-test-projected-27jz": Phase="Running", Reason="", readiness=true. Elapsed: 20.026007675s
Nov 13 10:54:34.912: INFO: Pod "pod-subpath-test-projected-27jz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.028098512s
STEP: Saw pod success
Nov 13 10:54:34.912: INFO: Pod "pod-subpath-test-projected-27jz" satisfied condition "success or failure"
Nov 13 10:54:34.914: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-subpath-test-projected-27jz container test-container-subpath-projected-27jz: <nil>
STEP: delete the pod
Nov 13 10:54:34.925: INFO: Waiting for pod pod-subpath-test-projected-27jz to disappear
Nov 13 10:54:34.932: INFO: Pod pod-subpath-test-projected-27jz no longer exists
STEP: Deleting pod pod-subpath-test-projected-27jz
Nov 13 10:54:34.932: INFO: Deleting pod "pod-subpath-test-projected-27jz" in namespace "subpath-4894"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:54:34.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4894" for this suite.

• [SLOW TEST:22.187 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":278,"completed":154,"skipped":2201,"failed":0}
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:54:34.938: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8994
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-8994.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-8994.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8994.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-8994.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-8994.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8994.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 13 10:54:37.086: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local from pod dns-8994/dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f: the server could not find the requested resource (get pods dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f)
Nov 13 10:54:37.088: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local from pod dns-8994/dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f: the server could not find the requested resource (get pods dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f)
Nov 13 10:54:37.090: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8994.svc.cluster.local from pod dns-8994/dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f: the server could not find the requested resource (get pods dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f)
Nov 13 10:54:37.091: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8994.svc.cluster.local from pod dns-8994/dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f: the server could not find the requested resource (get pods dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f)
Nov 13 10:54:37.096: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local from pod dns-8994/dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f: the server could not find the requested resource (get pods dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f)
Nov 13 10:54:37.098: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local from pod dns-8994/dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f: the server could not find the requested resource (get pods dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f)
Nov 13 10:54:37.099: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8994.svc.cluster.local from pod dns-8994/dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f: the server could not find the requested resource (get pods dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f)
Nov 13 10:54:37.101: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8994.svc.cluster.local from pod dns-8994/dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f: the server could not find the requested resource (get pods dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f)
Nov 13 10:54:37.104: INFO: Lookups using dns-8994/dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8994.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8994.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8994.svc.cluster.local jessie_udp@dns-test-service-2.dns-8994.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8994.svc.cluster.local]

Nov 13 10:54:42.111: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8994.svc.cluster.local from pod dns-8994/dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f: the server could not find the requested resource (get pods dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f)
Nov 13 10:54:42.125: INFO: Lookups using dns-8994/dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f failed for: [wheezy_udp@dns-test-service-2.dns-8994.svc.cluster.local]

Nov 13 10:54:47.131: INFO: DNS probes using dns-8994/dns-test-541cc474-1e37-4e07-bbe9-c0360a2a6a4f succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:54:47.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8994" for this suite.

• [SLOW TEST:12.232 seconds]
[sig-network] DNS
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":278,"completed":155,"skipped":2205,"failed":0}
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:54:47.169: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6668
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:54:47.306: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fb636c2f-da69-4ef4-acc9-7f9156db277e" in namespace "projected-6668" to be "success or failure"
Nov 13 10:54:47.310: INFO: Pod "downwardapi-volume-fb636c2f-da69-4ef4-acc9-7f9156db277e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.910611ms
Nov 13 10:54:49.312: INFO: Pod "downwardapi-volume-fb636c2f-da69-4ef4-acc9-7f9156db277e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00586884s
Nov 13 10:54:51.314: INFO: Pod "downwardapi-volume-fb636c2f-da69-4ef4-acc9-7f9156db277e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007715804s
STEP: Saw pod success
Nov 13 10:54:51.314: INFO: Pod "downwardapi-volume-fb636c2f-da69-4ef4-acc9-7f9156db277e" satisfied condition "success or failure"
Nov 13 10:54:51.315: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-fb636c2f-da69-4ef4-acc9-7f9156db277e container client-container: <nil>
STEP: delete the pod
Nov 13 10:54:51.324: INFO: Waiting for pod downwardapi-volume-fb636c2f-da69-4ef4-acc9-7f9156db277e to disappear
Nov 13 10:54:51.329: INFO: Pod downwardapi-volume-fb636c2f-da69-4ef4-acc9-7f9156db277e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:54:51.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6668" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":278,"completed":156,"skipped":2205,"failed":0}
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:54:51.334: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7582
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test substitution in container's command
Nov 13 10:54:51.461: INFO: Waiting up to 5m0s for pod "var-expansion-52c0ab90-f75b-4bb2-a63d-3f0294eeadfa" in namespace "var-expansion-7582" to be "success or failure"
Nov 13 10:54:51.469: INFO: Pod "var-expansion-52c0ab90-f75b-4bb2-a63d-3f0294eeadfa": Phase="Pending", Reason="", readiness=false. Elapsed: 8.20088ms
Nov 13 10:54:53.471: INFO: Pod "var-expansion-52c0ab90-f75b-4bb2-a63d-3f0294eeadfa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01002063s
STEP: Saw pod success
Nov 13 10:54:53.471: INFO: Pod "var-expansion-52c0ab90-f75b-4bb2-a63d-3f0294eeadfa" satisfied condition "success or failure"
Nov 13 10:54:53.472: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod var-expansion-52c0ab90-f75b-4bb2-a63d-3f0294eeadfa container dapi-container: <nil>
STEP: delete the pod
Nov 13 10:54:53.484: INFO: Waiting for pod var-expansion-52c0ab90-f75b-4bb2-a63d-3f0294eeadfa to disappear
Nov 13 10:54:53.486: INFO: Pod var-expansion-52c0ab90-f75b-4bb2-a63d-3f0294eeadfa no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:54:53.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7582" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":278,"completed":157,"skipped":2211,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:54:53.490: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4122
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-a5ff1af5-e400-47a3-8b6e-28f5c9a610e7
STEP: Creating a pod to test consume configMaps
Nov 13 10:54:53.617: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-300ae144-40ee-43c2-affe-9e5423024e84" in namespace "projected-4122" to be "success or failure"
Nov 13 10:54:53.625: INFO: Pod "pod-projected-configmaps-300ae144-40ee-43c2-affe-9e5423024e84": Phase="Pending", Reason="", readiness=false. Elapsed: 7.799147ms
Nov 13 10:54:55.627: INFO: Pod "pod-projected-configmaps-300ae144-40ee-43c2-affe-9e5423024e84": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009748361s
STEP: Saw pod success
Nov 13 10:54:55.627: INFO: Pod "pod-projected-configmaps-300ae144-40ee-43c2-affe-9e5423024e84" satisfied condition "success or failure"
Nov 13 10:54:55.628: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-projected-configmaps-300ae144-40ee-43c2-affe-9e5423024e84 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:54:55.637: INFO: Waiting for pod pod-projected-configmaps-300ae144-40ee-43c2-affe-9e5423024e84 to disappear
Nov 13 10:54:55.644: INFO: Pod pod-projected-configmaps-300ae144-40ee-43c2-affe-9e5423024e84 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:54:55.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4122" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":278,"completed":158,"skipped":2212,"failed":0}
SSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:54:55.650: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4080
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:54:55.778: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-825b3db1-897a-442a-9492-722f5e2e2454" in namespace "security-context-test-4080" to be "success or failure"
Nov 13 10:54:55.785: INFO: Pod "busybox-readonly-false-825b3db1-897a-442a-9492-722f5e2e2454": Phase="Pending", Reason="", readiness=false. Elapsed: 7.685908ms
Nov 13 10:54:57.787: INFO: Pod "busybox-readonly-false-825b3db1-897a-442a-9492-722f5e2e2454": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009507522s
Nov 13 10:54:57.787: INFO: Pod "busybox-readonly-false-825b3db1-897a-442a-9492-722f5e2e2454" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:54:57.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4080" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":278,"completed":159,"skipped":2216,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:54:57.791: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8192
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Nov 13 10:54:57.916: INFO: PodSpec: initContainers in spec.initContainers
Nov 13 10:55:40.944: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-88fbdb07-ea40-4b46-8a3e-7392a1ce04f8", GenerateName:"", Namespace:"init-container-8192", SelfLink:"/api/v1/namespaces/init-container-8192/pods/pod-init-88fbdb07-ea40-4b46-8a3e-7392a1ce04f8", UID:"e425d3da-4d28-4475-a86b-1b7062b4ffd4", ResourceVersion:"309442", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63740861697, loc:(*time.Location)(0x7925260)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"916200233"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-5q6ng", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0030b5240), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5q6ng", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5q6ng", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5q6ng", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0053981a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"29607307-5497-41cc-a8d5-c2f7d9a90e41", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002e71680), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc005398220)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc005398240)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc005398248), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00539824c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861697, loc:(*time.Location)(0x7925260)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861697, loc:(*time.Location)(0x7925260)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861697, loc:(*time.Location)(0x7925260)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861697, loc:(*time.Location)(0x7925260)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.95.32.12", PodIP:"10.200.5.160", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.200.5.160"}}, StartTime:(*v1.Time)(0xc004f61d80), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002e5e770)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002e5e7e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://912b1a498c0a0c40f4317c005a22cef0e4e89a7388f1a14a6539edb8286b1d01", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004f61dc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004f61da0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0053982cf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:55:40.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8192" for this suite.

• [SLOW TEST:43.160 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":278,"completed":160,"skipped":2225,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:55:40.953: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3084
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-2be89cda-12af-4e23-b75e-e9164d3089e7
STEP: Creating a pod to test consume configMaps
Nov 13 10:55:41.095: INFO: Waiting up to 5m0s for pod "pod-configmaps-486942fe-691d-4a22-baec-5f304686a4a7" in namespace "configmap-3084" to be "success or failure"
Nov 13 10:55:41.100: INFO: Pod "pod-configmaps-486942fe-691d-4a22-baec-5f304686a4a7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.995605ms
Nov 13 10:55:43.102: INFO: Pod "pod-configmaps-486942fe-691d-4a22-baec-5f304686a4a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007505757s
Nov 13 10:55:45.105: INFO: Pod "pod-configmaps-486942fe-691d-4a22-baec-5f304686a4a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009790315s
STEP: Saw pod success
Nov 13 10:55:45.105: INFO: Pod "pod-configmaps-486942fe-691d-4a22-baec-5f304686a4a7" satisfied condition "success or failure"
Nov 13 10:55:45.106: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-configmaps-486942fe-691d-4a22-baec-5f304686a4a7 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 10:55:45.118: INFO: Waiting for pod pod-configmaps-486942fe-691d-4a22-baec-5f304686a4a7 to disappear
Nov 13 10:55:45.124: INFO: Pod pod-configmaps-486942fe-691d-4a22-baec-5f304686a4a7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:55:45.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3084" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":278,"completed":161,"skipped":2237,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:55:45.129: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6920
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:55:45.259: INFO: Waiting up to 5m0s for pod "downwardapi-volume-56f0a8e0-7d16-4fe5-99d9-b0e5ae0528d0" in namespace "projected-6920" to be "success or failure"
Nov 13 10:55:45.267: INFO: Pod "downwardapi-volume-56f0a8e0-7d16-4fe5-99d9-b0e5ae0528d0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.680126ms
Nov 13 10:55:47.268: INFO: Pod "downwardapi-volume-56f0a8e0-7d16-4fe5-99d9-b0e5ae0528d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009510843s
STEP: Saw pod success
Nov 13 10:55:47.269: INFO: Pod "downwardapi-volume-56f0a8e0-7d16-4fe5-99d9-b0e5ae0528d0" satisfied condition "success or failure"
Nov 13 10:55:47.270: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-56f0a8e0-7d16-4fe5-99d9-b0e5ae0528d0 container client-container: <nil>
STEP: delete the pod
Nov 13 10:55:47.280: INFO: Waiting for pod downwardapi-volume-56f0a8e0-7d16-4fe5-99d9-b0e5ae0528d0 to disappear
Nov 13 10:55:47.285: INFO: Pod downwardapi-volume-56f0a8e0-7d16-4fe5-99d9-b0e5ae0528d0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:55:47.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6920" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":278,"completed":162,"skipped":2271,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:55:47.289: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3805
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Nov 13 10:55:49.946: INFO: Successfully updated pod "annotationupdatee145eb2b-7051-4f48-899c-30025ec4a622"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:55:53.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3805" for this suite.

• [SLOW TEST:6.678 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":278,"completed":163,"skipped":2289,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:55:53.970: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3596
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:55:54.095: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7093472-33e8-4c23-affd-16ccaddc312a" in namespace "projected-3596" to be "success or failure"
Nov 13 10:55:54.097: INFO: Pod "downwardapi-volume-a7093472-33e8-4c23-affd-16ccaddc312a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.477508ms
Nov 13 10:55:56.099: INFO: Pod "downwardapi-volume-a7093472-33e8-4c23-affd-16ccaddc312a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004509984s
STEP: Saw pod success
Nov 13 10:55:56.099: INFO: Pod "downwardapi-volume-a7093472-33e8-4c23-affd-16ccaddc312a" satisfied condition "success or failure"
Nov 13 10:55:56.101: INFO: Trying to get logs from node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c pod downwardapi-volume-a7093472-33e8-4c23-affd-16ccaddc312a container client-container: <nil>
STEP: delete the pod
Nov 13 10:55:56.117: INFO: Waiting for pod downwardapi-volume-a7093472-33e8-4c23-affd-16ccaddc312a to disappear
Nov 13 10:55:56.123: INFO: Pod downwardapi-volume-a7093472-33e8-4c23-affd-16ccaddc312a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:55:56.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3596" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":278,"completed":164,"skipped":2374,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:55:56.130: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9636
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:55:56.257: INFO: Waiting up to 5m0s for pod "downwardapi-volume-02623cf5-296a-4908-8662-f6454f198862" in namespace "downward-api-9636" to be "success or failure"
Nov 13 10:55:56.261: INFO: Pod "downwardapi-volume-02623cf5-296a-4908-8662-f6454f198862": Phase="Pending", Reason="", readiness=false. Elapsed: 3.624217ms
Nov 13 10:55:58.263: INFO: Pod "downwardapi-volume-02623cf5-296a-4908-8662-f6454f198862": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005817681s
STEP: Saw pod success
Nov 13 10:55:58.263: INFO: Pod "downwardapi-volume-02623cf5-296a-4908-8662-f6454f198862" satisfied condition "success or failure"
Nov 13 10:55:58.264: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-02623cf5-296a-4908-8662-f6454f198862 container client-container: <nil>
STEP: delete the pod
Nov 13 10:55:58.274: INFO: Waiting for pod downwardapi-volume-02623cf5-296a-4908-8662-f6454f198862 to disappear
Nov 13 10:55:58.279: INFO: Pod downwardapi-volume-02623cf5-296a-4908-8662-f6454f198862 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:55:58.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9636" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":278,"completed":165,"skipped":2440,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:55:58.288: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9076
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Nov 13 10:55:58.413: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:56:01.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9076" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":278,"completed":166,"skipped":2493,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:56:01.511: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6930
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1113 10:56:11.700748      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 13 10:56:11.700: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:56:11.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6930" for this suite.

• [SLOW TEST:10.194 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":278,"completed":167,"skipped":2508,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:56:11.705: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9182
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Nov 13 10:56:11.829: INFO: Waiting up to 5m0s for pod "downward-api-ef753909-1a85-4f09-a0dd-5c27c1316125" in namespace "downward-api-9182" to be "success or failure"
Nov 13 10:56:11.832: INFO: Pod "downward-api-ef753909-1a85-4f09-a0dd-5c27c1316125": Phase="Pending", Reason="", readiness=false. Elapsed: 2.804215ms
Nov 13 10:56:13.834: INFO: Pod "downward-api-ef753909-1a85-4f09-a0dd-5c27c1316125": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004974929s
STEP: Saw pod success
Nov 13 10:56:13.834: INFO: Pod "downward-api-ef753909-1a85-4f09-a0dd-5c27c1316125" satisfied condition "success or failure"
Nov 13 10:56:13.836: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downward-api-ef753909-1a85-4f09-a0dd-5c27c1316125 container dapi-container: <nil>
STEP: delete the pod
Nov 13 10:56:13.845: INFO: Waiting for pod downward-api-ef753909-1a85-4f09-a0dd-5c27c1316125 to disappear
Nov 13 10:56:13.851: INFO: Pod downward-api-ef753909-1a85-4f09-a0dd-5c27c1316125 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:56:13.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9182" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":278,"completed":168,"skipped":2527,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:56:13.855: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8840
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:56:14.515: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 13 10:56:16.519: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861774, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861774, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861774, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861774, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:56:19.528: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:56:19.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8840" for this suite.
STEP: Destroying namespace "webhook-8840-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.839 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":278,"completed":169,"skipped":2533,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:56:19.694: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4578
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:56:45.831: INFO: Container started at 2020-11-13 10:56:20 +0000 UTC, pod became ready at 2020-11-13 10:56:44 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:56:45.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4578" for this suite.

• [SLOW TEST:26.141 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":278,"completed":170,"skipped":2550,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:56:45.835: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1980
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:56:46.443: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 13 10:56:48.448: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861806, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861806, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861806, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861806, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:56:51.455: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:56:51.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1980" for this suite.
STEP: Destroying namespace "webhook-1980-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.657 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":278,"completed":171,"skipped":2564,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:56:51.493: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4957
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov 13 10:56:51.623: INFO: Waiting up to 5m0s for pod "pod-937f8d4c-d2f1-4422-b8e2-535efba38bdc" in namespace "emptydir-4957" to be "success or failure"
Nov 13 10:56:51.633: INFO: Pod "pod-937f8d4c-d2f1-4422-b8e2-535efba38bdc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.286862ms
Nov 13 10:56:53.635: INFO: Pod "pod-937f8d4c-d2f1-4422-b8e2-535efba38bdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010559324s
Nov 13 10:56:55.637: INFO: Pod "pod-937f8d4c-d2f1-4422-b8e2-535efba38bdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012400473s
STEP: Saw pod success
Nov 13 10:56:55.637: INFO: Pod "pod-937f8d4c-d2f1-4422-b8e2-535efba38bdc" satisfied condition "success or failure"
Nov 13 10:56:55.638: INFO: Trying to get logs from node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c pod pod-937f8d4c-d2f1-4422-b8e2-535efba38bdc container test-container: <nil>
STEP: delete the pod
Nov 13 10:56:55.647: INFO: Waiting for pod pod-937f8d4c-d2f1-4422-b8e2-535efba38bdc to disappear
Nov 13 10:56:55.653: INFO: Pod pod-937f8d4c-d2f1-4422-b8e2-535efba38bdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:56:55.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4957" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":172,"skipped":2572,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:56:55.657: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1933
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating Agnhost RC
Nov 13 10:56:55.779: INFO: namespace kubectl-1933
Nov 13 10:56:55.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 create -f - --namespace=kubectl-1933'
Nov 13 10:56:55.962: INFO: stderr: ""
Nov 13 10:56:55.962: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Nov 13 10:56:56.964: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 13 10:56:56.964: INFO: Found 0 / 1
Nov 13 10:56:57.964: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 13 10:56:57.964: INFO: Found 1 / 1
Nov 13 10:56:57.964: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 13 10:56:57.966: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 13 10:56:57.966: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 13 10:56:57.966: INFO: wait on agnhost-master startup in kubectl-1933 
Nov 13 10:56:57.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 logs agnhost-master-qwknz agnhost-master --namespace=kubectl-1933'
Nov 13 10:56:58.017: INFO: stderr: ""
Nov 13 10:56:58.017: INFO: stdout: "Paused\n"
STEP: exposing RC
Nov 13 10:56:58.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1933'
Nov 13 10:56:58.077: INFO: stderr: ""
Nov 13 10:56:58.077: INFO: stdout: "service/rm2 exposed\n"
Nov 13 10:56:58.078: INFO: Service rm2 in namespace kubectl-1933 found.
STEP: exposing service
Nov 13 10:57:00.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1933'
Nov 13 10:57:00.136: INFO: stderr: ""
Nov 13 10:57:00.136: INFO: stdout: "service/rm3 exposed\n"
Nov 13 10:57:00.138: INFO: Service rm3 in namespace kubectl-1933 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:02.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1933" for this suite.

• [SLOW TEST:6.487 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1188
    should create services for rc  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":278,"completed":173,"skipped":2572,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:02.144: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3066
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1626
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 13 10:57:02.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-3066'
Nov 13 10:57:02.314: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 13 10:57:02.314: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1631
Nov 13 10:57:04.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete deployment e2e-test-httpd-deployment --namespace=kubectl-3066'
Nov 13 10:57:04.385: INFO: stderr: ""
Nov 13 10:57:04.385: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:04.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3066" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run deployment should create a deployment from an image  [Conformance]","total":278,"completed":174,"skipped":2591,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:04.392: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8018
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-1321256c-9c27-4a4b-9823-744a7700cd11
STEP: Creating a pod to test consume secrets
Nov 13 10:57:04.533: INFO: Waiting up to 5m0s for pod "pod-secrets-4f30c82a-be38-4bf5-94a7-289c0ea66f8b" in namespace "secrets-8018" to be "success or failure"
Nov 13 10:57:04.545: INFO: Pod "pod-secrets-4f30c82a-be38-4bf5-94a7-289c0ea66f8b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.427103ms
Nov 13 10:57:06.547: INFO: Pod "pod-secrets-4f30c82a-be38-4bf5-94a7-289c0ea66f8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01331899s
STEP: Saw pod success
Nov 13 10:57:06.547: INFO: Pod "pod-secrets-4f30c82a-be38-4bf5-94a7-289c0ea66f8b" satisfied condition "success or failure"
Nov 13 10:57:06.548: INFO: Trying to get logs from node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c pod pod-secrets-4f30c82a-be38-4bf5-94a7-289c0ea66f8b container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 10:57:06.557: INFO: Waiting for pod pod-secrets-4f30c82a-be38-4bf5-94a7-289c0ea66f8b to disappear
Nov 13 10:57:06.562: INFO: Pod pod-secrets-4f30c82a-be38-4bf5-94a7-289c0ea66f8b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:06.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8018" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":278,"completed":175,"skipped":2609,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:06.566: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1487
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 10:57:06.744: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d3abe97c-dd84-4ffe-b6d7-50c981c26ba8" in namespace "downward-api-1487" to be "success or failure"
Nov 13 10:57:06.747: INFO: Pod "downwardapi-volume-d3abe97c-dd84-4ffe-b6d7-50c981c26ba8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.380124ms
Nov 13 10:57:08.749: INFO: Pod "downwardapi-volume-d3abe97c-dd84-4ffe-b6d7-50c981c26ba8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005390368s
STEP: Saw pod success
Nov 13 10:57:08.749: INFO: Pod "downwardapi-volume-d3abe97c-dd84-4ffe-b6d7-50c981c26ba8" satisfied condition "success or failure"
Nov 13 10:57:08.750: INFO: Trying to get logs from node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c pod downwardapi-volume-d3abe97c-dd84-4ffe-b6d7-50c981c26ba8 container client-container: <nil>
STEP: delete the pod
Nov 13 10:57:08.760: INFO: Waiting for pod downwardapi-volume-d3abe97c-dd84-4ffe-b6d7-50c981c26ba8 to disappear
Nov 13 10:57:08.765: INFO: Pod downwardapi-volume-d3abe97c-dd84-4ffe-b6d7-50c981c26ba8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:08.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1487" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":278,"completed":176,"skipped":2679,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:08.770: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7283
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1681
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 13 10:57:08.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-7283'
Nov 13 10:57:08.947: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 13 10:57:08.947: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
Nov 13 10:57:08.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete jobs e2e-test-httpd-job --namespace=kubectl-7283'
Nov 13 10:57:09.011: INFO: stderr: ""
Nov 13 10:57:09.011: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:09.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7283" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run job should create a job from an image when restart is OnFailure  [Conformance]","total":278,"completed":177,"skipped":2699,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:09.021: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5691
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-upd-4b8cc065-a7d7-4498-9bcc-d0e3d139ff8f
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-4b8cc065-a7d7-4498-9bcc-d0e3d139ff8f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:13.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5691" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":278,"completed":178,"skipped":2710,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:13.183: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3963
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:13.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3963" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":278,"completed":179,"skipped":2724,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:13.313: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-282
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov 13 10:57:13.444: INFO: Waiting up to 5m0s for pod "pod-9d9123ee-21bf-4209-a713-d9a1b82e4f9d" in namespace "emptydir-282" to be "success or failure"
Nov 13 10:57:13.447: INFO: Pod "pod-9d9123ee-21bf-4209-a713-d9a1b82e4f9d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.707768ms
Nov 13 10:57:15.461: INFO: Pod "pod-9d9123ee-21bf-4209-a713-d9a1b82e4f9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016903407s
STEP: Saw pod success
Nov 13 10:57:15.461: INFO: Pod "pod-9d9123ee-21bf-4209-a713-d9a1b82e4f9d" satisfied condition "success or failure"
Nov 13 10:57:15.462: INFO: Trying to get logs from node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c pod pod-9d9123ee-21bf-4209-a713-d9a1b82e4f9d container test-container: <nil>
STEP: delete the pod
Nov 13 10:57:15.472: INFO: Waiting for pod pod-9d9123ee-21bf-4209-a713-d9a1b82e4f9d to disappear
Nov 13 10:57:15.476: INFO: Pod pod-9d9123ee-21bf-4209-a713-d9a1b82e4f9d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:15.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-282" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":180,"skipped":2765,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:15.482: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2731
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:57:16.376: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 13 10:57:18.383: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861836, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861836, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861836, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861836, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:57:21.392: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:21.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2731" for this suite.
STEP: Destroying namespace "webhook-2731-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.986 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":278,"completed":181,"skipped":2785,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:21.469: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3314
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1275
STEP: creating the pod
Nov 13 10:57:21.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 create -f - --namespace=kubectl-3314'
Nov 13 10:57:21.719: INFO: stderr: ""
Nov 13 10:57:21.719: INFO: stdout: "pod/pause created\n"
Nov 13 10:57:21.719: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov 13 10:57:21.719: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3314" to be "running and ready"
Nov 13 10:57:21.721: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.662167ms
Nov 13 10:57:23.723: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.004508488s
Nov 13 10:57:23.723: INFO: Pod "pause" satisfied condition "running and ready"
Nov 13 10:57:23.723: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: adding the label testing-label with value testing-label-value to a pod
Nov 13 10:57:23.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 label pods pause testing-label=testing-label-value --namespace=kubectl-3314'
Nov 13 10:57:23.773: INFO: stderr: ""
Nov 13 10:57:23.773: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov 13 10:57:23.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pod pause -L testing-label --namespace=kubectl-3314'
Nov 13 10:57:23.818: INFO: stderr: ""
Nov 13 10:57:23.818: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov 13 10:57:23.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 label pods pause testing-label- --namespace=kubectl-3314'
Nov 13 10:57:23.867: INFO: stderr: ""
Nov 13 10:57:23.867: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov 13 10:57:23.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pod pause -L testing-label --namespace=kubectl-3314'
Nov 13 10:57:23.912: INFO: stderr: ""
Nov 13 10:57:23.912: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1282
STEP: using delete to clean up resources
Nov 13 10:57:23.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete --grace-period=0 --force -f - --namespace=kubectl-3314'
Nov 13 10:57:23.961: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 10:57:23.961: INFO: stdout: "pod \"pause\" force deleted\n"
Nov 13 10:57:23.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get rc,svc -l name=pause --no-headers --namespace=kubectl-3314'
Nov 13 10:57:24.015: INFO: stderr: "No resources found in kubectl-3314 namespace.\n"
Nov 13 10:57:24.015: INFO: stdout: ""
Nov 13 10:57:24.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -l name=pause --namespace=kubectl-3314 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 13 10:57:24.074: INFO: stderr: ""
Nov 13 10:57:24.074: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:24.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3314" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":278,"completed":182,"skipped":2787,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:24.080: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-7510
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:125
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:57:24.524: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Nov 13 10:57:26.534: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861844, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861844, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861844, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861844, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:57:29.553: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:57:29.555: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:30.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7510" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:136

• [SLOW TEST:6.604 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":278,"completed":183,"skipped":2834,"failed":0}
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:30.685: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9791
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9791.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9791.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9791.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9791.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9791.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9791.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 13 10:57:32.848: INFO: DNS probes using dns-9791/dns-test-352a56b1-6bf0-4f91-9d28-7ed46f313ea3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:32.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9791" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":278,"completed":184,"skipped":2834,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:32.864: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-7876
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:57:33.039: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-0da82232-0d0e-4595-bab6-c05f03fe56ed" in namespace "security-context-test-7876" to be "success or failure"
Nov 13 10:57:33.042: INFO: Pod "busybox-privileged-false-0da82232-0d0e-4595-bab6-c05f03fe56ed": Phase="Pending", Reason="", readiness=false. Elapsed: 3.659165ms
Nov 13 10:57:35.044: INFO: Pod "busybox-privileged-false-0da82232-0d0e-4595-bab6-c05f03fe56ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005559622s
Nov 13 10:57:35.044: INFO: Pod "busybox-privileged-false-0da82232-0d0e-4595-bab6-c05f03fe56ed" satisfied condition "success or failure"
Nov 13 10:57:35.048: INFO: Got logs for pod "busybox-privileged-false-0da82232-0d0e-4595-bab6-c05f03fe56ed": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:35.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7876" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":185,"skipped":2841,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:35.054: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1769
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:178
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:35.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1769" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":278,"completed":186,"skipped":2889,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:35.197: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-224
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override all
Nov 13 10:57:35.328: INFO: Waiting up to 5m0s for pod "client-containers-47a3f719-72c9-490a-8c05-f3af1a3f8a62" in namespace "containers-224" to be "success or failure"
Nov 13 10:57:35.340: INFO: Pod "client-containers-47a3f719-72c9-490a-8c05-f3af1a3f8a62": Phase="Pending", Reason="", readiness=false. Elapsed: 12.210617ms
Nov 13 10:57:37.342: INFO: Pod "client-containers-47a3f719-72c9-490a-8c05-f3af1a3f8a62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014261409s
STEP: Saw pod success
Nov 13 10:57:37.342: INFO: Pod "client-containers-47a3f719-72c9-490a-8c05-f3af1a3f8a62" satisfied condition "success or failure"
Nov 13 10:57:37.343: INFO: Trying to get logs from node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c pod client-containers-47a3f719-72c9-490a-8c05-f3af1a3f8a62 container test-container: <nil>
STEP: delete the pod
Nov 13 10:57:37.354: INFO: Waiting for pod client-containers-47a3f719-72c9-490a-8c05-f3af1a3f8a62 to disappear
Nov 13 10:57:37.360: INFO: Pod client-containers-47a3f719-72c9-490a-8c05-f3af1a3f8a62 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:37.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-224" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":278,"completed":187,"skipped":2909,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:37.364: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9432
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:39.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9432" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":278,"completed":188,"skipped":2921,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:39.508: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8724
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:57:39.637: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov 13 10:57:39.643: INFO: Number of nodes with available pods: 0
Nov 13 10:57:39.643: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov 13 10:57:39.653: INFO: Number of nodes with available pods: 0
Nov 13 10:57:39.654: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:57:40.657: INFO: Number of nodes with available pods: 0
Nov 13 10:57:40.657: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:57:41.656: INFO: Number of nodes with available pods: 0
Nov 13 10:57:41.656: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:57:42.656: INFO: Number of nodes with available pods: 1
Nov 13 10:57:42.656: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov 13 10:57:42.673: INFO: Number of nodes with available pods: 0
Nov 13 10:57:42.673: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov 13 10:57:42.688: INFO: Number of nodes with available pods: 0
Nov 13 10:57:42.688: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:57:43.694: INFO: Number of nodes with available pods: 0
Nov 13 10:57:43.694: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:57:44.690: INFO: Number of nodes with available pods: 0
Nov 13 10:57:44.690: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:57:45.690: INFO: Number of nodes with available pods: 0
Nov 13 10:57:45.690: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:57:46.689: INFO: Number of nodes with available pods: 0
Nov 13 10:57:46.690: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:57:47.690: INFO: Number of nodes with available pods: 0
Nov 13 10:57:47.690: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:57:48.689: INFO: Number of nodes with available pods: 0
Nov 13 10:57:48.690: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:57:49.690: INFO: Number of nodes with available pods: 0
Nov 13 10:57:49.690: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:57:50.689: INFO: Number of nodes with available pods: 0
Nov 13 10:57:50.689: INFO: Node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c is running more than one daemon pod
Nov 13 10:57:51.690: INFO: Number of nodes with available pods: 1
Nov 13 10:57:51.690: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8724, will wait for the garbage collector to delete the pods
Nov 13 10:57:51.746: INFO: Deleting DaemonSet.extensions daemon-set took: 3.304111ms
Nov 13 10:57:52.147: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.317251ms
Nov 13 10:57:54.851: INFO: Number of nodes with available pods: 0
Nov 13 10:57:54.851: INFO: Number of running nodes: 0, number of available pods: 0
Nov 13 10:57:54.852: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8724/daemonsets","resourceVersion":"310850"},"items":null}

Nov 13 10:57:54.853: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8724/pods","resourceVersion":"310850"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:57:54.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8724" for this suite.

• [SLOW TEST:15.360 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":278,"completed":189,"skipped":2932,"failed":0}
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:57:54.869: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2614
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-2614
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-2614
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2614
Nov 13 10:57:55.005: INFO: Found 0 stateful pods, waiting for 1
Nov 13 10:58:05.007: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov 13 10:58:05.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-2614 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 13 10:58:05.130: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 13 10:58:05.130: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 13 10:58:05.130: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 13 10:58:05.132: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 13 10:58:15.134: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 10:58:15.134: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 10:58:15.148: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999816s
Nov 13 10:58:16.150: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.991118497s
Nov 13 10:58:17.152: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989223566s
Nov 13 10:58:18.154: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.987317487s
Nov 13 10:58:19.156: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.98535007s
Nov 13 10:58:20.159: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.983062055s
Nov 13 10:58:21.161: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.980761459s
Nov 13 10:58:22.163: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.978760658s
Nov 13 10:58:23.165: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.976682512s
Nov 13 10:58:24.167: INFO: Verifying statefulset ss doesn't scale past 1 for another 974.596081ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2614
Nov 13 10:58:25.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-2614 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 13 10:58:25.285: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 13 10:58:25.285: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 13 10:58:25.285: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 13 10:58:25.287: INFO: Found 1 stateful pods, waiting for 3
Nov 13 10:58:35.289: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:58:35.289: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 10:58:35.289: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov 13 10:58:35.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-2614 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 13 10:58:35.435: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 13 10:58:35.435: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 13 10:58:35.435: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 13 10:58:35.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-2614 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 13 10:58:35.579: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 13 10:58:35.579: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 13 10:58:35.579: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 13 10:58:35.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-2614 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 13 10:58:35.710: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 13 10:58:35.710: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 13 10:58:35.710: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 13 10:58:35.710: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 10:58:35.712: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov 13 10:58:45.715: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 10:58:45.715: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 10:58:45.715: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 10:58:45.723: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999861s
Nov 13 10:58:46.725: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995921004s
Nov 13 10:58:47.727: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993815314s
Nov 13 10:58:48.729: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991582193s
Nov 13 10:58:49.732: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.9893419s
Nov 13 10:58:50.734: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98719956s
Nov 13 10:58:51.736: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.985000224s
Nov 13 10:58:52.738: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.982821393s
Nov 13 10:58:53.740: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.98069077s
Nov 13 10:58:54.742: INFO: Verifying statefulset ss doesn't scale past 3 for another 978.540105ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2614
Nov 13 10:58:55.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-2614 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 13 10:58:55.865: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 13 10:58:55.865: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 13 10:58:55.865: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 13 10:58:55.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-2614 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 13 10:58:55.996: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 13 10:58:55.996: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 13 10:58:55.996: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 13 10:58:55.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-2614 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 13 10:58:56.148: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 13 10:58:56.148: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 13 10:58:56.148: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 13 10:58:56.148: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Nov 13 10:59:16.163: INFO: Deleting all statefulset in ns statefulset-2614
Nov 13 10:59:16.164: INFO: Scaling statefulset ss to 0
Nov 13 10:59:16.169: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 10:59:16.170: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:59:16.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2614" for this suite.

• [SLOW TEST:81.313 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":278,"completed":190,"skipped":2937,"failed":0}
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:59:16.183: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-9915
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:46
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:59:16.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9915" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":278,"completed":191,"skipped":2937,"failed":0}
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:59:16.316: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-174
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Nov 13 10:59:16.490: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:59:19.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-174" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":278,"completed":192,"skipped":2940,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:59:19.701: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Nov 13 10:59:19.824: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 13 10:59:19.829: INFO: Waiting for terminating namespaces to be deleted...
Nov 13 10:59:19.830: INFO: 
Logging pods the kubelet thinks is on node 29607307-5497-41cc-a8d5-c2f7d9a90e41 before test
Nov 13 10:59:19.840: INFO: metrics-server-5df78f85b-kzd6m from kube-system started at 2020-11-12 01:07:27 +0000 UTC (1 container statuses recorded)
Nov 13 10:59:19.840: INFO: 	Container metrics-server ready: true, restart count 0
Nov 13 10:59:19.840: INFO: filebeat-chjmw from kube-system started at 2020-11-12 01:08:33 +0000 UTC (1 container statuses recorded)
Nov 13 10:59:19.840: INFO: 	Container filebeat ready: true, restart count 0
Nov 13 10:59:19.840: INFO: sonobuoy from sonobuoy started at 2020-11-13 09:37:07 +0000 UTC (1 container statuses recorded)
Nov 13 10:59:19.840: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 13 10:59:19.840: INFO: coredns-54b9777bfc-nhhjt from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 10:59:19.840: INFO: 	Container coredns ready: true, restart count 0
Nov 13 10:59:19.840: INFO: sonobuoy-systemd-logs-daemon-set-294e69fb102c4fcf-tncdk from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 10:59:19.840: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 10:59:19.840: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 13 10:59:19.840: INFO: pod-init-2564ac79-3132-490d-98d5-638aba801627 from init-container-174 started at 2020-11-13 10:59:16 +0000 UTC (1 container statuses recorded)
Nov 13 10:59:19.840: INFO: 	Container run1 ready: true, restart count 0
Nov 13 10:59:19.840: INFO: traefik-ingress-controller-v48l8 from traefik-ingress started at 2020-11-12 01:09:03 +0000 UTC (1 container statuses recorded)
Nov 13 10:59:19.840: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov 13 10:59:19.840: INFO: 
Logging pods the kubelet thinks is on node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c before test
Nov 13 10:59:19.853: INFO: sonobuoy-e2e-job-b8fa8fc01c7d4f11 from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 10:59:19.853: INFO: 	Container e2e ready: true, restart count 0
Nov 13 10:59:19.853: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 10:59:19.853: INFO: coredns-54b9777bfc-jj6kl from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 10:59:19.854: INFO: 	Container coredns ready: true, restart count 0
Nov 13 10:59:19.854: INFO: filebeat-zxtp6 from kube-system started at 2020-11-12 01:08:33 +0000 UTC (1 container statuses recorded)
Nov 13 10:59:19.854: INFO: 	Container filebeat ready: true, restart count 0
Nov 13 10:59:19.854: INFO: sonobuoy-systemd-logs-daemon-set-294e69fb102c4fcf-fk6ph from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 10:59:19.854: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 10:59:19.854: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 13 10:59:19.854: INFO: coredns-54b9777bfc-q6tzp from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 10:59:19.854: INFO: 	Container coredns ready: true, restart count 0
Nov 13 10:59:19.854: INFO: traefik-ingress-controller-xbfqn from traefik-ingress started at 2020-11-12 01:09:03 +0000 UTC (1 container statuses recorded)
Nov 13 10:59:19.854: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16470c286a154b77], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:59:20.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-709" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":278,"completed":193,"skipped":2966,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:59:20.906: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8813
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 10:59:21.321: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 13 10:59:23.325: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861961, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861961, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861961, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740861961, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 10:59:26.333: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Nov 13 10:59:28.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 attach --namespace=webhook-8813 to-be-attached-pod -i -c=container1'
Nov 13 10:59:29.028: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:59:29.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8813" for this suite.
STEP: Destroying namespace "webhook-8813-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.158 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":278,"completed":194,"skipped":2985,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:59:29.064: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6135
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 10:59:29.190: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 10:59:30.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6135" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":278,"completed":195,"skipped":2988,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 10:59:30.391: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1700
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:00:30.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1700" for this suite.

• [SLOW TEST:60.133 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":278,"completed":196,"skipped":3006,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:00:30.525: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3938
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name projected-secret-test-a4eb2a93-3f9e-4300-84d0-cbe4d74e1ed1
STEP: Creating a pod to test consume secrets
Nov 13 11:00:30.655: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-674573ab-d9ab-4ffd-a451-8d6d8e73d50b" in namespace "projected-3938" to be "success or failure"
Nov 13 11:00:30.662: INFO: Pod "pod-projected-secrets-674573ab-d9ab-4ffd-a451-8d6d8e73d50b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.548272ms
Nov 13 11:00:32.664: INFO: Pod "pod-projected-secrets-674573ab-d9ab-4ffd-a451-8d6d8e73d50b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009534021s
STEP: Saw pod success
Nov 13 11:00:32.664: INFO: Pod "pod-projected-secrets-674573ab-d9ab-4ffd-a451-8d6d8e73d50b" satisfied condition "success or failure"
Nov 13 11:00:32.665: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-projected-secrets-674573ab-d9ab-4ffd-a451-8d6d8e73d50b container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 11:00:32.675: INFO: Waiting for pod pod-projected-secrets-674573ab-d9ab-4ffd-a451-8d6d8e73d50b to disappear
Nov 13 11:00:32.680: INFO: Pod pod-projected-secrets-674573ab-d9ab-4ffd-a451-8d6d8e73d50b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:00:32.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3938" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":278,"completed":197,"skipped":3011,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:00:32.685: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3960
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service endpoint-test2 in namespace services-3960
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3960 to expose endpoints map[]
Nov 13 11:00:32.815: INFO: successfully validated that service endpoint-test2 in namespace services-3960 exposes endpoints map[] (2.452542ms elapsed)
STEP: Creating pod pod1 in namespace services-3960
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3960 to expose endpoints map[pod1:[80]]
Nov 13 11:00:34.837: INFO: successfully validated that service endpoint-test2 in namespace services-3960 exposes endpoints map[pod1:[80]] (2.017063531s elapsed)
STEP: Creating pod pod2 in namespace services-3960
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3960 to expose endpoints map[pod1:[80] pod2:[80]]
Nov 13 11:00:37.864: INFO: successfully validated that service endpoint-test2 in namespace services-3960 exposes endpoints map[pod1:[80] pod2:[80]] (3.023945424s elapsed)
STEP: Deleting pod pod1 in namespace services-3960
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3960 to expose endpoints map[pod2:[80]]
Nov 13 11:00:37.882: INFO: successfully validated that service endpoint-test2 in namespace services-3960 exposes endpoints map[pod2:[80]] (12.814926ms elapsed)
STEP: Deleting pod pod2 in namespace services-3960
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3960 to expose endpoints map[]
Nov 13 11:00:37.896: INFO: successfully validated that service endpoint-test2 in namespace services-3960 exposes endpoints map[] (6.993831ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:00:37.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3960" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:5.233 seconds]
[sig-network] Services
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":278,"completed":198,"skipped":3019,"failed":0}
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:00:37.922: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5010
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-5010
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating stateful set ss in namespace statefulset-5010
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5010
Nov 13 11:00:38.060: INFO: Found 0 stateful pods, waiting for 1
Nov 13 11:00:48.062: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov 13 11:00:48.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-5010 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 13 11:00:48.196: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 13 11:00:48.196: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 13 11:00:48.196: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 13 11:00:48.198: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 13 11:00:58.200: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 11:00:58.200: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 11:00:58.210: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Nov 13 11:00:58.210: INFO: ss-0  29607307-5497-41cc-a8d5-c2f7d9a90e41  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  }]
Nov 13 11:00:58.210: INFO: ss-1                                        Pending         []
Nov 13 11:00:58.210: INFO: 
Nov 13 11:00:58.210: INFO: StatefulSet ss has not reached scale 3, at 2
Nov 13 11:00:59.212: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995345725s
Nov 13 11:01:00.214: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993198007s
Nov 13 11:01:01.216: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990863628s
Nov 13 11:01:02.219: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.988744611s
Nov 13 11:01:03.221: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.986484383s
Nov 13 11:01:04.223: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.984323446s
Nov 13 11:01:05.225: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.982101135s
Nov 13 11:01:06.228: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.979928365s
Nov 13 11:01:07.230: INFO: Verifying statefulset ss doesn't scale past 3 for another 977.366723ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5010
Nov 13 11:01:08.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-5010 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 13 11:01:08.348: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 13 11:01:08.348: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 13 11:01:08.348: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 13 11:01:08.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-5010 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 13 11:01:08.472: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 13 11:01:08.472: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 13 11:01:08.472: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 13 11:01:08.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-5010 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 13 11:01:08.600: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 13 11:01:08.600: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 13 11:01:08.600: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 13 11:01:08.603: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Nov 13 11:01:18.606: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 11:01:18.606: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 11:01:18.606: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov 13 11:01:18.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-5010 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 13 11:01:18.735: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 13 11:01:18.735: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 13 11:01:18.735: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 13 11:01:18.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-5010 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 13 11:01:18.870: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 13 11:01:18.870: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 13 11:01:18.870: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 13 11:01:18.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-5010 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 13 11:01:18.989: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 13 11:01:18.989: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 13 11:01:18.989: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 13 11:01:18.990: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 11:01:18.992: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Nov 13 11:01:28.996: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 11:01:28.996: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 11:01:28.996: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 13 11:01:29.004: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Nov 13 11:01:29.004: INFO: ss-0  29607307-5497-41cc-a8d5-c2f7d9a90e41  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  }]
Nov 13 11:01:29.004: INFO: ss-1  53f793a7-f5c9-4f32-8dff-29ce2b6c347c  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:29.005: INFO: ss-2  29607307-5497-41cc-a8d5-c2f7d9a90e41  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:29.005: INFO: 
Nov 13 11:01:29.005: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 11:01:30.007: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Nov 13 11:01:30.007: INFO: ss-0  29607307-5497-41cc-a8d5-c2f7d9a90e41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  }]
Nov 13 11:01:30.007: INFO: ss-1  53f793a7-f5c9-4f32-8dff-29ce2b6c347c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:30.007: INFO: ss-2  29607307-5497-41cc-a8d5-c2f7d9a90e41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:30.007: INFO: 
Nov 13 11:01:30.007: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 11:01:31.009: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Nov 13 11:01:31.010: INFO: ss-0  29607307-5497-41cc-a8d5-c2f7d9a90e41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  }]
Nov 13 11:01:31.010: INFO: ss-1  53f793a7-f5c9-4f32-8dff-29ce2b6c347c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:31.010: INFO: ss-2  29607307-5497-41cc-a8d5-c2f7d9a90e41  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:31.010: INFO: 
Nov 13 11:01:31.010: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 11:01:32.012: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Nov 13 11:01:32.012: INFO: ss-0  29607307-5497-41cc-a8d5-c2f7d9a90e41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  }]
Nov 13 11:01:32.012: INFO: ss-1  53f793a7-f5c9-4f32-8dff-29ce2b6c347c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:32.012: INFO: ss-2  29607307-5497-41cc-a8d5-c2f7d9a90e41  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:32.012: INFO: 
Nov 13 11:01:32.012: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 11:01:33.015: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Nov 13 11:01:33.015: INFO: ss-0  29607307-5497-41cc-a8d5-c2f7d9a90e41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  }]
Nov 13 11:01:33.015: INFO: ss-1  53f793a7-f5c9-4f32-8dff-29ce2b6c347c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:33.015: INFO: ss-2  29607307-5497-41cc-a8d5-c2f7d9a90e41  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:33.015: INFO: 
Nov 13 11:01:33.015: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 11:01:34.017: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Nov 13 11:01:34.017: INFO: ss-0  29607307-5497-41cc-a8d5-c2f7d9a90e41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  }]
Nov 13 11:01:34.017: INFO: ss-1  53f793a7-f5c9-4f32-8dff-29ce2b6c347c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:34.017: INFO: ss-2  29607307-5497-41cc-a8d5-c2f7d9a90e41  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:34.017: INFO: 
Nov 13 11:01:34.017: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 11:01:35.020: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Nov 13 11:01:35.020: INFO: ss-0  29607307-5497-41cc-a8d5-c2f7d9a90e41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  }]
Nov 13 11:01:35.020: INFO: ss-1  53f793a7-f5c9-4f32-8dff-29ce2b6c347c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:35.020: INFO: ss-2  29607307-5497-41cc-a8d5-c2f7d9a90e41  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:35.021: INFO: 
Nov 13 11:01:35.021: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 11:01:36.023: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Nov 13 11:01:36.023: INFO: ss-0  29607307-5497-41cc-a8d5-c2f7d9a90e41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  }]
Nov 13 11:01:36.023: INFO: ss-1  53f793a7-f5c9-4f32-8dff-29ce2b6c347c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:36.024: INFO: ss-2  29607307-5497-41cc-a8d5-c2f7d9a90e41  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:36.024: INFO: 
Nov 13 11:01:36.024: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 11:01:37.026: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Nov 13 11:01:37.026: INFO: ss-0  29607307-5497-41cc-a8d5-c2f7d9a90e41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:38 +0000 UTC  }]
Nov 13 11:01:37.026: INFO: ss-1  53f793a7-f5c9-4f32-8dff-29ce2b6c347c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:37.026: INFO: ss-2  29607307-5497-41cc-a8d5-c2f7d9a90e41  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:37.026: INFO: 
Nov 13 11:01:37.026: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 13 11:01:38.028: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Nov 13 11:01:38.028: INFO: ss-1  53f793a7-f5c9-4f32-8dff-29ce2b6c347c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:01:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-13 11:00:58 +0000 UTC  }]
Nov 13 11:01:38.028: INFO: 
Nov 13 11:01:38.028: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5010
Nov 13 11:01:39.030: INFO: Scaling statefulset ss to 0
Nov 13 11:01:39.034: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Nov 13 11:01:39.035: INFO: Deleting all statefulset in ns statefulset-5010
Nov 13 11:01:39.036: INFO: Scaling statefulset ss to 0
Nov 13 11:01:39.040: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 11:01:39.041: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:01:39.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5010" for this suite.

• [SLOW TEST:61.130 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":278,"completed":199,"skipped":3026,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:01:39.053: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-7090
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov 13 11:01:41.196: INFO: &Pod{ObjectMeta:{send-events-4fb8b967-9a88-4159-b53d-116bec552dc1  events-7090 /api/v1/namespaces/events-7090/pods/send-events-4fb8b967-9a88-4159-b53d-116bec552dc1 1f3e8f9e-225f-4543-8188-caffaf4597f6 312062 0 2020-11-13 11:01:39 +0000 UTC <nil> <nil> map[name:foo time:179295694] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qn9ff,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qn9ff,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qn9ff,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:01:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:01:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:01:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:01:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:10.200.5.190,StartTime:2020-11-13 11:01:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-13 11:01:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5,ContainerID:docker://d571d13e313916890c89654028f863c0b6292a0e8ec7b41c12cb708eaf0a2390,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.5.190,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Nov 13 11:01:43.198: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov 13 11:01:45.200: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:01:45.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7090" for this suite.

• [SLOW TEST:6.160 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":278,"completed":200,"skipped":3035,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:01:45.213: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8790
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Nov 13 11:01:45.336: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 11:01:47.520: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:01:56.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8790" for this suite.

• [SLOW TEST:11.766 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":278,"completed":201,"skipped":3043,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:01:56.981: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-440
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:02:13.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-440" for this suite.

• [SLOW TEST:16.150 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":278,"completed":202,"skipped":3044,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:02:13.132: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename lease-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in lease-test-8945
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:02:13.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-8945" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":278,"completed":203,"skipped":3052,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:02:13.282: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1338
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 11:02:13.408: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0153c62d-841b-42dd-9055-d626afb766b7" in namespace "downward-api-1338" to be "success or failure"
Nov 13 11:02:13.415: INFO: Pod "downwardapi-volume-0153c62d-841b-42dd-9055-d626afb766b7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.665933ms
Nov 13 11:02:15.418: INFO: Pod "downwardapi-volume-0153c62d-841b-42dd-9055-d626afb766b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009701442s
STEP: Saw pod success
Nov 13 11:02:15.418: INFO: Pod "downwardapi-volume-0153c62d-841b-42dd-9055-d626afb766b7" satisfied condition "success or failure"
Nov 13 11:02:15.419: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-0153c62d-841b-42dd-9055-d626afb766b7 container client-container: <nil>
STEP: delete the pod
Nov 13 11:02:15.431: INFO: Waiting for pod downwardapi-volume-0153c62d-841b-42dd-9055-d626afb766b7 to disappear
Nov 13 11:02:15.436: INFO: Pod downwardapi-volume-0153c62d-841b-42dd-9055-d626afb766b7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:02:15.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1338" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":204,"skipped":3072,"failed":0}
SSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:02:15.441: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9300
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:02:17.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9300" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":205,"skipped":3075,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:02:17.585: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8073
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating secret secrets-8073/secret-test-7a85e8b3-421d-4c38-bfdf-cd840710010f
STEP: Creating a pod to test consume secrets
Nov 13 11:02:17.713: INFO: Waiting up to 5m0s for pod "pod-configmaps-250e8d3d-f3fb-4b4f-abcc-13529e0ff8bf" in namespace "secrets-8073" to be "success or failure"
Nov 13 11:02:17.716: INFO: Pod "pod-configmaps-250e8d3d-f3fb-4b4f-abcc-13529e0ff8bf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.43943ms
Nov 13 11:02:19.718: INFO: Pod "pod-configmaps-250e8d3d-f3fb-4b4f-abcc-13529e0ff8bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005452613s
STEP: Saw pod success
Nov 13 11:02:19.719: INFO: Pod "pod-configmaps-250e8d3d-f3fb-4b4f-abcc-13529e0ff8bf" satisfied condition "success or failure"
Nov 13 11:02:19.720: INFO: Trying to get logs from node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c pod pod-configmaps-250e8d3d-f3fb-4b4f-abcc-13529e0ff8bf container env-test: <nil>
STEP: delete the pod
Nov 13 11:02:19.735: INFO: Waiting for pod pod-configmaps-250e8d3d-f3fb-4b4f-abcc-13529e0ff8bf to disappear
Nov 13 11:02:19.741: INFO: Pod pod-configmaps-250e8d3d-f3fb-4b4f-abcc-13529e0ff8bf no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:02:19.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8073" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":278,"completed":206,"skipped":3087,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:02:19.746: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1634
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:02:31.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1634" for this suite.

• [SLOW TEST:11.399 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":278,"completed":207,"skipped":3104,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:02:31.145: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8531
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Nov 13 11:02:31.332: INFO: Waiting up to 5m0s for pod "downward-api-5fbdfa7b-a5f3-4159-b892-d01a60aa4883" in namespace "downward-api-8531" to be "success or failure"
Nov 13 11:02:31.338: INFO: Pod "downward-api-5fbdfa7b-a5f3-4159-b892-d01a60aa4883": Phase="Pending", Reason="", readiness=false. Elapsed: 5.366364ms
Nov 13 11:02:33.340: INFO: Pod "downward-api-5fbdfa7b-a5f3-4159-b892-d01a60aa4883": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007555767s
STEP: Saw pod success
Nov 13 11:02:33.340: INFO: Pod "downward-api-5fbdfa7b-a5f3-4159-b892-d01a60aa4883" satisfied condition "success or failure"
Nov 13 11:02:33.342: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downward-api-5fbdfa7b-a5f3-4159-b892-d01a60aa4883 container dapi-container: <nil>
STEP: delete the pod
Nov 13 11:02:33.352: INFO: Waiting for pod downward-api-5fbdfa7b-a5f3-4159-b892-d01a60aa4883 to disappear
Nov 13 11:02:33.354: INFO: Pod downward-api-5fbdfa7b-a5f3-4159-b892-d01a60aa4883 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:02:33.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8531" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":278,"completed":208,"skipped":3126,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:02:33.359: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5802
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 11:02:33.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 create -f - --namespace=kubectl-5802'
Nov 13 11:02:33.640: INFO: stderr: ""
Nov 13 11:02:33.640: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Nov 13 11:02:33.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 create -f - --namespace=kubectl-5802'
Nov 13 11:02:33.750: INFO: stderr: ""
Nov 13 11:02:33.750: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Nov 13 11:02:34.752: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 13 11:02:34.752: INFO: Found 0 / 1
Nov 13 11:02:35.753: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 13 11:02:35.753: INFO: Found 1 / 1
Nov 13 11:02:35.753: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 13 11:02:35.755: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 13 11:02:35.755: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 13 11:02:35.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 describe pod agnhost-master-dvkb8 --namespace=kubectl-5802'
Nov 13 11:02:35.834: INFO: stderr: ""
Nov 13 11:02:35.834: INFO: stdout: "Name:         agnhost-master-dvkb8\nNamespace:    kubectl-5802\nPriority:     0\nNode:         29607307-5497-41cc-a8d5-c2f7d9a90e41/10.95.32.12\nStart Time:   Fri, 13 Nov 2020 11:02:33 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.200.5.196\nIPs:\n  IP:           10.200.5.196\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://a6fde021aa7a8d551eb454b53120622bdf47a0eeb4a3caec191954ea8931d9f7\n    Image:          gcr.io/kubernetes-e2e-test-images/agnhost:2.8\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 13 Nov 2020 11:02:34 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-6wg49 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-6wg49:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-6wg49\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                           Message\n  ----    ------     ----  ----                                           -------\n  Normal  Scheduled  2s    default-scheduler                              Successfully assigned kubectl-5802/agnhost-master-dvkb8 to 29607307-5497-41cc-a8d5-c2f7d9a90e41\n  Normal  Pulled     1s    kubelet, 29607307-5497-41cc-a8d5-c2f7d9a90e41  Container image \"gcr.io/kubernetes-e2e-test-images/agnhost:2.8\" already present on machine\n  Normal  Created    1s    kubelet, 29607307-5497-41cc-a8d5-c2f7d9a90e41  Created container agnhost-master\n  Normal  Started    1s    kubelet, 29607307-5497-41cc-a8d5-c2f7d9a90e41  Started container agnhost-master\n"
Nov 13 11:02:35.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 describe rc agnhost-master --namespace=kubectl-5802'
Nov 13 11:02:35.912: INFO: stderr: ""
Nov 13 11:02:35.912: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-5802\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/agnhost:2.8\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-master-dvkb8\n"
Nov 13 11:02:35.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 describe service agnhost-master --namespace=kubectl-5802'
Nov 13 11:02:35.972: INFO: stderr: ""
Nov 13 11:02:35.972: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-5802\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                10.100.200.64\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.200.5.196:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov 13 11:02:35.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 describe node 29607307-5497-41cc-a8d5-c2f7d9a90e41'
Nov 13 11:02:36.042: INFO: stderr: ""
Nov 13 11:02:36.042: INFO: stdout: "Name:               29607307-5497-41cc-a8d5-c2f7d9a90e41\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    bosh.id=3db05f74-ed15-4c2b-97a4-502c293a72f6\n                    bosh.zone=z1\n                    failure-domain.beta.kubernetes.io/zone=z1\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.95.32.12\n                    kubernetes.io/os=linux\n                    spec.ip=10.95.32.12\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 12 Nov 2020 00:59:57 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  29607307-5497-41cc-a8d5-c2f7d9a90e41\n  AcquireTime:     <unset>\n  RenewTime:       Fri, 13 Nov 2020 11:02:27 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 13 Nov 2020 10:58:44 +0000   Thu, 12 Nov 2020 00:59:57 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 13 Nov 2020 10:58:44 +0000   Thu, 12 Nov 2020 00:59:57 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 13 Nov 2020 10:58:44 +0000   Thu, 12 Nov 2020 00:59:57 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 13 Nov 2020 10:58:44 +0000   Thu, 12 Nov 2020 01:00:07 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  ExternalIP:  10.95.32.12\n  InternalIP:  10.95.32.12\n  Hostname:    10.95.32.12\nCapacity:\n  cpu:                2\n  ephemeral-storage:  95038284Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8168504Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  87587282390\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8066104Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ba77a445b12e98e05a7e79770952ad20\n  System UUID:                422D8448-BE86-5286-3C15-2FA79407B009\n  Boot ID:                    6e8c61d8-42d2-4f46-b3d2-45f366993b0a\n  Kernel Version:             4.15.0-106-generic\n  OS Image:                   Ubuntu 16.04.6 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://18.9.9\n  Kubelet Version:            v1.17.9\n  Kube-Proxy Version:         v1.17.9\nProviderID:                   vsphere://422d8448-be86-5286-3c15-2fa79407b009\nNon-terminated Pods:          (8 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-54b9777bfc-nhhjt                                   100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     33h\n  kube-system                 filebeat-chjmw                                             200m (10%)    0 (0%)      200Mi (2%)       400Mi (5%)     33h\n  kube-system                 metrics-server-5df78f85b-kzd6m                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         33h\n  kubectl-5802                agnhost-master-dvkb8                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  kubelet-test-9300           busybox-readonly-fs5b53410f-c358-41af-a908-91024253c314    0 (0%)        0 (0%)      0 (0%)           0 (0%)         21s\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         85m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-294e69fb102c4fcf-tncdk    0 (0%)        0 (0%)      0 (0%)           0 (0%)         43m\n  traefik-ingress             traefik-ingress-controller-v48l8                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         33h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                300m (15%)  0 (0%)\n  memory             270Mi (3%)  570Mi (7%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Nov 13 11:02:36.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 describe namespace kubectl-5802'
Nov 13 11:02:36.093: INFO: stderr: ""
Nov 13 11:02:36.093: INFO: stdout: "Name:         kubectl-5802\nLabels:       e2e-framework=kubectl\n              e2e-run=3e525414-31f7-47c2-b550-1ec4879dbf9e\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:02:36.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5802" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":278,"completed":209,"skipped":3131,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:02:36.097: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5405
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating pod
Nov 13 11:02:38.241: INFO: Pod pod-hostip-f6e21e8c-709f-4dfd-a573-47eca7314dcd has hostIP: 10.95.32.13
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:02:38.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5405" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":278,"completed":210,"skipped":3150,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:02:38.245: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6353
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-5252
STEP: Creating secret with name secret-test-c0a37280-b73b-4f38-b2e5-4fc8acf0c5c1
STEP: Creating a pod to test consume secrets
Nov 13 11:02:38.513: INFO: Waiting up to 5m0s for pod "pod-secrets-a5efc062-bc23-4856-8b9d-26b868492770" in namespace "secrets-6353" to be "success or failure"
Nov 13 11:02:38.523: INFO: Pod "pod-secrets-a5efc062-bc23-4856-8b9d-26b868492770": Phase="Pending", Reason="", readiness=false. Elapsed: 9.763582ms
Nov 13 11:02:40.525: INFO: Pod "pod-secrets-a5efc062-bc23-4856-8b9d-26b868492770": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011715971s
STEP: Saw pod success
Nov 13 11:02:40.525: INFO: Pod "pod-secrets-a5efc062-bc23-4856-8b9d-26b868492770" satisfied condition "success or failure"
Nov 13 11:02:40.526: INFO: Trying to get logs from node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c pod pod-secrets-a5efc062-bc23-4856-8b9d-26b868492770 container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 11:02:40.536: INFO: Waiting for pod pod-secrets-a5efc062-bc23-4856-8b9d-26b868492770 to disappear
Nov 13 11:02:40.541: INFO: Pod pod-secrets-a5efc062-bc23-4856-8b9d-26b868492770 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:02:40.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6353" for this suite.
STEP: Destroying namespace "secret-namespace-5252" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":278,"completed":211,"skipped":3175,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:02:40.552: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5729
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Nov 13 11:03:10.705: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1113 11:03:10.705696      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:03:10.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5729" for this suite.

• [SLOW TEST:30.158 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":278,"completed":212,"skipped":3193,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:03:10.711: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3854
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:03:26.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3854" for this suite.

• [SLOW TEST:16.178 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":278,"completed":213,"skipped":3236,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:03:26.890: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4631
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-secret-vrk7
STEP: Creating a pod to test atomic-volume-subpath
Nov 13 11:03:27.021: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-vrk7" in namespace "subpath-4631" to be "success or failure"
Nov 13 11:03:27.030: INFO: Pod "pod-subpath-test-secret-vrk7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.792083ms
Nov 13 11:03:29.032: INFO: Pod "pod-subpath-test-secret-vrk7": Phase="Running", Reason="", readiness=true. Elapsed: 2.010546961s
Nov 13 11:03:31.034: INFO: Pod "pod-subpath-test-secret-vrk7": Phase="Running", Reason="", readiness=true. Elapsed: 4.012644765s
Nov 13 11:03:33.036: INFO: Pod "pod-subpath-test-secret-vrk7": Phase="Running", Reason="", readiness=true. Elapsed: 6.014616434s
Nov 13 11:03:35.038: INFO: Pod "pod-subpath-test-secret-vrk7": Phase="Running", Reason="", readiness=true. Elapsed: 8.016566391s
Nov 13 11:03:37.040: INFO: Pod "pod-subpath-test-secret-vrk7": Phase="Running", Reason="", readiness=true. Elapsed: 10.018653352s
Nov 13 11:03:39.043: INFO: Pod "pod-subpath-test-secret-vrk7": Phase="Running", Reason="", readiness=true. Elapsed: 12.021721196s
Nov 13 11:03:41.045: INFO: Pod "pod-subpath-test-secret-vrk7": Phase="Running", Reason="", readiness=true. Elapsed: 14.023700322s
Nov 13 11:03:43.047: INFO: Pod "pod-subpath-test-secret-vrk7": Phase="Running", Reason="", readiness=true. Elapsed: 16.025630552s
Nov 13 11:03:45.049: INFO: Pod "pod-subpath-test-secret-vrk7": Phase="Running", Reason="", readiness=true. Elapsed: 18.027995985s
Nov 13 11:03:47.052: INFO: Pod "pod-subpath-test-secret-vrk7": Phase="Running", Reason="", readiness=true. Elapsed: 20.030467669s
Nov 13 11:03:49.054: INFO: Pod "pod-subpath-test-secret-vrk7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.033138065s
STEP: Saw pod success
Nov 13 11:03:49.054: INFO: Pod "pod-subpath-test-secret-vrk7" satisfied condition "success or failure"
Nov 13 11:03:49.055: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-subpath-test-secret-vrk7 container test-container-subpath-secret-vrk7: <nil>
STEP: delete the pod
Nov 13 11:03:49.065: INFO: Waiting for pod pod-subpath-test-secret-vrk7 to disappear
Nov 13 11:03:49.071: INFO: Pod pod-subpath-test-secret-vrk7 no longer exists
STEP: Deleting pod pod-subpath-test-secret-vrk7
Nov 13 11:03:49.071: INFO: Deleting pod "pod-subpath-test-secret-vrk7" in namespace "subpath-4631"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:03:49.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4631" for this suite.

• [SLOW TEST:22.188 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":278,"completed":214,"skipped":3253,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:03:49.078: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-591
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Nov 13 11:03:52.224: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:03:52.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-591" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":278,"completed":215,"skipped":3265,"failed":0}

------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:03:52.259: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5039
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1113 11:03:58.411889      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 13 11:03:58.411: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:03:58.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5039" for this suite.

• [SLOW TEST:6.156 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":278,"completed":216,"skipped":3265,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:03:58.416: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8218
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8218
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-8218
I1113 11:03:58.562724      20 runners.go:189] Created replication controller with name: externalname-service, namespace: services-8218, replica count: 2
I1113 11:04:01.613149      20 runners.go:189] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1113 11:04:04.613367      20 runners.go:189] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 13 11:04:04.613: INFO: Creating new exec pod
Nov 13 11:04:07.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-8218 execpodb2r8g -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov 13 11:04:07.770: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 13 11:04:07.770: INFO: stdout: ""
Nov 13 11:04:07.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-8218 execpodb2r8g -- /bin/sh -x -c nc -zv -t -w 2 10.100.200.239 80'
Nov 13 11:04:07.912: INFO: stderr: "+ nc -zv -t -w 2 10.100.200.239 80\nConnection to 10.100.200.239 80 port [tcp/http] succeeded!\n"
Nov 13 11:04:07.912: INFO: stdout: ""
Nov 13 11:04:07.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-8218 execpodb2r8g -- /bin/sh -x -c nc -zv -t -w 2 10.95.32.12 32180'
Nov 13 11:04:08.045: INFO: stderr: "+ nc -zv -t -w 2 10.95.32.12 32180\nConnection to 10.95.32.12 32180 port [tcp/32180] succeeded!\n"
Nov 13 11:04:08.045: INFO: stdout: ""
Nov 13 11:04:08.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-8218 execpodb2r8g -- /bin/sh -x -c nc -zv -t -w 2 10.95.32.13 32180'
Nov 13 11:04:08.170: INFO: stderr: "+ nc -zv -t -w 2 10.95.32.13 32180\nConnection to 10.95.32.13 32180 port [tcp/32180] succeeded!\n"
Nov 13 11:04:08.170: INFO: stdout: ""
Nov 13 11:04:08.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-8218 execpodb2r8g -- /bin/sh -x -c nc -zv -t -w 2 10.95.32.12 32180'
Nov 13 11:04:08.301: INFO: stderr: "+ nc -zv -t -w 2 10.95.32.12 32180\nConnection to 10.95.32.12 32180 port [tcp/32180] succeeded!\n"
Nov 13 11:04:08.301: INFO: stdout: ""
Nov 13 11:04:08.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-8218 execpodb2r8g -- /bin/sh -x -c nc -zv -t -w 2 10.95.32.13 32180'
Nov 13 11:04:08.432: INFO: stderr: "+ nc -zv -t -w 2 10.95.32.13 32180\nConnection to 10.95.32.13 32180 port [tcp/32180] succeeded!\n"
Nov 13 11:04:08.432: INFO: stdout: ""
Nov 13 11:04:08.432: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:04:08.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8218" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:10.032 seconds]
[sig-network] Services
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":278,"completed":217,"skipped":3280,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:04:08.449: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7369
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1790
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 13 11:04:08.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-7369'
Nov 13 11:04:08.638: INFO: stderr: ""
Nov 13 11:04:08.638: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Nov 13 11:04:13.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pod e2e-test-httpd-pod --namespace=kubectl-7369 -o json'
Nov 13 11:04:13.755: INFO: stderr: ""
Nov 13 11:04:13.755: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-11-13T11:04:08Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-7369\",\n        \"resourceVersion\": \"313431\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7369/pods/e2e-test-httpd-pod\",\n        \"uid\": \"264ff1d2-1950-4dbf-b481-6aa4a2b99d21\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-scbdg\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"29607307-5497-41cc-a8d5-c2f7d9a90e41\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-scbdg\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-scbdg\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-11-13T11:04:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-11-13T11:04:09Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-11-13T11:04:09Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-11-13T11:04:08Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://22702cce25c700a1709b617853a8833e9e808749cc148ca1fce936335abb15c5\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-11-13T11:04:09Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.95.32.12\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.200.5.209\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.200.5.209\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-11-13T11:04:08Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov 13 11:04:13.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 replace -f - --namespace=kubectl-7369'
Nov 13 11:04:13.903: INFO: stderr: ""
Nov 13 11:04:13.903: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1795
Nov 13 11:04:13.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete pods e2e-test-httpd-pod --namespace=kubectl-7369'
Nov 13 11:04:27.432: INFO: stderr: ""
Nov 13 11:04:27.432: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:04:27.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7369" for this suite.

• [SLOW TEST:18.991 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1786
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":278,"completed":218,"skipped":3313,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:04:27.440: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8957
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Nov 13 11:04:27.567: INFO: Waiting up to 5m0s for pod "downward-api-4d4e0181-9940-4a06-ad5b-52d52364dd12" in namespace "downward-api-8957" to be "success or failure"
Nov 13 11:04:27.571: INFO: Pod "downward-api-4d4e0181-9940-4a06-ad5b-52d52364dd12": Phase="Pending", Reason="", readiness=false. Elapsed: 3.605614ms
Nov 13 11:04:29.573: INFO: Pod "downward-api-4d4e0181-9940-4a06-ad5b-52d52364dd12": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005544665s
STEP: Saw pod success
Nov 13 11:04:29.573: INFO: Pod "downward-api-4d4e0181-9940-4a06-ad5b-52d52364dd12" satisfied condition "success or failure"
Nov 13 11:04:29.574: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downward-api-4d4e0181-9940-4a06-ad5b-52d52364dd12 container dapi-container: <nil>
STEP: delete the pod
Nov 13 11:04:29.584: INFO: Waiting for pod downward-api-4d4e0181-9940-4a06-ad5b-52d52364dd12 to disappear
Nov 13 11:04:29.590: INFO: Pod downward-api-4d4e0181-9940-4a06-ad5b-52d52364dd12 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:04:29.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8957" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":278,"completed":219,"skipped":3332,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:04:29.595: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4778
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 11:04:29.771: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov 13 11:04:31.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-4778 create -f -'
Nov 13 11:04:32.715: INFO: stderr: ""
Nov 13 11:04:32.715: INFO: stdout: "e2e-test-crd-publish-openapi-4698-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov 13 11:04:32.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-4778 delete e2e-test-crd-publish-openapi-4698-crds test-cr'
Nov 13 11:04:32.768: INFO: stderr: ""
Nov 13 11:04:32.768: INFO: stdout: "e2e-test-crd-publish-openapi-4698-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Nov 13 11:04:32.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-4778 apply -f -'
Nov 13 11:04:32.876: INFO: stderr: ""
Nov 13 11:04:32.876: INFO: stdout: "e2e-test-crd-publish-openapi-4698-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov 13 11:04:32.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=crd-publish-openapi-4778 delete e2e-test-crd-publish-openapi-4698-crds test-cr'
Nov 13 11:04:32.927: INFO: stderr: ""
Nov 13 11:04:32.927: INFO: stdout: "e2e-test-crd-publish-openapi-4698-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov 13 11:04:32.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 explain e2e-test-crd-publish-openapi-4698-crds'
Nov 13 11:04:33.027: INFO: stderr: ""
Nov 13 11:04:33.027: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4698-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:04:35.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4778" for this suite.

• [SLOW TEST:6.067 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":278,"completed":220,"skipped":3356,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:04:35.663: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-3650
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:125
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov 13 11:04:36.041: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 11:04:39.050: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 11:04:39.052: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:04:40.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3650" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:136

• [SLOW TEST:5.036 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":278,"completed":221,"skipped":3400,"failed":0}
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:04:40.699: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5101
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting the proxy server
Nov 13 11:04:40.851: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-258392779 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:04:40.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5101" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":278,"completed":222,"skipped":3408,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:04:40.899: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1620
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override arguments
Nov 13 11:04:41.025: INFO: Waiting up to 5m0s for pod "client-containers-f2eb2053-3a7c-4612-9a17-889bc565fd07" in namespace "containers-1620" to be "success or failure"
Nov 13 11:04:41.029: INFO: Pod "client-containers-f2eb2053-3a7c-4612-9a17-889bc565fd07": Phase="Pending", Reason="", readiness=false. Elapsed: 4.07493ms
Nov 13 11:04:43.032: INFO: Pod "client-containers-f2eb2053-3a7c-4612-9a17-889bc565fd07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006731395s
STEP: Saw pod success
Nov 13 11:04:43.032: INFO: Pod "client-containers-f2eb2053-3a7c-4612-9a17-889bc565fd07" satisfied condition "success or failure"
Nov 13 11:04:43.033: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod client-containers-f2eb2053-3a7c-4612-9a17-889bc565fd07 container test-container: <nil>
STEP: delete the pod
Nov 13 11:04:43.045: INFO: Waiting for pod client-containers-f2eb2053-3a7c-4612-9a17-889bc565fd07 to disappear
Nov 13 11:04:43.051: INFO: Pod client-containers-f2eb2053-3a7c-4612-9a17-889bc565fd07 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:04:43.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1620" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":278,"completed":223,"skipped":3424,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:04:43.057: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9090
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-projected-all-test-volume-bd7717ee-affd-4393-8a4d-5e3b74ac6057
STEP: Creating secret with name secret-projected-all-test-volume-6acce908-535b-4e21-936a-dbbff68f10e9
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov 13 11:04:43.184: INFO: Waiting up to 5m0s for pod "projected-volume-c810258b-8665-49d9-865e-567951e4777b" in namespace "projected-9090" to be "success or failure"
Nov 13 11:04:43.188: INFO: Pod "projected-volume-c810258b-8665-49d9-865e-567951e4777b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.513155ms
Nov 13 11:04:45.190: INFO: Pod "projected-volume-c810258b-8665-49d9-865e-567951e4777b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005502613s
STEP: Saw pod success
Nov 13 11:04:45.190: INFO: Pod "projected-volume-c810258b-8665-49d9-865e-567951e4777b" satisfied condition "success or failure"
Nov 13 11:04:45.191: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod projected-volume-c810258b-8665-49d9-865e-567951e4777b container projected-all-volume-test: <nil>
STEP: delete the pod
Nov 13 11:04:45.201: INFO: Waiting for pod projected-volume-c810258b-8665-49d9-865e-567951e4777b to disappear
Nov 13 11:04:45.203: INFO: Pod projected-volume-c810258b-8665-49d9-865e-567951e4777b no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:04:45.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9090" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":278,"completed":224,"skipped":3471,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:04:45.209: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9409
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:05:01.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9409" for this suite.

• [SLOW TEST:16.177 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":278,"completed":225,"skipped":3494,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:05:01.386: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5528
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name secret-emptykey-test-2faf1e79-d325-4fcb-87d6-55002b65feb4
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:05:01.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5528" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":278,"completed":226,"skipped":3517,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:05:01.522: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4222
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name s-test-opt-del-c52d09da-66a3-439d-9a2b-b5bc3bfaf263
STEP: Creating secret with name s-test-opt-upd-d6b79456-f163-4b71-8c2a-3de120c51dbf
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c52d09da-66a3-439d-9a2b-b5bc3bfaf263
STEP: Updating secret s-test-opt-upd-d6b79456-f163-4b71-8c2a-3de120c51dbf
STEP: Creating secret with name s-test-opt-create-467e22a1-7de6-440e-863f-093dbe52ecd6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:05:05.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4222" for this suite.
•{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":278,"completed":227,"skipped":3583,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:05:05.715: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2755
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 11:05:05.840: INFO: Creating deployment "test-recreate-deployment"
Nov 13 11:05:05.843: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov 13 11:05:05.855: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Nov 13 11:05:07.859: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov 13 11:05:07.860: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov 13 11:05:07.863: INFO: Updating deployment test-recreate-deployment
Nov 13 11:05:07.863: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Nov 13 11:05:07.940: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2755 /apis/apps/v1/namespaces/deployment-2755/deployments/test-recreate-deployment 649e1db4-8d4f-4d9a-b438-1b5c2ffb555d 313936 2 2020-11-13 11:05:05 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004538d18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-11-13 11:05:07 +0000 UTC,LastTransitionTime:2020-11-13 11:05:07 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-11-13 11:05:07 +0000 UTC,LastTransitionTime:2020-11-13 11:05:05 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Nov 13 11:05:07.943: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-2755 /apis/apps/v1/namespaces/deployment-2755/replicasets/test-recreate-deployment-5f94c574ff ef3c07b5-7d69-4d92-81ae-785b579e2554 313935 1 2020-11-13 11:05:07 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 649e1db4-8d4f-4d9a-b438-1b5c2ffb555d 0xc004565ea7 0xc004565ea8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004565f18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 13 11:05:07.943: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov 13 11:05:07.943: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-799c574856  deployment-2755 /apis/apps/v1/namespaces/deployment-2755/replicasets/test-recreate-deployment-799c574856 c557d1ab-d878-457a-98a4-690bb15b9dcd 313925 2 2020-11-13 11:05:05 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:799c574856] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 649e1db4-8d4f-4d9a-b438-1b5c2ffb555d 0xc004565fc7 0xc004565fc8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 799c574856,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:799c574856] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00450a038 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 13 11:05:07.944: INFO: Pod "test-recreate-deployment-5f94c574ff-b2bgk" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-b2bgk test-recreate-deployment-5f94c574ff- deployment-2755 /api/v1/namespaces/deployment-2755/pods/test-recreate-deployment-5f94c574ff-b2bgk a7d2a429-ecfd-4599-a49a-cfd11a4bedb4 313937 0 2020-11-13 11:05:07 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff ef3c07b5-7d69-4d92-81ae-785b579e2554 0xc00450a6f7 0xc00450a6f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rnr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rnr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rnr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:,StartTime:2020-11-13 11:05:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:05:07.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2755" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":278,"completed":228,"skipped":3591,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:05:07.949: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5027
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:05:12.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5027" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":278,"completed":229,"skipped":3619,"failed":0}
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:05:12.098: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7595
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-7595
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 13 11:05:12.222: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 13 11:05:34.266: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.5.217 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7595 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 11:05:34.266: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 11:05:35.336: INFO: Found all expected endpoints: [netserver-0]
Nov 13 11:05:35.338: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.43.253 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7595 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 11:05:35.338: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 11:05:36.411: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:05:36.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7595" for this suite.

• [SLOW TEST:24.317 seconds]
[sig-network] Networking
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":230,"skipped":3626,"failed":0}
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:05:36.415: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1807
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 11:05:36.537: INFO: Creating deployment "webserver-deployment"
Nov 13 11:05:36.540: INFO: Waiting for observed generation 1
Nov 13 11:05:38.551: INFO: Waiting for all required pods to come up
Nov 13 11:05:38.553: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov 13 11:05:40.561: INFO: Waiting for deployment "webserver-deployment" to complete
Nov 13 11:05:40.564: INFO: Updating deployment "webserver-deployment" with a non-existent image
Nov 13 11:05:40.567: INFO: Updating deployment webserver-deployment
Nov 13 11:05:40.567: INFO: Waiting for observed generation 2
Nov 13 11:05:42.581: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov 13 11:05:42.582: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov 13 11:05:42.584: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov 13 11:05:42.587: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov 13 11:05:42.587: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov 13 11:05:42.588: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov 13 11:05:42.590: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Nov 13 11:05:42.590: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Nov 13 11:05:42.593: INFO: Updating deployment webserver-deployment
Nov 13 11:05:42.593: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Nov 13 11:05:42.607: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov 13 11:05:44.627: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Nov 13 11:05:44.630: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-1807 /apis/apps/v1/namespaces/deployment-1807/deployments/webserver-deployment eb615cb3-f87d-40f2-b427-15cd3b8d0a73 314416 3 2020-11-13 11:05:36 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0042f1e18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-11-13 11:05:42 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-11-13 11:05:42 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Nov 13 11:05:44.632: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-1807 /apis/apps/v1/namespaces/deployment-1807/replicasets/webserver-deployment-c7997dcc8 511ee720-674e-43cb-8e60-e72dc7442348 314412 3 2020-11-13 11:05:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment eb615cb3-f87d-40f2-b427-15cd3b8d0a73 0xc00428e707 0xc00428e708}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00428e808 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 13 11:05:44.632: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Nov 13 11:05:44.632: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-1807 /apis/apps/v1/namespaces/deployment-1807/replicasets/webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 314399 3 2020-11-13 11:05:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment eb615cb3-f87d-40f2-b427-15cd3b8d0a73 0xc00428e5e7 0xc00428e5e8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00428e678 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Nov 13 11:05:44.640: INFO: Pod "webserver-deployment-595b5b9587-2n2jc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2n2jc webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-2n2jc 93abebdf-ff38-4ebd-9720-3421a48ede43 314455 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc0042bfb27 0xc0042bfb28}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.640: INFO: Pod "webserver-deployment-595b5b9587-4pvbh" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4pvbh webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-4pvbh 202bf29e-ebc1-4c40-9c1f-4df9785acb91 314431 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc0042bfd97 0xc0042bfd98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.640: INFO: Pod "webserver-deployment-595b5b9587-4zfzf" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4zfzf webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-4zfzf a8dbfc37-1925-4b05-a775-1dff45e298f1 314243 0 2020-11-13 11:05:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc004262007 0xc004262008}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:10.200.5.224,StartTime:2020-11-13 11:05:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-13 11:05:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://0d29e15b0fd924241ea7704dce1fa81b125969435c3a1aadf5ba00d38e34bda9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.5.224,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.640: INFO: Pod "webserver-deployment-595b5b9587-545rz" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-545rz webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-545rz d56201b5-42d8-409b-886d-c0f010bfce26 314251 0 2020-11-13 11:05:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc004262287 0xc004262288}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:10.200.5.223,StartTime:2020-11-13 11:05:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-13 11:05:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://ebd7c0ac07b20da43993e048eb08c2c90ee926c488f28692e9ce137f9db8d483,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.5.223,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.640: INFO: Pod "webserver-deployment-595b5b9587-59r6l" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-59r6l webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-59r6l 63a16de0-0adf-4289-9cb3-641bfd8bf298 314466 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc004262487 0xc004262488}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.641: INFO: Pod "webserver-deployment-595b5b9587-899bw" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-899bw webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-899bw 5de842cb-c528-4273-80b9-db2869e158d1 314405 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc0042626d7 0xc0042626d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.641: INFO: Pod "webserver-deployment-595b5b9587-8fmdc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8fmdc webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-8fmdc b5fe81fd-81f5-4eb7-b8fa-6a747823a70b 314423 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc004262917 0xc004262918}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.641: INFO: Pod "webserver-deployment-595b5b9587-btcdd" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-btcdd webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-btcdd efd4417a-3bd6-44d1-9486-59b5f91b69d4 314420 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc004262b57 0xc004262b58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.641: INFO: Pod "webserver-deployment-595b5b9587-cvvnh" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-cvvnh webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-cvvnh da17fa67-0be2-4549-bd06-289662b63749 314392 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc004262d47 0xc004262d48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.641: INFO: Pod "webserver-deployment-595b5b9587-czlwt" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-czlwt webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-czlwt 12e4beb8-a58b-4771-8d24-c116de487462 314202 0 2020-11-13 11:05:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc004262f87 0xc004262f88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:10.200.43.254,StartTime:2020-11-13 11:05:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-13 11:05:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://7d9da298b130979d3347a171c0d31ebdac3ee575ab61c0211a2d2b3633ea6965,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.43.254,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.641: INFO: Pod "webserver-deployment-595b5b9587-dnklh" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-dnklh webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-dnklh c47dc2a6-36b0-4bc5-b60e-38bc77c47fa5 314467 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc004263197 0xc004263198}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.642: INFO: Pod "webserver-deployment-595b5b9587-hb2zq" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hb2zq webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-hb2zq c9098f3c-6950-4ed6-b7ca-28fcaa79a675 314249 0 2020-11-13 11:05:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc0042633e7 0xc0042633e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:10.200.5.222,StartTime:2020-11-13 11:05:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-13 11:05:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://9020bead7c92f970e6deed2714057834cf19b8d2bb64d55b203b5f7e52aa0d42,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.5.222,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.642: INFO: Pod "webserver-deployment-595b5b9587-hzlp5" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hzlp5 webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-hzlp5 7fdf47d4-acc5-48d6-9cfe-749b25c0bd2a 314216 0 2020-11-13 11:05:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc0042635e7 0xc0042635e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:10.200.43.5,StartTime:2020-11-13 11:05:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-13 11:05:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://46b60ccaa300fa193718344ec8fadbcec2df96f2c6182e3719159403c9d7fd20,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.43.5,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.642: INFO: Pod "webserver-deployment-595b5b9587-nhn6w" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nhn6w webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-nhn6w 90b55339-48cb-4da3-9fca-8cc1a31302f8 314372 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc0042637e7 0xc0042637e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.642: INFO: Pod "webserver-deployment-595b5b9587-nk97v" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nk97v webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-nk97v fd2bd305-9be9-469b-820d-cde32c86060e 314428 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc004263a57 0xc004263a58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.642: INFO: Pod "webserver-deployment-595b5b9587-s7msm" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-s7msm webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-s7msm a2e48237-be15-4a3c-a76b-524747726840 314195 0 2020-11-13 11:05:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc004263c57 0xc004263c58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:10.200.5.220,StartTime:2020-11-13 11:05:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-13 11:05:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://5d0ab8916d2d49914cba0ccecef47728ca8f5f1a6e2facd101f79a42ada6a29f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.5.220,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.642: INFO: Pod "webserver-deployment-595b5b9587-s9vq2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-s9vq2 webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-s9vq2 ddf0f0f9-0516-4718-88fd-a9d7224a0fd6 314474 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc004263f17 0xc004263f18}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.643: INFO: Pod "webserver-deployment-595b5b9587-xr7x4" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xr7x4 webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-xr7x4 98d1cfd2-f27d-4e9c-9df4-0a6bfa3ddc79 314213 0 2020-11-13 11:05:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc004240147 0xc004240148}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:10.200.43.4,StartTime:2020-11-13 11:05:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-13 11:05:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://048ad3cdcf736b94e18aa43c105c786db608a9d3e606a4c07955a40b823cd943,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.43.4,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.643: INFO: Pod "webserver-deployment-595b5b9587-z6pht" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-z6pht webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-z6pht c9ffd41c-4f65-4635-8e1a-206ddc3df59e 314452 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc0042403b7 0xc0042403b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.643: INFO: Pod "webserver-deployment-595b5b9587-zqwxc" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zqwxc webserver-deployment-595b5b9587- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-595b5b9587-zqwxc 579f9265-eb55-47d9-82e1-7cd2c802b81c 314246 0 2020-11-13 11:05:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 fb55a299-a064-4caf-af78-1d0d946074b2 0xc004240657 0xc004240658}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:10.200.5.221,StartTime:2020-11-13 11:05:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-13 11:05:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://1f604afbc67631d3a967da76ac924c21521dc959476a7d9951ced902ff20a091,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.5.221,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.643: INFO: Pod "webserver-deployment-c7997dcc8-2mfcx" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-2mfcx webserver-deployment-c7997dcc8- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-c7997dcc8-2mfcx c8bc24e1-389d-4b79-9206-c8d9cc17cd19 314435 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 511ee720-674e-43cb-8e60-e72dc7442348 0xc004240917 0xc004240918}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.643: INFO: Pod "webserver-deployment-c7997dcc8-6zm72" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-6zm72 webserver-deployment-c7997dcc8- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-c7997dcc8-6zm72 7cf8ae0e-ae7c-485e-a0a1-01f1d2e80319 314306 0 2020-11-13 11:05:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 511ee720-674e-43cb-8e60-e72dc7442348 0xc004240b70 0xc004240b71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:,StartTime:2020-11-13 11:05:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.643: INFO: Pod "webserver-deployment-c7997dcc8-8h5sm" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8h5sm webserver-deployment-c7997dcc8- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-c7997dcc8-8h5sm 887d28e1-5e07-487f-8541-e8563764c390 314302 0 2020-11-13 11:05:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 511ee720-674e-43cb-8e60-e72dc7442348 0xc004240db0 0xc004240db1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:,StartTime:2020-11-13 11:05:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.643: INFO: Pod "webserver-deployment-c7997dcc8-96x6g" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-96x6g webserver-deployment-c7997dcc8- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-c7997dcc8-96x6g abdf7c6f-fd1e-4a02-81f8-032431ee9bfd 314281 0 2020-11-13 11:05:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 511ee720-674e-43cb-8e60-e72dc7442348 0xc004240fb0 0xc004240fb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:,StartTime:2020-11-13 11:05:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.643: INFO: Pod "webserver-deployment-c7997dcc8-fd8rc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-fd8rc webserver-deployment-c7997dcc8- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-c7997dcc8-fd8rc ab27b1bd-0b23-41bc-a700-b33ffe6c85c4 314482 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 511ee720-674e-43cb-8e60-e72dc7442348 0xc004241170 0xc004241171}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.644: INFO: Pod "webserver-deployment-c7997dcc8-g7dtm" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-g7dtm webserver-deployment-c7997dcc8- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-c7997dcc8-g7dtm 0d0bf36a-f7fe-4b62-89e1-acf81ef5cd95 314493 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 511ee720-674e-43cb-8e60-e72dc7442348 0xc004241380 0xc004241381}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.644: INFO: Pod "webserver-deployment-c7997dcc8-m9pd2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-m9pd2 webserver-deployment-c7997dcc8- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-c7997dcc8-m9pd2 b7c5653c-6ba7-4c4b-97c0-b7fd3a1deedc 314494 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 511ee720-674e-43cb-8e60-e72dc7442348 0xc004241660 0xc004241661}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.644: INFO: Pod "webserver-deployment-c7997dcc8-p8hf5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-p8hf5 webserver-deployment-c7997dcc8- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-c7997dcc8-p8hf5 dbb7b085-236e-4be0-9ed9-e2a3a4b17604 314475 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 511ee720-674e-43cb-8e60-e72dc7442348 0xc004241890 0xc004241891}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.644: INFO: Pod "webserver-deployment-c7997dcc8-qtx8j" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-qtx8j webserver-deployment-c7997dcc8- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-c7997dcc8-qtx8j 0ac2a57e-65e3-44cc-86fd-ca6726d2e3e6 314414 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 511ee720-674e-43cb-8e60-e72dc7442348 0xc004241ad0 0xc004241ad1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.644: INFO: Pod "webserver-deployment-c7997dcc8-rj4d5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-rj4d5 webserver-deployment-c7997dcc8- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-c7997dcc8-rj4d5 c064e9ed-47fe-4ea7-85b0-16436e9e713f 314282 0 2020-11-13 11:05:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 511ee720-674e-43cb-8e60-e72dc7442348 0xc004241d50 0xc004241d51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:,StartTime:2020-11-13 11:05:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.644: INFO: Pod "webserver-deployment-c7997dcc8-tfvqh" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tfvqh webserver-deployment-c7997dcc8- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-c7997dcc8-tfvqh 19bf8e69-076a-4c07-8f1d-ff71b9922bb0 314275 0 2020-11-13 11:05:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 511ee720-674e-43cb-8e60-e72dc7442348 0xc004241f40 0xc004241f41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:,StartTime:2020-11-13 11:05:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.644: INFO: Pod "webserver-deployment-c7997dcc8-xrbwm" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-xrbwm webserver-deployment-c7997dcc8- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-c7997dcc8-xrbwm adb9b728-8ed7-4e60-803e-b732f30a7992 314415 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 511ee720-674e-43cb-8e60-e72dc7442348 0xc004222160 0xc004222161}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 13 11:05:44.645: INFO: Pod "webserver-deployment-c7997dcc8-xtf6n" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-xtf6n webserver-deployment-c7997dcc8- deployment-1807 /api/v1/namespaces/deployment-1807/pods/webserver-deployment-c7997dcc8-xtf6n c398de69-3454-4910-8592-d2488bbe068d 314484 0 2020-11-13 11:05:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 511ee720-674e-43cb-8e60-e72dc7442348 0xc004222430 0xc004222431}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-r48h2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-r48h2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-r48h2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:29607307-5497-41cc-a8d5-c2f7d9a90e41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:05:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.12,PodIP:,StartTime:2020-11-13 11:05:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:05:44.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1807" for this suite.

• [SLOW TEST:8.237 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":278,"completed":231,"skipped":3627,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:05:44.652: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-244
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-3e73204b-d6f1-4d4a-9900-72dc0bbb4be0
STEP: Creating a pod to test consume configMaps
Nov 13 11:05:44.821: INFO: Waiting up to 5m0s for pod "pod-configmaps-820b3437-547d-4009-b315-00d325a5c459" in namespace "configmap-244" to be "success or failure"
Nov 13 11:05:44.827: INFO: Pod "pod-configmaps-820b3437-547d-4009-b315-00d325a5c459": Phase="Pending", Reason="", readiness=false. Elapsed: 6.36545ms
Nov 13 11:05:46.829: INFO: Pod "pod-configmaps-820b3437-547d-4009-b315-00d325a5c459": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008277657s
Nov 13 11:05:48.831: INFO: Pod "pod-configmaps-820b3437-547d-4009-b315-00d325a5c459": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010102604s
Nov 13 11:05:50.833: INFO: Pod "pod-configmaps-820b3437-547d-4009-b315-00d325a5c459": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011794957s
Nov 13 11:05:52.834: INFO: Pod "pod-configmaps-820b3437-547d-4009-b315-00d325a5c459": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.013292375s
STEP: Saw pod success
Nov 13 11:05:52.834: INFO: Pod "pod-configmaps-820b3437-547d-4009-b315-00d325a5c459" satisfied condition "success or failure"
Nov 13 11:05:52.835: INFO: Trying to get logs from node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c pod pod-configmaps-820b3437-547d-4009-b315-00d325a5c459 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 11:05:52.846: INFO: Waiting for pod pod-configmaps-820b3437-547d-4009-b315-00d325a5c459 to disappear
Nov 13 11:05:52.851: INFO: Pod pod-configmaps-820b3437-547d-4009-b315-00d325a5c459 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:05:52.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-244" for this suite.

• [SLOW TEST:8.203 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":232,"skipped":3640,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:05:52.856: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4230
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:05:56.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4230" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":278,"completed":233,"skipped":3652,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:05:56.998: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1272
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 11:05:57.125: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a96aee93-6397-41f9-9c19-1dde9a282fff" in namespace "projected-1272" to be "success or failure"
Nov 13 11:05:57.133: INFO: Pod "downwardapi-volume-a96aee93-6397-41f9-9c19-1dde9a282fff": Phase="Pending", Reason="", readiness=false. Elapsed: 7.685874ms
Nov 13 11:05:59.135: INFO: Pod "downwardapi-volume-a96aee93-6397-41f9-9c19-1dde9a282fff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009679766s
STEP: Saw pod success
Nov 13 11:05:59.135: INFO: Pod "downwardapi-volume-a96aee93-6397-41f9-9c19-1dde9a282fff" satisfied condition "success or failure"
Nov 13 11:05:59.138: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-a96aee93-6397-41f9-9c19-1dde9a282fff container client-container: <nil>
STEP: delete the pod
Nov 13 11:05:59.147: INFO: Waiting for pod downwardapi-volume-a96aee93-6397-41f9-9c19-1dde9a282fff to disappear
Nov 13 11:05:59.152: INFO: Pod downwardapi-volume-a96aee93-6397-41f9-9c19-1dde9a282fff no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:05:59.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1272" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":234,"skipped":3657,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:05:59.158: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-277
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-map-36d40549-3826-4102-9574-19c1da98c10f
STEP: Creating a pod to test consume secrets
Nov 13 11:05:59.287: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-121491ce-e112-4280-9cb6-082c4159a6e9" in namespace "projected-277" to be "success or failure"
Nov 13 11:05:59.289: INFO: Pod "pod-projected-secrets-121491ce-e112-4280-9cb6-082c4159a6e9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.994063ms
Nov 13 11:06:01.291: INFO: Pod "pod-projected-secrets-121491ce-e112-4280-9cb6-082c4159a6e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00367824s
STEP: Saw pod success
Nov 13 11:06:01.291: INFO: Pod "pod-projected-secrets-121491ce-e112-4280-9cb6-082c4159a6e9" satisfied condition "success or failure"
Nov 13 11:06:01.292: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-projected-secrets-121491ce-e112-4280-9cb6-082c4159a6e9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 13 11:06:01.303: INFO: Waiting for pod pod-projected-secrets-121491ce-e112-4280-9cb6-082c4159a6e9 to disappear
Nov 13 11:06:01.305: INFO: Pod pod-projected-secrets-121491ce-e112-4280-9cb6-082c4159a6e9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:06:01.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-277" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":278,"completed":235,"skipped":3669,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:06:01.314: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9601
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-9601
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 13 11:06:01.440: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 13 11:06:17.500: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.5.241:8080/dial?request=hostname&protocol=http&host=10.200.5.240&port=8080&tries=1'] Namespace:pod-network-test-9601 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 11:06:17.500: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 11:06:17.575: INFO: Waiting for responses: map[]
Nov 13 11:06:17.577: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.5.241:8080/dial?request=hostname&protocol=http&host=10.200.43.24&port=8080&tries=1'] Namespace:pod-network-test-9601 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 11:06:17.577: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 11:06:17.646: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:06:17.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9601" for this suite.

• [SLOW TEST:16.339 seconds]
[sig-network] Networking
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":236,"skipped":3688,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:06:17.652: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-692
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-3911d179-8166-4fef-badb-2eaf9ec97cf5
STEP: Creating a pod to test consume secrets
Nov 13 11:06:17.786: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b5f5ad1a-1128-4f1d-a6b1-f2ec2ca31a9f" in namespace "projected-692" to be "success or failure"
Nov 13 11:06:17.791: INFO: Pod "pod-projected-secrets-b5f5ad1a-1128-4f1d-a6b1-f2ec2ca31a9f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.097589ms
Nov 13 11:06:19.794: INFO: Pod "pod-projected-secrets-b5f5ad1a-1128-4f1d-a6b1-f2ec2ca31a9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007622115s
STEP: Saw pod success
Nov 13 11:06:19.794: INFO: Pod "pod-projected-secrets-b5f5ad1a-1128-4f1d-a6b1-f2ec2ca31a9f" satisfied condition "success or failure"
Nov 13 11:06:19.795: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-projected-secrets-b5f5ad1a-1128-4f1d-a6b1-f2ec2ca31a9f container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 13 11:06:19.805: INFO: Waiting for pod pod-projected-secrets-b5f5ad1a-1128-4f1d-a6b1-f2ec2ca31a9f to disappear
Nov 13 11:06:19.812: INFO: Pod pod-projected-secrets-b5f5ad1a-1128-4f1d-a6b1-f2ec2ca31a9f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:06:19.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-692" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":278,"completed":237,"skipped":3717,"failed":0}

------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:06:19.818: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5597
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-5597
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 13 11:06:19.945: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 13 11:06:39.990: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.5.244:8080/dial?request=hostname&protocol=udp&host=10.200.5.243&port=8081&tries=1'] Namespace:pod-network-test-5597 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 11:06:39.990: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 11:06:40.078: INFO: Waiting for responses: map[]
Nov 13 11:06:40.080: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.5.244:8080/dial?request=hostname&protocol=udp&host=10.200.43.25&port=8081&tries=1'] Namespace:pod-network-test-5597 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 13 11:06:40.080: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
Nov 13 11:06:40.160: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:06:40.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5597" for this suite.

• [SLOW TEST:20.347 seconds]
[sig-network] Networking
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":238,"skipped":3717,"failed":0}
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:06:40.165: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5370
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test substitution in container's args
Nov 13 11:06:40.292: INFO: Waiting up to 5m0s for pod "var-expansion-a1c952f4-ccb0-4680-a51e-9deda6816874" in namespace "var-expansion-5370" to be "success or failure"
Nov 13 11:06:40.300: INFO: Pod "var-expansion-a1c952f4-ccb0-4680-a51e-9deda6816874": Phase="Pending", Reason="", readiness=false. Elapsed: 7.969425ms
Nov 13 11:06:42.302: INFO: Pod "var-expansion-a1c952f4-ccb0-4680-a51e-9deda6816874": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009823759s
STEP: Saw pod success
Nov 13 11:06:42.302: INFO: Pod "var-expansion-a1c952f4-ccb0-4680-a51e-9deda6816874" satisfied condition "success or failure"
Nov 13 11:06:42.303: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod var-expansion-a1c952f4-ccb0-4680-a51e-9deda6816874 container dapi-container: <nil>
STEP: delete the pod
Nov 13 11:06:42.314: INFO: Waiting for pod var-expansion-a1c952f4-ccb0-4680-a51e-9deda6816874 to disappear
Nov 13 11:06:42.315: INFO: Pod var-expansion-a1c952f4-ccb0-4680-a51e-9deda6816874 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:06:42.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5370" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":278,"completed":239,"skipped":3722,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:06:42.321: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1628
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-upd-bb49f45e-0aca-4984-858f-94ac816d7e23
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:06:44.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1628" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":278,"completed":240,"skipped":3739,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:06:44.480: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6967
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 11:06:44.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 version'
Nov 13 11:06:44.662: INFO: stderr: ""
Nov 13 11:06:44.662: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.9\", GitCommit:\"4fb7ed12476d57b8437ada90b4f93b17ffaeed99\", GitTreeState:\"clean\", BuildDate:\"2020-07-15T16:18:16Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.9\", GitCommit:\"4fb7ed12476d57b8437ada90b4f93b17ffaeed99\", GitTreeState:\"clean\", BuildDate:\"2020-07-15T16:10:45Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:06:44.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6967" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":278,"completed":241,"skipped":3764,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:06:44.666: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4329
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a replication controller
Nov 13 11:06:44.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 create -f - --namespace=kubectl-4329'
Nov 13 11:06:44.960: INFO: stderr: ""
Nov 13 11:06:44.960: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 13 11:06:44.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4329'
Nov 13 11:06:45.030: INFO: stderr: ""
Nov 13 11:06:45.030: INFO: stdout: "update-demo-nautilus-gv89z update-demo-nautilus-sjxlv "
Nov 13 11:06:45.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-gv89z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4329'
Nov 13 11:06:45.080: INFO: stderr: ""
Nov 13 11:06:45.080: INFO: stdout: ""
Nov 13 11:06:45.080: INFO: update-demo-nautilus-gv89z is created but not running
Nov 13 11:06:50.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4329'
Nov 13 11:06:50.131: INFO: stderr: ""
Nov 13 11:06:50.131: INFO: stdout: "update-demo-nautilus-gv89z update-demo-nautilus-sjxlv "
Nov 13 11:06:50.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-gv89z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4329'
Nov 13 11:06:50.188: INFO: stderr: ""
Nov 13 11:06:50.188: INFO: stdout: "true"
Nov 13 11:06:50.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-gv89z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4329'
Nov 13 11:06:50.239: INFO: stderr: ""
Nov 13 11:06:50.239: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 11:06:50.239: INFO: validating pod update-demo-nautilus-gv89z
Nov 13 11:06:50.242: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 11:06:50.242: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 11:06:50.242: INFO: update-demo-nautilus-gv89z is verified up and running
Nov 13 11:06:50.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-sjxlv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4329'
Nov 13 11:06:50.291: INFO: stderr: ""
Nov 13 11:06:50.291: INFO: stdout: "true"
Nov 13 11:06:50.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-sjxlv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4329'
Nov 13 11:06:50.343: INFO: stderr: ""
Nov 13 11:06:50.343: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 11:06:50.343: INFO: validating pod update-demo-nautilus-sjxlv
Nov 13 11:06:50.346: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 11:06:50.346: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 11:06:50.346: INFO: update-demo-nautilus-sjxlv is verified up and running
STEP: scaling down the replication controller
Nov 13 11:06:50.347: INFO: scanned /root for discovery docs: <nil>
Nov 13 11:06:50.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-4329'
Nov 13 11:06:51.422: INFO: stderr: ""
Nov 13 11:06:51.422: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 13 11:06:51.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4329'
Nov 13 11:06:51.487: INFO: stderr: ""
Nov 13 11:06:51.487: INFO: stdout: "update-demo-nautilus-gv89z update-demo-nautilus-sjxlv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov 13 11:06:56.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4329'
Nov 13 11:06:56.541: INFO: stderr: ""
Nov 13 11:06:56.541: INFO: stdout: "update-demo-nautilus-gv89z update-demo-nautilus-sjxlv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov 13 11:07:01.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4329'
Nov 13 11:07:01.592: INFO: stderr: ""
Nov 13 11:07:01.592: INFO: stdout: "update-demo-nautilus-gv89z "
Nov 13 11:07:01.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-gv89z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4329'
Nov 13 11:07:01.643: INFO: stderr: ""
Nov 13 11:07:01.643: INFO: stdout: "true"
Nov 13 11:07:01.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-gv89z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4329'
Nov 13 11:07:01.689: INFO: stderr: ""
Nov 13 11:07:01.689: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 11:07:01.689: INFO: validating pod update-demo-nautilus-gv89z
Nov 13 11:07:01.691: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 11:07:01.691: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 11:07:01.691: INFO: update-demo-nautilus-gv89z is verified up and running
STEP: scaling up the replication controller
Nov 13 11:07:01.692: INFO: scanned /root for discovery docs: <nil>
Nov 13 11:07:01.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-4329'
Nov 13 11:07:02.764: INFO: stderr: ""
Nov 13 11:07:02.764: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 13 11:07:02.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4329'
Nov 13 11:07:02.826: INFO: stderr: ""
Nov 13 11:07:02.826: INFO: stdout: "update-demo-nautilus-gv89z update-demo-nautilus-nh77m "
Nov 13 11:07:02.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-gv89z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4329'
Nov 13 11:07:02.890: INFO: stderr: ""
Nov 13 11:07:02.890: INFO: stdout: "true"
Nov 13 11:07:02.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-gv89z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4329'
Nov 13 11:07:02.948: INFO: stderr: ""
Nov 13 11:07:02.948: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 11:07:02.948: INFO: validating pod update-demo-nautilus-gv89z
Nov 13 11:07:02.950: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 11:07:02.950: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 11:07:02.950: INFO: update-demo-nautilus-gv89z is verified up and running
Nov 13 11:07:02.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-nh77m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4329'
Nov 13 11:07:03.003: INFO: stderr: ""
Nov 13 11:07:03.003: INFO: stdout: ""
Nov 13 11:07:03.003: INFO: update-demo-nautilus-nh77m is created but not running
Nov 13 11:07:08.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4329'
Nov 13 11:07:08.055: INFO: stderr: ""
Nov 13 11:07:08.055: INFO: stdout: "update-demo-nautilus-gv89z update-demo-nautilus-nh77m "
Nov 13 11:07:08.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-gv89z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4329'
Nov 13 11:07:08.100: INFO: stderr: ""
Nov 13 11:07:08.100: INFO: stdout: "true"
Nov 13 11:07:08.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-gv89z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4329'
Nov 13 11:07:08.145: INFO: stderr: ""
Nov 13 11:07:08.145: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 11:07:08.145: INFO: validating pod update-demo-nautilus-gv89z
Nov 13 11:07:08.147: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 11:07:08.147: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 11:07:08.147: INFO: update-demo-nautilus-gv89z is verified up and running
Nov 13 11:07:08.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-nh77m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4329'
Nov 13 11:07:08.191: INFO: stderr: ""
Nov 13 11:07:08.191: INFO: stdout: "true"
Nov 13 11:07:08.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-nh77m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4329'
Nov 13 11:07:08.235: INFO: stderr: ""
Nov 13 11:07:08.236: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 11:07:08.236: INFO: validating pod update-demo-nautilus-nh77m
Nov 13 11:07:08.238: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 11:07:08.238: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 11:07:08.238: INFO: update-demo-nautilus-nh77m is verified up and running
STEP: using delete to clean up resources
Nov 13 11:07:08.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete --grace-period=0 --force -f - --namespace=kubectl-4329'
Nov 13 11:07:08.284: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 13 11:07:08.284: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 13 11:07:08.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4329'
Nov 13 11:07:08.340: INFO: stderr: "No resources found in kubectl-4329 namespace.\n"
Nov 13 11:07:08.340: INFO: stdout: ""
Nov 13 11:07:08.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -l name=update-demo --namespace=kubectl-4329 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 13 11:07:08.389: INFO: stderr: ""
Nov 13 11:07:08.389: INFO: stdout: "update-demo-nautilus-gv89z\nupdate-demo-nautilus-nh77m\n"
Nov 13 11:07:08.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4329'
Nov 13 11:07:08.946: INFO: stderr: "No resources found in kubectl-4329 namespace.\n"
Nov 13 11:07:08.946: INFO: stdout: ""
Nov 13 11:07:08.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -l name=update-demo --namespace=kubectl-4329 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 13 11:07:08.993: INFO: stderr: ""
Nov 13 11:07:08.993: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:07:08.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4329" for this suite.

• [SLOW TEST:24.331 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":278,"completed":242,"skipped":3774,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:07:08.997: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5698
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-b7382f6d-adb0-4471-b6af-d87858d340d0
STEP: Creating a pod to test consume configMaps
Nov 13 11:07:09.127: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1583d86c-03b7-4da2-9bd4-1e5b94a96a3a" in namespace "projected-5698" to be "success or failure"
Nov 13 11:07:09.135: INFO: Pod "pod-projected-configmaps-1583d86c-03b7-4da2-9bd4-1e5b94a96a3a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.863822ms
Nov 13 11:07:11.137: INFO: Pod "pod-projected-configmaps-1583d86c-03b7-4da2-9bd4-1e5b94a96a3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010187119s
STEP: Saw pod success
Nov 13 11:07:11.137: INFO: Pod "pod-projected-configmaps-1583d86c-03b7-4da2-9bd4-1e5b94a96a3a" satisfied condition "success or failure"
Nov 13 11:07:11.139: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-projected-configmaps-1583d86c-03b7-4da2-9bd4-1e5b94a96a3a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 11:07:11.149: INFO: Waiting for pod pod-projected-configmaps-1583d86c-03b7-4da2-9bd4-1e5b94a96a3a to disappear
Nov 13 11:07:11.155: INFO: Pod pod-projected-configmaps-1583d86c-03b7-4da2-9bd4-1e5b94a96a3a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:07:11.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5698" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":278,"completed":243,"skipped":3783,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:07:11.163: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1832
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov 13 11:07:11.341: INFO: Waiting up to 5m0s for pod "pod-f6e27d0c-3d86-4514-9f52-281a19a06797" in namespace "emptydir-1832" to be "success or failure"
Nov 13 11:07:11.344: INFO: Pod "pod-f6e27d0c-3d86-4514-9f52-281a19a06797": Phase="Pending", Reason="", readiness=false. Elapsed: 3.217466ms
Nov 13 11:07:13.346: INFO: Pod "pod-f6e27d0c-3d86-4514-9f52-281a19a06797": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005291867s
STEP: Saw pod success
Nov 13 11:07:13.346: INFO: Pod "pod-f6e27d0c-3d86-4514-9f52-281a19a06797" satisfied condition "success or failure"
Nov 13 11:07:13.348: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-f6e27d0c-3d86-4514-9f52-281a19a06797 container test-container: <nil>
STEP: delete the pod
Nov 13 11:07:13.357: INFO: Waiting for pod pod-f6e27d0c-3d86-4514-9f52-281a19a06797 to disappear
Nov 13 11:07:13.363: INFO: Pod pod-f6e27d0c-3d86-4514-9f52-281a19a06797 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:07:13.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1832" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":244,"skipped":3803,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:07:13.368: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4152
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir volume type on node default medium
Nov 13 11:07:13.494: INFO: Waiting up to 5m0s for pod "pod-785ee356-ac1a-4a5e-b10c-09c6a2f2e082" in namespace "emptydir-4152" to be "success or failure"
Nov 13 11:07:13.499: INFO: Pod "pod-785ee356-ac1a-4a5e-b10c-09c6a2f2e082": Phase="Pending", Reason="", readiness=false. Elapsed: 4.497721ms
Nov 13 11:07:15.501: INFO: Pod "pod-785ee356-ac1a-4a5e-b10c-09c6a2f2e082": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006390887s
STEP: Saw pod success
Nov 13 11:07:15.501: INFO: Pod "pod-785ee356-ac1a-4a5e-b10c-09c6a2f2e082" satisfied condition "success or failure"
Nov 13 11:07:15.502: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-785ee356-ac1a-4a5e-b10c-09c6a2f2e082 container test-container: <nil>
STEP: delete the pod
Nov 13 11:07:15.511: INFO: Waiting for pod pod-785ee356-ac1a-4a5e-b10c-09c6a2f2e082 to disappear
Nov 13 11:07:15.517: INFO: Pod pod-785ee356-ac1a-4a5e-b10c-09c6a2f2e082 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:07:15.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4152" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":245,"skipped":3818,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:07:15.523: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3260
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1754
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 13 11:07:15.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-3260'
Nov 13 11:07:15.747: INFO: stderr: ""
Nov 13 11:07:15.748: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1759
Nov 13 11:07:15.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 delete pods e2e-test-httpd-pod --namespace=kubectl-3260'
Nov 13 11:07:17.552: INFO: stderr: ""
Nov 13 11:07:17.552: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:07:17.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3260" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":278,"completed":246,"skipped":3886,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:07:17.561: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4562
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 11:07:17.741: INFO: Waiting up to 5m0s for pod "downwardapi-volume-70768e1d-9d47-4506-93b1-cbff7150d5d9" in namespace "downward-api-4562" to be "success or failure"
Nov 13 11:07:17.745: INFO: Pod "downwardapi-volume-70768e1d-9d47-4506-93b1-cbff7150d5d9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.8228ms
Nov 13 11:07:19.747: INFO: Pod "downwardapi-volume-70768e1d-9d47-4506-93b1-cbff7150d5d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005910621s
STEP: Saw pod success
Nov 13 11:07:19.747: INFO: Pod "downwardapi-volume-70768e1d-9d47-4506-93b1-cbff7150d5d9" satisfied condition "success or failure"
Nov 13 11:07:19.748: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-70768e1d-9d47-4506-93b1-cbff7150d5d9 container client-container: <nil>
STEP: delete the pod
Nov 13 11:07:19.759: INFO: Waiting for pod downwardapi-volume-70768e1d-9d47-4506-93b1-cbff7150d5d9 to disappear
Nov 13 11:07:19.763: INFO: Pod downwardapi-volume-70768e1d-9d47-4506-93b1-cbff7150d5d9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:07:19.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4562" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":247,"skipped":3905,"failed":0}
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:07:19.769: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1724
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Nov 13 11:07:19.894: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 13 11:07:19.899: INFO: Waiting for terminating namespaces to be deleted...
Nov 13 11:07:19.901: INFO: 
Logging pods the kubelet thinks is on node 29607307-5497-41cc-a8d5-c2f7d9a90e41 before test
Nov 13 11:07:19.905: INFO: coredns-54b9777bfc-nhhjt from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 11:07:19.906: INFO: 	Container coredns ready: true, restart count 0
Nov 13 11:07:19.906: INFO: sonobuoy from sonobuoy started at 2020-11-13 09:37:07 +0000 UTC (1 container statuses recorded)
Nov 13 11:07:19.906: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 13 11:07:19.906: INFO: traefik-ingress-controller-v48l8 from traefik-ingress started at 2020-11-12 01:09:03 +0000 UTC (1 container statuses recorded)
Nov 13 11:07:19.906: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov 13 11:07:19.906: INFO: sonobuoy-systemd-logs-daemon-set-294e69fb102c4fcf-tncdk from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 11:07:19.906: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 11:07:19.906: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 13 11:07:19.906: INFO: metrics-server-5df78f85b-kzd6m from kube-system started at 2020-11-12 01:07:27 +0000 UTC (1 container statuses recorded)
Nov 13 11:07:19.906: INFO: 	Container metrics-server ready: true, restart count 0
Nov 13 11:07:19.906: INFO: filebeat-chjmw from kube-system started at 2020-11-12 01:08:33 +0000 UTC (1 container statuses recorded)
Nov 13 11:07:19.906: INFO: 	Container filebeat ready: true, restart count 0
Nov 13 11:07:19.906: INFO: 
Logging pods the kubelet thinks is on node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c before test
Nov 13 11:07:19.913: INFO: coredns-54b9777bfc-q6tzp from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 11:07:19.913: INFO: 	Container coredns ready: true, restart count 0
Nov 13 11:07:19.913: INFO: sonobuoy-systemd-logs-daemon-set-294e69fb102c4fcf-fk6ph from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 11:07:19.913: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 11:07:19.913: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 13 11:07:19.913: INFO: coredns-54b9777bfc-jj6kl from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 11:07:19.914: INFO: 	Container coredns ready: true, restart count 0
Nov 13 11:07:19.914: INFO: sonobuoy-e2e-job-b8fa8fc01c7d4f11 from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 11:07:19.914: INFO: 	Container e2e ready: true, restart count 0
Nov 13 11:07:19.914: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 11:07:19.914: INFO: traefik-ingress-controller-xbfqn from traefik-ingress started at 2020-11-12 01:09:03 +0000 UTC (1 container statuses recorded)
Nov 13 11:07:19.914: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov 13 11:07:19.914: INFO: filebeat-zxtp6 from kube-system started at 2020-11-12 01:08:33 +0000 UTC (1 container statuses recorded)
Nov 13 11:07:19.915: INFO: 	Container filebeat ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-94d63ef2-c809-4b41-b4cc-733842270357 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-94d63ef2-c809-4b41-b4cc-733842270357 off the node 29607307-5497-41cc-a8d5-c2f7d9a90e41
STEP: verifying the node doesn't have the label kubernetes.io/e2e-94d63ef2-c809-4b41-b4cc-733842270357
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:07:23.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1724" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":278,"completed":248,"skipped":3912,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:07:23.992: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-434
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-434
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-434
STEP: creating replication controller externalsvc in namespace services-434
I1113 11:07:24.143118      20 runners.go:189] Created replication controller with name: externalsvc, namespace: services-434, replica count: 2
I1113 11:07:27.193404      20 runners.go:189] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Nov 13 11:07:27.200: INFO: Creating new exec pod
Nov 13 11:07:29.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-434 execpodvgxzs -- /bin/sh -x -c nslookup clusterip-service'
Nov 13 11:07:29.336: INFO: stderr: "+ nslookup clusterip-service\n"
Nov 13 11:07:29.336: INFO: stdout: "Server:\t\t10.100.200.10\nAddress:\t10.100.200.10#53\n\nclusterip-service.services-434.svc.cluster.local\tcanonical name = externalsvc.services-434.svc.cluster.local.\nName:\texternalsvc.services-434.svc.cluster.local\nAddress: 10.100.200.115\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-434, will wait for the garbage collector to delete the pods
Nov 13 11:07:29.392: INFO: Deleting ReplicationController externalsvc took: 4.314953ms
Nov 13 11:07:29.792: INFO: Terminating ReplicationController externalsvc pods took: 400.280686ms
Nov 13 11:07:38.902: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:07:38.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-434" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:14.925 seconds]
[sig-network] Services
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":278,"completed":249,"skipped":3955,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:07:38.921: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2180
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 11:07:39.049: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9c01aad2-7771-48ea-9599-058687d71a5f" in namespace "downward-api-2180" to be "success or failure"
Nov 13 11:07:39.057: INFO: Pod "downwardapi-volume-9c01aad2-7771-48ea-9599-058687d71a5f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.813197ms
Nov 13 11:07:41.060: INFO: Pod "downwardapi-volume-9c01aad2-7771-48ea-9599-058687d71a5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010515386s
STEP: Saw pod success
Nov 13 11:07:41.060: INFO: Pod "downwardapi-volume-9c01aad2-7771-48ea-9599-058687d71a5f" satisfied condition "success or failure"
Nov 13 11:07:41.061: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-9c01aad2-7771-48ea-9599-058687d71a5f container client-container: <nil>
STEP: delete the pod
Nov 13 11:07:41.072: INFO: Waiting for pod downwardapi-volume-9c01aad2-7771-48ea-9599-058687d71a5f to disappear
Nov 13 11:07:41.078: INFO: Pod downwardapi-volume-9c01aad2-7771-48ea-9599-058687d71a5f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:07:41.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2180" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":278,"completed":250,"skipped":3968,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:07:41.082: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8447
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Nov 13 11:07:43.722: INFO: Successfully updated pod "adopt-release-l64mf"
STEP: Checking that the Job readopts the Pod
Nov 13 11:07:43.722: INFO: Waiting up to 15m0s for pod "adopt-release-l64mf" in namespace "job-8447" to be "adopted"
Nov 13 11:07:43.725: INFO: Pod "adopt-release-l64mf": Phase="Running", Reason="", readiness=true. Elapsed: 3.488956ms
Nov 13 11:07:45.727: INFO: Pod "adopt-release-l64mf": Phase="Running", Reason="", readiness=true. Elapsed: 2.005347789s
Nov 13 11:07:45.727: INFO: Pod "adopt-release-l64mf" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Nov 13 11:07:46.232: INFO: Successfully updated pod "adopt-release-l64mf"
STEP: Checking that the Job releases the Pod
Nov 13 11:07:46.232: INFO: Waiting up to 15m0s for pod "adopt-release-l64mf" in namespace "job-8447" to be "released"
Nov 13 11:07:46.240: INFO: Pod "adopt-release-l64mf": Phase="Running", Reason="", readiness=true. Elapsed: 8.187259ms
Nov 13 11:07:46.240: INFO: Pod "adopt-release-l64mf" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:07:46.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8447" for this suite.

• [SLOW TEST:5.183 seconds]
[sig-apps] Job
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":278,"completed":251,"skipped":3983,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:07:46.271: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4955
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-b2cda23e-ff1f-44e6-9f2e-30fe475936b3
STEP: Creating a pod to test consume configMaps
Nov 13 11:07:46.399: INFO: Waiting up to 5m0s for pod "pod-configmaps-082d9bb5-fe5d-46ee-8d08-1dd3e20a861e" in namespace "configmap-4955" to be "success or failure"
Nov 13 11:07:46.402: INFO: Pod "pod-configmaps-082d9bb5-fe5d-46ee-8d08-1dd3e20a861e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.246845ms
Nov 13 11:07:48.405: INFO: Pod "pod-configmaps-082d9bb5-fe5d-46ee-8d08-1dd3e20a861e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005691532s
Nov 13 11:07:50.407: INFO: Pod "pod-configmaps-082d9bb5-fe5d-46ee-8d08-1dd3e20a861e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007820404s
STEP: Saw pod success
Nov 13 11:07:50.407: INFO: Pod "pod-configmaps-082d9bb5-fe5d-46ee-8d08-1dd3e20a861e" satisfied condition "success or failure"
Nov 13 11:07:50.408: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-configmaps-082d9bb5-fe5d-46ee-8d08-1dd3e20a861e container configmap-volume-test: <nil>
STEP: delete the pod
Nov 13 11:07:50.418: INFO: Waiting for pod pod-configmaps-082d9bb5-fe5d-46ee-8d08-1dd3e20a861e to disappear
Nov 13 11:07:50.427: INFO: Pod pod-configmaps-082d9bb5-fe5d-46ee-8d08-1dd3e20a861e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:07:50.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4955" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":252,"skipped":4046,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:07:50.434: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3940
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 11:07:51.104: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 11:07:54.113: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:07:54.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3940" for this suite.
STEP: Destroying namespace "webhook-3940-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":278,"completed":253,"skipped":4050,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:07:54.196: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2593
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Nov 13 11:07:54.329: INFO: Waiting up to 5m0s for pod "downward-api-651d0461-c8f8-4b28-8bfc-6129404b810f" in namespace "downward-api-2593" to be "success or failure"
Nov 13 11:07:54.339: INFO: Pod "downward-api-651d0461-c8f8-4b28-8bfc-6129404b810f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.428821ms
Nov 13 11:07:56.341: INFO: Pod "downward-api-651d0461-c8f8-4b28-8bfc-6129404b810f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012352283s
STEP: Saw pod success
Nov 13 11:07:56.342: INFO: Pod "downward-api-651d0461-c8f8-4b28-8bfc-6129404b810f" satisfied condition "success or failure"
Nov 13 11:07:56.343: INFO: Trying to get logs from node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c pod downward-api-651d0461-c8f8-4b28-8bfc-6129404b810f container dapi-container: <nil>
STEP: delete the pod
Nov 13 11:07:56.353: INFO: Waiting for pod downward-api-651d0461-c8f8-4b28-8bfc-6129404b810f to disappear
Nov 13 11:07:56.358: INFO: Pod downward-api-651d0461-c8f8-4b28-8bfc-6129404b810f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:07:56.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2593" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":278,"completed":254,"skipped":4123,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:07:56.363: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5545
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 13 11:07:56.808: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 13 11:07:59.818: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:08:11.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5545" for this suite.
STEP: Destroying namespace "webhook-5545-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.557 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":278,"completed":255,"skipped":4134,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:08:11.920: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9714
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov 13 11:08:12.104: INFO: Waiting up to 5m0s for pod "pod-2b73a560-d7a3-44d1-bd42-beba6a5f5653" in namespace "emptydir-9714" to be "success or failure"
Nov 13 11:08:12.112: INFO: Pod "pod-2b73a560-d7a3-44d1-bd42-beba6a5f5653": Phase="Pending", Reason="", readiness=false. Elapsed: 7.782903ms
Nov 13 11:08:14.115: INFO: Pod "pod-2b73a560-d7a3-44d1-bd42-beba6a5f5653": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011306251s
STEP: Saw pod success
Nov 13 11:08:14.115: INFO: Pod "pod-2b73a560-d7a3-44d1-bd42-beba6a5f5653" satisfied condition "success or failure"
Nov 13 11:08:14.117: INFO: Trying to get logs from node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c pod pod-2b73a560-d7a3-44d1-bd42-beba6a5f5653 container test-container: <nil>
STEP: delete the pod
Nov 13 11:08:14.126: INFO: Waiting for pod pod-2b73a560-d7a3-44d1-bd42-beba6a5f5653 to disappear
Nov 13 11:08:14.132: INFO: Pod pod-2b73a560-d7a3-44d1-bd42-beba6a5f5653 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:08:14.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9714" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":256,"skipped":4151,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:08:14.136: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7736
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-configmap-lwth
STEP: Creating a pod to test atomic-volume-subpath
Nov 13 11:08:14.267: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-lwth" in namespace "subpath-7736" to be "success or failure"
Nov 13 11:08:14.275: INFO: Pod "pod-subpath-test-configmap-lwth": Phase="Pending", Reason="", readiness=false. Elapsed: 7.797915ms
Nov 13 11:08:16.277: INFO: Pod "pod-subpath-test-configmap-lwth": Phase="Running", Reason="", readiness=true. Elapsed: 2.009839364s
Nov 13 11:08:18.278: INFO: Pod "pod-subpath-test-configmap-lwth": Phase="Running", Reason="", readiness=true. Elapsed: 4.011672417s
Nov 13 11:08:20.280: INFO: Pod "pod-subpath-test-configmap-lwth": Phase="Running", Reason="", readiness=true. Elapsed: 6.013592775s
Nov 13 11:08:22.284: INFO: Pod "pod-subpath-test-configmap-lwth": Phase="Running", Reason="", readiness=true. Elapsed: 8.016762594s
Nov 13 11:08:24.286: INFO: Pod "pod-subpath-test-configmap-lwth": Phase="Running", Reason="", readiness=true. Elapsed: 10.018827s
Nov 13 11:08:26.287: INFO: Pod "pod-subpath-test-configmap-lwth": Phase="Running", Reason="", readiness=true. Elapsed: 12.02068054s
Nov 13 11:08:28.290: INFO: Pod "pod-subpath-test-configmap-lwth": Phase="Running", Reason="", readiness=true. Elapsed: 14.022753978s
Nov 13 11:08:30.300: INFO: Pod "pod-subpath-test-configmap-lwth": Phase="Running", Reason="", readiness=true. Elapsed: 16.03354123s
Nov 13 11:08:32.303: INFO: Pod "pod-subpath-test-configmap-lwth": Phase="Running", Reason="", readiness=true. Elapsed: 18.035798958s
Nov 13 11:08:34.305: INFO: Pod "pod-subpath-test-configmap-lwth": Phase="Running", Reason="", readiness=true. Elapsed: 20.037786341s
Nov 13 11:08:36.307: INFO: Pod "pod-subpath-test-configmap-lwth": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.039843553s
STEP: Saw pod success
Nov 13 11:08:36.307: INFO: Pod "pod-subpath-test-configmap-lwth" satisfied condition "success or failure"
Nov 13 11:08:36.308: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-subpath-test-configmap-lwth container test-container-subpath-configmap-lwth: <nil>
STEP: delete the pod
Nov 13 11:08:36.329: INFO: Waiting for pod pod-subpath-test-configmap-lwth to disappear
Nov 13 11:08:36.331: INFO: Pod pod-subpath-test-configmap-lwth no longer exists
STEP: Deleting pod pod-subpath-test-configmap-lwth
Nov 13 11:08:36.331: INFO: Deleting pod "pod-subpath-test-configmap-lwth" in namespace "subpath-7736"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:08:36.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7736" for this suite.

• [SLOW TEST:22.200 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":278,"completed":257,"skipped":4183,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:08:36.337: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7779
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service nodeport-test with type=NodePort in namespace services-7779
STEP: creating replication controller nodeport-test in namespace services-7779
I1113 11:08:36.478095      20 runners.go:189] Created replication controller with name: nodeport-test, namespace: services-7779, replica count: 2
I1113 11:08:39.528478      20 runners.go:189] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 13 11:08:39.528: INFO: Creating new exec pod
Nov 13 11:08:42.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-7779 execpodktzhf -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Nov 13 11:08:42.689: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov 13 11:08:42.689: INFO: stdout: ""
Nov 13 11:08:42.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-7779 execpodktzhf -- /bin/sh -x -c nc -zv -t -w 2 10.100.200.198 80'
Nov 13 11:08:42.820: INFO: stderr: "+ nc -zv -t -w 2 10.100.200.198 80\nConnection to 10.100.200.198 80 port [tcp/http] succeeded!\n"
Nov 13 11:08:42.820: INFO: stdout: ""
Nov 13 11:08:42.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-7779 execpodktzhf -- /bin/sh -x -c nc -zv -t -w 2 10.95.32.12 31381'
Nov 13 11:08:42.948: INFO: stderr: "+ nc -zv -t -w 2 10.95.32.12 31381\nConnection to 10.95.32.12 31381 port [tcp/31381] succeeded!\n"
Nov 13 11:08:42.948: INFO: stdout: ""
Nov 13 11:08:42.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-7779 execpodktzhf -- /bin/sh -x -c nc -zv -t -w 2 10.95.32.13 31381'
Nov 13 11:08:43.079: INFO: stderr: "+ nc -zv -t -w 2 10.95.32.13 31381\nConnection to 10.95.32.13 31381 port [tcp/31381] succeeded!\n"
Nov 13 11:08:43.079: INFO: stdout: ""
Nov 13 11:08:43.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-7779 execpodktzhf -- /bin/sh -x -c nc -zv -t -w 2 10.95.32.12 31381'
Nov 13 11:08:43.228: INFO: stderr: "+ nc -zv -t -w 2 10.95.32.12 31381\nConnection to 10.95.32.12 31381 port [tcp/31381] succeeded!\n"
Nov 13 11:08:43.228: INFO: stdout: ""
Nov 13 11:08:43.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-7779 execpodktzhf -- /bin/sh -x -c nc -zv -t -w 2 10.95.32.13 31381'
Nov 13 11:08:43.353: INFO: stderr: "+ nc -zv -t -w 2 10.95.32.13 31381\nConnection to 10.95.32.13 31381 port [tcp/31381] succeeded!\n"
Nov 13 11:08:43.353: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:08:43.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7779" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:7.021 seconds]
[sig-network] Services
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":278,"completed":258,"skipped":4226,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:08:43.358: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3979
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:324
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the initial replication controller
Nov 13 11:08:43.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 create -f - --namespace=kubectl-3979'
Nov 13 11:08:43.654: INFO: stderr: ""
Nov 13 11:08:43.654: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 13 11:08:43.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3979'
Nov 13 11:08:43.711: INFO: stderr: ""
Nov 13 11:08:43.711: INFO: stdout: "update-demo-nautilus-bjdcd update-demo-nautilus-nrx97 "
Nov 13 11:08:43.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-bjdcd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3979'
Nov 13 11:08:43.759: INFO: stderr: ""
Nov 13 11:08:43.759: INFO: stdout: ""
Nov 13 11:08:43.759: INFO: update-demo-nautilus-bjdcd is created but not running
Nov 13 11:08:48.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3979'
Nov 13 11:08:48.828: INFO: stderr: ""
Nov 13 11:08:48.828: INFO: stdout: "update-demo-nautilus-bjdcd update-demo-nautilus-nrx97 "
Nov 13 11:08:48.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-bjdcd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3979'
Nov 13 11:08:48.884: INFO: stderr: ""
Nov 13 11:08:48.884: INFO: stdout: "true"
Nov 13 11:08:48.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-bjdcd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3979'
Nov 13 11:08:48.933: INFO: stderr: ""
Nov 13 11:08:48.933: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 11:08:48.933: INFO: validating pod update-demo-nautilus-bjdcd
Nov 13 11:08:48.936: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 11:08:48.936: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 11:08:48.936: INFO: update-demo-nautilus-bjdcd is verified up and running
Nov 13 11:08:48.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-nrx97 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3979'
Nov 13 11:08:48.990: INFO: stderr: ""
Nov 13 11:08:48.990: INFO: stdout: "true"
Nov 13 11:08:48.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-nautilus-nrx97 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3979'
Nov 13 11:08:49.049: INFO: stderr: ""
Nov 13 11:08:49.049: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 13 11:08:49.049: INFO: validating pod update-demo-nautilus-nrx97
Nov 13 11:08:49.051: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 13 11:08:49.051: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 13 11:08:49.051: INFO: update-demo-nautilus-nrx97 is verified up and running
STEP: rolling-update to new replication controller
Nov 13 11:08:49.052: INFO: scanned /root for discovery docs: <nil>
Nov 13 11:08:49.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3979'
Nov 13 11:09:11.361: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov 13 11:09:11.361: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 13 11:09:11.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3979'
Nov 13 11:09:11.408: INFO: stderr: ""
Nov 13 11:09:11.408: INFO: stdout: "update-demo-kitten-l4zbm update-demo-kitten-zggcr "
Nov 13 11:09:11.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-kitten-l4zbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3979'
Nov 13 11:09:11.463: INFO: stderr: ""
Nov 13 11:09:11.463: INFO: stdout: "true"
Nov 13 11:09:11.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-kitten-l4zbm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3979'
Nov 13 11:09:11.519: INFO: stderr: ""
Nov 13 11:09:11.519: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov 13 11:09:11.519: INFO: validating pod update-demo-kitten-l4zbm
Nov 13 11:09:11.521: INFO: got data: {
  "image": "kitten.jpg"
}

Nov 13 11:09:11.521: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov 13 11:09:11.521: INFO: update-demo-kitten-l4zbm is verified up and running
Nov 13 11:09:11.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-kitten-zggcr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3979'
Nov 13 11:09:11.570: INFO: stderr: ""
Nov 13 11:09:11.570: INFO: stdout: "true"
Nov 13 11:09:11.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 get pods update-demo-kitten-zggcr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3979'
Nov 13 11:09:11.619: INFO: stderr: ""
Nov 13 11:09:11.619: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov 13 11:09:11.619: INFO: validating pod update-demo-kitten-zggcr
Nov 13 11:09:11.621: INFO: got data: {
  "image": "kitten.jpg"
}

Nov 13 11:09:11.621: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov 13 11:09:11.621: INFO: update-demo-kitten-zggcr is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:09:11.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3979" for this suite.

• [SLOW TEST:28.267 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:322
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should do a rolling update of a replication controller  [Conformance]","total":278,"completed":259,"skipped":4257,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:09:11.626: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7673
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov 13 11:09:11.756: INFO: Waiting up to 5m0s for pod "pod-54f55756-eb36-4319-8b9d-76add7130229" in namespace "emptydir-7673" to be "success or failure"
Nov 13 11:09:11.759: INFO: Pod "pod-54f55756-eb36-4319-8b9d-76add7130229": Phase="Pending", Reason="", readiness=false. Elapsed: 3.65566ms
Nov 13 11:09:13.761: INFO: Pod "pod-54f55756-eb36-4319-8b9d-76add7130229": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005494253s
STEP: Saw pod success
Nov 13 11:09:13.761: INFO: Pod "pod-54f55756-eb36-4319-8b9d-76add7130229" satisfied condition "success or failure"
Nov 13 11:09:13.762: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-54f55756-eb36-4319-8b9d-76add7130229 container test-container: <nil>
STEP: delete the pod
Nov 13 11:09:13.771: INFO: Waiting for pod pod-54f55756-eb36-4319-8b9d-76add7130229 to disappear
Nov 13 11:09:13.777: INFO: Pod pod-54f55756-eb36-4319-8b9d-76add7130229 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:09:13.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7673" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":260,"skipped":4258,"failed":0}

------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:09:13.781: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-2677
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Nov 13 11:09:13.902: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the sample API server.
Nov 13 11:09:14.170: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Nov 13 11:09:16.203: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 11:09:18.205: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 11:09:20.205: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 11:09:22.205: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 11:09:24.205: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 11:09:26.205: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 11:09:28.204: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 11:09:30.207: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 11:09:32.206: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740862554, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 13 11:09:34.947: INFO: Waited 735.922464ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:09:35.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2677" for this suite.

• [SLOW TEST:22.044 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]","total":278,"completed":261,"skipped":4258,"failed":0}
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:09:35.826: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7263
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:09:48.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7263" for this suite.

• [SLOW TEST:13.166 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":278,"completed":262,"skipped":4258,"failed":0}
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:09:48.992: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6538
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-6538
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a new StatefulSet
Nov 13 11:09:49.133: INFO: Found 0 stateful pods, waiting for 3
Nov 13 11:09:59.135: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 11:09:59.135: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 11:09:59.135: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov 13 11:09:59.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-6538 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 13 11:09:59.273: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 13 11:09:59.273: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 13 11:09:59.273: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov 13 11:10:09.294: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov 13 11:10:19.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-6538 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 13 11:10:19.440: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 13 11:10:19.440: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 13 11:10:19.440: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 13 11:10:29.449: INFO: Waiting for StatefulSet statefulset-6538/ss2 to complete update
Nov 13 11:10:29.449: INFO: Waiting for Pod statefulset-6538/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 13 11:10:39.453: INFO: Waiting for StatefulSet statefulset-6538/ss2 to complete update
STEP: Rolling back to a previous revision
Nov 13 11:10:49.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-6538 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 13 11:10:49.563: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 13 11:10:49.563: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 13 11:10:49.563: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 13 11:10:59.587: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov 13 11:11:09.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=statefulset-6538 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 13 11:11:09.727: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 13 11:11:09.727: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 13 11:11:09.727: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 13 11:11:19.736: INFO: Waiting for StatefulSet statefulset-6538/ss2 to complete update
Nov 13 11:11:19.736: INFO: Waiting for Pod statefulset-6538/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov 13 11:11:19.736: INFO: Waiting for Pod statefulset-6538/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Nov 13 11:11:29.740: INFO: Deleting all statefulset in ns statefulset-6538
Nov 13 11:11:29.741: INFO: Scaling statefulset ss2 to 0
Nov 13 11:11:39.750: INFO: Waiting for statefulset status.replicas updated to 0
Nov 13 11:11:39.751: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:11:39.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6538" for this suite.

• [SLOW TEST:110.771 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":278,"completed":263,"skipped":4265,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:11:39.765: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6452
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:11:42.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6452" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":278,"completed":264,"skipped":4293,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:11:42.911: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-640
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Nov 13 11:11:43.034: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 13 11:11:43.040: INFO: Waiting for terminating namespaces to be deleted...
Nov 13 11:11:43.041: INFO: 
Logging pods the kubelet thinks is on node 29607307-5497-41cc-a8d5-c2f7d9a90e41 before test
Nov 13 11:11:43.049: INFO: metrics-server-5df78f85b-kzd6m from kube-system started at 2020-11-12 01:07:27 +0000 UTC (1 container statuses recorded)
Nov 13 11:11:43.049: INFO: 	Container metrics-server ready: true, restart count 0
Nov 13 11:11:43.049: INFO: filebeat-chjmw from kube-system started at 2020-11-12 01:08:33 +0000 UTC (1 container statuses recorded)
Nov 13 11:11:43.049: INFO: 	Container filebeat ready: true, restart count 0
Nov 13 11:11:43.049: INFO: pod-adoption from replication-controller-6452 started at 2020-11-13 11:11:39 +0000 UTC (1 container statuses recorded)
Nov 13 11:11:43.049: INFO: 	Container pod-adoption ready: true, restart count 0
Nov 13 11:11:43.049: INFO: coredns-54b9777bfc-nhhjt from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 11:11:43.050: INFO: 	Container coredns ready: true, restart count 0
Nov 13 11:11:43.050: INFO: sonobuoy from sonobuoy started at 2020-11-13 09:37:07 +0000 UTC (1 container statuses recorded)
Nov 13 11:11:43.050: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 13 11:11:43.050: INFO: traefik-ingress-controller-v48l8 from traefik-ingress started at 2020-11-12 01:09:03 +0000 UTC (1 container statuses recorded)
Nov 13 11:11:43.050: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov 13 11:11:43.050: INFO: sonobuoy-systemd-logs-daemon-set-294e69fb102c4fcf-tncdk from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 11:11:43.050: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 11:11:43.050: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 13 11:11:43.050: INFO: 
Logging pods the kubelet thinks is on node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c before test
Nov 13 11:11:43.058: INFO: filebeat-zxtp6 from kube-system started at 2020-11-12 01:08:33 +0000 UTC (1 container statuses recorded)
Nov 13 11:11:43.058: INFO: 	Container filebeat ready: true, restart count 0
Nov 13 11:11:43.058: INFO: coredns-54b9777bfc-q6tzp from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 11:11:43.058: INFO: 	Container coredns ready: true, restart count 0
Nov 13 11:11:43.058: INFO: sonobuoy-systemd-logs-daemon-set-294e69fb102c4fcf-fk6ph from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 11:11:43.058: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 11:11:43.058: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 13 11:11:43.058: INFO: coredns-54b9777bfc-jj6kl from kube-system started at 2020-11-12 01:07:18 +0000 UTC (1 container statuses recorded)
Nov 13 11:11:43.058: INFO: 	Container coredns ready: true, restart count 0
Nov 13 11:11:43.058: INFO: sonobuoy-e2e-job-b8fa8fc01c7d4f11 from sonobuoy started at 2020-11-13 10:19:19 +0000 UTC (2 container statuses recorded)
Nov 13 11:11:43.058: INFO: 	Container e2e ready: true, restart count 0
Nov 13 11:11:43.058: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 13 11:11:43.058: INFO: traefik-ingress-controller-xbfqn from traefik-ingress started at 2020-11-12 01:09:03 +0000 UTC (1 container statuses recorded)
Nov 13 11:11:43.058: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-5482f7ae-95bd-4563-93b1-8116f5fe8f35 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-5482f7ae-95bd-4563-93b1-8116f5fe8f35 off the node 29607307-5497-41cc-a8d5-c2f7d9a90e41
STEP: verifying the node doesn't have the label kubernetes.io/e2e-5482f7ae-95bd-4563-93b1-8116f5fe8f35
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:16:47.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-640" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77

• [SLOW TEST:304.242 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":278,"completed":265,"skipped":4346,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:16:47.153: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-187
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 11:16:47.284: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov 13 11:16:47.289: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 13 11:16:52.296: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 13 11:16:52.296: INFO: Creating deployment "test-rolling-update-deployment"
Nov 13 11:16:52.305: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov 13 11:16:52.314: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov 13 11:16:54.318: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov 13 11:16:54.319: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Nov 13 11:16:54.324: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-187 /apis/apps/v1/namespaces/deployment-187/deployments/test-rolling-update-deployment 9b8ceb5d-b581-4874-b404-ecdef91e8e53 318401 1 2020-11-13 11:16:52 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004694838 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-11-13 11:16:52 +0000 UTC,LastTransitionTime:2020-11-13 11:16:52 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-67cf4f6444" has successfully progressed.,LastUpdateTime:2020-11-13 11:16:53 +0000 UTC,LastTransitionTime:2020-11-13 11:16:52 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 13 11:16:54.326: INFO: New ReplicaSet "test-rolling-update-deployment-67cf4f6444" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-67cf4f6444  deployment-187 /apis/apps/v1/namespaces/deployment-187/replicasets/test-rolling-update-deployment-67cf4f6444 47681bd7-1f1a-48c5-96cb-6a967a94a82f 318390 1 2020-11-13 11:16:52 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 9b8ceb5d-b581-4874-b404-ecdef91e8e53 0xc004694cf7 0xc004694cf8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67cf4f6444,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004694d68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 13 11:16:54.326: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov 13 11:16:54.326: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-187 /apis/apps/v1/namespaces/deployment-187/replicasets/test-rolling-update-controller 708708d2-8b90-44b0-928f-677a9a480781 318400 2 2020-11-13 11:16:47 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 9b8ceb5d-b581-4874-b404-ecdef91e8e53 0xc004694c27 0xc004694c28}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004694c88 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 13 11:16:54.328: INFO: Pod "test-rolling-update-deployment-67cf4f6444-s8v9x" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-67cf4f6444-s8v9x test-rolling-update-deployment-67cf4f6444- deployment-187 /api/v1/namespaces/deployment-187/pods/test-rolling-update-deployment-67cf4f6444-s8v9x 3445d9ba-33f8-4ffc-8a6b-05e951d4cf7e 318389 0 2020-11-13 11:16:52 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-67cf4f6444 47681bd7-1f1a-48c5-96cb-6a967a94a82f 0xc004695657 0xc004695658}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-5svss,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-5svss,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-5svss,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:53f793a7-f5c9-4f32-8dff-29ce2b6c347c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:16:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:16:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:16:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-13 11:16:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.95.32.13,PodIP:10.200.43.41,StartTime:2020-11-13 11:16:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-13 11:16:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5,ContainerID:docker://8300cebbdc45fbe80b49c73c1aac707a2e620b4cb2cb67243e2a22864cce5238,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.43.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:16:54.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-187" for this suite.

• [SLOW TEST:7.179 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":278,"completed":266,"skipped":4358,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:16:54.337: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7656
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 11:16:54.467: INFO: Waiting up to 5m0s for pod "downwardapi-volume-421c8662-d036-4316-a6e0-5a276016e5ec" in namespace "downward-api-7656" to be "success or failure"
Nov 13 11:16:54.482: INFO: Pod "downwardapi-volume-421c8662-d036-4316-a6e0-5a276016e5ec": Phase="Pending", Reason="", readiness=false. Elapsed: 14.750384ms
Nov 13 11:16:56.484: INFO: Pod "downwardapi-volume-421c8662-d036-4316-a6e0-5a276016e5ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016739749s
STEP: Saw pod success
Nov 13 11:16:56.484: INFO: Pod "downwardapi-volume-421c8662-d036-4316-a6e0-5a276016e5ec" satisfied condition "success or failure"
Nov 13 11:16:56.485: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-421c8662-d036-4316-a6e0-5a276016e5ec container client-container: <nil>
STEP: delete the pod
Nov 13 11:16:56.495: INFO: Waiting for pod downwardapi-volume-421c8662-d036-4316-a6e0-5a276016e5ec to disappear
Nov 13 11:16:56.500: INFO: Pod downwardapi-volume-421c8662-d036-4316-a6e0-5a276016e5ec no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:16:56.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7656" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":278,"completed":267,"skipped":4394,"failed":0}

------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:16:56.505: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7875
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-8bf29fe8-2568-4d91-9ab3-68893c6143de
STEP: Creating a pod to test consume secrets
Nov 13 11:16:56.635: INFO: Waiting up to 5m0s for pod "pod-secrets-23948a0c-11d6-4ed0-ad8b-ef88565491f5" in namespace "secrets-7875" to be "success or failure"
Nov 13 11:16:56.643: INFO: Pod "pod-secrets-23948a0c-11d6-4ed0-ad8b-ef88565491f5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013428ms
Nov 13 11:16:58.645: INFO: Pod "pod-secrets-23948a0c-11d6-4ed0-ad8b-ef88565491f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009933235s
STEP: Saw pod success
Nov 13 11:16:58.646: INFO: Pod "pod-secrets-23948a0c-11d6-4ed0-ad8b-ef88565491f5" satisfied condition "success or failure"
Nov 13 11:16:58.648: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-secrets-23948a0c-11d6-4ed0-ad8b-ef88565491f5 container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 11:16:58.657: INFO: Waiting for pod pod-secrets-23948a0c-11d6-4ed0-ad8b-ef88565491f5 to disappear
Nov 13 11:16:58.662: INFO: Pod pod-secrets-23948a0c-11d6-4ed0-ad8b-ef88565491f5 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:16:58.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7875" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":278,"completed":268,"skipped":4394,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:16:58.669: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7877
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-d0f5b5be-31b1-4dba-b3cd-fd195bd92323
STEP: Creating a pod to test consume secrets
Nov 13 11:16:58.810: INFO: Waiting up to 5m0s for pod "pod-secrets-b40ac834-cef8-4d8e-a595-3143eec788ad" in namespace "secrets-7877" to be "success or failure"
Nov 13 11:16:58.817: INFO: Pod "pod-secrets-b40ac834-cef8-4d8e-a595-3143eec788ad": Phase="Pending", Reason="", readiness=false. Elapsed: 6.883654ms
Nov 13 11:17:00.819: INFO: Pod "pod-secrets-b40ac834-cef8-4d8e-a595-3143eec788ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009036119s
STEP: Saw pod success
Nov 13 11:17:00.819: INFO: Pod "pod-secrets-b40ac834-cef8-4d8e-a595-3143eec788ad" satisfied condition "success or failure"
Nov 13 11:17:00.820: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod pod-secrets-b40ac834-cef8-4d8e-a595-3143eec788ad container secret-volume-test: <nil>
STEP: delete the pod
Nov 13 11:17:00.831: INFO: Waiting for pod pod-secrets-b40ac834-cef8-4d8e-a595-3143eec788ad to disappear
Nov 13 11:17:00.834: INFO: Pod pod-secrets-b40ac834-cef8-4d8e-a595-3143eec788ad no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:17:00.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7877" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":269,"skipped":4407,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:17:00.841: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7806
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name cm-test-opt-del-7145fc9a-f944-4c89-b940-a5493d17c5a2
STEP: Creating configMap with name cm-test-opt-upd-6b33fdcc-30e8-4fa4-a5a0-476276d4d100
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-7145fc9a-f944-4c89-b940-a5493d17c5a2
STEP: Updating configmap cm-test-opt-upd-6b33fdcc-30e8-4fa4-a5a0-476276d4d100
STEP: Creating configMap with name cm-test-opt-create-8dffe4a2-bcfe-4060-b5f3-41e0f876b213
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:17:05.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7806" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":278,"completed":270,"skipped":4415,"failed":0}

------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:17:05.040: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9059
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov 13 11:17:05.579: INFO: Waiting up to 5m0s for pod "pod-6b17ccb4-083f-47c2-a17a-5fad567d4922" in namespace "emptydir-9059" to be "success or failure"
Nov 13 11:17:05.589: INFO: Pod "pod-6b17ccb4-083f-47c2-a17a-5fad567d4922": Phase="Pending", Reason="", readiness=false. Elapsed: 10.515506ms
Nov 13 11:17:07.591: INFO: Pod "pod-6b17ccb4-083f-47c2-a17a-5fad567d4922": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012536093s
STEP: Saw pod success
Nov 13 11:17:07.592: INFO: Pod "pod-6b17ccb4-083f-47c2-a17a-5fad567d4922" satisfied condition "success or failure"
Nov 13 11:17:07.593: INFO: Trying to get logs from node 53f793a7-f5c9-4f32-8dff-29ce2b6c347c pod pod-6b17ccb4-083f-47c2-a17a-5fad567d4922 container test-container: <nil>
STEP: delete the pod
Nov 13 11:17:07.608: INFO: Waiting for pod pod-6b17ccb4-083f-47c2-a17a-5fad567d4922 to disappear
Nov 13 11:17:07.618: INFO: Pod pod-6b17ccb4-083f-47c2-a17a-5fad567d4922 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:17:07.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9059" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":271,"skipped":4415,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:17:07.625: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1810
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service nodeport-service with the type=NodePort in namespace services-1810
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-1810
STEP: creating replication controller externalsvc in namespace services-1810
I1113 11:17:07.821969      20 runners.go:189] Created replication controller with name: externalsvc, namespace: services-1810, replica count: 2
I1113 11:17:10.872469      20 runners.go:189] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Nov 13 11:17:10.884: INFO: Creating new exec pod
Nov 13 11:17:12.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 exec --namespace=services-1810 execpodwf24h -- /bin/sh -x -c nslookup nodeport-service'
Nov 13 11:17:13.653: INFO: stderr: "+ nslookup nodeport-service\n"
Nov 13 11:17:13.653: INFO: stdout: "Server:\t\t10.100.200.10\nAddress:\t10.100.200.10#53\n\nnodeport-service.services-1810.svc.cluster.local\tcanonical name = externalsvc.services-1810.svc.cluster.local.\nName:\texternalsvc.services-1810.svc.cluster.local\nAddress: 10.100.200.15\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1810, will wait for the garbage collector to delete the pods
Nov 13 11:17:13.711: INFO: Deleting ReplicationController externalsvc took: 5.516302ms
Nov 13 11:17:13.811: INFO: Terminating ReplicationController externalsvc pods took: 100.167467ms
Nov 13 11:17:28.821: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:17:28.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1810" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:21.213 seconds]
[sig-network] Services
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":278,"completed":272,"skipped":4459,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:17:28.840: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 11:17:28.966: INFO: Waiting up to 5m0s for pod "downwardapi-volume-77cd489e-0293-4385-a408-40d2cbbfc9e4" in namespace "projected-1583" to be "success or failure"
Nov 13 11:17:28.974: INFO: Pod "downwardapi-volume-77cd489e-0293-4385-a408-40d2cbbfc9e4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.666232ms
Nov 13 11:17:30.976: INFO: Pod "downwardapi-volume-77cd489e-0293-4385-a408-40d2cbbfc9e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009495361s
STEP: Saw pod success
Nov 13 11:17:30.976: INFO: Pod "downwardapi-volume-77cd489e-0293-4385-a408-40d2cbbfc9e4" satisfied condition "success or failure"
Nov 13 11:17:30.977: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-77cd489e-0293-4385-a408-40d2cbbfc9e4 container client-container: <nil>
STEP: delete the pod
Nov 13 11:17:30.986: INFO: Waiting for pod downwardapi-volume-77cd489e-0293-4385-a408-40d2cbbfc9e4 to disappear
Nov 13 11:17:30.991: INFO: Pod downwardapi-volume-77cd489e-0293-4385-a408-40d2cbbfc9e4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:17:30.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1583" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":278,"completed":273,"skipped":4466,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:17:30.995: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8552
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:17:33.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8552" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":278,"completed":274,"skipped":4475,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:17:33.141: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-575
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov 13 11:17:33.266: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:17:34.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-575" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":278,"completed":275,"skipped":4481,"failed":0}
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:17:34.375: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1933
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov 13 11:17:34.504: INFO: Waiting up to 5m0s for pod "downwardapi-volume-10c6cdf8-2bf1-4d0d-b078-f0b717759ac0" in namespace "downward-api-1933" to be "success or failure"
Nov 13 11:17:34.512: INFO: Pod "downwardapi-volume-10c6cdf8-2bf1-4d0d-b078-f0b717759ac0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.106142ms
Nov 13 11:17:36.514: INFO: Pod "downwardapi-volume-10c6cdf8-2bf1-4d0d-b078-f0b717759ac0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009810168s
STEP: Saw pod success
Nov 13 11:17:36.514: INFO: Pod "downwardapi-volume-10c6cdf8-2bf1-4d0d-b078-f0b717759ac0" satisfied condition "success or failure"
Nov 13 11:17:36.516: INFO: Trying to get logs from node 29607307-5497-41cc-a8d5-c2f7d9a90e41 pod downwardapi-volume-10c6cdf8-2bf1-4d0d-b078-f0b717759ac0 container client-container: <nil>
STEP: delete the pod
Nov 13 11:17:36.525: INFO: Waiting for pod downwardapi-volume-10c6cdf8-2bf1-4d0d-b078-f0b717759ac0 to disappear
Nov 13 11:17:36.531: INFO: Pod downwardapi-volume-10c6cdf8-2bf1-4d0d-b078-f0b717759ac0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:17:36.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1933" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":278,"completed":276,"skipped":4487,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:17:36.535: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5222
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: executing a command with run --rm and attach with stdin
Nov 13 11:17:36.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-258392779 --namespace=kubectl-5222 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov 13 11:17:38.565: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov 13 11:17:38.565: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:17:40.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5222" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run --rm job should create a job from an image, then delete the job  [Conformance]","total":278,"completed":277,"skipped":4527,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 13 11:17:40.572: INFO: >>> kubeConfig: /tmp/kubeconfig-258392779
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2250
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 13 11:17:57.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2250" for this suite.

• [SLOW TEST:17.148 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":278,"completed":278,"skipped":4562,"failed":0}
SSSNov 13 11:17:57.721: INFO: Running AfterSuite actions on all nodes
Nov 13 11:17:57.721: INFO: Running AfterSuite actions on node 1
Nov 13 11:17:57.721: INFO: Skipping dumping logs from cluster
{"msg":"Test Suite completed","total":278,"completed":278,"skipped":4565,"failed":0}

Ran 278 of 4843 Specs in 3477.455 seconds
SUCCESS! -- 278 Passed | 0 Failed | 0 Pending | 4565 Skipped
PASS

Ginkgo ran 1 suite in 57m58.504564556s
Test Suite Passed

I0818 17:08:43.253324      23 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-434562375
I0818 17:08:43.253465      23 e2e.go:92] Starting e2e run "1c079d05-ffe1-4524-ac00-98c48b911240" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1597770521 - Will randomize all specs
Will run 276 of 4847 specs

Aug 18 17:08:43.266: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 17:08:43.269: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 18 17:08:43.316: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 18 17:08:43.389: INFO: 22 / 22 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 18 17:08:43.389: INFO: expected 13 pod replicas in namespace 'kube-system', 13 are Running and Ready.
Aug 18 17:08:43.389: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 18 17:08:43.412: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Aug 18 17:08:43.412: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Aug 18 17:08:43.412: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Aug 18 17:08:43.412: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Aug 18 17:08:43.412: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Aug 18 17:08:43.412: INFO: e2e test version: v1.16.14
Aug 18 17:08:43.421: INFO: kube-apiserver version: v1.16.14+IKS
Aug 18 17:08:43.421: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 17:08:43.444: INFO: Cluster IP family: ipv4
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:08:43.445: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
Aug 18 17:08:43.551: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Aug 18 17:08:43.602: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8898
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-f588d916-2c94-4782-8c9a-c0ea53fb8897
STEP: Creating a pod to test consume secrets
Aug 18 17:08:43.775: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2aad81c4-4c0c-4b33-9297-5e8772a293ee" in namespace "projected-8898" to be "success or failure"
Aug 18 17:08:43.796: INFO: Pod "pod-projected-secrets-2aad81c4-4c0c-4b33-9297-5e8772a293ee": Phase="Pending", Reason="", readiness=false. Elapsed: 20.978833ms
Aug 18 17:08:45.808: INFO: Pod "pod-projected-secrets-2aad81c4-4c0c-4b33-9297-5e8772a293ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033002084s
Aug 18 17:08:47.905: INFO: Pod "pod-projected-secrets-2aad81c4-4c0c-4b33-9297-5e8772a293ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.129734345s
STEP: Saw pod success
Aug 18 17:08:47.905: INFO: Pod "pod-projected-secrets-2aad81c4-4c0c-4b33-9297-5e8772a293ee" satisfied condition "success or failure"
Aug 18 17:08:47.918: INFO: Trying to get logs from node 10.241.69.181 pod pod-projected-secrets-2aad81c4-4c0c-4b33-9297-5e8772a293ee container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 18 17:08:48.046: INFO: Waiting for pod pod-projected-secrets-2aad81c4-4c0c-4b33-9297-5e8772a293ee to disappear
Aug 18 17:08:48.061: INFO: Pod pod-projected-secrets-2aad81c4-4c0c-4b33-9297-5e8772a293ee no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:08:48.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8898" for this suite.
Aug 18 17:08:54.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:08:54.543: INFO: namespace projected-8898 deletion completed in 6.469976835s

• [SLOW TEST:11.099 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:08:54.544: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6568
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 18 17:08:58.858: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:08:58.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6568" for this suite.
Aug 18 17:09:04.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:09:05.442: INFO: namespace container-runtime-6568 deletion completed in 6.522253808s

• [SLOW TEST:10.899 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:09:05.444: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3265
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-c0d10837-d76c-4261-af92-0db5342476bb
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:09:09.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3265" for this suite.
Aug 18 17:09:21.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:09:22.342: INFO: namespace configmap-3265 deletion completed in 12.463816553s

• [SLOW TEST:16.898 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:09:22.343: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-527
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Aug 18 17:09:22.583: INFO: Waiting up to 5m0s for pod "downward-api-9e754842-99c3-4f4a-9210-db2e920e60ee" in namespace "downward-api-527" to be "success or failure"
Aug 18 17:09:22.594: INFO: Pod "downward-api-9e754842-99c3-4f4a-9210-db2e920e60ee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.255922ms
Aug 18 17:09:24.606: INFO: Pod "downward-api-9e754842-99c3-4f4a-9210-db2e920e60ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02262884s
STEP: Saw pod success
Aug 18 17:09:24.606: INFO: Pod "downward-api-9e754842-99c3-4f4a-9210-db2e920e60ee" satisfied condition "success or failure"
Aug 18 17:09:24.616: INFO: Trying to get logs from node 10.241.69.181 pod downward-api-9e754842-99c3-4f4a-9210-db2e920e60ee container dapi-container: <nil>
STEP: delete the pod
Aug 18 17:09:24.679: INFO: Waiting for pod downward-api-9e754842-99c3-4f4a-9210-db2e920e60ee to disappear
Aug 18 17:09:24.700: INFO: Pod downward-api-9e754842-99c3-4f4a-9210-db2e920e60ee no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:09:24.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-527" for this suite.
Aug 18 17:09:30.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:09:31.192: INFO: namespace downward-api-527 deletion completed in 6.477356264s

• [SLOW TEST:8.849 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:09:31.192: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-246
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:09:31.434: INFO: Waiting up to 5m0s for pod "busybox-user-65534-af96a11b-4856-4017-9d52-73ea46689ea8" in namespace "security-context-test-246" to be "success or failure"
Aug 18 17:09:31.446: INFO: Pod "busybox-user-65534-af96a11b-4856-4017-9d52-73ea46689ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.214591ms
Aug 18 17:09:33.458: INFO: Pod "busybox-user-65534-af96a11b-4856-4017-9d52-73ea46689ea8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024483617s
Aug 18 17:09:35.470: INFO: Pod "busybox-user-65534-af96a11b-4856-4017-9d52-73ea46689ea8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036035279s
Aug 18 17:09:35.470: INFO: Pod "busybox-user-65534-af96a11b-4856-4017-9d52-73ea46689ea8" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:09:35.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-246" for this suite.
Aug 18 17:09:41.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:09:41.967: INFO: namespace security-context-test-246 deletion completed in 6.483787193s

• [SLOW TEST:10.775 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:09:41.970: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2331
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 17:09:42.227: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f782fcd5-2f40-49ea-b03a-62fd71876bc5" in namespace "downward-api-2331" to be "success or failure"
Aug 18 17:09:42.242: INFO: Pod "downwardapi-volume-f782fcd5-2f40-49ea-b03a-62fd71876bc5": Phase="Pending", Reason="", readiness=false. Elapsed: 15.393683ms
Aug 18 17:09:44.254: INFO: Pod "downwardapi-volume-f782fcd5-2f40-49ea-b03a-62fd71876bc5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026788089s
Aug 18 17:09:46.270: INFO: Pod "downwardapi-volume-f782fcd5-2f40-49ea-b03a-62fd71876bc5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043422123s
STEP: Saw pod success
Aug 18 17:09:46.270: INFO: Pod "downwardapi-volume-f782fcd5-2f40-49ea-b03a-62fd71876bc5" satisfied condition "success or failure"
Aug 18 17:09:46.282: INFO: Trying to get logs from node 10.241.69.184 pod downwardapi-volume-f782fcd5-2f40-49ea-b03a-62fd71876bc5 container client-container: <nil>
STEP: delete the pod
Aug 18 17:09:46.379: INFO: Waiting for pod downwardapi-volume-f782fcd5-2f40-49ea-b03a-62fd71876bc5 to disappear
Aug 18 17:09:46.389: INFO: Pod downwardapi-volume-f782fcd5-2f40-49ea-b03a-62fd71876bc5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:09:46.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2331" for this suite.
Aug 18 17:09:52.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:09:52.840: INFO: namespace downward-api-2331 deletion completed in 6.436374245s

• [SLOW TEST:10.870 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:09:52.841: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8561
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 17:09:53.886: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 18 17:09:55.934: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367393, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367393, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367393, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367393, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 17:09:57.950: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367393, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367393, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367393, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367393, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 17:10:00.990: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:10:01.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8561" for this suite.
Aug 18 17:10:09.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:10:10.039: INFO: namespace webhook-8561 deletion completed in 8.48496227s
STEP: Destroying namespace "webhook-8561-markers" for this suite.
Aug 18 17:10:16.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:10:16.516: INFO: namespace webhook-8561-markers deletion completed in 6.476586401s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.736 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:10:16.581: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1851
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 18 17:10:21.392: INFO: Successfully updated pod "pod-update-fa2eccba-844b-48b7-82b0-0ad0a74c4c99"
STEP: verifying the updated pod is in kubernetes
Aug 18 17:10:21.417: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:10:21.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1851" for this suite.
Aug 18 17:10:33.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:10:33.897: INFO: namespace pods-1851 deletion completed in 12.464520035s

• [SLOW TEST:17.316 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:10:33.897: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5139
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 17:10:35.281: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 18 17:10:37.320: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367435, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367435, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367435, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367435, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 17:10:39.335: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367435, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367435, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367435, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367435, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 17:10:42.368: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:10:42.383: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8598-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:10:43.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5139" for this suite.
Aug 18 17:10:51.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:10:52.129: INFO: namespace webhook-5139 deletion completed in 8.432633922s
STEP: Destroying namespace "webhook-5139-markers" for this suite.
Aug 18 17:10:58.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:10:58.565: INFO: namespace webhook-5139-markers deletion completed in 6.436519326s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.728 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:10:58.626: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-896
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:11:20.889: INFO: Container started at 2020-08-18 17:11:00 +0000 UTC, pod became ready at 2020-08-18 17:11:20 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:11:20.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-896" for this suite.
Aug 18 17:11:32.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:11:33.381: INFO: namespace container-probe-896 deletion completed in 12.477162277s

• [SLOW TEST:34.756 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:11:33.385: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-201
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Aug 18 17:11:33.658: INFO: Waiting up to 5m0s for pod "client-containers-69367533-de5e-4ae0-aaa8-f2fa15244ae2" in namespace "containers-201" to be "success or failure"
Aug 18 17:11:33.676: INFO: Pod "client-containers-69367533-de5e-4ae0-aaa8-f2fa15244ae2": Phase="Pending", Reason="", readiness=false. Elapsed: 18.439454ms
Aug 18 17:11:35.689: INFO: Pod "client-containers-69367533-de5e-4ae0-aaa8-f2fa15244ae2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031423681s
Aug 18 17:11:37.702: INFO: Pod "client-containers-69367533-de5e-4ae0-aaa8-f2fa15244ae2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044555511s
STEP: Saw pod success
Aug 18 17:11:37.702: INFO: Pod "client-containers-69367533-de5e-4ae0-aaa8-f2fa15244ae2" satisfied condition "success or failure"
Aug 18 17:11:37.712: INFO: Trying to get logs from node 10.241.69.172 pod client-containers-69367533-de5e-4ae0-aaa8-f2fa15244ae2 container test-container: <nil>
STEP: delete the pod
Aug 18 17:11:37.815: INFO: Waiting for pod client-containers-69367533-de5e-4ae0-aaa8-f2fa15244ae2 to disappear
Aug 18 17:11:37.835: INFO: Pod client-containers-69367533-de5e-4ae0-aaa8-f2fa15244ae2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:11:37.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-201" for this suite.
Aug 18 17:11:43.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:11:44.297: INFO: namespace containers-201 deletion completed in 6.438411588s

• [SLOW TEST:10.912 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:11:44.297: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6843
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 17:11:44.543: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ece20b8-3189-44bb-ab21-41b5299cbb4c" in namespace "downward-api-6843" to be "success or failure"
Aug 18 17:11:44.554: INFO: Pod "downwardapi-volume-8ece20b8-3189-44bb-ab21-41b5299cbb4c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.791954ms
Aug 18 17:11:46.565: INFO: Pod "downwardapi-volume-8ece20b8-3189-44bb-ab21-41b5299cbb4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022462653s
STEP: Saw pod success
Aug 18 17:11:46.566: INFO: Pod "downwardapi-volume-8ece20b8-3189-44bb-ab21-41b5299cbb4c" satisfied condition "success or failure"
Aug 18 17:11:46.576: INFO: Trying to get logs from node 10.241.69.184 pod downwardapi-volume-8ece20b8-3189-44bb-ab21-41b5299cbb4c container client-container: <nil>
STEP: delete the pod
Aug 18 17:11:46.662: INFO: Waiting for pod downwardapi-volume-8ece20b8-3189-44bb-ab21-41b5299cbb4c to disappear
Aug 18 17:11:46.674: INFO: Pod downwardapi-volume-8ece20b8-3189-44bb-ab21-41b5299cbb4c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:11:46.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6843" for this suite.
Aug 18 17:11:52.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:11:53.382: INFO: namespace downward-api-6843 deletion completed in 6.68822615s

• [SLOW TEST:9.085 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:11:53.383: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8257
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 17:11:54.230: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 18 17:11:56.270: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367514, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367514, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367514, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367514, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 17:11:59.317: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:11:59.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8257" for this suite.
Aug 18 17:12:07.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:12:08.023: INFO: namespace webhook-8257 deletion completed in 8.431736713s
STEP: Destroying namespace "webhook-8257-markers" for this suite.
Aug 18 17:12:14.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:12:14.470: INFO: namespace webhook-8257-markers deletion completed in 6.446425495s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.149 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:12:14.533: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9174
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-9174
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 18 17:12:14.750: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 18 17:12:38.998: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.108.4:8080/dial?request=hostName&protocol=udp&host=172.30.104.171&port=8081&tries=1'] Namespace:pod-network-test-9174 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 17:12:38.998: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 17:12:39.173: INFO: Waiting for endpoints: map[]
Aug 18 17:12:39.184: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.108.4:8080/dial?request=hostName&protocol=udp&host=172.30.108.3&port=8081&tries=1'] Namespace:pod-network-test-9174 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 17:12:39.184: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 17:12:39.353: INFO: Waiting for endpoints: map[]
Aug 18 17:12:39.366: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.108.4:8080/dial?request=hostName&protocol=udp&host=172.30.134.68&port=8081&tries=1'] Namespace:pod-network-test-9174 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 17:12:39.366: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 17:12:39.530: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:12:39.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9174" for this suite.
Aug 18 17:12:53.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:12:54.016: INFO: namespace pod-network-test-9174 deletion completed in 14.458831069s

• [SLOW TEST:39.483 seconds]
[sig-network] Networking
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:12:54.016: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8476
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 18 17:12:54.262: INFO: Waiting up to 5m0s for pod "pod-95f777ba-5afd-4043-b9d7-8f7d4e1b263a" in namespace "emptydir-8476" to be "success or failure"
Aug 18 17:12:54.274: INFO: Pod "pod-95f777ba-5afd-4043-b9d7-8f7d4e1b263a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.124544ms
Aug 18 17:12:56.285: INFO: Pod "pod-95f777ba-5afd-4043-b9d7-8f7d4e1b263a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023436635s
STEP: Saw pod success
Aug 18 17:12:56.285: INFO: Pod "pod-95f777ba-5afd-4043-b9d7-8f7d4e1b263a" satisfied condition "success or failure"
Aug 18 17:12:56.297: INFO: Trying to get logs from node 10.241.69.184 pod pod-95f777ba-5afd-4043-b9d7-8f7d4e1b263a container test-container: <nil>
STEP: delete the pod
Aug 18 17:12:56.358: INFO: Waiting for pod pod-95f777ba-5afd-4043-b9d7-8f7d4e1b263a to disappear
Aug 18 17:12:56.368: INFO: Pod pod-95f777ba-5afd-4043-b9d7-8f7d4e1b263a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:12:56.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8476" for this suite.
Aug 18 17:13:02.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:13:02.834: INFO: namespace emptydir-8476 deletion completed in 6.447488673s

• [SLOW TEST:8.818 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:13:02.834: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3543
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:13:07.153: INFO: Waiting up to 5m0s for pod "client-envvars-b20871dd-9787-4e14-b4c3-ef5262c8bf2f" in namespace "pods-3543" to be "success or failure"
Aug 18 17:13:07.164: INFO: Pod "client-envvars-b20871dd-9787-4e14-b4c3-ef5262c8bf2f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.657681ms
Aug 18 17:13:09.177: INFO: Pod "client-envvars-b20871dd-9787-4e14-b4c3-ef5262c8bf2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024315527s
Aug 18 17:13:11.189: INFO: Pod "client-envvars-b20871dd-9787-4e14-b4c3-ef5262c8bf2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036166238s
STEP: Saw pod success
Aug 18 17:13:11.189: INFO: Pod "client-envvars-b20871dd-9787-4e14-b4c3-ef5262c8bf2f" satisfied condition "success or failure"
Aug 18 17:13:11.199: INFO: Trying to get logs from node 10.241.69.184 pod client-envvars-b20871dd-9787-4e14-b4c3-ef5262c8bf2f container env3cont: <nil>
STEP: delete the pod
Aug 18 17:13:11.274: INFO: Waiting for pod client-envvars-b20871dd-9787-4e14-b4c3-ef5262c8bf2f to disappear
Aug 18 17:13:11.284: INFO: Pod client-envvars-b20871dd-9787-4e14-b4c3-ef5262c8bf2f no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:13:11.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3543" for this suite.
Aug 18 17:13:41.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:13:41.743: INFO: namespace pods-3543 deletion completed in 30.444067543s

• [SLOW TEST:38.909 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:13:41.744: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3273
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 17:13:42.260: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 18 17:13:44.299: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367622, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367622, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367622, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367622, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 17:13:47.353: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:13:47.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3273" for this suite.
Aug 18 17:13:55.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:13:55.879: INFO: namespace webhook-3273 deletion completed in 8.478084515s
STEP: Destroying namespace "webhook-3273-markers" for this suite.
Aug 18 17:14:01.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:14:02.321: INFO: namespace webhook-3273-markers deletion completed in 6.44183538s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:20.638 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:14:02.383: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8282
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Aug 18 17:14:04.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec pod-sharedvolume-6a07a329-8f68-46cf-a2f5-ea61f5792d81 -c busybox-main-container --namespace=emptydir-8282 -- cat /usr/share/volumeshare/shareddata.txt'
Aug 18 17:14:05.079: INFO: stderr: ""
Aug 18 17:14:05.079: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:14:05.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8282" for this suite.
Aug 18 17:14:11.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:14:11.575: INFO: namespace emptydir-8282 deletion completed in 6.473272526s

• [SLOW TEST:9.192 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:14:11.575: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-367
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Aug 18 17:14:15.871: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-434562375 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug 18 17:14:21.074: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:14:21.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-367" for this suite.
Aug 18 17:14:27.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:14:27.578: INFO: namespace pods-367 deletion completed in 6.47251155s

• [SLOW TEST:16.003 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:14:27.578: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2687
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-flhf
STEP: Creating a pod to test atomic-volume-subpath
Aug 18 17:14:27.839: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-flhf" in namespace "subpath-2687" to be "success or failure"
Aug 18 17:14:27.850: INFO: Pod "pod-subpath-test-configmap-flhf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.630986ms
Aug 18 17:14:29.862: INFO: Pod "pod-subpath-test-configmap-flhf": Phase="Running", Reason="", readiness=true. Elapsed: 2.022272206s
Aug 18 17:14:31.876: INFO: Pod "pod-subpath-test-configmap-flhf": Phase="Running", Reason="", readiness=true. Elapsed: 4.036374882s
Aug 18 17:14:33.888: INFO: Pod "pod-subpath-test-configmap-flhf": Phase="Running", Reason="", readiness=true. Elapsed: 6.048568278s
Aug 18 17:14:35.901: INFO: Pod "pod-subpath-test-configmap-flhf": Phase="Running", Reason="", readiness=true. Elapsed: 8.061372537s
Aug 18 17:14:37.913: INFO: Pod "pod-subpath-test-configmap-flhf": Phase="Running", Reason="", readiness=true. Elapsed: 10.07341591s
Aug 18 17:14:39.926: INFO: Pod "pod-subpath-test-configmap-flhf": Phase="Running", Reason="", readiness=true. Elapsed: 12.086708874s
Aug 18 17:14:41.939: INFO: Pod "pod-subpath-test-configmap-flhf": Phase="Running", Reason="", readiness=true. Elapsed: 14.099358416s
Aug 18 17:14:43.952: INFO: Pod "pod-subpath-test-configmap-flhf": Phase="Running", Reason="", readiness=true. Elapsed: 16.1123731s
Aug 18 17:14:45.965: INFO: Pod "pod-subpath-test-configmap-flhf": Phase="Running", Reason="", readiness=true. Elapsed: 18.12489604s
Aug 18 17:14:47.976: INFO: Pod "pod-subpath-test-configmap-flhf": Phase="Running", Reason="", readiness=true. Elapsed: 20.136337694s
Aug 18 17:14:49.988: INFO: Pod "pod-subpath-test-configmap-flhf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.147826152s
STEP: Saw pod success
Aug 18 17:14:49.988: INFO: Pod "pod-subpath-test-configmap-flhf" satisfied condition "success or failure"
Aug 18 17:14:49.999: INFO: Trying to get logs from node 10.241.69.181 pod pod-subpath-test-configmap-flhf container test-container-subpath-configmap-flhf: <nil>
STEP: delete the pod
Aug 18 17:14:50.091: INFO: Waiting for pod pod-subpath-test-configmap-flhf to disappear
Aug 18 17:14:50.105: INFO: Pod pod-subpath-test-configmap-flhf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-flhf
Aug 18 17:14:50.105: INFO: Deleting pod "pod-subpath-test-configmap-flhf" in namespace "subpath-2687"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:14:50.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2687" for this suite.
Aug 18 17:14:56.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:14:56.823: INFO: namespace subpath-2687 deletion completed in 6.68872185s

• [SLOW TEST:29.245 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:14:56.824: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5655
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-d6799c34-b4b5-4c83-b239-8398bad26553 in namespace container-probe-5655
Aug 18 17:14:59.126: INFO: Started pod liveness-d6799c34-b4b5-4c83-b239-8398bad26553 in namespace container-probe-5655
STEP: checking the pod's current state and verifying that restartCount is present
Aug 18 17:14:59.137: INFO: Initial restart count of pod liveness-d6799c34-b4b5-4c83-b239-8398bad26553 is 0
Aug 18 17:15:17.264: INFO: Restart count of pod container-probe-5655/liveness-d6799c34-b4b5-4c83-b239-8398bad26553 is now 1 (18.12721629s elapsed)
Aug 18 17:15:37.382: INFO: Restart count of pod container-probe-5655/liveness-d6799c34-b4b5-4c83-b239-8398bad26553 is now 2 (38.244892935s elapsed)
Aug 18 17:15:57.499: INFO: Restart count of pod container-probe-5655/liveness-d6799c34-b4b5-4c83-b239-8398bad26553 is now 3 (58.361677936s elapsed)
Aug 18 17:16:17.617: INFO: Restart count of pod container-probe-5655/liveness-d6799c34-b4b5-4c83-b239-8398bad26553 is now 4 (1m18.480522503s elapsed)
Aug 18 17:17:19.995: INFO: Restart count of pod container-probe-5655/liveness-d6799c34-b4b5-4c83-b239-8398bad26553 is now 5 (2m20.858017957s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:17:20.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5655" for this suite.
Aug 18 17:17:26.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:17:26.508: INFO: namespace container-probe-5655 deletion completed in 6.459725251s

• [SLOW TEST:149.684 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:17:26.508: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-776
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-776
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-776 to expose endpoints map[]
Aug 18 17:17:26.767: INFO: Get endpoints failed (9.016672ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Aug 18 17:17:27.781: INFO: successfully validated that service multi-endpoint-test in namespace services-776 exposes endpoints map[] (1.022319679s elapsed)
STEP: Creating pod pod1 in namespace services-776
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-776 to expose endpoints map[pod1:[100]]
Aug 18 17:17:29.884: INFO: successfully validated that service multi-endpoint-test in namespace services-776 exposes endpoints map[pod1:[100]] (2.078160105s elapsed)
STEP: Creating pod pod2 in namespace services-776
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-776 to expose endpoints map[pod1:[100] pod2:[101]]
Aug 18 17:17:32.002: INFO: successfully validated that service multi-endpoint-test in namespace services-776 exposes endpoints map[pod1:[100] pod2:[101]] (2.103861535s elapsed)
STEP: Deleting pod pod1 in namespace services-776
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-776 to expose endpoints map[pod2:[101]]
Aug 18 17:17:32.045: INFO: successfully validated that service multi-endpoint-test in namespace services-776 exposes endpoints map[pod2:[101]] (23.756216ms elapsed)
STEP: Deleting pod pod2 in namespace services-776
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-776 to expose endpoints map[]
Aug 18 17:17:32.075: INFO: successfully validated that service multi-endpoint-test in namespace services-776 exposes endpoints map[] (12.741154ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:17:32.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-776" for this suite.
Aug 18 17:17:44.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:17:44.688: INFO: namespace services-776 deletion completed in 12.517533094s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.180 seconds]
[sig-network] Services
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:17:44.689: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2769
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-1a9df33e-99f4-4563-a60d-3203c4d19f00
STEP: Creating a pod to test consume secrets
Aug 18 17:17:44.951: INFO: Waiting up to 5m0s for pod "pod-secrets-a68e7ae0-c2c1-4e71-8486-3d75e9a5e159" in namespace "secrets-2769" to be "success or failure"
Aug 18 17:17:44.967: INFO: Pod "pod-secrets-a68e7ae0-c2c1-4e71-8486-3d75e9a5e159": Phase="Pending", Reason="", readiness=false. Elapsed: 15.582871ms
Aug 18 17:17:46.979: INFO: Pod "pod-secrets-a68e7ae0-c2c1-4e71-8486-3d75e9a5e159": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027805899s
Aug 18 17:17:48.990: INFO: Pod "pod-secrets-a68e7ae0-c2c1-4e71-8486-3d75e9a5e159": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038501676s
STEP: Saw pod success
Aug 18 17:17:48.990: INFO: Pod "pod-secrets-a68e7ae0-c2c1-4e71-8486-3d75e9a5e159" satisfied condition "success or failure"
Aug 18 17:17:49.000: INFO: Trying to get logs from node 10.241.69.181 pod pod-secrets-a68e7ae0-c2c1-4e71-8486-3d75e9a5e159 container secret-env-test: <nil>
STEP: delete the pod
Aug 18 17:17:49.085: INFO: Waiting for pod pod-secrets-a68e7ae0-c2c1-4e71-8486-3d75e9a5e159 to disappear
Aug 18 17:17:49.096: INFO: Pod pod-secrets-a68e7ae0-c2c1-4e71-8486-3d75e9a5e159 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:17:49.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2769" for this suite.
Aug 18 17:17:55.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:17:55.591: INFO: namespace secrets-2769 deletion completed in 6.474361457s

• [SLOW TEST:10.902 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:17:55.592: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5419
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 18 17:17:55.829: INFO: Waiting up to 5m0s for pod "pod-c6d0dbdc-aacc-48f0-8749-260c30192a3c" in namespace "emptydir-5419" to be "success or failure"
Aug 18 17:17:55.839: INFO: Pod "pod-c6d0dbdc-aacc-48f0-8749-260c30192a3c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.753032ms
Aug 18 17:17:57.851: INFO: Pod "pod-c6d0dbdc-aacc-48f0-8749-260c30192a3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021960564s
Aug 18 17:17:59.862: INFO: Pod "pod-c6d0dbdc-aacc-48f0-8749-260c30192a3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033156349s
STEP: Saw pod success
Aug 18 17:17:59.863: INFO: Pod "pod-c6d0dbdc-aacc-48f0-8749-260c30192a3c" satisfied condition "success or failure"
Aug 18 17:17:59.872: INFO: Trying to get logs from node 10.241.69.181 pod pod-c6d0dbdc-aacc-48f0-8749-260c30192a3c container test-container: <nil>
STEP: delete the pod
Aug 18 17:17:59.944: INFO: Waiting for pod pod-c6d0dbdc-aacc-48f0-8749-260c30192a3c to disappear
Aug 18 17:17:59.957: INFO: Pod pod-c6d0dbdc-aacc-48f0-8749-260c30192a3c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:17:59.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5419" for this suite.
Aug 18 17:18:06.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:18:06.474: INFO: namespace emptydir-5419 deletion completed in 6.496197731s

• [SLOW TEST:10.882 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:18:06.474: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6704
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-fff5e08b-981a-4ccc-a316-5cced5adfde3
STEP: Creating a pod to test consume secrets
Aug 18 17:18:06.731: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3d6b3d42-1ed8-47f8-9d71-60f9ac5f2933" in namespace "projected-6704" to be "success or failure"
Aug 18 17:18:06.741: INFO: Pod "pod-projected-secrets-3d6b3d42-1ed8-47f8-9d71-60f9ac5f2933": Phase="Pending", Reason="", readiness=false. Elapsed: 10.166976ms
Aug 18 17:18:08.753: INFO: Pod "pod-projected-secrets-3d6b3d42-1ed8-47f8-9d71-60f9ac5f2933": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022303184s
STEP: Saw pod success
Aug 18 17:18:08.753: INFO: Pod "pod-projected-secrets-3d6b3d42-1ed8-47f8-9d71-60f9ac5f2933" satisfied condition "success or failure"
Aug 18 17:18:08.764: INFO: Trying to get logs from node 10.241.69.172 pod pod-projected-secrets-3d6b3d42-1ed8-47f8-9d71-60f9ac5f2933 container secret-volume-test: <nil>
STEP: delete the pod
Aug 18 17:18:08.856: INFO: Waiting for pod pod-projected-secrets-3d6b3d42-1ed8-47f8-9d71-60f9ac5f2933 to disappear
Aug 18 17:18:08.871: INFO: Pod pod-projected-secrets-3d6b3d42-1ed8-47f8-9d71-60f9ac5f2933 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:18:08.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6704" for this suite.
Aug 18 17:18:14.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:18:15.378: INFO: namespace projected-6704 deletion completed in 6.486690556s

• [SLOW TEST:8.904 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:18:15.380: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6739
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Aug 18 17:18:15.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=kubectl-6739 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug 18 17:18:18.804: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug 18 17:18:18.804: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:18:20.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6739" for this suite.
Aug 18 17:18:26.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:18:27.305: INFO: namespace kubectl-6739 deletion completed in 6.445859982s

• [SLOW TEST:11.926 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:18:27.305: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-4966
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:18:27.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4966" for this suite.
Aug 18 17:18:33.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:18:34.013: INFO: namespace custom-resource-definition-4966 deletion completed in 6.45793618s

• [SLOW TEST:6.708 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:18:34.014: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-726e8e90-616d-40ab-964f-fc35f73dceac
STEP: Creating a pod to test consume configMaps
Aug 18 17:18:34.269: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a762022b-593c-4531-92e9-e8ea6c2e276d" in namespace "projected-9176" to be "success or failure"
Aug 18 17:18:34.281: INFO: Pod "pod-projected-configmaps-a762022b-593c-4531-92e9-e8ea6c2e276d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.887153ms
Aug 18 17:18:36.292: INFO: Pod "pod-projected-configmaps-a762022b-593c-4531-92e9-e8ea6c2e276d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023038129s
STEP: Saw pod success
Aug 18 17:18:36.292: INFO: Pod "pod-projected-configmaps-a762022b-593c-4531-92e9-e8ea6c2e276d" satisfied condition "success or failure"
Aug 18 17:18:36.304: INFO: Trying to get logs from node 10.241.69.181 pod pod-projected-configmaps-a762022b-593c-4531-92e9-e8ea6c2e276d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 18 17:18:36.371: INFO: Waiting for pod pod-projected-configmaps-a762022b-593c-4531-92e9-e8ea6c2e276d to disappear
Aug 18 17:18:36.384: INFO: Pod pod-projected-configmaps-a762022b-593c-4531-92e9-e8ea6c2e276d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:18:36.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9176" for this suite.
Aug 18 17:18:42.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:18:42.860: INFO: namespace projected-9176 deletion completed in 6.454964805s

• [SLOW TEST:8.847 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:18:42.861: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5858
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5858
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 18 17:18:43.075: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 18 17:19:03.355: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.104.177 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5858 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 17:19:03.355: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 17:19:04.544: INFO: Found all expected endpoints: [netserver-0]
Aug 18 17:19:04.557: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.134.76 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5858 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 17:19:04.557: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 17:19:05.735: INFO: Found all expected endpoints: [netserver-1]
Aug 18 17:19:05.749: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.108.10 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5858 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 17:19:05.749: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 17:19:06.929: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:19:06.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5858" for this suite.
Aug 18 17:19:18.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:19:19.371: INFO: namespace pod-network-test-5858 deletion completed in 12.42301252s

• [SLOW TEST:36.510 seconds]
[sig-network] Networking
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:19:19.372: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6873
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Aug 18 17:19:19.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-6873'
Aug 18 17:19:19.720: INFO: stderr: ""
Aug 18 17:19:19.720: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Aug 18 17:19:29.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pod e2e-test-httpd-pod --namespace=kubectl-6873 -o json'
Aug 18 17:19:29.871: INFO: stderr: ""
Aug 18 17:19:29.871: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2020-08-18T17:19:19Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6873\",\n        \"resourceVersion\": \"19916\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-6873/pods/e2e-test-httpd-pod\",\n        \"uid\": \"864bf726-aeb3-407b-8716-390b598eb902\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-4fdkw\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.241.69.184\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-4fdkw\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-4fdkw\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-08-18T17:19:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-08-18T17:19:26Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-08-18T17:19:26Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-08-18T17:19:19Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://8dfaf01628636d4e457971a14b0aaa522089cc6b619e1384ac0ade0b1f0af5ed\",\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-08-18T17:19:25Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.241.69.184\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.134.78\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.30.134.78\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-08-18T17:19:19Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 18 17:19:29.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 replace -f - --namespace=kubectl-6873'
Aug 18 17:19:30.236: INFO: stderr: ""
Aug 18 17:19:30.236: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Aug 18 17:19:30.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete pods e2e-test-httpd-pod --namespace=kubectl-6873'
Aug 18 17:19:32.133: INFO: stderr: ""
Aug 18 17:19:32.133: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:19:32.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6873" for this suite.
Aug 18 17:19:38.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:19:38.603: INFO: namespace kubectl-6873 deletion completed in 6.451909135s

• [SLOW TEST:19.231 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:19:38.604: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4129
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:19:38.838: INFO: Creating deployment "test-recreate-deployment"
Aug 18 17:19:38.854: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 18 17:19:38.881: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Aug 18 17:19:40.908: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 18 17:19:40.922: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367978, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367978, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367978, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367978, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 17:19:42.937: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367978, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367978, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367978, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733367978, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 17:19:44.936: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 18 17:19:44.964: INFO: Updating deployment test-recreate-deployment
Aug 18 17:19:44.964: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Aug 18 17:19:45.099: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-4129 /apis/apps/v1/namespaces/deployment-4129/deployments/test-recreate-deployment 46897832-0993-431c-bad6-73914b1b6aa8 20022 2 2020-08-18 17:19:38 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0036930c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-08-18 17:19:45 +0000 UTC,LastTransitionTime:2020-08-18 17:19:45 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-08-18 17:19:45 +0000 UTC,LastTransitionTime:2020-08-18 17:19:38 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Aug 18 17:19:45.111: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-4129 /apis/apps/v1/namespaces/deployment-4129/replicasets/test-recreate-deployment-5f94c574ff f93802db-61e3-4ba0-bc94-8ad2fb7023e9 20020 1 2020-08-18 17:19:45 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 46897832-0993-431c-bad6-73914b1b6aa8 0xc0039407e7 0xc0039407e8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003940848 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 18 17:19:45.111: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 18 17:19:45.111: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-4129 /apis/apps/v1/namespaces/deployment-4129/replicasets/test-recreate-deployment-68fc85c7bb c27519fc-8785-47a6-b0e5-df9263d82e0a 20009 2 2020-08-18 17:19:38 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 46897832-0993-431c-bad6-73914b1b6aa8 0xc0039408b7 0xc0039408b8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003940918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 18 17:19:45.122: INFO: Pod "test-recreate-deployment-5f94c574ff-6thwd" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-6thwd test-recreate-deployment-5f94c574ff- deployment-4129 /api/v1/namespaces/deployment-4129/pods/test-recreate-deployment-5f94c574ff-6thwd 4f7eba85-165d-4b65-b714-856614a76076 20021 0 2020-08-18 17:19:45 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff f93802db-61e3-4ba0-bc94-8ad2fb7023e9 0xc003693497 0xc003693498}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-p24t7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-p24t7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-p24t7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:19:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:19:45 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:19:45 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:19:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:,StartTime:2020-08-18 17:19:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:19:45.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4129" for this suite.
Aug 18 17:19:53.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:19:53.603: INFO: namespace deployment-4129 deletion completed in 8.457045369s

• [SLOW TEST:15.000 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:19:53.604: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3423
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-sggp
STEP: Creating a pod to test atomic-volume-subpath
Aug 18 17:19:53.873: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-sggp" in namespace "subpath-3423" to be "success or failure"
Aug 18 17:19:53.889: INFO: Pod "pod-subpath-test-secret-sggp": Phase="Pending", Reason="", readiness=false. Elapsed: 15.559439ms
Aug 18 17:19:55.909: INFO: Pod "pod-subpath-test-secret-sggp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035744826s
Aug 18 17:19:57.921: INFO: Pod "pod-subpath-test-secret-sggp": Phase="Running", Reason="", readiness=true. Elapsed: 4.047571192s
Aug 18 17:19:59.932: INFO: Pod "pod-subpath-test-secret-sggp": Phase="Running", Reason="", readiness=true. Elapsed: 6.058832244s
Aug 18 17:20:01.945: INFO: Pod "pod-subpath-test-secret-sggp": Phase="Running", Reason="", readiness=true. Elapsed: 8.071713277s
Aug 18 17:20:03.957: INFO: Pod "pod-subpath-test-secret-sggp": Phase="Running", Reason="", readiness=true. Elapsed: 10.08337937s
Aug 18 17:20:05.977: INFO: Pod "pod-subpath-test-secret-sggp": Phase="Running", Reason="", readiness=true. Elapsed: 12.103484004s
Aug 18 17:20:07.989: INFO: Pod "pod-subpath-test-secret-sggp": Phase="Running", Reason="", readiness=true. Elapsed: 14.115756929s
Aug 18 17:20:10.001: INFO: Pod "pod-subpath-test-secret-sggp": Phase="Running", Reason="", readiness=true. Elapsed: 16.128014475s
Aug 18 17:20:12.013: INFO: Pod "pod-subpath-test-secret-sggp": Phase="Running", Reason="", readiness=true. Elapsed: 18.139643225s
Aug 18 17:20:14.024: INFO: Pod "pod-subpath-test-secret-sggp": Phase="Running", Reason="", readiness=true. Elapsed: 20.151120552s
Aug 18 17:20:16.036: INFO: Pod "pod-subpath-test-secret-sggp": Phase="Running", Reason="", readiness=true. Elapsed: 22.162596879s
Aug 18 17:20:18.059: INFO: Pod "pod-subpath-test-secret-sggp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.185820163s
STEP: Saw pod success
Aug 18 17:20:18.059: INFO: Pod "pod-subpath-test-secret-sggp" satisfied condition "success or failure"
Aug 18 17:20:18.070: INFO: Trying to get logs from node 10.241.69.184 pod pod-subpath-test-secret-sggp container test-container-subpath-secret-sggp: <nil>
STEP: delete the pod
Aug 18 17:20:18.164: INFO: Waiting for pod pod-subpath-test-secret-sggp to disappear
Aug 18 17:20:18.178: INFO: Pod pod-subpath-test-secret-sggp no longer exists
STEP: Deleting pod pod-subpath-test-secret-sggp
Aug 18 17:20:18.178: INFO: Deleting pod "pod-subpath-test-secret-sggp" in namespace "subpath-3423"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:20:18.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3423" for this suite.
Aug 18 17:20:24.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:20:24.660: INFO: namespace subpath-3423 deletion completed in 6.44870318s

• [SLOW TEST:31.057 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:20:24.661: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-797
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Aug 18 17:20:24.900: INFO: Waiting up to 5m0s for pod "var-expansion-79a8b42e-609a-4890-b175-e09b0aecd61d" in namespace "var-expansion-797" to be "success or failure"
Aug 18 17:20:24.911: INFO: Pod "var-expansion-79a8b42e-609a-4890-b175-e09b0aecd61d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.145249ms
Aug 18 17:20:26.928: INFO: Pod "var-expansion-79a8b42e-609a-4890-b175-e09b0aecd61d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027452222s
STEP: Saw pod success
Aug 18 17:20:26.928: INFO: Pod "var-expansion-79a8b42e-609a-4890-b175-e09b0aecd61d" satisfied condition "success or failure"
Aug 18 17:20:26.941: INFO: Trying to get logs from node 10.241.69.172 pod var-expansion-79a8b42e-609a-4890-b175-e09b0aecd61d container dapi-container: <nil>
STEP: delete the pod
Aug 18 17:20:27.037: INFO: Waiting for pod var-expansion-79a8b42e-609a-4890-b175-e09b0aecd61d to disappear
Aug 18 17:20:27.047: INFO: Pod var-expansion-79a8b42e-609a-4890-b175-e09b0aecd61d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:20:27.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-797" for this suite.
Aug 18 17:20:33.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:20:33.532: INFO: namespace var-expansion-797 deletion completed in 6.456297023s

• [SLOW TEST:8.871 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:20:33.533: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8435
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 18 17:20:33.777: INFO: Waiting up to 5m0s for pod "pod-9fe782ee-2b26-4f56-bfc9-59f87b1eafee" in namespace "emptydir-8435" to be "success or failure"
Aug 18 17:20:33.792: INFO: Pod "pod-9fe782ee-2b26-4f56-bfc9-59f87b1eafee": Phase="Pending", Reason="", readiness=false. Elapsed: 15.236183ms
Aug 18 17:20:35.803: INFO: Pod "pod-9fe782ee-2b26-4f56-bfc9-59f87b1eafee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026442633s
STEP: Saw pod success
Aug 18 17:20:35.803: INFO: Pod "pod-9fe782ee-2b26-4f56-bfc9-59f87b1eafee" satisfied condition "success or failure"
Aug 18 17:20:35.814: INFO: Trying to get logs from node 10.241.69.181 pod pod-9fe782ee-2b26-4f56-bfc9-59f87b1eafee container test-container: <nil>
STEP: delete the pod
Aug 18 17:20:35.908: INFO: Waiting for pod pod-9fe782ee-2b26-4f56-bfc9-59f87b1eafee to disappear
Aug 18 17:20:35.920: INFO: Pod pod-9fe782ee-2b26-4f56-bfc9-59f87b1eafee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:20:35.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8435" for this suite.
Aug 18 17:20:41.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:20:42.375: INFO: namespace emptydir-8435 deletion completed in 6.43789225s

• [SLOW TEST:8.843 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:20:42.376: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-8782
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Aug 18 17:20:42.585: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 18 17:21:42.656: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:21:42.667: INFO: Starting informer...
STEP: Starting pods...
Aug 18 17:21:42.939: INFO: Pod1 is running on 10.241.69.172. Tainting Node
Aug 18 17:21:45.197: INFO: Pod2 is running on 10.241.69.172. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Aug 18 17:22:00.424: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Aug 18 17:22:20.358: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:22:20.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-8782" for this suite.
Aug 18 17:22:44.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:22:44.964: INFO: namespace taint-multiple-pods-8782 deletion completed in 24.536247827s

• [SLOW TEST:122.588 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:22:44.974: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8562
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:22:45.198: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 18 17:22:45.222: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 18 17:22:50.235: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 18 17:22:50.235: INFO: Creating deployment "test-rolling-update-deployment"
Aug 18 17:22:50.251: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 18 17:22:50.277: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 18 17:22:52.302: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 18 17:22:52.314: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733368170, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733368170, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733368170, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733368170, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 17:22:54.328: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733368170, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733368170, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733368174, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733368170, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 17:22:56.328: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Aug 18 17:22:56.366: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-8562 /apis/apps/v1/namespaces/deployment-8562/deployments/test-rolling-update-deployment 4833a78a-ae1d-46e3-bd4b-4aba6277e41e 20989 1 2020-08-18 17:22:50 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001ffa3a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-08-18 17:22:50 +0000 UTC,LastTransitionTime:2020-08-18 17:22:50 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2020-08-18 17:22:54 +0000 UTC,LastTransitionTime:2020-08-18 17:22:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 18 17:22:56.377: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-8562 /apis/apps/v1/namespaces/deployment-8562/replicasets/test-rolling-update-deployment-55d946486 70bd2682-9ab7-4ff1-ac98-dda99f934ccf 20978 1 2020-08-18 17:22:50 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 4833a78a-ae1d-46e3-bd4b-4aba6277e41e 0xc001ffa880 0xc001ffa881}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001ffa8e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 18 17:22:56.377: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 18 17:22:56.377: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-8562 /apis/apps/v1/namespaces/deployment-8562/replicasets/test-rolling-update-controller f7e5697f-965d-4184-b177-27ffac85858c 20988 2 2020-08-18 17:22:45 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 4833a78a-ae1d-46e3-bd4b-4aba6277e41e 0xc001ffa7b7 0xc001ffa7b8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc001ffa818 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 18 17:22:56.389: INFO: Pod "test-rolling-update-deployment-55d946486-2ln4j" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-2ln4j test-rolling-update-deployment-55d946486- deployment-8562 /api/v1/namespaces/deployment-8562/pods/test-rolling-update-deployment-55d946486-2ln4j 333f1f69-83a9-4614-9869-3edcf4407e2c 20977 0 2020-08-18 17:22:50 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 70bd2682-9ab7-4ff1-ac98-dda99f934ccf 0xc001ffad50 0xc001ffad51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2bfrv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2bfrv,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2bfrv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:22:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:22:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:22:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:22:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:172.30.104.183,StartTime:2020-08-18 17:22:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 17:22:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://fcbb0ffb32c7642a09ec08029556cd339231bced0b0bb61e42f348e4e1445a2e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.183,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:22:56.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8562" for this suite.
Aug 18 17:23:04.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:23:04.881: INFO: namespace deployment-8562 deletion completed in 8.476021483s

• [SLOW TEST:19.908 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:23:04.882: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8822
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 17:23:05.168: INFO: Waiting up to 5m0s for pod "downwardapi-volume-01a21137-a6e6-4140-afdd-d42de83751c4" in namespace "downward-api-8822" to be "success or failure"
Aug 18 17:23:05.185: INFO: Pod "downwardapi-volume-01a21137-a6e6-4140-afdd-d42de83751c4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.392574ms
Aug 18 17:23:07.196: INFO: Pod "downwardapi-volume-01a21137-a6e6-4140-afdd-d42de83751c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028004141s
Aug 18 17:23:09.208: INFO: Pod "downwardapi-volume-01a21137-a6e6-4140-afdd-d42de83751c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040059508s
STEP: Saw pod success
Aug 18 17:23:09.208: INFO: Pod "downwardapi-volume-01a21137-a6e6-4140-afdd-d42de83751c4" satisfied condition "success or failure"
Aug 18 17:23:09.219: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-01a21137-a6e6-4140-afdd-d42de83751c4 container client-container: <nil>
STEP: delete the pod
Aug 18 17:23:09.320: INFO: Waiting for pod downwardapi-volume-01a21137-a6e6-4140-afdd-d42de83751c4 to disappear
Aug 18 17:23:09.336: INFO: Pod downwardapi-volume-01a21137-a6e6-4140-afdd-d42de83751c4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:23:09.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8822" for this suite.
Aug 18 17:23:15.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:23:15.793: INFO: namespace downward-api-8822 deletion completed in 6.440274017s

• [SLOW TEST:10.911 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:23:15.793: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6006
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 18 17:23:16.036: INFO: Waiting up to 5m0s for pod "pod-b036a9f0-ae5c-475a-bb03-2458357e2173" in namespace "emptydir-6006" to be "success or failure"
Aug 18 17:23:16.046: INFO: Pod "pod-b036a9f0-ae5c-475a-bb03-2458357e2173": Phase="Pending", Reason="", readiness=false. Elapsed: 10.924852ms
Aug 18 17:23:18.059: INFO: Pod "pod-b036a9f0-ae5c-475a-bb03-2458357e2173": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023223462s
Aug 18 17:23:20.074: INFO: Pod "pod-b036a9f0-ae5c-475a-bb03-2458357e2173": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038507137s
STEP: Saw pod success
Aug 18 17:23:20.074: INFO: Pod "pod-b036a9f0-ae5c-475a-bb03-2458357e2173" satisfied condition "success or failure"
Aug 18 17:23:20.088: INFO: Trying to get logs from node 10.241.69.172 pod pod-b036a9f0-ae5c-475a-bb03-2458357e2173 container test-container: <nil>
STEP: delete the pod
Aug 18 17:23:20.159: INFO: Waiting for pod pod-b036a9f0-ae5c-475a-bb03-2458357e2173 to disappear
Aug 18 17:23:20.180: INFO: Pod pod-b036a9f0-ae5c-475a-bb03-2458357e2173 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:23:20.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6006" for this suite.
Aug 18 17:23:26.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:23:26.636: INFO: namespace emptydir-6006 deletion completed in 6.43807089s

• [SLOW TEST:10.843 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:23:26.636: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2741
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-2df7ba77-fa89-475c-9acf-46a09aa176f2
STEP: Creating a pod to test consume configMaps
Aug 18 17:23:26.890: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-eb45d043-9729-4aa7-a755-e141333e6866" in namespace "projected-2741" to be "success or failure"
Aug 18 17:23:26.902: INFO: Pod "pod-projected-configmaps-eb45d043-9729-4aa7-a755-e141333e6866": Phase="Pending", Reason="", readiness=false. Elapsed: 12.072497ms
Aug 18 17:23:28.914: INFO: Pod "pod-projected-configmaps-eb45d043-9729-4aa7-a755-e141333e6866": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023839177s
STEP: Saw pod success
Aug 18 17:23:28.914: INFO: Pod "pod-projected-configmaps-eb45d043-9729-4aa7-a755-e141333e6866" satisfied condition "success or failure"
Aug 18 17:23:28.925: INFO: Trying to get logs from node 10.241.69.172 pod pod-projected-configmaps-eb45d043-9729-4aa7-a755-e141333e6866 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 18 17:23:28.990: INFO: Waiting for pod pod-projected-configmaps-eb45d043-9729-4aa7-a755-e141333e6866 to disappear
Aug 18 17:23:29.000: INFO: Pod pod-projected-configmaps-eb45d043-9729-4aa7-a755-e141333e6866 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:23:29.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2741" for this suite.
Aug 18 17:23:35.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:23:35.484: INFO: namespace projected-2741 deletion completed in 6.468284834s

• [SLOW TEST:8.847 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:23:35.489: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6668
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-a6ab7bba-5f5a-43c7-8313-bf9832ae55d3
STEP: Creating a pod to test consume secrets
Aug 18 17:23:35.744: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3a344111-572b-4cea-b92d-5a07eab59499" in namespace "projected-6668" to be "success or failure"
Aug 18 17:23:35.755: INFO: Pod "pod-projected-secrets-3a344111-572b-4cea-b92d-5a07eab59499": Phase="Pending", Reason="", readiness=false. Elapsed: 10.669453ms
Aug 18 17:23:37.770: INFO: Pod "pod-projected-secrets-3a344111-572b-4cea-b92d-5a07eab59499": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026143046s
Aug 18 17:23:39.782: INFO: Pod "pod-projected-secrets-3a344111-572b-4cea-b92d-5a07eab59499": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038117837s
STEP: Saw pod success
Aug 18 17:23:39.782: INFO: Pod "pod-projected-secrets-3a344111-572b-4cea-b92d-5a07eab59499" satisfied condition "success or failure"
Aug 18 17:23:39.805: INFO: Trying to get logs from node 10.241.69.172 pod pod-projected-secrets-3a344111-572b-4cea-b92d-5a07eab59499 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 18 17:23:39.871: INFO: Waiting for pod pod-projected-secrets-3a344111-572b-4cea-b92d-5a07eab59499 to disappear
Aug 18 17:23:39.881: INFO: Pod pod-projected-secrets-3a344111-572b-4cea-b92d-5a07eab59499 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:23:39.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6668" for this suite.
Aug 18 17:23:47.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:23:48.368: INFO: namespace projected-6668 deletion completed in 8.463908759s

• [SLOW TEST:12.879 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:23:48.368: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3233
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-be016d0e-2d31-4fba-aa7a-29874e550429 in namespace container-probe-3233
Aug 18 17:23:50.632: INFO: Started pod test-webserver-be016d0e-2d31-4fba-aa7a-29874e550429 in namespace container-probe-3233
STEP: checking the pod's current state and verifying that restartCount is present
Aug 18 17:23:50.644: INFO: Initial restart count of pod test-webserver-be016d0e-2d31-4fba-aa7a-29874e550429 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:27:52.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3233" for this suite.
Aug 18 17:27:58.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:27:58.912: INFO: namespace container-probe-3233 deletion completed in 6.437109077s

• [SLOW TEST:250.544 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:27:58.913: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9935
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:27:59.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9935" for this suite.
Aug 18 17:28:11.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:28:11.672: INFO: namespace kubelet-test-9935 deletion completed in 12.474093897s

• [SLOW TEST:12.760 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:28:11.673: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4873
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:28:11.969: INFO: (0) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 51.28993ms)
Aug 18 17:28:11.993: INFO: (1) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.545513ms)
Aug 18 17:28:12.012: INFO: (2) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 19.453394ms)
Aug 18 17:28:12.034: INFO: (3) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 21.035293ms)
Aug 18 17:28:12.059: INFO: (4) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 25.301402ms)
Aug 18 17:28:12.083: INFO: (5) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.999102ms)
Aug 18 17:28:12.105: INFO: (6) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.46038ms)
Aug 18 17:28:12.128: INFO: (7) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.766537ms)
Aug 18 17:28:12.154: INFO: (8) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 25.608178ms)
Aug 18 17:28:12.174: INFO: (9) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.381003ms)
Aug 18 17:28:12.195: INFO: (10) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.720315ms)
Aug 18 17:28:12.216: INFO: (11) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 21.037844ms)
Aug 18 17:28:12.238: INFO: (12) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 21.476836ms)
Aug 18 17:28:12.259: INFO: (13) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.794634ms)
Aug 18 17:28:12.279: INFO: (14) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 19.964181ms)
Aug 18 17:28:12.299: INFO: (15) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.865148ms)
Aug 18 17:28:12.319: INFO: (16) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 19.629474ms)
Aug 18 17:28:12.339: INFO: (17) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.04796ms)
Aug 18 17:28:12.361: INFO: (18) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 21.272921ms)
Aug 18 17:28:12.383: INFO: (19) /api/v1/nodes/10.241.69.172/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.628335ms)
[AfterEach] version v1
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:28:12.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4873" for this suite.
Aug 18 17:28:18.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:28:18.862: INFO: namespace proxy-4873 deletion completed in 6.45927362s

• [SLOW TEST:7.189 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:28:18.867: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4935
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-4935
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-4935
STEP: creating replication controller externalsvc in namespace services-4935
I0818 17:28:19.170583      23 runners.go:184] Created replication controller with name: externalsvc, namespace: services-4935, replica count: 2
I0818 17:28:22.221079      23 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Aug 18 17:28:22.300: INFO: Creating new exec pod
Aug 18 17:28:24.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-4935 execpodn7xkt -- /bin/sh -x -c nslookup clusterip-service'
Aug 18 17:28:24.773: INFO: stderr: "+ nslookup clusterip-service\n"
Aug 18 17:28:24.773: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nclusterip-service.services-4935.svc.cluster.local\tcanonical name = externalsvc.services-4935.svc.cluster.local.\nName:\texternalsvc.services-4935.svc.cluster.local\nAddress: 172.21.52.236\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4935, will wait for the garbage collector to delete the pods
Aug 18 17:28:24.856: INFO: Deleting ReplicationController externalsvc took: 23.157321ms
Aug 18 17:28:25.057: INFO: Terminating ReplicationController externalsvc pods took: 200.348734ms
Aug 18 17:28:33.633: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:28:33.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4935" for this suite.
Aug 18 17:28:41.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:28:42.190: INFO: namespace services-4935 deletion completed in 8.4870988s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:23.323 seconds]
[sig-network] Services
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:28:42.191: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6763
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6763
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Aug 18 17:28:42.476: INFO: Found 0 stateful pods, waiting for 3
Aug 18 17:28:52.490: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 18 17:28:52.490: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 18 17:28:52.490: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Aug 18 17:29:02.490: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 18 17:29:02.490: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 18 17:29:02.490: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 18 17:29:02.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-6763 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 18 17:29:02.831: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 18 17:29:02.831: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 18 17:29:02.831: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Aug 18 17:29:12.913: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 18 17:29:22.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-6763 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 18 17:29:23.253: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 18 17:29:23.253: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 18 17:29:23.253: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 18 17:29:33.328: INFO: Waiting for StatefulSet statefulset-6763/ss2 to complete update
Aug 18 17:29:33.328: INFO: Waiting for Pod statefulset-6763/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Aug 18 17:29:33.328: INFO: Waiting for Pod statefulset-6763/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Aug 18 17:29:43.359: INFO: Waiting for StatefulSet statefulset-6763/ss2 to complete update
Aug 18 17:29:43.360: INFO: Waiting for Pod statefulset-6763/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Aug 18 17:29:43.360: INFO: Waiting for Pod statefulset-6763/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Aug 18 17:29:53.350: INFO: Waiting for StatefulSet statefulset-6763/ss2 to complete update
STEP: Rolling back to a previous revision
Aug 18 17:30:03.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-6763 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 18 17:30:03.656: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 18 17:30:03.656: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 18 17:30:03.656: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 18 17:30:13.752: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 18 17:30:23.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-6763 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 18 17:30:24.090: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 18 17:30:24.090: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 18 17:30:24.090: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Aug 18 17:30:44.159: INFO: Deleting all statefulset in ns statefulset-6763
Aug 18 17:30:44.169: INFO: Scaling statefulset ss2 to 0
Aug 18 17:31:14.219: INFO: Waiting for statefulset status.replicas updated to 0
Aug 18 17:31:14.231: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:31:14.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6763" for this suite.
Aug 18 17:31:22.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:31:22.755: INFO: namespace statefulset-6763 deletion completed in 8.447532461s

• [SLOW TEST:160.565 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:31:22.756: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9497
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 17:31:23.591: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 18 17:31:25.630: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733368683, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733368683, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733368683, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733368683, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 17:31:28.682: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
Aug 18 17:31:38.746: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Aug 18 17:31:42.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 attach --namespace=webhook-9497 to-be-attached-pod -i -c=container1'
Aug 18 17:31:43.081: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:31:43.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9497" for this suite.
Aug 18 17:31:55.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:31:55.630: INFO: namespace webhook-9497 deletion completed in 12.500505511s
STEP: Destroying namespace "webhook-9497-markers" for this suite.
Aug 18 17:32:01.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:32:02.098: INFO: namespace webhook-9497-markers deletion completed in 6.468269064s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:39.412 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:32:02.168: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0818 17:32:42.516947      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 18 17:32:42.517: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:32:42.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6262" for this suite.
Aug 18 17:32:50.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:32:51.026: INFO: namespace gc-6262 deletion completed in 8.488772341s

• [SLOW TEST:48.858 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:32:51.026: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4977
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Aug 18 17:32:51.256: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:32:54.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4977" for this suite.
Aug 18 17:33:00.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:33:00.783: INFO: namespace init-container-4977 deletion completed in 6.459919967s

• [SLOW TEST:9.757 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:33:00.783: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1017
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 17:33:01.026: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1a679222-fc26-4a64-877e-1cb952683e5a" in namespace "downward-api-1017" to be "success or failure"
Aug 18 17:33:01.036: INFO: Pod "downwardapi-volume-1a679222-fc26-4a64-877e-1cb952683e5a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.913035ms
Aug 18 17:33:03.067: INFO: Pod "downwardapi-volume-1a679222-fc26-4a64-877e-1cb952683e5a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040319983s
STEP: Saw pod success
Aug 18 17:33:03.067: INFO: Pod "downwardapi-volume-1a679222-fc26-4a64-877e-1cb952683e5a" satisfied condition "success or failure"
Aug 18 17:33:03.078: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-1a679222-fc26-4a64-877e-1cb952683e5a container client-container: <nil>
STEP: delete the pod
Aug 18 17:33:03.177: INFO: Waiting for pod downwardapi-volume-1a679222-fc26-4a64-877e-1cb952683e5a to disappear
Aug 18 17:33:03.187: INFO: Pod downwardapi-volume-1a679222-fc26-4a64-877e-1cb952683e5a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:33:03.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1017" for this suite.
Aug 18 17:33:09.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:33:09.710: INFO: namespace downward-api-1017 deletion completed in 6.496590243s

• [SLOW TEST:8.927 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:33:09.711: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5956
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5956.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-5956.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5956.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-5956.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5956.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5956.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-5956.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5956.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-5956.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5956.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 18 17:33:20.048: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:20.068: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:20.087: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:20.111: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:20.173: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:20.193: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:20.226: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:20.248: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:20.300: INFO: Lookups using dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5956.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5956.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local jessie_udp@dns-test-service-2.dns-5956.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5956.svc.cluster.local]

Aug 18 17:33:25.323: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:25.346: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:25.370: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:25.393: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:25.458: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:25.481: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:25.513: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:25.538: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:25.584: INFO: Lookups using dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5956.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5956.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local jessie_udp@dns-test-service-2.dns-5956.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5956.svc.cluster.local]

Aug 18 17:33:30.329: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:30.355: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:30.384: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:30.408: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:30.482: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:30.504: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:30.531: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:30.554: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:30.603: INFO: Lookups using dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5956.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5956.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local jessie_udp@dns-test-service-2.dns-5956.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5956.svc.cluster.local]

Aug 18 17:33:35.322: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:35.341: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:35.361: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:35.382: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:35.442: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:35.469: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:35.488: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:35.513: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:35.551: INFO: Lookups using dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5956.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5956.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local jessie_udp@dns-test-service-2.dns-5956.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5956.svc.cluster.local]

Aug 18 17:33:40.320: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:40.342: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:40.361: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:40.379: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:40.439: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:40.457: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:40.478: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:40.497: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:40.536: INFO: Lookups using dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5956.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5956.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local jessie_udp@dns-test-service-2.dns-5956.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5956.svc.cluster.local]

Aug 18 17:33:45.344: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local from pod dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b: the server could not find the requested resource (get pods dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b)
Aug 18 17:33:45.548: INFO: Lookups using dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b failed for: [wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5956.svc.cluster.local]

Aug 18 17:33:50.546: INFO: DNS probes using dns-5956/dns-test-293ebcd0-22c7-4aa0-8091-fabf7811674b succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:33:50.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5956" for this suite.
Aug 18 17:33:58.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:33:59.097: INFO: namespace dns-5956 deletion completed in 8.442355164s

• [SLOW TEST:49.386 seconds]
[sig-network] DNS
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:33:59.097: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9110
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-76e3267b-20e5-4fd5-8427-df9b42bba7e5
Aug 18 17:33:59.330: INFO: Pod name my-hostname-basic-76e3267b-20e5-4fd5-8427-df9b42bba7e5: Found 0 pods out of 1
Aug 18 17:34:04.545: INFO: Pod name my-hostname-basic-76e3267b-20e5-4fd5-8427-df9b42bba7e5: Found 1 pods out of 1
Aug 18 17:34:04.545: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-76e3267b-20e5-4fd5-8427-df9b42bba7e5" are running
Aug 18 17:34:04.555: INFO: Pod "my-hostname-basic-76e3267b-20e5-4fd5-8427-df9b42bba7e5-r5g48" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-18 17:33:59 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-18 17:34:01 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-18 17:34:01 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-18 17:33:59 +0000 UTC Reason: Message:}])
Aug 18 17:34:04.555: INFO: Trying to dial the pod
Aug 18 17:34:09.611: INFO: Controller my-hostname-basic-76e3267b-20e5-4fd5-8427-df9b42bba7e5: Got expected result from replica 1 [my-hostname-basic-76e3267b-20e5-4fd5-8427-df9b42bba7e5-r5g48]: "my-hostname-basic-76e3267b-20e5-4fd5-8427-df9b42bba7e5-r5g48", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:34:09.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9110" for this suite.
Aug 18 17:34:15.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:34:16.115: INFO: namespace replication-controller-9110 deletion completed in 6.473712452s

• [SLOW TEST:17.018 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:34:16.116: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7235
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Aug 18 17:34:16.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-7235 -- logs-generator --log-lines-total 100 --run-duration 20s'
Aug 18 17:34:16.529: INFO: stderr: ""
Aug 18 17:34:16.529: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Aug 18 17:34:16.529: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Aug 18 17:34:16.529: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-7235" to be "running and ready, or succeeded"
Aug 18 17:34:16.543: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 13.492728ms
Aug 18 17:34:18.557: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.027671161s
Aug 18 17:34:18.557: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Aug 18 17:34:18.557: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Aug 18 17:34:18.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 logs logs-generator logs-generator --namespace=kubectl-7235'
Aug 18 17:34:18.691: INFO: stderr: ""
Aug 18 17:34:18.692: INFO: stdout: "I0818 17:34:17.728639       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/lm9 416\nI0818 17:34:17.928806       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/vsnx 332\nI0818 17:34:18.128786       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/xgx 549\nI0818 17:34:18.328792       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/7ql 247\nI0818 17:34:18.528772       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/v22h 564\n"
STEP: limiting log lines
Aug 18 17:34:18.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 logs logs-generator logs-generator --namespace=kubectl-7235 --tail=1'
Aug 18 17:34:18.833: INFO: stderr: ""
Aug 18 17:34:18.833: INFO: stdout: "I0818 17:34:18.728823       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/z7f 290\n"
STEP: limiting log bytes
Aug 18 17:34:18.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 logs logs-generator logs-generator --namespace=kubectl-7235 --limit-bytes=1'
Aug 18 17:34:19.026: INFO: stderr: ""
Aug 18 17:34:19.026: INFO: stdout: "I"
STEP: exposing timestamps
Aug 18 17:34:19.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 logs logs-generator logs-generator --namespace=kubectl-7235 --tail=1 --timestamps'
Aug 18 17:34:19.197: INFO: stderr: ""
Aug 18 17:34:19.198: INFO: stdout: "2020-08-18T17:34:19.128988778Z I0818 17:34:19.128806       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/6rb 437\n"
STEP: restricting to a time range
Aug 18 17:34:21.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 logs logs-generator logs-generator --namespace=kubectl-7235 --since=1s'
Aug 18 17:34:21.855: INFO: stderr: ""
Aug 18 17:34:21.855: INFO: stdout: "I0818 17:34:20.928802       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/p4cr 295\nI0818 17:34:21.128793       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/nz7 207\nI0818 17:34:21.328792       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/5nwn 557\nI0818 17:34:21.528802       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/mf7v 567\nI0818 17:34:21.728791       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/kcj 318\n"
Aug 18 17:34:21.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 logs logs-generator logs-generator --namespace=kubectl-7235 --since=24h'
Aug 18 17:34:21.997: INFO: stderr: ""
Aug 18 17:34:21.997: INFO: stdout: "I0818 17:34:17.728639       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/lm9 416\nI0818 17:34:17.928806       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/vsnx 332\nI0818 17:34:18.128786       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/xgx 549\nI0818 17:34:18.328792       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/7ql 247\nI0818 17:34:18.528772       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/v22h 564\nI0818 17:34:18.728823       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/z7f 290\nI0818 17:34:18.928824       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/4x4l 239\nI0818 17:34:19.128806       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/6rb 437\nI0818 17:34:19.328846       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/2k4 312\nI0818 17:34:19.528797       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/tsm 583\nI0818 17:34:19.728822       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/cxzw 498\nI0818 17:34:19.928813       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/2vr 398\nI0818 17:34:20.128806       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/f72 593\nI0818 17:34:20.328829       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/b6w 313\nI0818 17:34:20.528848       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/zp4g 458\nI0818 17:34:20.728800       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/842 363\nI0818 17:34:20.928802       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/p4cr 295\nI0818 17:34:21.128793       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/nz7 207\nI0818 17:34:21.328792       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/5nwn 557\nI0818 17:34:21.528802       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/mf7v 567\nI0818 17:34:21.728791       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/kcj 318\nI0818 17:34:21.928819       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/2jfx 573\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Aug 18 17:34:21.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete pod logs-generator --namespace=kubectl-7235'
Aug 18 17:34:30.363: INFO: stderr: ""
Aug 18 17:34:30.363: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:34:30.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7235" for this suite.
Aug 18 17:34:36.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:34:36.863: INFO: namespace kubectl-7235 deletion completed in 6.473980309s

• [SLOW TEST:20.748 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:34:36.866: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3697
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-3697
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-3697
STEP: creating replication controller externalsvc in namespace services-3697
I0818 17:34:37.186920      23 runners.go:184] Created replication controller with name: externalsvc, namespace: services-3697, replica count: 2
I0818 17:34:40.237395      23 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Aug 18 17:34:40.319: INFO: Creating new exec pod
Aug 18 17:34:44.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-3697 execpodqrn67 -- /bin/sh -x -c nslookup nodeport-service'
Aug 18 17:34:44.669: INFO: stderr: "+ nslookup nodeport-service\n"
Aug 18 17:34:44.669: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nnodeport-service.services-3697.svc.cluster.local\tcanonical name = externalsvc.services-3697.svc.cluster.local.\nName:\texternalsvc.services-3697.svc.cluster.local\nAddress: 172.21.105.184\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3697, will wait for the garbage collector to delete the pods
Aug 18 17:34:44.751: INFO: Deleting ReplicationController externalsvc took: 21.79264ms
Aug 18 17:34:44.951: INFO: Terminating ReplicationController externalsvc pods took: 200.333219ms
Aug 18 17:34:53.622: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:34:53.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3697" for this suite.
Aug 18 17:35:01.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:35:02.187: INFO: namespace services-3697 deletion completed in 8.474730269s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:25.322 seconds]
[sig-network] Services
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:35:02.188: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3885
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-4336840e-d2a9-4da1-9a6a-8e12fe33c40c
STEP: Creating a pod to test consume configMaps
Aug 18 17:35:02.459: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-56bff6f7-c6cd-4a21-99af-dbed6490a8ef" in namespace "projected-3885" to be "success or failure"
Aug 18 17:35:02.475: INFO: Pod "pod-projected-configmaps-56bff6f7-c6cd-4a21-99af-dbed6490a8ef": Phase="Pending", Reason="", readiness=false. Elapsed: 15.221882ms
Aug 18 17:35:04.487: INFO: Pod "pod-projected-configmaps-56bff6f7-c6cd-4a21-99af-dbed6490a8ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027926148s
Aug 18 17:35:06.499: INFO: Pod "pod-projected-configmaps-56bff6f7-c6cd-4a21-99af-dbed6490a8ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039494591s
STEP: Saw pod success
Aug 18 17:35:06.499: INFO: Pod "pod-projected-configmaps-56bff6f7-c6cd-4a21-99af-dbed6490a8ef" satisfied condition "success or failure"
Aug 18 17:35:06.509: INFO: Trying to get logs from node 10.241.69.172 pod pod-projected-configmaps-56bff6f7-c6cd-4a21-99af-dbed6490a8ef container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 18 17:35:06.571: INFO: Waiting for pod pod-projected-configmaps-56bff6f7-c6cd-4a21-99af-dbed6490a8ef to disappear
Aug 18 17:35:06.580: INFO: Pod pod-projected-configmaps-56bff6f7-c6cd-4a21-99af-dbed6490a8ef no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:35:06.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3885" for this suite.
Aug 18 17:35:12.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:35:13.063: INFO: namespace projected-3885 deletion completed in 6.459767229s

• [SLOW TEST:10.875 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:35:13.064: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-5151
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:35:13.329: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-1601d593-7547-4aa0-8c15-292f9698b659" in namespace "security-context-test-5151" to be "success or failure"
Aug 18 17:35:13.339: INFO: Pod "alpine-nnp-false-1601d593-7547-4aa0-8c15-292f9698b659": Phase="Pending", Reason="", readiness=false. Elapsed: 10.472281ms
Aug 18 17:35:15.351: INFO: Pod "alpine-nnp-false-1601d593-7547-4aa0-8c15-292f9698b659": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022861496s
Aug 18 17:35:17.363: INFO: Pod "alpine-nnp-false-1601d593-7547-4aa0-8c15-292f9698b659": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034163788s
Aug 18 17:35:17.363: INFO: Pod "alpine-nnp-false-1601d593-7547-4aa0-8c15-292f9698b659" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:35:17.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5151" for this suite.
Aug 18 17:35:23.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:35:23.873: INFO: namespace security-context-test-5151 deletion completed in 6.451633825s

• [SLOW TEST:10.809 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:35:23.873: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6078
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Aug 18 17:35:24.111: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 18 17:35:24.178: INFO: Waiting for terminating namespaces to be deleted...
Aug 18 17:35:24.189: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.172 before test
Aug 18 17:35:24.227: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-m29th from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 17:35:24.227: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 18 17:35:24.227: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 17:35:24.227: INFO: ibm-keepalived-watcher-2f6fp from kube-system started at 2020-08-18 15:45:12 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.227: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 17:35:24.227: INFO: addon-catalog-source-gmd49 from ibm-system started at 2020-08-18 15:45:49 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.227: INFO: 	Container configmap-registry-server ready: true, restart count 0
Aug 18 17:35:24.227: INFO: ibm-master-proxy-static-10.241.69.172 from kube-system started at 2020-08-18 15:45:10 +0000 UTC (2 container statuses recorded)
Aug 18 17:35:24.227: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 17:35:24.227: INFO: 	Container pause ready: true, restart count 0
Aug 18 17:35:24.227: INFO: calico-node-sz9mb from kube-system started at 2020-08-18 15:45:12 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.227: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 17:35:24.227: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.181 before test
Aug 18 17:35:24.310: INFO: olm-operator-6f74dfc868-28t4m from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.310: INFO: 	Container olm-operator ready: true, restart count 0
Aug 18 17:35:24.310: INFO: ibm-keepalived-watcher-kr9tn from kube-system started at 2020-08-18 15:50:03 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.310: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 17:35:24.310: INFO: sonobuoy-e2e-job-692caab668c14a3b from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 17:35:24.310: INFO: 	Container e2e ready: true, restart count 0
Aug 18 17:35:24.310: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 18 17:35:24.310: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-rwtzr from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 17:35:24.310: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 18 17:35:24.310: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 17:35:24.310: INFO: coredns-55db5d97fb-8tfqf from kube-system started at 2020-08-18 15:57:41 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.310: INFO: 	Container coredns ready: true, restart count 0
Aug 18 17:35:24.310: INFO: sonobuoy from sonobuoy started at 2020-08-18 17:08:11 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.310: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 18 17:35:24.310: INFO: kubernetes-dashboard-85b945ff4b-9cklr from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.310: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 18 17:35:24.310: INFO: public-crbstv5sqd0r3kmi9abm0g-alb1-5f59ffb4c7-4k6xv from kube-system started at 2020-08-18 17:21:45 +0000 UTC (4 container statuses recorded)
Aug 18 17:35:24.310: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 18 17:35:24.310: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 18 17:35:24.310: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 18 17:35:24.310: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 18 17:35:24.311: INFO: calico-node-vn5q9 from kube-system started at 2020-08-18 15:50:03 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.311: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 17:35:24.311: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-08-18 15:52:42 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.311: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Aug 18 17:35:24.311: INFO: coredns-autoscaler-65c89858bf-q6hj7 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.311: INFO: 	Container autoscaler ready: true, restart count 0
Aug 18 17:35:24.311: INFO: dashboard-metrics-scraper-76756886dc-rk2k2 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.311: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Aug 18 17:35:24.311: INFO: ibm-cloud-provider-ip-169-47-71-114-64b8d74dd8-8brdn from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.311: INFO: 	Container ibm-cloud-provider-ip-169-47-71-114 ready: true, restart count 0
Aug 18 17:35:24.311: INFO: ibm-master-proxy-static-10.241.69.181 from kube-system started at 2020-08-18 15:49:51 +0000 UTC (2 container statuses recorded)
Aug 18 17:35:24.311: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 17:35:24.311: INFO: 	Container pause ready: true, restart count 0
Aug 18 17:35:24.311: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.184 before test
Aug 18 17:35:24.388: INFO: coredns-55db5d97fb-2h7nb from kube-system started at 2020-08-18 15:57:41 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.388: INFO: 	Container coredns ready: true, restart count 0
Aug 18 17:35:24.389: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-ctchp from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 17:35:24.389: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 18 17:35:24.389: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 17:35:24.389: INFO: ibm-storage-watcher-5685787df4-w25gd from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.389: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug 18 17:35:24.389: INFO: ibm-master-proxy-static-10.241.69.184 from kube-system started at 2020-08-18 15:46:23 +0000 UTC (2 container statuses recorded)
Aug 18 17:35:24.389: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 17:35:24.390: INFO: 	Container pause ready: true, restart count 0
Aug 18 17:35:24.390: INFO: calico-node-f56nz from kube-system started at 2020-08-18 15:46:36 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.390: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 17:35:24.390: INFO: calico-kube-controllers-66c5f69b5f-9qvwh from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.390: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 18 17:35:24.390: INFO: ibm-keepalived-watcher-xt8rx from kube-system started at 2020-08-18 15:46:36 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.390: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 17:35:24.390: INFO: public-crbstv5sqd0r3kmi9abm0g-alb1-5f59ffb4c7-s8vcr from kube-system started at 2020-08-18 15:48:16 +0000 UTC (4 container statuses recorded)
Aug 18 17:35:24.390: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 18 17:35:24.391: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 18 17:35:24.391: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 18 17:35:24.391: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 18 17:35:24.391: INFO: ibm-file-plugin-7c6788b5f5-ldfzf from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.391: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug 18 17:35:24.391: INFO: catalog-operator-67cbc5d959-hqgh5 from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.391: INFO: 	Container catalog-operator ready: true, restart count 0
Aug 18 17:35:24.391: INFO: ibm-cloud-provider-ip-169-47-71-114-64b8d74dd8-dc47l from ibm-system started at 2020-08-18 15:46:51 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.391: INFO: 	Container ibm-cloud-provider-ip-169-47-71-114 ready: true, restart count 0
Aug 18 17:35:24.392: INFO: vpn-79845b6f9d-wmz87 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.392: INFO: 	Container vpn ready: true, restart count 0
Aug 18 17:35:24.392: INFO: metrics-server-695ffd979-8z2wt from kube-system started at 2020-08-18 17:21:45 +0000 UTC (2 container statuses recorded)
Aug 18 17:35:24.392: INFO: 	Container metrics-server ready: true, restart count 0
Aug 18 17:35:24.392: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 18 17:35:24.392: INFO: coredns-55db5d97fb-cqx5b from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 17:35:24.392: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3650484e-31ca-491c-a47e-0f69e5d707c7 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-3650484e-31ca-491c-a47e-0f69e5d707c7 off the node 10.241.69.172
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3650484e-31ca-491c-a47e-0f69e5d707c7
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:35:32.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6078" for this suite.
Aug 18 17:35:42.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:35:43.083: INFO: namespace sched-pred-6078 deletion completed in 10.44777974s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:19.210 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:35:43.083: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6575
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-6575/configmap-test-8681f6ae-8520-4a88-abcd-b460b7f91ffe
STEP: Creating a pod to test consume configMaps
Aug 18 17:35:43.343: INFO: Waiting up to 5m0s for pod "pod-configmaps-cb31c205-c7c4-49ef-bf3f-cd4709b5607d" in namespace "configmap-6575" to be "success or failure"
Aug 18 17:35:43.360: INFO: Pod "pod-configmaps-cb31c205-c7c4-49ef-bf3f-cd4709b5607d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.681024ms
Aug 18 17:35:45.372: INFO: Pod "pod-configmaps-cb31c205-c7c4-49ef-bf3f-cd4709b5607d": Phase="Running", Reason="", readiness=true. Elapsed: 2.028897532s
Aug 18 17:35:47.384: INFO: Pod "pod-configmaps-cb31c205-c7c4-49ef-bf3f-cd4709b5607d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041213704s
STEP: Saw pod success
Aug 18 17:35:47.384: INFO: Pod "pod-configmaps-cb31c205-c7c4-49ef-bf3f-cd4709b5607d" satisfied condition "success or failure"
Aug 18 17:35:47.394: INFO: Trying to get logs from node 10.241.69.172 pod pod-configmaps-cb31c205-c7c4-49ef-bf3f-cd4709b5607d container env-test: <nil>
STEP: delete the pod
Aug 18 17:35:47.453: INFO: Waiting for pod pod-configmaps-cb31c205-c7c4-49ef-bf3f-cd4709b5607d to disappear
Aug 18 17:35:47.464: INFO: Pod pod-configmaps-cb31c205-c7c4-49ef-bf3f-cd4709b5607d no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:35:47.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6575" for this suite.
Aug 18 17:35:53.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:35:53.940: INFO: namespace configmap-6575 deletion completed in 6.445729621s

• [SLOW TEST:10.858 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:35:53.942: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4985
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-76f07e12-adde-4f8c-839e-d4222f64f30f
STEP: Creating a pod to test consume configMaps
Aug 18 17:35:54.202: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e79e7b2f-22d2-4209-99aa-6f73261a02c8" in namespace "projected-4985" to be "success or failure"
Aug 18 17:35:54.213: INFO: Pod "pod-projected-configmaps-e79e7b2f-22d2-4209-99aa-6f73261a02c8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.019864ms
Aug 18 17:35:56.225: INFO: Pod "pod-projected-configmaps-e79e7b2f-22d2-4209-99aa-6f73261a02c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022358619s
STEP: Saw pod success
Aug 18 17:35:56.225: INFO: Pod "pod-projected-configmaps-e79e7b2f-22d2-4209-99aa-6f73261a02c8" satisfied condition "success or failure"
Aug 18 17:35:56.235: INFO: Trying to get logs from node 10.241.69.172 pod pod-projected-configmaps-e79e7b2f-22d2-4209-99aa-6f73261a02c8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 18 17:35:56.299: INFO: Waiting for pod pod-projected-configmaps-e79e7b2f-22d2-4209-99aa-6f73261a02c8 to disappear
Aug 18 17:35:56.309: INFO: Pod pod-projected-configmaps-e79e7b2f-22d2-4209-99aa-6f73261a02c8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:35:56.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4985" for this suite.
Aug 18 17:36:02.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:36:02.776: INFO: namespace projected-4985 deletion completed in 6.451658145s

• [SLOW TEST:8.833 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:36:02.776: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8898
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:36:03.095: INFO: Create a RollingUpdate DaemonSet
Aug 18 17:36:03.111: INFO: Check that daemon pods launch on every node of the cluster
Aug 18 17:36:03.144: INFO: Number of nodes with available pods: 0
Aug 18 17:36:03.144: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:36:04.176: INFO: Number of nodes with available pods: 0
Aug 18 17:36:04.176: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:36:05.173: INFO: Number of nodes with available pods: 2
Aug 18 17:36:05.173: INFO: Node 10.241.69.184 is running more than one daemon pod
Aug 18 17:36:06.184: INFO: Number of nodes with available pods: 3
Aug 18 17:36:06.184: INFO: Number of running nodes: 3, number of available pods: 3
Aug 18 17:36:06.184: INFO: Update the DaemonSet to trigger a rollout
Aug 18 17:36:06.214: INFO: Updating DaemonSet daemon-set
Aug 18 17:36:09.265: INFO: Roll back the DaemonSet before rollout is complete
Aug 18 17:36:09.288: INFO: Updating DaemonSet daemon-set
Aug 18 17:36:09.288: INFO: Make sure DaemonSet rollback is complete
Aug 18 17:36:09.298: INFO: Wrong image for pod: daemon-set-rm28t. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Aug 18 17:36:09.298: INFO: Pod daemon-set-rm28t is not available
Aug 18 17:36:10.325: INFO: Wrong image for pod: daemon-set-rm28t. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Aug 18 17:36:10.325: INFO: Pod daemon-set-rm28t is not available
Aug 18 17:36:11.325: INFO: Pod daemon-set-qgqnb is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8898, will wait for the garbage collector to delete the pods
Aug 18 17:36:11.448: INFO: Deleting DaemonSet.extensions daemon-set took: 24.8601ms
Aug 18 17:36:11.648: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.696178ms
Aug 18 17:36:23.562: INFO: Number of nodes with available pods: 0
Aug 18 17:36:23.562: INFO: Number of running nodes: 0, number of available pods: 0
Aug 18 17:36:23.575: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8898/daemonsets","resourceVersion":"23929"},"items":null}

Aug 18 17:36:23.586: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8898/pods","resourceVersion":"23929"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:36:23.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8898" for this suite.
Aug 18 17:36:31.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:36:32.089: INFO: namespace daemonsets-8898 deletion completed in 8.439075357s

• [SLOW TEST:29.313 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:36:32.089: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8165
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:36:36.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8165" for this suite.
Aug 18 17:36:42.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:36:42.826: INFO: namespace kubelet-test-8165 deletion completed in 6.43912307s

• [SLOW TEST:10.737 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:36:42.827: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3045
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 17:36:43.068: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bacc4646-370a-42b2-bf9c-fe0882f58f20" in namespace "projected-3045" to be "success or failure"
Aug 18 17:36:43.079: INFO: Pod "downwardapi-volume-bacc4646-370a-42b2-bf9c-fe0882f58f20": Phase="Pending", Reason="", readiness=false. Elapsed: 10.351124ms
Aug 18 17:36:45.091: INFO: Pod "downwardapi-volume-bacc4646-370a-42b2-bf9c-fe0882f58f20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022115719s
STEP: Saw pod success
Aug 18 17:36:45.091: INFO: Pod "downwardapi-volume-bacc4646-370a-42b2-bf9c-fe0882f58f20" satisfied condition "success or failure"
Aug 18 17:36:45.102: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-bacc4646-370a-42b2-bf9c-fe0882f58f20 container client-container: <nil>
STEP: delete the pod
Aug 18 17:36:45.166: INFO: Waiting for pod downwardapi-volume-bacc4646-370a-42b2-bf9c-fe0882f58f20 to disappear
Aug 18 17:36:45.177: INFO: Pod downwardapi-volume-bacc4646-370a-42b2-bf9c-fe0882f58f20 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:36:45.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3045" for this suite.
Aug 18 17:36:51.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:36:51.622: INFO: namespace projected-3045 deletion completed in 6.426753689s

• [SLOW TEST:8.795 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:36:51.623: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1301
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:36:51.913: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 18 17:36:51.935: INFO: Number of nodes with available pods: 0
Aug 18 17:36:51.935: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug 18 17:36:51.984: INFO: Number of nodes with available pods: 0
Aug 18 17:36:51.984: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:36:52.996: INFO: Number of nodes with available pods: 0
Aug 18 17:36:52.997: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:36:53.995: INFO: Number of nodes with available pods: 1
Aug 18 17:36:53.995: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 18 17:36:54.052: INFO: Number of nodes with available pods: 1
Aug 18 17:36:54.052: INFO: Number of running nodes: 0, number of available pods: 1
Aug 18 17:36:55.063: INFO: Number of nodes with available pods: 0
Aug 18 17:36:55.063: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 18 17:36:55.086: INFO: Number of nodes with available pods: 0
Aug 18 17:36:55.086: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:36:56.097: INFO: Number of nodes with available pods: 0
Aug 18 17:36:56.097: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:36:57.099: INFO: Number of nodes with available pods: 0
Aug 18 17:36:57.099: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:36:58.098: INFO: Number of nodes with available pods: 0
Aug 18 17:36:58.098: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:36:59.101: INFO: Number of nodes with available pods: 0
Aug 18 17:36:59.101: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:37:00.098: INFO: Number of nodes with available pods: 0
Aug 18 17:37:00.098: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:37:01.097: INFO: Number of nodes with available pods: 0
Aug 18 17:37:01.097: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:37:02.099: INFO: Number of nodes with available pods: 1
Aug 18 17:37:02.099: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1301, will wait for the garbage collector to delete the pods
Aug 18 17:37:02.227: INFO: Deleting DaemonSet.extensions daemon-set took: 27.631892ms
Aug 18 17:37:02.427: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.274962ms
Aug 18 17:37:10.438: INFO: Number of nodes with available pods: 0
Aug 18 17:37:10.438: INFO: Number of running nodes: 0, number of available pods: 0
Aug 18 17:37:10.451: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1301/daemonsets","resourceVersion":"24179"},"items":null}

Aug 18 17:37:10.461: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1301/pods","resourceVersion":"24179"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:37:10.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1301" for this suite.
Aug 18 17:37:18.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:37:18.993: INFO: namespace daemonsets-1301 deletion completed in 8.444997396s

• [SLOW TEST:27.371 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:37:18.993: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5802
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-0aa9af6e-5914-4298-8532-7e4763c44b59
STEP: Creating configMap with name cm-test-opt-upd-8ff3907c-82c6-4536-9110-9dedbe961507
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-0aa9af6e-5914-4298-8532-7e4763c44b59
STEP: Updating configmap cm-test-opt-upd-8ff3907c-82c6-4536-9110-9dedbe961507
STEP: Creating configMap with name cm-test-opt-create-c8c5bd91-75a9-4aed-8f8b-d6f7479db149
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:38:28.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5802" for this suite.
Aug 18 17:38:42.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:38:43.004: INFO: namespace projected-5802 deletion completed in 14.435063774s

• [SLOW TEST:84.011 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:38:43.005: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-48
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:38:43.229: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:38:48.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-48" for this suite.
Aug 18 17:38:54.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:38:55.198: INFO: namespace custom-resource-definition-48 deletion completed in 6.471924058s

• [SLOW TEST:12.194 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:38:55.199: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9790
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Aug 18 17:38:55.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-9790'
Aug 18 17:38:55.686: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 18 17:38:55.686: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Aug 18 17:38:55.701: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Aug 18 17:38:55.703: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug 18 17:38:55.713: INFO: scanned /root for discovery docs: <nil>
Aug 18 17:38:55.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9790'
Aug 18 17:39:11.682: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 18 17:39:11.682: INFO: stdout: "Created e2e-test-httpd-rc-fe25c9c15edb556b6e90b6460521894b\nScaling up e2e-test-httpd-rc-fe25c9c15edb556b6e90b6460521894b from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-fe25c9c15edb556b6e90b6460521894b up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-fe25c9c15edb556b6e90b6460521894b to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Aug 18 17:39:11.682: INFO: stdout: "Created e2e-test-httpd-rc-fe25c9c15edb556b6e90b6460521894b\nScaling up e2e-test-httpd-rc-fe25c9c15edb556b6e90b6460521894b from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-fe25c9c15edb556b6e90b6460521894b up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-fe25c9c15edb556b6e90b6460521894b to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Aug 18 17:39:11.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-9790'
Aug 18 17:39:11.800: INFO: stderr: ""
Aug 18 17:39:11.800: INFO: stdout: "e2e-test-httpd-rc-fe25c9c15edb556b6e90b6460521894b-jknz4 "
Aug 18 17:39:11.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods e2e-test-httpd-rc-fe25c9c15edb556b6e90b6460521894b-jknz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9790'
Aug 18 17:39:11.903: INFO: stderr: ""
Aug 18 17:39:11.903: INFO: stdout: "true"
Aug 18 17:39:11.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods e2e-test-httpd-rc-fe25c9c15edb556b6e90b6460521894b-jknz4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9790'
Aug 18 17:39:12.004: INFO: stderr: ""
Aug 18 17:39:12.004: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Aug 18 17:39:12.004: INFO: e2e-test-httpd-rc-fe25c9c15edb556b6e90b6460521894b-jknz4 is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Aug 18 17:39:12.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete rc e2e-test-httpd-rc --namespace=kubectl-9790'
Aug 18 17:39:12.172: INFO: stderr: ""
Aug 18 17:39:12.172: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:39:12.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9790" for this suite.
Aug 18 17:39:24.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:39:24.647: INFO: namespace kubectl-9790 deletion completed in 12.442530162s

• [SLOW TEST:29.449 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:39:24.648: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-3813
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Aug 18 17:39:25.454: INFO: created pod pod-service-account-defaultsa
Aug 18 17:39:25.454: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 18 17:39:25.467: INFO: created pod pod-service-account-mountsa
Aug 18 17:39:25.467: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 18 17:39:25.479: INFO: created pod pod-service-account-nomountsa
Aug 18 17:39:25.479: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 18 17:39:25.495: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 18 17:39:25.495: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 18 17:39:25.507: INFO: created pod pod-service-account-mountsa-mountspec
Aug 18 17:39:25.507: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 18 17:39:25.522: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 18 17:39:25.522: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 18 17:39:25.535: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 18 17:39:25.535: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 18 17:39:25.547: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 18 17:39:25.547: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 18 17:39:25.558: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 18 17:39:25.558: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:39:25.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3813" for this suite.
Aug 18 17:39:33.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:39:34.032: INFO: namespace svcaccounts-3813 deletion completed in 8.452658855s

• [SLOW TEST:9.384 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:39:34.032: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4406
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 17:39:34.272: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23ac0ac9-ac7d-4087-89d6-0b2435681520" in namespace "projected-4406" to be "success or failure"
Aug 18 17:39:34.282: INFO: Pod "downwardapi-volume-23ac0ac9-ac7d-4087-89d6-0b2435681520": Phase="Pending", Reason="", readiness=false. Elapsed: 9.813365ms
Aug 18 17:39:36.295: INFO: Pod "downwardapi-volume-23ac0ac9-ac7d-4087-89d6-0b2435681520": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022654514s
STEP: Saw pod success
Aug 18 17:39:36.295: INFO: Pod "downwardapi-volume-23ac0ac9-ac7d-4087-89d6-0b2435681520" satisfied condition "success or failure"
Aug 18 17:39:36.308: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-23ac0ac9-ac7d-4087-89d6-0b2435681520 container client-container: <nil>
STEP: delete the pod
Aug 18 17:39:36.379: INFO: Waiting for pod downwardapi-volume-23ac0ac9-ac7d-4087-89d6-0b2435681520 to disappear
Aug 18 17:39:36.393: INFO: Pod downwardapi-volume-23ac0ac9-ac7d-4087-89d6-0b2435681520 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:39:36.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4406" for this suite.
Aug 18 17:39:42.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:39:42.857: INFO: namespace projected-4406 deletion completed in 6.445638283s

• [SLOW TEST:8.825 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:39:42.857: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8175
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug 18 17:39:43.108: INFO: Pod name pod-release: Found 0 pods out of 1
Aug 18 17:39:48.120: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:39:48.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8175" for this suite.
Aug 18 17:39:56.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:39:56.640: INFO: namespace replication-controller-8175 deletion completed in 8.461670778s

• [SLOW TEST:13.783 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:39:56.642: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7615
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Aug 18 17:39:56.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-7615'
Aug 18 17:39:56.988: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 18 17:39:56.988: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Aug 18 17:39:59.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete deployment e2e-test-httpd-deployment --namespace=kubectl-7615'
Aug 18 17:39:59.133: INFO: stderr: ""
Aug 18 17:39:59.133: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:39:59.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7615" for this suite.
Aug 18 17:40:29.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:40:29.604: INFO: namespace kubectl-7615 deletion completed in 30.452696513s

• [SLOW TEST:32.963 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:40:29.608: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9622
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:40:46.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9622" for this suite.
Aug 18 17:40:53.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:40:53.461: INFO: namespace resourcequota-9622 deletion completed in 6.464811768s

• [SLOW TEST:23.854 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:40:53.461: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5231
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 17:40:53.722: INFO: Waiting up to 5m0s for pod "downwardapi-volume-da4ea877-fb04-4d90-b535-30efbd93454c" in namespace "downward-api-5231" to be "success or failure"
Aug 18 17:40:53.738: INFO: Pod "downwardapi-volume-da4ea877-fb04-4d90-b535-30efbd93454c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.060947ms
Aug 18 17:40:55.752: INFO: Pod "downwardapi-volume-da4ea877-fb04-4d90-b535-30efbd93454c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029992915s
STEP: Saw pod success
Aug 18 17:40:55.752: INFO: Pod "downwardapi-volume-da4ea877-fb04-4d90-b535-30efbd93454c" satisfied condition "success or failure"
Aug 18 17:40:55.763: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-da4ea877-fb04-4d90-b535-30efbd93454c container client-container: <nil>
STEP: delete the pod
Aug 18 17:40:55.829: INFO: Waiting for pod downwardapi-volume-da4ea877-fb04-4d90-b535-30efbd93454c to disappear
Aug 18 17:40:55.841: INFO: Pod downwardapi-volume-da4ea877-fb04-4d90-b535-30efbd93454c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:40:55.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5231" for this suite.
Aug 18 17:41:01.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:41:02.340: INFO: namespace downward-api-5231 deletion completed in 6.473733278s

• [SLOW TEST:8.878 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:41:02.340: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5004
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:41:02.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5004" for this suite.
Aug 18 17:41:14.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:41:15.098: INFO: namespace pods-5004 deletion completed in 12.467354693s

• [SLOW TEST:12.758 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:41:15.099: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6180
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:41:15.343: INFO: Creating deployment "webserver-deployment"
Aug 18 17:41:15.368: INFO: Waiting for observed generation 1
Aug 18 17:41:17.397: INFO: Waiting for all required pods to come up
Aug 18 17:41:17.419: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug 18 17:41:19.445: INFO: Waiting for deployment "webserver-deployment" to complete
Aug 18 17:41:19.469: INFO: Updating deployment "webserver-deployment" with a non-existent image
Aug 18 17:41:19.496: INFO: Updating deployment webserver-deployment
Aug 18 17:41:19.496: INFO: Waiting for observed generation 2
Aug 18 17:41:21.522: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 18 17:41:21.532: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 18 17:41:21.543: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Aug 18 17:41:21.577: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 18 17:41:21.578: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 18 17:41:21.588: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Aug 18 17:41:21.610: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Aug 18 17:41:21.610: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Aug 18 17:41:21.638: INFO: Updating deployment webserver-deployment
Aug 18 17:41:21.638: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Aug 18 17:41:21.659: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 18 17:41:23.683: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Aug 18 17:41:23.708: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-6180 /apis/apps/v1/namespaces/deployment-6180/deployments/webserver-deployment d9034a70-0651-4cc7-aad0-cb8a7f446438 25620 3 2020-08-18 17:41:15 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0035e8548 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:12,UnavailableReplicas:21,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-08-18 17:41:21 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-08-18 17:41:23 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,},},ReadyReplicas:12,CollisionCount:nil,},}

Aug 18 17:41:23.725: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-6180 /apis/apps/v1/namespaces/deployment-6180/replicasets/webserver-deployment-c7997dcc8 fa57e2a9-5d77-4fa3-a062-c6de3f0276ee 25474 3 2020-08-18 17:41:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment d9034a70-0651-4cc7-aad0-cb8a7f446438 0xc003bf3527 0xc003bf3528}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003bf3598 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 18 17:41:23.725: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Aug 18 17:41:23.725: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-6180 /apis/apps/v1/namespaces/deployment-6180/replicasets/webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 25619 3 2020-08-18 17:41:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment d9034a70-0651-4cc7-aad0-cb8a7f446438 0xc003bf3467 0xc003bf3468}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003bf34c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:12,AvailableReplicas:12,Conditions:[]ReplicaSetCondition{},},}
Aug 18 17:41:23.752: INFO: Pod "webserver-deployment-595b5b9587-22mlc" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-22mlc webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-22mlc cfc89a1b-6911-4276-85ab-0d137875d346 25283 0 2020-08-18 17:41:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e8947 0xc0035e8948}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.184,PodIP:172.30.134.97,StartTime:2020-08-18 17:41:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 17:41:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://bd058e42253826ee0014e09c917b64b76377307ea8f4c93d466c482e048f4d77,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.134.97,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.752: INFO: Pod "webserver-deployment-595b5b9587-6wknd" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6wknd webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-6wknd 8921ce78-e5a8-44fe-adef-f05f4b052fb9 25512 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e8ac7 0xc0035e8ac8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.181,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.181,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.752: INFO: Pod "webserver-deployment-595b5b9587-7dk65" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7dk65 webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-7dk65 29f7bef0-8a9c-4580-9a46-fcf2e7cdf6b7 25502 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e8c27 0xc0035e8c28}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.181,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.181,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.753: INFO: Pod "webserver-deployment-595b5b9587-7qqh8" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7qqh8 webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-7qqh8 db897a51-8909-45dc-b5e0-b036d23de65a 25611 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e8d87 0xc0035e8d88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.181,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.181,PodIP:172.30.108.29,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 17:41:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://4e0a0e8caff3caa09ee52dc7bcd69b474462d92ffdaf69daec84204a0646eca6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.108.29,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.753: INFO: Pod "webserver-deployment-595b5b9587-8zqbc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8zqbc webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-8zqbc 39da4b3a-d49c-4be0-8a0d-9ccfa34838cc 25507 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e8f07 0xc0035e8f08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.753: INFO: Pod "webserver-deployment-595b5b9587-djjtn" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-djjtn webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-djjtn 0c017ee0-6fa2-4ff9-a835-590d1787ee02 25579 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e9067 0xc0035e9068}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.184,PodIP:172.30.134.100,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 17:41:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://cf92fa1b670f86b7dc9ad001fabb127fdd6717b289b7679775df3851e68e7f86,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.134.100,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.753: INFO: Pod "webserver-deployment-595b5b9587-gk84j" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gk84j webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-gk84j c6ca86cb-91a5-4ddd-9875-93d062e0d0dd 25600 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e91e7 0xc0035e91e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:172.30.104.185,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 17:41:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://cff9e548995eac5dc3e16fb2069a426dcf3a9a4963b254e809dca8de922c3a77,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.185,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.753: INFO: Pod "webserver-deployment-595b5b9587-jrmm6" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jrmm6 webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-jrmm6 d6715ac6-ebd7-4a64-bb7a-ea26f900510f 25484 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e9367 0xc0035e9368}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.184,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.753: INFO: Pod "webserver-deployment-595b5b9587-kjpmc" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kjpmc webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-kjpmc d3dd1471-8aae-452b-b016-26b7ee72d627 25293 0 2020-08-18 17:41:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e94c7 0xc0035e94c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:172.30.104.142,StartTime:2020-08-18 17:41:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 17:41:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://c38071999e9bd07e730828915b7dae9cee9ce4e369b02980d785a2608270dbef,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.142,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.754: INFO: Pod "webserver-deployment-595b5b9587-nw6xr" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nw6xr webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-nw6xr 665e9b51-aa6b-4a22-9b0a-07344297516c 25492 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e9647 0xc0035e9648}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.184,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.754: INFO: Pod "webserver-deployment-595b5b9587-qbbrx" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qbbrx webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-qbbrx 68158d7d-0d99-4a02-81fe-f03cf7b253bf 25277 0 2020-08-18 17:41:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e97a7 0xc0035e97a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.184,PodIP:172.30.134.99,StartTime:2020-08-18 17:41:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 17:41:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://9f1176527b6d38099ab8c19c21b285953ca141f6b7efca30823b5f0a29e69d48,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.134.99,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.754: INFO: Pod "webserver-deployment-595b5b9587-qgrt2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qgrt2 webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-qgrt2 e1f3a3da-b260-4970-b77e-9690cc4eaa0c 25486 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e9927 0xc0035e9928}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.754: INFO: Pod "webserver-deployment-595b5b9587-qxs7w" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qxs7w webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-qxs7w 7b17ab8a-ab7c-43c3-991c-b0105a5c6105 25303 0 2020-08-18 17:41:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e9a87 0xc0035e9a88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.181,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.181,PodIP:172.30.108.26,StartTime:2020-08-18 17:41:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 17:41:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://e6d903514b75918ded7d43f0acdb2de47a511ca6da850c72c1e6dfcd20d36169,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.108.26,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.754: INFO: Pod "webserver-deployment-595b5b9587-t598f" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-t598f webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-t598f a8c7983a-f815-4cd8-9364-3da7af22fa09 25289 0 2020-08-18 17:41:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e9c07 0xc0035e9c08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:172.30.104.145,StartTime:2020-08-18 17:41:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 17:41:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://17ee2e5ec5a84342a5d2aac931c350cc04426707d0f65a1500b77fa964912997,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.145,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.754: INFO: Pod "webserver-deployment-595b5b9587-t8pd6" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-t8pd6 webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-t8pd6 04c87fbb-c6e7-49cb-b511-947f00560d8f 25302 0 2020-08-18 17:41:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e9d87 0xc0035e9d88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:172.30.104.180,StartTime:2020-08-18 17:41:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 17:41:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://3ebd93633effbdc49cbeec10c70dc71a5bdf7d85f641ed69a49aa988d5ceb37a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.180,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.755: INFO: Pod "webserver-deployment-595b5b9587-v5tpt" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-v5tpt webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-v5tpt 6ecb8624-f772-4090-8854-1a7b10a69692 25297 0 2020-08-18 17:41:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0035e9f07 0xc0035e9f08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:172.30.104.135,StartTime:2020-08-18 17:41:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 17:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://3092f3ea3edb4374bbbe4a3808dd822c0543bca8d69af219bb3af360df81832e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.135,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.759: INFO: Pod "webserver-deployment-595b5b9587-vfx2m" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vfx2m webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-vfx2m 6e9dded5-14be-441e-9579-e14706965f99 25504 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0036ea087 0xc0036ea088}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.184,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.759: INFO: Pod "webserver-deployment-595b5b9587-wlq7w" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wlq7w webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-wlq7w 548e832c-c82b-4a86-9769-e81721f0a0d1 25510 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0036ea1e7 0xc0036ea1e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.184,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.760: INFO: Pod "webserver-deployment-595b5b9587-x7swl" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-x7swl webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-x7swl 7d588896-61eb-49c0-901c-5c9d6cc0e114 25295 0 2020-08-18 17:41:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0036ea347 0xc0036ea348}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.181,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.181,PodIP:172.30.108.25,StartTime:2020-08-18 17:41:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 17:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://dcf64b0b6065410e44bf8e92365d5377dbf5267a4ec9e719dfb83a22e14f658b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.108.25,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.760: INFO: Pod "webserver-deployment-595b5b9587-x9r65" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-x9r65 webserver-deployment-595b5b9587- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-595b5b9587-x9r65 fbd19a91-1036-4cc0-80dd-050a85da849c 25618 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 34297a50-47c5-4ff3-acd0-2b255b5cd3e4 0xc0036ea4c7 0xc0036ea4c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:172.30.104.184,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 17:41:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://00d050cbd2678a1fe78ae0e3ec8bbd19221ca48d845288ceed86582389f8e662,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.184,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.760: INFO: Pod "webserver-deployment-c7997dcc8-4h6hg" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-4h6hg webserver-deployment-c7997dcc8- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-c7997dcc8-4h6hg 416b0978-f62c-4803-bdf8-89198e58459f 25478 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 fa57e2a9-5d77-4fa3-a062-c6de3f0276ee 0xc0036ea647 0xc0036ea648}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.760: INFO: Pod "webserver-deployment-c7997dcc8-589x2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-589x2 webserver-deployment-c7997dcc8- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-c7997dcc8-589x2 222de097-29ee-4c31-b336-92accc003560 25476 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 fa57e2a9-5d77-4fa3-a062-c6de3f0276ee 0xc0036ea7c7 0xc0036ea7c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.184,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.761: INFO: Pod "webserver-deployment-c7997dcc8-7z5cc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7z5cc webserver-deployment-c7997dcc8- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-c7997dcc8-7z5cc 42156853-eb2b-4039-ae1f-784556d68f8c 25527 0 2020-08-18 17:41:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 fa57e2a9-5d77-4fa3-a062-c6de3f0276ee 0xc0036ea947 0xc0036ea948}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:172.30.104.182,StartTime:2020-08-18 17:41:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.182,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.761: INFO: Pod "webserver-deployment-c7997dcc8-8xvcw" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8xvcw webserver-deployment-c7997dcc8- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-c7997dcc8-8xvcw 6756a4a6-6d02-40d7-9739-47ba24bd91e0 25405 0 2020-08-18 17:41:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 fa57e2a9-5d77-4fa3-a062-c6de3f0276ee 0xc0036eaaf7 0xc0036eaaf8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:172.30.104.144,StartTime:2020-08-18 17:41:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.144,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.761: INFO: Pod "webserver-deployment-c7997dcc8-b8dnk" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-b8dnk webserver-deployment-c7997dcc8- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-c7997dcc8-b8dnk c538e310-6114-434b-a7f1-fada616345e4 25490 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 fa57e2a9-5d77-4fa3-a062-c6de3f0276ee 0xc0036eaca7 0xc0036eaca8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.181,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.181,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.762: INFO: Pod "webserver-deployment-c7997dcc8-d4nl7" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-d4nl7 webserver-deployment-c7997dcc8- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-c7997dcc8-d4nl7 db8aad94-bf90-4010-b7f7-6e4e73a65e79 25409 0 2020-08-18 17:41:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 fa57e2a9-5d77-4fa3-a062-c6de3f0276ee 0xc0036eae27 0xc0036eae28}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.181,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.181,PodIP:172.30.108.27,StartTime:2020-08-18 17:41:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.108.27,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.765: INFO: Pod "webserver-deployment-c7997dcc8-gshwv" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gshwv webserver-deployment-c7997dcc8- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-c7997dcc8-gshwv e3f1c14f-3683-4c2c-9c9b-be62d866bd23 25610 0 2020-08-18 17:41:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 fa57e2a9-5d77-4fa3-a062-c6de3f0276ee 0xc0036eafd7 0xc0036eafd8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:172.30.104.183,StartTime:2020-08-18 17:41:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.183,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.767: INFO: Pod "webserver-deployment-c7997dcc8-gw6b7" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gw6b7 webserver-deployment-c7997dcc8- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-c7997dcc8-gw6b7 4b1d89e2-97c4-4722-8261-d77fa9866308 25518 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 fa57e2a9-5d77-4fa3-a062-c6de3f0276ee 0xc0036eb187 0xc0036eb188}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.181,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.181,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.767: INFO: Pod "webserver-deployment-c7997dcc8-h6nrx" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-h6nrx webserver-deployment-c7997dcc8- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-c7997dcc8-h6nrx 9dcea428-acaf-4573-a1ba-de7e82f10d4e 25466 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 fa57e2a9-5d77-4fa3-a062-c6de3f0276ee 0xc0036eb307 0xc0036eb308}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.181,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.181,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.767: INFO: Pod "webserver-deployment-c7997dcc8-j4rz7" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-j4rz7 webserver-deployment-c7997dcc8- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-c7997dcc8-j4rz7 0d2ac8f0-f7ee-4e71-ad07-d1017e0dc41a 25499 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 fa57e2a9-5d77-4fa3-a062-c6de3f0276ee 0xc0036eb487 0xc0036eb488}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.768: INFO: Pod "webserver-deployment-c7997dcc8-pcwfn" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-pcwfn webserver-deployment-c7997dcc8- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-c7997dcc8-pcwfn 1283abb4-207f-47bc-8475-1d4ffafc8676 25398 0 2020-08-18 17:41:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 fa57e2a9-5d77-4fa3-a062-c6de3f0276ee 0xc0036eb607 0xc0036eb608}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.184,PodIP:172.30.134.98,StartTime:2020-08-18 17:41:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.134.98,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.768: INFO: Pod "webserver-deployment-c7997dcc8-rfh7x" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-rfh7x webserver-deployment-c7997dcc8- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-c7997dcc8-rfh7x 2c8cbc4b-d883-4d8e-83f4-69e087dc94c8 25498 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 fa57e2a9-5d77-4fa3-a062-c6de3f0276ee 0xc0036eb7b7 0xc0036eb7b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.184,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 18 17:41:23.768: INFO: Pod "webserver-deployment-c7997dcc8-wzbg5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-wzbg5 webserver-deployment-c7997dcc8- deployment-6180 /api/v1/namespaces/deployment-6180/pods/webserver-deployment-c7997dcc8-wzbg5 97f6ab1d-ec93-4710-9438-38c603bb5c80 25494 0 2020-08-18 17:41:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 fa57e2a9-5d77-4fa3-a062-c6de3f0276ee 0xc0036eb937 0xc0036eb938}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rv6n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rv6n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rv6n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:41:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:,StartTime:2020-08-18 17:41:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:41:23.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6180" for this suite.
Aug 18 17:41:35.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:41:36.334: INFO: namespace deployment-6180 deletion completed in 12.545214088s

• [SLOW TEST:21.236 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:41:36.335: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6829
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:41:36.605: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:41:37.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6829" for this suite.
Aug 18 17:41:43.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:41:44.183: INFO: namespace custom-resource-definition-6829 deletion completed in 6.463301083s

• [SLOW TEST:7.848 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:41:44.183: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-1763
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:41:44.458: INFO: (0) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 25.884056ms)
Aug 18 17:41:44.479: INFO: (1) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 21.212984ms)
Aug 18 17:41:44.499: INFO: (2) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.283977ms)
Aug 18 17:41:44.519: INFO: (3) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.157672ms)
Aug 18 17:41:44.539: INFO: (4) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 19.758446ms)
Aug 18 17:41:44.563: INFO: (5) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.746391ms)
Aug 18 17:41:44.583: INFO: (6) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.265793ms)
Aug 18 17:41:44.604: INFO: (7) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.904522ms)
Aug 18 17:41:44.628: INFO: (8) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.400181ms)
Aug 18 17:41:44.651: INFO: (9) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.222118ms)
Aug 18 17:41:44.677: INFO: (10) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 26.397898ms)
Aug 18 17:41:44.710: INFO: (11) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 32.212775ms)
Aug 18 17:41:44.732: INFO: (12) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.504521ms)
Aug 18 17:41:44.755: INFO: (13) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.740243ms)
Aug 18 17:41:44.778: INFO: (14) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.387788ms)
Aug 18 17:41:44.801: INFO: (15) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.090807ms)
Aug 18 17:41:44.823: INFO: (16) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.303168ms)
Aug 18 17:41:44.845: INFO: (17) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.069035ms)
Aug 18 17:41:44.866: INFO: (18) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 21.035362ms)
Aug 18 17:41:44.887: INFO: (19) /api/v1/nodes/10.241.69.172:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.544343ms)
[AfterEach] version v1
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:41:44.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1763" for this suite.
Aug 18 17:41:50.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:41:51.364: INFO: namespace proxy-1763 deletion completed in 6.440338772s

• [SLOW TEST:7.181 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:41:51.364: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5088
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5088
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5088
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5088
Aug 18 17:41:51.619: INFO: Found 0 stateful pods, waiting for 1
Aug 18 17:42:01.632: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 18 17:42:01.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-5088 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 18 17:42:01.937: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 18 17:42:01.937: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 18 17:42:01.937: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 18 17:42:01.950: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 18 17:42:11.962: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 18 17:42:11.962: INFO: Waiting for statefulset status.replicas updated to 0
Aug 18 17:42:12.020: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999997878s
Aug 18 17:42:13.034: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.988655283s
Aug 18 17:42:14.049: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.975125796s
Aug 18 17:42:15.062: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.959597482s
Aug 18 17:42:16.074: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.946426073s
Aug 18 17:42:17.086: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.934950685s
Aug 18 17:42:18.098: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.922677413s
Aug 18 17:42:19.111: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.910841004s
Aug 18 17:42:20.125: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.89799569s
Aug 18 17:42:21.138: INFO: Verifying statefulset ss doesn't scale past 1 for another 884.286287ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5088
Aug 18 17:42:22.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-5088 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 18 17:42:22.453: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 18 17:42:22.453: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 18 17:42:22.453: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 18 17:42:22.464: INFO: Found 1 stateful pods, waiting for 3
Aug 18 17:42:32.479: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 18 17:42:32.479: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 18 17:42:32.479: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 18 17:42:32.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-5088 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 18 17:42:32.770: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 18 17:42:32.770: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 18 17:42:32.770: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 18 17:42:32.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-5088 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 18 17:42:33.081: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 18 17:42:33.081: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 18 17:42:33.081: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 18 17:42:33.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-5088 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 18 17:42:33.381: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 18 17:42:33.381: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 18 17:42:33.381: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 18 17:42:33.381: INFO: Waiting for statefulset status.replicas updated to 0
Aug 18 17:42:33.392: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Aug 18 17:42:43.416: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 18 17:42:43.416: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 18 17:42:43.416: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 18 17:42:43.473: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998103s
Aug 18 17:42:44.488: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985464271s
Aug 18 17:42:45.509: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.971037039s
Aug 18 17:42:46.524: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.94921549s
Aug 18 17:42:47.538: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.934455979s
Aug 18 17:42:48.553: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.920361606s
Aug 18 17:42:49.568: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.9051695s
Aug 18 17:42:50.582: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.890494031s
Aug 18 17:42:51.597: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.876181562s
Aug 18 17:42:52.611: INFO: Verifying statefulset ss doesn't scale past 3 for another 861.852713ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5088
Aug 18 17:42:53.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-5088 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 18 17:42:54.144: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 18 17:42:54.144: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 18 17:42:54.144: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 18 17:42:54.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-5088 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 18 17:42:54.444: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 18 17:42:54.444: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 18 17:42:54.444: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 18 17:42:54.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-5088 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 18 17:42:54.731: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 18 17:42:54.731: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 18 17:42:54.731: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 18 17:42:54.731: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Aug 18 17:43:14.779: INFO: Deleting all statefulset in ns statefulset-5088
Aug 18 17:43:14.789: INFO: Scaling statefulset ss to 0
Aug 18 17:43:14.823: INFO: Waiting for statefulset status.replicas updated to 0
Aug 18 17:43:14.834: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:43:14.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5088" for this suite.
Aug 18 17:43:22.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:43:23.384: INFO: namespace statefulset-5088 deletion completed in 8.477022746s

• [SLOW TEST:92.020 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:43:23.384: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-761
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Aug 18 17:43:23.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-761'
Aug 18 17:43:23.753: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 18 17:43:23.753: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Aug 18 17:43:23.819: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-vfwnp]
Aug 18 17:43:23.819: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-vfwnp" in namespace "kubectl-761" to be "running and ready"
Aug 18 17:43:23.830: INFO: Pod "e2e-test-httpd-rc-vfwnp": Phase="Pending", Reason="", readiness=false. Elapsed: 11.1518ms
Aug 18 17:43:25.845: INFO: Pod "e2e-test-httpd-rc-vfwnp": Phase="Running", Reason="", readiness=true. Elapsed: 2.025794588s
Aug 18 17:43:25.845: INFO: Pod "e2e-test-httpd-rc-vfwnp" satisfied condition "running and ready"
Aug 18 17:43:25.845: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-vfwnp]
Aug 18 17:43:25.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 logs rc/e2e-test-httpd-rc --namespace=kubectl-761'
Aug 18 17:43:26.056: INFO: stderr: ""
Aug 18 17:43:26.057: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.30.104.138. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.30.104.138. Set the 'ServerName' directive globally to suppress this message\n[Tue Aug 18 17:43:25.023005 2020] [mpm_event:notice] [pid 1:tid 139924519021416] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Tue Aug 18 17:43:25.023064 2020] [core:notice] [pid 1:tid 139924519021416] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Aug 18 17:43:26.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete rc e2e-test-httpd-rc --namespace=kubectl-761'
Aug 18 17:43:26.191: INFO: stderr: ""
Aug 18 17:43:26.191: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:43:26.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-761" for this suite.
Aug 18 17:43:54.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:43:54.633: INFO: namespace kubectl-761 deletion completed in 28.419167662s

• [SLOW TEST:31.249 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:43:54.634: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8991
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Aug 18 17:43:54.869: INFO: Waiting up to 5m0s for pod "client-containers-e2ecc007-58e9-4f95-8974-ba75ebe2d06a" in namespace "containers-8991" to be "success or failure"
Aug 18 17:43:54.881: INFO: Pod "client-containers-e2ecc007-58e9-4f95-8974-ba75ebe2d06a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.495065ms
Aug 18 17:43:57.109: INFO: Pod "client-containers-e2ecc007-58e9-4f95-8974-ba75ebe2d06a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.239513295s
STEP: Saw pod success
Aug 18 17:43:57.109: INFO: Pod "client-containers-e2ecc007-58e9-4f95-8974-ba75ebe2d06a" satisfied condition "success or failure"
Aug 18 17:43:57.120: INFO: Trying to get logs from node 10.241.69.172 pod client-containers-e2ecc007-58e9-4f95-8974-ba75ebe2d06a container test-container: <nil>
STEP: delete the pod
Aug 18 17:43:57.209: INFO: Waiting for pod client-containers-e2ecc007-58e9-4f95-8974-ba75ebe2d06a to disappear
Aug 18 17:43:57.219: INFO: Pod client-containers-e2ecc007-58e9-4f95-8974-ba75ebe2d06a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:43:57.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8991" for this suite.
Aug 18 17:44:03.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:44:03.734: INFO: namespace containers-8991 deletion completed in 6.495889463s

• [SLOW TEST:9.101 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:44:03.734: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1190
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 18 17:44:06.031: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:44:06.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1190" for this suite.
Aug 18 17:44:12.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:44:12.537: INFO: namespace container-runtime-1190 deletion completed in 6.439606929s

• [SLOW TEST:8.803 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:44:12.537: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6366
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Aug 18 17:44:12.759: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 17:44:16.664: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:44:31.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6366" for this suite.
Aug 18 17:44:37.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:44:38.407: INFO: namespace crd-publish-openapi-6366 deletion completed in 6.459477061s

• [SLOW TEST:25.869 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:44:38.409: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2784
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:44:38.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2784" for this suite.
Aug 18 17:44:44.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:44:45.208: INFO: namespace resourcequota-2784 deletion completed in 6.438155838s

• [SLOW TEST:6.799 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:44:45.209: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3467
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 18 17:44:45.522: INFO: Number of nodes with available pods: 0
Aug 18 17:44:45.522: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:44:46.554: INFO: Number of nodes with available pods: 0
Aug 18 17:44:46.554: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:44:47.549: INFO: Number of nodes with available pods: 2
Aug 18 17:44:47.549: INFO: Node 10.241.69.184 is running more than one daemon pod
Aug 18 17:44:48.549: INFO: Number of nodes with available pods: 3
Aug 18 17:44:48.549: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 18 17:44:48.611: INFO: Number of nodes with available pods: 2
Aug 18 17:44:48.612: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:44:49.638: INFO: Number of nodes with available pods: 2
Aug 18 17:44:49.639: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:44:50.637: INFO: Number of nodes with available pods: 2
Aug 18 17:44:50.637: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 17:44:51.645: INFO: Number of nodes with available pods: 3
Aug 18 17:44:51.645: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3467, will wait for the garbage collector to delete the pods
Aug 18 17:44:51.750: INFO: Deleting DaemonSet.extensions daemon-set took: 22.996407ms
Aug 18 17:44:51.951: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.317563ms
Aug 18 17:45:00.963: INFO: Number of nodes with available pods: 0
Aug 18 17:45:00.963: INFO: Number of running nodes: 0, number of available pods: 0
Aug 18 17:45:00.974: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3467/daemonsets","resourceVersion":"26848"},"items":null}

Aug 18 17:45:00.984: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3467/pods","resourceVersion":"26848"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:45:01.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3467" for this suite.
Aug 18 17:45:09.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:45:09.479: INFO: namespace daemonsets-3467 deletion completed in 8.42201081s

• [SLOW TEST:24.270 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:45:09.480: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9531
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:45:09.730: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 18 17:45:14.743: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 18 17:45:14.743: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 18 17:45:16.754: INFO: Creating deployment "test-rollover-deployment"
Aug 18 17:45:16.787: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 18 17:45:18.815: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 18 17:45:18.841: INFO: Ensure that both replica sets have 1 created replica
Aug 18 17:45:18.866: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 18 17:45:18.896: INFO: Updating deployment test-rollover-deployment
Aug 18 17:45:18.896: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 18 17:45:20.923: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 18 17:45:20.950: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 18 17:45:20.984: INFO: all replica sets need to contain the pod-template-hash label
Aug 18 17:45:20.984: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369518, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 17:45:23.009: INFO: all replica sets need to contain the pod-template-hash label
Aug 18 17:45:23.009: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369522, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 17:45:25.013: INFO: all replica sets need to contain the pod-template-hash label
Aug 18 17:45:25.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369522, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 17:45:27.009: INFO: all replica sets need to contain the pod-template-hash label
Aug 18 17:45:27.009: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369522, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 17:45:29.012: INFO: all replica sets need to contain the pod-template-hash label
Aug 18 17:45:29.012: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369522, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 17:45:31.008: INFO: all replica sets need to contain the pod-template-hash label
Aug 18 17:45:31.008: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369522, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733369516, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 17:45:33.008: INFO: 
Aug 18 17:45:33.008: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Aug 18 17:45:33.042: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-9531 /apis/apps/v1/namespaces/deployment-9531/deployments/test-rollover-deployment 03dc5b33-8164-4247-a995-e49b25e58433 27020 2 2020-08-18 17:45:16 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006ad9018 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-08-18 17:45:16 +0000 UTC,LastTransitionTime:2020-08-18 17:45:16 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2020-08-18 17:45:32 +0000 UTC,LastTransitionTime:2020-08-18 17:45:16 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 18 17:45:33.053: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-9531 /apis/apps/v1/namespaces/deployment-9531/replicasets/test-rollover-deployment-7d7dc6548c 4ab22015-fe89-4dae-bc58-ab18cedf9565 27009 2 2020-08-18 17:45:18 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 03dc5b33-8164-4247-a995-e49b25e58433 0xc006bfb697 0xc006bfb698}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006bfb6f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 18 17:45:33.053: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 18 17:45:33.053: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9531 /apis/apps/v1/namespaces/deployment-9531/replicasets/test-rollover-controller 0d6830c2-980a-42b7-8530-10a3349a6bfc 27018 2 2020-08-18 17:45:09 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 03dc5b33-8164-4247-a995-e49b25e58433 0xc006bfb5c7 0xc006bfb5c8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc006bfb628 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 18 17:45:33.053: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-9531 /apis/apps/v1/namespaces/deployment-9531/replicasets/test-rollover-deployment-f6c94f66c 5d202b4f-ff0e-41eb-b8c4-be073338638f 26969 2 2020-08-18 17:45:16 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 03dc5b33-8164-4247-a995-e49b25e58433 0xc006bfb760 0xc006bfb761}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006bfb7d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 18 17:45:33.064: INFO: Pod "test-rollover-deployment-7d7dc6548c-d8zmk" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-d8zmk test-rollover-deployment-7d7dc6548c- deployment-9531 /api/v1/namespaces/deployment-9531/pods/test-rollover-deployment-7d7dc6548c-d8zmk e73f25cb-08ec-4c17-8c19-266c06c1d1ef 26991 0 2020-08-18 17:45:18 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 4ab22015-fe89-4dae-bc58-ab18cedf9565 0xc006bfbd37 0xc006bfbd38}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6pxxk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6pxxk,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6pxxk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:45:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:45:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:45:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 17:45:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.184,PodIP:172.30.134.110,StartTime:2020-08-18 17:45:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 17:45:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://600b2eae42fd8f65d913d7d1721554da16a6e88ebe009ab83d8274d2243fca7c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.134.110,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:45:33.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9531" for this suite.
Aug 18 17:45:41.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:45:41.498: INFO: namespace deployment-9531 deletion completed in 8.418957208s

• [SLOW TEST:32.019 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:45:41.499: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4545
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 18 17:45:41.818: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4545 /api/v1/namespaces/watch-4545/configmaps/e2e-watch-test-resource-version af52699c-f802-4216-a3cc-0fc6e5bee639 27087 0 2020-08-18 17:45:41 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 18 17:45:41.818: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4545 /api/v1/namespaces/watch-4545/configmaps/e2e-watch-test-resource-version af52699c-f802-4216-a3cc-0fc6e5bee639 27089 0 2020-08-18 17:45:41 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:45:41.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4545" for this suite.
Aug 18 17:45:47.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:45:48.327: INFO: namespace watch-4545 deletion completed in 6.494333665s

• [SLOW TEST:6.828 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:45:48.327: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4330
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 18 17:45:52.673: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 18 17:45:52.690: INFO: Pod pod-with-prestop-http-hook still exists
Aug 18 17:45:54.691: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 18 17:45:54.703: INFO: Pod pod-with-prestop-http-hook still exists
Aug 18 17:45:56.691: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 18 17:45:56.803: INFO: Pod pod-with-prestop-http-hook still exists
Aug 18 17:45:58.691: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 18 17:45:58.703: INFO: Pod pod-with-prestop-http-hook still exists
Aug 18 17:46:00.691: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 18 17:46:00.702: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:46:00.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4330" for this suite.
Aug 18 17:46:12.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:46:13.219: INFO: namespace container-lifecycle-hook-4330 deletion completed in 12.451158722s

• [SLOW TEST:24.892 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:46:13.222: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9020
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:46:13.518: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"c2dad1ce-17ea-47e3-9aa3-9ddf951f0c70", Controller:(*bool)(0xc001c9d296), BlockOwnerDeletion:(*bool)(0xc001c9d297)}}
Aug 18 17:46:13.529: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"7f9d6235-a7a2-44a1-aaf5-b0d01ca4d0cd", Controller:(*bool)(0xc002f1c7b6), BlockOwnerDeletion:(*bool)(0xc002f1c7b7)}}
Aug 18 17:46:13.542: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"9a4c2aaa-ef38-4419-ba95-ed4be306f28a", Controller:(*bool)(0xc002f1c95e), BlockOwnerDeletion:(*bool)(0xc002f1c95f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:46:18.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9020" for this suite.
Aug 18 17:46:24.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:46:25.026: INFO: namespace gc-9020 deletion completed in 6.440778741s

• [SLOW TEST:11.805 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:46:25.027: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6741
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Aug 18 17:46:25.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 cluster-info'
Aug 18 17:46:25.373: INFO: stderr: ""
Aug 18 17:46:25.373: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\x1b[0;32mNodeLocalDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/node-local-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:46:25.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6741" for this suite.
Aug 18 17:46:31.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:46:31.857: INFO: namespace kubectl-6741 deletion completed in 6.460347919s

• [SLOW TEST:6.830 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:46:31.858: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1674
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-82c4fa88-8fd0-4be6-abfb-088975cc074c
STEP: Creating a pod to test consume configMaps
Aug 18 17:46:32.123: INFO: Waiting up to 5m0s for pod "pod-configmaps-b48fb768-baa1-4653-9a8e-1d76df04e42e" in namespace "configmap-1674" to be "success or failure"
Aug 18 17:46:32.133: INFO: Pod "pod-configmaps-b48fb768-baa1-4653-9a8e-1d76df04e42e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.023546ms
Aug 18 17:46:34.144: INFO: Pod "pod-configmaps-b48fb768-baa1-4653-9a8e-1d76df04e42e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021110237s
STEP: Saw pod success
Aug 18 17:46:34.144: INFO: Pod "pod-configmaps-b48fb768-baa1-4653-9a8e-1d76df04e42e" satisfied condition "success or failure"
Aug 18 17:46:34.158: INFO: Trying to get logs from node 10.241.69.172 pod pod-configmaps-b48fb768-baa1-4653-9a8e-1d76df04e42e container configmap-volume-test: <nil>
STEP: delete the pod
Aug 18 17:46:34.217: INFO: Waiting for pod pod-configmaps-b48fb768-baa1-4653-9a8e-1d76df04e42e to disappear
Aug 18 17:46:34.227: INFO: Pod pod-configmaps-b48fb768-baa1-4653-9a8e-1d76df04e42e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:46:34.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1674" for this suite.
Aug 18 17:46:40.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:46:40.689: INFO: namespace configmap-1674 deletion completed in 6.445120959s

• [SLOW TEST:8.832 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:46:40.690: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8153
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2482
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6251
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:47:11.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8153" for this suite.
Aug 18 17:47:17.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:47:17.930: INFO: namespace namespaces-8153 deletion completed in 6.476899414s
STEP: Destroying namespace "nsdeletetest-2482" for this suite.
Aug 18 17:47:17.944: INFO: Namespace nsdeletetest-2482 was already deleted
STEP: Destroying namespace "nsdeletetest-6251" for this suite.
Aug 18 17:47:23.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:47:24.437: INFO: namespace nsdeletetest-6251 deletion completed in 6.492110332s

• [SLOW TEST:43.747 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:47:24.437: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-815
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:47:24.656: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Aug 18 17:47:28.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-815 create -f -'
Aug 18 17:47:29.076: INFO: stderr: ""
Aug 18 17:47:29.076: INFO: stdout: "e2e-test-crd-publish-openapi-4530-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Aug 18 17:47:29.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-815 delete e2e-test-crd-publish-openapi-4530-crds test-cr'
Aug 18 17:47:29.304: INFO: stderr: ""
Aug 18 17:47:29.304: INFO: stdout: "e2e-test-crd-publish-openapi-4530-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Aug 18 17:47:29.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-815 apply -f -'
Aug 18 17:47:29.687: INFO: stderr: ""
Aug 18 17:47:29.687: INFO: stdout: "e2e-test-crd-publish-openapi-4530-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Aug 18 17:47:29.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-815 delete e2e-test-crd-publish-openapi-4530-crds test-cr'
Aug 18 17:47:29.829: INFO: stderr: ""
Aug 18 17:47:29.829: INFO: stdout: "e2e-test-crd-publish-openapi-4530-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Aug 18 17:47:29.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 explain e2e-test-crd-publish-openapi-4530-crds'
Aug 18 17:47:30.022: INFO: stderr: ""
Aug 18 17:47:30.022: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4530-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:47:33.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-815" for this suite.
Aug 18 17:47:39.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:47:40.368: INFO: namespace crd-publish-openapi-815 deletion completed in 6.453054358s

• [SLOW TEST:15.931 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:47:40.368: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-9950
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-9950
I0818 17:47:40.606913      23 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9950, replica count: 1
I0818 17:47:41.657461      23 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0818 17:47:42.657758      23 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 18 17:47:42.794: INFO: Created: latency-svc-lsrdk
Aug 18 17:47:42.805: INFO: Got endpoints: latency-svc-lsrdk [47.492219ms]
Aug 18 17:47:42.837: INFO: Created: latency-svc-nmhmp
Aug 18 17:47:42.844: INFO: Got endpoints: latency-svc-nmhmp [38.691373ms]
Aug 18 17:47:42.853: INFO: Created: latency-svc-wfnzs
Aug 18 17:47:42.860: INFO: Got endpoints: latency-svc-wfnzs [54.162974ms]
Aug 18 17:47:42.870: INFO: Created: latency-svc-2tr2z
Aug 18 17:47:42.878: INFO: Got endpoints: latency-svc-2tr2z [71.996876ms]
Aug 18 17:47:42.887: INFO: Created: latency-svc-c7fvs
Aug 18 17:47:42.893: INFO: Got endpoints: latency-svc-c7fvs [87.153076ms]
Aug 18 17:47:42.904: INFO: Created: latency-svc-kkzvs
Aug 18 17:47:42.912: INFO: Got endpoints: latency-svc-kkzvs [105.875838ms]
Aug 18 17:47:42.918: INFO: Created: latency-svc-rs8p5
Aug 18 17:47:42.926: INFO: Got endpoints: latency-svc-rs8p5 [120.254099ms]
Aug 18 17:47:42.942: INFO: Created: latency-svc-cz49x
Aug 18 17:47:42.950: INFO: Created: latency-svc-7xn7k
Aug 18 17:47:42.950: INFO: Got endpoints: latency-svc-cz49x [144.261574ms]
Aug 18 17:47:42.957: INFO: Got endpoints: latency-svc-7xn7k [150.684882ms]
Aug 18 17:47:42.967: INFO: Created: latency-svc-dgr9s
Aug 18 17:47:42.972: INFO: Got endpoints: latency-svc-dgr9s [166.481368ms]
Aug 18 17:47:42.981: INFO: Created: latency-svc-b4ph9
Aug 18 17:47:42.988: INFO: Got endpoints: latency-svc-b4ph9 [182.047796ms]
Aug 18 17:47:42.996: INFO: Created: latency-svc-bg9vp
Aug 18 17:47:43.003: INFO: Got endpoints: latency-svc-bg9vp [196.565957ms]
Aug 18 17:47:43.012: INFO: Created: latency-svc-xphw9
Aug 18 17:47:43.020: INFO: Got endpoints: latency-svc-xphw9 [213.442625ms]
Aug 18 17:47:43.025: INFO: Created: latency-svc-6rlhk
Aug 18 17:47:43.033: INFO: Got endpoints: latency-svc-6rlhk [226.739582ms]
Aug 18 17:47:43.043: INFO: Created: latency-svc-5hwwt
Aug 18 17:47:43.048: INFO: Got endpoints: latency-svc-5hwwt [242.510491ms]
Aug 18 17:47:43.055: INFO: Created: latency-svc-5f4bl
Aug 18 17:47:43.062: INFO: Got endpoints: latency-svc-5f4bl [255.868271ms]
Aug 18 17:47:43.069: INFO: Created: latency-svc-g55mt
Aug 18 17:47:43.076: INFO: Got endpoints: latency-svc-g55mt [231.626639ms]
Aug 18 17:47:43.082: INFO: Created: latency-svc-mbzsj
Aug 18 17:47:43.090: INFO: Got endpoints: latency-svc-mbzsj [230.042152ms]
Aug 18 17:47:43.096: INFO: Created: latency-svc-kgblp
Aug 18 17:47:43.103: INFO: Got endpoints: latency-svc-kgblp [224.860421ms]
Aug 18 17:47:43.112: INFO: Created: latency-svc-7v4r6
Aug 18 17:47:43.117: INFO: Got endpoints: latency-svc-7v4r6 [224.015697ms]
Aug 18 17:47:43.123: INFO: Created: latency-svc-n5vwh
Aug 18 17:47:43.131: INFO: Got endpoints: latency-svc-n5vwh [219.454203ms]
Aug 18 17:47:43.138: INFO: Created: latency-svc-ndmwd
Aug 18 17:47:43.145: INFO: Got endpoints: latency-svc-ndmwd [219.437054ms]
Aug 18 17:47:43.151: INFO: Created: latency-svc-dcwjz
Aug 18 17:47:43.160: INFO: Got endpoints: latency-svc-dcwjz [209.586694ms]
Aug 18 17:47:43.165: INFO: Created: latency-svc-zfvgs
Aug 18 17:47:43.172: INFO: Got endpoints: latency-svc-zfvgs [215.459542ms]
Aug 18 17:47:43.181: INFO: Created: latency-svc-96pwf
Aug 18 17:47:43.187: INFO: Got endpoints: latency-svc-96pwf [214.774966ms]
Aug 18 17:47:43.193: INFO: Created: latency-svc-2fsdr
Aug 18 17:47:43.201: INFO: Got endpoints: latency-svc-2fsdr [212.513295ms]
Aug 18 17:47:43.207: INFO: Created: latency-svc-4zgcw
Aug 18 17:47:43.215: INFO: Got endpoints: latency-svc-4zgcw [212.307506ms]
Aug 18 17:47:43.222: INFO: Created: latency-svc-tgxxp
Aug 18 17:47:43.229: INFO: Got endpoints: latency-svc-tgxxp [209.477097ms]
Aug 18 17:47:43.235: INFO: Created: latency-svc-9swn2
Aug 18 17:47:43.243: INFO: Got endpoints: latency-svc-9swn2 [210.324413ms]
Aug 18 17:47:43.250: INFO: Created: latency-svc-znx4q
Aug 18 17:47:43.258: INFO: Got endpoints: latency-svc-znx4q [209.990913ms]
Aug 18 17:47:43.263: INFO: Created: latency-svc-x6978
Aug 18 17:47:43.270: INFO: Got endpoints: latency-svc-x6978 [208.155042ms]
Aug 18 17:47:43.277: INFO: Created: latency-svc-hxxwr
Aug 18 17:47:43.284: INFO: Got endpoints: latency-svc-hxxwr [208.566342ms]
Aug 18 17:47:43.290: INFO: Created: latency-svc-bqwdc
Aug 18 17:47:43.298: INFO: Got endpoints: latency-svc-bqwdc [207.37776ms]
Aug 18 17:47:43.306: INFO: Created: latency-svc-lnc8h
Aug 18 17:47:43.313: INFO: Got endpoints: latency-svc-lnc8h [210.497492ms]
Aug 18 17:47:43.320: INFO: Created: latency-svc-9nfqq
Aug 18 17:47:43.327: INFO: Got endpoints: latency-svc-9nfqq [210.046836ms]
Aug 18 17:47:43.333: INFO: Created: latency-svc-g2gf2
Aug 18 17:47:43.341: INFO: Got endpoints: latency-svc-g2gf2 [209.422498ms]
Aug 18 17:47:43.348: INFO: Created: latency-svc-xzplt
Aug 18 17:47:43.355: INFO: Got endpoints: latency-svc-xzplt [209.849718ms]
Aug 18 17:47:43.363: INFO: Created: latency-svc-dg2sn
Aug 18 17:47:43.372: INFO: Got endpoints: latency-svc-dg2sn [211.941474ms]
Aug 18 17:47:43.378: INFO: Created: latency-svc-4xjcd
Aug 18 17:47:43.386: INFO: Got endpoints: latency-svc-4xjcd [213.433522ms]
Aug 18 17:47:43.393: INFO: Created: latency-svc-9dvps
Aug 18 17:47:43.400: INFO: Got endpoints: latency-svc-9dvps [212.929946ms]
Aug 18 17:47:43.405: INFO: Created: latency-svc-8psvw
Aug 18 17:47:43.412: INFO: Got endpoints: latency-svc-8psvw [211.557268ms]
Aug 18 17:47:43.418: INFO: Created: latency-svc-c2cfp
Aug 18 17:47:43.425: INFO: Got endpoints: latency-svc-c2cfp [209.874443ms]
Aug 18 17:47:43.432: INFO: Created: latency-svc-lknvq
Aug 18 17:47:43.440: INFO: Got endpoints: latency-svc-lknvq [210.337004ms]
Aug 18 17:47:43.444: INFO: Created: latency-svc-fpg7r
Aug 18 17:47:43.452: INFO: Got endpoints: latency-svc-fpg7r [208.784277ms]
Aug 18 17:47:43.461: INFO: Created: latency-svc-hxkjk
Aug 18 17:47:43.468: INFO: Got endpoints: latency-svc-hxkjk [209.730656ms]
Aug 18 17:47:43.471: INFO: Created: latency-svc-hbkcv
Aug 18 17:47:43.479: INFO: Got endpoints: latency-svc-hbkcv [209.052644ms]
Aug 18 17:47:43.485: INFO: Created: latency-svc-q5598
Aug 18 17:47:43.492: INFO: Got endpoints: latency-svc-q5598 [207.578653ms]
Aug 18 17:47:43.500: INFO: Created: latency-svc-pp2p4
Aug 18 17:47:43.507: INFO: Got endpoints: latency-svc-pp2p4 [208.827362ms]
Aug 18 17:47:43.515: INFO: Created: latency-svc-hxnk2
Aug 18 17:47:43.521: INFO: Got endpoints: latency-svc-hxnk2 [207.373791ms]
Aug 18 17:47:43.528: INFO: Created: latency-svc-77wq9
Aug 18 17:47:43.535: INFO: Got endpoints: latency-svc-77wq9 [208.209168ms]
Aug 18 17:47:43.542: INFO: Created: latency-svc-fff9d
Aug 18 17:47:43.550: INFO: Got endpoints: latency-svc-fff9d [208.997144ms]
Aug 18 17:47:43.556: INFO: Created: latency-svc-r8hxb
Aug 18 17:47:43.564: INFO: Got endpoints: latency-svc-r8hxb [209.000203ms]
Aug 18 17:47:43.571: INFO: Created: latency-svc-qxlf7
Aug 18 17:47:43.577: INFO: Got endpoints: latency-svc-qxlf7 [205.651177ms]
Aug 18 17:47:43.584: INFO: Created: latency-svc-888jx
Aug 18 17:47:43.591: INFO: Got endpoints: latency-svc-888jx [205.38921ms]
Aug 18 17:47:43.599: INFO: Created: latency-svc-btxgq
Aug 18 17:47:43.606: INFO: Got endpoints: latency-svc-btxgq [205.836172ms]
Aug 18 17:47:43.612: INFO: Created: latency-svc-vl6zs
Aug 18 17:47:43.620: INFO: Got endpoints: latency-svc-vl6zs [207.551901ms]
Aug 18 17:47:43.626: INFO: Created: latency-svc-8dwp8
Aug 18 17:47:43.634: INFO: Got endpoints: latency-svc-8dwp8 [209.412591ms]
Aug 18 17:47:43.641: INFO: Created: latency-svc-hjsfr
Aug 18 17:47:43.648: INFO: Got endpoints: latency-svc-hjsfr [208.805409ms]
Aug 18 17:47:43.655: INFO: Created: latency-svc-gsfnz
Aug 18 17:47:43.664: INFO: Got endpoints: latency-svc-gsfnz [211.689742ms]
Aug 18 17:47:43.671: INFO: Created: latency-svc-bn4ld
Aug 18 17:47:43.681: INFO: Got endpoints: latency-svc-bn4ld [212.498076ms]
Aug 18 17:47:43.689: INFO: Created: latency-svc-h6c5d
Aug 18 17:47:43.698: INFO: Got endpoints: latency-svc-h6c5d [218.57892ms]
Aug 18 17:47:43.707: INFO: Created: latency-svc-9wkkc
Aug 18 17:47:43.712: INFO: Got endpoints: latency-svc-9wkkc [220.388102ms]
Aug 18 17:47:43.723: INFO: Created: latency-svc-zfd8g
Aug 18 17:47:43.741: INFO: Created: latency-svc-5hvhh
Aug 18 17:47:43.742: INFO: Got endpoints: latency-svc-zfd8g [234.980764ms]
Aug 18 17:47:43.745: INFO: Got endpoints: latency-svc-5hvhh [224.030379ms]
Aug 18 17:47:43.751: INFO: Created: latency-svc-xlbrs
Aug 18 17:47:43.758: INFO: Got endpoints: latency-svc-xlbrs [222.995927ms]
Aug 18 17:47:43.765: INFO: Created: latency-svc-nrf4b
Aug 18 17:47:43.773: INFO: Got endpoints: latency-svc-nrf4b [222.816333ms]
Aug 18 17:47:43.784: INFO: Created: latency-svc-59g9t
Aug 18 17:47:43.786: INFO: Got endpoints: latency-svc-59g9t [222.071602ms]
Aug 18 17:47:43.793: INFO: Created: latency-svc-6bbzq
Aug 18 17:47:43.801: INFO: Got endpoints: latency-svc-6bbzq [222.955249ms]
Aug 18 17:47:43.807: INFO: Created: latency-svc-4dst6
Aug 18 17:47:43.815: INFO: Got endpoints: latency-svc-4dst6 [223.881058ms]
Aug 18 17:47:43.823: INFO: Created: latency-svc-2pc9l
Aug 18 17:47:43.831: INFO: Got endpoints: latency-svc-2pc9l [224.616933ms]
Aug 18 17:47:43.839: INFO: Created: latency-svc-h6g4c
Aug 18 17:47:43.847: INFO: Got endpoints: latency-svc-h6g4c [226.975073ms]
Aug 18 17:47:43.854: INFO: Created: latency-svc-6fc79
Aug 18 17:47:43.862: INFO: Got endpoints: latency-svc-6fc79 [227.2053ms]
Aug 18 17:47:43.871: INFO: Created: latency-svc-dkp8p
Aug 18 17:47:43.880: INFO: Got endpoints: latency-svc-dkp8p [231.708318ms]
Aug 18 17:47:43.886: INFO: Created: latency-svc-hdsjb
Aug 18 17:47:43.894: INFO: Got endpoints: latency-svc-hdsjb [229.805355ms]
Aug 18 17:47:43.903: INFO: Created: latency-svc-sksz4
Aug 18 17:47:43.912: INFO: Got endpoints: latency-svc-sksz4 [230.968125ms]
Aug 18 17:47:43.921: INFO: Created: latency-svc-nzxxt
Aug 18 17:47:43.927: INFO: Got endpoints: latency-svc-nzxxt [229.351129ms]
Aug 18 17:47:43.939: INFO: Created: latency-svc-k45vz
Aug 18 17:47:43.946: INFO: Got endpoints: latency-svc-k45vz [232.983615ms]
Aug 18 17:47:43.951: INFO: Created: latency-svc-62q2v
Aug 18 17:47:43.957: INFO: Got endpoints: latency-svc-62q2v [215.54346ms]
Aug 18 17:47:43.965: INFO: Created: latency-svc-46t62
Aug 18 17:47:43.973: INFO: Got endpoints: latency-svc-46t62 [227.663221ms]
Aug 18 17:47:43.979: INFO: Created: latency-svc-hpmlk
Aug 18 17:47:43.986: INFO: Got endpoints: latency-svc-hpmlk [228.148254ms]
Aug 18 17:47:43.994: INFO: Created: latency-svc-bxwjh
Aug 18 17:47:44.003: INFO: Got endpoints: latency-svc-bxwjh [230.403947ms]
Aug 18 17:47:44.010: INFO: Created: latency-svc-8wb68
Aug 18 17:47:44.020: INFO: Got endpoints: latency-svc-8wb68 [233.714234ms]
Aug 18 17:47:44.026: INFO: Created: latency-svc-5vm7w
Aug 18 17:47:44.034: INFO: Got endpoints: latency-svc-5vm7w [233.556575ms]
Aug 18 17:47:44.042: INFO: Created: latency-svc-vr7rt
Aug 18 17:47:44.049: INFO: Got endpoints: latency-svc-vr7rt [233.749079ms]
Aug 18 17:47:44.057: INFO: Created: latency-svc-hl5kf
Aug 18 17:47:44.063: INFO: Got endpoints: latency-svc-hl5kf [232.131233ms]
Aug 18 17:47:44.072: INFO: Created: latency-svc-2wfjz
Aug 18 17:47:44.079: INFO: Got endpoints: latency-svc-2wfjz [231.598843ms]
Aug 18 17:47:44.087: INFO: Created: latency-svc-qjv68
Aug 18 17:47:44.095: INFO: Got endpoints: latency-svc-qjv68 [233.167935ms]
Aug 18 17:47:44.102: INFO: Created: latency-svc-98jt2
Aug 18 17:47:44.110: INFO: Got endpoints: latency-svc-98jt2 [229.314094ms]
Aug 18 17:47:44.117: INFO: Created: latency-svc-5jqdd
Aug 18 17:47:44.123: INFO: Got endpoints: latency-svc-5jqdd [229.563271ms]
Aug 18 17:47:44.131: INFO: Created: latency-svc-7h2jg
Aug 18 17:47:44.138: INFO: Got endpoints: latency-svc-7h2jg [226.681475ms]
Aug 18 17:47:44.147: INFO: Created: latency-svc-xpmxb
Aug 18 17:47:44.153: INFO: Got endpoints: latency-svc-xpmxb [225.754384ms]
Aug 18 17:47:44.160: INFO: Created: latency-svc-4wphv
Aug 18 17:47:44.168: INFO: Got endpoints: latency-svc-4wphv [222.060872ms]
Aug 18 17:47:44.174: INFO: Created: latency-svc-bpnj2
Aug 18 17:47:44.183: INFO: Got endpoints: latency-svc-bpnj2 [225.004106ms]
Aug 18 17:47:44.190: INFO: Created: latency-svc-cdhbc
Aug 18 17:47:44.196: INFO: Got endpoints: latency-svc-cdhbc [223.666816ms]
Aug 18 17:47:44.205: INFO: Created: latency-svc-6nk52
Aug 18 17:47:44.213: INFO: Got endpoints: latency-svc-6nk52 [226.882738ms]
Aug 18 17:47:44.221: INFO: Created: latency-svc-hnhng
Aug 18 17:47:44.229: INFO: Got endpoints: latency-svc-hnhng [225.613269ms]
Aug 18 17:47:44.237: INFO: Created: latency-svc-9dbkp
Aug 18 17:47:44.244: INFO: Got endpoints: latency-svc-9dbkp [223.791201ms]
Aug 18 17:47:44.251: INFO: Created: latency-svc-vlch6
Aug 18 17:47:44.261: INFO: Got endpoints: latency-svc-vlch6 [226.278512ms]
Aug 18 17:47:44.266: INFO: Created: latency-svc-sv76p
Aug 18 17:47:44.273: INFO: Got endpoints: latency-svc-sv76p [223.926524ms]
Aug 18 17:47:44.279: INFO: Created: latency-svc-g787t
Aug 18 17:47:44.288: INFO: Got endpoints: latency-svc-g787t [224.712245ms]
Aug 18 17:47:44.296: INFO: Created: latency-svc-6mqqh
Aug 18 17:47:44.302: INFO: Got endpoints: latency-svc-6mqqh [222.818927ms]
Aug 18 17:47:44.309: INFO: Created: latency-svc-s6x87
Aug 18 17:47:44.316: INFO: Got endpoints: latency-svc-s6x87 [221.012048ms]
Aug 18 17:47:44.324: INFO: Created: latency-svc-ztlp8
Aug 18 17:47:44.330: INFO: Got endpoints: latency-svc-ztlp8 [220.823813ms]
Aug 18 17:47:44.338: INFO: Created: latency-svc-8tfmf
Aug 18 17:47:44.346: INFO: Got endpoints: latency-svc-8tfmf [222.052268ms]
Aug 18 17:47:44.359: INFO: Created: latency-svc-76bvx
Aug 18 17:47:44.366: INFO: Got endpoints: latency-svc-76bvx [227.712995ms]
Aug 18 17:47:44.368: INFO: Created: latency-svc-46q5v
Aug 18 17:47:44.375: INFO: Got endpoints: latency-svc-46q5v [221.082551ms]
Aug 18 17:47:44.382: INFO: Created: latency-svc-wp48b
Aug 18 17:47:44.389: INFO: Got endpoints: latency-svc-wp48b [221.439454ms]
Aug 18 17:47:44.399: INFO: Created: latency-svc-q45gs
Aug 18 17:47:44.407: INFO: Got endpoints: latency-svc-q45gs [224.345627ms]
Aug 18 17:47:44.411: INFO: Created: latency-svc-kgrkp
Aug 18 17:47:44.418: INFO: Got endpoints: latency-svc-kgrkp [221.471206ms]
Aug 18 17:47:44.426: INFO: Created: latency-svc-vht4g
Aug 18 17:47:44.433: INFO: Got endpoints: latency-svc-vht4g [219.785045ms]
Aug 18 17:47:44.443: INFO: Created: latency-svc-65dvw
Aug 18 17:47:44.450: INFO: Got endpoints: latency-svc-65dvw [220.857528ms]
Aug 18 17:47:44.456: INFO: Created: latency-svc-5z78g
Aug 18 17:47:44.463: INFO: Got endpoints: latency-svc-5z78g [218.454817ms]
Aug 18 17:47:44.473: INFO: Created: latency-svc-hltk8
Aug 18 17:47:44.480: INFO: Got endpoints: latency-svc-hltk8 [219.269194ms]
Aug 18 17:47:44.486: INFO: Created: latency-svc-cjsqf
Aug 18 17:47:44.494: INFO: Got endpoints: latency-svc-cjsqf [220.817202ms]
Aug 18 17:47:44.502: INFO: Created: latency-svc-f7bwn
Aug 18 17:47:44.513: INFO: Got endpoints: latency-svc-f7bwn [224.830768ms]
Aug 18 17:47:44.522: INFO: Created: latency-svc-kcwdj
Aug 18 17:47:44.530: INFO: Got endpoints: latency-svc-kcwdj [228.669889ms]
Aug 18 17:47:44.540: INFO: Created: latency-svc-4k69t
Aug 18 17:47:44.549: INFO: Got endpoints: latency-svc-4k69t [232.218867ms]
Aug 18 17:47:44.556: INFO: Created: latency-svc-7nwr2
Aug 18 17:47:44.564: INFO: Got endpoints: latency-svc-7nwr2 [233.543785ms]
Aug 18 17:47:44.571: INFO: Created: latency-svc-fm8xt
Aug 18 17:47:44.579: INFO: Got endpoints: latency-svc-fm8xt [233.633316ms]
Aug 18 17:47:44.588: INFO: Created: latency-svc-k9wsc
Aug 18 17:47:44.595: INFO: Got endpoints: latency-svc-k9wsc [229.252339ms]
Aug 18 17:47:44.601: INFO: Created: latency-svc-jhnsb
Aug 18 17:47:44.608: INFO: Got endpoints: latency-svc-jhnsb [233.165804ms]
Aug 18 17:47:44.616: INFO: Created: latency-svc-5ztvq
Aug 18 17:47:44.623: INFO: Got endpoints: latency-svc-5ztvq [233.862915ms]
Aug 18 17:47:44.630: INFO: Created: latency-svc-bt8fx
Aug 18 17:47:44.637: INFO: Got endpoints: latency-svc-bt8fx [230.311494ms]
Aug 18 17:47:44.649: INFO: Created: latency-svc-ngmdh
Aug 18 17:47:44.657: INFO: Got endpoints: latency-svc-ngmdh [238.79201ms]
Aug 18 17:47:44.666: INFO: Created: latency-svc-tpwtw
Aug 18 17:47:44.673: INFO: Got endpoints: latency-svc-tpwtw [239.888261ms]
Aug 18 17:47:44.682: INFO: Created: latency-svc-9lt28
Aug 18 17:47:44.689: INFO: Got endpoints: latency-svc-9lt28 [238.806248ms]
Aug 18 17:47:44.696: INFO: Created: latency-svc-r8q4l
Aug 18 17:47:44.704: INFO: Got endpoints: latency-svc-r8q4l [240.733328ms]
Aug 18 17:47:44.711: INFO: Created: latency-svc-8bqtv
Aug 18 17:47:44.720: INFO: Got endpoints: latency-svc-8bqtv [240.006035ms]
Aug 18 17:47:44.727: INFO: Created: latency-svc-tbj5t
Aug 18 17:47:44.737: INFO: Got endpoints: latency-svc-tbj5t [242.511221ms]
Aug 18 17:47:44.745: INFO: Created: latency-svc-ct2ls
Aug 18 17:47:44.754: INFO: Got endpoints: latency-svc-ct2ls [241.457199ms]
Aug 18 17:47:44.763: INFO: Created: latency-svc-8457b
Aug 18 17:47:44.772: INFO: Got endpoints: latency-svc-8457b [241.1606ms]
Aug 18 17:47:44.779: INFO: Created: latency-svc-x82qq
Aug 18 17:47:44.787: INFO: Got endpoints: latency-svc-x82qq [238.107263ms]
Aug 18 17:47:44.796: INFO: Created: latency-svc-qzh9m
Aug 18 17:47:44.804: INFO: Got endpoints: latency-svc-qzh9m [239.66521ms]
Aug 18 17:47:44.812: INFO: Created: latency-svc-zrxkq
Aug 18 17:47:44.820: INFO: Got endpoints: latency-svc-zrxkq [241.224401ms]
Aug 18 17:47:44.828: INFO: Created: latency-svc-mvsbl
Aug 18 17:47:44.836: INFO: Got endpoints: latency-svc-mvsbl [240.639973ms]
Aug 18 17:47:44.845: INFO: Created: latency-svc-7775k
Aug 18 17:47:44.853: INFO: Got endpoints: latency-svc-7775k [245.193061ms]
Aug 18 17:47:44.859: INFO: Created: latency-svc-vvmj4
Aug 18 17:47:44.869: INFO: Got endpoints: latency-svc-vvmj4 [245.555578ms]
Aug 18 17:47:44.873: INFO: Created: latency-svc-74p4m
Aug 18 17:47:44.880: INFO: Got endpoints: latency-svc-74p4m [242.368995ms]
Aug 18 17:47:44.888: INFO: Created: latency-svc-zcw9l
Aug 18 17:47:44.895: INFO: Got endpoints: latency-svc-zcw9l [238.383785ms]
Aug 18 17:47:44.905: INFO: Created: latency-svc-wrqjd
Aug 18 17:47:44.914: INFO: Got endpoints: latency-svc-wrqjd [240.582454ms]
Aug 18 17:47:44.923: INFO: Created: latency-svc-x6j2m
Aug 18 17:47:44.928: INFO: Got endpoints: latency-svc-x6j2m [239.77559ms]
Aug 18 17:47:44.935: INFO: Created: latency-svc-482jc
Aug 18 17:47:44.942: INFO: Got endpoints: latency-svc-482jc [238.437366ms]
Aug 18 17:47:44.950: INFO: Created: latency-svc-mrdk6
Aug 18 17:47:44.958: INFO: Got endpoints: latency-svc-mrdk6 [237.711625ms]
Aug 18 17:47:44.965: INFO: Created: latency-svc-hb7v5
Aug 18 17:47:44.973: INFO: Got endpoints: latency-svc-hb7v5 [235.97198ms]
Aug 18 17:47:44.979: INFO: Created: latency-svc-bxwrb
Aug 18 17:47:44.986: INFO: Got endpoints: latency-svc-bxwrb [231.91157ms]
Aug 18 17:47:44.994: INFO: Created: latency-svc-bhz92
Aug 18 17:47:45.001: INFO: Got endpoints: latency-svc-bhz92 [229.571333ms]
Aug 18 17:47:45.010: INFO: Created: latency-svc-z2tbh
Aug 18 17:47:45.017: INFO: Got endpoints: latency-svc-z2tbh [230.220012ms]
Aug 18 17:47:45.023: INFO: Created: latency-svc-f9c4b
Aug 18 17:47:45.030: INFO: Got endpoints: latency-svc-f9c4b [225.726616ms]
Aug 18 17:47:45.037: INFO: Created: latency-svc-n79cz
Aug 18 17:47:45.044: INFO: Got endpoints: latency-svc-n79cz [223.254624ms]
Aug 18 17:47:45.051: INFO: Created: latency-svc-8z5pt
Aug 18 17:47:45.060: INFO: Got endpoints: latency-svc-8z5pt [223.468579ms]
Aug 18 17:47:45.066: INFO: Created: latency-svc-dm6mf
Aug 18 17:47:45.073: INFO: Got endpoints: latency-svc-dm6mf [220.344571ms]
Aug 18 17:47:45.080: INFO: Created: latency-svc-dv8tp
Aug 18 17:47:45.086: INFO: Got endpoints: latency-svc-dv8tp [217.68511ms]
Aug 18 17:47:45.095: INFO: Created: latency-svc-c8p6l
Aug 18 17:47:45.103: INFO: Got endpoints: latency-svc-c8p6l [222.718125ms]
Aug 18 17:47:45.109: INFO: Created: latency-svc-95dwg
Aug 18 17:47:45.117: INFO: Got endpoints: latency-svc-95dwg [221.71557ms]
Aug 18 17:47:45.125: INFO: Created: latency-svc-tq9dg
Aug 18 17:47:45.133: INFO: Got endpoints: latency-svc-tq9dg [219.24836ms]
Aug 18 17:47:45.138: INFO: Created: latency-svc-5j6f8
Aug 18 17:47:45.146: INFO: Got endpoints: latency-svc-5j6f8 [217.860417ms]
Aug 18 17:47:45.155: INFO: Created: latency-svc-7bsh9
Aug 18 17:47:45.163: INFO: Got endpoints: latency-svc-7bsh9 [220.80562ms]
Aug 18 17:47:45.174: INFO: Created: latency-svc-9r9cl
Aug 18 17:47:45.176: INFO: Got endpoints: latency-svc-9r9cl [218.178051ms]
Aug 18 17:47:45.183: INFO: Created: latency-svc-69mfz
Aug 18 17:47:45.190: INFO: Got endpoints: latency-svc-69mfz [217.546704ms]
Aug 18 17:47:45.198: INFO: Created: latency-svc-nsnp4
Aug 18 17:47:45.208: INFO: Got endpoints: latency-svc-nsnp4 [221.908664ms]
Aug 18 17:47:45.217: INFO: Created: latency-svc-8bj8d
Aug 18 17:47:45.221: INFO: Got endpoints: latency-svc-8bj8d [220.061212ms]
Aug 18 17:47:45.228: INFO: Created: latency-svc-cmd49
Aug 18 17:47:45.236: INFO: Got endpoints: latency-svc-cmd49 [218.501853ms]
Aug 18 17:47:45.245: INFO: Created: latency-svc-rbd86
Aug 18 17:47:45.254: INFO: Got endpoints: latency-svc-rbd86 [224.401579ms]
Aug 18 17:47:45.260: INFO: Created: latency-svc-gkdxr
Aug 18 17:47:45.273: INFO: Got endpoints: latency-svc-gkdxr [228.947603ms]
Aug 18 17:47:45.276: INFO: Created: latency-svc-vw42d
Aug 18 17:47:45.284: INFO: Got endpoints: latency-svc-vw42d [223.88922ms]
Aug 18 17:47:45.289: INFO: Created: latency-svc-ghln6
Aug 18 17:47:45.297: INFO: Got endpoints: latency-svc-ghln6 [223.293932ms]
Aug 18 17:47:45.304: INFO: Created: latency-svc-7qg2h
Aug 18 17:47:45.311: INFO: Got endpoints: latency-svc-7qg2h [224.934932ms]
Aug 18 17:47:45.319: INFO: Created: latency-svc-st6vn
Aug 18 17:47:45.326: INFO: Got endpoints: latency-svc-st6vn [223.745007ms]
Aug 18 17:47:45.332: INFO: Created: latency-svc-pr4rd
Aug 18 17:47:45.350: INFO: Created: latency-svc-rvpwt
Aug 18 17:47:45.350: INFO: Got endpoints: latency-svc-pr4rd [233.125385ms]
Aug 18 17:47:45.355: INFO: Got endpoints: latency-svc-rvpwt [221.673524ms]
Aug 18 17:47:45.365: INFO: Created: latency-svc-l8fr7
Aug 18 17:47:45.371: INFO: Got endpoints: latency-svc-l8fr7 [225.057388ms]
Aug 18 17:47:45.377: INFO: Created: latency-svc-8fq7z
Aug 18 17:47:45.384: INFO: Got endpoints: latency-svc-8fq7z [221.101801ms]
Aug 18 17:47:45.391: INFO: Created: latency-svc-rtktr
Aug 18 17:47:45.398: INFO: Got endpoints: latency-svc-rtktr [222.07178ms]
Aug 18 17:47:45.408: INFO: Created: latency-svc-xlsxf
Aug 18 17:47:45.414: INFO: Got endpoints: latency-svc-xlsxf [222.668675ms]
Aug 18 17:47:45.428: INFO: Created: latency-svc-l627f
Aug 18 17:47:45.435: INFO: Got endpoints: latency-svc-l627f [226.639009ms]
Aug 18 17:47:45.444: INFO: Created: latency-svc-7kdss
Aug 18 17:47:45.453: INFO: Got endpoints: latency-svc-7kdss [231.376427ms]
Aug 18 17:47:45.458: INFO: Created: latency-svc-rdhlc
Aug 18 17:47:45.472: INFO: Got endpoints: latency-svc-rdhlc [236.706832ms]
Aug 18 17:47:45.493: INFO: Created: latency-svc-68gtk
Aug 18 17:47:45.493: INFO: Got endpoints: latency-svc-68gtk [238.973769ms]
Aug 18 17:47:45.493: INFO: Created: latency-svc-ffcrl
Aug 18 17:47:45.504: INFO: Got endpoints: latency-svc-ffcrl [230.907757ms]
Aug 18 17:47:45.510: INFO: Created: latency-svc-xsgrg
Aug 18 17:47:45.529: INFO: Got endpoints: latency-svc-xsgrg [244.818776ms]
Aug 18 17:47:45.529: INFO: Created: latency-svc-8wv8j
Aug 18 17:47:45.536: INFO: Got endpoints: latency-svc-8wv8j [238.501757ms]
Aug 18 17:47:45.544: INFO: Created: latency-svc-q4dgx
Aug 18 17:47:45.553: INFO: Got endpoints: latency-svc-q4dgx [241.504282ms]
Aug 18 17:47:45.565: INFO: Created: latency-svc-g5zcp
Aug 18 17:47:45.572: INFO: Got endpoints: latency-svc-g5zcp [245.153344ms]
Aug 18 17:47:45.579: INFO: Created: latency-svc-gg95c
Aug 18 17:47:45.595: INFO: Created: latency-svc-dbxqn
Aug 18 17:47:45.595: INFO: Got endpoints: latency-svc-gg95c [245.013464ms]
Aug 18 17:47:45.603: INFO: Got endpoints: latency-svc-dbxqn [247.810024ms]
Aug 18 17:47:45.610: INFO: Created: latency-svc-l8x2v
Aug 18 17:47:45.619: INFO: Got endpoints: latency-svc-l8x2v [247.263205ms]
Aug 18 17:47:45.622: INFO: Created: latency-svc-gzfnr
Aug 18 17:47:45.631: INFO: Got endpoints: latency-svc-gzfnr [246.859765ms]
Aug 18 17:47:45.643: INFO: Created: latency-svc-phg6d
Aug 18 17:47:45.644: INFO: Got endpoints: latency-svc-phg6d [245.56579ms]
Aug 18 17:47:45.652: INFO: Created: latency-svc-l5shk
Aug 18 17:47:45.659: INFO: Got endpoints: latency-svc-l5shk [244.909536ms]
Aug 18 17:47:45.668: INFO: Created: latency-svc-x7bm7
Aug 18 17:47:45.675: INFO: Got endpoints: latency-svc-x7bm7 [239.830188ms]
Aug 18 17:47:45.683: INFO: Created: latency-svc-pl8z8
Aug 18 17:47:45.690: INFO: Got endpoints: latency-svc-pl8z8 [236.625209ms]
Aug 18 17:47:45.701: INFO: Created: latency-svc-6bdk8
Aug 18 17:47:45.706: INFO: Got endpoints: latency-svc-6bdk8 [233.746505ms]
Aug 18 17:47:45.714: INFO: Created: latency-svc-762f9
Aug 18 17:47:45.722: INFO: Got endpoints: latency-svc-762f9 [228.91311ms]
Aug 18 17:47:45.732: INFO: Created: latency-svc-qsknl
Aug 18 17:47:45.741: INFO: Got endpoints: latency-svc-qsknl [236.979396ms]
Aug 18 17:47:45.752: INFO: Created: latency-svc-vgcx7
Aug 18 17:47:45.760: INFO: Got endpoints: latency-svc-vgcx7 [231.618081ms]
Aug 18 17:47:45.766: INFO: Created: latency-svc-svfmf
Aug 18 17:47:45.775: INFO: Got endpoints: latency-svc-svfmf [239.656149ms]
Aug 18 17:47:45.779: INFO: Created: latency-svc-qdddj
Aug 18 17:47:45.790: INFO: Got endpoints: latency-svc-qdddj [236.786578ms]
Aug 18 17:47:45.794: INFO: Created: latency-svc-h4tmj
Aug 18 17:47:45.802: INFO: Got endpoints: latency-svc-h4tmj [230.738175ms]
Aug 18 17:47:45.809: INFO: Created: latency-svc-t4zrm
Aug 18 17:47:45.817: INFO: Got endpoints: latency-svc-t4zrm [221.080301ms]
Aug 18 17:47:45.824: INFO: Created: latency-svc-6c4tg
Aug 18 17:47:45.835: INFO: Got endpoints: latency-svc-6c4tg [231.90434ms]
Aug 18 17:47:45.844: INFO: Created: latency-svc-n88n8
Aug 18 17:47:45.848: INFO: Got endpoints: latency-svc-n88n8 [229.031134ms]
Aug 18 17:47:45.848: INFO: Latencies: [38.691373ms 54.162974ms 71.996876ms 87.153076ms 105.875838ms 120.254099ms 144.261574ms 150.684882ms 166.481368ms 182.047796ms 196.565957ms 205.38921ms 205.651177ms 205.836172ms 207.373791ms 207.37776ms 207.551901ms 207.578653ms 208.155042ms 208.209168ms 208.566342ms 208.784277ms 208.805409ms 208.827362ms 208.997144ms 209.000203ms 209.052644ms 209.412591ms 209.422498ms 209.477097ms 209.586694ms 209.730656ms 209.849718ms 209.874443ms 209.990913ms 210.046836ms 210.324413ms 210.337004ms 210.497492ms 211.557268ms 211.689742ms 211.941474ms 212.307506ms 212.498076ms 212.513295ms 212.929946ms 213.433522ms 213.442625ms 214.774966ms 215.459542ms 215.54346ms 217.546704ms 217.68511ms 217.860417ms 218.178051ms 218.454817ms 218.501853ms 218.57892ms 219.24836ms 219.269194ms 219.437054ms 219.454203ms 219.785045ms 220.061212ms 220.344571ms 220.388102ms 220.80562ms 220.817202ms 220.823813ms 220.857528ms 221.012048ms 221.080301ms 221.082551ms 221.101801ms 221.439454ms 221.471206ms 221.673524ms 221.71557ms 221.908664ms 222.052268ms 222.060872ms 222.071602ms 222.07178ms 222.668675ms 222.718125ms 222.816333ms 222.818927ms 222.955249ms 222.995927ms 223.254624ms 223.293932ms 223.468579ms 223.666816ms 223.745007ms 223.791201ms 223.881058ms 223.88922ms 223.926524ms 224.015697ms 224.030379ms 224.345627ms 224.401579ms 224.616933ms 224.712245ms 224.830768ms 224.860421ms 224.934932ms 225.004106ms 225.057388ms 225.613269ms 225.726616ms 225.754384ms 226.278512ms 226.639009ms 226.681475ms 226.739582ms 226.882738ms 226.975073ms 227.2053ms 227.663221ms 227.712995ms 228.148254ms 228.669889ms 228.91311ms 228.947603ms 229.031134ms 229.252339ms 229.314094ms 229.351129ms 229.563271ms 229.571333ms 229.805355ms 230.042152ms 230.220012ms 230.311494ms 230.403947ms 230.738175ms 230.907757ms 230.968125ms 231.376427ms 231.598843ms 231.618081ms 231.626639ms 231.708318ms 231.90434ms 231.91157ms 232.131233ms 232.218867ms 232.983615ms 233.125385ms 233.165804ms 233.167935ms 233.543785ms 233.556575ms 233.633316ms 233.714234ms 233.746505ms 233.749079ms 233.862915ms 234.980764ms 235.97198ms 236.625209ms 236.706832ms 236.786578ms 236.979396ms 237.711625ms 238.107263ms 238.383785ms 238.437366ms 238.501757ms 238.79201ms 238.806248ms 238.973769ms 239.656149ms 239.66521ms 239.77559ms 239.830188ms 239.888261ms 240.006035ms 240.582454ms 240.639973ms 240.733328ms 241.1606ms 241.224401ms 241.457199ms 241.504282ms 242.368995ms 242.510491ms 242.511221ms 244.818776ms 244.909536ms 245.013464ms 245.153344ms 245.193061ms 245.555578ms 245.56579ms 246.859765ms 247.263205ms 247.810024ms 255.868271ms]
Aug 18 17:47:45.848: INFO: 50 %ile: 224.345627ms
Aug 18 17:47:45.848: INFO: 90 %ile: 240.639973ms
Aug 18 17:47:45.848: INFO: 99 %ile: 247.810024ms
Aug 18 17:47:45.848: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:47:45.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-9950" for this suite.
Aug 18 17:48:13.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:48:14.341: INFO: namespace svc-latency-9950 deletion completed in 28.475299055s

• [SLOW TEST:33.972 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:48:14.341: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8040
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:48:25.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8040" for this suite.
Aug 18 17:48:31.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:48:32.205: INFO: namespace resourcequota-8040 deletion completed in 6.453971048s

• [SLOW TEST:17.864 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:48:32.205: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4955
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Aug 18 17:48:35.108: INFO: Successfully updated pod "annotationupdate67261e4d-e20d-499b-82f7-4574b10dac49"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:48:37.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4955" for this suite.
Aug 18 17:48:51.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:48:51.643: INFO: namespace downward-api-4955 deletion completed in 14.437395379s

• [SLOW TEST:19.438 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:48:51.646: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9803
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Aug 18 17:48:56.486: INFO: Successfully updated pod "labelsupdate712bec7b-bdd6-4b4b-8df0-54bf82e4238d"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:48:58.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9803" for this suite.
Aug 18 17:49:26.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:49:27.453: INFO: namespace projected-9803 deletion completed in 28.891911676s

• [SLOW TEST:35.808 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:49:27.454: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6812
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Aug 18 17:49:27.698: INFO: Waiting up to 5m0s for pod "downward-api-f7e81819-6405-41b6-8a42-25cce817c8ca" in namespace "downward-api-6812" to be "success or failure"
Aug 18 17:49:27.710: INFO: Pod "downward-api-f7e81819-6405-41b6-8a42-25cce817c8ca": Phase="Pending", Reason="", readiness=false. Elapsed: 12.123057ms
Aug 18 17:49:29.723: INFO: Pod "downward-api-f7e81819-6405-41b6-8a42-25cce817c8ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025229955s
STEP: Saw pod success
Aug 18 17:49:29.723: INFO: Pod "downward-api-f7e81819-6405-41b6-8a42-25cce817c8ca" satisfied condition "success or failure"
Aug 18 17:49:29.734: INFO: Trying to get logs from node 10.241.69.172 pod downward-api-f7e81819-6405-41b6-8a42-25cce817c8ca container dapi-container: <nil>
STEP: delete the pod
Aug 18 17:49:29.804: INFO: Waiting for pod downward-api-f7e81819-6405-41b6-8a42-25cce817c8ca to disappear
Aug 18 17:49:29.814: INFO: Pod downward-api-f7e81819-6405-41b6-8a42-25cce817c8ca no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:49:29.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6812" for this suite.
Aug 18 17:49:35.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:49:36.265: INFO: namespace downward-api-6812 deletion completed in 6.425863062s

• [SLOW TEST:8.812 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:49:36.267: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9101
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:49:41.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9101" for this suite.
Aug 18 17:49:47.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:49:47.643: INFO: namespace watch-9101 deletion completed in 6.497616099s

• [SLOW TEST:11.377 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:49:47.644: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4134
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Aug 18 17:49:47.859: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 17:49:51.726: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:50:07.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4134" for this suite.
Aug 18 17:50:13.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:50:13.500: INFO: namespace crd-publish-openapi-4134 deletion completed in 6.452242284s

• [SLOW TEST:25.856 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:50:13.502: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8850
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Aug 18 17:50:13.729: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:50:17.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8850" for this suite.
Aug 18 17:50:25.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:50:25.850: INFO: namespace init-container-8850 deletion completed in 8.420386355s

• [SLOW TEST:12.347 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:50:25.850: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1375
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:50:28.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1375" for this suite.
Aug 18 17:51:14.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:51:14.612: INFO: namespace kubelet-test-1375 deletion completed in 46.432939743s

• [SLOW TEST:48.762 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:51:14.612: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-898
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 17:51:14.858: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e37fb138-6d03-4a08-8c20-7e6c76e939a9" in namespace "downward-api-898" to be "success or failure"
Aug 18 17:51:14.876: INFO: Pod "downwardapi-volume-e37fb138-6d03-4a08-8c20-7e6c76e939a9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.053448ms
Aug 18 17:51:16.896: INFO: Pod "downwardapi-volume-e37fb138-6d03-4a08-8c20-7e6c76e939a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037835292s
STEP: Saw pod success
Aug 18 17:51:16.896: INFO: Pod "downwardapi-volume-e37fb138-6d03-4a08-8c20-7e6c76e939a9" satisfied condition "success or failure"
Aug 18 17:51:16.911: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-e37fb138-6d03-4a08-8c20-7e6c76e939a9 container client-container: <nil>
STEP: delete the pod
Aug 18 17:51:17.020: INFO: Waiting for pod downwardapi-volume-e37fb138-6d03-4a08-8c20-7e6c76e939a9 to disappear
Aug 18 17:51:17.039: INFO: Pod downwardapi-volume-e37fb138-6d03-4a08-8c20-7e6c76e939a9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:51:17.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-898" for this suite.
Aug 18 17:51:23.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:51:23.528: INFO: namespace downward-api-898 deletion completed in 6.457303441s

• [SLOW TEST:8.916 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:51:23.529: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-3679
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Aug 18 17:51:28.329: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3679 pod-service-account-335a50ed-81d8-4849-8acb-437852bb48f0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Aug 18 17:51:28.624: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3679 pod-service-account-335a50ed-81d8-4849-8acb-437852bb48f0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Aug 18 17:51:28.932: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3679 pod-service-account-335a50ed-81d8-4849-8acb-437852bb48f0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:51:29.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3679" for this suite.
Aug 18 17:51:35.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:51:35.703: INFO: namespace svcaccounts-3679 deletion completed in 6.452723349s

• [SLOW TEST:12.175 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:51:35.704: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9218
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 18 17:51:35.960: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9218 /api/v1/namespaces/watch-9218/configmaps/e2e-watch-test-watch-closed 6463394e-99c9-4886-a29b-76784c19171e 29538 0 2020-08-18 17:51:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 18 17:51:35.960: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9218 /api/v1/namespaces/watch-9218/configmaps/e2e-watch-test-watch-closed 6463394e-99c9-4886-a29b-76784c19171e 29539 0 2020-08-18 17:51:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 18 17:51:36.015: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9218 /api/v1/namespaces/watch-9218/configmaps/e2e-watch-test-watch-closed 6463394e-99c9-4886-a29b-76784c19171e 29540 0 2020-08-18 17:51:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 18 17:51:36.016: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9218 /api/v1/namespaces/watch-9218/configmaps/e2e-watch-test-watch-closed 6463394e-99c9-4886-a29b-76784c19171e 29541 0 2020-08-18 17:51:35 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:51:36.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9218" for this suite.
Aug 18 17:51:42.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:51:42.468: INFO: namespace watch-9218 deletion completed in 6.434195606s

• [SLOW TEST:6.765 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:51:42.472: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-3925
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:51:48.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3925" for this suite.
Aug 18 17:51:56.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:51:57.195: INFO: namespace job-3925 deletion completed in 8.457048785s

• [SLOW TEST:14.724 seconds]
[sig-apps] Job
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:51:57.195: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-5721
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug 18 17:51:58.038: INFO: Pod name wrapped-volume-race-db178964-acf6-4e0d-b785-4e6b11a8d69f: Found 0 pods out of 5
Aug 18 17:52:03.062: INFO: Pod name wrapped-volume-race-db178964-acf6-4e0d-b785-4e6b11a8d69f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-db178964-acf6-4e0d-b785-4e6b11a8d69f in namespace emptydir-wrapper-5721, will wait for the garbage collector to delete the pods
Aug 18 17:52:03.217: INFO: Deleting ReplicationController wrapped-volume-race-db178964-acf6-4e0d-b785-4e6b11a8d69f took: 22.336395ms
Aug 18 17:52:03.418: INFO: Terminating ReplicationController wrapped-volume-race-db178964-acf6-4e0d-b785-4e6b11a8d69f pods took: 200.303152ms
STEP: Creating RC which spawns configmap-volume pods
Aug 18 17:52:40.770: INFO: Pod name wrapped-volume-race-7c820915-8a61-416a-a167-c867302f574b: Found 0 pods out of 5
Aug 18 17:52:45.790: INFO: Pod name wrapped-volume-race-7c820915-8a61-416a-a167-c867302f574b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7c820915-8a61-416a-a167-c867302f574b in namespace emptydir-wrapper-5721, will wait for the garbage collector to delete the pods
Aug 18 17:52:45.936: INFO: Deleting ReplicationController wrapped-volume-race-7c820915-8a61-416a-a167-c867302f574b took: 23.89518ms
Aug 18 17:52:46.136: INFO: Terminating ReplicationController wrapped-volume-race-7c820915-8a61-416a-a167-c867302f574b pods took: 200.32389ms
STEP: Creating RC which spawns configmap-volume pods
Aug 18 17:53:30.487: INFO: Pod name wrapped-volume-race-8efab7ad-b537-4654-ab1c-11965a8abfab: Found 0 pods out of 5
Aug 18 17:53:35.506: INFO: Pod name wrapped-volume-race-8efab7ad-b537-4654-ab1c-11965a8abfab: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8efab7ad-b537-4654-ab1c-11965a8abfab in namespace emptydir-wrapper-5721, will wait for the garbage collector to delete the pods
Aug 18 17:53:35.651: INFO: Deleting ReplicationController wrapped-volume-race-8efab7ad-b537-4654-ab1c-11965a8abfab took: 27.282364ms
Aug 18 17:53:35.852: INFO: Terminating ReplicationController wrapped-volume-race-8efab7ad-b537-4654-ab1c-11965a8abfab pods took: 200.611157ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:54:21.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5721" for this suite.
Aug 18 17:54:31.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:54:32.251: INFO: namespace emptydir-wrapper-5721 deletion completed in 10.450870939s

• [SLOW TEST:155.056 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:54:32.252: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1869
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 17:54:32.504: INFO: Waiting up to 5m0s for pod "downwardapi-volume-571e4ed8-5ecf-4634-bfa3-ba51566eb804" in namespace "projected-1869" to be "success or failure"
Aug 18 17:54:32.516: INFO: Pod "downwardapi-volume-571e4ed8-5ecf-4634-bfa3-ba51566eb804": Phase="Pending", Reason="", readiness=false. Elapsed: 11.751615ms
Aug 18 17:54:34.528: INFO: Pod "downwardapi-volume-571e4ed8-5ecf-4634-bfa3-ba51566eb804": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023781342s
STEP: Saw pod success
Aug 18 17:54:34.528: INFO: Pod "downwardapi-volume-571e4ed8-5ecf-4634-bfa3-ba51566eb804" satisfied condition "success or failure"
Aug 18 17:54:34.540: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-571e4ed8-5ecf-4634-bfa3-ba51566eb804 container client-container: <nil>
STEP: delete the pod
Aug 18 17:54:34.629: INFO: Waiting for pod downwardapi-volume-571e4ed8-5ecf-4634-bfa3-ba51566eb804 to disappear
Aug 18 17:54:34.640: INFO: Pod downwardapi-volume-571e4ed8-5ecf-4634-bfa3-ba51566eb804 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:54:34.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1869" for this suite.
Aug 18 17:54:40.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:54:41.086: INFO: namespace projected-1869 deletion completed in 6.418990273s

• [SLOW TEST:8.834 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:54:41.087: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6882
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 18 17:54:41.325: INFO: Waiting up to 5m0s for pod "pod-34f9db12-2f4f-4ef9-b6ba-cfc1661b2369" in namespace "emptydir-6882" to be "success or failure"
Aug 18 17:54:41.340: INFO: Pod "pod-34f9db12-2f4f-4ef9-b6ba-cfc1661b2369": Phase="Pending", Reason="", readiness=false. Elapsed: 15.045708ms
Aug 18 17:54:43.353: INFO: Pod "pod-34f9db12-2f4f-4ef9-b6ba-cfc1661b2369": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02783755s
STEP: Saw pod success
Aug 18 17:54:43.353: INFO: Pod "pod-34f9db12-2f4f-4ef9-b6ba-cfc1661b2369" satisfied condition "success or failure"
Aug 18 17:54:43.363: INFO: Trying to get logs from node 10.241.69.172 pod pod-34f9db12-2f4f-4ef9-b6ba-cfc1661b2369 container test-container: <nil>
STEP: delete the pod
Aug 18 17:54:43.421: INFO: Waiting for pod pod-34f9db12-2f4f-4ef9-b6ba-cfc1661b2369 to disappear
Aug 18 17:54:43.430: INFO: Pod pod-34f9db12-2f4f-4ef9-b6ba-cfc1661b2369 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:54:43.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6882" for this suite.
Aug 18 17:54:49.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:54:49.906: INFO: namespace emptydir-6882 deletion completed in 6.455621232s

• [SLOW TEST:8.820 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:54:49.906: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3211
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3211
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-3211
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3211
Aug 18 17:54:50.168: INFO: Found 0 stateful pods, waiting for 1
Aug 18 17:55:00.181: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 18 17:55:00.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-3211 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 18 17:55:00.473: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 18 17:55:00.473: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 18 17:55:00.473: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 18 17:55:00.485: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 18 17:55:10.499: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 18 17:55:10.499: INFO: Waiting for statefulset status.replicas updated to 0
Aug 18 17:55:10.543: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 18 17:55:10.543: INFO: ss-0  10.241.69.172  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  }]
Aug 18 17:55:10.543: INFO: ss-1                 Pending         []
Aug 18 17:55:10.543: INFO: 
Aug 18 17:55:10.543: INFO: StatefulSet ss has not reached scale 3, at 2
Aug 18 17:55:11.557: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.98694797s
Aug 18 17:55:12.569: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.973846946s
Aug 18 17:55:13.581: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.96188191s
Aug 18 17:55:14.594: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.949672573s
Aug 18 17:55:15.607: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.936971373s
Aug 18 17:55:16.619: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.92351294s
Aug 18 17:55:17.632: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.911389017s
Aug 18 17:55:18.644: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.898698689s
Aug 18 17:55:19.657: INFO: Verifying statefulset ss doesn't scale past 3 for another 886.444389ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3211
Aug 18 17:55:20.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-3211 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 18 17:55:20.955: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 18 17:55:20.955: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 18 17:55:20.955: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 18 17:55:20.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-3211 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 18 17:55:21.228: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 18 17:55:21.228: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 18 17:55:21.228: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 18 17:55:21.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-3211 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 18 17:55:21.530: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 18 17:55:21.530: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 18 17:55:21.530: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 18 17:55:21.543: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug 18 17:55:31.557: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 18 17:55:31.557: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 18 17:55:31.557: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 18 17:55:31.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-3211 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 18 17:55:31.881: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 18 17:55:31.881: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 18 17:55:31.881: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 18 17:55:31.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-3211 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 18 17:55:32.203: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 18 17:55:32.203: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 18 17:55:32.203: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 18 17:55:32.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=statefulset-3211 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 18 17:55:32.474: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 18 17:55:32.474: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 18 17:55:32.474: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 18 17:55:32.474: INFO: Waiting for statefulset status.replicas updated to 0
Aug 18 17:55:32.484: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 18 17:55:42.507: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 18 17:55:42.507: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 18 17:55:42.507: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 18 17:55:42.543: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 18 17:55:42.543: INFO: ss-0  10.241.69.172  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  }]
Aug 18 17:55:42.543: INFO: ss-1  10.241.69.184  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  }]
Aug 18 17:55:42.543: INFO: ss-2  10.241.69.181  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  }]
Aug 18 17:55:42.543: INFO: 
Aug 18 17:55:42.543: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 18 17:55:43.555: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 18 17:55:43.555: INFO: ss-0  10.241.69.172  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  }]
Aug 18 17:55:43.555: INFO: ss-1  10.241.69.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  }]
Aug 18 17:55:43.555: INFO: ss-2  10.241.69.181  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  }]
Aug 18 17:55:43.555: INFO: 
Aug 18 17:55:43.555: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 18 17:55:44.569: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 18 17:55:44.569: INFO: ss-0  10.241.69.172  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  }]
Aug 18 17:55:44.569: INFO: ss-2  10.241.69.181  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  }]
Aug 18 17:55:44.569: INFO: 
Aug 18 17:55:44.569: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 18 17:55:45.582: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 18 17:55:45.582: INFO: ss-0  10.241.69.172  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  }]
Aug 18 17:55:45.582: INFO: ss-2  10.241.69.181  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  }]
Aug 18 17:55:45.582: INFO: 
Aug 18 17:55:45.582: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 18 17:55:46.594: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 18 17:55:46.594: INFO: ss-0  10.241.69.172  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  }]
Aug 18 17:55:46.594: INFO: ss-2  10.241.69.181  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  }]
Aug 18 17:55:46.594: INFO: 
Aug 18 17:55:46.594: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 18 17:55:47.614: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 18 17:55:47.614: INFO: ss-0  10.241.69.172  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  }]
Aug 18 17:55:47.614: INFO: ss-2  10.241.69.181  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  }]
Aug 18 17:55:47.614: INFO: 
Aug 18 17:55:47.614: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 18 17:55:48.627: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 18 17:55:48.627: INFO: ss-0  10.241.69.172  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  }]
Aug 18 17:55:48.627: INFO: ss-2  10.241.69.181  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  }]
Aug 18 17:55:48.627: INFO: 
Aug 18 17:55:48.627: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 18 17:55:49.639: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 18 17:55:49.639: INFO: ss-0  10.241.69.172  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:54:50 +0000 UTC  }]
Aug 18 17:55:49.639: INFO: ss-2  10.241.69.181  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  }]
Aug 18 17:55:49.639: INFO: 
Aug 18 17:55:49.639: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 18 17:55:50.653: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 18 17:55:50.653: INFO: ss-2  10.241.69.181  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-08-18 17:55:10 +0000 UTC  }]
Aug 18 17:55:50.653: INFO: 
Aug 18 17:55:50.653: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 18 17:55:51.665: INFO: Verifying statefulset ss doesn't scale past 0 for another 873.263775ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3211
Aug 18 17:55:52.676: INFO: Scaling statefulset ss to 0
Aug 18 17:55:52.707: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Aug 18 17:55:52.716: INFO: Deleting all statefulset in ns statefulset-3211
Aug 18 17:55:52.725: INFO: Scaling statefulset ss to 0
Aug 18 17:55:52.753: INFO: Waiting for statefulset status.replicas updated to 0
Aug 18 17:55:52.762: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:55:52.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3211" for this suite.
Aug 18 17:56:00.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:56:01.302: INFO: namespace statefulset-3211 deletion completed in 8.477566151s

• [SLOW TEST:71.396 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:56:01.303: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5929
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Aug 18 17:56:01.528: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-434562375 proxy --unix-socket=/tmp/kubectl-proxy-unix293199774/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:56:01.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5929" for this suite.
Aug 18 17:56:07.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:56:08.044: INFO: namespace kubectl-5929 deletion completed in 6.413319161s

• [SLOW TEST:6.742 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:56:08.046: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-7120
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 17:56:08.264: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Creating first CR 
Aug 18 17:56:08.930: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-08-18T17:56:08Z generation:1 name:name1 resourceVersion:30883 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:16b30da8-51b0-439a-9f5f-373dd049644d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Aug 18 17:56:18.944: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-08-18T17:56:18Z generation:1 name:name2 resourceVersion:30896 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:2007dd10-7286-4c7a-a5c3-60fade9e151c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Aug 18 17:56:28.957: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-08-18T17:56:08Z generation:2 name:name1 resourceVersion:30912 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:16b30da8-51b0-439a-9f5f-373dd049644d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Aug 18 17:56:38.970: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-08-18T17:56:18Z generation:2 name:name2 resourceVersion:30925 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:2007dd10-7286-4c7a-a5c3-60fade9e151c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Aug 18 17:56:48.994: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-08-18T17:56:08Z generation:2 name:name1 resourceVersion:30938 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:16b30da8-51b0-439a-9f5f-373dd049644d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Aug 18 17:56:59.019: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-08-18T17:56:18Z generation:2 name:name2 resourceVersion:30953 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:2007dd10-7286-4c7a-a5c3-60fade9e151c] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:57:09.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-7120" for this suite.
Aug 18 17:57:15.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:57:16.047: INFO: namespace crd-watch-7120 deletion completed in 6.469338727s

• [SLOW TEST:68.002 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:57:16.048: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3984
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3984.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3984.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3984.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3984.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 18 17:57:18.392: INFO: DNS probes using dns-test-de5aab74-84ef-4744-9d23-713c1420dbc0 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3984.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3984.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3984.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3984.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 18 17:57:20.570: INFO: DNS probes using dns-test-2ebd74a4-4003-46c0-90cd-6d954de3a4fc succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3984.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3984.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3984.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3984.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 18 17:57:24.785: INFO: DNS probes using dns-test-553b4176-4719-4f85-aecb-ad07ff617ea6 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:57:24.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3984" for this suite.
Aug 18 17:57:32.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:57:33.354: INFO: namespace dns-3984 deletion completed in 8.446413022s

• [SLOW TEST:17.307 seconds]
[sig-network] DNS
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:57:33.369: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5415
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5415
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 18 17:57:33.587: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 18 17:57:55.850: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.104.181:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5415 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 17:57:55.850: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 17:57:56.028: INFO: Found all expected endpoints: [netserver-0]
Aug 18 17:57:56.039: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.108.37:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5415 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 17:57:56.039: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 17:57:56.207: INFO: Found all expected endpoints: [netserver-1]
Aug 18 17:57:56.217: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.134.112:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5415 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 17:57:56.217: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 17:57:56.419: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:57:56.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5415" for this suite.
Aug 18 17:58:10.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:58:10.894: INFO: namespace pod-network-test-5415 deletion completed in 14.456025933s

• [SLOW TEST:37.525 seconds]
[sig-network] Networking
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:58:10.896: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9867
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-90f79872-8cda-4b30-8eb1-665e5c4ccbe4
STEP: Creating a pod to test consume secrets
Aug 18 17:58:11.153: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2f7f074f-6fab-4796-bc61-1bbae490df90" in namespace "projected-9867" to be "success or failure"
Aug 18 17:58:11.163: INFO: Pod "pod-projected-secrets-2f7f074f-6fab-4796-bc61-1bbae490df90": Phase="Pending", Reason="", readiness=false. Elapsed: 9.741756ms
Aug 18 17:58:13.176: INFO: Pod "pod-projected-secrets-2f7f074f-6fab-4796-bc61-1bbae490df90": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022708457s
Aug 18 17:58:15.190: INFO: Pod "pod-projected-secrets-2f7f074f-6fab-4796-bc61-1bbae490df90": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03691628s
STEP: Saw pod success
Aug 18 17:58:15.190: INFO: Pod "pod-projected-secrets-2f7f074f-6fab-4796-bc61-1bbae490df90" satisfied condition "success or failure"
Aug 18 17:58:15.204: INFO: Trying to get logs from node 10.241.69.172 pod pod-projected-secrets-2f7f074f-6fab-4796-bc61-1bbae490df90 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 18 17:58:15.317: INFO: Waiting for pod pod-projected-secrets-2f7f074f-6fab-4796-bc61-1bbae490df90 to disappear
Aug 18 17:58:15.328: INFO: Pod pod-projected-secrets-2f7f074f-6fab-4796-bc61-1bbae490df90 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:58:15.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9867" for this suite.
Aug 18 17:58:21.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:58:21.811: INFO: namespace projected-9867 deletion completed in 6.458290551s

• [SLOW TEST:10.916 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:58:21.815: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4964
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 18 17:58:26.210: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 18 17:58:26.225: INFO: Pod pod-with-poststart-http-hook still exists
Aug 18 17:58:28.226: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 18 17:58:28.237: INFO: Pod pod-with-poststart-http-hook still exists
Aug 18 17:58:30.226: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 18 17:58:30.241: INFO: Pod pod-with-poststart-http-hook still exists
Aug 18 17:58:32.226: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 18 17:58:32.238: INFO: Pod pod-with-poststart-http-hook still exists
Aug 18 17:58:34.226: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 18 17:58:34.238: INFO: Pod pod-with-poststart-http-hook still exists
Aug 18 17:58:36.226: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 18 17:58:36.238: INFO: Pod pod-with-poststart-http-hook still exists
Aug 18 17:58:38.226: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 18 17:58:38.238: INFO: Pod pod-with-poststart-http-hook still exists
Aug 18 17:58:40.226: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 18 17:58:40.704: INFO: Pod pod-with-poststart-http-hook still exists
Aug 18 17:58:42.226: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 18 17:58:42.237: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:58:42.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4964" for this suite.
Aug 18 17:59:12.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:59:12.697: INFO: namespace container-lifecycle-hook-4964 deletion completed in 30.440061692s

• [SLOW TEST:50.883 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:59:12.701: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3894
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-8f54e02b-2c8a-422d-a350-104e178d624f
STEP: Creating a pod to test consume configMaps
Aug 18 17:59:12.984: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-72b3206d-a988-48ea-95b5-443b5ccdbbb9" in namespace "projected-3894" to be "success or failure"
Aug 18 17:59:12.997: INFO: Pod "pod-projected-configmaps-72b3206d-a988-48ea-95b5-443b5ccdbbb9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.642951ms
Aug 18 17:59:15.008: INFO: Pod "pod-projected-configmaps-72b3206d-a988-48ea-95b5-443b5ccdbbb9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024401489s
STEP: Saw pod success
Aug 18 17:59:15.008: INFO: Pod "pod-projected-configmaps-72b3206d-a988-48ea-95b5-443b5ccdbbb9" satisfied condition "success or failure"
Aug 18 17:59:15.020: INFO: Trying to get logs from node 10.241.69.172 pod pod-projected-configmaps-72b3206d-a988-48ea-95b5-443b5ccdbbb9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 18 17:59:15.112: INFO: Waiting for pod pod-projected-configmaps-72b3206d-a988-48ea-95b5-443b5ccdbbb9 to disappear
Aug 18 17:59:15.123: INFO: Pod pod-projected-configmaps-72b3206d-a988-48ea-95b5-443b5ccdbbb9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:59:15.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3894" for this suite.
Aug 18 17:59:21.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:59:21.579: INFO: namespace projected-3894 deletion completed in 6.435151641s

• [SLOW TEST:8.879 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:59:21.580: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1971
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-d955b608-e4ff-4055-a323-620104a3037a
STEP: Creating secret with name secret-projected-all-test-volume-fa1daa6c-162e-48a2-badd-d379a1e5d5af
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 18 17:59:21.853: INFO: Waiting up to 5m0s for pod "projected-volume-3a7e14b7-5cfa-41d2-add1-c14cb827934b" in namespace "projected-1971" to be "success or failure"
Aug 18 17:59:21.864: INFO: Pod "projected-volume-3a7e14b7-5cfa-41d2-add1-c14cb827934b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.271862ms
Aug 18 17:59:23.875: INFO: Pod "projected-volume-3a7e14b7-5cfa-41d2-add1-c14cb827934b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022547799s
STEP: Saw pod success
Aug 18 17:59:23.875: INFO: Pod "projected-volume-3a7e14b7-5cfa-41d2-add1-c14cb827934b" satisfied condition "success or failure"
Aug 18 17:59:23.885: INFO: Trying to get logs from node 10.241.69.172 pod projected-volume-3a7e14b7-5cfa-41d2-add1-c14cb827934b container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 18 17:59:23.952: INFO: Waiting for pod projected-volume-3a7e14b7-5cfa-41d2-add1-c14cb827934b to disappear
Aug 18 17:59:23.971: INFO: Pod projected-volume-3a7e14b7-5cfa-41d2-add1-c14cb827934b no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:59:23.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1971" for this suite.
Aug 18 17:59:30.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:59:30.432: INFO: namespace projected-1971 deletion completed in 6.437051131s

• [SLOW TEST:8.852 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:59:30.432: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2130
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:59:30.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2130" for this suite.
Aug 18 17:59:36.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:59:37.185: INFO: namespace services-2130 deletion completed in 6.48351042s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.753 seconds]
[sig-network] Services
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:59:37.186: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5870
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-70d25abd-b808-4618-a3c5-60b86fd01f6a
STEP: Creating a pod to test consume configMaps
Aug 18 17:59:37.443: INFO: Waiting up to 5m0s for pod "pod-configmaps-59fbcdf9-32f6-4028-98da-cd5c35e5e417" in namespace "configmap-5870" to be "success or failure"
Aug 18 17:59:37.455: INFO: Pod "pod-configmaps-59fbcdf9-32f6-4028-98da-cd5c35e5e417": Phase="Pending", Reason="", readiness=false. Elapsed: 12.052597ms
Aug 18 17:59:39.470: INFO: Pod "pod-configmaps-59fbcdf9-32f6-4028-98da-cd5c35e5e417": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026990697s
Aug 18 17:59:41.483: INFO: Pod "pod-configmaps-59fbcdf9-32f6-4028-98da-cd5c35e5e417": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039622543s
STEP: Saw pod success
Aug 18 17:59:41.483: INFO: Pod "pod-configmaps-59fbcdf9-32f6-4028-98da-cd5c35e5e417" satisfied condition "success or failure"
Aug 18 17:59:41.496: INFO: Trying to get logs from node 10.241.69.172 pod pod-configmaps-59fbcdf9-32f6-4028-98da-cd5c35e5e417 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 18 17:59:41.585: INFO: Waiting for pod pod-configmaps-59fbcdf9-32f6-4028-98da-cd5c35e5e417 to disappear
Aug 18 17:59:41.597: INFO: Pod pod-configmaps-59fbcdf9-32f6-4028-98da-cd5c35e5e417 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:59:41.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5870" for this suite.
Aug 18 17:59:47.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:59:48.081: INFO: namespace configmap-5870 deletion completed in 6.461267309s

• [SLOW TEST:10.895 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:59:48.083: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4659
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Aug 18 17:59:48.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4659'
Aug 18 17:59:48.534: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 18 17:59:48.534: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Aug 18 17:59:48.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete jobs e2e-test-httpd-job --namespace=kubectl-4659'
Aug 18 17:59:48.697: INFO: stderr: ""
Aug 18 17:59:48.697: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 17:59:48.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4659" for this suite.
Aug 18 17:59:54.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 17:59:55.187: INFO: namespace kubectl-4659 deletion completed in 6.459390423s

• [SLOW TEST:7.104 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 17:59:55.187: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4978
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 18 18:00:03.578: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 18 18:00:03.594: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 18 18:00:05.594: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 18 18:00:05.608: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 18 18:00:07.594: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 18 18:00:07.608: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 18 18:00:09.596: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 18 18:00:09.622: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 18 18:00:11.594: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 18 18:00:11.607: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:00:11.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4978" for this suite.
Aug 18 18:00:23.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:00:24.125: INFO: namespace container-lifecycle-hook-4978 deletion completed in 12.488385328s

• [SLOW TEST:28.937 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:00:24.129: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-147
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Aug 18 18:00:24.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 create -f - --namespace=kubectl-147'
Aug 18 18:00:24.704: INFO: stderr: ""
Aug 18 18:00:24.704: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 18 18:00:24.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-147'
Aug 18 18:00:24.827: INFO: stderr: ""
Aug 18 18:00:24.827: INFO: stdout: "update-demo-nautilus-6dcfh update-demo-nautilus-qdqm9 "
Aug 18 18:00:24.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-6dcfh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-147'
Aug 18 18:00:24.940: INFO: stderr: ""
Aug 18 18:00:24.940: INFO: stdout: ""
Aug 18 18:00:24.940: INFO: update-demo-nautilus-6dcfh is created but not running
Aug 18 18:00:29.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-147'
Aug 18 18:00:30.045: INFO: stderr: ""
Aug 18 18:00:30.045: INFO: stdout: "update-demo-nautilus-6dcfh update-demo-nautilus-qdqm9 "
Aug 18 18:00:30.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-6dcfh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-147'
Aug 18 18:00:30.161: INFO: stderr: ""
Aug 18 18:00:30.161: INFO: stdout: "true"
Aug 18 18:00:30.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-6dcfh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-147'
Aug 18 18:00:30.273: INFO: stderr: ""
Aug 18 18:00:30.273: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 18 18:00:30.273: INFO: validating pod update-demo-nautilus-6dcfh
Aug 18 18:00:30.306: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 18 18:00:30.306: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 18 18:00:30.306: INFO: update-demo-nautilus-6dcfh is verified up and running
Aug 18 18:00:30.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-qdqm9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-147'
Aug 18 18:00:30.418: INFO: stderr: ""
Aug 18 18:00:30.418: INFO: stdout: "true"
Aug 18 18:00:30.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-qdqm9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-147'
Aug 18 18:00:30.526: INFO: stderr: ""
Aug 18 18:00:30.526: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 18 18:00:30.526: INFO: validating pod update-demo-nautilus-qdqm9
Aug 18 18:00:30.556: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 18 18:00:30.556: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 18 18:00:30.556: INFO: update-demo-nautilus-qdqm9 is verified up and running
STEP: using delete to clean up resources
Aug 18 18:00:30.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete --grace-period=0 --force -f - --namespace=kubectl-147'
Aug 18 18:00:30.673: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 18 18:00:30.673: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 18 18:00:30.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-147'
Aug 18 18:00:30.808: INFO: stderr: "No resources found in kubectl-147 namespace.\n"
Aug 18 18:00:30.808: INFO: stdout: ""
Aug 18 18:00:30.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods -l name=update-demo --namespace=kubectl-147 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 18 18:00:30.929: INFO: stderr: ""
Aug 18 18:00:30.929: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:00:30.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-147" for this suite.
Aug 18 18:01:00.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:01:01.401: INFO: namespace kubectl-147 deletion completed in 30.448713041s

• [SLOW TEST:37.272 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:01:01.401: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5740
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-96d66f26-0b92-47d6-9935-c0a30a96755f
STEP: Creating a pod to test consume configMaps
Aug 18 18:01:01.669: INFO: Waiting up to 5m0s for pod "pod-configmaps-05e7c049-6bb8-49af-850e-35e8fbd44c6a" in namespace "configmap-5740" to be "success or failure"
Aug 18 18:01:01.682: INFO: Pod "pod-configmaps-05e7c049-6bb8-49af-850e-35e8fbd44c6a": Phase="Pending", Reason="", readiness=false. Elapsed: 13.486678ms
Aug 18 18:01:03.694: INFO: Pod "pod-configmaps-05e7c049-6bb8-49af-850e-35e8fbd44c6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024965712s
Aug 18 18:01:05.705: INFO: Pod "pod-configmaps-05e7c049-6bb8-49af-850e-35e8fbd44c6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036216552s
STEP: Saw pod success
Aug 18 18:01:05.705: INFO: Pod "pod-configmaps-05e7c049-6bb8-49af-850e-35e8fbd44c6a" satisfied condition "success or failure"
Aug 18 18:01:05.717: INFO: Trying to get logs from node 10.241.69.172 pod pod-configmaps-05e7c049-6bb8-49af-850e-35e8fbd44c6a container configmap-volume-test: <nil>
STEP: delete the pod
Aug 18 18:01:05.776: INFO: Waiting for pod pod-configmaps-05e7c049-6bb8-49af-850e-35e8fbd44c6a to disappear
Aug 18 18:01:05.786: INFO: Pod pod-configmaps-05e7c049-6bb8-49af-850e-35e8fbd44c6a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:01:05.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5740" for this suite.
Aug 18 18:01:11.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:01:12.305: INFO: namespace configmap-5740 deletion completed in 6.499144369s

• [SLOW TEST:10.904 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:01:12.305: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-6590
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:01:12.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-6590" for this suite.
Aug 18 18:01:18.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:01:19.086: INFO: namespace tables-6590 deletion completed in 6.503984747s

• [SLOW TEST:6.781 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:01:19.087: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5560
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 18:01:19.355: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fd44c7b1-c9d1-4253-85e9-ef4a28e745c8" in namespace "projected-5560" to be "success or failure"
Aug 18 18:01:19.367: INFO: Pod "downwardapi-volume-fd44c7b1-c9d1-4253-85e9-ef4a28e745c8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.676399ms
Aug 18 18:01:21.380: INFO: Pod "downwardapi-volume-fd44c7b1-c9d1-4253-85e9-ef4a28e745c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025186689s
STEP: Saw pod success
Aug 18 18:01:21.380: INFO: Pod "downwardapi-volume-fd44c7b1-c9d1-4253-85e9-ef4a28e745c8" satisfied condition "success or failure"
Aug 18 18:01:21.391: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-fd44c7b1-c9d1-4253-85e9-ef4a28e745c8 container client-container: <nil>
STEP: delete the pod
Aug 18 18:01:21.453: INFO: Waiting for pod downwardapi-volume-fd44c7b1-c9d1-4253-85e9-ef4a28e745c8 to disappear
Aug 18 18:01:21.464: INFO: Pod downwardapi-volume-fd44c7b1-c9d1-4253-85e9-ef4a28e745c8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:01:21.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5560" for this suite.
Aug 18 18:01:27.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:01:27.993: INFO: namespace projected-5560 deletion completed in 6.500872963s

• [SLOW TEST:8.906 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:01:27.993: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 18 18:01:30.426: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:01:30.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4834" for this suite.
Aug 18 18:01:36.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:01:36.955: INFO: namespace container-runtime-4834 deletion completed in 6.454896057s

• [SLOW TEST:8.962 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:01:36.955: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-409
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Aug 18 18:01:37.198: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-409" to be "success or failure"
Aug 18 18:01:37.211: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 12.299386ms
Aug 18 18:01:39.222: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023769433s
STEP: Saw pod success
Aug 18 18:01:39.223: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug 18 18:01:39.234: INFO: Trying to get logs from node 10.241.69.172 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug 18 18:01:39.293: INFO: Waiting for pod pod-host-path-test to disappear
Aug 18 18:01:39.303: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:01:39.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-409" for this suite.
Aug 18 18:01:45.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:01:45.796: INFO: namespace hostpath-409 deletion completed in 6.469894888s

• [SLOW TEST:8.841 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:01:45.798: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-4548
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 18 18:01:50.183: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4548 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 18:01:50.183: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 18:01:50.366: INFO: Exec stderr: ""
Aug 18 18:01:50.366: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4548 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 18:01:50.367: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 18:01:50.545: INFO: Exec stderr: ""
Aug 18 18:01:50.545: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4548 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 18:01:50.545: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 18:01:50.703: INFO: Exec stderr: ""
Aug 18 18:01:50.703: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4548 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 18:01:50.703: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 18:01:50.890: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 18 18:01:50.890: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4548 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 18:01:50.890: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 18:01:51.064: INFO: Exec stderr: ""
Aug 18 18:01:51.064: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4548 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 18:01:51.064: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 18:01:51.227: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 18 18:01:51.227: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4548 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 18:01:51.227: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 18:01:51.403: INFO: Exec stderr: ""
Aug 18 18:01:51.403: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4548 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 18:01:51.403: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 18:01:51.564: INFO: Exec stderr: ""
Aug 18 18:01:51.564: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4548 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 18:01:51.564: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 18:01:51.731: INFO: Exec stderr: ""
Aug 18 18:01:51.731: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4548 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 18:01:51.731: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 18:01:51.892: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:01:51.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4548" for this suite.
Aug 18 18:02:41.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:02:42.379: INFO: namespace e2e-kubelet-etc-hosts-4548 deletion completed in 50.465527411s

• [SLOW TEST:56.582 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:02:42.382: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4393
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-8963
STEP: Creating secret with name secret-test-5fb00fff-96ec-4991-83db-c5115b5df50b
STEP: Creating a pod to test consume secrets
Aug 18 18:02:42.884: INFO: Waiting up to 5m0s for pod "pod-secrets-556cb05e-acdb-44c9-81a2-0e4f2036f759" in namespace "secrets-4393" to be "success or failure"
Aug 18 18:02:42.902: INFO: Pod "pod-secrets-556cb05e-acdb-44c9-81a2-0e4f2036f759": Phase="Pending", Reason="", readiness=false. Elapsed: 18.142765ms
Aug 18 18:02:44.914: INFO: Pod "pod-secrets-556cb05e-acdb-44c9-81a2-0e4f2036f759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030111644s
Aug 18 18:02:46.926: INFO: Pod "pod-secrets-556cb05e-acdb-44c9-81a2-0e4f2036f759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042031385s
STEP: Saw pod success
Aug 18 18:02:46.926: INFO: Pod "pod-secrets-556cb05e-acdb-44c9-81a2-0e4f2036f759" satisfied condition "success or failure"
Aug 18 18:02:46.937: INFO: Trying to get logs from node 10.241.69.172 pod pod-secrets-556cb05e-acdb-44c9-81a2-0e4f2036f759 container secret-volume-test: <nil>
STEP: delete the pod
Aug 18 18:02:46.999: INFO: Waiting for pod pod-secrets-556cb05e-acdb-44c9-81a2-0e4f2036f759 to disappear
Aug 18 18:02:47.009: INFO: Pod pod-secrets-556cb05e-acdb-44c9-81a2-0e4f2036f759 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:02:47.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4393" for this suite.
Aug 18 18:02:53.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:02:53.499: INFO: namespace secrets-4393 deletion completed in 6.466908401s
STEP: Destroying namespace "secret-namespace-8963" for this suite.
Aug 18 18:02:59.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:02:59.961: INFO: namespace secret-namespace-8963 deletion completed in 6.461693794s

• [SLOW TEST:17.580 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:02:59.962: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4319
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Aug 18 18:03:00.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 api-versions'
Aug 18 18:03:00.300: INFO: stderr: ""
Aug 18 18:03:00.300: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\noperators.coreos.com/v1\noperators.coreos.com/v1alpha1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:03:00.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4319" for this suite.
Aug 18 18:03:06.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:03:06.844: INFO: namespace kubectl-4319 deletion completed in 6.520707006s

• [SLOW TEST:6.882 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:03:06.846: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8737
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-8737/configmap-test-06244464-527c-4321-887f-6a617a9589ae
STEP: Creating a pod to test consume configMaps
Aug 18 18:03:07.127: INFO: Waiting up to 5m0s for pod "pod-configmaps-68c34869-a0cf-4a27-9236-3ad4abe795e9" in namespace "configmap-8737" to be "success or failure"
Aug 18 18:03:07.140: INFO: Pod "pod-configmaps-68c34869-a0cf-4a27-9236-3ad4abe795e9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.787549ms
Aug 18 18:03:09.152: INFO: Pod "pod-configmaps-68c34869-a0cf-4a27-9236-3ad4abe795e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02426585s
STEP: Saw pod success
Aug 18 18:03:09.152: INFO: Pod "pod-configmaps-68c34869-a0cf-4a27-9236-3ad4abe795e9" satisfied condition "success or failure"
Aug 18 18:03:09.162: INFO: Trying to get logs from node 10.241.69.172 pod pod-configmaps-68c34869-a0cf-4a27-9236-3ad4abe795e9 container env-test: <nil>
STEP: delete the pod
Aug 18 18:03:09.222: INFO: Waiting for pod pod-configmaps-68c34869-a0cf-4a27-9236-3ad4abe795e9 to disappear
Aug 18 18:03:09.233: INFO: Pod pod-configmaps-68c34869-a0cf-4a27-9236-3ad4abe795e9 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:03:09.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8737" for this suite.
Aug 18 18:03:15.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:03:15.721: INFO: namespace configmap-8737 deletion completed in 6.462439212s

• [SLOW TEST:8.875 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:03:15.723: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7593
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 18:03:15.971: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d5278112-d70d-438c-afaa-dded4d41f1e4" in namespace "downward-api-7593" to be "success or failure"
Aug 18 18:03:15.981: INFO: Pod "downwardapi-volume-d5278112-d70d-438c-afaa-dded4d41f1e4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.35677ms
Aug 18 18:03:17.992: INFO: Pod "downwardapi-volume-d5278112-d70d-438c-afaa-dded4d41f1e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021713575s
Aug 18 18:03:20.004: INFO: Pod "downwardapi-volume-d5278112-d70d-438c-afaa-dded4d41f1e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033379909s
STEP: Saw pod success
Aug 18 18:03:20.004: INFO: Pod "downwardapi-volume-d5278112-d70d-438c-afaa-dded4d41f1e4" satisfied condition "success or failure"
Aug 18 18:03:20.016: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-d5278112-d70d-438c-afaa-dded4d41f1e4 container client-container: <nil>
STEP: delete the pod
Aug 18 18:03:20.077: INFO: Waiting for pod downwardapi-volume-d5278112-d70d-438c-afaa-dded4d41f1e4 to disappear
Aug 18 18:03:20.087: INFO: Pod downwardapi-volume-d5278112-d70d-438c-afaa-dded4d41f1e4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:03:20.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7593" for this suite.
Aug 18 18:03:28.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:03:28.613: INFO: namespace downward-api-7593 deletion completed in 8.502768127s

• [SLOW TEST:12.890 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:03:28.613: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7674
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-pt4v
STEP: Creating a pod to test atomic-volume-subpath
Aug 18 18:03:28.889: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-pt4v" in namespace "subpath-7674" to be "success or failure"
Aug 18 18:03:28.913: INFO: Pod "pod-subpath-test-configmap-pt4v": Phase="Pending", Reason="", readiness=false. Elapsed: 24.199994ms
Aug 18 18:03:30.927: INFO: Pod "pod-subpath-test-configmap-pt4v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03853887s
Aug 18 18:03:32.941: INFO: Pod "pod-subpath-test-configmap-pt4v": Phase="Running", Reason="", readiness=true. Elapsed: 4.05248971s
Aug 18 18:03:34.955: INFO: Pod "pod-subpath-test-configmap-pt4v": Phase="Running", Reason="", readiness=true. Elapsed: 6.066250848s
Aug 18 18:03:36.978: INFO: Pod "pod-subpath-test-configmap-pt4v": Phase="Running", Reason="", readiness=true. Elapsed: 8.089416573s
Aug 18 18:03:38.990: INFO: Pod "pod-subpath-test-configmap-pt4v": Phase="Running", Reason="", readiness=true. Elapsed: 10.101117299s
Aug 18 18:03:41.004: INFO: Pod "pod-subpath-test-configmap-pt4v": Phase="Running", Reason="", readiness=true. Elapsed: 12.115008072s
Aug 18 18:03:43.017: INFO: Pod "pod-subpath-test-configmap-pt4v": Phase="Running", Reason="", readiness=true. Elapsed: 14.12808549s
Aug 18 18:03:45.029: INFO: Pod "pod-subpath-test-configmap-pt4v": Phase="Running", Reason="", readiness=true. Elapsed: 16.140377305s
Aug 18 18:03:47.044: INFO: Pod "pod-subpath-test-configmap-pt4v": Phase="Running", Reason="", readiness=true. Elapsed: 18.155101418s
Aug 18 18:03:49.056: INFO: Pod "pod-subpath-test-configmap-pt4v": Phase="Running", Reason="", readiness=true. Elapsed: 20.167279752s
Aug 18 18:03:51.068: INFO: Pod "pod-subpath-test-configmap-pt4v": Phase="Running", Reason="", readiness=true. Elapsed: 22.178986238s
Aug 18 18:03:53.081: INFO: Pod "pod-subpath-test-configmap-pt4v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.191824558s
STEP: Saw pod success
Aug 18 18:03:53.081: INFO: Pod "pod-subpath-test-configmap-pt4v" satisfied condition "success or failure"
Aug 18 18:03:53.093: INFO: Trying to get logs from node 10.241.69.172 pod pod-subpath-test-configmap-pt4v container test-container-subpath-configmap-pt4v: <nil>
STEP: delete the pod
Aug 18 18:03:53.162: INFO: Waiting for pod pod-subpath-test-configmap-pt4v to disappear
Aug 18 18:03:53.174: INFO: Pod pod-subpath-test-configmap-pt4v no longer exists
STEP: Deleting pod pod-subpath-test-configmap-pt4v
Aug 18 18:03:53.174: INFO: Deleting pod "pod-subpath-test-configmap-pt4v" in namespace "subpath-7674"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:03:53.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7674" for this suite.
Aug 18 18:03:59.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:03:59.681: INFO: namespace subpath-7674 deletion completed in 6.468549566s

• [SLOW TEST:31.068 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:03:59.681: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3490
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:03:59.926: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 18 18:04:04.939: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 18 18:04:04.940: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Aug 18 18:04:09.042: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-3490 /apis/apps/v1/namespaces/deployment-3490/deployments/test-cleanup-deployment bf7e803e-a95f-4787-aad1-372c8712d615 32666 1 2020-08-18 18:04:04 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0007b1488 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-08-18 18:04:05 +0000 UTC,LastTransitionTime:2020-08-18 18:04:05 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-65db99849b" has successfully progressed.,LastUpdateTime:2020-08-18 18:04:07 +0000 UTC,LastTransitionTime:2020-08-18 18:04:05 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 18 18:04:09.054: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-3490 /apis/apps/v1/namespaces/deployment-3490/replicasets/test-cleanup-deployment-65db99849b 49e8d77e-816e-4878-ab49-844f5426faba 32655 1 2020-08-18 18:04:04 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment bf7e803e-a95f-4787-aad1-372c8712d615 0xc0007b18b7 0xc0007b18b8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0007b1918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 18 18:04:09.067: INFO: Pod "test-cleanup-deployment-65db99849b-ppb2m" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-ppb2m test-cleanup-deployment-65db99849b- deployment-3490 /api/v1/namespaces/deployment-3490/pods/test-cleanup-deployment-65db99849b-ppb2m e0288dc1-327f-4dd7-ae02-ff04096be6cb 32654 0 2020-08-18 18:04:05 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b 49e8d77e-816e-4878-ab49-844f5426faba 0xc0007b1cc7 0xc0007b1cc8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4686r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4686r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4686r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 18:04:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 18:04:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 18:04:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 18:04:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:172.30.104.149,StartTime:2020-08-18 18:04:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 18:04:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://89b02962f7e6adb8d431dad4f94b997c1a5ddd661e49103aa395e25fd851bb58,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.149,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:04:09.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3490" for this suite.
Aug 18 18:04:17.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:04:17.538: INFO: namespace deployment-3490 deletion completed in 8.454064518s

• [SLOW TEST:17.857 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:04:17.538: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5501
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Aug 18 18:04:17.758: INFO: PodSpec: initContainers in spec.initContainers
Aug 18 18:04:59.248: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-12df9046-2b1b-4a4f-97db-29666ff78092", GenerateName:"", Namespace:"init-container-5501", SelfLink:"/api/v1/namespaces/init-container-5501/pods/pod-init-12df9046-2b1b-4a4f-97db-29666ff78092", UID:"42ac0999-3a3c-4b06-9b0e-5837db041056", ResourceVersion:"32809", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63733370657, loc:(*time.Location)(0x78ac9c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"758151614"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-j2hr4", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0056fa380), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-j2hr4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-j2hr4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-j2hr4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0007b1058), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.241.69.172", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001f50420), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0007b1100)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0007b1120)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0007b1128), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0007b112c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370657, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370657, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370657, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370657, loc:(*time.Location)(0x78ac9c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.241.69.172", PodIP:"172.30.104.134", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.30.104.134"}}, StartTime:(*v1.Time)(0xc0035b0000), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000974310)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000974620)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://370c503f1d20209c8d01bcd49e3d24308d5ef77eb4e772ebefaa83a9cdd1c6b6", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0035b0040), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0035b0020), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0007b12c4)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:04:59.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5501" for this suite.
Aug 18 18:05:29.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:05:29.728: INFO: namespace init-container-5501 deletion completed in 30.460501082s

• [SLOW TEST:72.190 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:05:29.729: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8961
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8961
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 18 18:05:29.959: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 18 18:05:54.246: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.104.150:8080/dial?request=hostName&protocol=http&host=172.30.108.31&port=8080&tries=1'] Namespace:pod-network-test-8961 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 18:05:54.246: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 18:05:54.443: INFO: Waiting for endpoints: map[]
Aug 18 18:05:54.456: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.104.150:8080/dial?request=hostName&protocol=http&host=172.30.104.148&port=8080&tries=1'] Namespace:pod-network-test-8961 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 18:05:54.456: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 18:05:54.621: INFO: Waiting for endpoints: map[]
Aug 18 18:05:54.633: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.104.150:8080/dial?request=hostName&protocol=http&host=172.30.134.114&port=8080&tries=1'] Namespace:pod-network-test-8961 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 18 18:05:54.633: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 18:05:54.791: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:05:54.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8961" for this suite.
Aug 18 18:06:08.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:06:09.292: INFO: namespace pod-network-test-8961 deletion completed in 14.480893605s

• [SLOW TEST:39.563 seconds]
[sig-network] Networking
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:06:09.293: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2691
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 18:06:10.100: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 18 18:06:12.139: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370770, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370770, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370770, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370770, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 18:06:15.191: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:06:15.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2691" for this suite.
Aug 18 18:06:23.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:06:23.937: INFO: namespace webhook-2691 deletion completed in 8.486766042s
STEP: Destroying namespace "webhook-2691-markers" for this suite.
Aug 18 18:06:29.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:06:30.413: INFO: namespace webhook-2691-markers deletion completed in 6.475892067s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.181 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:06:30.474: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-2930
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Aug 18 18:06:30.694: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Aug 18 18:06:31.339: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Aug 18 18:06:33.471: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 18:06:35.485: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 18:06:37.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 18:06:39.486: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733370791, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 18 18:06:46.768: INFO: Waited 5.267613408s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:06:47.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2930" for this suite.
Aug 18 18:06:55.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:06:55.868: INFO: namespace aggregator-2930 deletion completed in 8.474164093s

• [SLOW TEST:25.394 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:06:55.868: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4098
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-9bfa1cfc-483b-4ff2-9a36-3add9a42f2ce
STEP: Creating a pod to test consume configMaps
Aug 18 18:06:56.127: INFO: Waiting up to 5m0s for pod "pod-configmaps-a5720c0d-be47-4b29-9f35-ff8321f83938" in namespace "configmap-4098" to be "success or failure"
Aug 18 18:06:56.145: INFO: Pod "pod-configmaps-a5720c0d-be47-4b29-9f35-ff8321f83938": Phase="Pending", Reason="", readiness=false. Elapsed: 17.668707ms
Aug 18 18:06:58.157: INFO: Pod "pod-configmaps-a5720c0d-be47-4b29-9f35-ff8321f83938": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030021482s
STEP: Saw pod success
Aug 18 18:06:58.158: INFO: Pod "pod-configmaps-a5720c0d-be47-4b29-9f35-ff8321f83938" satisfied condition "success or failure"
Aug 18 18:06:58.174: INFO: Trying to get logs from node 10.241.69.172 pod pod-configmaps-a5720c0d-be47-4b29-9f35-ff8321f83938 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 18 18:06:58.265: INFO: Waiting for pod pod-configmaps-a5720c0d-be47-4b29-9f35-ff8321f83938 to disappear
Aug 18 18:06:58.275: INFO: Pod pod-configmaps-a5720c0d-be47-4b29-9f35-ff8321f83938 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:06:58.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4098" for this suite.
Aug 18 18:07:06.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:07:06.772: INFO: namespace configmap-4098 deletion completed in 8.471215333s

• [SLOW TEST:10.903 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:07:06.772: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4470
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 18:07:07.012: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dcda5727-40d9-4c3a-bd2f-8a5444aaf269" in namespace "projected-4470" to be "success or failure"
Aug 18 18:07:07.023: INFO: Pod "downwardapi-volume-dcda5727-40d9-4c3a-bd2f-8a5444aaf269": Phase="Pending", Reason="", readiness=false. Elapsed: 10.542299ms
Aug 18 18:07:09.034: INFO: Pod "downwardapi-volume-dcda5727-40d9-4c3a-bd2f-8a5444aaf269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021861889s
STEP: Saw pod success
Aug 18 18:07:09.034: INFO: Pod "downwardapi-volume-dcda5727-40d9-4c3a-bd2f-8a5444aaf269" satisfied condition "success or failure"
Aug 18 18:07:09.045: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-dcda5727-40d9-4c3a-bd2f-8a5444aaf269 container client-container: <nil>
STEP: delete the pod
Aug 18 18:07:09.121: INFO: Waiting for pod downwardapi-volume-dcda5727-40d9-4c3a-bd2f-8a5444aaf269 to disappear
Aug 18 18:07:09.132: INFO: Pod downwardapi-volume-dcda5727-40d9-4c3a-bd2f-8a5444aaf269 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:07:09.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4470" for this suite.
Aug 18 18:07:15.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:07:15.588: INFO: namespace projected-4470 deletion completed in 6.428746289s

• [SLOW TEST:8.816 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:07:15.593: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-7610
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:07:17.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7610" for this suite.
Aug 18 18:07:24.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:07:24.483: INFO: namespace emptydir-wrapper-7610 deletion completed in 6.480224264s

• [SLOW TEST:8.890 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:07:24.483: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7797
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 18:07:24.733: INFO: Waiting up to 5m0s for pod "downwardapi-volume-207c08db-4849-44f2-88ec-a45109a74052" in namespace "projected-7797" to be "success or failure"
Aug 18 18:07:24.753: INFO: Pod "downwardapi-volume-207c08db-4849-44f2-88ec-a45109a74052": Phase="Pending", Reason="", readiness=false. Elapsed: 19.431819ms
Aug 18 18:07:26.764: INFO: Pod "downwardapi-volume-207c08db-4849-44f2-88ec-a45109a74052": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030885781s
STEP: Saw pod success
Aug 18 18:07:26.764: INFO: Pod "downwardapi-volume-207c08db-4849-44f2-88ec-a45109a74052" satisfied condition "success or failure"
Aug 18 18:07:26.775: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-207c08db-4849-44f2-88ec-a45109a74052 container client-container: <nil>
STEP: delete the pod
Aug 18 18:07:26.857: INFO: Waiting for pod downwardapi-volume-207c08db-4849-44f2-88ec-a45109a74052 to disappear
Aug 18 18:07:26.879: INFO: Pod downwardapi-volume-207c08db-4849-44f2-88ec-a45109a74052 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:07:26.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7797" for this suite.
Aug 18 18:07:32.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:07:33.372: INFO: namespace projected-7797 deletion completed in 6.451279988s

• [SLOW TEST:8.888 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:07:33.372: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2514
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 18 18:07:33.602: INFO: Waiting up to 5m0s for pod "pod-a032099f-fe69-4af2-9f6f-db1488b34ce6" in namespace "emptydir-2514" to be "success or failure"
Aug 18 18:07:33.613: INFO: Pod "pod-a032099f-fe69-4af2-9f6f-db1488b34ce6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.963952ms
Aug 18 18:07:35.625: INFO: Pod "pod-a032099f-fe69-4af2-9f6f-db1488b34ce6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022025277s
STEP: Saw pod success
Aug 18 18:07:35.625: INFO: Pod "pod-a032099f-fe69-4af2-9f6f-db1488b34ce6" satisfied condition "success or failure"
Aug 18 18:07:35.635: INFO: Trying to get logs from node 10.241.69.172 pod pod-a032099f-fe69-4af2-9f6f-db1488b34ce6 container test-container: <nil>
STEP: delete the pod
Aug 18 18:07:35.701: INFO: Waiting for pod pod-a032099f-fe69-4af2-9f6f-db1488b34ce6 to disappear
Aug 18 18:07:35.711: INFO: Pod pod-a032099f-fe69-4af2-9f6f-db1488b34ce6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:07:35.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2514" for this suite.
Aug 18 18:07:41.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:07:42.180: INFO: namespace emptydir-2514 deletion completed in 6.445427203s

• [SLOW TEST:8.808 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:07:42.180: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-792
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 18:07:42.429: INFO: Waiting up to 5m0s for pod "downwardapi-volume-46d36e0f-90ae-4684-b5ed-a669b9108f8b" in namespace "projected-792" to be "success or failure"
Aug 18 18:07:42.440: INFO: Pod "downwardapi-volume-46d36e0f-90ae-4684-b5ed-a669b9108f8b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.6064ms
Aug 18 18:07:44.452: INFO: Pod "downwardapi-volume-46d36e0f-90ae-4684-b5ed-a669b9108f8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023516102s
Aug 18 18:07:46.467: INFO: Pod "downwardapi-volume-46d36e0f-90ae-4684-b5ed-a669b9108f8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038096339s
STEP: Saw pod success
Aug 18 18:07:46.467: INFO: Pod "downwardapi-volume-46d36e0f-90ae-4684-b5ed-a669b9108f8b" satisfied condition "success or failure"
Aug 18 18:07:46.479: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-46d36e0f-90ae-4684-b5ed-a669b9108f8b container client-container: <nil>
STEP: delete the pod
Aug 18 18:07:46.538: INFO: Waiting for pod downwardapi-volume-46d36e0f-90ae-4684-b5ed-a669b9108f8b to disappear
Aug 18 18:07:46.549: INFO: Pod downwardapi-volume-46d36e0f-90ae-4684-b5ed-a669b9108f8b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:07:46.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-792" for this suite.
Aug 18 18:07:52.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:07:53.050: INFO: namespace projected-792 deletion completed in 6.470171915s

• [SLOW TEST:10.870 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:07:53.050: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8830
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-3f392878-e23a-45e5-acd0-dbef7abdd3e4
STEP: Creating a pod to test consume secrets
Aug 18 18:07:53.348: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-db482abc-afd8-483b-92ae-63975e4c4e90" in namespace "projected-8830" to be "success or failure"
Aug 18 18:07:53.359: INFO: Pod "pod-projected-secrets-db482abc-afd8-483b-92ae-63975e4c4e90": Phase="Pending", Reason="", readiness=false. Elapsed: 10.57838ms
Aug 18 18:07:55.371: INFO: Pod "pod-projected-secrets-db482abc-afd8-483b-92ae-63975e4c4e90": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023216586s
Aug 18 18:07:57.384: INFO: Pod "pod-projected-secrets-db482abc-afd8-483b-92ae-63975e4c4e90": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03595604s
STEP: Saw pod success
Aug 18 18:07:57.384: INFO: Pod "pod-projected-secrets-db482abc-afd8-483b-92ae-63975e4c4e90" satisfied condition "success or failure"
Aug 18 18:07:57.395: INFO: Trying to get logs from node 10.241.69.172 pod pod-projected-secrets-db482abc-afd8-483b-92ae-63975e4c4e90 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 18 18:07:57.455: INFO: Waiting for pod pod-projected-secrets-db482abc-afd8-483b-92ae-63975e4c4e90 to disappear
Aug 18 18:07:57.474: INFO: Pod pod-projected-secrets-db482abc-afd8-483b-92ae-63975e4c4e90 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:07:57.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8830" for this suite.
Aug 18 18:08:05.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:08:06.071: INFO: namespace projected-8830 deletion completed in 8.57644226s

• [SLOW TEST:13.021 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:08:06.072: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3955
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-357d3127-248c-4b3b-b054-0b4a19648709
STEP: Creating a pod to test consume configMaps
Aug 18 18:08:06.350: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ac328125-6288-4092-8b4a-32fb458a6dfb" in namespace "projected-3955" to be "success or failure"
Aug 18 18:08:06.367: INFO: Pod "pod-projected-configmaps-ac328125-6288-4092-8b4a-32fb458a6dfb": Phase="Pending", Reason="", readiness=false. Elapsed: 16.747619ms
Aug 18 18:08:08.380: INFO: Pod "pod-projected-configmaps-ac328125-6288-4092-8b4a-32fb458a6dfb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030039806s
STEP: Saw pod success
Aug 18 18:08:08.380: INFO: Pod "pod-projected-configmaps-ac328125-6288-4092-8b4a-32fb458a6dfb" satisfied condition "success or failure"
Aug 18 18:08:08.393: INFO: Trying to get logs from node 10.241.69.172 pod pod-projected-configmaps-ac328125-6288-4092-8b4a-32fb458a6dfb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 18 18:08:08.455: INFO: Waiting for pod pod-projected-configmaps-ac328125-6288-4092-8b4a-32fb458a6dfb to disappear
Aug 18 18:08:08.466: INFO: Pod pod-projected-configmaps-ac328125-6288-4092-8b4a-32fb458a6dfb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:08:08.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3955" for this suite.
Aug 18 18:08:14.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:08:14.937: INFO: namespace projected-3955 deletion completed in 6.450689469s

• [SLOW TEST:8.865 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:08:14.939: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8246
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Aug 18 18:08:15.174: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 18 18:08:15.265: INFO: Waiting for terminating namespaces to be deleted...
Aug 18 18:08:15.279: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.172 before test
Aug 18 18:08:15.327: INFO: ibm-keepalived-watcher-2f6fp from kube-system started at 2020-08-18 15:45:12 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.327: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 18:08:15.327: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-m29th from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 18:08:15.327: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 18 18:08:15.327: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 18:08:15.327: INFO: ibm-master-proxy-static-10.241.69.172 from kube-system started at 2020-08-18 15:45:10 +0000 UTC (2 container statuses recorded)
Aug 18 18:08:15.327: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 18:08:15.327: INFO: 	Container pause ready: true, restart count 0
Aug 18 18:08:15.327: INFO: calico-node-sz9mb from kube-system started at 2020-08-18 15:45:12 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.327: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 18:08:15.327: INFO: addon-catalog-source-gmd49 from ibm-system started at 2020-08-18 15:45:49 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.327: INFO: 	Container configmap-registry-server ready: true, restart count 0
Aug 18 18:08:15.327: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.181 before test
Aug 18 18:08:15.417: INFO: ibm-master-proxy-static-10.241.69.181 from kube-system started at 2020-08-18 15:49:51 +0000 UTC (2 container statuses recorded)
Aug 18 18:08:15.417: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 18:08:15.417: INFO: 	Container pause ready: true, restart count 0
Aug 18 18:08:15.418: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-08-18 15:52:42 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.418: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Aug 18 18:08:15.418: INFO: coredns-autoscaler-65c89858bf-q6hj7 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.418: INFO: 	Container autoscaler ready: true, restart count 0
Aug 18 18:08:15.418: INFO: dashboard-metrics-scraper-76756886dc-rk2k2 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.418: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Aug 18 18:08:15.418: INFO: ibm-cloud-provider-ip-169-47-71-114-64b8d74dd8-8brdn from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.418: INFO: 	Container ibm-cloud-provider-ip-169-47-71-114 ready: true, restart count 0
Aug 18 18:08:15.418: INFO: ibm-keepalived-watcher-kr9tn from kube-system started at 2020-08-18 15:50:03 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.418: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 18:08:15.418: INFO: olm-operator-6f74dfc868-28t4m from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.418: INFO: 	Container olm-operator ready: true, restart count 0
Aug 18 18:08:15.418: INFO: coredns-55db5d97fb-8tfqf from kube-system started at 2020-08-18 15:57:41 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.418: INFO: 	Container coredns ready: true, restart count 0
Aug 18 18:08:15.418: INFO: sonobuoy-e2e-job-692caab668c14a3b from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 18:08:15.418: INFO: 	Container e2e ready: true, restart count 0
Aug 18 18:08:15.418: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 18 18:08:15.418: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-rwtzr from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 18:08:15.418: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 18 18:08:15.418: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 18:08:15.418: INFO: calico-node-vn5q9 from kube-system started at 2020-08-18 15:50:03 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.418: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 18:08:15.418: INFO: sonobuoy from sonobuoy started at 2020-08-18 17:08:11 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.418: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 18 18:08:15.418: INFO: kubernetes-dashboard-85b945ff4b-9cklr from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.418: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 18 18:08:15.418: INFO: public-crbstv5sqd0r3kmi9abm0g-alb1-5f59ffb4c7-4k6xv from kube-system started at 2020-08-18 17:21:45 +0000 UTC (4 container statuses recorded)
Aug 18 18:08:15.418: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 18 18:08:15.418: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 18 18:08:15.418: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 18 18:08:15.418: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 18 18:08:15.418: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.184 before test
Aug 18 18:08:15.498: INFO: ibm-keepalived-watcher-xt8rx from kube-system started at 2020-08-18 15:46:36 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.498: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 18:08:15.499: INFO: public-crbstv5sqd0r3kmi9abm0g-alb1-5f59ffb4c7-s8vcr from kube-system started at 2020-08-18 15:48:16 +0000 UTC (4 container statuses recorded)
Aug 18 18:08:15.499: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 18 18:08:15.499: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 18 18:08:15.499: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 18 18:08:15.499: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 18 18:08:15.499: INFO: ibm-file-plugin-7c6788b5f5-ldfzf from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.499: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug 18 18:08:15.499: INFO: catalog-operator-67cbc5d959-hqgh5 from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.499: INFO: 	Container catalog-operator ready: true, restart count 0
Aug 18 18:08:15.499: INFO: ibm-cloud-provider-ip-169-47-71-114-64b8d74dd8-dc47l from ibm-system started at 2020-08-18 15:46:51 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.499: INFO: 	Container ibm-cloud-provider-ip-169-47-71-114 ready: true, restart count 0
Aug 18 18:08:15.499: INFO: vpn-79845b6f9d-wmz87 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.499: INFO: 	Container vpn ready: true, restart count 0
Aug 18 18:08:15.499: INFO: metrics-server-695ffd979-8z2wt from kube-system started at 2020-08-18 17:21:45 +0000 UTC (2 container statuses recorded)
Aug 18 18:08:15.499: INFO: 	Container metrics-server ready: true, restart count 0
Aug 18 18:08:15.499: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 18 18:08:15.499: INFO: coredns-55db5d97fb-cqx5b from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.499: INFO: 	Container coredns ready: true, restart count 0
Aug 18 18:08:15.499: INFO: coredns-55db5d97fb-2h7nb from kube-system started at 2020-08-18 15:57:41 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.499: INFO: 	Container coredns ready: true, restart count 0
Aug 18 18:08:15.499: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-ctchp from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 18:08:15.499: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 18 18:08:15.499: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 18:08:15.499: INFO: ibm-storage-watcher-5685787df4-w25gd from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.499: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug 18 18:08:15.499: INFO: ibm-master-proxy-static-10.241.69.184 from kube-system started at 2020-08-18 15:46:23 +0000 UTC (2 container statuses recorded)
Aug 18 18:08:15.499: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 18:08:15.499: INFO: 	Container pause ready: true, restart count 0
Aug 18 18:08:15.500: INFO: calico-node-f56nz from kube-system started at 2020-08-18 15:46:36 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.500: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 18:08:15.500: INFO: calico-kube-controllers-66c5f69b5f-9qvwh from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:08:15.500: INFO: 	Container calico-kube-controllers ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-fa991044-0be4-4fa8-96e3-8f492b141f4b 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-fa991044-0be4-4fa8-96e3-8f492b141f4b off the node 10.241.69.172
STEP: verifying the node doesn't have the label kubernetes.io/e2e-fa991044-0be4-4fa8-96e3-8f492b141f4b
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:08:29.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8246" for this suite.
Aug 18 18:08:53.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:08:54.304: INFO: namespace sched-pred-8246 deletion completed in 24.484692273s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:39.365 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:08:54.305: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-108
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-108.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-108.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-108.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-108.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-108.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-108.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 18 18:08:58.775: INFO: DNS probes using dns-108/dns-test-ada5d33c-cac9-44d7-8dfc-cc4c0c1b1331 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:08:58.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-108" for this suite.
Aug 18 18:09:06.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:09:07.358: INFO: namespace dns-108 deletion completed in 8.483843724s

• [SLOW TEST:13.052 seconds]
[sig-network] DNS
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:09:07.359: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4611
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:09:23.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4611" for this suite.
Aug 18 18:09:31.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:09:32.361: INFO: namespace resourcequota-4611 deletion completed in 8.473520783s

• [SLOW TEST:25.002 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:09:32.361: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4142
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Aug 18 18:09:32.609: INFO: Waiting up to 5m0s for pod "downward-api-9f306e77-cbaf-44f6-960e-5b4401a9caea" in namespace "downward-api-4142" to be "success or failure"
Aug 18 18:09:32.620: INFO: Pod "downward-api-9f306e77-cbaf-44f6-960e-5b4401a9caea": Phase="Pending", Reason="", readiness=false. Elapsed: 10.932197ms
Aug 18 18:09:34.632: INFO: Pod "downward-api-9f306e77-cbaf-44f6-960e-5b4401a9caea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023110442s
Aug 18 18:09:36.643: INFO: Pod "downward-api-9f306e77-cbaf-44f6-960e-5b4401a9caea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034766762s
STEP: Saw pod success
Aug 18 18:09:36.644: INFO: Pod "downward-api-9f306e77-cbaf-44f6-960e-5b4401a9caea" satisfied condition "success or failure"
Aug 18 18:09:36.654: INFO: Trying to get logs from node 10.241.69.172 pod downward-api-9f306e77-cbaf-44f6-960e-5b4401a9caea container dapi-container: <nil>
STEP: delete the pod
Aug 18 18:09:36.724: INFO: Waiting for pod downward-api-9f306e77-cbaf-44f6-960e-5b4401a9caea to disappear
Aug 18 18:09:36.735: INFO: Pod downward-api-9f306e77-cbaf-44f6-960e-5b4401a9caea no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:09:36.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4142" for this suite.
Aug 18 18:09:42.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:09:43.256: INFO: namespace downward-api-4142 deletion completed in 6.495488756s

• [SLOW TEST:10.895 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:09:43.256: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-631
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:09:43.492: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Aug 18 18:09:46.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-631 create -f -'
Aug 18 18:09:47.372: INFO: stderr: ""
Aug 18 18:09:47.372: INFO: stdout: "e2e-test-crd-publish-openapi-1438-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Aug 18 18:09:47.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-631 delete e2e-test-crd-publish-openapi-1438-crds test-cr'
Aug 18 18:09:47.501: INFO: stderr: ""
Aug 18 18:09:47.501: INFO: stdout: "e2e-test-crd-publish-openapi-1438-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Aug 18 18:09:47.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-631 apply -f -'
Aug 18 18:09:47.837: INFO: stderr: ""
Aug 18 18:09:47.837: INFO: stdout: "e2e-test-crd-publish-openapi-1438-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Aug 18 18:09:47.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-631 delete e2e-test-crd-publish-openapi-1438-crds test-cr'
Aug 18 18:09:47.962: INFO: stderr: ""
Aug 18 18:09:47.962: INFO: stdout: "e2e-test-crd-publish-openapi-1438-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Aug 18 18:09:47.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 explain e2e-test-crd-publish-openapi-1438-crds'
Aug 18 18:09:48.148: INFO: stderr: ""
Aug 18 18:09:48.148: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1438-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:09:51.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-631" for this suite.
Aug 18 18:09:58.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:09:58.447: INFO: namespace crd-publish-openapi-631 deletion completed in 6.443911555s

• [SLOW TEST:15.191 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:09:58.456: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9918
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 18:09:58.714: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f69f4698-20ca-42aa-bbd4-83bd1c5c3a04" in namespace "downward-api-9918" to be "success or failure"
Aug 18 18:09:58.730: INFO: Pod "downwardapi-volume-f69f4698-20ca-42aa-bbd4-83bd1c5c3a04": Phase="Pending", Reason="", readiness=false. Elapsed: 16.444105ms
Aug 18 18:10:00.742: INFO: Pod "downwardapi-volume-f69f4698-20ca-42aa-bbd4-83bd1c5c3a04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027707789s
Aug 18 18:10:02.752: INFO: Pod "downwardapi-volume-f69f4698-20ca-42aa-bbd4-83bd1c5c3a04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038694936s
STEP: Saw pod success
Aug 18 18:10:02.753: INFO: Pod "downwardapi-volume-f69f4698-20ca-42aa-bbd4-83bd1c5c3a04" satisfied condition "success or failure"
Aug 18 18:10:02.766: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-f69f4698-20ca-42aa-bbd4-83bd1c5c3a04 container client-container: <nil>
STEP: delete the pod
Aug 18 18:10:02.827: INFO: Waiting for pod downwardapi-volume-f69f4698-20ca-42aa-bbd4-83bd1c5c3a04 to disappear
Aug 18 18:10:02.842: INFO: Pod downwardapi-volume-f69f4698-20ca-42aa-bbd4-83bd1c5c3a04 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:10:02.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9918" for this suite.
Aug 18 18:10:08.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:10:09.363: INFO: namespace downward-api-9918 deletion completed in 6.501033066s

• [SLOW TEST:10.907 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:10:09.363: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3803
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 18:10:10.375: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 18:10:13.452: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:10:13.463: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7657-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:10:14.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3803" for this suite.
Aug 18 18:10:22.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:10:23.204: INFO: namespace webhook-3803 deletion completed in 8.466732719s
STEP: Destroying namespace "webhook-3803-markers" for this suite.
Aug 18 18:10:29.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:10:29.643: INFO: namespace webhook-3803-markers deletion completed in 6.438625767s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:20.342 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:10:29.707: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6456
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-ff1dc803-2b3a-4100-ba92-b4d987f8383b
STEP: Creating a pod to test consume secrets
Aug 18 18:10:29.969: INFO: Waiting up to 5m0s for pod "pod-secrets-7725ebf4-42e9-4e05-9ee6-c0449e384b57" in namespace "secrets-6456" to be "success or failure"
Aug 18 18:10:29.984: INFO: Pod "pod-secrets-7725ebf4-42e9-4e05-9ee6-c0449e384b57": Phase="Pending", Reason="", readiness=false. Elapsed: 15.037692ms
Aug 18 18:10:31.996: INFO: Pod "pod-secrets-7725ebf4-42e9-4e05-9ee6-c0449e384b57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026720489s
STEP: Saw pod success
Aug 18 18:10:31.996: INFO: Pod "pod-secrets-7725ebf4-42e9-4e05-9ee6-c0449e384b57" satisfied condition "success or failure"
Aug 18 18:10:32.007: INFO: Trying to get logs from node 10.241.69.172 pod pod-secrets-7725ebf4-42e9-4e05-9ee6-c0449e384b57 container secret-volume-test: <nil>
STEP: delete the pod
Aug 18 18:10:32.074: INFO: Waiting for pod pod-secrets-7725ebf4-42e9-4e05-9ee6-c0449e384b57 to disappear
Aug 18 18:10:32.090: INFO: Pod pod-secrets-7725ebf4-42e9-4e05-9ee6-c0449e384b57 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:10:32.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6456" for this suite.
Aug 18 18:10:38.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:10:38.612: INFO: namespace secrets-6456 deletion completed in 6.49350365s

• [SLOW TEST:8.906 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:10:38.614: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5045
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Aug 18 18:10:38.910: INFO: namespace kubectl-5045
Aug 18 18:10:38.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 create -f - --namespace=kubectl-5045'
Aug 18 18:10:39.189: INFO: stderr: ""
Aug 18 18:10:39.189: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 18 18:10:40.201: INFO: Selector matched 1 pods for map[app:redis]
Aug 18 18:10:40.201: INFO: Found 0 / 1
Aug 18 18:10:41.201: INFO: Selector matched 1 pods for map[app:redis]
Aug 18 18:10:41.201: INFO: Found 1 / 1
Aug 18 18:10:41.201: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 18 18:10:41.212: INFO: Selector matched 1 pods for map[app:redis]
Aug 18 18:10:41.212: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 18 18:10:41.212: INFO: wait on redis-master startup in kubectl-5045 
Aug 18 18:10:41.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 logs redis-master-dhjbn redis-master --namespace=kubectl-5045'
Aug 18 18:10:41.384: INFO: stderr: ""
Aug 18 18:10:41.384: INFO: stdout: "1:C 18 Aug 2020 18:10:40.481 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 18 Aug 2020 18:10:40.481 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 18 Aug 2020 18:10:40.481 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 18 Aug 2020 18:10:40.483 * Running mode=standalone, port=6379.\n1:M 18 Aug 2020 18:10:40.483 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Aug 2020 18:10:40.483 # Server initialized\n1:M 18 Aug 2020 18:10:40.483 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Aug 2020 18:10:40.483 * Ready to accept connections\n"
STEP: exposing RC
Aug 18 18:10:41.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5045'
Aug 18 18:10:41.539: INFO: stderr: ""
Aug 18 18:10:41.539: INFO: stdout: "service/rm2 exposed\n"
Aug 18 18:10:41.553: INFO: Service rm2 in namespace kubectl-5045 found.
STEP: exposing service
Aug 18 18:10:43.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5045'
Aug 18 18:10:43.744: INFO: stderr: ""
Aug 18 18:10:43.744: INFO: stdout: "service/rm3 exposed\n"
Aug 18 18:10:43.759: INFO: Service rm3 in namespace kubectl-5045 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:10:45.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5045" for this suite.
Aug 18 18:10:57.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:10:58.324: INFO: namespace kubectl-5045 deletion completed in 12.511297146s

• [SLOW TEST:19.711 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:10:58.325: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2830
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0818 18:11:04.662092      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 18 18:11:04.662: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:11:04.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2830" for this suite.
Aug 18 18:11:12.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:11:13.163: INFO: namespace gc-2830 deletion completed in 8.481263127s

• [SLOW TEST:14.839 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:11:13.165: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6357
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:11:37.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6357" for this suite.
Aug 18 18:11:45.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:11:45.614: INFO: namespace container-runtime-6357 deletion completed in 8.477784352s

• [SLOW TEST:32.450 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:11:45.615: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2808
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2808.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2808.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2808.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2808.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2808.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2808.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 18 18:11:50.090: INFO: DNS probes using dns-2808/dns-test-d1f97547-1d03-4624-90df-4a3f977faedf succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:11:50.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2808" for this suite.
Aug 18 18:11:58.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:11:58.604: INFO: namespace dns-2808 deletion completed in 8.451567949s

• [SLOW TEST:12.990 seconds]
[sig-network] DNS
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:11:58.604: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1231
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Aug 18 18:11:58.831: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:12:21.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1231" for this suite.
Aug 18 18:12:27.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:12:27.540: INFO: namespace crd-publish-openapi-1231 deletion completed in 6.4780726s

• [SLOW TEST:28.936 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:12:27.541: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9088
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9088
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-9088
Aug 18 18:12:27.794: INFO: Found 0 stateful pods, waiting for 1
Aug 18 18:12:37.808: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Aug 18 18:12:37.869: INFO: Deleting all statefulset in ns statefulset-9088
Aug 18 18:12:37.880: INFO: Scaling statefulset ss to 0
Aug 18 18:12:57.938: INFO: Waiting for statefulset status.replicas updated to 0
Aug 18 18:12:57.952: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:12:58.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9088" for this suite.
Aug 18 18:13:06.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:13:06.553: INFO: namespace statefulset-9088 deletion completed in 8.512384353s

• [SLOW TEST:39.013 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:13:06.554: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5806
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Aug 18 18:13:06.791: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:13:27.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5806" for this suite.
Aug 18 18:13:33.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:13:34.225: INFO: namespace crd-publish-openapi-5806 deletion completed in 6.510879209s

• [SLOW TEST:27.671 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:13:34.228: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6185
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 18 18:13:34.510: INFO: Waiting up to 5m0s for pod "pod-3610e40e-2506-468c-9571-2a565dfbe4a9" in namespace "emptydir-6185" to be "success or failure"
Aug 18 18:13:34.523: INFO: Pod "pod-3610e40e-2506-468c-9571-2a565dfbe4a9": Phase="Pending", Reason="", readiness=false. Elapsed: 13.454878ms
Aug 18 18:13:36.535: INFO: Pod "pod-3610e40e-2506-468c-9571-2a565dfbe4a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025349849s
STEP: Saw pod success
Aug 18 18:13:36.535: INFO: Pod "pod-3610e40e-2506-468c-9571-2a565dfbe4a9" satisfied condition "success or failure"
Aug 18 18:13:36.547: INFO: Trying to get logs from node 10.241.69.172 pod pod-3610e40e-2506-468c-9571-2a565dfbe4a9 container test-container: <nil>
STEP: delete the pod
Aug 18 18:13:36.642: INFO: Waiting for pod pod-3610e40e-2506-468c-9571-2a565dfbe4a9 to disappear
Aug 18 18:13:36.656: INFO: Pod pod-3610e40e-2506-468c-9571-2a565dfbe4a9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:13:36.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6185" for this suite.
Aug 18 18:13:42.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:13:43.130: INFO: namespace emptydir-6185 deletion completed in 6.455289278s

• [SLOW TEST:8.902 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:13:43.132: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-347
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:13:43.362: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Aug 18 18:13:47.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-347 create -f -'
Aug 18 18:13:47.823: INFO: stderr: ""
Aug 18 18:13:47.823: INFO: stdout: "e2e-test-crd-publish-openapi-5906-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Aug 18 18:13:47.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-347 delete e2e-test-crd-publish-openapi-5906-crds test-foo'
Aug 18 18:13:47.950: INFO: stderr: ""
Aug 18 18:13:47.950: INFO: stdout: "e2e-test-crd-publish-openapi-5906-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Aug 18 18:13:47.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-347 apply -f -'
Aug 18 18:13:48.419: INFO: stderr: ""
Aug 18 18:13:48.419: INFO: stdout: "e2e-test-crd-publish-openapi-5906-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Aug 18 18:13:48.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-347 delete e2e-test-crd-publish-openapi-5906-crds test-foo'
Aug 18 18:13:48.537: INFO: stderr: ""
Aug 18 18:13:48.537: INFO: stdout: "e2e-test-crd-publish-openapi-5906-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Aug 18 18:13:48.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-347 create -f -'
Aug 18 18:13:48.817: INFO: rc: 1
Aug 18 18:13:48.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-347 apply -f -'
Aug 18 18:13:49.104: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Aug 18 18:13:49.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-347 create -f -'
Aug 18 18:13:49.411: INFO: rc: 1
Aug 18 18:13:49.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-347 apply -f -'
Aug 18 18:13:49.732: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Aug 18 18:13:49.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 explain e2e-test-crd-publish-openapi-5906-crds'
Aug 18 18:13:50.043: INFO: stderr: ""
Aug 18 18:13:50.043: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5906-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Aug 18 18:13:50.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 explain e2e-test-crd-publish-openapi-5906-crds.metadata'
Aug 18 18:13:50.349: INFO: stderr: ""
Aug 18 18:13:50.349: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5906-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Aug 18 18:13:50.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 explain e2e-test-crd-publish-openapi-5906-crds.spec'
Aug 18 18:13:50.680: INFO: stderr: ""
Aug 18 18:13:50.680: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5906-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Aug 18 18:13:50.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 explain e2e-test-crd-publish-openapi-5906-crds.spec.bars'
Aug 18 18:13:50.964: INFO: stderr: ""
Aug 18 18:13:50.964: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5906-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Aug 18 18:13:50.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 explain e2e-test-crd-publish-openapi-5906-crds.spec.bars2'
Aug 18 18:13:51.294: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:13:55.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-347" for this suite.
Aug 18 18:14:01.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:14:01.667: INFO: namespace crd-publish-openapi-347 deletion completed in 6.456896655s

• [SLOW TEST:18.535 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:14:01.668: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5462
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 18:14:02.515: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 18 18:14:04.554: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733371242, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733371242, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733371242, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733371242, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 18:14:07.601: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:14:08.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5462" for this suite.
Aug 18 18:14:16.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:14:16.902: INFO: namespace webhook-5462 deletion completed in 8.704262649s
STEP: Destroying namespace "webhook-5462-markers" for this suite.
Aug 18 18:14:22.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:14:23.376: INFO: namespace webhook-5462-markers deletion completed in 6.473574005s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.771 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:14:23.440: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6780
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 18:14:23.697: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9191b69f-971a-4cb1-81e6-06bca648900a" in namespace "projected-6780" to be "success or failure"
Aug 18 18:14:23.714: INFO: Pod "downwardapi-volume-9191b69f-971a-4cb1-81e6-06bca648900a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.575334ms
Aug 18 18:14:25.726: INFO: Pod "downwardapi-volume-9191b69f-971a-4cb1-81e6-06bca648900a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028129994s
STEP: Saw pod success
Aug 18 18:14:25.726: INFO: Pod "downwardapi-volume-9191b69f-971a-4cb1-81e6-06bca648900a" satisfied condition "success or failure"
Aug 18 18:14:25.736: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-9191b69f-971a-4cb1-81e6-06bca648900a container client-container: <nil>
STEP: delete the pod
Aug 18 18:14:25.796: INFO: Waiting for pod downwardapi-volume-9191b69f-971a-4cb1-81e6-06bca648900a to disappear
Aug 18 18:14:25.807: INFO: Pod downwardapi-volume-9191b69f-971a-4cb1-81e6-06bca648900a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:14:25.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6780" for this suite.
Aug 18 18:14:31.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:14:32.310: INFO: namespace projected-6780 deletion completed in 6.484303318s

• [SLOW TEST:8.870 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:14:32.310: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-782
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 18:14:33.351: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 18 18:14:35.393: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733371273, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733371273, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733371273, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733371273, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 18:14:38.446: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:14:38.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-782" for this suite.
Aug 18 18:14:44.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:14:45.037: INFO: namespace webhook-782 deletion completed in 6.437006826s
STEP: Destroying namespace "webhook-782-markers" for this suite.
Aug 18 18:14:51.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:14:51.469: INFO: namespace webhook-782-markers deletion completed in 6.431155879s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.218 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:14:51.528: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8629
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-8629
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8629 to expose endpoints map[]
Aug 18 18:14:51.791: INFO: successfully validated that service endpoint-test2 in namespace services-8629 exposes endpoints map[] (10.549274ms elapsed)
STEP: Creating pod pod1 in namespace services-8629
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8629 to expose endpoints map[pod1:[80]]
Aug 18 18:14:53.877: INFO: successfully validated that service endpoint-test2 in namespace services-8629 exposes endpoints map[pod1:[80]] (2.063580463s elapsed)
STEP: Creating pod pod2 in namespace services-8629
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8629 to expose endpoints map[pod1:[80] pod2:[80]]
Aug 18 18:14:55.997: INFO: successfully validated that service endpoint-test2 in namespace services-8629 exposes endpoints map[pod1:[80] pod2:[80]] (2.105489444s elapsed)
STEP: Deleting pod pod1 in namespace services-8629
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8629 to expose endpoints map[pod2:[80]]
Aug 18 18:14:56.040: INFO: successfully validated that service endpoint-test2 in namespace services-8629 exposes endpoints map[pod2:[80]] (23.774027ms elapsed)
STEP: Deleting pod pod2 in namespace services-8629
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8629 to expose endpoints map[]
Aug 18 18:14:56.069: INFO: successfully validated that service endpoint-test2 in namespace services-8629 exposes endpoints map[] (9.923411ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:14:56.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8629" for this suite.
Aug 18 18:15:04.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:15:04.600: INFO: namespace services-8629 deletion completed in 8.444911597s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.071 seconds]
[sig-network] Services
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:15:04.600: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-30
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-83d55ce5-94ce-48a2-bee6-58ceddafb9d1 in namespace container-probe-30
Aug 18 18:15:06.876: INFO: Started pod liveness-83d55ce5-94ce-48a2-bee6-58ceddafb9d1 in namespace container-probe-30
STEP: checking the pod's current state and verifying that restartCount is present
Aug 18 18:15:06.889: INFO: Initial restart count of pod liveness-83d55ce5-94ce-48a2-bee6-58ceddafb9d1 is 0
Aug 18 18:15:25.008: INFO: Restart count of pod container-probe-30/liveness-83d55ce5-94ce-48a2-bee6-58ceddafb9d1 is now 1 (18.118698184s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:15:25.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-30" for this suite.
Aug 18 18:15:31.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:15:31.550: INFO: namespace container-probe-30 deletion completed in 6.482479087s

• [SLOW TEST:26.950 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:15:31.551: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4647
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:15:44.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4647" for this suite.
Aug 18 18:15:51.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:15:51.479: INFO: namespace resourcequota-4647 deletion completed in 6.485163757s

• [SLOW TEST:19.928 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:15:51.480: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8345
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-8345, will wait for the garbage collector to delete the pods
Aug 18 18:15:53.856: INFO: Deleting Job.batch foo took: 38.720454ms
Aug 18 18:15:54.057: INFO: Terminating Job.batch foo pods took: 200.389851ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:16:30.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8345" for this suite.
Aug 18 18:16:38.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:16:38.917: INFO: namespace job-8345 deletion completed in 8.51328712s

• [SLOW TEST:47.437 seconds]
[sig-apps] Job
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:16:38.917: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-448
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-cad12484-f540-4c20-8103-a7483965e589
STEP: Creating a pod to test consume configMaps
Aug 18 18:16:39.181: INFO: Waiting up to 5m0s for pod "pod-configmaps-2b20573a-4187-4d94-9e01-6445032a5ac8" in namespace "configmap-448" to be "success or failure"
Aug 18 18:16:39.193: INFO: Pod "pod-configmaps-2b20573a-4187-4d94-9e01-6445032a5ac8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.758236ms
Aug 18 18:16:41.205: INFO: Pod "pod-configmaps-2b20573a-4187-4d94-9e01-6445032a5ac8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023814081s
STEP: Saw pod success
Aug 18 18:16:41.205: INFO: Pod "pod-configmaps-2b20573a-4187-4d94-9e01-6445032a5ac8" satisfied condition "success or failure"
Aug 18 18:16:41.215: INFO: Trying to get logs from node 10.241.69.172 pod pod-configmaps-2b20573a-4187-4d94-9e01-6445032a5ac8 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 18 18:16:41.303: INFO: Waiting for pod pod-configmaps-2b20573a-4187-4d94-9e01-6445032a5ac8 to disappear
Aug 18 18:16:41.313: INFO: Pod pod-configmaps-2b20573a-4187-4d94-9e01-6445032a5ac8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:16:41.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-448" for this suite.
Aug 18 18:16:47.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:16:47.786: INFO: namespace configmap-448 deletion completed in 6.439840059s

• [SLOW TEST:8.869 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:16:47.787: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7946
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Aug 18 18:16:48.008: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 18 18:16:48.068: INFO: Waiting for terminating namespaces to be deleted...
Aug 18 18:16:48.079: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.172 before test
Aug 18 18:16:48.120: INFO: ibm-keepalived-watcher-2f6fp from kube-system started at 2020-08-18 15:45:12 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.120: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 18:16:48.120: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-m29th from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 18:16:48.121: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 18 18:16:48.121: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 18:16:48.121: INFO: ibm-master-proxy-static-10.241.69.172 from kube-system started at 2020-08-18 15:45:10 +0000 UTC (2 container statuses recorded)
Aug 18 18:16:48.121: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 18:16:48.121: INFO: 	Container pause ready: true, restart count 0
Aug 18 18:16:48.121: INFO: calico-node-sz9mb from kube-system started at 2020-08-18 15:45:12 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.121: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 18:16:48.121: INFO: addon-catalog-source-gmd49 from ibm-system started at 2020-08-18 15:45:49 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.121: INFO: 	Container configmap-registry-server ready: true, restart count 0
Aug 18 18:16:48.121: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.181 before test
Aug 18 18:16:48.210: INFO: ibm-master-proxy-static-10.241.69.181 from kube-system started at 2020-08-18 15:49:51 +0000 UTC (2 container statuses recorded)
Aug 18 18:16:48.210: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 18:16:48.210: INFO: 	Container pause ready: true, restart count 0
Aug 18 18:16:48.211: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-08-18 15:52:42 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.211: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Aug 18 18:16:48.211: INFO: coredns-autoscaler-65c89858bf-q6hj7 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.211: INFO: 	Container autoscaler ready: true, restart count 0
Aug 18 18:16:48.211: INFO: dashboard-metrics-scraper-76756886dc-rk2k2 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.211: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Aug 18 18:16:48.212: INFO: ibm-cloud-provider-ip-169-47-71-114-64b8d74dd8-8brdn from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.212: INFO: 	Container ibm-cloud-provider-ip-169-47-71-114 ready: true, restart count 0
Aug 18 18:16:48.212: INFO: ibm-keepalived-watcher-kr9tn from kube-system started at 2020-08-18 15:50:03 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.212: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 18:16:48.212: INFO: olm-operator-6f74dfc868-28t4m from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.212: INFO: 	Container olm-operator ready: true, restart count 0
Aug 18 18:16:48.212: INFO: coredns-55db5d97fb-8tfqf from kube-system started at 2020-08-18 15:57:41 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.213: INFO: 	Container coredns ready: true, restart count 0
Aug 18 18:16:48.213: INFO: sonobuoy-e2e-job-692caab668c14a3b from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 18:16:48.213: INFO: 	Container e2e ready: true, restart count 0
Aug 18 18:16:48.213: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 18 18:16:48.213: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-rwtzr from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 18:16:48.213: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 18 18:16:48.214: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 18:16:48.214: INFO: calico-node-vn5q9 from kube-system started at 2020-08-18 15:50:03 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.214: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 18:16:48.214: INFO: sonobuoy from sonobuoy started at 2020-08-18 17:08:11 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.214: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 18 18:16:48.214: INFO: kubernetes-dashboard-85b945ff4b-9cklr from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.214: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 18 18:16:48.214: INFO: public-crbstv5sqd0r3kmi9abm0g-alb1-5f59ffb4c7-4k6xv from kube-system started at 2020-08-18 17:21:45 +0000 UTC (4 container statuses recorded)
Aug 18 18:16:48.214: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 18 18:16:48.215: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 18 18:16:48.215: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 18 18:16:48.215: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 18 18:16:48.215: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.184 before test
Aug 18 18:16:48.292: INFO: coredns-55db5d97fb-2h7nb from kube-system started at 2020-08-18 15:57:41 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.292: INFO: 	Container coredns ready: true, restart count 0
Aug 18 18:16:48.292: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-ctchp from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 18:16:48.292: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 18 18:16:48.292: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 18:16:48.292: INFO: ibm-storage-watcher-5685787df4-w25gd from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.292: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug 18 18:16:48.292: INFO: ibm-master-proxy-static-10.241.69.184 from kube-system started at 2020-08-18 15:46:23 +0000 UTC (2 container statuses recorded)
Aug 18 18:16:48.292: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 18:16:48.292: INFO: 	Container pause ready: true, restart count 0
Aug 18 18:16:48.292: INFO: calico-node-f56nz from kube-system started at 2020-08-18 15:46:36 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.292: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 18:16:48.292: INFO: calico-kube-controllers-66c5f69b5f-9qvwh from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.293: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 18 18:16:48.293: INFO: catalog-operator-67cbc5d959-hqgh5 from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.293: INFO: 	Container catalog-operator ready: true, restart count 0
Aug 18 18:16:48.293: INFO: ibm-keepalived-watcher-xt8rx from kube-system started at 2020-08-18 15:46:36 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.293: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 18:16:48.293: INFO: public-crbstv5sqd0r3kmi9abm0g-alb1-5f59ffb4c7-s8vcr from kube-system started at 2020-08-18 15:48:16 +0000 UTC (4 container statuses recorded)
Aug 18 18:16:48.293: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 18 18:16:48.293: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 18 18:16:48.293: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 18 18:16:48.293: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 18 18:16:48.293: INFO: ibm-file-plugin-7c6788b5f5-ldfzf from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.293: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug 18 18:16:48.293: INFO: coredns-55db5d97fb-cqx5b from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.293: INFO: 	Container coredns ready: true, restart count 0
Aug 18 18:16:48.293: INFO: ibm-cloud-provider-ip-169-47-71-114-64b8d74dd8-dc47l from ibm-system started at 2020-08-18 15:46:51 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.293: INFO: 	Container ibm-cloud-provider-ip-169-47-71-114 ready: true, restart count 0
Aug 18 18:16:48.293: INFO: vpn-79845b6f9d-wmz87 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:16:48.293: INFO: 	Container vpn ready: true, restart count 0
Aug 18 18:16:48.293: INFO: metrics-server-695ffd979-8z2wt from kube-system started at 2020-08-18 17:21:45 +0000 UTC (2 container statuses recorded)
Aug 18 18:16:48.293: INFO: 	Container metrics-server ready: true, restart count 0
Aug 18 18:16:48.293: INFO: 	Container metrics-server-nanny ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.162c6f8a7b25e46f], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:16:49.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7946" for this suite.
Aug 18 18:16:55.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:16:55.855: INFO: namespace sched-pred-7946 deletion completed in 6.456943654s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:8.068 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:16:55.856: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8038
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Aug 18 18:16:56.099: INFO: Waiting up to 5m0s for pod "downward-api-75b032d0-1e22-43f5-8e10-d6ad30082651" in namespace "downward-api-8038" to be "success or failure"
Aug 18 18:16:56.110: INFO: Pod "downward-api-75b032d0-1e22-43f5-8e10-d6ad30082651": Phase="Pending", Reason="", readiness=false. Elapsed: 10.445706ms
Aug 18 18:16:58.122: INFO: Pod "downward-api-75b032d0-1e22-43f5-8e10-d6ad30082651": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022715916s
STEP: Saw pod success
Aug 18 18:16:58.122: INFO: Pod "downward-api-75b032d0-1e22-43f5-8e10-d6ad30082651" satisfied condition "success or failure"
Aug 18 18:16:58.133: INFO: Trying to get logs from node 10.241.69.172 pod downward-api-75b032d0-1e22-43f5-8e10-d6ad30082651 container dapi-container: <nil>
STEP: delete the pod
Aug 18 18:16:58.199: INFO: Waiting for pod downward-api-75b032d0-1e22-43f5-8e10-d6ad30082651 to disappear
Aug 18 18:16:58.209: INFO: Pod downward-api-75b032d0-1e22-43f5-8e10-d6ad30082651 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:16:58.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8038" for this suite.
Aug 18 18:17:04.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:17:04.666: INFO: namespace downward-api-8038 deletion completed in 6.436177628s

• [SLOW TEST:8.810 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:17:04.666: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5550
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 18 18:17:04.902: INFO: Waiting up to 5m0s for pod "pod-0a4d3a9b-08e1-4e22-a603-46aae929dd85" in namespace "emptydir-5550" to be "success or failure"
Aug 18 18:17:04.914: INFO: Pod "pod-0a4d3a9b-08e1-4e22-a603-46aae929dd85": Phase="Pending", Reason="", readiness=false. Elapsed: 11.462164ms
Aug 18 18:17:06.926: INFO: Pod "pod-0a4d3a9b-08e1-4e22-a603-46aae929dd85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023400067s
STEP: Saw pod success
Aug 18 18:17:06.926: INFO: Pod "pod-0a4d3a9b-08e1-4e22-a603-46aae929dd85" satisfied condition "success or failure"
Aug 18 18:17:06.938: INFO: Trying to get logs from node 10.241.69.172 pod pod-0a4d3a9b-08e1-4e22-a603-46aae929dd85 container test-container: <nil>
STEP: delete the pod
Aug 18 18:17:06.999: INFO: Waiting for pod pod-0a4d3a9b-08e1-4e22-a603-46aae929dd85 to disappear
Aug 18 18:17:07.009: INFO: Pod pod-0a4d3a9b-08e1-4e22-a603-46aae929dd85 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:17:07.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5550" for this suite.
Aug 18 18:17:13.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:17:13.469: INFO: namespace emptydir-5550 deletion completed in 6.444063761s

• [SLOW TEST:8.803 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:17:13.469: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-6692
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Aug 18 18:17:14.474: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 18:17:17.556: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:17:17.566: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:17:18.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6692" for this suite.
Aug 18 18:17:26.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:17:27.146: INFO: namespace crd-webhook-6692 deletion completed in 8.505163237s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.744 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:17:27.213: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4144
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 18 18:17:27.450: INFO: Waiting up to 5m0s for pod "pod-be475651-5b4d-476c-a14d-9222835bbec0" in namespace "emptydir-4144" to be "success or failure"
Aug 18 18:17:27.461: INFO: Pod "pod-be475651-5b4d-476c-a14d-9222835bbec0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.18088ms
Aug 18 18:17:29.473: INFO: Pod "pod-be475651-5b4d-476c-a14d-9222835bbec0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023192165s
STEP: Saw pod success
Aug 18 18:17:29.473: INFO: Pod "pod-be475651-5b4d-476c-a14d-9222835bbec0" satisfied condition "success or failure"
Aug 18 18:17:29.488: INFO: Trying to get logs from node 10.241.69.172 pod pod-be475651-5b4d-476c-a14d-9222835bbec0 container test-container: <nil>
STEP: delete the pod
Aug 18 18:17:29.548: INFO: Waiting for pod pod-be475651-5b4d-476c-a14d-9222835bbec0 to disappear
Aug 18 18:17:29.561: INFO: Pod pod-be475651-5b4d-476c-a14d-9222835bbec0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:17:29.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4144" for this suite.
Aug 18 18:17:35.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:17:36.074: INFO: namespace emptydir-4144 deletion completed in 6.493020154s

• [SLOW TEST:8.861 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:17:36.075: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9281
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-9281
STEP: creating replication controller nodeport-test in namespace services-9281
I0818 18:17:36.368328      23 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-9281, replica count: 2
Aug 18 18:17:39.419: INFO: Creating new exec pod
I0818 18:17:39.418989      23 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 18 18:17:42.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-9281 execpodk5z2l -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Aug 18 18:17:42.809: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Aug 18 18:17:42.810: INFO: stdout: ""
Aug 18 18:17:42.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-9281 execpodk5z2l -- /bin/sh -x -c nc -zv -t -w 2 172.21.29.42 80'
Aug 18 18:17:43.137: INFO: stderr: "+ nc -zv -t -w 2 172.21.29.42 80\nConnection to 172.21.29.42 80 port [tcp/http] succeeded!\n"
Aug 18 18:17:43.137: INFO: stdout: ""
Aug 18 18:17:43.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-9281 execpodk5z2l -- /bin/sh -x -c nc -zv -t -w 2 10.241.69.172 30505'
Aug 18 18:17:43.443: INFO: stderr: "+ nc -zv -t -w 2 10.241.69.172 30505\nConnection to 10.241.69.172 30505 port [tcp/30505] succeeded!\n"
Aug 18 18:17:43.443: INFO: stdout: ""
Aug 18 18:17:43.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-9281 execpodk5z2l -- /bin/sh -x -c nc -zv -t -w 2 10.241.69.181 30505'
Aug 18 18:17:43.742: INFO: stderr: "+ nc -zv -t -w 2 10.241.69.181 30505\nConnection to 10.241.69.181 30505 port [tcp/30505] succeeded!\n"
Aug 18 18:17:43.742: INFO: stdout: ""
Aug 18 18:17:43.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-9281 execpodk5z2l -- /bin/sh -x -c nc -zv -t -w 2 169.59.196.52 30505'
Aug 18 18:17:44.048: INFO: stderr: "+ nc -zv -t -w 2 169.59.196.52 30505\nConnection to 169.59.196.52 30505 port [tcp/30505] succeeded!\n"
Aug 18 18:17:44.048: INFO: stdout: ""
Aug 18 18:17:44.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-9281 execpodk5z2l -- /bin/sh -x -c nc -zv -t -w 2 169.59.196.53 30505'
Aug 18 18:17:44.313: INFO: stderr: "+ nc -zv -t -w 2 169.59.196.53 30505\nConnection to 169.59.196.53 30505 port [tcp/30505] succeeded!\n"
Aug 18 18:17:44.313: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:17:44.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9281" for this suite.
Aug 18 18:17:52.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:17:52.807: INFO: namespace services-9281 deletion completed in 8.473368919s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.732 seconds]
[sig-network] Services
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:17:52.807: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-2667
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug 18 18:17:56.201: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:17:56.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2667" for this suite.
Aug 18 18:18:26.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:18:26.721: INFO: namespace replicaset-2667 deletion completed in 30.464491588s

• [SLOW TEST:33.914 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:18:26.722: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5628
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Aug 18 18:18:26.985: INFO: Waiting up to 5m0s for pod "downward-api-f55d0173-6d58-4ac7-b7fc-8b95551c0898" in namespace "downward-api-5628" to be "success or failure"
Aug 18 18:18:27.002: INFO: Pod "downward-api-f55d0173-6d58-4ac7-b7fc-8b95551c0898": Phase="Pending", Reason="", readiness=false. Elapsed: 17.161499ms
Aug 18 18:18:29.014: INFO: Pod "downward-api-f55d0173-6d58-4ac7-b7fc-8b95551c0898": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028755671s
STEP: Saw pod success
Aug 18 18:18:29.014: INFO: Pod "downward-api-f55d0173-6d58-4ac7-b7fc-8b95551c0898" satisfied condition "success or failure"
Aug 18 18:18:29.025: INFO: Trying to get logs from node 10.241.69.172 pod downward-api-f55d0173-6d58-4ac7-b7fc-8b95551c0898 container dapi-container: <nil>
STEP: delete the pod
Aug 18 18:18:29.089: INFO: Waiting for pod downward-api-f55d0173-6d58-4ac7-b7fc-8b95551c0898 to disappear
Aug 18 18:18:29.106: INFO: Pod downward-api-f55d0173-6d58-4ac7-b7fc-8b95551c0898 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:18:29.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5628" for this suite.
Aug 18 18:18:35.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:18:35.569: INFO: namespace downward-api-5628 deletion completed in 6.441210626s

• [SLOW TEST:8.847 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:18:35.570: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4169
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4169
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Aug 18 18:18:35.829: INFO: Found 0 stateful pods, waiting for 3
Aug 18 18:18:45.842: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 18 18:18:45.842: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 18 18:18:45.842: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Aug 18 18:18:45.907: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 18 18:18:55.985: INFO: Updating stateful set ss2
Aug 18 18:18:56.006: INFO: Waiting for Pod statefulset-4169/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Aug 18 18:19:06.119: INFO: Found 2 stateful pods, waiting for 3
Aug 18 18:19:16.132: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 18 18:19:16.132: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 18 18:19:16.132: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 18 18:19:16.190: INFO: Updating stateful set ss2
Aug 18 18:19:16.212: INFO: Waiting for Pod statefulset-4169/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Aug 18 18:19:26.267: INFO: Updating stateful set ss2
Aug 18 18:19:26.289: INFO: Waiting for StatefulSet statefulset-4169/ss2 to complete update
Aug 18 18:19:26.289: INFO: Waiting for Pod statefulset-4169/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Aug 18 18:19:36.311: INFO: Deleting all statefulset in ns statefulset-4169
Aug 18 18:19:36.321: INFO: Scaling statefulset ss2 to 0
Aug 18 18:19:56.369: INFO: Waiting for statefulset status.replicas updated to 0
Aug 18 18:19:56.380: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:19:56.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4169" for this suite.
Aug 18 18:20:04.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:20:04.913: INFO: namespace statefulset-4169 deletion completed in 8.462354028s

• [SLOW TEST:89.343 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:20:04.914: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3277
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-c584e922-0570-497c-9dcd-7fce30f700ba
STEP: Creating configMap with name cm-test-opt-upd-308b2c30-53ef-4104-b502-65ce17e8e1ba
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c584e922-0570-497c-9dcd-7fce30f700ba
STEP: Updating configmap cm-test-opt-upd-308b2c30-53ef-4104-b502-65ce17e8e1ba
STEP: Creating configMap with name cm-test-opt-create-d6155e55-7619-4ee9-b38f-015dacd4feac
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:21:36.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3277" for this suite.
Aug 18 18:22:06.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:22:07.373: INFO: namespace configmap-3277 deletion completed in 30.501239626s

• [SLOW TEST:122.459 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:22:07.374: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4962
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:22:07.628: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-b1de900e-2f71-4b87-ade2-f3e069f467c4" in namespace "security-context-test-4962" to be "success or failure"
Aug 18 18:22:07.642: INFO: Pod "busybox-privileged-false-b1de900e-2f71-4b87-ade2-f3e069f467c4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.123171ms
Aug 18 18:22:09.653: INFO: Pod "busybox-privileged-false-b1de900e-2f71-4b87-ade2-f3e069f467c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025084974s
Aug 18 18:22:09.653: INFO: Pod "busybox-privileged-false-b1de900e-2f71-4b87-ade2-f3e069f467c4" satisfied condition "success or failure"
Aug 18 18:22:09.679: INFO: Got logs for pod "busybox-privileged-false-b1de900e-2f71-4b87-ade2-f3e069f467c4": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:22:09.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4962" for this suite.
Aug 18 18:22:15.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:22:16.146: INFO: namespace security-context-test-4962 deletion completed in 6.445639915s

• [SLOW TEST:8.772 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:22:16.146: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-467
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Aug 18 18:22:16.366: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug 18 18:22:16.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 create -f - --namespace=kubectl-467'
Aug 18 18:22:17.734: INFO: stderr: ""
Aug 18 18:22:17.734: INFO: stdout: "service/redis-slave created\n"
Aug 18 18:22:17.735: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug 18 18:22:17.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 create -f - --namespace=kubectl-467'
Aug 18 18:22:18.057: INFO: stderr: ""
Aug 18 18:22:18.057: INFO: stdout: "service/redis-master created\n"
Aug 18 18:22:18.057: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 18 18:22:18.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 create -f - --namespace=kubectl-467'
Aug 18 18:22:18.274: INFO: stderr: ""
Aug 18 18:22:18.274: INFO: stdout: "service/frontend created\n"
Aug 18 18:22:18.275: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug 18 18:22:18.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 create -f - --namespace=kubectl-467'
Aug 18 18:22:18.634: INFO: stderr: ""
Aug 18 18:22:18.634: INFO: stdout: "deployment.apps/frontend created\n"
Aug 18 18:22:18.634: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 18 18:22:18.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 create -f - --namespace=kubectl-467'
Aug 18 18:22:18.969: INFO: stderr: ""
Aug 18 18:22:18.969: INFO: stdout: "deployment.apps/redis-master created\n"
Aug 18 18:22:18.969: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug 18 18:22:18.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 create -f - --namespace=kubectl-467'
Aug 18 18:22:19.264: INFO: stderr: ""
Aug 18 18:22:19.264: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Aug 18 18:22:19.264: INFO: Waiting for all frontend pods to be Running.
Aug 18 18:22:34.315: INFO: Waiting for frontend to serve content.
Aug 18 18:22:34.364: INFO: Trying to add a new entry to the guestbook.
Aug 18 18:22:34.402: INFO: Verifying that added entry can be retrieved.
Aug 18 18:22:34.435: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 18 18:22:39.496: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 18 18:22:44.541: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 18 18:22:49.584: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 18 18:22:54.637: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 18 18:22:59.691: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 18 18:23:04.732: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 18 18:23:09.780: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 18 18:23:14.824: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 18 18:23:19.864: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Aug 18 18:23:24.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete --grace-period=0 --force -f - --namespace=kubectl-467'
Aug 18 18:23:25.076: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 18 18:23:25.076: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug 18 18:23:25.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete --grace-period=0 --force -f - --namespace=kubectl-467'
Aug 18 18:23:25.297: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 18 18:23:25.297: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 18 18:23:25.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete --grace-period=0 --force -f - --namespace=kubectl-467'
Aug 18 18:23:25.468: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 18 18:23:25.468: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 18 18:23:25.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete --grace-period=0 --force -f - --namespace=kubectl-467'
Aug 18 18:23:25.619: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 18 18:23:25.619: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 18 18:23:25.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete --grace-period=0 --force -f - --namespace=kubectl-467'
Aug 18 18:23:25.766: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 18 18:23:25.766: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 18 18:23:25.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete --grace-period=0 --force -f - --namespace=kubectl-467'
Aug 18 18:23:25.899: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 18 18:23:25.899: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:23:25.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-467" for this suite.
Aug 18 18:23:55.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:23:56.378: INFO: namespace kubectl-467 deletion completed in 30.463739547s

• [SLOW TEST:100.232 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:23:56.378: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6886
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Aug 18 18:24:06.808: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0818 18:24:06.808744      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:24:06.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6886" for this suite.
Aug 18 18:24:14.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:24:15.303: INFO: namespace gc-6886 deletion completed in 8.477910936s

• [SLOW TEST:18.925 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:24:15.306: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8694
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:24:19.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8694" for this suite.
Aug 18 18:25:05.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:25:06.129: INFO: namespace kubelet-test-8694 deletion completed in 46.446556045s

• [SLOW TEST:50.823 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:25:06.129: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6235
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-bae97ba2-2ab1-4413-b1a4-1e4c51d9f6e4
STEP: Creating a pod to test consume secrets
Aug 18 18:25:06.390: INFO: Waiting up to 5m0s for pod "pod-secrets-13b31861-59e4-4c8a-b39b-630eeae7cfcf" in namespace "secrets-6235" to be "success or failure"
Aug 18 18:25:06.401: INFO: Pod "pod-secrets-13b31861-59e4-4c8a-b39b-630eeae7cfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.64154ms
Aug 18 18:25:08.414: INFO: Pod "pod-secrets-13b31861-59e4-4c8a-b39b-630eeae7cfcf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023589954s
STEP: Saw pod success
Aug 18 18:25:08.414: INFO: Pod "pod-secrets-13b31861-59e4-4c8a-b39b-630eeae7cfcf" satisfied condition "success or failure"
Aug 18 18:25:08.425: INFO: Trying to get logs from node 10.241.69.172 pod pod-secrets-13b31861-59e4-4c8a-b39b-630eeae7cfcf container secret-volume-test: <nil>
STEP: delete the pod
Aug 18 18:25:08.486: INFO: Waiting for pod pod-secrets-13b31861-59e4-4c8a-b39b-630eeae7cfcf to disappear
Aug 18 18:25:08.495: INFO: Pod pod-secrets-13b31861-59e4-4c8a-b39b-630eeae7cfcf no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:25:08.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6235" for this suite.
Aug 18 18:25:14.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:25:14.989: INFO: namespace secrets-6235 deletion completed in 6.474781321s

• [SLOW TEST:8.860 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:25:14.989: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6716
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-27a21ceb-70b1-4e6f-809c-faa5d8ddeb84 in namespace container-probe-6716
Aug 18 18:25:17.270: INFO: Started pod busybox-27a21ceb-70b1-4e6f-809c-faa5d8ddeb84 in namespace container-probe-6716
STEP: checking the pod's current state and verifying that restartCount is present
Aug 18 18:25:17.280: INFO: Initial restart count of pod busybox-27a21ceb-70b1-4e6f-809c-faa5d8ddeb84 is 0
Aug 18 18:26:09.623: INFO: Restart count of pod container-probe-6716/busybox-27a21ceb-70b1-4e6f-809c-faa5d8ddeb84 is now 1 (52.343035394s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:26:09.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6716" for this suite.
Aug 18 18:26:15.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:26:16.154: INFO: namespace container-probe-6716 deletion completed in 6.470779105s

• [SLOW TEST:61.165 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:26:16.154: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5352
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:26:27.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5352" for this suite.
Aug 18 18:26:33.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:26:33.981: INFO: namespace resourcequota-5352 deletion completed in 6.446871962s

• [SLOW TEST:17.826 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:26:33.981: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-803
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:26:34.209: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:26:36.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-803" for this suite.
Aug 18 18:27:22.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:27:22.880: INFO: namespace pods-803 deletion completed in 46.429204597s

• [SLOW TEST:48.899 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:27:22.881: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-521
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Aug 18 18:27:23.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-521'
Aug 18 18:27:23.345: INFO: stderr: ""
Aug 18 18:27:23.345: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Aug 18 18:27:23.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete pods e2e-test-httpd-pod --namespace=kubectl-521'
Aug 18 18:27:30.357: INFO: stderr: ""
Aug 18 18:27:30.357: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:27:30.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-521" for this suite.
Aug 18 18:27:36.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:27:36.840: INFO: namespace kubectl-521 deletion completed in 6.458035367s

• [SLOW TEST:13.959 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:27:36.840: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7816
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 18:27:37.825: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 18 18:27:39.864: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733372057, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733372057, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733372057, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733372057, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 18:27:42.922: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:27:43.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7816" for this suite.
Aug 18 18:28:13.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:28:13.506: INFO: namespace webhook-7816 deletion completed in 30.434328101s
STEP: Destroying namespace "webhook-7816-markers" for this suite.
Aug 18 18:28:19.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:28:19.989: INFO: namespace webhook-7816-markers deletion completed in 6.482748337s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:43.213 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:28:20.054: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4283
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 18:28:20.326: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d60ad154-8205-44aa-9554-e8295bdf5ea9" in namespace "projected-4283" to be "success or failure"
Aug 18 18:28:20.343: INFO: Pod "downwardapi-volume-d60ad154-8205-44aa-9554-e8295bdf5ea9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.957706ms
Aug 18 18:28:22.355: INFO: Pod "downwardapi-volume-d60ad154-8205-44aa-9554-e8295bdf5ea9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029246557s
STEP: Saw pod success
Aug 18 18:28:22.355: INFO: Pod "downwardapi-volume-d60ad154-8205-44aa-9554-e8295bdf5ea9" satisfied condition "success or failure"
Aug 18 18:28:22.366: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-d60ad154-8205-44aa-9554-e8295bdf5ea9 container client-container: <nil>
STEP: delete the pod
Aug 18 18:28:22.458: INFO: Waiting for pod downwardapi-volume-d60ad154-8205-44aa-9554-e8295bdf5ea9 to disappear
Aug 18 18:28:22.468: INFO: Pod downwardapi-volume-d60ad154-8205-44aa-9554-e8295bdf5ea9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:28:22.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4283" for this suite.
Aug 18 18:28:28.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:28:28.974: INFO: namespace projected-4283 deletion completed in 6.481491854s

• [SLOW TEST:8.921 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:28:28.975: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-223
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-r9csp in namespace proxy-223
I0818 18:28:29.240015      23 runners.go:184] Created replication controller with name: proxy-service-r9csp, namespace: proxy-223, replica count: 1
I0818 18:28:30.290533      23 runners.go:184] proxy-service-r9csp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0818 18:28:31.290774      23 runners.go:184] proxy-service-r9csp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0818 18:28:32.291040      23 runners.go:184] proxy-service-r9csp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0818 18:28:33.291303      23 runners.go:184] proxy-service-r9csp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0818 18:28:34.291603      23 runners.go:184] proxy-service-r9csp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0818 18:28:35.291945      23 runners.go:184] proxy-service-r9csp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0818 18:28:36.292244      23 runners.go:184] proxy-service-r9csp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0818 18:28:37.292534      23 runners.go:184] proxy-service-r9csp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0818 18:28:38.292805      23 runners.go:184] proxy-service-r9csp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0818 18:28:39.293105      23 runners.go:184] proxy-service-r9csp Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 18 18:28:39.306: INFO: setup took 10.115966844s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 18 18:28:39.333: INFO: (0) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 26.601263ms)
Aug 18 18:28:39.340: INFO: (0) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 33.628793ms)
Aug 18 18:28:39.340: INFO: (0) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 33.798583ms)
Aug 18 18:28:39.342: INFO: (0) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 35.550833ms)
Aug 18 18:28:39.342: INFO: (0) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 35.506136ms)
Aug 18 18:28:39.342: INFO: (0) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 36.135161ms)
Aug 18 18:28:39.342: INFO: (0) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 35.73506ms)
Aug 18 18:28:39.343: INFO: (0) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 36.332605ms)
Aug 18 18:28:39.343: INFO: (0) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 36.431551ms)
Aug 18 18:28:39.345: INFO: (0) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 38.170491ms)
Aug 18 18:28:39.347: INFO: (0) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 40.567821ms)
Aug 18 18:28:39.357: INFO: (0) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 50.581142ms)
Aug 18 18:28:39.357: INFO: (0) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 50.953287ms)
Aug 18 18:28:39.360: INFO: (0) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 52.827868ms)
Aug 18 18:28:39.360: INFO: (0) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 52.905225ms)
Aug 18 18:28:39.360: INFO: (0) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 52.84144ms)
Aug 18 18:28:39.379: INFO: (1) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 19.150011ms)
Aug 18 18:28:39.385: INFO: (1) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 24.750849ms)
Aug 18 18:28:39.385: INFO: (1) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 24.514037ms)
Aug 18 18:28:39.385: INFO: (1) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 24.299118ms)
Aug 18 18:28:39.385: INFO: (1) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 24.718227ms)
Aug 18 18:28:39.387: INFO: (1) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 26.628128ms)
Aug 18 18:28:39.387: INFO: (1) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 26.889319ms)
Aug 18 18:28:39.387: INFO: (1) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 26.763578ms)
Aug 18 18:28:39.387: INFO: (1) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 26.874824ms)
Aug 18 18:28:39.387: INFO: (1) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 26.769035ms)
Aug 18 18:28:39.388: INFO: (1) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 27.820695ms)
Aug 18 18:28:39.388: INFO: (1) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 27.881174ms)
Aug 18 18:28:39.388: INFO: (1) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 27.83194ms)
Aug 18 18:28:39.392: INFO: (1) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 32.314827ms)
Aug 18 18:28:39.393: INFO: (1) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 32.522624ms)
Aug 18 18:28:39.393: INFO: (1) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 32.479836ms)
Aug 18 18:28:39.410: INFO: (2) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 17.278647ms)
Aug 18 18:28:39.416: INFO: (2) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 22.758809ms)
Aug 18 18:28:39.416: INFO: (2) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 23.140059ms)
Aug 18 18:28:39.416: INFO: (2) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 23.228333ms)
Aug 18 18:28:39.416: INFO: (2) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 23.195427ms)
Aug 18 18:28:39.416: INFO: (2) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 23.245647ms)
Aug 18 18:28:39.416: INFO: (2) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 23.342849ms)
Aug 18 18:28:39.416: INFO: (2) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 23.47634ms)
Aug 18 18:28:39.416: INFO: (2) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 23.32323ms)
Aug 18 18:28:39.419: INFO: (2) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 26.157953ms)
Aug 18 18:28:39.421: INFO: (2) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 27.466449ms)
Aug 18 18:28:39.421: INFO: (2) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 27.496668ms)
Aug 18 18:28:39.423: INFO: (2) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 30.662898ms)
Aug 18 18:28:39.423: INFO: (2) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 30.424989ms)
Aug 18 18:28:39.423: INFO: (2) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 30.363969ms)
Aug 18 18:28:39.425: INFO: (2) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 32.441891ms)
Aug 18 18:28:39.450: INFO: (3) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 24.001739ms)
Aug 18 18:28:39.450: INFO: (3) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 23.79294ms)
Aug 18 18:28:39.450: INFO: (3) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 23.845416ms)
Aug 18 18:28:39.452: INFO: (3) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 25.887093ms)
Aug 18 18:28:39.452: INFO: (3) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 26.045148ms)
Aug 18 18:28:39.452: INFO: (3) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 26.516193ms)
Aug 18 18:28:39.452: INFO: (3) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 26.218453ms)
Aug 18 18:28:39.452: INFO: (3) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 25.934909ms)
Aug 18 18:28:39.452: INFO: (3) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 26.186033ms)
Aug 18 18:28:39.452: INFO: (3) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 26.017924ms)
Aug 18 18:28:39.453: INFO: (3) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 27.456822ms)
Aug 18 18:28:39.454: INFO: (3) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 28.590096ms)
Aug 18 18:28:39.457: INFO: (3) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 30.758531ms)
Aug 18 18:28:39.458: INFO: (3) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 31.872235ms)
Aug 18 18:28:39.458: INFO: (3) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 31.608225ms)
Aug 18 18:28:39.458: INFO: (3) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 31.734611ms)
Aug 18 18:28:39.478: INFO: (4) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 19.265287ms)
Aug 18 18:28:39.483: INFO: (4) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 24.299147ms)
Aug 18 18:28:39.483: INFO: (4) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 24.365649ms)
Aug 18 18:28:39.485: INFO: (4) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 26.703453ms)
Aug 18 18:28:39.485: INFO: (4) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 26.956504ms)
Aug 18 18:28:39.485: INFO: (4) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 27.066265ms)
Aug 18 18:28:39.485: INFO: (4) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 26.978476ms)
Aug 18 18:28:39.486: INFO: (4) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 26.890562ms)
Aug 18 18:28:39.486: INFO: (4) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 27.042961ms)
Aug 18 18:28:39.485: INFO: (4) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 26.860935ms)
Aug 18 18:28:39.494: INFO: (4) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 35.456055ms)
Aug 18 18:28:39.494: INFO: (4) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 35.387387ms)
Aug 18 18:28:39.494: INFO: (4) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 35.608006ms)
Aug 18 18:28:39.494: INFO: (4) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 35.433921ms)
Aug 18 18:28:39.494: INFO: (4) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 35.493766ms)
Aug 18 18:28:39.498: INFO: (4) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 39.478416ms)
Aug 18 18:28:39.516: INFO: (5) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 17.832642ms)
Aug 18 18:28:39.522: INFO: (5) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 23.303551ms)
Aug 18 18:28:39.522: INFO: (5) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 23.266001ms)
Aug 18 18:28:39.522: INFO: (5) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 23.463513ms)
Aug 18 18:28:39.522: INFO: (5) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 23.475722ms)
Aug 18 18:28:39.522: INFO: (5) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 23.851537ms)
Aug 18 18:28:39.522: INFO: (5) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 23.713742ms)
Aug 18 18:28:39.522: INFO: (5) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 24.104045ms)
Aug 18 18:28:39.522: INFO: (5) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 24.109664ms)
Aug 18 18:28:39.523: INFO: (5) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 24.287987ms)
Aug 18 18:28:39.529: INFO: (5) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 30.607676ms)
Aug 18 18:28:39.530: INFO: (5) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 31.602899ms)
Aug 18 18:28:39.531: INFO: (5) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 32.909655ms)
Aug 18 18:28:39.531: INFO: (5) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 32.99326ms)
Aug 18 18:28:39.531: INFO: (5) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 33.34535ms)
Aug 18 18:28:39.532: INFO: (5) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 33.551918ms)
Aug 18 18:28:39.550: INFO: (6) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 18.445117ms)
Aug 18 18:28:39.556: INFO: (6) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 23.469739ms)
Aug 18 18:28:39.556: INFO: (6) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 23.928794ms)
Aug 18 18:28:39.556: INFO: (6) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 23.624771ms)
Aug 18 18:28:39.556: INFO: (6) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 23.93952ms)
Aug 18 18:28:39.556: INFO: (6) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 23.416598ms)
Aug 18 18:28:39.556: INFO: (6) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 23.596357ms)
Aug 18 18:28:39.556: INFO: (6) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 23.872255ms)
Aug 18 18:28:39.556: INFO: (6) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 23.708238ms)
Aug 18 18:28:39.558: INFO: (6) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 26.271109ms)
Aug 18 18:28:39.561: INFO: (6) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 28.845365ms)
Aug 18 18:28:39.561: INFO: (6) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 28.885609ms)
Aug 18 18:28:39.564: INFO: (6) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 31.474971ms)
Aug 18 18:28:39.564: INFO: (6) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 31.604775ms)
Aug 18 18:28:39.564: INFO: (6) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 31.654676ms)
Aug 18 18:28:39.564: INFO: (6) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 31.979472ms)
Aug 18 18:28:39.585: INFO: (7) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 21.112969ms)
Aug 18 18:28:39.588: INFO: (7) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 22.922997ms)
Aug 18 18:28:39.588: INFO: (7) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 22.889816ms)
Aug 18 18:28:39.588: INFO: (7) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 23.070906ms)
Aug 18 18:28:39.588: INFO: (7) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 23.020646ms)
Aug 18 18:28:39.588: INFO: (7) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 23.018696ms)
Aug 18 18:28:39.588: INFO: (7) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 23.188391ms)
Aug 18 18:28:39.588: INFO: (7) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 23.837448ms)
Aug 18 18:28:39.588: INFO: (7) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 23.322138ms)
Aug 18 18:28:39.588: INFO: (7) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 23.256691ms)
Aug 18 18:28:39.596: INFO: (7) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 30.73146ms)
Aug 18 18:28:39.598: INFO: (7) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 32.946531ms)
Aug 18 18:28:39.598: INFO: (7) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 32.852892ms)
Aug 18 18:28:39.598: INFO: (7) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 32.959407ms)
Aug 18 18:28:39.598: INFO: (7) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 33.235242ms)
Aug 18 18:28:39.598: INFO: (7) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 33.337235ms)
Aug 18 18:28:39.617: INFO: (8) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 18.21055ms)
Aug 18 18:28:39.623: INFO: (8) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 23.474776ms)
Aug 18 18:28:39.623: INFO: (8) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 23.207878ms)
Aug 18 18:28:39.623: INFO: (8) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 23.608017ms)
Aug 18 18:28:39.623: INFO: (8) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 24.133636ms)
Aug 18 18:28:39.623: INFO: (8) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 23.473977ms)
Aug 18 18:28:39.623: INFO: (8) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 24.20445ms)
Aug 18 18:28:39.625: INFO: (8) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 25.887755ms)
Aug 18 18:28:39.625: INFO: (8) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 25.888774ms)
Aug 18 18:28:39.625: INFO: (8) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 25.859503ms)
Aug 18 18:28:39.627: INFO: (8) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 28.347737ms)
Aug 18 18:28:39.627: INFO: (8) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 28.111368ms)
Aug 18 18:28:39.630: INFO: (8) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 31.5181ms)
Aug 18 18:28:39.630: INFO: (8) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 30.899689ms)
Aug 18 18:28:39.633: INFO: (8) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 33.217203ms)
Aug 18 18:28:39.633: INFO: (8) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 33.689234ms)
Aug 18 18:28:39.651: INFO: (9) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 18.097663ms)
Aug 18 18:28:39.656: INFO: (9) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 23.304113ms)
Aug 18 18:28:39.656: INFO: (9) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 23.262906ms)
Aug 18 18:28:39.657: INFO: (9) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 23.613788ms)
Aug 18 18:28:39.664: INFO: (9) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 31.088124ms)
Aug 18 18:28:39.664: INFO: (9) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 30.859476ms)
Aug 18 18:28:39.664: INFO: (9) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 30.808988ms)
Aug 18 18:28:39.664: INFO: (9) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 30.978825ms)
Aug 18 18:28:39.664: INFO: (9) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 31.128254ms)
Aug 18 18:28:39.664: INFO: (9) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 30.962533ms)
Aug 18 18:28:39.664: INFO: (9) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 31.422478ms)
Aug 18 18:28:39.666: INFO: (9) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 33.305882ms)
Aug 18 18:28:39.666: INFO: (9) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 33.272589ms)
Aug 18 18:28:39.666: INFO: (9) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 33.341703ms)
Aug 18 18:28:39.666: INFO: (9) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 33.508454ms)
Aug 18 18:28:39.666: INFO: (9) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 33.690911ms)
Aug 18 18:28:39.686: INFO: (10) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 19.329746ms)
Aug 18 18:28:39.691: INFO: (10) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 24.455048ms)
Aug 18 18:28:39.691: INFO: (10) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 24.301141ms)
Aug 18 18:28:39.691: INFO: (10) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 24.490423ms)
Aug 18 18:28:39.691: INFO: (10) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 24.192145ms)
Aug 18 18:28:39.691: INFO: (10) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 24.293796ms)
Aug 18 18:28:39.691: INFO: (10) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 24.27841ms)
Aug 18 18:28:39.691: INFO: (10) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 24.275374ms)
Aug 18 18:28:39.693: INFO: (10) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 26.367431ms)
Aug 18 18:28:39.693: INFO: (10) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 26.461543ms)
Aug 18 18:28:39.695: INFO: (10) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 28.506433ms)
Aug 18 18:28:39.695: INFO: (10) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 28.606627ms)
Aug 18 18:28:39.704: INFO: (10) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 37.690566ms)
Aug 18 18:28:39.704: INFO: (10) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 37.605705ms)
Aug 18 18:28:39.707: INFO: (10) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 40.114533ms)
Aug 18 18:28:39.707: INFO: (10) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 40.293484ms)
Aug 18 18:28:39.732: INFO: (11) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 25.173558ms)
Aug 18 18:28:39.737: INFO: (11) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 30.212293ms)
Aug 18 18:28:39.738: INFO: (11) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 31.028228ms)
Aug 18 18:28:39.738: INFO: (11) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 31.189071ms)
Aug 18 18:28:39.738: INFO: (11) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 31.321154ms)
Aug 18 18:28:39.738: INFO: (11) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 31.270114ms)
Aug 18 18:28:39.740: INFO: (11) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 32.593937ms)
Aug 18 18:28:39.740: INFO: (11) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 32.55738ms)
Aug 18 18:28:39.740: INFO: (11) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 32.780295ms)
Aug 18 18:28:39.740: INFO: (11) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 32.820669ms)
Aug 18 18:28:39.740: INFO: (11) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 33.062978ms)
Aug 18 18:28:39.740: INFO: (11) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 33.092213ms)
Aug 18 18:28:39.745: INFO: (11) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 37.988723ms)
Aug 18 18:28:39.746: INFO: (11) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 38.54807ms)
Aug 18 18:28:39.746: INFO: (11) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 38.729068ms)
Aug 18 18:28:39.746: INFO: (11) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 38.614381ms)
Aug 18 18:28:39.765: INFO: (12) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 19.096231ms)
Aug 18 18:28:39.772: INFO: (12) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 26.26316ms)
Aug 18 18:28:39.772: INFO: (12) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 26.108655ms)
Aug 18 18:28:39.773: INFO: (12) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 26.60513ms)
Aug 18 18:28:39.773: INFO: (12) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 26.73594ms)
Aug 18 18:28:39.773: INFO: (12) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 26.454351ms)
Aug 18 18:28:39.773: INFO: (12) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 26.506066ms)
Aug 18 18:28:39.773: INFO: (12) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 26.437434ms)
Aug 18 18:28:39.773: INFO: (12) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 26.688108ms)
Aug 18 18:28:39.775: INFO: (12) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 28.234572ms)
Aug 18 18:28:39.779: INFO: (12) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 32.970374ms)
Aug 18 18:28:39.780: INFO: (12) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 33.795865ms)
Aug 18 18:28:39.781: INFO: (12) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 35.208759ms)
Aug 18 18:28:39.781: INFO: (12) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 35.185242ms)
Aug 18 18:28:39.781: INFO: (12) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 35.277623ms)
Aug 18 18:28:39.781: INFO: (12) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 35.188115ms)
Aug 18 18:28:39.801: INFO: (13) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 19.230641ms)
Aug 18 18:28:39.806: INFO: (13) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 23.548105ms)
Aug 18 18:28:39.806: INFO: (13) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 24.551992ms)
Aug 18 18:28:39.806: INFO: (13) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 24.475942ms)
Aug 18 18:28:39.806: INFO: (13) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 24.240094ms)
Aug 18 18:28:39.806: INFO: (13) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 24.538138ms)
Aug 18 18:28:39.806: INFO: (13) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 24.548931ms)
Aug 18 18:28:39.807: INFO: (13) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 24.486744ms)
Aug 18 18:28:39.806: INFO: (13) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 24.24746ms)
Aug 18 18:28:39.812: INFO: (13) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 30.17084ms)
Aug 18 18:28:39.813: INFO: (13) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 30.660607ms)
Aug 18 18:28:39.813: INFO: (13) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 30.52775ms)
Aug 18 18:28:39.815: INFO: (13) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 32.724206ms)
Aug 18 18:28:39.815: INFO: (13) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 32.97199ms)
Aug 18 18:28:39.815: INFO: (13) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 32.646014ms)
Aug 18 18:28:39.815: INFO: (13) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 32.972943ms)
Aug 18 18:28:39.834: INFO: (14) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 18.518359ms)
Aug 18 18:28:39.840: INFO: (14) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 23.94847ms)
Aug 18 18:28:39.840: INFO: (14) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 24.334697ms)
Aug 18 18:28:39.840: INFO: (14) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 24.132071ms)
Aug 18 18:28:39.840: INFO: (14) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 24.000654ms)
Aug 18 18:28:39.840: INFO: (14) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 24.350451ms)
Aug 18 18:28:39.840: INFO: (14) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 24.309415ms)
Aug 18 18:28:39.840: INFO: (14) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 24.393268ms)
Aug 18 18:28:39.840: INFO: (14) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 24.307188ms)
Aug 18 18:28:39.841: INFO: (14) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 25.909382ms)
Aug 18 18:28:39.845: INFO: (14) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 29.246713ms)
Aug 18 18:28:39.845: INFO: (14) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 29.058591ms)
Aug 18 18:28:39.847: INFO: (14) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 31.3667ms)
Aug 18 18:28:39.847: INFO: (14) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 31.478214ms)
Aug 18 18:28:39.847: INFO: (14) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 32.051556ms)
Aug 18 18:28:39.850: INFO: (14) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 33.630345ms)
Aug 18 18:28:39.868: INFO: (15) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 18.292107ms)
Aug 18 18:28:39.874: INFO: (15) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 23.673203ms)
Aug 18 18:28:39.874: INFO: (15) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 23.919737ms)
Aug 18 18:28:39.874: INFO: (15) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 23.970422ms)
Aug 18 18:28:39.877: INFO: (15) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 26.965249ms)
Aug 18 18:28:39.877: INFO: (15) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 26.946683ms)
Aug 18 18:28:39.877: INFO: (15) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 27.276222ms)
Aug 18 18:28:39.877: INFO: (15) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 26.98339ms)
Aug 18 18:28:39.877: INFO: (15) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 27.398116ms)
Aug 18 18:28:39.877: INFO: (15) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 26.919442ms)
Aug 18 18:28:39.878: INFO: (15) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 27.727112ms)
Aug 18 18:28:39.878: INFO: (15) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 28.10247ms)
Aug 18 18:28:39.880: INFO: (15) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 30.273127ms)
Aug 18 18:28:39.881: INFO: (15) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 30.997314ms)
Aug 18 18:28:39.881: INFO: (15) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 31.302832ms)
Aug 18 18:28:39.883: INFO: (15) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 32.999279ms)
Aug 18 18:28:39.902: INFO: (16) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 18.739306ms)
Aug 18 18:28:39.907: INFO: (16) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 23.151858ms)
Aug 18 18:28:39.907: INFO: (16) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 23.107614ms)
Aug 18 18:28:39.907: INFO: (16) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 23.207062ms)
Aug 18 18:28:39.909: INFO: (16) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 25.421594ms)
Aug 18 18:28:39.909: INFO: (16) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 25.273801ms)
Aug 18 18:28:39.909: INFO: (16) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 25.340558ms)
Aug 18 18:28:39.909: INFO: (16) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 25.24859ms)
Aug 18 18:28:39.909: INFO: (16) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 25.409797ms)
Aug 18 18:28:39.909: INFO: (16) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 25.547129ms)
Aug 18 18:28:39.911: INFO: (16) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 27.670194ms)
Aug 18 18:28:39.911: INFO: (16) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 27.690146ms)
Aug 18 18:28:39.914: INFO: (16) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 30.801454ms)
Aug 18 18:28:39.914: INFO: (16) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 30.75617ms)
Aug 18 18:28:39.914: INFO: (16) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 30.706272ms)
Aug 18 18:28:39.919: INFO: (16) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 35.423618ms)
Aug 18 18:28:39.952: INFO: (17) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 33.278589ms)
Aug 18 18:28:39.952: INFO: (17) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 33.402718ms)
Aug 18 18:28:39.952: INFO: (17) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 33.087158ms)
Aug 18 18:28:39.953: INFO: (17) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 33.083049ms)
Aug 18 18:28:39.953: INFO: (17) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 33.079564ms)
Aug 18 18:28:39.953: INFO: (17) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 33.152237ms)
Aug 18 18:28:39.953: INFO: (17) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 33.37664ms)
Aug 18 18:28:39.953: INFO: (17) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 33.325185ms)
Aug 18 18:28:39.953: INFO: (17) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 33.327798ms)
Aug 18 18:28:39.953: INFO: (17) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 33.63131ms)
Aug 18 18:28:39.953: INFO: (17) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 33.450608ms)
Aug 18 18:28:39.953: INFO: (17) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 33.429419ms)
Aug 18 18:28:39.953: INFO: (17) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 33.393341ms)
Aug 18 18:28:39.953: INFO: (17) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 33.4906ms)
Aug 18 18:28:39.953: INFO: (17) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 33.627775ms)
Aug 18 18:28:39.953: INFO: (17) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 33.373853ms)
Aug 18 18:28:39.972: INFO: (18) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 18.171899ms)
Aug 18 18:28:39.979: INFO: (18) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 24.834014ms)
Aug 18 18:28:39.979: INFO: (18) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 24.721127ms)
Aug 18 18:28:39.982: INFO: (18) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 28.272726ms)
Aug 18 18:28:39.982: INFO: (18) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 28.112228ms)
Aug 18 18:28:39.982: INFO: (18) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 28.488206ms)
Aug 18 18:28:39.982: INFO: (18) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 28.462083ms)
Aug 18 18:28:39.982: INFO: (18) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 28.760833ms)
Aug 18 18:28:39.983: INFO: (18) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 28.451806ms)
Aug 18 18:28:39.983: INFO: (18) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 28.297528ms)
Aug 18 18:28:39.985: INFO: (18) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 31.141187ms)
Aug 18 18:28:39.985: INFO: (18) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 31.240193ms)
Aug 18 18:28:39.985: INFO: (18) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 30.952481ms)
Aug 18 18:28:39.989: INFO: (18) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 34.983099ms)
Aug 18 18:28:39.989: INFO: (18) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 35.03283ms)
Aug 18 18:28:39.989: INFO: (18) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 34.866377ms)
Aug 18 18:28:40.010: INFO: (19) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm/proxy/rewriteme">test</a> (200; 20.524126ms)
Aug 18 18:28:40.013: INFO: (19) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:160/proxy/: foo (200; 23.751037ms)
Aug 18 18:28:40.013: INFO: (19) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:162/proxy/: bar (200; 23.981479ms)
Aug 18 18:28:40.016: INFO: (19) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:160/proxy/: foo (200; 26.184792ms)
Aug 18 18:28:40.016: INFO: (19) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:1080/proxy/rewriteme">t... (200; 26.195883ms)
Aug 18 18:28:40.016: INFO: (19) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:443/proxy/tlsrewriteme... (200; 26.160295ms)
Aug 18 18:28:40.016: INFO: (19) /api/v1/namespaces/proxy-223/pods/http:proxy-service-r9csp-59lwm:162/proxy/: bar (200; 26.450895ms)
Aug 18 18:28:40.016: INFO: (19) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:462/proxy/: tls qux (200; 26.380138ms)
Aug 18 18:28:40.016: INFO: (19) /api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/: <a href="/api/v1/namespaces/proxy-223/pods/proxy-service-r9csp-59lwm:1080/proxy/rewriteme">test</... (200; 26.359061ms)
Aug 18 18:28:40.016: INFO: (19) /api/v1/namespaces/proxy-223/pods/https:proxy-service-r9csp-59lwm:460/proxy/: tls baz (200; 26.871526ms)
Aug 18 18:28:40.022: INFO: (19) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname2/proxy/: bar (200; 32.641073ms)
Aug 18 18:28:40.022: INFO: (19) /api/v1/namespaces/proxy-223/services/http:proxy-service-r9csp:portname1/proxy/: foo (200; 32.700232ms)
Aug 18 18:28:40.025: INFO: (19) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname2/proxy/: bar (200; 35.579672ms)
Aug 18 18:28:40.025: INFO: (19) /api/v1/namespaces/proxy-223/services/proxy-service-r9csp:portname1/proxy/: foo (200; 35.191693ms)
Aug 18 18:28:40.025: INFO: (19) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname2/proxy/: tls qux (200; 35.523136ms)
Aug 18 18:28:40.025: INFO: (19) /api/v1/namespaces/proxy-223/services/https:proxy-service-r9csp:tlsportname1/proxy/: tls baz (200; 35.393308ms)
STEP: deleting ReplicationController proxy-service-r9csp in namespace proxy-223, will wait for the garbage collector to delete the pods
Aug 18 18:28:40.113: INFO: Deleting ReplicationController proxy-service-r9csp took: 26.821387ms
Aug 18 18:28:40.314: INFO: Terminating ReplicationController proxy-service-r9csp pods took: 200.522501ms
[AfterEach] version v1
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:28:50.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-223" for this suite.
Aug 18 18:28:56.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:28:56.893: INFO: namespace proxy-223 deletion completed in 6.437553383s

• [SLOW TEST:27.918 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:28:56.894: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-170
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Aug 18 18:28:57.127: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Aug 18 18:29:12.270: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
Aug 18 18:29:16.158: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:29:31.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-170" for this suite.
Aug 18 18:29:37.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:29:37.932: INFO: namespace crd-publish-openapi-170 deletion completed in 6.443110172s

• [SLOW TEST:41.038 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:29:37.933: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5935
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-50e43a75-386c-410f-8ccd-f86cdfd68cd3
STEP: Creating a pod to test consume secrets
Aug 18 18:29:38.188: INFO: Waiting up to 5m0s for pod "pod-secrets-0406abb1-a50c-4f70-a597-249bacced29b" in namespace "secrets-5935" to be "success or failure"
Aug 18 18:29:38.198: INFO: Pod "pod-secrets-0406abb1-a50c-4f70-a597-249bacced29b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.084172ms
Aug 18 18:29:40.209: INFO: Pod "pod-secrets-0406abb1-a50c-4f70-a597-249bacced29b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020503444s
STEP: Saw pod success
Aug 18 18:29:40.209: INFO: Pod "pod-secrets-0406abb1-a50c-4f70-a597-249bacced29b" satisfied condition "success or failure"
Aug 18 18:29:40.219: INFO: Trying to get logs from node 10.241.69.172 pod pod-secrets-0406abb1-a50c-4f70-a597-249bacced29b container secret-volume-test: <nil>
STEP: delete the pod
Aug 18 18:29:40.278: INFO: Waiting for pod pod-secrets-0406abb1-a50c-4f70-a597-249bacced29b to disappear
Aug 18 18:29:40.293: INFO: Pod pod-secrets-0406abb1-a50c-4f70-a597-249bacced29b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:29:40.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5935" for this suite.
Aug 18 18:29:46.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:29:46.740: INFO: namespace secrets-5935 deletion completed in 6.42945992s

• [SLOW TEST:8.808 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:29:46.742: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4095
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-jfpc
STEP: Creating a pod to test atomic-volume-subpath
Aug 18 18:29:47.009: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-jfpc" in namespace "subpath-4095" to be "success or failure"
Aug 18 18:29:47.021: INFO: Pod "pod-subpath-test-projected-jfpc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.17758ms
Aug 18 18:29:49.033: INFO: Pod "pod-subpath-test-projected-jfpc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024347636s
Aug 18 18:29:51.045: INFO: Pod "pod-subpath-test-projected-jfpc": Phase="Running", Reason="", readiness=true. Elapsed: 4.035955846s
Aug 18 18:29:53.059: INFO: Pod "pod-subpath-test-projected-jfpc": Phase="Running", Reason="", readiness=true. Elapsed: 6.05019119s
Aug 18 18:29:55.073: INFO: Pod "pod-subpath-test-projected-jfpc": Phase="Running", Reason="", readiness=true. Elapsed: 8.063700157s
Aug 18 18:29:57.085: INFO: Pod "pod-subpath-test-projected-jfpc": Phase="Running", Reason="", readiness=true. Elapsed: 10.075525623s
Aug 18 18:29:59.096: INFO: Pod "pod-subpath-test-projected-jfpc": Phase="Running", Reason="", readiness=true. Elapsed: 12.086725189s
Aug 18 18:30:01.107: INFO: Pod "pod-subpath-test-projected-jfpc": Phase="Running", Reason="", readiness=true. Elapsed: 14.098336453s
Aug 18 18:30:03.181: INFO: Pod "pod-subpath-test-projected-jfpc": Phase="Running", Reason="", readiness=true. Elapsed: 16.171746585s
Aug 18 18:30:05.195: INFO: Pod "pod-subpath-test-projected-jfpc": Phase="Running", Reason="", readiness=true. Elapsed: 18.186365275s
Aug 18 18:30:07.210: INFO: Pod "pod-subpath-test-projected-jfpc": Phase="Running", Reason="", readiness=true. Elapsed: 20.201249229s
Aug 18 18:30:09.222: INFO: Pod "pod-subpath-test-projected-jfpc": Phase="Running", Reason="", readiness=true. Elapsed: 22.213427121s
Aug 18 18:30:11.234: INFO: Pod "pod-subpath-test-projected-jfpc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.224727393s
STEP: Saw pod success
Aug 18 18:30:11.234: INFO: Pod "pod-subpath-test-projected-jfpc" satisfied condition "success or failure"
Aug 18 18:30:11.245: INFO: Trying to get logs from node 10.241.69.172 pod pod-subpath-test-projected-jfpc container test-container-subpath-projected-jfpc: <nil>
STEP: delete the pod
Aug 18 18:30:11.305: INFO: Waiting for pod pod-subpath-test-projected-jfpc to disappear
Aug 18 18:30:11.318: INFO: Pod pod-subpath-test-projected-jfpc no longer exists
STEP: Deleting pod pod-subpath-test-projected-jfpc
Aug 18 18:30:11.319: INFO: Deleting pod "pod-subpath-test-projected-jfpc" in namespace "subpath-4095"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:30:11.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4095" for this suite.
Aug 18 18:30:17.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:30:17.819: INFO: namespace subpath-4095 deletion completed in 6.473403825s

• [SLOW TEST:31.077 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:30:17.819: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2000
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 18 18:30:18.063: INFO: Waiting up to 5m0s for pod "pod-f6f6114a-945b-4c77-9fc0-5e957f048d3a" in namespace "emptydir-2000" to be "success or failure"
Aug 18 18:30:18.074: INFO: Pod "pod-f6f6114a-945b-4c77-9fc0-5e957f048d3a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.790324ms
Aug 18 18:30:20.086: INFO: Pod "pod-f6f6114a-945b-4c77-9fc0-5e957f048d3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023584902s
Aug 18 18:30:22.099: INFO: Pod "pod-f6f6114a-945b-4c77-9fc0-5e957f048d3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0364552s
STEP: Saw pod success
Aug 18 18:30:22.099: INFO: Pod "pod-f6f6114a-945b-4c77-9fc0-5e957f048d3a" satisfied condition "success or failure"
Aug 18 18:30:22.112: INFO: Trying to get logs from node 10.241.69.172 pod pod-f6f6114a-945b-4c77-9fc0-5e957f048d3a container test-container: <nil>
STEP: delete the pod
Aug 18 18:30:22.187: INFO: Waiting for pod pod-f6f6114a-945b-4c77-9fc0-5e957f048d3a to disappear
Aug 18 18:30:22.197: INFO: Pod pod-f6f6114a-945b-4c77-9fc0-5e957f048d3a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:30:22.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2000" for this suite.
Aug 18 18:30:28.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:30:28.664: INFO: namespace emptydir-2000 deletion completed in 6.449848481s

• [SLOW TEST:10.845 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:30:28.664: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2203
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-712c3e1a-50cd-4242-b833-618897689b82
STEP: Creating a pod to test consume secrets
Aug 18 18:30:28.933: INFO: Waiting up to 5m0s for pod "pod-secrets-2166d8ff-61ca-4117-a5ab-3e5a3e887b84" in namespace "secrets-2203" to be "success or failure"
Aug 18 18:30:28.945: INFO: Pod "pod-secrets-2166d8ff-61ca-4117-a5ab-3e5a3e887b84": Phase="Pending", Reason="", readiness=false. Elapsed: 11.751715ms
Aug 18 18:30:30.956: INFO: Pod "pod-secrets-2166d8ff-61ca-4117-a5ab-3e5a3e887b84": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02315774s
STEP: Saw pod success
Aug 18 18:30:30.956: INFO: Pod "pod-secrets-2166d8ff-61ca-4117-a5ab-3e5a3e887b84" satisfied condition "success or failure"
Aug 18 18:30:30.966: INFO: Trying to get logs from node 10.241.69.172 pod pod-secrets-2166d8ff-61ca-4117-a5ab-3e5a3e887b84 container secret-volume-test: <nil>
STEP: delete the pod
Aug 18 18:30:31.025: INFO: Waiting for pod pod-secrets-2166d8ff-61ca-4117-a5ab-3e5a3e887b84 to disappear
Aug 18 18:30:31.034: INFO: Pod pod-secrets-2166d8ff-61ca-4117-a5ab-3e5a3e887b84 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:30:31.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2203" for this suite.
Aug 18 18:30:37.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:30:37.483: INFO: namespace secrets-2203 deletion completed in 6.431832381s

• [SLOW TEST:8.819 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:30:37.484: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6594
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 18 18:30:37.772: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6594 /api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-label-changed 8ca08ec1-e432-42ef-aef4-5da2c7b4220d 39091 0 2020-08-18 18:30:37 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 18 18:30:37.772: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6594 /api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-label-changed 8ca08ec1-e432-42ef-aef4-5da2c7b4220d 39092 0 2020-08-18 18:30:37 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 18 18:30:37.772: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6594 /api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-label-changed 8ca08ec1-e432-42ef-aef4-5da2c7b4220d 39093 0 2020-08-18 18:30:37 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 18 18:30:47.864: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6594 /api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-label-changed 8ca08ec1-e432-42ef-aef4-5da2c7b4220d 39108 0 2020-08-18 18:30:37 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 18 18:30:47.864: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6594 /api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-label-changed 8ca08ec1-e432-42ef-aef4-5da2c7b4220d 39109 0 2020-08-18 18:30:37 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug 18 18:30:47.864: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6594 /api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-label-changed 8ca08ec1-e432-42ef-aef4-5da2c7b4220d 39110 0 2020-08-18 18:30:37 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:30:47.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6594" for this suite.
Aug 18 18:30:53.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:30:54.333: INFO: namespace watch-6594 deletion completed in 6.45373117s

• [SLOW TEST:16.849 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:30:54.338: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1750
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:31:54.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1750" for this suite.
Aug 18 18:32:24.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:32:25.076: INFO: namespace container-probe-1750 deletion completed in 30.46267377s

• [SLOW TEST:90.738 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:32:25.076: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4406
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Aug 18 18:32:25.326: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3b133c5a-a68f-46d2-a045-54eaa2694eab" in namespace "downward-api-4406" to be "success or failure"
Aug 18 18:32:25.338: INFO: Pod "downwardapi-volume-3b133c5a-a68f-46d2-a045-54eaa2694eab": Phase="Pending", Reason="", readiness=false. Elapsed: 11.75971ms
Aug 18 18:32:27.351: INFO: Pod "downwardapi-volume-3b133c5a-a68f-46d2-a045-54eaa2694eab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024742501s
Aug 18 18:32:29.364: INFO: Pod "downwardapi-volume-3b133c5a-a68f-46d2-a045-54eaa2694eab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037323593s
STEP: Saw pod success
Aug 18 18:32:29.364: INFO: Pod "downwardapi-volume-3b133c5a-a68f-46d2-a045-54eaa2694eab" satisfied condition "success or failure"
Aug 18 18:32:29.376: INFO: Trying to get logs from node 10.241.69.172 pod downwardapi-volume-3b133c5a-a68f-46d2-a045-54eaa2694eab container client-container: <nil>
STEP: delete the pod
Aug 18 18:32:29.465: INFO: Waiting for pod downwardapi-volume-3b133c5a-a68f-46d2-a045-54eaa2694eab to disappear
Aug 18 18:32:29.475: INFO: Pod downwardapi-volume-3b133c5a-a68f-46d2-a045-54eaa2694eab no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:32:29.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4406" for this suite.
Aug 18 18:32:35.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:32:35.943: INFO: namespace downward-api-4406 deletion completed in 6.449528375s

• [SLOW TEST:10.868 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:32:35.946: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1522
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Aug 18 18:32:36.175: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:32:40.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1522" for this suite.
Aug 18 18:32:52.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:32:52.994: INFO: namespace init-container-1522 deletion completed in 12.45607937s

• [SLOW TEST:17.048 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:32:52.994: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3359
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Aug 18 18:32:54.372: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0818 18:32:54.372587      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:32:54.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3359" for this suite.
Aug 18 18:33:00.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:33:00.837: INFO: namespace gc-3359 deletion completed in 6.441587355s

• [SLOW TEST:7.843 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:33:00.837: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1560
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:33:03.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1560" for this suite.
Aug 18 18:33:51.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:33:51.647: INFO: namespace kubelet-test-1560 deletion completed in 48.485603731s

• [SLOW TEST:50.810 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:33:51.648: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1726
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Aug 18 18:33:54.501: INFO: Successfully updated pod "annotationupdatecf401f58-ebdc-40f7-bfb3-a8fe9e7f5460"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:33:56.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1726" for this suite.
Aug 18 18:34:26.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:34:27.410: INFO: namespace projected-1726 deletion completed in 30.818785669s

• [SLOW TEST:35.763 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:34:27.411: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9033
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 18:34:28.631: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 18 18:34:30.671: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733372468, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733372468, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733372468, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733372468, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 18:34:33.721: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:34:33.734: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:34:35.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9033" for this suite.
Aug 18 18:34:43.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:34:43.601: INFO: namespace webhook-9033 deletion completed in 8.436321928s
STEP: Destroying namespace "webhook-9033-markers" for this suite.
Aug 18 18:34:49.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:34:50.073: INFO: namespace webhook-9033-markers deletion completed in 6.471891339s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.743 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:34:50.153: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5483
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Aug 18 18:34:50.372: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 18 18:34:50.430: INFO: Waiting for terminating namespaces to be deleted...
Aug 18 18:34:50.442: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.172 before test
Aug 18 18:34:50.480: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-m29th from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 18:34:50.480: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 18 18:34:50.481: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 18:34:50.481: INFO: ibm-keepalived-watcher-2f6fp from kube-system started at 2020-08-18 15:45:12 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.481: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 18:34:50.481: INFO: addon-catalog-source-gmd49 from ibm-system started at 2020-08-18 15:45:49 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.481: INFO: 	Container configmap-registry-server ready: true, restart count 0
Aug 18 18:34:50.482: INFO: ibm-master-proxy-static-10.241.69.172 from kube-system started at 2020-08-18 15:45:10 +0000 UTC (2 container statuses recorded)
Aug 18 18:34:50.482: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 18:34:50.482: INFO: 	Container pause ready: true, restart count 0
Aug 18 18:34:50.482: INFO: calico-node-sz9mb from kube-system started at 2020-08-18 15:45:12 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.482: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 18:34:50.483: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.181 before test
Aug 18 18:34:50.566: INFO: coredns-55db5d97fb-8tfqf from kube-system started at 2020-08-18 15:57:41 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.566: INFO: 	Container coredns ready: true, restart count 0
Aug 18 18:34:50.566: INFO: sonobuoy-e2e-job-692caab668c14a3b from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 18:34:50.566: INFO: 	Container e2e ready: true, restart count 0
Aug 18 18:34:50.566: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 18 18:34:50.566: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-rwtzr from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 18:34:50.566: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 18 18:34:50.566: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 18:34:50.566: INFO: calico-node-vn5q9 from kube-system started at 2020-08-18 15:50:03 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.566: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 18:34:50.566: INFO: sonobuoy from sonobuoy started at 2020-08-18 17:08:11 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.566: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 18 18:34:50.566: INFO: kubernetes-dashboard-85b945ff4b-9cklr from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.566: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 18 18:34:50.566: INFO: public-crbstv5sqd0r3kmi9abm0g-alb1-5f59ffb4c7-4k6xv from kube-system started at 2020-08-18 17:21:45 +0000 UTC (4 container statuses recorded)
Aug 18 18:34:50.566: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 18 18:34:50.566: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 18 18:34:50.566: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 18 18:34:50.566: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 18 18:34:50.566: INFO: ibm-master-proxy-static-10.241.69.181 from kube-system started at 2020-08-18 15:49:51 +0000 UTC (2 container statuses recorded)
Aug 18 18:34:50.566: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 18:34:50.566: INFO: 	Container pause ready: true, restart count 0
Aug 18 18:34:50.566: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-08-18 15:52:42 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.566: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Aug 18 18:34:50.566: INFO: coredns-autoscaler-65c89858bf-q6hj7 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.566: INFO: 	Container autoscaler ready: true, restart count 0
Aug 18 18:34:50.566: INFO: dashboard-metrics-scraper-76756886dc-rk2k2 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.566: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Aug 18 18:34:50.566: INFO: ibm-cloud-provider-ip-169-47-71-114-64b8d74dd8-8brdn from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.566: INFO: 	Container ibm-cloud-provider-ip-169-47-71-114 ready: true, restart count 0
Aug 18 18:34:50.566: INFO: ibm-keepalived-watcher-kr9tn from kube-system started at 2020-08-18 15:50:03 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.566: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 18:34:50.566: INFO: olm-operator-6f74dfc868-28t4m from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.566: INFO: 	Container olm-operator ready: true, restart count 0
Aug 18 18:34:50.566: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.184 before test
Aug 18 18:34:50.644: INFO: coredns-55db5d97fb-cqx5b from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.644: INFO: 	Container coredns ready: true, restart count 0
Aug 18 18:34:50.644: INFO: ibm-cloud-provider-ip-169-47-71-114-64b8d74dd8-dc47l from ibm-system started at 2020-08-18 15:46:51 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.644: INFO: 	Container ibm-cloud-provider-ip-169-47-71-114 ready: true, restart count 0
Aug 18 18:34:50.644: INFO: vpn-79845b6f9d-wmz87 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.644: INFO: 	Container vpn ready: true, restart count 0
Aug 18 18:34:50.644: INFO: metrics-server-695ffd979-8z2wt from kube-system started at 2020-08-18 17:21:45 +0000 UTC (2 container statuses recorded)
Aug 18 18:34:50.644: INFO: 	Container metrics-server ready: true, restart count 0
Aug 18 18:34:50.644: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 18 18:34:50.644: INFO: coredns-55db5d97fb-2h7nb from kube-system started at 2020-08-18 15:57:41 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.644: INFO: 	Container coredns ready: true, restart count 0
Aug 18 18:34:50.644: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-ctchp from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 18:34:50.644: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 18 18:34:50.644: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 18:34:50.644: INFO: ibm-storage-watcher-5685787df4-w25gd from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.644: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug 18 18:34:50.644: INFO: ibm-master-proxy-static-10.241.69.184 from kube-system started at 2020-08-18 15:46:23 +0000 UTC (2 container statuses recorded)
Aug 18 18:34:50.644: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 18:34:50.644: INFO: 	Container pause ready: true, restart count 0
Aug 18 18:34:50.644: INFO: calico-node-f56nz from kube-system started at 2020-08-18 15:46:36 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.644: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 18:34:50.644: INFO: calico-kube-controllers-66c5f69b5f-9qvwh from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.644: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 18 18:34:50.644: INFO: catalog-operator-67cbc5d959-hqgh5 from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.644: INFO: 	Container catalog-operator ready: true, restart count 0
Aug 18 18:34:50.644: INFO: ibm-keepalived-watcher-xt8rx from kube-system started at 2020-08-18 15:46:36 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.644: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 18:34:50.644: INFO: public-crbstv5sqd0r3kmi9abm0g-alb1-5f59ffb4c7-s8vcr from kube-system started at 2020-08-18 15:48:16 +0000 UTC (4 container statuses recorded)
Aug 18 18:34:50.644: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 18 18:34:50.644: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 18 18:34:50.644: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 18 18:34:50.644: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 18 18:34:50.644: INFO: ibm-file-plugin-7c6788b5f5-ldfzf from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 18:34:50.644: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node 10.241.69.172
STEP: verifying the node has the label node 10.241.69.181
STEP: verifying the node has the label node 10.241.69.184
Aug 18 18:34:50.777: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.241.69.181
Aug 18 18:34:50.777: INFO: Pod addon-catalog-source-gmd49 requesting resource cpu=10m on Node 10.241.69.172
Aug 18 18:34:50.777: INFO: Pod catalog-operator-67cbc5d959-hqgh5 requesting resource cpu=10m on Node 10.241.69.184
Aug 18 18:34:50.777: INFO: Pod ibm-cloud-provider-ip-169-47-71-114-64b8d74dd8-8brdn requesting resource cpu=5m on Node 10.241.69.181
Aug 18 18:34:50.777: INFO: Pod ibm-cloud-provider-ip-169-47-71-114-64b8d74dd8-dc47l requesting resource cpu=5m on Node 10.241.69.184
Aug 18 18:34:50.777: INFO: Pod olm-operator-6f74dfc868-28t4m requesting resource cpu=10m on Node 10.241.69.181
Aug 18 18:34:50.777: INFO: Pod calico-kube-controllers-66c5f69b5f-9qvwh requesting resource cpu=10m on Node 10.241.69.184
Aug 18 18:34:50.777: INFO: Pod calico-node-f56nz requesting resource cpu=250m on Node 10.241.69.184
Aug 18 18:34:50.777: INFO: Pod calico-node-sz9mb requesting resource cpu=250m on Node 10.241.69.172
Aug 18 18:34:50.777: INFO: Pod calico-node-vn5q9 requesting resource cpu=250m on Node 10.241.69.181
Aug 18 18:34:50.777: INFO: Pod coredns-55db5d97fb-2h7nb requesting resource cpu=100m on Node 10.241.69.184
Aug 18 18:34:50.778: INFO: Pod coredns-55db5d97fb-8tfqf requesting resource cpu=100m on Node 10.241.69.181
Aug 18 18:34:50.778: INFO: Pod coredns-55db5d97fb-cqx5b requesting resource cpu=100m on Node 10.241.69.184
Aug 18 18:34:50.778: INFO: Pod coredns-autoscaler-65c89858bf-q6hj7 requesting resource cpu=20m on Node 10.241.69.181
Aug 18 18:34:50.778: INFO: Pod dashboard-metrics-scraper-76756886dc-rk2k2 requesting resource cpu=1m on Node 10.241.69.181
Aug 18 18:34:50.778: INFO: Pod ibm-file-plugin-7c6788b5f5-ldfzf requesting resource cpu=50m on Node 10.241.69.184
Aug 18 18:34:50.778: INFO: Pod ibm-keepalived-watcher-2f6fp requesting resource cpu=5m on Node 10.241.69.172
Aug 18 18:34:50.778: INFO: Pod ibm-keepalived-watcher-kr9tn requesting resource cpu=5m on Node 10.241.69.181
Aug 18 18:34:50.778: INFO: Pod ibm-keepalived-watcher-xt8rx requesting resource cpu=5m on Node 10.241.69.184
Aug 18 18:34:50.778: INFO: Pod ibm-master-proxy-static-10.241.69.172 requesting resource cpu=25m on Node 10.241.69.172
Aug 18 18:34:50.778: INFO: Pod ibm-master-proxy-static-10.241.69.181 requesting resource cpu=25m on Node 10.241.69.181
Aug 18 18:34:50.778: INFO: Pod ibm-master-proxy-static-10.241.69.184 requesting resource cpu=25m on Node 10.241.69.184
Aug 18 18:34:50.778: INFO: Pod ibm-storage-watcher-5685787df4-w25gd requesting resource cpu=50m on Node 10.241.69.184
Aug 18 18:34:50.778: INFO: Pod kubernetes-dashboard-85b945ff4b-9cklr requesting resource cpu=50m on Node 10.241.69.181
Aug 18 18:34:50.778: INFO: Pod metrics-server-695ffd979-8z2wt requesting resource cpu=121m on Node 10.241.69.184
Aug 18 18:34:50.778: INFO: Pod public-crbstv5sqd0r3kmi9abm0g-alb1-5f59ffb4c7-4k6xv requesting resource cpu=10m on Node 10.241.69.181
Aug 18 18:34:50.778: INFO: Pod public-crbstv5sqd0r3kmi9abm0g-alb1-5f59ffb4c7-s8vcr requesting resource cpu=10m on Node 10.241.69.184
Aug 18 18:34:50.778: INFO: Pod vpn-79845b6f9d-wmz87 requesting resource cpu=5m on Node 10.241.69.184
Aug 18 18:34:50.778: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.241.69.181
Aug 18 18:34:50.778: INFO: Pod sonobuoy-e2e-job-692caab668c14a3b requesting resource cpu=0m on Node 10.241.69.181
Aug 18 18:34:50.778: INFO: Pod sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-ctchp requesting resource cpu=0m on Node 10.241.69.184
Aug 18 18:34:50.778: INFO: Pod sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-m29th requesting resource cpu=0m on Node 10.241.69.172
Aug 18 18:34:50.778: INFO: Pod sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-rwtzr requesting resource cpu=0m on Node 10.241.69.181
STEP: Starting Pods to consume most of the cluster CPU.
Aug 18 18:34:50.778: INFO: Creating a pod which consumes cpu=2218m on Node 10.241.69.184
Aug 18 18:34:50.803: INFO: Creating a pod which consumes cpu=2534m on Node 10.241.69.172
Aug 18 18:34:50.816: INFO: Creating a pod which consumes cpu=2403m on Node 10.241.69.181
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cb795335-dff1-4df7-9d72-f58e2fbcb8a8.162c70868342416c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5483/filler-pod-cb795335-dff1-4df7-9d72-f58e2fbcb8a8 to 10.241.69.181]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cb795335-dff1-4df7-9d72-f58e2fbcb8a8.162c7086bf59e3ff], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cb795335-dff1-4df7-9d72-f58e2fbcb8a8.162c7086c7ae7dbd], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cb795335-dff1-4df7-9d72-f58e2fbcb8a8.162c7086cb52006a], Reason = [Created], Message = [Created container filler-pod-cb795335-dff1-4df7-9d72-f58e2fbcb8a8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cb795335-dff1-4df7-9d72-f58e2fbcb8a8.162c7086d62bc1e9], Reason = [Started], Message = [Started container filler-pod-cb795335-dff1-4df7-9d72-f58e2fbcb8a8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d6f8b4c5-bd44-4ccd-86a7-4bf90de7d24e.162c708681c13a45], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5483/filler-pod-d6f8b4c5-bd44-4ccd-86a7-4bf90de7d24e to 10.241.69.184]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d6f8b4c5-bd44-4ccd-86a7-4bf90de7d24e.162c7086bd53f4bb], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d6f8b4c5-bd44-4ccd-86a7-4bf90de7d24e.162c7086c56f0c79], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d6f8b4c5-bd44-4ccd-86a7-4bf90de7d24e.162c7086c8f3a56e], Reason = [Created], Message = [Created container filler-pod-d6f8b4c5-bd44-4ccd-86a7-4bf90de7d24e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d6f8b4c5-bd44-4ccd-86a7-4bf90de7d24e.162c7086d325546e], Reason = [Started], Message = [Started container filler-pod-d6f8b4c5-bd44-4ccd-86a7-4bf90de7d24e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-eaeb1fe1-63f0-4007-b314-1657d8c6d6b4.162c708682684515], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5483/filler-pod-eaeb1fe1-63f0-4007-b314-1657d8c6d6b4 to 10.241.69.172]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-eaeb1fe1-63f0-4007-b314-1657d8c6d6b4.162c7086bf3dd0ec], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-eaeb1fe1-63f0-4007-b314-1657d8c6d6b4.162c7086c39877ba], Reason = [Created], Message = [Created container filler-pod-eaeb1fe1-63f0-4007-b314-1657d8c6d6b4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-eaeb1fe1-63f0-4007-b314-1657d8c6d6b4.162c7086cc3229b2], Reason = [Started], Message = [Started container filler-pod-eaeb1fe1-63f0-4007-b314-1657d8c6d6b4]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.162c708776e1ef47], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.241.69.184
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.241.69.172
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.241.69.181
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:34:56.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5483" for this suite.
Aug 18 18:35:04.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:35:04.547: INFO: namespace sched-pred-5483 deletion completed in 8.465580776s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:14.394 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:35:04.548: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8658
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8658
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-8658
I0818 18:35:04.881861      23 runners.go:184] Created replication controller with name: externalname-service, namespace: services-8658, replica count: 2
Aug 18 18:35:07.932: INFO: Creating new exec pod
I0818 18:35:07.932401      23 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 18 18:35:10.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-8658 execpod558sg -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Aug 18 18:35:11.305: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 18 18:35:11.305: INFO: stdout: ""
Aug 18 18:35:11.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-8658 execpod558sg -- /bin/sh -x -c nc -zv -t -w 2 172.21.215.9 80'
Aug 18 18:35:11.578: INFO: stderr: "+ nc -zv -t -w 2 172.21.215.9 80\nConnection to 172.21.215.9 80 port [tcp/http] succeeded!\n"
Aug 18 18:35:11.578: INFO: stdout: ""
Aug 18 18:35:11.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-8658 execpod558sg -- /bin/sh -x -c nc -zv -t -w 2 10.241.69.172 31614'
Aug 18 18:35:11.869: INFO: stderr: "+ nc -zv -t -w 2 10.241.69.172 31614\nConnection to 10.241.69.172 31614 port [tcp/31614] succeeded!\n"
Aug 18 18:35:11.870: INFO: stdout: ""
Aug 18 18:35:11.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-8658 execpod558sg -- /bin/sh -x -c nc -zv -t -w 2 10.241.69.181 31614'
Aug 18 18:35:12.135: INFO: stderr: "+ nc -zv -t -w 2 10.241.69.181 31614\nConnection to 10.241.69.181 31614 port [tcp/31614] succeeded!\n"
Aug 18 18:35:12.135: INFO: stdout: ""
Aug 18 18:35:12.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-8658 execpod558sg -- /bin/sh -x -c nc -zv -t -w 2 169.59.196.52 31614'
Aug 18 18:35:12.409: INFO: stderr: "+ nc -zv -t -w 2 169.59.196.52 31614\nConnection to 169.59.196.52 31614 port [tcp/31614] succeeded!\n"
Aug 18 18:35:12.409: INFO: stdout: ""
Aug 18 18:35:12.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-8658 execpod558sg -- /bin/sh -x -c nc -zv -t -w 2 169.59.196.53 31614'
Aug 18 18:35:12.729: INFO: stderr: "+ nc -zv -t -w 2 169.59.196.53 31614\nConnection to 169.59.196.53 31614 port [tcp/31614] succeeded!\n"
Aug 18 18:35:12.729: INFO: stdout: ""
Aug 18 18:35:12.729: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:35:12.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8658" for this suite.
Aug 18 18:35:20.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:35:21.338: INFO: namespace services-8658 deletion completed in 8.496205603s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.790 seconds]
[sig-network] Services
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:35:21.349: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8029
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 18 18:35:21.594: INFO: Waiting up to 5m0s for pod "pod-23ffd831-a6f2-4519-891d-b7c180e37f7b" in namespace "emptydir-8029" to be "success or failure"
Aug 18 18:35:21.611: INFO: Pod "pod-23ffd831-a6f2-4519-891d-b7c180e37f7b": Phase="Pending", Reason="", readiness=false. Elapsed: 17.336904ms
Aug 18 18:35:23.623: INFO: Pod "pod-23ffd831-a6f2-4519-891d-b7c180e37f7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029387026s
Aug 18 18:35:25.635: INFO: Pod "pod-23ffd831-a6f2-4519-891d-b7c180e37f7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041421711s
STEP: Saw pod success
Aug 18 18:35:25.635: INFO: Pod "pod-23ffd831-a6f2-4519-891d-b7c180e37f7b" satisfied condition "success or failure"
Aug 18 18:35:25.647: INFO: Trying to get logs from node 10.241.69.172 pod pod-23ffd831-a6f2-4519-891d-b7c180e37f7b container test-container: <nil>
STEP: delete the pod
Aug 18 18:35:25.708: INFO: Waiting for pod pod-23ffd831-a6f2-4519-891d-b7c180e37f7b to disappear
Aug 18 18:35:25.719: INFO: Pod pod-23ffd831-a6f2-4519-891d-b7c180e37f7b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:35:25.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8029" for this suite.
Aug 18 18:35:31.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:35:32.192: INFO: namespace emptydir-8029 deletion completed in 6.455982335s

• [SLOW TEST:10.844 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:35:32.193: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6101
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Aug 18 18:35:32.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 create -f - --namespace=kubectl-6101'
Aug 18 18:35:32.713: INFO: stderr: ""
Aug 18 18:35:32.713: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 18 18:35:32.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6101'
Aug 18 18:35:32.859: INFO: stderr: ""
Aug 18 18:35:32.860: INFO: stdout: "update-demo-nautilus-79tnq update-demo-nautilus-t8gn5 "
Aug 18 18:35:32.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-79tnq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6101'
Aug 18 18:35:32.966: INFO: stderr: ""
Aug 18 18:35:32.966: INFO: stdout: ""
Aug 18 18:35:32.966: INFO: update-demo-nautilus-79tnq is created but not running
Aug 18 18:35:37.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6101'
Aug 18 18:35:38.076: INFO: stderr: ""
Aug 18 18:35:38.076: INFO: stdout: "update-demo-nautilus-79tnq update-demo-nautilus-t8gn5 "
Aug 18 18:35:38.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-79tnq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6101'
Aug 18 18:35:38.186: INFO: stderr: ""
Aug 18 18:35:38.186: INFO: stdout: "true"
Aug 18 18:35:38.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-79tnq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6101'
Aug 18 18:35:38.292: INFO: stderr: ""
Aug 18 18:35:38.292: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 18 18:35:38.292: INFO: validating pod update-demo-nautilus-79tnq
Aug 18 18:35:38.327: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 18 18:35:38.327: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 18 18:35:38.327: INFO: update-demo-nautilus-79tnq is verified up and running
Aug 18 18:35:38.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-t8gn5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6101'
Aug 18 18:35:38.431: INFO: stderr: ""
Aug 18 18:35:38.431: INFO: stdout: "true"
Aug 18 18:35:38.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-t8gn5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6101'
Aug 18 18:35:38.546: INFO: stderr: ""
Aug 18 18:35:38.546: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 18 18:35:38.546: INFO: validating pod update-demo-nautilus-t8gn5
Aug 18 18:35:38.576: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 18 18:35:38.576: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 18 18:35:38.576: INFO: update-demo-nautilus-t8gn5 is verified up and running
STEP: scaling down the replication controller
Aug 18 18:35:38.578: INFO: scanned /root for discovery docs: <nil>
Aug 18 18:35:38.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-6101'
Aug 18 18:35:39.732: INFO: stderr: ""
Aug 18 18:35:39.733: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 18 18:35:39.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6101'
Aug 18 18:35:39.836: INFO: stderr: ""
Aug 18 18:35:39.836: INFO: stdout: "update-demo-nautilus-79tnq update-demo-nautilus-t8gn5 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 18 18:35:44.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6101'
Aug 18 18:35:44.954: INFO: stderr: ""
Aug 18 18:35:44.954: INFO: stdout: "update-demo-nautilus-t8gn5 "
Aug 18 18:35:44.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-t8gn5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6101'
Aug 18 18:35:45.077: INFO: stderr: ""
Aug 18 18:35:45.077: INFO: stdout: "true"
Aug 18 18:35:45.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-t8gn5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6101'
Aug 18 18:35:45.192: INFO: stderr: ""
Aug 18 18:35:45.192: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 18 18:35:45.192: INFO: validating pod update-demo-nautilus-t8gn5
Aug 18 18:35:45.214: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 18 18:35:45.214: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 18 18:35:45.214: INFO: update-demo-nautilus-t8gn5 is verified up and running
STEP: scaling up the replication controller
Aug 18 18:35:45.216: INFO: scanned /root for discovery docs: <nil>
Aug 18 18:35:45.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-6101'
Aug 18 18:35:46.405: INFO: stderr: ""
Aug 18 18:35:46.405: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 18 18:35:46.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6101'
Aug 18 18:35:46.511: INFO: stderr: ""
Aug 18 18:35:46.511: INFO: stdout: "update-demo-nautilus-t8gn5 update-demo-nautilus-wsvrd "
Aug 18 18:35:46.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-t8gn5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6101'
Aug 18 18:35:46.631: INFO: stderr: ""
Aug 18 18:35:46.632: INFO: stdout: "true"
Aug 18 18:35:46.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-t8gn5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6101'
Aug 18 18:35:46.744: INFO: stderr: ""
Aug 18 18:35:46.744: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 18 18:35:46.744: INFO: validating pod update-demo-nautilus-t8gn5
Aug 18 18:35:46.764: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 18 18:35:46.764: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 18 18:35:46.764: INFO: update-demo-nautilus-t8gn5 is verified up and running
Aug 18 18:35:46.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-wsvrd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6101'
Aug 18 18:35:46.876: INFO: stderr: ""
Aug 18 18:35:46.876: INFO: stdout: "true"
Aug 18 18:35:46.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-wsvrd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6101'
Aug 18 18:35:46.990: INFO: stderr: ""
Aug 18 18:35:46.990: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 18 18:35:46.990: INFO: validating pod update-demo-nautilus-wsvrd
Aug 18 18:35:47.018: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 18 18:35:47.018: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 18 18:35:47.018: INFO: update-demo-nautilus-wsvrd is verified up and running
STEP: using delete to clean up resources
Aug 18 18:35:47.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete --grace-period=0 --force -f - --namespace=kubectl-6101'
Aug 18 18:35:47.162: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 18 18:35:47.162: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 18 18:35:47.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6101'
Aug 18 18:35:47.303: INFO: stderr: "No resources found in kubectl-6101 namespace.\n"
Aug 18 18:35:47.303: INFO: stdout: ""
Aug 18 18:35:47.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods -l name=update-demo --namespace=kubectl-6101 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 18 18:35:47.580: INFO: stderr: ""
Aug 18 18:35:47.580: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:35:47.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6101" for this suite.
Aug 18 18:35:59.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:36:00.059: INFO: namespace kubectl-6101 deletion completed in 12.462170339s

• [SLOW TEST:27.866 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:36:00.063: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4614
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-6f420dc2-7ece-4be3-a4bf-12c847342047
STEP: Creating a pod to test consume secrets
Aug 18 18:36:00.333: INFO: Waiting up to 5m0s for pod "pod-secrets-2cc34511-543e-4d7d-8d37-f51b653a865d" in namespace "secrets-4614" to be "success or failure"
Aug 18 18:36:00.345: INFO: Pod "pod-secrets-2cc34511-543e-4d7d-8d37-f51b653a865d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.44752ms
Aug 18 18:36:02.358: INFO: Pod "pod-secrets-2cc34511-543e-4d7d-8d37-f51b653a865d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024875403s
STEP: Saw pod success
Aug 18 18:36:02.358: INFO: Pod "pod-secrets-2cc34511-543e-4d7d-8d37-f51b653a865d" satisfied condition "success or failure"
Aug 18 18:36:02.368: INFO: Trying to get logs from node 10.241.69.172 pod pod-secrets-2cc34511-543e-4d7d-8d37-f51b653a865d container secret-volume-test: <nil>
STEP: delete the pod
Aug 18 18:36:02.433: INFO: Waiting for pod pod-secrets-2cc34511-543e-4d7d-8d37-f51b653a865d to disappear
Aug 18 18:36:02.448: INFO: Pod pod-secrets-2cc34511-543e-4d7d-8d37-f51b653a865d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:36:02.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4614" for this suite.
Aug 18 18:36:08.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:36:08.982: INFO: namespace secrets-4614 deletion completed in 6.49122725s

• [SLOW TEST:8.919 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:36:08.983: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-207
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-9ab4df45-c309-430d-8c69-594b87bd1e10
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-9ab4df45-c309-430d-8c69-594b87bd1e10
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:36:13.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-207" for this suite.
Aug 18 18:36:25.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:36:25.938: INFO: namespace configmap-207 deletion completed in 12.45957452s

• [SLOW TEST:16.955 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:36:25.939: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3377
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-43bcb479-277f-4cbf-b8d8-2068aa77e111
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-43bcb479-277f-4cbf-b8d8-2068aa77e111
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:36:30.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3377" for this suite.
Aug 18 18:36:42.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:36:42.887: INFO: namespace projected-3377 deletion completed in 12.47206057s

• [SLOW TEST:16.948 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:36:42.888: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-8331
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug 18 18:36:45.188: INFO: &Pod{ObjectMeta:{send-events-81e581f7-a541-43a7-b573-bece85f8adff  events-8331 /api/v1/namespaces/events-8331/pods/send-events-81e581f7-a541-43a7-b573-bece85f8adff b25d621b-65c5-4865-9e40-d75b5cf7f19f 40420 0 2020-08-18 18:36:43 +0000 UTC <nil> <nil> map[name:foo time:110644967] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nlhzc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nlhzc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nlhzc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.172,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 18:36:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 18:36:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 18:36:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-08-18 18:36:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.172,PodIP:172.30.104.130,StartTime:2020-08-18 18:36:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-08-18 18:36:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:containerd://e1021cff8d8e99812d7cb466e8e26667f04e5c214ca31ea16e00dc3e7f4b5e29,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.130,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Aug 18 18:36:47.206: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug 18 18:36:49.221: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:36:49.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8331" for this suite.
Aug 18 18:37:35.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:37:35.799: INFO: namespace events-8331 deletion completed in 46.537541624s

• [SLOW TEST:52.911 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:37:35.799: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5008
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 18:37:36.812: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 18 18:37:38.854: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733372656, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733372656, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733372656, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733372656, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 18:37:41.903: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:37:42.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5008" for this suite.
Aug 18 18:37:50.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:37:50.586: INFO: namespace webhook-5008 deletion completed in 8.492654266s
STEP: Destroying namespace "webhook-5008-markers" for this suite.
Aug 18 18:37:56.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:37:57.054: INFO: namespace webhook-5008-markers deletion completed in 6.467501218s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.317 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:37:57.117: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6173
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6173
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-6173
I0818 18:37:57.453741      23 runners.go:184] Created replication controller with name: externalname-service, namespace: services-6173, replica count: 2
I0818 18:38:00.504349      23 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 18 18:38:00.504: INFO: Creating new exec pod
Aug 18 18:38:03.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-6173 execpodpwl2z -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Aug 18 18:38:03.970: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 18 18:38:03.970: INFO: stdout: ""
Aug 18 18:38:03.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 exec --namespace=services-6173 execpodpwl2z -- /bin/sh -x -c nc -zv -t -w 2 172.21.193.12 80'
Aug 18 18:38:04.267: INFO: stderr: "+ nc -zv -t -w 2 172.21.193.12 80\nConnection to 172.21.193.12 80 port [tcp/http] succeeded!\n"
Aug 18 18:38:04.267: INFO: stdout: ""
Aug 18 18:38:04.267: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:38:04.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6173" for this suite.
Aug 18 18:38:12.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:38:12.826: INFO: namespace services-6173 deletion completed in 8.463493352s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:15.710 seconds]
[sig-network] Services
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:38:12.831: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6566
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 18 18:38:13.077: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6566 /api/v1/namespaces/watch-6566/configmaps/e2e-watch-test-configmap-a 24a88f38-4d9e-4a3d-9c4b-b0770b2b638d 40758 0 2020-08-18 18:38:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 18 18:38:13.077: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6566 /api/v1/namespaces/watch-6566/configmaps/e2e-watch-test-configmap-a 24a88f38-4d9e-4a3d-9c4b-b0770b2b638d 40758 0 2020-08-18 18:38:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 18 18:38:23.102: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6566 /api/v1/namespaces/watch-6566/configmaps/e2e-watch-test-configmap-a 24a88f38-4d9e-4a3d-9c4b-b0770b2b638d 40773 0 2020-08-18 18:38:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 18 18:38:23.102: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6566 /api/v1/namespaces/watch-6566/configmaps/e2e-watch-test-configmap-a 24a88f38-4d9e-4a3d-9c4b-b0770b2b638d 40773 0 2020-08-18 18:38:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 18 18:38:33.132: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6566 /api/v1/namespaces/watch-6566/configmaps/e2e-watch-test-configmap-a 24a88f38-4d9e-4a3d-9c4b-b0770b2b638d 40787 0 2020-08-18 18:38:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 18 18:38:33.132: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6566 /api/v1/namespaces/watch-6566/configmaps/e2e-watch-test-configmap-a 24a88f38-4d9e-4a3d-9c4b-b0770b2b638d 40787 0 2020-08-18 18:38:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 18 18:38:43.158: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6566 /api/v1/namespaces/watch-6566/configmaps/e2e-watch-test-configmap-a 24a88f38-4d9e-4a3d-9c4b-b0770b2b638d 40800 0 2020-08-18 18:38:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 18 18:38:43.159: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6566 /api/v1/namespaces/watch-6566/configmaps/e2e-watch-test-configmap-a 24a88f38-4d9e-4a3d-9c4b-b0770b2b638d 40800 0 2020-08-18 18:38:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 18 18:38:53.183: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6566 /api/v1/namespaces/watch-6566/configmaps/e2e-watch-test-configmap-b 2e1c8951-c411-4b4c-adbe-74422d9d6ab0 40816 0 2020-08-18 18:38:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 18 18:38:53.183: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6566 /api/v1/namespaces/watch-6566/configmaps/e2e-watch-test-configmap-b 2e1c8951-c411-4b4c-adbe-74422d9d6ab0 40816 0 2020-08-18 18:38:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 18 18:39:03.211: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6566 /api/v1/namespaces/watch-6566/configmaps/e2e-watch-test-configmap-b 2e1c8951-c411-4b4c-adbe-74422d9d6ab0 40830 0 2020-08-18 18:38:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 18 18:39:03.211: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6566 /api/v1/namespaces/watch-6566/configmaps/e2e-watch-test-configmap-b 2e1c8951-c411-4b4c-adbe-74422d9d6ab0 40830 0 2020-08-18 18:38:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:39:13.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6566" for this suite.
Aug 18 18:39:19.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:39:19.705: INFO: namespace watch-6566 deletion completed in 6.467042157s

• [SLOW TEST:66.874 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:39:19.706: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7265
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 18 18:39:19.954: INFO: Waiting up to 5m0s for pod "pod-eccb7da5-a56c-49a5-b15a-383adf1e1dcc" in namespace "emptydir-7265" to be "success or failure"
Aug 18 18:39:19.970: INFO: Pod "pod-eccb7da5-a56c-49a5-b15a-383adf1e1dcc": Phase="Pending", Reason="", readiness=false. Elapsed: 16.181962ms
Aug 18 18:39:21.985: INFO: Pod "pod-eccb7da5-a56c-49a5-b15a-383adf1e1dcc": Phase="Running", Reason="", readiness=true. Elapsed: 2.031315465s
Aug 18 18:39:23.999: INFO: Pod "pod-eccb7da5-a56c-49a5-b15a-383adf1e1dcc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045539234s
STEP: Saw pod success
Aug 18 18:39:23.999: INFO: Pod "pod-eccb7da5-a56c-49a5-b15a-383adf1e1dcc" satisfied condition "success or failure"
Aug 18 18:39:24.011: INFO: Trying to get logs from node 10.241.69.172 pod pod-eccb7da5-a56c-49a5-b15a-383adf1e1dcc container test-container: <nil>
STEP: delete the pod
Aug 18 18:39:24.108: INFO: Waiting for pod pod-eccb7da5-a56c-49a5-b15a-383adf1e1dcc to disappear
Aug 18 18:39:24.124: INFO: Pod pod-eccb7da5-a56c-49a5-b15a-383adf1e1dcc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:39:24.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7265" for this suite.
Aug 18 18:39:30.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:39:30.608: INFO: namespace emptydir-7265 deletion completed in 6.462519662s

• [SLOW TEST:10.903 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:39:30.609: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5907
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 18 18:39:30.858: INFO: Waiting up to 5m0s for pod "pod-b365d809-06fe-429f-9baa-8d1ec5dad548" in namespace "emptydir-5907" to be "success or failure"
Aug 18 18:39:30.868: INFO: Pod "pod-b365d809-06fe-429f-9baa-8d1ec5dad548": Phase="Pending", Reason="", readiness=false. Elapsed: 10.557434ms
Aug 18 18:39:32.880: INFO: Pod "pod-b365d809-06fe-429f-9baa-8d1ec5dad548": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022330113s
STEP: Saw pod success
Aug 18 18:39:32.880: INFO: Pod "pod-b365d809-06fe-429f-9baa-8d1ec5dad548" satisfied condition "success or failure"
Aug 18 18:39:32.890: INFO: Trying to get logs from node 10.241.69.172 pod pod-b365d809-06fe-429f-9baa-8d1ec5dad548 container test-container: <nil>
STEP: delete the pod
Aug 18 18:39:32.961: INFO: Waiting for pod pod-b365d809-06fe-429f-9baa-8d1ec5dad548 to disappear
Aug 18 18:39:32.978: INFO: Pod pod-b365d809-06fe-429f-9baa-8d1ec5dad548 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:39:32.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5907" for this suite.
Aug 18 18:39:39.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:39:39.447: INFO: namespace emptydir-5907 deletion completed in 6.451143495s

• [SLOW TEST:8.838 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:39:39.447: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1622
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-46270e26-aa26-4a6d-99f4-3d5e87c8f914
STEP: Creating a pod to test consume secrets
Aug 18 18:39:39.721: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4fbf6275-a1be-42a0-bb70-83292c5132f8" in namespace "projected-1622" to be "success or failure"
Aug 18 18:39:39.737: INFO: Pod "pod-projected-secrets-4fbf6275-a1be-42a0-bb70-83292c5132f8": Phase="Pending", Reason="", readiness=false. Elapsed: 15.915033ms
Aug 18 18:39:41.751: INFO: Pod "pod-projected-secrets-4fbf6275-a1be-42a0-bb70-83292c5132f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029594161s
STEP: Saw pod success
Aug 18 18:39:41.751: INFO: Pod "pod-projected-secrets-4fbf6275-a1be-42a0-bb70-83292c5132f8" satisfied condition "success or failure"
Aug 18 18:39:41.762: INFO: Trying to get logs from node 10.241.69.172 pod pod-projected-secrets-4fbf6275-a1be-42a0-bb70-83292c5132f8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 18 18:39:41.827: INFO: Waiting for pod pod-projected-secrets-4fbf6275-a1be-42a0-bb70-83292c5132f8 to disappear
Aug 18 18:39:41.837: INFO: Pod pod-projected-secrets-4fbf6275-a1be-42a0-bb70-83292c5132f8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:39:41.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1622" for this suite.
Aug 18 18:39:47.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:39:48.318: INFO: namespace projected-1622 deletion completed in 6.460037828s

• [SLOW TEST:8.871 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:39:48.320: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1314
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-2e507079-783a-46cf-a28c-9df243746a8d
STEP: Creating a pod to test consume configMaps
Aug 18 18:39:48.579: INFO: Waiting up to 5m0s for pod "pod-configmaps-d5d2b740-1649-48c2-8c5e-604521817226" in namespace "configmap-1314" to be "success or failure"
Aug 18 18:39:48.597: INFO: Pod "pod-configmaps-d5d2b740-1649-48c2-8c5e-604521817226": Phase="Pending", Reason="", readiness=false. Elapsed: 17.735795ms
Aug 18 18:39:50.609: INFO: Pod "pod-configmaps-d5d2b740-1649-48c2-8c5e-604521817226": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02948196s
STEP: Saw pod success
Aug 18 18:39:50.609: INFO: Pod "pod-configmaps-d5d2b740-1649-48c2-8c5e-604521817226" satisfied condition "success or failure"
Aug 18 18:39:50.621: INFO: Trying to get logs from node 10.241.69.172 pod pod-configmaps-d5d2b740-1649-48c2-8c5e-604521817226 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 18 18:39:50.681: INFO: Waiting for pod pod-configmaps-d5d2b740-1649-48c2-8c5e-604521817226 to disappear
Aug 18 18:39:50.696: INFO: Pod pod-configmaps-d5d2b740-1649-48c2-8c5e-604521817226 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:39:50.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1314" for this suite.
Aug 18 18:39:56.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:39:57.170: INFO: namespace configmap-1314 deletion completed in 6.454765475s

• [SLOW TEST:8.851 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:39:57.170: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-6555
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-6555
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6555
STEP: Deleting pre-stop pod
Aug 18 18:40:06.535: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:40:06.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6555" for this suite.
Aug 18 18:40:52.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:40:53.107: INFO: namespace prestop-6555 deletion completed in 46.532034331s

• [SLOW TEST:55.937 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:40:53.108: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3011
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 18 18:40:53.480: INFO: Number of nodes with available pods: 0
Aug 18 18:40:53.480: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:40:54.516: INFO: Number of nodes with available pods: 0
Aug 18 18:40:54.516: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:40:55.521: INFO: Number of nodes with available pods: 3
Aug 18 18:40:55.521: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 18 18:40:55.593: INFO: Number of nodes with available pods: 2
Aug 18 18:40:55.594: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:40:56.629: INFO: Number of nodes with available pods: 2
Aug 18 18:40:56.629: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:40:57.622: INFO: Number of nodes with available pods: 2
Aug 18 18:40:57.622: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:40:58.620: INFO: Number of nodes with available pods: 2
Aug 18 18:40:58.620: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:40:59.622: INFO: Number of nodes with available pods: 2
Aug 18 18:40:59.622: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:41:00.621: INFO: Number of nodes with available pods: 2
Aug 18 18:41:00.621: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:41:01.625: INFO: Number of nodes with available pods: 2
Aug 18 18:41:01.625: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:41:02.622: INFO: Number of nodes with available pods: 2
Aug 18 18:41:02.622: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:41:03.638: INFO: Number of nodes with available pods: 2
Aug 18 18:41:03.638: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:41:04.622: INFO: Number of nodes with available pods: 2
Aug 18 18:41:04.622: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:41:05.624: INFO: Number of nodes with available pods: 2
Aug 18 18:41:05.624: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:41:06.625: INFO: Number of nodes with available pods: 2
Aug 18 18:41:06.625: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:41:07.633: INFO: Number of nodes with available pods: 2
Aug 18 18:41:07.633: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:41:08.625: INFO: Number of nodes with available pods: 2
Aug 18 18:41:08.626: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:41:09.634: INFO: Number of nodes with available pods: 2
Aug 18 18:41:09.635: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:41:10.626: INFO: Number of nodes with available pods: 2
Aug 18 18:41:10.626: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:41:11.624: INFO: Number of nodes with available pods: 2
Aug 18 18:41:11.624: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:41:12.622: INFO: Number of nodes with available pods: 3
Aug 18 18:41:12.622: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3011, will wait for the garbage collector to delete the pods
Aug 18 18:41:12.720: INFO: Deleting DaemonSet.extensions daemon-set took: 24.444444ms
Aug 18 18:41:12.920: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.286212ms
Aug 18 18:41:23.532: INFO: Number of nodes with available pods: 0
Aug 18 18:41:23.532: INFO: Number of running nodes: 0, number of available pods: 0
Aug 18 18:41:23.543: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3011/daemonsets","resourceVersion":"41333"},"items":null}

Aug 18 18:41:23.555: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3011/pods","resourceVersion":"41333"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:41:23.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3011" for this suite.
Aug 18 18:41:31.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:41:32.259: INFO: namespace daemonsets-3011 deletion completed in 8.638850509s

• [SLOW TEST:39.151 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:41:32.260: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8377
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8377
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-8377
STEP: Creating statefulset with conflicting port in namespace statefulset-8377
STEP: Waiting until pod test-pod will start running in namespace statefulset-8377
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8377
Aug 18 18:41:36.656: INFO: Observed stateful pod in namespace: statefulset-8377, name: ss-0, uid: cd7b22b5-a95e-4e6b-90d4-1c9a93d2cbfc, status phase: Pending. Waiting for statefulset controller to delete.
Aug 18 18:41:36.768: INFO: Observed stateful pod in namespace: statefulset-8377, name: ss-0, uid: cd7b22b5-a95e-4e6b-90d4-1c9a93d2cbfc, status phase: Failed. Waiting for statefulset controller to delete.
Aug 18 18:41:36.785: INFO: Observed stateful pod in namespace: statefulset-8377, name: ss-0, uid: cd7b22b5-a95e-4e6b-90d4-1c9a93d2cbfc, status phase: Failed. Waiting for statefulset controller to delete.
Aug 18 18:41:36.799: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-8377
STEP: Removing pod with conflicting port in namespace statefulset-8377
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8377 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Aug 18 18:41:38.857: INFO: Deleting all statefulset in ns statefulset-8377
Aug 18 18:41:38.869: INFO: Scaling statefulset ss to 0
Aug 18 18:41:48.925: INFO: Waiting for statefulset status.replicas updated to 0
Aug 18 18:41:48.935: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:41:48.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8377" for this suite.
Aug 18 18:41:57.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:41:57.485: INFO: namespace statefulset-8377 deletion completed in 8.478567365s

• [SLOW TEST:25.225 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:41:57.485: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6252
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-92ec1068-ae55-4257-89ff-7c4261c0a826
STEP: Creating a pod to test consume configMaps
Aug 18 18:41:57.748: INFO: Waiting up to 5m0s for pod "pod-configmaps-017a3368-9be5-4147-9ef8-6e0a734da91a" in namespace "configmap-6252" to be "success or failure"
Aug 18 18:41:57.759: INFO: Pod "pod-configmaps-017a3368-9be5-4147-9ef8-6e0a734da91a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.763536ms
Aug 18 18:41:59.771: INFO: Pod "pod-configmaps-017a3368-9be5-4147-9ef8-6e0a734da91a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022851487s
STEP: Saw pod success
Aug 18 18:41:59.771: INFO: Pod "pod-configmaps-017a3368-9be5-4147-9ef8-6e0a734da91a" satisfied condition "success or failure"
Aug 18 18:41:59.782: INFO: Trying to get logs from node 10.241.69.172 pod pod-configmaps-017a3368-9be5-4147-9ef8-6e0a734da91a container configmap-volume-test: <nil>
STEP: delete the pod
Aug 18 18:41:59.863: INFO: Waiting for pod pod-configmaps-017a3368-9be5-4147-9ef8-6e0a734da91a to disappear
Aug 18 18:41:59.874: INFO: Pod pod-configmaps-017a3368-9be5-4147-9ef8-6e0a734da91a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:41:59.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6252" for this suite.
Aug 18 18:42:05.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:42:06.436: INFO: namespace configmap-6252 deletion completed in 6.539993828s

• [SLOW TEST:8.950 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:42:06.436: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6548
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:42:06.669: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Aug 18 18:42:08.777: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:42:08.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6548" for this suite.
Aug 18 18:42:16.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:42:17.285: INFO: namespace replication-controller-6548 deletion completed in 8.473997594s

• [SLOW TEST:10.849 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:42:17.285: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7111
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:42:21.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7111" for this suite.
Aug 18 18:42:29.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:42:30.115: INFO: namespace containers-7111 deletion completed in 8.498992548s

• [SLOW TEST:12.830 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:42:30.119: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6716
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Aug 18 18:42:30.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 create -f - --namespace=kubectl-6716'
Aug 18 18:42:30.713: INFO: stderr: ""
Aug 18 18:42:30.713: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 18 18:42:30.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6716'
Aug 18 18:42:30.827: INFO: stderr: ""
Aug 18 18:42:30.827: INFO: stdout: "update-demo-nautilus-7rckv update-demo-nautilus-t8mc6 "
Aug 18 18:42:30.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-7rckv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6716'
Aug 18 18:42:30.927: INFO: stderr: ""
Aug 18 18:42:30.927: INFO: stdout: ""
Aug 18 18:42:30.927: INFO: update-demo-nautilus-7rckv is created but not running
Aug 18 18:42:35.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6716'
Aug 18 18:42:36.048: INFO: stderr: ""
Aug 18 18:42:36.048: INFO: stdout: "update-demo-nautilus-7rckv update-demo-nautilus-t8mc6 "
Aug 18 18:42:36.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-7rckv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6716'
Aug 18 18:42:36.171: INFO: stderr: ""
Aug 18 18:42:36.171: INFO: stdout: "true"
Aug 18 18:42:36.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-7rckv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6716'
Aug 18 18:42:36.289: INFO: stderr: ""
Aug 18 18:42:36.289: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 18 18:42:36.289: INFO: validating pod update-demo-nautilus-7rckv
Aug 18 18:42:36.321: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 18 18:42:36.321: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 18 18:42:36.321: INFO: update-demo-nautilus-7rckv is verified up and running
Aug 18 18:42:36.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-t8mc6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6716'
Aug 18 18:42:36.427: INFO: stderr: ""
Aug 18 18:42:36.427: INFO: stdout: "true"
Aug 18 18:42:36.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-nautilus-t8mc6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6716'
Aug 18 18:42:36.547: INFO: stderr: ""
Aug 18 18:42:36.548: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 18 18:42:36.548: INFO: validating pod update-demo-nautilus-t8mc6
Aug 18 18:42:36.575: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 18 18:42:36.575: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 18 18:42:36.575: INFO: update-demo-nautilus-t8mc6 is verified up and running
STEP: rolling-update to new replication controller
Aug 18 18:42:36.577: INFO: scanned /root for discovery docs: <nil>
Aug 18 18:42:36.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-6716'
Aug 18 18:42:59.589: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 18 18:42:59.589: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 18 18:42:59.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6716'
Aug 18 18:42:59.702: INFO: stderr: ""
Aug 18 18:42:59.702: INFO: stdout: "update-demo-kitten-mgmdq update-demo-kitten-p5rb4 "
Aug 18 18:42:59.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-kitten-mgmdq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6716'
Aug 18 18:42:59.824: INFO: stderr: ""
Aug 18 18:42:59.824: INFO: stdout: "true"
Aug 18 18:42:59.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-kitten-mgmdq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6716'
Aug 18 18:42:59.938: INFO: stderr: ""
Aug 18 18:42:59.938: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 18 18:42:59.938: INFO: validating pod update-demo-kitten-mgmdq
Aug 18 18:42:59.968: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 18 18:42:59.968: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 18 18:42:59.968: INFO: update-demo-kitten-mgmdq is verified up and running
Aug 18 18:42:59.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-kitten-p5rb4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6716'
Aug 18 18:43:00.074: INFO: stderr: ""
Aug 18 18:43:00.074: INFO: stdout: "true"
Aug 18 18:43:00.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods update-demo-kitten-p5rb4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6716'
Aug 18 18:43:00.185: INFO: stderr: ""
Aug 18 18:43:00.185: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 18 18:43:00.185: INFO: validating pod update-demo-kitten-p5rb4
Aug 18 18:43:00.212: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 18 18:43:00.212: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 18 18:43:00.212: INFO: update-demo-kitten-p5rb4 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:43:00.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6716" for this suite.
Aug 18 18:43:30.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:43:30.712: INFO: namespace kubectl-6716 deletion completed in 30.470801614s

• [SLOW TEST:60.593 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:43:30.712: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1288
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1288.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1288.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 18 18:43:33.197: INFO: DNS probes using dns-1288/dns-test-14cd03e0-88e7-448a-b319-afe0c935f654 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:43:33.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1288" for this suite.
Aug 18 18:43:41.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:43:41.770: INFO: namespace dns-1288 deletion completed in 8.512681876s

• [SLOW TEST:11.058 seconds]
[sig-network] DNS
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:43:41.770: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3215
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Aug 18 18:43:42.027: INFO: Waiting up to 5m0s for pod "client-containers-2203f3b8-ceed-4fb6-bf55-47067fe23467" in namespace "containers-3215" to be "success or failure"
Aug 18 18:43:42.039: INFO: Pod "client-containers-2203f3b8-ceed-4fb6-bf55-47067fe23467": Phase="Pending", Reason="", readiness=false. Elapsed: 12.466065ms
Aug 18 18:43:44.052: INFO: Pod "client-containers-2203f3b8-ceed-4fb6-bf55-47067fe23467": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024872389s
STEP: Saw pod success
Aug 18 18:43:44.052: INFO: Pod "client-containers-2203f3b8-ceed-4fb6-bf55-47067fe23467" satisfied condition "success or failure"
Aug 18 18:43:44.065: INFO: Trying to get logs from node 10.241.69.172 pod client-containers-2203f3b8-ceed-4fb6-bf55-47067fe23467 container test-container: <nil>
STEP: delete the pod
Aug 18 18:43:44.133: INFO: Waiting for pod client-containers-2203f3b8-ceed-4fb6-bf55-47067fe23467 to disappear
Aug 18 18:43:44.146: INFO: Pod client-containers-2203f3b8-ceed-4fb6-bf55-47067fe23467 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:43:44.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3215" for this suite.
Aug 18 18:43:50.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:43:50.676: INFO: namespace containers-3215 deletion completed in 6.511437226s

• [SLOW TEST:8.906 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:43:50.676: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9243
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 18:43:51.597: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 18 18:43:53.638: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733373031, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733373031, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733373031, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733373031, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 18:43:56.686: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:43:56.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9243" for this suite.
Aug 18 18:44:04.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:44:05.389: INFO: namespace webhook-9243 deletion completed in 8.467068496s
STEP: Destroying namespace "webhook-9243-markers" for this suite.
Aug 18 18:44:11.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:44:11.867: INFO: namespace webhook-9243-markers deletion completed in 6.478019644s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.260 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:44:11.936: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1868
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Aug 18 18:44:12.185: INFO: Waiting up to 5m0s for pod "var-expansion-e9901a21-c73f-4a43-9eb8-a64a86585841" in namespace "var-expansion-1868" to be "success or failure"
Aug 18 18:44:12.196: INFO: Pod "var-expansion-e9901a21-c73f-4a43-9eb8-a64a86585841": Phase="Pending", Reason="", readiness=false. Elapsed: 11.378454ms
Aug 18 18:44:14.208: INFO: Pod "var-expansion-e9901a21-c73f-4a43-9eb8-a64a86585841": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023241464s
STEP: Saw pod success
Aug 18 18:44:14.208: INFO: Pod "var-expansion-e9901a21-c73f-4a43-9eb8-a64a86585841" satisfied condition "success or failure"
Aug 18 18:44:14.223: INFO: Trying to get logs from node 10.241.69.172 pod var-expansion-e9901a21-c73f-4a43-9eb8-a64a86585841 container dapi-container: <nil>
STEP: delete the pod
Aug 18 18:44:14.286: INFO: Waiting for pod var-expansion-e9901a21-c73f-4a43-9eb8-a64a86585841 to disappear
Aug 18 18:44:14.300: INFO: Pod var-expansion-e9901a21-c73f-4a43-9eb8-a64a86585841 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:44:14.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1868" for this suite.
Aug 18 18:44:20.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:44:20.778: INFO: namespace var-expansion-1868 deletion completed in 6.455142037s

• [SLOW TEST:8.842 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:44:20.778: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-120
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:44:37.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-120" for this suite.
Aug 18 18:44:45.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:44:45.770: INFO: namespace resourcequota-120 deletion completed in 8.4739247s

• [SLOW TEST:24.993 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:44:45.773: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9497
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-fe668cfc-b02b-470c-87a3-441c9fbdb0b9
STEP: Creating a pod to test consume secrets
Aug 18 18:44:46.055: INFO: Waiting up to 5m0s for pod "pod-secrets-f1c8f524-259c-4578-b581-56d7584813d8" in namespace "secrets-9497" to be "success or failure"
Aug 18 18:44:46.068: INFO: Pod "pod-secrets-f1c8f524-259c-4578-b581-56d7584813d8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.951132ms
Aug 18 18:44:48.085: INFO: Pod "pod-secrets-f1c8f524-259c-4578-b581-56d7584813d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029787402s
STEP: Saw pod success
Aug 18 18:44:48.085: INFO: Pod "pod-secrets-f1c8f524-259c-4578-b581-56d7584813d8" satisfied condition "success or failure"
Aug 18 18:44:48.098: INFO: Trying to get logs from node 10.241.69.172 pod pod-secrets-f1c8f524-259c-4578-b581-56d7584813d8 container secret-volume-test: <nil>
STEP: delete the pod
Aug 18 18:44:48.168: INFO: Waiting for pod pod-secrets-f1c8f524-259c-4578-b581-56d7584813d8 to disappear
Aug 18 18:44:48.179: INFO: Pod pod-secrets-f1c8f524-259c-4578-b581-56d7584813d8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:44:48.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9497" for this suite.
Aug 18 18:44:54.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:44:54.699: INFO: namespace secrets-9497 deletion completed in 6.50103203s

• [SLOW TEST:8.927 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:44:54.700: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4387
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Aug 18 18:44:54.944: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug 18 18:45:02.084: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:45:02.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4387" for this suite.
Aug 18 18:45:08.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:45:08.626: INFO: namespace pods-4387 deletion completed in 6.505454157s

• [SLOW TEST:13.926 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:45:08.627: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5926
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 18 18:45:13.442: INFO: Successfully updated pod "pod-update-activedeadlineseconds-300aab91-79f0-4b8d-9cb6-5ac3c322634b"
Aug 18 18:45:13.442: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-300aab91-79f0-4b8d-9cb6-5ac3c322634b" in namespace "pods-5926" to be "terminated due to deadline exceeded"
Aug 18 18:45:13.457: INFO: Pod "pod-update-activedeadlineseconds-300aab91-79f0-4b8d-9cb6-5ac3c322634b": Phase="Running", Reason="", readiness=true. Elapsed: 14.928364ms
Aug 18 18:45:15.469: INFO: Pod "pod-update-activedeadlineseconds-300aab91-79f0-4b8d-9cb6-5ac3c322634b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.026545936s
Aug 18 18:45:15.469: INFO: Pod "pod-update-activedeadlineseconds-300aab91-79f0-4b8d-9cb6-5ac3c322634b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:45:15.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5926" for this suite.
Aug 18 18:45:21.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:45:22.013: INFO: namespace pods-5926 deletion completed in 6.519639219s

• [SLOW TEST:13.385 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:45:22.013: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4974
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:45:22.348: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 18 18:45:22.395: INFO: Number of nodes with available pods: 0
Aug 18 18:45:22.395: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:45:23.426: INFO: Number of nodes with available pods: 0
Aug 18 18:45:23.426: INFO: Node 10.241.69.172 is running more than one daemon pod
Aug 18 18:45:24.426: INFO: Number of nodes with available pods: 2
Aug 18 18:45:24.426: INFO: Node 10.241.69.181 is running more than one daemon pod
Aug 18 18:45:25.426: INFO: Number of nodes with available pods: 3
Aug 18 18:45:25.426: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 18 18:45:25.529: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:25.529: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:25.530: INFO: Wrong image for pod: daemon-set-zlgq2. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:26.562: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:26.562: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:26.562: INFO: Wrong image for pod: daemon-set-zlgq2. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:27.563: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:27.563: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:27.563: INFO: Wrong image for pod: daemon-set-zlgq2. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:27.563: INFO: Pod daemon-set-zlgq2 is not available
Aug 18 18:45:28.560: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:28.561: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:28.561: INFO: Wrong image for pod: daemon-set-zlgq2. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:28.561: INFO: Pod daemon-set-zlgq2 is not available
Aug 18 18:45:29.567: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:29.567: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:29.567: INFO: Wrong image for pod: daemon-set-zlgq2. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:29.567: INFO: Pod daemon-set-zlgq2 is not available
Aug 18 18:45:30.562: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:30.562: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:30.562: INFO: Wrong image for pod: daemon-set-zlgq2. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:30.562: INFO: Pod daemon-set-zlgq2 is not available
Aug 18 18:45:31.564: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:31.564: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:31.564: INFO: Pod daemon-set-q7fkh is not available
Aug 18 18:45:32.561: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:32.561: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:32.561: INFO: Pod daemon-set-q7fkh is not available
Aug 18 18:45:33.562: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:33.562: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:34.563: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:34.563: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:34.563: INFO: Pod daemon-set-l5qz4 is not available
Aug 18 18:45:35.577: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:35.577: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:35.577: INFO: Pod daemon-set-l5qz4 is not available
Aug 18 18:45:36.563: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:36.563: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:36.564: INFO: Pod daemon-set-l5qz4 is not available
Aug 18 18:45:37.561: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:37.561: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:37.561: INFO: Pod daemon-set-l5qz4 is not available
Aug 18 18:45:38.561: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:38.561: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:38.561: INFO: Pod daemon-set-l5qz4 is not available
Aug 18 18:45:39.561: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:39.561: INFO: Wrong image for pod: daemon-set-l5qz4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:39.561: INFO: Pod daemon-set-l5qz4 is not available
Aug 18 18:45:40.560: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:40.560: INFO: Pod daemon-set-k64r7 is not available
Aug 18 18:45:41.561: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:41.561: INFO: Pod daemon-set-k64r7 is not available
Aug 18 18:45:42.561: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:43.560: INFO: Wrong image for pod: daemon-set-7q4hv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Aug 18 18:45:43.560: INFO: Pod daemon-set-7q4hv is not available
Aug 18 18:45:44.561: INFO: Pod daemon-set-g4xlt is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 18 18:45:44.608: INFO: Number of nodes with available pods: 2
Aug 18 18:45:44.608: INFO: Node 10.241.69.184 is running more than one daemon pod
Aug 18 18:45:45.636: INFO: Number of nodes with available pods: 2
Aug 18 18:45:45.636: INFO: Node 10.241.69.184 is running more than one daemon pod
Aug 18 18:45:46.636: INFO: Number of nodes with available pods: 3
Aug 18 18:45:46.636: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4974, will wait for the garbage collector to delete the pods
Aug 18 18:45:46.777: INFO: Deleting DaemonSet.extensions daemon-set took: 25.395322ms
Aug 18 18:45:46.977: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.24716ms
Aug 18 18:45:50.989: INFO: Number of nodes with available pods: 0
Aug 18 18:45:50.989: INFO: Number of running nodes: 0, number of available pods: 0
Aug 18 18:45:50.999: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4974/daemonsets","resourceVersion":"42922"},"items":null}

Aug 18 18:45:51.012: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4974/pods","resourceVersion":"42922"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:45:51.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4974" for this suite.
Aug 18 18:45:59.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:45:59.537: INFO: namespace daemonsets-4974 deletion completed in 8.449022449s

• [SLOW TEST:37.523 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:45:59.537: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1118
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Aug 18 18:45:59.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 create -f - --namespace=kubectl-1118'
Aug 18 18:46:00.142: INFO: stderr: ""
Aug 18 18:46:00.142: INFO: stdout: "pod/pause created\n"
Aug 18 18:46:00.142: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 18 18:46:00.142: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1118" to be "running and ready"
Aug 18 18:46:00.156: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 13.077019ms
Aug 18 18:46:02.168: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.025221869s
Aug 18 18:46:02.168: INFO: Pod "pause" satisfied condition "running and ready"
Aug 18 18:46:02.168: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 18 18:46:02.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 label pods pause testing-label=testing-label-value --namespace=kubectl-1118'
Aug 18 18:46:02.295: INFO: stderr: ""
Aug 18 18:46:02.295: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 18 18:46:02.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pod pause -L testing-label --namespace=kubectl-1118'
Aug 18 18:46:02.404: INFO: stderr: ""
Aug 18 18:46:02.404: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 18 18:46:02.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 label pods pause testing-label- --namespace=kubectl-1118'
Aug 18 18:46:02.530: INFO: stderr: ""
Aug 18 18:46:02.530: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 18 18:46:02.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pod pause -L testing-label --namespace=kubectl-1118'
Aug 18 18:46:02.641: INFO: stderr: ""
Aug 18 18:46:02.641: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Aug 18 18:46:02.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete --grace-period=0 --force -f - --namespace=kubectl-1118'
Aug 18 18:46:02.794: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 18 18:46:02.794: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 18 18:46:02.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get rc,svc -l name=pause --no-headers --namespace=kubectl-1118'
Aug 18 18:46:02.938: INFO: stderr: "No resources found in kubectl-1118 namespace.\n"
Aug 18 18:46:02.938: INFO: stdout: ""
Aug 18 18:46:02.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 get pods -l name=pause --namespace=kubectl-1118 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 18 18:46:03.041: INFO: stderr: ""
Aug 18 18:46:03.041: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:46:03.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1118" for this suite.
Aug 18 18:46:09.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:46:09.517: INFO: namespace kubectl-1118 deletion completed in 6.458574515s

• [SLOW TEST:9.980 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:46:09.518: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5438
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:46:09.751: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Aug 18 18:46:13.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-5438 create -f -'
Aug 18 18:46:14.094: INFO: stderr: ""
Aug 18 18:46:14.094: INFO: stdout: "e2e-test-crd-publish-openapi-4939-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Aug 18 18:46:14.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-5438 delete e2e-test-crd-publish-openapi-4939-crds test-cr'
Aug 18 18:46:14.223: INFO: stderr: ""
Aug 18 18:46:14.224: INFO: stdout: "e2e-test-crd-publish-openapi-4939-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Aug 18 18:46:14.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-5438 apply -f -'
Aug 18 18:46:14.635: INFO: stderr: ""
Aug 18 18:46:14.635: INFO: stdout: "e2e-test-crd-publish-openapi-4939-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Aug 18 18:46:14.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 --namespace=crd-publish-openapi-5438 delete e2e-test-crd-publish-openapi-4939-crds test-cr'
Aug 18 18:46:14.871: INFO: stderr: ""
Aug 18 18:46:14.871: INFO: stdout: "e2e-test-crd-publish-openapi-4939-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Aug 18 18:46:14.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 explain e2e-test-crd-publish-openapi-4939-crds'
Aug 18 18:46:15.207: INFO: stderr: ""
Aug 18 18:46:15.207: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4939-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:46:19.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5438" for this suite.
Aug 18 18:46:25.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:46:25.553: INFO: namespace crd-publish-openapi-5438 deletion completed in 6.469623965s

• [SLOW TEST:16.035 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:46:25.553: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1770
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Aug 18 18:46:25.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-1770'
Aug 18 18:46:25.886: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 18 18:46:25.886: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Aug 18 18:46:27.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 delete deployment e2e-test-httpd-deployment --namespace=kubectl-1770'
Aug 18 18:46:28.044: INFO: stderr: ""
Aug 18 18:46:28.044: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:46:28.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1770" for this suite.
Aug 18 18:46:58.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:46:58.522: INFO: namespace kubectl-1770 deletion completed in 30.455344473s

• [SLOW TEST:32.969 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:46:58.523: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8075
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8075.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8075.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8075.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8075.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8075.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8075.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8075.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8075.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8075.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8075.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8075.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8075.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8075.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 216.184.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.184.216_udp@PTR;check="$$(dig +tcp +noall +answer +search 216.184.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.184.216_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8075.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8075.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8075.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8075.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8075.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8075.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8075.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8075.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8075.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8075.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8075.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8075.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8075.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 216.184.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.184.216_udp@PTR;check="$$(dig +tcp +noall +answer +search 216.184.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.184.216_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 18 18:47:02.912: INFO: Unable to read wheezy_udp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:02.933: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:02.963: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:02.984: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:03.149: INFO: Unable to read jessie_udp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:03.172: INFO: Unable to read jessie_tcp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:03.347: INFO: Lookups using dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac failed for: [wheezy_udp@dns-test-service.dns-8075.svc.cluster.local wheezy_tcp@dns-test-service.dns-8075.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8075.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8075.svc.cluster.local jessie_udp@dns-test-service.dns-8075.svc.cluster.local jessie_tcp@dns-test-service.dns-8075.svc.cluster.local]

Aug 18 18:47:08.369: INFO: Unable to read wheezy_udp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:08.392: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:08.579: INFO: Unable to read jessie_udp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:08.599: INFO: Unable to read jessie_tcp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:08.774: INFO: Lookups using dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac failed for: [wheezy_udp@dns-test-service.dns-8075.svc.cluster.local wheezy_tcp@dns-test-service.dns-8075.svc.cluster.local jessie_udp@dns-test-service.dns-8075.svc.cluster.local jessie_tcp@dns-test-service.dns-8075.svc.cluster.local]

Aug 18 18:47:13.368: INFO: Unable to read wheezy_udp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:13.388: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:13.568: INFO: Unable to read jessie_udp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:13.588: INFO: Unable to read jessie_tcp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:13.752: INFO: Lookups using dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac failed for: [wheezy_udp@dns-test-service.dns-8075.svc.cluster.local wheezy_tcp@dns-test-service.dns-8075.svc.cluster.local jessie_udp@dns-test-service.dns-8075.svc.cluster.local jessie_tcp@dns-test-service.dns-8075.svc.cluster.local]

Aug 18 18:47:18.367: INFO: Unable to read wheezy_udp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:18.387: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:18.576: INFO: Unable to read jessie_udp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:18.597: INFO: Unable to read jessie_tcp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:18.757: INFO: Lookups using dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac failed for: [wheezy_udp@dns-test-service.dns-8075.svc.cluster.local wheezy_tcp@dns-test-service.dns-8075.svc.cluster.local jessie_udp@dns-test-service.dns-8075.svc.cluster.local jessie_tcp@dns-test-service.dns-8075.svc.cluster.local]

Aug 18 18:47:23.371: INFO: Unable to read wheezy_udp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:23.393: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:23.586: INFO: Unable to read jessie_udp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:23.606: INFO: Unable to read jessie_tcp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:23.781: INFO: Lookups using dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac failed for: [wheezy_udp@dns-test-service.dns-8075.svc.cluster.local wheezy_tcp@dns-test-service.dns-8075.svc.cluster.local jessie_udp@dns-test-service.dns-8075.svc.cluster.local jessie_tcp@dns-test-service.dns-8075.svc.cluster.local]

Aug 18 18:47:28.368: INFO: Unable to read wheezy_udp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:28.388: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:28.574: INFO: Unable to read jessie_udp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:28.593: INFO: Unable to read jessie_tcp@dns-test-service.dns-8075.svc.cluster.local from pod dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac: the server could not find the requested resource (get pods dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac)
Aug 18 18:47:28.770: INFO: Lookups using dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac failed for: [wheezy_udp@dns-test-service.dns-8075.svc.cluster.local wheezy_tcp@dns-test-service.dns-8075.svc.cluster.local jessie_udp@dns-test-service.dns-8075.svc.cluster.local jessie_tcp@dns-test-service.dns-8075.svc.cluster.local]

Aug 18 18:47:33.763: INFO: DNS probes using dns-8075/dns-test-67e57eb9-410b-4b1e-b48e-f4100307a4ac succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:47:33.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8075" for this suite.
Aug 18 18:47:42.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:47:42.430: INFO: namespace dns-8075 deletion completed in 8.468966037s

• [SLOW TEST:43.907 seconds]
[sig-network] DNS
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:47:42.431: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7404
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:47:58.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7404" for this suite.
Aug 18 18:48:04.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:48:05.339: INFO: namespace resourcequota-7404 deletion completed in 6.498122741s

• [SLOW TEST:22.909 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:48:05.339: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9934
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:48:05.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 version'
Aug 18 18:48:05.658: INFO: stderr: ""
Aug 18 18:48:05.658: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.14\", GitCommit:\"d2a081c8e14e21e28fe5bdfa38a817ef9c0bb8e3\", GitTreeState:\"clean\", BuildDate:\"2020-08-13T12:33:34Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.14+IKS\", GitCommit:\"cf9cde26330f5799debb3f1564984d0406d23c40\", GitTreeState:\"clean\", BuildDate:\"2020-08-13T19:41:39Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:48:05.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9934" for this suite.
Aug 18 18:48:11.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:48:12.179: INFO: namespace kubectl-9934 deletion completed in 6.497132068s

• [SLOW TEST:6.839 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:48:12.179: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7871
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 18 18:48:16.547: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 18 18:48:16.561: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 18 18:48:18.562: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 18 18:48:18.573: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 18 18:48:20.562: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 18 18:48:20.574: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:48:20.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7871" for this suite.
Aug 18 18:48:32.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:48:33.159: INFO: namespace container-lifecycle-hook-7871 deletion completed in 12.506503656s

• [SLOW TEST:20.980 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:48:33.163: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8567
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:48:33.385: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:48:33.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8567" for this suite.
Aug 18 18:48:40.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:48:40.482: INFO: namespace custom-resource-definition-8567 deletion completed in 6.451669083s

• [SLOW TEST:7.319 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:48:40.486: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2927
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Aug 18 18:48:50.798: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W0818 18:48:50.798031      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 18 18:48:50.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2927" for this suite.
Aug 18 18:48:58.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:48:59.299: INFO: namespace gc-2927 deletion completed in 8.479325717s

• [SLOW TEST:18.812 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:48:59.301: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9235
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Aug 18 18:49:01.600: INFO: Pod pod-hostip-4496e94e-2c82-4202-8466-91219761b013 has hostIP: 10.241.69.172
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:49:01.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9235" for this suite.
Aug 18 18:49:31.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:49:32.091: INFO: namespace pods-9235 deletion completed in 30.473309787s

• [SLOW TEST:32.790 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:49:32.092: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5915
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-vv2h
STEP: Creating a pod to test atomic-volume-subpath
Aug 18 18:49:32.370: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-vv2h" in namespace "subpath-5915" to be "success or failure"
Aug 18 18:49:32.380: INFO: Pod "pod-subpath-test-downwardapi-vv2h": Phase="Pending", Reason="", readiness=false. Elapsed: 10.527223ms
Aug 18 18:49:34.393: INFO: Pod "pod-subpath-test-downwardapi-vv2h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023027913s
Aug 18 18:49:36.407: INFO: Pod "pod-subpath-test-downwardapi-vv2h": Phase="Running", Reason="", readiness=true. Elapsed: 4.037522091s
Aug 18 18:49:38.419: INFO: Pod "pod-subpath-test-downwardapi-vv2h": Phase="Running", Reason="", readiness=true. Elapsed: 6.049948028s
Aug 18 18:49:40.431: INFO: Pod "pod-subpath-test-downwardapi-vv2h": Phase="Running", Reason="", readiness=true. Elapsed: 8.061223372s
Aug 18 18:49:42.443: INFO: Pod "pod-subpath-test-downwardapi-vv2h": Phase="Running", Reason="", readiness=true. Elapsed: 10.073748255s
Aug 18 18:49:44.457: INFO: Pod "pod-subpath-test-downwardapi-vv2h": Phase="Running", Reason="", readiness=true. Elapsed: 12.087125288s
Aug 18 18:49:46.468: INFO: Pod "pod-subpath-test-downwardapi-vv2h": Phase="Running", Reason="", readiness=true. Elapsed: 14.098667518s
Aug 18 18:49:48.480: INFO: Pod "pod-subpath-test-downwardapi-vv2h": Phase="Running", Reason="", readiness=true. Elapsed: 16.110348464s
Aug 18 18:49:50.491: INFO: Pod "pod-subpath-test-downwardapi-vv2h": Phase="Running", Reason="", readiness=true. Elapsed: 18.121411322s
Aug 18 18:49:52.502: INFO: Pod "pod-subpath-test-downwardapi-vv2h": Phase="Running", Reason="", readiness=true. Elapsed: 20.132728394s
Aug 18 18:49:54.516: INFO: Pod "pod-subpath-test-downwardapi-vv2h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.14660963s
STEP: Saw pod success
Aug 18 18:49:54.516: INFO: Pod "pod-subpath-test-downwardapi-vv2h" satisfied condition "success or failure"
Aug 18 18:49:54.526: INFO: Trying to get logs from node 10.241.69.172 pod pod-subpath-test-downwardapi-vv2h container test-container-subpath-downwardapi-vv2h: <nil>
STEP: delete the pod
Aug 18 18:49:54.619: INFO: Waiting for pod pod-subpath-test-downwardapi-vv2h to disappear
Aug 18 18:49:54.628: INFO: Pod pod-subpath-test-downwardapi-vv2h no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-vv2h
Aug 18 18:49:54.628: INFO: Deleting pod "pod-subpath-test-downwardapi-vv2h" in namespace "subpath-5915"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:49:54.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5915" for this suite.
Aug 18 18:50:00.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:50:01.131: INFO: namespace subpath-5915 deletion completed in 6.466790193s

• [SLOW TEST:29.039 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:50:01.131: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7289
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Aug 18 18:50:06.003: INFO: Successfully updated pod "labelsupdate4252ee4d-c001-4571-b198-35a9a5b09acf"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:50:08.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7289" for this suite.
Aug 18 18:50:22.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:50:22.559: INFO: namespace downward-api-7289 deletion completed in 14.472811185s

• [SLOW TEST:21.427 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:50:22.559: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2100
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-14cb83dc-2bee-488b-8a14-9380a736420f in namespace container-probe-2100
Aug 18 18:50:24.840: INFO: Started pod busybox-14cb83dc-2bee-488b-8a14-9380a736420f in namespace container-probe-2100
STEP: checking the pod's current state and verifying that restartCount is present
Aug 18 18:50:24.850: INFO: Initial restart count of pod busybox-14cb83dc-2bee-488b-8a14-9380a736420f is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:54:26.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2100" for this suite.
Aug 18 18:54:32.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:54:33.335: INFO: namespace container-probe-2100 deletion completed in 6.488515375s

• [SLOW TEST:250.776 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:54:33.335: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1292
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-1741c97f-c5e5-4e19-aeb8-e29a0515ef64
STEP: Creating secret with name s-test-opt-upd-f835fb84-0ae4-40d6-84ba-6fdf8adcdade
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1741c97f-c5e5-4e19-aeb8-e29a0515ef64
STEP: Updating secret s-test-opt-upd-f835fb84-0ae4-40d6-84ba-6fdf8adcdade
STEP: Creating secret with name s-test-opt-create-2883f83f-a4d3-4ede-a0ac-b981f2bd3200
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:56:07.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1292" for this suite.
Aug 18 18:56:23.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:56:23.784: INFO: namespace projected-1292 deletion completed in 16.543902423s

• [SLOW TEST:110.449 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:56:23.785: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-976
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Aug 18 18:56:24.004: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 18 18:57:24.142: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:57:24.154: INFO: Starting informer...
STEP: Starting pod...
Aug 18 18:57:24.403: INFO: Pod is running on 10.241.69.172. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Aug 18 18:57:24.437: INFO: Pod wasn't evicted. Proceeding
Aug 18 18:57:24.438: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Aug 18 18:58:39.471: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:58:39.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-976" for this suite.
Aug 18 18:58:51.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:58:51.928: INFO: namespace taint-single-pod-976 deletion completed in 12.44395946s

• [SLOW TEST:148.144 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:58:51.935: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8341
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 18:58:52.783: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Aug 18 18:58:54.821: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733373932, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733373932, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733373932, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733373932, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 18:58:57.881: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:58:57.894: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1080-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:58:59.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8341" for this suite.
Aug 18 18:59:07.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:59:07.853: INFO: namespace webhook-8341 deletion completed in 8.488680852s
STEP: Destroying namespace "webhook-8341-markers" for this suite.
Aug 18 18:59:13.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:59:14.321: INFO: namespace webhook-8341-markers deletion completed in 6.467116784s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.448 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:59:14.383: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8439
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 18 18:59:14.625: INFO: Waiting up to 5m0s for pod "pod-f353ec73-84ac-4456-8394-e820340459b9" in namespace "emptydir-8439" to be "success or failure"
Aug 18 18:59:14.641: INFO: Pod "pod-f353ec73-84ac-4456-8394-e820340459b9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.522163ms
Aug 18 18:59:16.653: INFO: Pod "pod-f353ec73-84ac-4456-8394-e820340459b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028223461s
STEP: Saw pod success
Aug 18 18:59:16.653: INFO: Pod "pod-f353ec73-84ac-4456-8394-e820340459b9" satisfied condition "success or failure"
Aug 18 18:59:16.665: INFO: Trying to get logs from node 10.241.69.172 pod pod-f353ec73-84ac-4456-8394-e820340459b9 container test-container: <nil>
STEP: delete the pod
Aug 18 18:59:16.756: INFO: Waiting for pod pod-f353ec73-84ac-4456-8394-e820340459b9 to disappear
Aug 18 18:59:16.774: INFO: Pod pod-f353ec73-84ac-4456-8394-e820340459b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:59:16.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8439" for this suite.
Aug 18 18:59:22.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:59:23.387: INFO: namespace emptydir-8439 deletion completed in 6.587003113s

• [SLOW TEST:9.004 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:59:23.387: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1535
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:59:34.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1535" for this suite.
Aug 18 18:59:40.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:59:41.241: INFO: namespace resourcequota-1535 deletion completed in 6.483865399s

• [SLOW TEST:17.854 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:59:41.242: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-4424
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Aug 18 18:59:42.239: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Aug 18 18:59:44.277: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733373982, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733373982, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733373982, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733373982, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 18:59:47.327: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:59:47.339: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 18:59:48.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4424" for this suite.
Aug 18 18:59:56.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 18:59:56.672: INFO: namespace crd-webhook-4424 deletion completed in 8.465560349s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:15.503 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 18:59:56.744: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5384
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 18:59:56.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 create -f - --namespace=kubectl-5384'
Aug 18 18:59:57.361: INFO: stderr: ""
Aug 18 18:59:57.361: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug 18 18:59:57.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 create -f - --namespace=kubectl-5384'
Aug 18 18:59:57.601: INFO: stderr: ""
Aug 18 18:59:57.601: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 18 18:59:58.614: INFO: Selector matched 1 pods for map[app:redis]
Aug 18 18:59:58.614: INFO: Found 0 / 1
Aug 18 18:59:59.613: INFO: Selector matched 1 pods for map[app:redis]
Aug 18 18:59:59.613: INFO: Found 1 / 1
Aug 18 18:59:59.613: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 18 18:59:59.624: INFO: Selector matched 1 pods for map[app:redis]
Aug 18 18:59:59.624: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 18 18:59:59.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 describe pod redis-master-v6xmk --namespace=kubectl-5384'
Aug 18 18:59:59.784: INFO: stderr: ""
Aug 18 18:59:59.784: INFO: stdout: "Name:         redis-master-v6xmk\nNamespace:    kubectl-5384\nPriority:     0\nNode:         10.241.69.172/10.241.69.172\nStart Time:   Tue, 18 Aug 2020 18:59:57 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           172.30.104.170\nIPs:\n  IP:           172.30.104.170\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://6417ad423fab0440694017efd9ab32d35d30ab5b1641fe39421ac7426946b4b9\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 18 Aug 2020 18:59:58 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vk4kv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-vk4kv:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-vk4kv\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age   From                    Message\n  ----    ------     ----  ----                    -------\n  Normal  Scheduled  2s    default-scheduler       Successfully assigned kubectl-5384/redis-master-v6xmk to 10.241.69.172\n  Normal  Pulled     1s    kubelet, 10.241.69.172  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s    kubelet, 10.241.69.172  Created container redis-master\n  Normal  Started    1s    kubelet, 10.241.69.172  Started container redis-master\n"
Aug 18 18:59:59.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 describe rc redis-master --namespace=kubectl-5384'
Aug 18 18:59:59.946: INFO: stderr: ""
Aug 18 18:59:59.946: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-5384\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-v6xmk\n"
Aug 18 18:59:59.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 describe service redis-master --namespace=kubectl-5384'
Aug 18 19:00:00.132: INFO: stderr: ""
Aug 18 19:00:00.132: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-5384\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.220.94\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.104.170:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 18 19:00:00.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 describe node 10.241.69.172'
Aug 18 19:00:00.335: INFO: stderr: ""
Aug 18 19:00:00.335: INFO: stdout: "Name:               10.241.69.172\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-south\n                    failure-domain.beta.kubernetes.io/zone=dal12\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=169.59.196.52\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.241.69.172\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=us-south\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-bstv5sqd0r3kmi9abm0g-kubee2epvg2-default-00000329\n                    ibm-cloud.kubernetes.io/worker-pool-id=bstv5sqd0r3kmi9abm0g-a33f49b\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.16.14_1544\n                    ibm-cloud.kubernetes.io/zone=dal12\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.241.69.172\n                    kubernetes.io/os=linux\n                    privateVLAN=2722938\n                    publicVLAN=2722936\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 18 Aug 2020 15:45:11 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 18 Aug 2020 18:59:45 +0000   Tue, 18 Aug 2020 15:45:11 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 18 Aug 2020 18:59:45 +0000   Tue, 18 Aug 2020 15:45:11 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 18 Aug 2020 18:59:45 +0000   Tue, 18 Aug 2020 15:45:11 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 18 Aug 2020 18:59:45 +0000   Tue, 18 Aug 2020 15:45:21 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.241.69.172\n  ExternalIP:  169.59.196.52\n  Hostname:    10.241.69.172\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419664Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627216Ki\n pods:               110\nSystem Info:\n Machine ID:                 7212cbfd51d54d9bb8c081657f781acf\n System UUID:                9AABC880-E957-6D76-BC76-7F3329CB9AC2\n Boot ID:                    346cba86-4dd2-4949-971e-77974ac0de71\n Kernel Version:             4.15.0-112-generic\n OS Image:                   Ubuntu 18.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.3.4\n Kubelet Version:            v1.16.14+IKS\n Kube-Proxy Version:         v1.16.14+IKS\nProviderID:                  ibm://fee034388aa6435883a1f720010ab3a2///bstv5sqd0r3kmi9abm0g/kube-bstv5sqd0r3kmi9abm0g-kubee2epvg2-default-00000329\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  ibm-system                 addon-catalog-source-gmd49                                 10m (0%)      100m (2%)   50Mi (0%)        100Mi (0%)     3h14m\n  kube-system                calico-node-sz9mb                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         3h14m\n  kube-system                ibm-keepalived-watcher-2f6fp                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         3h14m\n  kube-system                ibm-master-proxy-static-10.241.69.172                      25m (0%)      300m (7%)   32M (0%)         512M (3%)      3h14m\n  kubectl-5384               redis-master-v6xmk                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-m29th    0 (0%)        0 (0%)      0 (0%)           0 (0%)         111m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                290m (7%)      400m (10%)\n  memory             174610Ki (1%)  602400Ki (4%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Aug 18 19:00:00.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 describe namespace kubectl-5384'
Aug 18 19:00:00.469: INFO: stderr: ""
Aug 18 19:00:00.469: INFO: stdout: "Name:         kubectl-5384\nLabels:       e2e-framework=kubectl\n              e2e-run=1c079d05-ffe1-4524-ac00-98c48b911240\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:00:00.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5384" for this suite.
Aug 18 19:00:12.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:00:13.132: INFO: namespace kubectl-5384 deletion completed in 12.640418376s

• [SLOW TEST:16.388 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:00:13.133: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2857
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Aug 18 19:00:13.371: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 18 19:00:13.488: INFO: Waiting for terminating namespaces to be deleted...
Aug 18 19:00:13.502: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.172 before test
Aug 18 19:00:13.553: INFO: ibm-keepalived-watcher-2f6fp from kube-system started at 2020-08-18 15:45:12 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.553: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 19:00:13.553: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-m29th from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 19:00:13.553: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 18 19:00:13.553: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 19:00:13.553: INFO: ibm-master-proxy-static-10.241.69.172 from kube-system started at 2020-08-18 15:45:10 +0000 UTC (2 container statuses recorded)
Aug 18 19:00:13.553: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 19:00:13.553: INFO: 	Container pause ready: true, restart count 0
Aug 18 19:00:13.553: INFO: calico-node-sz9mb from kube-system started at 2020-08-18 15:45:12 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.553: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 19:00:13.553: INFO: addon-catalog-source-gmd49 from ibm-system started at 2020-08-18 15:45:49 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.553: INFO: 	Container configmap-registry-server ready: true, restart count 0
Aug 18 19:00:13.553: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.181 before test
Aug 18 19:00:13.667: INFO: ibm-keepalived-watcher-kr9tn from kube-system started at 2020-08-18 15:50:03 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.667: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 19:00:13.667: INFO: olm-operator-6f74dfc868-28t4m from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.667: INFO: 	Container olm-operator ready: true, restart count 0
Aug 18 19:00:13.667: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-rwtzr from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 19:00:13.667: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 18 19:00:13.667: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 19:00:13.667: INFO: coredns-55db5d97fb-8tfqf from kube-system started at 2020-08-18 15:57:41 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.667: INFO: 	Container coredns ready: true, restart count 0
Aug 18 19:00:13.667: INFO: sonobuoy-e2e-job-692caab668c14a3b from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 19:00:13.667: INFO: 	Container e2e ready: true, restart count 0
Aug 18 19:00:13.667: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 18 19:00:13.667: INFO: kubernetes-dashboard-85b945ff4b-9cklr from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.667: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 18 19:00:13.667: INFO: public-crbstv5sqd0r3kmi9abm0g-alb1-5f59ffb4c7-4k6xv from kube-system started at 2020-08-18 17:21:45 +0000 UTC (4 container statuses recorded)
Aug 18 19:00:13.667: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 18 19:00:13.667: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 18 19:00:13.667: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 18 19:00:13.667: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 18 19:00:13.667: INFO: calico-node-vn5q9 from kube-system started at 2020-08-18 15:50:03 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.668: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 19:00:13.668: INFO: sonobuoy from sonobuoy started at 2020-08-18 17:08:11 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.668: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 18 19:00:13.668: INFO: coredns-autoscaler-65c89858bf-q6hj7 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.668: INFO: 	Container autoscaler ready: true, restart count 0
Aug 18 19:00:13.668: INFO: dashboard-metrics-scraper-76756886dc-rk2k2 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.668: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Aug 18 19:00:13.668: INFO: ibm-cloud-provider-ip-169-47-71-114-64b8d74dd8-8brdn from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.668: INFO: 	Container ibm-cloud-provider-ip-169-47-71-114 ready: true, restart count 0
Aug 18 19:00:13.668: INFO: ibm-master-proxy-static-10.241.69.181 from kube-system started at 2020-08-18 15:49:51 +0000 UTC (2 container statuses recorded)
Aug 18 19:00:13.668: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 19:00:13.668: INFO: 	Container pause ready: true, restart count 0
Aug 18 19:00:13.668: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-08-18 15:52:42 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.668: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Aug 18 19:00:13.668: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.184 before test
Aug 18 19:00:13.766: INFO: coredns-55db5d97fb-2h7nb from kube-system started at 2020-08-18 15:57:41 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.766: INFO: 	Container coredns ready: true, restart count 0
Aug 18 19:00:13.766: INFO: sonobuoy-systemd-logs-daemon-set-36b2b2ac5c334f54-ctchp from sonobuoy started at 2020-08-18 17:08:17 +0000 UTC (2 container statuses recorded)
Aug 18 19:00:13.766: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 18 19:00:13.766: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 18 19:00:13.766: INFO: ibm-storage-watcher-5685787df4-w25gd from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.766: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug 18 19:00:13.766: INFO: ibm-master-proxy-static-10.241.69.184 from kube-system started at 2020-08-18 15:46:23 +0000 UTC (2 container statuses recorded)
Aug 18 19:00:13.766: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 18 19:00:13.766: INFO: 	Container pause ready: true, restart count 0
Aug 18 19:00:13.766: INFO: calico-node-f56nz from kube-system started at 2020-08-18 15:46:36 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.766: INFO: 	Container calico-node ready: true, restart count 0
Aug 18 19:00:13.766: INFO: calico-kube-controllers-66c5f69b5f-9qvwh from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.766: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 18 19:00:13.766: INFO: catalog-operator-67cbc5d959-hqgh5 from ibm-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.766: INFO: 	Container catalog-operator ready: true, restart count 0
Aug 18 19:00:13.766: INFO: ibm-keepalived-watcher-xt8rx from kube-system started at 2020-08-18 15:46:36 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.766: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 18 19:00:13.766: INFO: public-crbstv5sqd0r3kmi9abm0g-alb1-5f59ffb4c7-s8vcr from kube-system started at 2020-08-18 15:48:16 +0000 UTC (4 container statuses recorded)
Aug 18 19:00:13.766: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 18 19:00:13.767: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 18 19:00:13.767: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 18 19:00:13.767: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 18 19:00:13.767: INFO: ibm-file-plugin-7c6788b5f5-ldfzf from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.767: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug 18 19:00:13.767: INFO: coredns-55db5d97fb-cqx5b from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.767: INFO: 	Container coredns ready: true, restart count 0
Aug 18 19:00:13.767: INFO: ibm-cloud-provider-ip-169-47-71-114-64b8d74dd8-dc47l from ibm-system started at 2020-08-18 15:46:51 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.767: INFO: 	Container ibm-cloud-provider-ip-169-47-71-114 ready: true, restart count 0
Aug 18 19:00:13.767: INFO: vpn-79845b6f9d-wmz87 from kube-system started at 2020-08-18 17:21:45 +0000 UTC (1 container statuses recorded)
Aug 18 19:00:13.767: INFO: 	Container vpn ready: true, restart count 0
Aug 18 19:00:13.767: INFO: metrics-server-695ffd979-8z2wt from kube-system started at 2020-08-18 17:21:45 +0000 UTC (2 container statuses recorded)
Aug 18 19:00:13.767: INFO: 	Container metrics-server ready: true, restart count 0
Aug 18 19:00:13.767: INFO: 	Container metrics-server-nanny ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f139008a-b3ac-49f2-9802-1af118fc18aa 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-f139008a-b3ac-49f2-9802-1af118fc18aa off the node 10.241.69.172
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f139008a-b3ac-49f2-9802-1af118fc18aa
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:05:18.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2857" for this suite.
Aug 18 19:05:34.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:05:34.575: INFO: namespace sched-pred-2857 deletion completed in 16.525898667s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:321.443 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:05:34.576: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7891
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Aug 18 19:05:34.833: INFO: Waiting up to 5m0s for pod "var-expansion-15b53c9b-6653-4079-a406-c121eb4d47f1" in namespace "var-expansion-7891" to be "success or failure"
Aug 18 19:05:34.853: INFO: Pod "var-expansion-15b53c9b-6653-4079-a406-c121eb4d47f1": Phase="Pending", Reason="", readiness=false. Elapsed: 19.605214ms
Aug 18 19:05:36.864: INFO: Pod "var-expansion-15b53c9b-6653-4079-a406-c121eb4d47f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031369448s
STEP: Saw pod success
Aug 18 19:05:36.865: INFO: Pod "var-expansion-15b53c9b-6653-4079-a406-c121eb4d47f1" satisfied condition "success or failure"
Aug 18 19:05:36.876: INFO: Trying to get logs from node 10.241.69.172 pod var-expansion-15b53c9b-6653-4079-a406-c121eb4d47f1 container dapi-container: <nil>
STEP: delete the pod
Aug 18 19:05:36.968: INFO: Waiting for pod var-expansion-15b53c9b-6653-4079-a406-c121eb4d47f1 to disappear
Aug 18 19:05:36.979: INFO: Pod var-expansion-15b53c9b-6653-4079-a406-c121eb4d47f1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:05:36.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7891" for this suite.
Aug 18 19:05:43.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:05:43.464: INFO: namespace var-expansion-7891 deletion completed in 6.464776992s

• [SLOW TEST:8.888 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:05:43.466: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6061
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-6061/secret-test-1912fb6f-8880-45c7-8d79-e5ea95592bda
STEP: Creating a pod to test consume secrets
Aug 18 19:05:43.734: INFO: Waiting up to 5m0s for pod "pod-configmaps-a8518fb7-0d80-4c22-b7d5-ce95c1249d63" in namespace "secrets-6061" to be "success or failure"
Aug 18 19:05:43.745: INFO: Pod "pod-configmaps-a8518fb7-0d80-4c22-b7d5-ce95c1249d63": Phase="Pending", Reason="", readiness=false. Elapsed: 10.585214ms
Aug 18 19:05:45.757: INFO: Pod "pod-configmaps-a8518fb7-0d80-4c22-b7d5-ce95c1249d63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022723145s
Aug 18 19:05:47.770: INFO: Pod "pod-configmaps-a8518fb7-0d80-4c22-b7d5-ce95c1249d63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035052025s
STEP: Saw pod success
Aug 18 19:05:47.770: INFO: Pod "pod-configmaps-a8518fb7-0d80-4c22-b7d5-ce95c1249d63" satisfied condition "success or failure"
Aug 18 19:05:47.781: INFO: Trying to get logs from node 10.241.69.172 pod pod-configmaps-a8518fb7-0d80-4c22-b7d5-ce95c1249d63 container env-test: <nil>
STEP: delete the pod
Aug 18 19:05:47.849: INFO: Waiting for pod pod-configmaps-a8518fb7-0d80-4c22-b7d5-ce95c1249d63 to disappear
Aug 18 19:05:47.860: INFO: Pod pod-configmaps-a8518fb7-0d80-4c22-b7d5-ce95c1249d63 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:05:47.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6061" for this suite.
Aug 18 19:05:53.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:05:54.356: INFO: namespace secrets-6061 deletion completed in 6.477328804s

• [SLOW TEST:10.890 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:05:54.356: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7361
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 19:05:54.578: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:05:56.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7361" for this suite.
Aug 18 19:06:42.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:06:43.259: INFO: namespace pods-7361 deletion completed in 46.477266039s

• [SLOW TEST:48.904 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:06:43.260: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9268
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:06:50.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9268" for this suite.
Aug 18 19:06:56.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:06:57.317: INFO: namespace resourcequota-9268 deletion completed in 6.765819968s

• [SLOW TEST:14.057 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:06:57.317: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4199
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-2cdb32c0-a1a5-4810-8c44-c16d2ba2adab
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:06:57.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4199" for this suite.
Aug 18 19:07:03.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:07:04.032: INFO: namespace secrets-4199 deletion completed in 6.466001077s

• [SLOW TEST:6.715 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:07:04.033: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5602
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Aug 18 19:07:04.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 create -f - --namespace=kubectl-5602'
Aug 18 19:07:04.592: INFO: stderr: ""
Aug 18 19:07:04.592: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 18 19:07:05.604: INFO: Selector matched 1 pods for map[app:redis]
Aug 18 19:07:05.604: INFO: Found 0 / 1
Aug 18 19:07:06.606: INFO: Selector matched 1 pods for map[app:redis]
Aug 18 19:07:06.606: INFO: Found 1 / 1
Aug 18 19:07:06.606: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 18 19:07:06.620: INFO: Selector matched 1 pods for map[app:redis]
Aug 18 19:07:06.620: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 18 19:07:06.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434562375 patch pod redis-master-4tt2w --namespace=kubectl-5602 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 18 19:07:06.750: INFO: stderr: ""
Aug 18 19:07:06.750: INFO: stdout: "pod/redis-master-4tt2w patched\n"
STEP: checking annotations
Aug 18 19:07:06.763: INFO: Selector matched 1 pods for map[app:redis]
Aug 18 19:07:06.763: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:07:06.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5602" for this suite.
Aug 18 19:07:18.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:07:19.242: INFO: namespace kubectl-5602 deletion completed in 12.45168148s

• [SLOW TEST:15.209 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:07:19.242: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2712
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Aug 18 19:07:19.462: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-434562375 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:07:19.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2712" for this suite.
Aug 18 19:07:25.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:07:26.034: INFO: namespace kubectl-2712 deletion completed in 6.451446236s

• [SLOW TEST:6.792 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:07:26.035: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9766
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 19:07:26.264: INFO: Creating ReplicaSet my-hostname-basic-39e71c14-b0a3-483a-9e2a-355c9316989f
Aug 18 19:07:26.287: INFO: Pod name my-hostname-basic-39e71c14-b0a3-483a-9e2a-355c9316989f: Found 0 pods out of 1
Aug 18 19:07:31.312: INFO: Pod name my-hostname-basic-39e71c14-b0a3-483a-9e2a-355c9316989f: Found 1 pods out of 1
Aug 18 19:07:31.312: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-39e71c14-b0a3-483a-9e2a-355c9316989f" is running
Aug 18 19:07:31.323: INFO: Pod "my-hostname-basic-39e71c14-b0a3-483a-9e2a-355c9316989f-9kxlw" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-18 19:07:26 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-18 19:07:28 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-18 19:07:28 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-08-18 19:07:26 +0000 UTC Reason: Message:}])
Aug 18 19:07:31.323: INFO: Trying to dial the pod
Aug 18 19:07:36.378: INFO: Controller my-hostname-basic-39e71c14-b0a3-483a-9e2a-355c9316989f: Got expected result from replica 1 [my-hostname-basic-39e71c14-b0a3-483a-9e2a-355c9316989f-9kxlw]: "my-hostname-basic-39e71c14-b0a3-483a-9e2a-355c9316989f-9kxlw", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:07:36.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9766" for this suite.
Aug 18 19:07:42.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:07:42.864: INFO: namespace replicaset-9766 deletion completed in 6.465449047s

• [SLOW TEST:16.829 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:07:42.865: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8692
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:07:48.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8692" for this suite.
Aug 18 19:08:18.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:08:18.703: INFO: namespace replication-controller-8692 deletion completed in 30.484842655s

• [SLOW TEST:35.839 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:08:18.704: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5875
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 19:08:19.649: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 19:08:22.742: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:08:33.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5875" for this suite.
Aug 18 19:08:41.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:08:41.730: INFO: namespace webhook-5875 deletion completed in 8.461858879s
STEP: Destroying namespace "webhook-5875-markers" for this suite.
Aug 18 19:08:47.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:08:48.208: INFO: namespace webhook-5875-markers deletion completed in 6.478119515s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:29.569 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:08:48.274: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8612
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Aug 18 19:08:51.084: INFO: Successfully updated pod "adopt-release-6bvk7"
STEP: Checking that the Job readopts the Pod
Aug 18 19:08:51.084: INFO: Waiting up to 15m0s for pod "adopt-release-6bvk7" in namespace "job-8612" to be "adopted"
Aug 18 19:08:51.095: INFO: Pod "adopt-release-6bvk7": Phase="Running", Reason="", readiness=true. Elapsed: 11.192501ms
Aug 18 19:08:53.107: INFO: Pod "adopt-release-6bvk7": Phase="Running", Reason="", readiness=true. Elapsed: 2.023233509s
Aug 18 19:08:53.107: INFO: Pod "adopt-release-6bvk7" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Aug 18 19:08:53.635: INFO: Successfully updated pod "adopt-release-6bvk7"
STEP: Checking that the Job releases the Pod
Aug 18 19:08:53.636: INFO: Waiting up to 15m0s for pod "adopt-release-6bvk7" in namespace "job-8612" to be "released"
Aug 18 19:08:53.652: INFO: Pod "adopt-release-6bvk7": Phase="Running", Reason="", readiness=true. Elapsed: 16.299788ms
Aug 18 19:08:53.652: INFO: Pod "adopt-release-6bvk7" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:08:53.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8612" for this suite.
Aug 18 19:09:41.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:09:42.174: INFO: namespace job-8612 deletion completed in 48.498857181s

• [SLOW TEST:53.900 seconds]
[sig-apps] Job
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:09:42.176: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2712
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Aug 18 19:09:42.436: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-14393742-c23c-4cad-8a16-64e3809714c8" in namespace "security-context-test-2712" to be "success or failure"
Aug 18 19:09:42.451: INFO: Pod "busybox-readonly-false-14393742-c23c-4cad-8a16-64e3809714c8": Phase="Pending", Reason="", readiness=false. Elapsed: 15.018526ms
Aug 18 19:09:44.462: INFO: Pod "busybox-readonly-false-14393742-c23c-4cad-8a16-64e3809714c8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026622097s
Aug 18 19:09:46.474: INFO: Pod "busybox-readonly-false-14393742-c23c-4cad-8a16-64e3809714c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038289035s
Aug 18 19:09:46.474: INFO: Pod "busybox-readonly-false-14393742-c23c-4cad-8a16-64e3809714c8" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:09:46.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2712" for this suite.
Aug 18 19:09:52.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:09:53.079: INFO: namespace security-context-test-2712 deletion completed in 6.580895039s

• [SLOW TEST:10.903 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:09:53.079: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4154
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-58ce5b8b-014f-4840-a0da-3359a8873006
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:09:53.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4154" for this suite.
Aug 18 19:09:59.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:09:59.822: INFO: namespace configmap-4154 deletion completed in 6.479637798s

• [SLOW TEST:6.742 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:09:59.823: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6988
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 19:10:00.671: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 18 19:10:02.713: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733374600, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733374600, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63733374600, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63733374600, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 19:10:05.769: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:10:18.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6988" for this suite.
Aug 18 19:10:26.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:10:26.752: INFO: namespace webhook-6988 deletion completed in 8.484340285s
STEP: Destroying namespace "webhook-6988-markers" for this suite.
Aug 18 19:10:32.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:10:33.234: INFO: namespace webhook-6988-markers deletion completed in 6.482322955s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:33.474 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:10:33.298: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-500
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1783
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3108
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:10:40.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-500" for this suite.
Aug 18 19:10:46.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:10:46.597: INFO: namespace namespaces-500 deletion completed in 6.531921932s
STEP: Destroying namespace "nsdeletetest-1783" for this suite.
Aug 18 19:10:46.608: INFO: Namespace nsdeletetest-1783 was already deleted
STEP: Destroying namespace "nsdeletetest-3108" for this suite.
Aug 18 19:10:52.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:10:53.082: INFO: namespace nsdeletetest-3108 deletion completed in 6.474180936s

• [SLOW TEST:19.785 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:10:53.083: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9589
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 18 19:10:54.153: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 18 19:10:57.232: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Aug 18 19:10:57.309: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:10:57.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9589" for this suite.
Aug 18 19:11:05.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:11:05.867: INFO: namespace webhook-9589 deletion completed in 8.475352769s
STEP: Destroying namespace "webhook-9589-markers" for this suite.
Aug 18 19:11:11.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:11:12.333: INFO: namespace webhook-9589-markers deletion completed in 6.466281231s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.311 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:11:12.396: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9097
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 18 19:11:15.702: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:11:15.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9097" for this suite.
Aug 18 19:11:21.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:11:22.274: INFO: namespace container-runtime-9097 deletion completed in 6.498108572s

• [SLOW TEST:9.878 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:11:22.274: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6299
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-1be27292-58d2-4df8-8a9e-e0989ae7d0d6
STEP: Creating a pod to test consume configMaps
Aug 18 19:11:22.527: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e68ecf7e-d5e0-4c4a-8be4-dfc00ac717bd" in namespace "projected-6299" to be "success or failure"
Aug 18 19:11:22.550: INFO: Pod "pod-projected-configmaps-e68ecf7e-d5e0-4c4a-8be4-dfc00ac717bd": Phase="Pending", Reason="", readiness=false. Elapsed: 23.221465ms
Aug 18 19:11:24.564: INFO: Pod "pod-projected-configmaps-e68ecf7e-d5e0-4c4a-8be4-dfc00ac717bd": Phase="Running", Reason="", readiness=true. Elapsed: 2.037053769s
Aug 18 19:11:26.577: INFO: Pod "pod-projected-configmaps-e68ecf7e-d5e0-4c4a-8be4-dfc00ac717bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050178864s
STEP: Saw pod success
Aug 18 19:11:26.577: INFO: Pod "pod-projected-configmaps-e68ecf7e-d5e0-4c4a-8be4-dfc00ac717bd" satisfied condition "success or failure"
Aug 18 19:11:26.589: INFO: Trying to get logs from node 10.241.69.172 pod pod-projected-configmaps-e68ecf7e-d5e0-4c4a-8be4-dfc00ac717bd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 18 19:11:26.693: INFO: Waiting for pod pod-projected-configmaps-e68ecf7e-d5e0-4c4a-8be4-dfc00ac717bd to disappear
Aug 18 19:11:26.712: INFO: Pod pod-projected-configmaps-e68ecf7e-d5e0-4c4a-8be4-dfc00ac717bd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:11:26.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6299" for this suite.
Aug 18 19:11:32.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:11:33.292: INFO: namespace projected-6299 deletion completed in 6.547943224s

• [SLOW TEST:11.018 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:11:33.293: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3444
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0818 19:12:03.684729      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 18 19:12:03.684: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:12:03.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3444" for this suite.
Aug 18 19:12:11.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:12:12.186: INFO: namespace gc-3444 deletion completed in 8.48005883s

• [SLOW TEST:38.894 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Aug 18 19:12:12.187: INFO: >>> kubeConfig: /tmp/kubeconfig-434562375
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3710
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-929a001b-905a-4674-907c-34379ee0c864
STEP: Creating secret with name s-test-opt-upd-d416ea2d-15c2-4ae0-8040-9eb920fe8da6
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-929a001b-905a-4674-907c-34379ee0c864
STEP: Updating secret s-test-opt-upd-d416ea2d-15c2-4ae0-8040-9eb920fe8da6
STEP: Creating secret with name s-test-opt-create-97505a20-f451-4681-a4eb-24eecbcd4516
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Aug 18 19:13:27.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3710" for this suite.
Aug 18 19:13:57.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 18 19:13:58.365: INFO: namespace secrets-3710 deletion completed in 30.447013838s

• [SLOW TEST:106.178 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.14-rc.0.40+11715c2fdcbdf2/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSAug 18 19:13:58.365: INFO: Running AfterSuite actions on all nodes
Aug 18 19:13:58.365: INFO: Running AfterSuite actions on node 1
Aug 18 19:13:58.365: INFO: Skipping dumping logs from cluster

Ran 276 of 4847 Specs in 7515.103 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4571 Skipped
PASS

Ginkgo ran 1 suite in 2h5m16.829603441s
Test Suite Passed

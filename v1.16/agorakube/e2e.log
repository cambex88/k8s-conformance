I1104 08:34:08.991651      19 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-416373942
I1104 08:34:08.992132      19 e2e.go:92] Starting e2e run "4865970f-d2d3-4475-9ffb-48eaf5ccf058" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1572856447 - Will randomize all specs
Will run 276 of 4897 specs

Nov  4 08:34:09.010: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 08:34:09.014: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov  4 08:34:09.036: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov  4 08:34:09.072: INFO: 9 / 9 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov  4 08:34:09.072: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Nov  4 08:34:09.072: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov  4 08:34:09.086: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
Nov  4 08:34:09.086: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm' (0 seconds elapsed)
Nov  4 08:34:09.086: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm64' (0 seconds elapsed)
Nov  4 08:34:09.087: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-ppc64le' (0 seconds elapsed)
Nov  4 08:34:09.087: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-s390x' (0 seconds elapsed)
Nov  4 08:34:09.087: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'traefik-ingress-controller' (0 seconds elapsed)
Nov  4 08:34:09.087: INFO: e2e test version: v1.16.2
Nov  4 08:34:09.088: INFO: kube-apiserver version: v1.16.2
Nov  4 08:34:09.088: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 08:34:09.094: INFO: Cluster IP family: ipv4
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:34:09.095: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename replication-controller
Nov  4 08:34:09.139: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Nov  4 08:34:09.154: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7367
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:34:18.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7367" for this suite.
Nov  4 08:34:46.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:34:46.468: INFO: namespace replication-controller-7367 deletion completed in 28.108044509s

• [SLOW TEST:37.374 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:34:46.470: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3828
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2514
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-419
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:34:59.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3828" for this suite.
Nov  4 08:35:05.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:35:06.035: INFO: namespace namespaces-3828 deletion completed in 6.104232177s
STEP: Destroying namespace "nsdeletetest-2514" for this suite.
Nov  4 08:35:06.038: INFO: Namespace nsdeletetest-2514 was already deleted
STEP: Destroying namespace "nsdeletetest-419" for this suite.
Nov  4 08:35:12.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:35:12.138: INFO: namespace nsdeletetest-419 deletion completed in 6.100113869s

• [SLOW TEST:25.668 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:35:12.139: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1676
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 08:35:12.308: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dcac3767-6078-4cd9-a281-e499d83bdc90" in namespace "projected-1676" to be "success or failure"
Nov  4 08:35:12.312: INFO: Pod "downwardapi-volume-dcac3767-6078-4cd9-a281-e499d83bdc90": Phase="Pending", Reason="", readiness=false. Elapsed: 3.90167ms
Nov  4 08:35:14.315: INFO: Pod "downwardapi-volume-dcac3767-6078-4cd9-a281-e499d83bdc90": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00712398s
Nov  4 08:35:16.319: INFO: Pod "downwardapi-volume-dcac3767-6078-4cd9-a281-e499d83bdc90": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010344383s
STEP: Saw pod success
Nov  4 08:35:16.319: INFO: Pod "downwardapi-volume-dcac3767-6078-4cd9-a281-e499d83bdc90" satisfied condition "success or failure"
Nov  4 08:35:16.321: INFO: Trying to get logs from node k8s-2 pod downwardapi-volume-dcac3767-6078-4cd9-a281-e499d83bdc90 container client-container: <nil>
STEP: delete the pod
Nov  4 08:35:16.350: INFO: Waiting for pod downwardapi-volume-dcac3767-6078-4cd9-a281-e499d83bdc90 to disappear
Nov  4 08:35:16.352: INFO: Pod downwardapi-volume-dcac3767-6078-4cd9-a281-e499d83bdc90 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:35:16.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1676" for this suite.
Nov  4 08:35:22.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:35:22.448: INFO: namespace projected-1676 deletion completed in 6.093172728s

• [SLOW TEST:10.310 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:35:22.449: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-11
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  4 08:35:22.598: INFO: Waiting up to 5m0s for pod "pod-40a17753-2bf1-4017-8be1-d3df0aec136e" in namespace "emptydir-11" to be "success or failure"
Nov  4 08:35:22.610: INFO: Pod "pod-40a17753-2bf1-4017-8be1-d3df0aec136e": Phase="Pending", Reason="", readiness=false. Elapsed: 11.790973ms
Nov  4 08:35:24.620: INFO: Pod "pod-40a17753-2bf1-4017-8be1-d3df0aec136e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021612326s
Nov  4 08:35:26.623: INFO: Pod "pod-40a17753-2bf1-4017-8be1-d3df0aec136e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025057849s
STEP: Saw pod success
Nov  4 08:35:26.623: INFO: Pod "pod-40a17753-2bf1-4017-8be1-d3df0aec136e" satisfied condition "success or failure"
Nov  4 08:35:26.626: INFO: Trying to get logs from node k8s-2 pod pod-40a17753-2bf1-4017-8be1-d3df0aec136e container test-container: <nil>
STEP: delete the pod
Nov  4 08:35:26.651: INFO: Waiting for pod pod-40a17753-2bf1-4017-8be1-d3df0aec136e to disappear
Nov  4 08:35:26.652: INFO: Pod pod-40a17753-2bf1-4017-8be1-d3df0aec136e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:35:26.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-11" for this suite.
Nov  4 08:35:32.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:35:32.749: INFO: namespace emptydir-11 deletion completed in 6.093633849s

• [SLOW TEST:10.301 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:35:32.750: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9632
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9632.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9632.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9632.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9632.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9632.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9632.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 08:35:46.952: INFO: DNS probes using dns-9632/dns-test-1cc59e29-e6df-42f8-a599-6268dd6da67b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:35:46.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9632" for this suite.
Nov  4 08:35:53.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:35:53.088: INFO: namespace dns-9632 deletion completed in 6.102541415s

• [SLOW TEST:20.339 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:35:53.089: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5659
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-7dd3061d-03c2-4503-9980-b46aec28be7e
STEP: Creating a pod to test consume secrets
Nov  4 08:35:53.250: INFO: Waiting up to 5m0s for pod "pod-secrets-219c9b4b-cb54-497c-a4d9-091a67705905" in namespace "secrets-5659" to be "success or failure"
Nov  4 08:35:53.261: INFO: Pod "pod-secrets-219c9b4b-cb54-497c-a4d9-091a67705905": Phase="Pending", Reason="", readiness=false. Elapsed: 11.465962ms
Nov  4 08:35:55.264: INFO: Pod "pod-secrets-219c9b4b-cb54-497c-a4d9-091a67705905": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014703655s
Nov  4 08:35:57.267: INFO: Pod "pod-secrets-219c9b4b-cb54-497c-a4d9-091a67705905": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01766798s
STEP: Saw pod success
Nov  4 08:35:57.268: INFO: Pod "pod-secrets-219c9b4b-cb54-497c-a4d9-091a67705905" satisfied condition "success or failure"
Nov  4 08:35:57.270: INFO: Trying to get logs from node k8s-1 pod pod-secrets-219c9b4b-cb54-497c-a4d9-091a67705905 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 08:35:57.301: INFO: Waiting for pod pod-secrets-219c9b4b-cb54-497c-a4d9-091a67705905 to disappear
Nov  4 08:35:57.304: INFO: Pod pod-secrets-219c9b4b-cb54-497c-a4d9-091a67705905 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:35:57.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5659" for this suite.
Nov  4 08:36:03.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:36:03.414: INFO: namespace secrets-5659 deletion completed in 6.105934704s

• [SLOW TEST:10.324 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:36:03.414: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3597
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3597
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Nov  4 08:36:03.577: INFO: Found 0 stateful pods, waiting for 3
Nov  4 08:36:13.581: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 08:36:13.581: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 08:36:13.581: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Nov  4 08:36:23.581: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 08:36:23.581: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 08:36:23.581: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov  4 08:36:23.610: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov  4 08:36:33.647: INFO: Updating stateful set ss2
Nov  4 08:36:33.672: INFO: Waiting for Pod statefulset-3597/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Nov  4 08:36:43.752: INFO: Found 2 stateful pods, waiting for 3
Nov  4 08:36:53.756: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 08:36:53.756: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 08:36:53.756: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov  4 08:36:53.785: INFO: Updating stateful set ss2
Nov  4 08:36:53.792: INFO: Waiting for Pod statefulset-3597/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  4 08:37:03.819: INFO: Updating stateful set ss2
Nov  4 08:37:03.827: INFO: Waiting for StatefulSet statefulset-3597/ss2 to complete update
Nov  4 08:37:03.827: INFO: Waiting for Pod statefulset-3597/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  4 08:37:13.839: INFO: Waiting for StatefulSet statefulset-3597/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 08:37:23.833: INFO: Deleting all statefulset in ns statefulset-3597
Nov  4 08:37:23.836: INFO: Scaling statefulset ss2 to 0
Nov  4 08:37:43.851: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 08:37:43.853: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:37:43.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3597" for this suite.
Nov  4 08:37:49.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:37:49.972: INFO: namespace statefulset-3597 deletion completed in 6.100091586s

• [SLOW TEST:106.558 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:37:49.974: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8548
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-8548, will wait for the garbage collector to delete the pods
Nov  4 08:37:54.234: INFO: Deleting Job.batch foo took: 9.620499ms
Nov  4 08:37:54.334: INFO: Terminating Job.batch foo pods took: 100.160407ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:38:26.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8548" for this suite.
Nov  4 08:38:32.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:38:32.645: INFO: namespace job-8548 deletion completed in 6.104554365s

• [SLOW TEST:42.671 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:38:32.645: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3779
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 08:38:32.850: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aff7640b-2a78-4c8f-8fe4-e9a59d255620" in namespace "downward-api-3779" to be "success or failure"
Nov  4 08:38:32.861: INFO: Pod "downwardapi-volume-aff7640b-2a78-4c8f-8fe4-e9a59d255620": Phase="Pending", Reason="", readiness=false. Elapsed: 11.52366ms
Nov  4 08:38:34.864: INFO: Pod "downwardapi-volume-aff7640b-2a78-4c8f-8fe4-e9a59d255620": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014562557s
Nov  4 08:38:36.868: INFO: Pod "downwardapi-volume-aff7640b-2a78-4c8f-8fe4-e9a59d255620": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018066538s
STEP: Saw pod success
Nov  4 08:38:36.868: INFO: Pod "downwardapi-volume-aff7640b-2a78-4c8f-8fe4-e9a59d255620" satisfied condition "success or failure"
Nov  4 08:38:36.874: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-aff7640b-2a78-4c8f-8fe4-e9a59d255620 container client-container: <nil>
STEP: delete the pod
Nov  4 08:38:36.896: INFO: Waiting for pod downwardapi-volume-aff7640b-2a78-4c8f-8fe4-e9a59d255620 to disappear
Nov  4 08:38:36.901: INFO: Pod downwardapi-volume-aff7640b-2a78-4c8f-8fe4-e9a59d255620 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:38:36.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3779" for this suite.
Nov  4 08:38:42.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:38:42.997: INFO: namespace downward-api-3779 deletion completed in 6.093009061s

• [SLOW TEST:10.351 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:38:42.997: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-4049
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 08:38:43.135: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:39:44.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4049" for this suite.
Nov  4 08:39:50.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:39:50.757: INFO: namespace custom-resource-definition-4049 deletion completed in 6.120060861s

• [SLOW TEST:67.760 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:39:50.758: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3957
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 08:39:50.902: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 08:39:50.919: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 08:39:50.927: INFO: 
Logging pods the kubelet thinks is on node k8s-1 before test
Nov  4 08:39:50.943: INFO: nginx-6db489d4b7-kjf2v from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.943: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.943: INFO: nginx-6db489d4b7-rfdfr from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.943: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.943: INFO: nginx-6db489d4b7-bqk79 from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.943: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.943: INFO: nginx-6db489d4b7-pms6q from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.943: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.943: INFO: traefik-ingress-controller-7n22b from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.943: INFO: 	Container traefik-ingress-lb ready: true, restart count 2
Nov  4 08:39:50.943: INFO: nginx-6db489d4b7-hqkcs from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.943: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.943: INFO: kubernetes-metrics-scraper-6b97c6d857-pxn2p from kubernetes-dashboard started at 2019-10-31 19:06:43 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.943: INFO: 	Container kubernetes-metrics-scraper ready: true, restart count 2
Nov  4 08:39:50.943: INFO: nginx-6db489d4b7-mbf72 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.943: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.944: INFO: nginx-6db489d4b7-2clqk from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.944: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.944: INFO: nginx-6db489d4b7-wbcnc from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.944: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.944: INFO: kubernetes-dashboard-bf855c94d-bmww6 from kubernetes-dashboard started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.944: INFO: 	Container kubernetes-dashboard ready: true, restart count 2
Nov  4 08:39:50.944: INFO: nginx-6db489d4b7-hfmq8 from default started at 2019-10-31 19:35:15 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.944: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.944: INFO: tiller-deploy-5798768fb-l5xrr from kube-system started at 2019-10-31 19:06:43 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.944: INFO: 	Container tiller ready: true, restart count 2
Nov  4 08:39:50.944: INFO: nginx-6db489d4b7-zwjhd from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.944: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.944: INFO: nginx-6db489d4b7-th4q2 from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.944: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.944: INFO: linkerd-identity-6d9bf4497f-8vd6f from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 08:39:50.944: INFO: 	Container identity ready: true, restart count 2
Nov  4 08:39:50.944: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 08:39:50.944: INFO: nginx-6db489d4b7-65ttj from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.944: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.944: INFO: nginx-6db489d4b7-h552p from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.944: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.944: INFO: nginx-6db489d4b7-9z99c from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.944: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.944: INFO: sonobuoy from sonobuoy started at 2019-11-04 08:33:38 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.944: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 08:39:50.944: INFO: linkerd-tap-8478664cb4-t2jsh from linkerd started at 2019-10-31 19:06:42 +0000 UTC (2 container statuses recorded)
Nov  4 08:39:50.944: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 08:39:50.944: INFO: 	Container tap ready: true, restart count 2
Nov  4 08:39:50.946: INFO: nginx-6db489d4b7-mznbh from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.946: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.946: INFO: nginx-6db489d4b7-xm26m from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.946: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.946: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-9v4q5 from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 08:39:50.946: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 08:39:50.946: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 08:39:50.946: INFO: kube-flannel-ds-amd64-k76xw from kube-system started at 2019-10-31 19:06:43 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.946: INFO: 	Container kube-flannel ready: true, restart count 2
Nov  4 08:39:50.946: INFO: nginx-6db489d4b7-whlcg from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.947: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.947: INFO: 
Logging pods the kubelet thinks is on node k8s-2 before test
Nov  4 08:39:50.962: INFO: nginx-6db489d4b7-xmrg5 from default started at 2019-10-31 19:35:15 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.962: INFO: nginx-6db489d4b7-8j7fq from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.962: INFO: traefik-ingress-controller-2rb4m from kube-system started at 2019-10-31 19:06:43 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container traefik-ingress-lb ready: true, restart count 2
Nov  4 08:39:50.962: INFO: linkerd-sp-validator-8489dfcf59-4vvmx from linkerd started at 2019-10-31 19:06:42 +0000 UTC (2 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 08:39:50.962: INFO: 	Container sp-validator ready: true, restart count 2
Nov  4 08:39:50.962: INFO: nginx-6db489d4b7-74qqm from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.962: INFO: kube-flannel-ds-amd64-f44md from kube-system started at 2019-10-31 19:06:43 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container kube-flannel ready: true, restart count 2
Nov  4 08:39:50.962: INFO: coredns-b7f8c8654-8kwbt from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container coredns ready: true, restart count 2
Nov  4 08:39:50.962: INFO: nginx-6db489d4b7-q647m from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.962: INFO: nginx-6db489d4b7-c4xhg from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.962: INFO: nginx-6db489d4b7-4rl5q from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.962: INFO: nginx-6db489d4b7-6hht8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.962: INFO: sonobuoy-e2e-job-77622933ebe14f87 from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container e2e ready: true, restart count 0
Nov  4 08:39:50.962: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 08:39:50.962: INFO: linkerd-web-685cd8d7c-dhpj5 from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 08:39:50.962: INFO: 	Container web ready: true, restart count 2
Nov  4 08:39:50.962: INFO: nginx-6db489d4b7-5lbr9 from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.962: INFO: nginx-6db489d4b7-rlnhg from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.962: INFO: nginx-6db489d4b7-w6jwg from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.962: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-z8dpb from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 08:39:50.962: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 08:39:50.962: INFO: linkerd-prometheus-f74b98d8-hgtgk from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 08:39:50.962: INFO: 	Container prometheus ready: true, restart count 2
Nov  4 08:39:50.962: INFO: nginx-6db489d4b7-kcbjs from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.962: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.963: INFO: nginx-6db489d4b7-hwpf8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.963: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.963: INFO: nginx-6db489d4b7-xds5m from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.963: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.965: INFO: linkerd-grafana-744cfbd49d-dnzqr from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 08:39:50.965: INFO: 	Container grafana ready: true, restart count 2
Nov  4 08:39:50.965: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 08:39:50.965: INFO: nginx-6db489d4b7-qg6lx from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.965: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.965: INFO: nginx-6db489d4b7-ncpfq from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.965: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.965: INFO: nginx-6db489d4b7-dk2z8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.965: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.965: INFO: nginx-6db489d4b7-qp42l from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.965: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.965: INFO: 
Logging pods the kubelet thinks is on node k8s-3 before test
Nov  4 08:39:50.980: INFO: linkerd-destination-65b7586456-xkd4w from linkerd started at 2019-10-31 19:06:42 +0000 UTC (2 container statuses recorded)
Nov  4 08:39:50.980: INFO: 	Container destination ready: true, restart count 2
Nov  4 08:39:50.980: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 08:39:50.980: INFO: nginx-6db489d4b7-545v7 from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.980: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.980: INFO: nginx-6db489d4b7-zvzhk from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.980: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.980: INFO: nginx-6db489d4b7-676cx from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.980: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.980: INFO: nginx-6db489d4b7-x46qr from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.980: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.981: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-9crmt from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 08:39:50.981: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 08:39:50.981: INFO: nginx-6db489d4b7-4bl92 from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.981: INFO: traefik-ingress-controller-m4sr7 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container traefik-ingress-lb ready: true, restart count 2
Nov  4 08:39:50.981: INFO: linkerd-controller-7f457d599-x5dg5 from linkerd started at 2019-10-31 19:06:42 +0000 UTC (3 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container destination ready: true, restart count 2
Nov  4 08:39:50.981: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 08:39:50.981: INFO: 	Container public-api ready: true, restart count 2
Nov  4 08:39:50.981: INFO: linkerd-proxy-injector-76c5cd6fdb-vtp7v from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 08:39:50.981: INFO: 	Container proxy-injector ready: true, restart count 2
Nov  4 08:39:50.981: INFO: nginx-6db489d4b7-hxbjr from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.981: INFO: nginx-6db489d4b7-zk6l6 from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.981: INFO: nginx-6db489d4b7-qlxbl from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.981: INFO: coredns-b7f8c8654-nxpz9 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container coredns ready: true, restart count 2
Nov  4 08:39:50.981: INFO: nginx-6db489d4b7-4pxjk from default started at 2019-10-31 19:35:14 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.981: INFO: nginx-6db489d4b7-7m8cn from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.981: INFO: nginx-6db489d4b7-5zxqm from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.981: INFO: kube-flannel-ds-amd64-jc2f4 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container kube-flannel ready: true, restart count 2
Nov  4 08:39:50.981: INFO: nginx-6db489d4b7-nx48l from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.981: INFO: nginx-6db489d4b7-hq9kk from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.981: INFO: nginx-6db489d4b7-wx6gd from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.981: INFO: nginx-6db489d4b7-6dswq from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container nginx ready: true, restart count 1
Nov  4 08:39:50.981: INFO: nginx-6db489d4b7-cbv7l from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 08:39:50.981: INFO: 	Container nginx ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-4323c085-7b78-4299-ab59-2334fbfb9d36 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-4323c085-7b78-4299-ab59-2334fbfb9d36 off the node k8s-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-4323c085-7b78-4299-ab59-2334fbfb9d36
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:39:55.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3957" for this suite.
Nov  4 08:40:03.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:40:03.181: INFO: namespace sched-pred-3957 deletion completed in 8.092783096s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:12.423 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:40:03.182: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8223
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 08:40:03.332: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2092661f-1266-4aa7-a03f-3a1fce7ab344" in namespace "projected-8223" to be "success or failure"
Nov  4 08:40:03.342: INFO: Pod "downwardapi-volume-2092661f-1266-4aa7-a03f-3a1fce7ab344": Phase="Pending", Reason="", readiness=false. Elapsed: 10.430393ms
Nov  4 08:40:05.346: INFO: Pod "downwardapi-volume-2092661f-1266-4aa7-a03f-3a1fce7ab344": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014346902s
STEP: Saw pod success
Nov  4 08:40:05.346: INFO: Pod "downwardapi-volume-2092661f-1266-4aa7-a03f-3a1fce7ab344" satisfied condition "success or failure"
Nov  4 08:40:05.349: INFO: Trying to get logs from node k8s-2 pod downwardapi-volume-2092661f-1266-4aa7-a03f-3a1fce7ab344 container client-container: <nil>
STEP: delete the pod
Nov  4 08:40:05.372: INFO: Waiting for pod downwardapi-volume-2092661f-1266-4aa7-a03f-3a1fce7ab344 to disappear
Nov  4 08:40:05.375: INFO: Pod downwardapi-volume-2092661f-1266-4aa7-a03f-3a1fce7ab344 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:40:05.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8223" for this suite.
Nov  4 08:40:11.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:40:11.472: INFO: namespace projected-8223 deletion completed in 6.094127256s

• [SLOW TEST:8.290 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:40:11.473: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9287
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1104 08:40:17.645917      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  4 08:40:17.646: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:40:17.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9287" for this suite.
Nov  4 08:40:23.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:40:23.749: INFO: namespace gc-9287 deletion completed in 6.093209795s

• [SLOW TEST:12.276 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:40:23.749: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9794
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:40:27.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9794" for this suite.
Nov  4 08:41:11.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:41:12.039: INFO: namespace kubelet-test-9794 deletion completed in 44.111819933s

• [SLOW TEST:48.290 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:41:12.040: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8592
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-b4118275-d549-4a2f-b7db-d9d739121135
STEP: Creating a pod to test consume secrets
Nov  4 08:41:12.245: INFO: Waiting up to 5m0s for pod "pod-secrets-ec92f7cf-7a6f-4f39-a065-b2e1f40e3a4e" in namespace "secrets-8592" to be "success or failure"
Nov  4 08:41:12.273: INFO: Pod "pod-secrets-ec92f7cf-7a6f-4f39-a065-b2e1f40e3a4e": Phase="Pending", Reason="", readiness=false. Elapsed: 28.065191ms
Nov  4 08:41:14.279: INFO: Pod "pod-secrets-ec92f7cf-7a6f-4f39-a065-b2e1f40e3a4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034646587s
STEP: Saw pod success
Nov  4 08:41:14.279: INFO: Pod "pod-secrets-ec92f7cf-7a6f-4f39-a065-b2e1f40e3a4e" satisfied condition "success or failure"
Nov  4 08:41:14.282: INFO: Trying to get logs from node k8s-3 pod pod-secrets-ec92f7cf-7a6f-4f39-a065-b2e1f40e3a4e container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 08:41:14.302: INFO: Waiting for pod pod-secrets-ec92f7cf-7a6f-4f39-a065-b2e1f40e3a4e to disappear
Nov  4 08:41:14.304: INFO: Pod pod-secrets-ec92f7cf-7a6f-4f39-a065-b2e1f40e3a4e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:41:14.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8592" for this suite.
Nov  4 08:41:20.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:41:20.403: INFO: namespace secrets-8592 deletion completed in 6.094513155s

• [SLOW TEST:8.363 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:41:20.404: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8953
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 08:41:26.805: INFO: Waiting up to 5m0s for pod "client-envvars-ec1e9f18-7954-4ffc-80db-8a1c45697073" in namespace "pods-8953" to be "success or failure"
Nov  4 08:41:26.807: INFO: Pod "client-envvars-ec1e9f18-7954-4ffc-80db-8a1c45697073": Phase="Pending", Reason="", readiness=false. Elapsed: 2.404805ms
Nov  4 08:41:28.813: INFO: Pod "client-envvars-ec1e9f18-7954-4ffc-80db-8a1c45697073": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008179447s
STEP: Saw pod success
Nov  4 08:41:28.813: INFO: Pod "client-envvars-ec1e9f18-7954-4ffc-80db-8a1c45697073" satisfied condition "success or failure"
Nov  4 08:41:28.817: INFO: Trying to get logs from node k8s-3 pod client-envvars-ec1e9f18-7954-4ffc-80db-8a1c45697073 container env3cont: <nil>
STEP: delete the pod
Nov  4 08:41:28.834: INFO: Waiting for pod client-envvars-ec1e9f18-7954-4ffc-80db-8a1c45697073 to disappear
Nov  4 08:41:28.843: INFO: Pod client-envvars-ec1e9f18-7954-4ffc-80db-8a1c45697073 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:41:28.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8953" for this suite.
Nov  4 08:41:56.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:41:57.004: INFO: namespace pods-8953 deletion completed in 28.157465943s

• [SLOW TEST:36.600 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:41:57.005: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6925
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:41:59.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6925" for this suite.
Nov  4 08:42:43.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:42:43.623: INFO: namespace kubelet-test-6925 deletion completed in 44.109795508s

• [SLOW TEST:46.619 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:42:43.624: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-891
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 08:42:43.784: INFO: Waiting up to 5m0s for pod "downward-api-fc38bc10-df14-4abc-a831-53932a3a54f6" in namespace "downward-api-891" to be "success or failure"
Nov  4 08:42:43.797: INFO: Pod "downward-api-fc38bc10-df14-4abc-a831-53932a3a54f6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.145972ms
Nov  4 08:42:45.799: INFO: Pod "downward-api-fc38bc10-df14-4abc-a831-53932a3a54f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015089503s
STEP: Saw pod success
Nov  4 08:42:45.800: INFO: Pod "downward-api-fc38bc10-df14-4abc-a831-53932a3a54f6" satisfied condition "success or failure"
Nov  4 08:42:45.802: INFO: Trying to get logs from node k8s-2 pod downward-api-fc38bc10-df14-4abc-a831-53932a3a54f6 container dapi-container: <nil>
STEP: delete the pod
Nov  4 08:42:45.827: INFO: Waiting for pod downward-api-fc38bc10-df14-4abc-a831-53932a3a54f6 to disappear
Nov  4 08:42:45.830: INFO: Pod downward-api-fc38bc10-df14-4abc-a831-53932a3a54f6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:42:45.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-891" for this suite.
Nov  4 08:42:51.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:42:51.948: INFO: namespace downward-api-891 deletion completed in 6.114174785s

• [SLOW TEST:8.324 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:42:51.948: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3732
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-3732
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  4 08:42:52.091: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  4 08:43:18.230: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.33.1.44:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3732 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 08:43:18.230: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 08:43:18.408: INFO: Found all expected endpoints: [netserver-0]
Nov  4 08:43:18.412: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.33.0.40:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3732 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 08:43:18.412: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 08:43:18.588: INFO: Found all expected endpoints: [netserver-1]
Nov  4 08:43:18.591: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.33.2.41:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3732 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 08:43:18.591: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 08:43:18.739: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:43:18.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3732" for this suite.
Nov  4 08:43:30.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:43:30.860: INFO: namespace pod-network-test-3732 deletion completed in 12.11432278s

• [SLOW TEST:38.912 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:43:30.861: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2421
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 08:43:31.008: INFO: Waiting up to 5m0s for pod "downward-api-1dc4c8b0-24d2-48fd-9728-b60983aefc1c" in namespace "downward-api-2421" to be "success or failure"
Nov  4 08:43:31.011: INFO: Pod "downward-api-1dc4c8b0-24d2-48fd-9728-b60983aefc1c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.41895ms
Nov  4 08:43:33.014: INFO: Pod "downward-api-1dc4c8b0-24d2-48fd-9728-b60983aefc1c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005783979s
STEP: Saw pod success
Nov  4 08:43:33.014: INFO: Pod "downward-api-1dc4c8b0-24d2-48fd-9728-b60983aefc1c" satisfied condition "success or failure"
Nov  4 08:43:33.016: INFO: Trying to get logs from node k8s-3 pod downward-api-1dc4c8b0-24d2-48fd-9728-b60983aefc1c container dapi-container: <nil>
STEP: delete the pod
Nov  4 08:43:33.041: INFO: Waiting for pod downward-api-1dc4c8b0-24d2-48fd-9728-b60983aefc1c to disappear
Nov  4 08:43:33.045: INFO: Pod downward-api-1dc4c8b0-24d2-48fd-9728-b60983aefc1c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:43:33.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2421" for this suite.
Nov  4 08:43:39.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:43:39.161: INFO: namespace downward-api-2421 deletion completed in 6.109314055s

• [SLOW TEST:8.300 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:43:39.162: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6717
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  4 08:43:41.570: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:43:41.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6717" for this suite.
Nov  4 08:43:47.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:43:47.700: INFO: namespace container-runtime-6717 deletion completed in 6.105509937s

• [SLOW TEST:8.538 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:43:47.701: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3996
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  4 08:43:47.899: INFO: Waiting up to 5m0s for pod "pod-e5f4ff45-fd92-4d1f-8f40-0c247fe31e47" in namespace "emptydir-3996" to be "success or failure"
Nov  4 08:43:47.901: INFO: Pod "pod-e5f4ff45-fd92-4d1f-8f40-0c247fe31e47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206706ms
Nov  4 08:43:49.904: INFO: Pod "pod-e5f4ff45-fd92-4d1f-8f40-0c247fe31e47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004971015s
STEP: Saw pod success
Nov  4 08:43:49.904: INFO: Pod "pod-e5f4ff45-fd92-4d1f-8f40-0c247fe31e47" satisfied condition "success or failure"
Nov  4 08:43:49.907: INFO: Trying to get logs from node k8s-2 pod pod-e5f4ff45-fd92-4d1f-8f40-0c247fe31e47 container test-container: <nil>
STEP: delete the pod
Nov  4 08:43:49.930: INFO: Waiting for pod pod-e5f4ff45-fd92-4d1f-8f40-0c247fe31e47 to disappear
Nov  4 08:43:49.934: INFO: Pod pod-e5f4ff45-fd92-4d1f-8f40-0c247fe31e47 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:43:49.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3996" for this suite.
Nov  4 08:43:55.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:43:56.039: INFO: namespace emptydir-3996 deletion completed in 6.100841324s

• [SLOW TEST:8.339 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:43:56.040: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7577
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-80fbd68f-f470-470f-8142-948530a3534c
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:43:56.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7577" for this suite.
Nov  4 08:44:02.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:44:02.282: INFO: namespace configmap-7577 deletion completed in 6.096852756s

• [SLOW TEST:6.243 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:44:02.283: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8419
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8419.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8419.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8419.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8419.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 08:44:18.515: INFO: DNS probes using dns-test-66de5546-b994-43f4-9705-5a9a155c95b1 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8419.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8419.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8419.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8419.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 08:44:22.579: INFO: File wheezy_udp@dns-test-service-3.dns-8419.svc.cluster.local from pod  dns-8419/dns-test-11dd159a-7592-4201-a335-4757b75d861c contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov  4 08:44:22.582: INFO: File jessie_udp@dns-test-service-3.dns-8419.svc.cluster.local from pod  dns-8419/dns-test-11dd159a-7592-4201-a335-4757b75d861c contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov  4 08:44:22.582: INFO: Lookups using dns-8419/dns-test-11dd159a-7592-4201-a335-4757b75d861c failed for: [wheezy_udp@dns-test-service-3.dns-8419.svc.cluster.local jessie_udp@dns-test-service-3.dns-8419.svc.cluster.local]

Nov  4 08:44:27.589: INFO: DNS probes using dns-test-11dd159a-7592-4201-a335-4757b75d861c succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8419.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8419.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8419.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8419.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 08:44:29.677: INFO: DNS probes using dns-test-e5491924-b892-4756-8c35-9c655f511941 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:44:29.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8419" for this suite.
Nov  4 08:44:35.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:44:35.841: INFO: namespace dns-8419 deletion completed in 6.105562677s

• [SLOW TEST:33.558 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:44:35.841: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4354
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  4 08:44:38.528: INFO: Successfully updated pod "annotationupdate5a969667-83ed-4907-b637-a038470b2062"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:44:42.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4354" for this suite.
Nov  4 08:44:54.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:44:54.657: INFO: namespace downward-api-4354 deletion completed in 12.103546436s

• [SLOW TEST:18.816 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:44:54.658: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7179
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Nov  4 08:44:56.831: INFO: Pod pod-hostip-6f0534fe-dab1-471b-a8cb-91e38eb68df4 has hostIP: 10.20.20.4
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:44:56.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7179" for this suite.
Nov  4 08:45:24.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:45:24.946: INFO: namespace pods-7179 deletion completed in 28.110543061s

• [SLOW TEST:30.288 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:45:24.946: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2385
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 08:45:25.110: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2c3fbef9-470a-4f3f-90e5-67cd4aa2b171" in namespace "downward-api-2385" to be "success or failure"
Nov  4 08:45:25.113: INFO: Pod "downwardapi-volume-2c3fbef9-470a-4f3f-90e5-67cd4aa2b171": Phase="Pending", Reason="", readiness=false. Elapsed: 3.324292ms
Nov  4 08:45:27.116: INFO: Pod "downwardapi-volume-2c3fbef9-470a-4f3f-90e5-67cd4aa2b171": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006376985s
STEP: Saw pod success
Nov  4 08:45:27.116: INFO: Pod "downwardapi-volume-2c3fbef9-470a-4f3f-90e5-67cd4aa2b171" satisfied condition "success or failure"
Nov  4 08:45:27.119: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-2c3fbef9-470a-4f3f-90e5-67cd4aa2b171 container client-container: <nil>
STEP: delete the pod
Nov  4 08:45:27.142: INFO: Waiting for pod downwardapi-volume-2c3fbef9-470a-4f3f-90e5-67cd4aa2b171 to disappear
Nov  4 08:45:27.148: INFO: Pod downwardapi-volume-2c3fbef9-470a-4f3f-90e5-67cd4aa2b171 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:45:27.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2385" for this suite.
Nov  4 08:45:33.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:45:33.252: INFO: namespace downward-api-2385 deletion completed in 6.099904853s

• [SLOW TEST:8.305 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:45:33.254: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3343
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov  4 08:45:33.414: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3343 /api/v1/namespaces/watch-3343/configmaps/e2e-watch-test-label-changed 58f70d07-e73c-49af-9b6f-afd9bc17b80a 513265 0 2019-11-04 08:45:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 08:45:33.414: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3343 /api/v1/namespaces/watch-3343/configmaps/e2e-watch-test-label-changed 58f70d07-e73c-49af-9b6f-afd9bc17b80a 513266 0 2019-11-04 08:45:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  4 08:45:33.415: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3343 /api/v1/namespaces/watch-3343/configmaps/e2e-watch-test-label-changed 58f70d07-e73c-49af-9b6f-afd9bc17b80a 513267 0 2019-11-04 08:45:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov  4 08:45:43.441: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3343 /api/v1/namespaces/watch-3343/configmaps/e2e-watch-test-label-changed 58f70d07-e73c-49af-9b6f-afd9bc17b80a 513285 0 2019-11-04 08:45:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 08:45:43.442: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3343 /api/v1/namespaces/watch-3343/configmaps/e2e-watch-test-label-changed 58f70d07-e73c-49af-9b6f-afd9bc17b80a 513286 0 2019-11-04 08:45:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov  4 08:45:43.442: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3343 /api/v1/namespaces/watch-3343/configmaps/e2e-watch-test-label-changed 58f70d07-e73c-49af-9b6f-afd9bc17b80a 513287 0 2019-11-04 08:45:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:45:43.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3343" for this suite.
Nov  4 08:45:49.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:45:49.552: INFO: namespace watch-3343 deletion completed in 6.106725731s

• [SLOW TEST:16.298 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:45:49.553: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-6294
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:45:55.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6294" for this suite.
Nov  4 08:46:01.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:46:01.859: INFO: namespace job-6294 deletion completed in 6.139736771s

• [SLOW TEST:12.307 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:46:01.861: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-3058
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Nov  4 08:46:05.087: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:46:05.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3058" for this suite.
Nov  4 08:46:17.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:46:17.211: INFO: namespace replicaset-3058 deletion completed in 12.101109078s

• [SLOW TEST:15.350 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:46:17.212: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2757
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 08:46:17.380: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7f2b5692-dbed-42a8-8a70-f65456760cc1" in namespace "downward-api-2757" to be "success or failure"
Nov  4 08:46:17.392: INFO: Pod "downwardapi-volume-7f2b5692-dbed-42a8-8a70-f65456760cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.460013ms
Nov  4 08:46:19.396: INFO: Pod "downwardapi-volume-7f2b5692-dbed-42a8-8a70-f65456760cc1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015826507s
STEP: Saw pod success
Nov  4 08:46:19.396: INFO: Pod "downwardapi-volume-7f2b5692-dbed-42a8-8a70-f65456760cc1" satisfied condition "success or failure"
Nov  4 08:46:19.398: INFO: Trying to get logs from node k8s-2 pod downwardapi-volume-7f2b5692-dbed-42a8-8a70-f65456760cc1 container client-container: <nil>
STEP: delete the pod
Nov  4 08:46:19.421: INFO: Waiting for pod downwardapi-volume-7f2b5692-dbed-42a8-8a70-f65456760cc1 to disappear
Nov  4 08:46:19.423: INFO: Pod downwardapi-volume-7f2b5692-dbed-42a8-8a70-f65456760cc1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:46:19.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2757" for this suite.
Nov  4 08:46:25.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:46:25.526: INFO: namespace downward-api-2757 deletion completed in 6.096243269s

• [SLOW TEST:8.314 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:46:25.527: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-9327
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Nov  4 08:46:28.193: INFO: Successfully updated pod "adopt-release-gphms"
STEP: Checking that the Job readopts the Pod
Nov  4 08:46:28.193: INFO: Waiting up to 15m0s for pod "adopt-release-gphms" in namespace "job-9327" to be "adopted"
Nov  4 08:46:28.197: INFO: Pod "adopt-release-gphms": Phase="Running", Reason="", readiness=true. Elapsed: 4.02298ms
Nov  4 08:46:30.201: INFO: Pod "adopt-release-gphms": Phase="Running", Reason="", readiness=true. Elapsed: 2.007799109s
Nov  4 08:46:30.201: INFO: Pod "adopt-release-gphms" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Nov  4 08:46:30.711: INFO: Successfully updated pod "adopt-release-gphms"
STEP: Checking that the Job releases the Pod
Nov  4 08:46:30.711: INFO: Waiting up to 15m0s for pod "adopt-release-gphms" in namespace "job-9327" to be "released"
Nov  4 08:46:30.716: INFO: Pod "adopt-release-gphms": Phase="Running", Reason="", readiness=true. Elapsed: 4.957291ms
Nov  4 08:46:30.716: INFO: Pod "adopt-release-gphms" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:46:30.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9327" for this suite.
Nov  4 08:47:14.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:47:14.885: INFO: namespace job-9327 deletion completed in 44.160783864s

• [SLOW TEST:49.358 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:47:14.891: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9657
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 08:47:15.045: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:47:17.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9657" for this suite.
Nov  4 08:48:03.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:48:03.329: INFO: namespace pods-9657 deletion completed in 46.099945811s

• [SLOW TEST:48.439 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:48:03.330: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-1183
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 08:48:03.536: INFO: (0) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.492459ms)
Nov  4 08:48:03.542: INFO: (1) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.608366ms)
Nov  4 08:48:03.545: INFO: (2) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.142061ms)
Nov  4 08:48:03.548: INFO: (3) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.074194ms)
Nov  4 08:48:03.551: INFO: (4) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.994267ms)
Nov  4 08:48:03.554: INFO: (5) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.243198ms)
Nov  4 08:48:03.557: INFO: (6) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.783115ms)
Nov  4 08:48:03.561: INFO: (7) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.61784ms)
Nov  4 08:48:03.564: INFO: (8) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.394265ms)
Nov  4 08:48:03.568: INFO: (9) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.630181ms)
Nov  4 08:48:03.571: INFO: (10) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.317907ms)
Nov  4 08:48:03.575: INFO: (11) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.617481ms)
Nov  4 08:48:03.579: INFO: (12) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.213278ms)
Nov  4 08:48:03.583: INFO: (13) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.392534ms)
Nov  4 08:48:03.587: INFO: (14) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.768355ms)
Nov  4 08:48:03.590: INFO: (15) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.415755ms)
Nov  4 08:48:03.596: INFO: (16) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.43694ms)
Nov  4 08:48:03.599: INFO: (17) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.337986ms)
Nov  4 08:48:03.602: INFO: (18) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.920975ms)
Nov  4 08:48:03.606: INFO: (19) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.565258ms)
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:48:03.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1183" for this suite.
Nov  4 08:48:09.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:48:09.710: INFO: namespace proxy-1183 deletion completed in 6.100603439s

• [SLOW TEST:6.380 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:48:09.711: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-710
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-92036392-4ec1-491b-9cab-783f18458c08 in namespace container-probe-710
Nov  4 08:48:11.936: INFO: Started pod test-webserver-92036392-4ec1-491b-9cab-783f18458c08 in namespace container-probe-710
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 08:48:11.939: INFO: Initial restart count of pod test-webserver-92036392-4ec1-491b-9cab-783f18458c08 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:52:12.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-710" for this suite.
Nov  4 08:52:18.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:52:18.551: INFO: namespace container-probe-710 deletion completed in 6.109240124s

• [SLOW TEST:248.841 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:52:18.552: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7697
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-587e46f9-276f-467e-a9c0-5ba983d2fe06
STEP: Creating a pod to test consume secrets
Nov  4 08:52:18.714: INFO: Waiting up to 5m0s for pod "pod-secrets-4324a62e-9fd2-4f30-ab38-04f286b9a5f3" in namespace "secrets-7697" to be "success or failure"
Nov  4 08:52:18.737: INFO: Pod "pod-secrets-4324a62e-9fd2-4f30-ab38-04f286b9a5f3": Phase="Pending", Reason="", readiness=false. Elapsed: 22.295356ms
Nov  4 08:52:20.746: INFO: Pod "pod-secrets-4324a62e-9fd2-4f30-ab38-04f286b9a5f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032018274s
STEP: Saw pod success
Nov  4 08:52:20.747: INFO: Pod "pod-secrets-4324a62e-9fd2-4f30-ab38-04f286b9a5f3" satisfied condition "success or failure"
Nov  4 08:52:20.749: INFO: Trying to get logs from node k8s-3 pod pod-secrets-4324a62e-9fd2-4f30-ab38-04f286b9a5f3 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 08:52:20.776: INFO: Waiting for pod pod-secrets-4324a62e-9fd2-4f30-ab38-04f286b9a5f3 to disappear
Nov  4 08:52:20.778: INFO: Pod pod-secrets-4324a62e-9fd2-4f30-ab38-04f286b9a5f3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:52:20.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7697" for this suite.
Nov  4 08:52:26.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:52:26.885: INFO: namespace secrets-7697 deletion completed in 6.103771449s

• [SLOW TEST:8.333 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:52:26.887: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8659
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 08:52:27.142: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"93f245b1-8c51-42bf-ba52-f41efa55777c", Controller:(*bool)(0xc00209f4f2), BlockOwnerDeletion:(*bool)(0xc00209f4f3)}}
Nov  4 08:52:27.152: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"2346cd00-1ad1-470b-ac3c-7d6d978ecce4", Controller:(*bool)(0xc00209f6ba), BlockOwnerDeletion:(*bool)(0xc00209f6bb)}}
Nov  4 08:52:27.160: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"82728318-68d3-45b0-b957-f15db5604cea", Controller:(*bool)(0xc00209f88a), BlockOwnerDeletion:(*bool)(0xc00209f88b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:52:32.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8659" for this suite.
Nov  4 08:52:38.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:52:38.296: INFO: namespace gc-8659 deletion completed in 6.105278234s

• [SLOW TEST:11.409 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:52:38.297: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4905
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-2fa8eb3e-fa48-4e58-9886-fefb6d882623 in namespace container-probe-4905
Nov  4 08:52:40.458: INFO: Started pod busybox-2fa8eb3e-fa48-4e58-9886-fefb6d882623 in namespace container-probe-4905
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 08:52:40.461: INFO: Initial restart count of pod busybox-2fa8eb3e-fa48-4e58-9886-fefb6d882623 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:56:40.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4905" for this suite.
Nov  4 08:56:46.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:56:47.001: INFO: namespace container-probe-4905 deletion completed in 6.103389857s

• [SLOW TEST:248.705 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:56:47.002: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6924
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 08:56:47.158: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cb50286e-182e-4c76-bede-ed82d8134db6" in namespace "downward-api-6924" to be "success or failure"
Nov  4 08:56:47.161: INFO: Pod "downwardapi-volume-cb50286e-182e-4c76-bede-ed82d8134db6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.964782ms
Nov  4 08:56:49.165: INFO: Pod "downwardapi-volume-cb50286e-182e-4c76-bede-ed82d8134db6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006921995s
STEP: Saw pod success
Nov  4 08:56:49.165: INFO: Pod "downwardapi-volume-cb50286e-182e-4c76-bede-ed82d8134db6" satisfied condition "success or failure"
Nov  4 08:56:49.171: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-cb50286e-182e-4c76-bede-ed82d8134db6 container client-container: <nil>
STEP: delete the pod
Nov  4 08:56:49.200: INFO: Waiting for pod downwardapi-volume-cb50286e-182e-4c76-bede-ed82d8134db6 to disappear
Nov  4 08:56:49.211: INFO: Pod downwardapi-volume-cb50286e-182e-4c76-bede-ed82d8134db6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:56:49.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6924" for this suite.
Nov  4 08:56:55.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:56:55.312: INFO: namespace downward-api-6924 deletion completed in 6.093889236s

• [SLOW TEST:8.310 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:56:55.313: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9265
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  4 08:56:55.451: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:56:59.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9265" for this suite.
Nov  4 08:57:11.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:57:11.152: INFO: namespace init-container-9265 deletion completed in 12.096170831s

• [SLOW TEST:15.839 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:57:11.153: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4988
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Nov  4 08:57:11.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 api-versions'
Nov  4 08:57:11.507: INFO: stderr: ""
Nov  4 08:57:11.507: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nlinkerd.io/v1alpha1\nlinkerd.io/v1alpha2\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nsplit.smi-spec.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\ntap.linkerd.io/v1alpha1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:57:11.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4988" for this suite.
Nov  4 08:57:17.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:57:17.627: INFO: namespace kubectl-4988 deletion completed in 6.116305135s

• [SLOW TEST:6.474 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:57:17.628: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5248
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Nov  4 08:57:17.820: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:57:39.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5248" for this suite.
Nov  4 08:57:45.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:57:45.933: INFO: namespace crd-publish-openapi-5248 deletion completed in 6.106889186s

• [SLOW TEST:28.305 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:57:45.933: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9917
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9917.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9917.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9917.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9917.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9917.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9917.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 08:58:00.355: INFO: DNS probes using dns-9917/dns-test-81d78425-97a0-4489-9ada-b182f35d04ad succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:58:00.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9917" for this suite.
Nov  4 08:58:06.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:58:06.728: INFO: namespace dns-9917 deletion completed in 6.315178756s

• [SLOW TEST:20.794 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:58:06.728: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-7950
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Nov  4 08:58:06.914: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  4 08:59:06.945: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 08:59:06.949: INFO: Starting informer...
STEP: Starting pods...
Nov  4 08:59:07.173: INFO: Pod1 is running on k8s-1. Tainting Node
Nov  4 08:59:09.417: INFO: Pod2 is running on k8s-1. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Nov  4 08:59:31.276: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Nov  4 08:59:42.279: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 08:59:42.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-7950" for this suite.
Nov  4 08:59:48.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 08:59:48.420: INFO: namespace taint-multiple-pods-7950 deletion completed in 6.106907044s

• [SLOW TEST:101.692 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 08:59:48.421: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7308
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Nov  4 08:59:48.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 create -f - --namespace=kubectl-7308'
Nov  4 08:59:49.187: INFO: stderr: ""
Nov  4 08:59:49.187: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 08:59:49.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7308'
Nov  4 08:59:49.323: INFO: stderr: ""
Nov  4 08:59:49.323: INFO: stdout: "update-demo-nautilus-6x6vx update-demo-nautilus-hn94k "
Nov  4 08:59:49.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-6x6vx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7308'
Nov  4 08:59:49.447: INFO: stderr: ""
Nov  4 08:59:49.447: INFO: stdout: ""
Nov  4 08:59:49.447: INFO: update-demo-nautilus-6x6vx is created but not running
Nov  4 08:59:54.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7308'
Nov  4 08:59:54.534: INFO: stderr: ""
Nov  4 08:59:54.534: INFO: stdout: "update-demo-nautilus-6x6vx update-demo-nautilus-hn94k "
Nov  4 08:59:54.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-6x6vx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7308'
Nov  4 08:59:54.610: INFO: stderr: ""
Nov  4 08:59:54.610: INFO: stdout: "true"
Nov  4 08:59:54.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-6x6vx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7308'
Nov  4 08:59:54.687: INFO: stderr: ""
Nov  4 08:59:54.687: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 08:59:54.687: INFO: validating pod update-demo-nautilus-6x6vx
Nov  4 08:59:54.692: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 08:59:54.692: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 08:59:54.692: INFO: update-demo-nautilus-6x6vx is verified up and running
Nov  4 08:59:54.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-hn94k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7308'
Nov  4 08:59:54.798: INFO: stderr: ""
Nov  4 08:59:54.798: INFO: stdout: "true"
Nov  4 08:59:54.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-hn94k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7308'
Nov  4 08:59:54.909: INFO: stderr: ""
Nov  4 08:59:54.909: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 08:59:54.909: INFO: validating pod update-demo-nautilus-hn94k
Nov  4 08:59:54.913: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 08:59:54.913: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 08:59:54.913: INFO: update-demo-nautilus-hn94k is verified up and running
STEP: scaling down the replication controller
Nov  4 08:59:54.915: INFO: scanned /root for discovery docs: <nil>
Nov  4 08:59:54.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7308'
Nov  4 08:59:56.073: INFO: stderr: ""
Nov  4 08:59:56.073: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 08:59:56.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7308'
Nov  4 08:59:56.155: INFO: stderr: ""
Nov  4 08:59:56.155: INFO: stdout: "update-demo-nautilus-6x6vx update-demo-nautilus-hn94k "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  4 09:00:01.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7308'
Nov  4 09:00:02.175: INFO: stderr: ""
Nov  4 09:00:02.175: INFO: stdout: "update-demo-nautilus-6x6vx "
Nov  4 09:00:02.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-6x6vx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7308'
Nov  4 09:00:02.267: INFO: stderr: ""
Nov  4 09:00:02.267: INFO: stdout: "true"
Nov  4 09:00:02.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-6x6vx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7308'
Nov  4 09:00:02.352: INFO: stderr: ""
Nov  4 09:00:02.352: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 09:00:02.352: INFO: validating pod update-demo-nautilus-6x6vx
Nov  4 09:00:02.355: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 09:00:02.355: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 09:00:02.355: INFO: update-demo-nautilus-6x6vx is verified up and running
STEP: scaling up the replication controller
Nov  4 09:00:02.356: INFO: scanned /root for discovery docs: <nil>
Nov  4 09:00:02.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7308'
Nov  4 09:00:03.474: INFO: stderr: ""
Nov  4 09:00:03.474: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 09:00:03.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7308'
Nov  4 09:00:03.584: INFO: stderr: ""
Nov  4 09:00:03.584: INFO: stdout: "update-demo-nautilus-2qwz4 update-demo-nautilus-6x6vx "
Nov  4 09:00:03.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-2qwz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7308'
Nov  4 09:00:03.679: INFO: stderr: ""
Nov  4 09:00:03.679: INFO: stdout: "true"
Nov  4 09:00:03.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-2qwz4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7308'
Nov  4 09:00:03.759: INFO: stderr: ""
Nov  4 09:00:03.759: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 09:00:03.759: INFO: validating pod update-demo-nautilus-2qwz4
Nov  4 09:00:03.764: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 09:00:03.764: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 09:00:03.764: INFO: update-demo-nautilus-2qwz4 is verified up and running
Nov  4 09:00:03.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-6x6vx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7308'
Nov  4 09:00:03.845: INFO: stderr: ""
Nov  4 09:00:03.845: INFO: stdout: "true"
Nov  4 09:00:03.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-6x6vx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7308'
Nov  4 09:00:03.923: INFO: stderr: ""
Nov  4 09:00:03.923: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 09:00:03.923: INFO: validating pod update-demo-nautilus-6x6vx
Nov  4 09:00:03.926: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 09:00:03.926: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 09:00:03.926: INFO: update-demo-nautilus-6x6vx is verified up and running
STEP: using delete to clean up resources
Nov  4 09:00:03.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete --grace-period=0 --force -f - --namespace=kubectl-7308'
Nov  4 09:00:04.019: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 09:00:04.019: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  4 09:00:04.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7308'
Nov  4 09:00:04.120: INFO: stderr: "No resources found in kubectl-7308 namespace.\n"
Nov  4 09:00:04.120: INFO: stdout: ""
Nov  4 09:00:04.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -l name=update-demo --namespace=kubectl-7308 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  4 09:00:04.204: INFO: stderr: ""
Nov  4 09:00:04.204: INFO: stdout: "update-demo-nautilus-2qwz4\nupdate-demo-nautilus-6x6vx\n"
Nov  4 09:00:04.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7308'
Nov  4 09:00:04.794: INFO: stderr: "No resources found in kubectl-7308 namespace.\n"
Nov  4 09:00:04.794: INFO: stdout: ""
Nov  4 09:00:04.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -l name=update-demo --namespace=kubectl-7308 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  4 09:00:04.883: INFO: stderr: ""
Nov  4 09:00:04.883: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:00:04.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7308" for this suite.
Nov  4 09:00:16.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:00:16.990: INFO: namespace kubectl-7308 deletion completed in 12.103165377s

• [SLOW TEST:28.569 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:00:16.991: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8916
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-fdf38a6e-dd78-4fc8-b552-08d45a280a27
STEP: Creating secret with name s-test-opt-upd-d584fc53-4464-4f9e-ad18-c3dc6dfef72a
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-fdf38a6e-dd78-4fc8-b552-08d45a280a27
STEP: Updating secret s-test-opt-upd-d584fc53-4464-4f9e-ad18-c3dc6dfef72a
STEP: Creating secret with name s-test-opt-create-1a589a9c-4cbd-4c20-a7e9-74b49590f7a2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:00:21.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8916" for this suite.
Nov  4 09:00:33.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:00:33.330: INFO: namespace secrets-8916 deletion completed in 12.107985613s

• [SLOW TEST:16.339 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:00:33.332: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4423
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  4 09:00:36.021: INFO: Successfully updated pod "annotationupdate1e76ae99-e06c-4221-9761-ab4acf21bfe7"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:00:40.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4423" for this suite.
Nov  4 09:00:52.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:00:52.136: INFO: namespace projected-4423 deletion completed in 12.093207548s

• [SLOW TEST:18.804 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:00:52.137: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3841
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  4 09:00:52.318: INFO: Waiting up to 5m0s for pod "pod-d21fc24d-042a-4db7-959a-7b56f272cbb4" in namespace "emptydir-3841" to be "success or failure"
Nov  4 09:00:52.321: INFO: Pod "pod-d21fc24d-042a-4db7-959a-7b56f272cbb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.397969ms
Nov  4 09:00:54.324: INFO: Pod "pod-d21fc24d-042a-4db7-959a-7b56f272cbb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006285717s
STEP: Saw pod success
Nov  4 09:00:54.324: INFO: Pod "pod-d21fc24d-042a-4db7-959a-7b56f272cbb4" satisfied condition "success or failure"
Nov  4 09:00:54.327: INFO: Trying to get logs from node k8s-1 pod pod-d21fc24d-042a-4db7-959a-7b56f272cbb4 container test-container: <nil>
STEP: delete the pod
Nov  4 09:00:54.348: INFO: Waiting for pod pod-d21fc24d-042a-4db7-959a-7b56f272cbb4 to disappear
Nov  4 09:00:54.353: INFO: Pod pod-d21fc24d-042a-4db7-959a-7b56f272cbb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:00:54.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3841" for this suite.
Nov  4 09:01:00.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:01:00.458: INFO: namespace emptydir-3841 deletion completed in 6.102301156s

• [SLOW TEST:8.322 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:01:00.459: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6454
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:01:16.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6454" for this suite.
Nov  4 09:01:22.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:01:22.829: INFO: namespace resourcequota-6454 deletion completed in 6.109367459s

• [SLOW TEST:22.371 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:01:22.830: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4014
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 09:01:22.979: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dfc99c9c-4e22-400c-9137-8f3e773d67b6" in namespace "downward-api-4014" to be "success or failure"
Nov  4 09:01:22.991: INFO: Pod "downwardapi-volume-dfc99c9c-4e22-400c-9137-8f3e773d67b6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.225853ms
Nov  4 09:01:24.994: INFO: Pod "downwardapi-volume-dfc99c9c-4e22-400c-9137-8f3e773d67b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015280584s
STEP: Saw pod success
Nov  4 09:01:24.994: INFO: Pod "downwardapi-volume-dfc99c9c-4e22-400c-9137-8f3e773d67b6" satisfied condition "success or failure"
Nov  4 09:01:24.997: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-dfc99c9c-4e22-400c-9137-8f3e773d67b6 container client-container: <nil>
STEP: delete the pod
Nov  4 09:01:25.013: INFO: Waiting for pod downwardapi-volume-dfc99c9c-4e22-400c-9137-8f3e773d67b6 to disappear
Nov  4 09:01:25.026: INFO: Pod downwardapi-volume-dfc99c9c-4e22-400c-9137-8f3e773d67b6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:01:25.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4014" for this suite.
Nov  4 09:01:31.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:01:31.129: INFO: namespace downward-api-4014 deletion completed in 6.099785823s

• [SLOW TEST:8.300 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:01:31.130: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7627
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  4 09:01:34.301: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:01:34.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7627" for this suite.
Nov  4 09:01:40.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:01:40.456: INFO: namespace container-runtime-7627 deletion completed in 6.128600036s

• [SLOW TEST:9.325 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:01:40.458: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8489
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-df7ee553-9094-478b-a991-dc470ded02c7
STEP: Creating a pod to test consume configMaps
Nov  4 09:01:40.633: INFO: Waiting up to 5m0s for pod "pod-configmaps-1dc1e4fe-0c04-4e83-b342-7807d7d10bbb" in namespace "configmap-8489" to be "success or failure"
Nov  4 09:01:40.638: INFO: Pod "pod-configmaps-1dc1e4fe-0c04-4e83-b342-7807d7d10bbb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.445784ms
Nov  4 09:01:42.641: INFO: Pod "pod-configmaps-1dc1e4fe-0c04-4e83-b342-7807d7d10bbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008423472s
STEP: Saw pod success
Nov  4 09:01:42.642: INFO: Pod "pod-configmaps-1dc1e4fe-0c04-4e83-b342-7807d7d10bbb" satisfied condition "success or failure"
Nov  4 09:01:42.644: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-1dc1e4fe-0c04-4e83-b342-7807d7d10bbb container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 09:01:42.667: INFO: Waiting for pod pod-configmaps-1dc1e4fe-0c04-4e83-b342-7807d7d10bbb to disappear
Nov  4 09:01:42.671: INFO: Pod pod-configmaps-1dc1e4fe-0c04-4e83-b342-7807d7d10bbb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:01:42.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8489" for this suite.
Nov  4 09:01:48.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:01:48.793: INFO: namespace configmap-8489 deletion completed in 6.117198838s

• [SLOW TEST:8.334 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:01:48.794: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9129
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  4 09:01:48.950: INFO: Waiting up to 5m0s for pod "pod-828076fb-cdbe-488b-bc6a-bf424eeeb0aa" in namespace "emptydir-9129" to be "success or failure"
Nov  4 09:01:48.957: INFO: Pod "pod-828076fb-cdbe-488b-bc6a-bf424eeeb0aa": Phase="Pending", Reason="", readiness=false. Elapsed: 6.785705ms
Nov  4 09:01:50.960: INFO: Pod "pod-828076fb-cdbe-488b-bc6a-bf424eeeb0aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009667273s
STEP: Saw pod success
Nov  4 09:01:50.960: INFO: Pod "pod-828076fb-cdbe-488b-bc6a-bf424eeeb0aa" satisfied condition "success or failure"
Nov  4 09:01:50.963: INFO: Trying to get logs from node k8s-1 pod pod-828076fb-cdbe-488b-bc6a-bf424eeeb0aa container test-container: <nil>
STEP: delete the pod
Nov  4 09:01:50.983: INFO: Waiting for pod pod-828076fb-cdbe-488b-bc6a-bf424eeeb0aa to disappear
Nov  4 09:01:50.989: INFO: Pod pod-828076fb-cdbe-488b-bc6a-bf424eeeb0aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:01:50.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9129" for this suite.
Nov  4 09:01:57.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:01:57.097: INFO: namespace emptydir-9129 deletion completed in 6.104826314s

• [SLOW TEST:8.303 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:01:57.098: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1102
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  4 09:01:59.263: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:01:59.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1102" for this suite.
Nov  4 09:02:05.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:02:05.409: INFO: namespace container-runtime-1102 deletion completed in 6.092032828s

• [SLOW TEST:8.312 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:02:05.410: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9383
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  4 09:02:05.555: INFO: Waiting up to 5m0s for pod "pod-1f2b2fe2-0228-4479-a3d9-e3e302b8cf74" in namespace "emptydir-9383" to be "success or failure"
Nov  4 09:02:05.560: INFO: Pod "pod-1f2b2fe2-0228-4479-a3d9-e3e302b8cf74": Phase="Pending", Reason="", readiness=false. Elapsed: 4.761608ms
Nov  4 09:02:07.563: INFO: Pod "pod-1f2b2fe2-0228-4479-a3d9-e3e302b8cf74": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007909147s
Nov  4 09:02:09.566: INFO: Pod "pod-1f2b2fe2-0228-4479-a3d9-e3e302b8cf74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010871041s
STEP: Saw pod success
Nov  4 09:02:09.566: INFO: Pod "pod-1f2b2fe2-0228-4479-a3d9-e3e302b8cf74" satisfied condition "success or failure"
Nov  4 09:02:09.569: INFO: Trying to get logs from node k8s-1 pod pod-1f2b2fe2-0228-4479-a3d9-e3e302b8cf74 container test-container: <nil>
STEP: delete the pod
Nov  4 09:02:09.590: INFO: Waiting for pod pod-1f2b2fe2-0228-4479-a3d9-e3e302b8cf74 to disappear
Nov  4 09:02:09.593: INFO: Pod pod-1f2b2fe2-0228-4479-a3d9-e3e302b8cf74 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:02:09.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9383" for this suite.
Nov  4 09:02:15.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:02:15.706: INFO: namespace emptydir-9383 deletion completed in 6.110085521s

• [SLOW TEST:10.296 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:02:15.707: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-57
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:02:16.368: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 09:02:18.377: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454936, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454936, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454936, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454936, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:02:21.390: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Nov  4 09:02:23.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 attach --namespace=webhook-57 to-be-attached-pod -i -c=container1'
Nov  4 09:02:23.542: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:02:23.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-57" for this suite.
Nov  4 09:02:35.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:02:35.655: INFO: namespace webhook-57 deletion completed in 12.101234348s
STEP: Destroying namespace "webhook-57-markers" for this suite.
Nov  4 09:02:41.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:02:41.762: INFO: namespace webhook-57-markers deletion completed in 6.106090507s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:26.068 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:02:41.776: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-5466
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Nov  4 09:02:42.442: INFO: created pod pod-service-account-defaultsa
Nov  4 09:02:42.442: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov  4 09:02:42.450: INFO: created pod pod-service-account-mountsa
Nov  4 09:02:42.450: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov  4 09:02:42.462: INFO: created pod pod-service-account-nomountsa
Nov  4 09:02:42.462: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov  4 09:02:42.470: INFO: created pod pod-service-account-defaultsa-mountspec
Nov  4 09:02:42.470: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov  4 09:02:42.477: INFO: created pod pod-service-account-mountsa-mountspec
Nov  4 09:02:42.477: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov  4 09:02:42.502: INFO: created pod pod-service-account-nomountsa-mountspec
Nov  4 09:02:42.502: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov  4 09:02:42.519: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov  4 09:02:42.519: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov  4 09:02:42.528: INFO: created pod pod-service-account-mountsa-nomountspec
Nov  4 09:02:42.528: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov  4 09:02:42.544: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov  4 09:02:42.544: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:02:42.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5466" for this suite.
Nov  4 09:02:56.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:02:56.648: INFO: namespace svcaccounts-5466 deletion completed in 14.100099218s

• [SLOW TEST:14.873 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:02:56.649: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-3340
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Nov  4 09:02:56.787: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Nov  4 09:02:57.180: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Nov  4 09:02:59.233: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 09:03:01.235: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 09:03:03.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 09:03:05.238: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 09:03:07.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 09:03:09.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708454977, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 09:03:12.072: INFO: Waited 829.265558ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:03:12.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-3340" for this suite.
Nov  4 09:03:18.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:03:19.056: INFO: namespace aggregator-3340 deletion completed in 6.145734221s

• [SLOW TEST:22.407 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:03:19.057: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9510
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-425d99a3-cbb1-4a2e-9400-eee4feb97379
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:03:19.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9510" for this suite.
Nov  4 09:03:25.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:03:25.295: INFO: namespace secrets-9510 deletion completed in 6.09458238s

• [SLOW TEST:6.239 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:03:25.296: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9460
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 09:03:25.443: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2d006840-37f5-4a0e-8486-0c41fcff578d" in namespace "downward-api-9460" to be "success or failure"
Nov  4 09:03:25.447: INFO: Pod "downwardapi-volume-2d006840-37f5-4a0e-8486-0c41fcff578d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.755267ms
Nov  4 09:03:27.450: INFO: Pod "downwardapi-volume-2d006840-37f5-4a0e-8486-0c41fcff578d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006821292s
STEP: Saw pod success
Nov  4 09:03:27.450: INFO: Pod "downwardapi-volume-2d006840-37f5-4a0e-8486-0c41fcff578d" satisfied condition "success or failure"
Nov  4 09:03:27.453: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-2d006840-37f5-4a0e-8486-0c41fcff578d container client-container: <nil>
STEP: delete the pod
Nov  4 09:03:27.475: INFO: Waiting for pod downwardapi-volume-2d006840-37f5-4a0e-8486-0c41fcff578d to disappear
Nov  4 09:03:27.490: INFO: Pod downwardapi-volume-2d006840-37f5-4a0e-8486-0c41fcff578d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:03:27.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9460" for this suite.
Nov  4 09:03:33.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:03:33.593: INFO: namespace downward-api-9460 deletion completed in 6.099860517s

• [SLOW TEST:8.297 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:03:33.593: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7873
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 09:03:33.749: INFO: Waiting up to 5m0s for pod "downwardapi-volume-62e135c3-7559-4e12-9076-6656803bf16e" in namespace "downward-api-7873" to be "success or failure"
Nov  4 09:03:33.760: INFO: Pod "downwardapi-volume-62e135c3-7559-4e12-9076-6656803bf16e": Phase="Pending", Reason="", readiness=false. Elapsed: 11.276855ms
Nov  4 09:03:35.763: INFO: Pod "downwardapi-volume-62e135c3-7559-4e12-9076-6656803bf16e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014463133s
STEP: Saw pod success
Nov  4 09:03:35.763: INFO: Pod "downwardapi-volume-62e135c3-7559-4e12-9076-6656803bf16e" satisfied condition "success or failure"
Nov  4 09:03:35.766: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-62e135c3-7559-4e12-9076-6656803bf16e container client-container: <nil>
STEP: delete the pod
Nov  4 09:03:35.789: INFO: Waiting for pod downwardapi-volume-62e135c3-7559-4e12-9076-6656803bf16e to disappear
Nov  4 09:03:35.794: INFO: Pod downwardapi-volume-62e135c3-7559-4e12-9076-6656803bf16e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:03:35.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7873" for this suite.
Nov  4 09:03:41.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:03:41.901: INFO: namespace downward-api-7873 deletion completed in 6.104471391s

• [SLOW TEST:8.308 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:03:41.902: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-3342
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Nov  4 09:03:42.051: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-3342" to be "success or failure"
Nov  4 09:03:42.064: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 12.877323ms
Nov  4 09:03:44.067: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016003349s
STEP: Saw pod success
Nov  4 09:03:44.067: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov  4 09:03:44.070: INFO: Trying to get logs from node k8s-1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov  4 09:03:44.090: INFO: Waiting for pod pod-host-path-test to disappear
Nov  4 09:03:44.095: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:03:44.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-3342" for this suite.
Nov  4 09:03:50.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:03:50.189: INFO: namespace hostpath-3342 deletion completed in 6.08939472s

• [SLOW TEST:8.287 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:03:50.190: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8739
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-8ee12479-77f7-4d67-b3a6-538bf40ddd9d
STEP: Creating a pod to test consume configMaps
Nov  4 09:03:50.347: INFO: Waiting up to 5m0s for pod "pod-configmaps-ea02c4d7-fc01-415c-949f-3d375202559e" in namespace "configmap-8739" to be "success or failure"
Nov  4 09:03:50.351: INFO: Pod "pod-configmaps-ea02c4d7-fc01-415c-949f-3d375202559e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.708477ms
Nov  4 09:03:52.354: INFO: Pod "pod-configmaps-ea02c4d7-fc01-415c-949f-3d375202559e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00700381s
STEP: Saw pod success
Nov  4 09:03:52.354: INFO: Pod "pod-configmaps-ea02c4d7-fc01-415c-949f-3d375202559e" satisfied condition "success or failure"
Nov  4 09:03:52.356: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-ea02c4d7-fc01-415c-949f-3d375202559e container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 09:03:52.379: INFO: Waiting for pod pod-configmaps-ea02c4d7-fc01-415c-949f-3d375202559e to disappear
Nov  4 09:03:52.383: INFO: Pod pod-configmaps-ea02c4d7-fc01-415c-949f-3d375202559e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:03:52.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8739" for this suite.
Nov  4 09:03:58.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:03:58.479: INFO: namespace configmap-8739 deletion completed in 6.092372071s

• [SLOW TEST:8.289 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:03:58.479: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6759
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Nov  4 09:03:58.616: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Nov  4 09:04:17.688: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:04:26.214: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:04:43.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6759" for this suite.
Nov  4 09:04:49.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:04:50.042: INFO: namespace crd-publish-openapi-6759 deletion completed in 6.103708478s

• [SLOW TEST:51.562 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:04:50.042: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-737
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Nov  4 09:04:50.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 cluster-info'
Nov  4 09:04:50.315: INFO: stderr: ""
Nov  4 09:04:50.315: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.32.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.32.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:04:50.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-737" for this suite.
Nov  4 09:04:56.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:04:56.424: INFO: namespace kubectl-737 deletion completed in 6.103551017s

• [SLOW TEST:6.382 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:04:56.426: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9397
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Nov  4 09:04:56.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 create -f - --namespace=kubectl-9397'
Nov  4 09:04:56.819: INFO: stderr: ""
Nov  4 09:04:56.819: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  4 09:04:57.822: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 09:04:57.822: INFO: Found 0 / 1
Nov  4 09:04:58.821: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 09:04:58.821: INFO: Found 0 / 1
Nov  4 09:04:59.822: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 09:04:59.822: INFO: Found 0 / 1
Nov  4 09:05:00.823: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 09:05:00.823: INFO: Found 1 / 1
Nov  4 09:05:00.823: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov  4 09:05:00.826: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 09:05:00.826: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  4 09:05:00.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 patch pod redis-master-6z2ht --namespace=kubectl-9397 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov  4 09:05:00.926: INFO: stderr: ""
Nov  4 09:05:00.926: INFO: stdout: "pod/redis-master-6z2ht patched\n"
STEP: checking annotations
Nov  4 09:05:00.929: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 09:05:00.929: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:05:00.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9397" for this suite.
Nov  4 09:05:28.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:05:29.050: INFO: namespace kubectl-9397 deletion completed in 28.117083002s

• [SLOW TEST:32.624 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:05:29.051: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6467
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6467
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  4 09:05:29.187: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  4 09:05:49.325: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.2.89:8080/dial?request=hostName&protocol=http&host=10.33.0.61&port=8080&tries=1'] Namespace:pod-network-test-6467 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:05:49.326: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:05:49.474: INFO: Waiting for endpoints: map[]
Nov  4 09:05:49.478: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.2.89:8080/dial?request=hostName&protocol=http&host=10.33.2.88&port=8080&tries=1'] Namespace:pod-network-test-6467 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:05:49.478: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:05:49.618: INFO: Waiting for endpoints: map[]
Nov  4 09:05:49.621: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.2.89:8080/dial?request=hostName&protocol=http&host=10.33.1.66&port=8080&tries=1'] Namespace:pod-network-test-6467 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:05:49.621: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:05:49.782: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:05:49.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6467" for this suite.
Nov  4 09:06:01.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:06:01.890: INFO: namespace pod-network-test-6467 deletion completed in 12.104250847s

• [SLOW TEST:32.839 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:06:01.891: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9862
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-e42a7c6c-6323-40e8-9bb5-bba18119cbf1
STEP: Creating a pod to test consume secrets
Nov  4 09:06:02.048: INFO: Waiting up to 5m0s for pod "pod-secrets-840edf30-f1b0-4a88-80cc-74f6e89e97b9" in namespace "secrets-9862" to be "success or failure"
Nov  4 09:06:02.062: INFO: Pod "pod-secrets-840edf30-f1b0-4a88-80cc-74f6e89e97b9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.140475ms
Nov  4 09:06:04.065: INFO: Pod "pod-secrets-840edf30-f1b0-4a88-80cc-74f6e89e97b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017403911s
STEP: Saw pod success
Nov  4 09:06:04.065: INFO: Pod "pod-secrets-840edf30-f1b0-4a88-80cc-74f6e89e97b9" satisfied condition "success or failure"
Nov  4 09:06:04.068: INFO: Trying to get logs from node k8s-1 pod pod-secrets-840edf30-f1b0-4a88-80cc-74f6e89e97b9 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 09:06:04.294: INFO: Waiting for pod pod-secrets-840edf30-f1b0-4a88-80cc-74f6e89e97b9 to disappear
Nov  4 09:06:04.297: INFO: Pod pod-secrets-840edf30-f1b0-4a88-80cc-74f6e89e97b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:06:04.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9862" for this suite.
Nov  4 09:06:10.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:06:10.518: INFO: namespace secrets-9862 deletion completed in 6.218087784s

• [SLOW TEST:8.627 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:06:10.518: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4431
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-053fa080-0139-42b1-88cb-7ebdc5ee2523
STEP: Creating a pod to test consume secrets
Nov  4 09:06:10.678: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e27270d8-aef6-4248-a221-083f3db8aa6b" in namespace "projected-4431" to be "success or failure"
Nov  4 09:06:10.681: INFO: Pod "pod-projected-secrets-e27270d8-aef6-4248-a221-083f3db8aa6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.88458ms
Nov  4 09:06:12.685: INFO: Pod "pod-projected-secrets-e27270d8-aef6-4248-a221-083f3db8aa6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006409839s
STEP: Saw pod success
Nov  4 09:06:12.685: INFO: Pod "pod-projected-secrets-e27270d8-aef6-4248-a221-083f3db8aa6b" satisfied condition "success or failure"
Nov  4 09:06:12.687: INFO: Trying to get logs from node k8s-1 pod pod-projected-secrets-e27270d8-aef6-4248-a221-083f3db8aa6b container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 09:06:12.708: INFO: Waiting for pod pod-projected-secrets-e27270d8-aef6-4248-a221-083f3db8aa6b to disappear
Nov  4 09:06:12.713: INFO: Pod pod-projected-secrets-e27270d8-aef6-4248-a221-083f3db8aa6b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:06:12.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4431" for this suite.
Nov  4 09:06:18.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:06:18.822: INFO: namespace projected-4431 deletion completed in 6.105617472s

• [SLOW TEST:8.304 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:06:18.823: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-584
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-584
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-584 to expose endpoints map[]
Nov  4 09:06:18.984: INFO: successfully validated that service endpoint-test2 in namespace services-584 exposes endpoints map[] (4.116521ms elapsed)
STEP: Creating pod pod1 in namespace services-584
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-584 to expose endpoints map[pod1:[80]]
Nov  4 09:06:20.008: INFO: successfully validated that service endpoint-test2 in namespace services-584 exposes endpoints map[pod1:[80]] (1.012758388s elapsed)
STEP: Creating pod pod2 in namespace services-584
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-584 to expose endpoints map[pod1:[80] pod2:[80]]
Nov  4 09:06:22.051: INFO: successfully validated that service endpoint-test2 in namespace services-584 exposes endpoints map[pod1:[80] pod2:[80]] (2.033172992s elapsed)
STEP: Deleting pod pod1 in namespace services-584
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-584 to expose endpoints map[pod2:[80]]
Nov  4 09:06:22.084: INFO: successfully validated that service endpoint-test2 in namespace services-584 exposes endpoints map[pod2:[80]] (16.934821ms elapsed)
STEP: Deleting pod pod2 in namespace services-584
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-584 to expose endpoints map[]
Nov  4 09:06:23.103: INFO: successfully validated that service endpoint-test2 in namespace services-584 exposes endpoints map[] (1.006599143s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:06:23.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-584" for this suite.
Nov  4 09:06:35.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:06:35.232: INFO: namespace services-584 deletion completed in 12.09431822s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.409 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:06:35.232: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-119
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:06:35.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-119" for this suite.
Nov  4 09:06:41.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:06:41.475: INFO: namespace custom-resource-definition-119 deletion completed in 6.100048812s

• [SLOW TEST:6.243 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:06:41.476: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3786
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 09:06:41.611: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 09:06:41.620: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 09:06:41.623: INFO: 
Logging pods the kubelet thinks is on node k8s-1 before test
Nov  4 09:06:41.627: INFO: sonobuoy from sonobuoy started at 2019-11-04 08:33:38 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.627: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 09:06:41.627: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-9v4q5 from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:06:41.628: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 09:06:41.628: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 09:06:41.628: INFO: traefik-ingress-controller-dpwjm from kube-system started at 2019-11-04 08:59:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.628: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 09:06:41.628: INFO: kube-flannel-ds-amd64-mf5hp from kube-system started at 2019-11-04 08:59:44 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.628: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 09:06:41.628: INFO: 
Logging pods the kubelet thinks is on node k8s-2 before test
Nov  4 09:06:41.648: INFO: nginx-6db489d4b7-74qqm from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.648: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.648: INFO: linkerd-identity-6d9bf4497f-qfsm4 from linkerd started at 2019-11-04 08:59:09 +0000 UTC (2 container statuses recorded)
Nov  4 09:06:41.648: INFO: 	Container identity ready: true, restart count 0
Nov  4 09:06:41.648: INFO: 	Container linkerd-proxy ready: true, restart count 0
Nov  4 09:06:41.648: INFO: kubernetes-metrics-scraper-6b97c6d857-cc8fz from kubernetes-dashboard started at 2019-11-04 08:59:09 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.648: INFO: 	Container kubernetes-metrics-scraper ready: true, restart count 0
Nov  4 09:06:41.648: INFO: nginx-6db489d4b7-x9chn from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.648: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.648: INFO: traefik-ingress-controller-2rb4m from kube-system started at 2019-10-31 19:06:43 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.648: INFO: 	Container traefik-ingress-lb ready: true, restart count 2
Nov  4 09:06:41.648: INFO: linkerd-sp-validator-8489dfcf59-4vvmx from linkerd started at 2019-10-31 19:06:42 +0000 UTC (2 container statuses recorded)
Nov  4 09:06:41.648: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:06:41.648: INFO: 	Container sp-validator ready: true, restart count 2
Nov  4 09:06:41.648: INFO: nginx-6db489d4b7-2nv6m from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.648: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.648: INFO: nginx-6db489d4b7-ltjcr from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.649: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.649: INFO: nginx-6db489d4b7-q647m from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.649: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.649: INFO: nginx-6db489d4b7-c4xhg from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.649: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.649: INFO: nginx-6db489d4b7-4rl5q from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.649: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.649: INFO: nginx-6db489d4b7-6hht8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.649: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.649: INFO: sonobuoy-e2e-job-77622933ebe14f87 from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:06:41.649: INFO: 	Container e2e ready: true, restart count 0
Nov  4 09:06:41.649: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 09:06:41.649: INFO: kube-flannel-ds-amd64-f44md from kube-system started at 2019-10-31 19:06:43 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.649: INFO: 	Container kube-flannel ready: true, restart count 2
Nov  4 09:06:41.649: INFO: coredns-b7f8c8654-8kwbt from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.649: INFO: 	Container coredns ready: true, restart count 2
Nov  4 09:06:41.649: INFO: linkerd-web-685cd8d7c-dhpj5 from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:06:41.649: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:06:41.650: INFO: 	Container web ready: true, restart count 2
Nov  4 09:06:41.650: INFO: kubernetes-dashboard-bf855c94d-s95bc from kubernetes-dashboard started at 2019-11-04 08:59:09 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.650: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov  4 09:06:41.650: INFO: nginx-6db489d4b7-w6jwg from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.650: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.650: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-z8dpb from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:06:41.650: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 09:06:41.650: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 09:06:41.650: INFO: nginx-6db489d4b7-t97cp from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.650: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.650: INFO: nginx-6db489d4b7-5lbr9 from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.650: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.650: INFO: nginx-6db489d4b7-rlnhg from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.650: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.650: INFO: nginx-6db489d4b7-hwpf8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.650: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.650: INFO: nginx-6db489d4b7-xds5m from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.650: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.650: INFO: nginx-6db489d4b7-6gqp6 from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.650: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.650: INFO: nginx-6db489d4b7-pbhw4 from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.651: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.651: INFO: nginx-6db489d4b7-x5b7v from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.654: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.654: INFO: linkerd-prometheus-f74b98d8-hgtgk from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:06:41.654: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:06:41.654: INFO: 	Container prometheus ready: true, restart count 2
Nov  4 09:06:41.654: INFO: nginx-6db489d4b7-kcbjs from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.654: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.654: INFO: nginx-6db489d4b7-ncpfq from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.654: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.654: INFO: nginx-6db489d4b7-dk2z8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.654: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.654: INFO: nginx-6db489d4b7-qp42l from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.654: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.654: INFO: linkerd-grafana-744cfbd49d-dnzqr from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:06:41.654: INFO: 	Container grafana ready: true, restart count 2
Nov  4 09:06:41.654: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:06:41.654: INFO: nginx-6db489d4b7-qg6lx from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.654: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.654: INFO: nginx-6db489d4b7-cgwdq from default started at 2019-11-04 08:59:09 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.654: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.654: INFO: nginx-6db489d4b7-lhjpz from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.654: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.654: INFO: nginx-6db489d4b7-xmrg5 from default started at 2019-10-31 19:35:15 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.654: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.654: INFO: nginx-6db489d4b7-8j7fq from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.655: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.655: INFO: 
Logging pods the kubelet thinks is on node k8s-3 before test
Nov  4 09:06:41.675: INFO: nginx-6db489d4b7-hq9kk from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.675: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.675: INFO: nginx-6db489d4b7-wx6gd from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.675: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.675: INFO: nginx-6db489d4b7-zwl99 from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.675: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.675: INFO: nginx-6db489d4b7-545v7 from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.675: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.675: INFO: nginx-6db489d4b7-x46qr from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.675: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.675: INFO: linkerd-tap-8478664cb4-r687h from linkerd started at 2019-11-04 08:59:09 +0000 UTC (2 container statuses recorded)
Nov  4 09:06:41.675: INFO: 	Container linkerd-proxy ready: true, restart count 0
Nov  4 09:06:41.675: INFO: 	Container tap ready: true, restart count 0
Nov  4 09:06:41.675: INFO: nginx-6db489d4b7-6xgqq from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.675: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.675: INFO: linkerd-controller-7f457d599-x5dg5 from linkerd started at 2019-10-31 19:06:42 +0000 UTC (3 container statuses recorded)
Nov  4 09:06:41.675: INFO: 	Container destination ready: true, restart count 2
Nov  4 09:06:41.675: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:06:41.675: INFO: 	Container public-api ready: true, restart count 2
Nov  4 09:06:41.675: INFO: nginx-6db489d4b7-hxbjr from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.675: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.675: INFO: nginx-6db489d4b7-qlxbl from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.675: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.675: INFO: nginx-6db489d4b7-4bl92 from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.675: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.676: INFO: nginx-6db489d4b7-q494r from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.676: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.676: INFO: coredns-b7f8c8654-nxpz9 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.676: INFO: 	Container coredns ready: true, restart count 2
Nov  4 09:06:41.676: INFO: nginx-6db489d4b7-4pxjk from default started at 2019-10-31 19:35:14 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.676: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.676: INFO: nginx-6db489d4b7-7m8cn from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.676: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.676: INFO: nginx-6db489d4b7-5zxqm from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.676: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.676: INFO: nginx-6db489d4b7-5mzcb from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.676: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.676: INFO: kube-flannel-ds-amd64-jc2f4 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.676: INFO: 	Container kube-flannel ready: true, restart count 2
Nov  4 09:06:41.676: INFO: nginx-6db489d4b7-nx48l from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.676: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.676: INFO: nginx-6db489d4b7-6dswq from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.676: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.676: INFO: nginx-6db489d4b7-cbv7l from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.676: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.677: INFO: linkerd-destination-65b7586456-xkd4w from linkerd started at 2019-10-31 19:06:42 +0000 UTC (2 container statuses recorded)
Nov  4 09:06:41.677: INFO: 	Container destination ready: true, restart count 2
Nov  4 09:06:41.677: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:06:41.677: INFO: nginx-6db489d4b7-zvzhk from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.677: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.677: INFO: nginx-6db489d4b7-676cx from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.677: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.677: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-9crmt from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:06:41.677: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 09:06:41.677: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 09:06:41.677: INFO: nginx-6db489d4b7-dnpsl from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.677: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.677: INFO: traefik-ingress-controller-m4sr7 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.677: INFO: 	Container traefik-ingress-lb ready: true, restart count 2
Nov  4 09:06:41.677: INFO: linkerd-proxy-injector-76c5cd6fdb-vtp7v from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:06:41.677: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:06:41.677: INFO: 	Container proxy-injector ready: true, restart count 2
Nov  4 09:06:41.677: INFO: nginx-6db489d4b7-zk6l6 from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.677: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:06:41.677: INFO: tiller-deploy-5798768fb-x6ggz from kube-system started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.677: INFO: 	Container tiller ready: true, restart count 0
Nov  4 09:06:41.677: INFO: nginx-6db489d4b7-hkfrg from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.677: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.677: INFO: nginx-6db489d4b7-rfdsm from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.678: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:06:41.678: INFO: nginx-6db489d4b7-wtgl9 from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:06:41.678: INFO: 	Container nginx ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node k8s-1
STEP: verifying the node has the label node k8s-2
STEP: verifying the node has the label node k8s-3
Nov  4 09:06:41.758: INFO: Pod nginx-6db489d4b7-2nv6m requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.758: INFO: Pod nginx-6db489d4b7-4bl92 requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.758: INFO: Pod nginx-6db489d4b7-4pxjk requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-4rl5q requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-545v7 requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-5lbr9 requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-5mzcb requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-5zxqm requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-676cx requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-6dswq requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-6gqp6 requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-6hht8 requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-6xgqq requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-74qqm requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-7m8cn requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-8j7fq requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-c4xhg requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-cbv7l requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-cgwdq requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-dk2z8 requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-dnpsl requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-hkfrg requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-hq9kk requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-hwpf8 requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-hxbjr requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-kcbjs requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-lhjpz requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-ltjcr requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-ncpfq requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-nx48l requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-pbhw4 requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-q494r requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-q647m requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-qg6lx requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-qlxbl requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-qp42l requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-rfdsm requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-rlnhg requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-t97cp requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-w6jwg requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-wtgl9 requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-wx6gd requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-x46qr requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-x5b7v requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-x9chn requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-xds5m requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-xmrg5 requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-zk6l6 requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-zvzhk requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod nginx-6db489d4b7-zwl99 requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod coredns-b7f8c8654-8kwbt requesting resource cpu=100m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod coredns-b7f8c8654-nxpz9 requesting resource cpu=100m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod kube-flannel-ds-amd64-f44md requesting resource cpu=100m on Node k8s-2
Nov  4 09:06:41.759: INFO: Pod kube-flannel-ds-amd64-jc2f4 requesting resource cpu=100m on Node k8s-3
Nov  4 09:06:41.759: INFO: Pod kube-flannel-ds-amd64-mf5hp requesting resource cpu=100m on Node k8s-1
Nov  4 09:06:41.760: INFO: Pod tiller-deploy-5798768fb-x6ggz requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.760: INFO: Pod traefik-ingress-controller-2rb4m requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.760: INFO: Pod traefik-ingress-controller-dpwjm requesting resource cpu=0m on Node k8s-1
Nov  4 09:06:41.760: INFO: Pod traefik-ingress-controller-m4sr7 requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.760: INFO: Pod kubernetes-dashboard-bf855c94d-s95bc requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.760: INFO: Pod kubernetes-metrics-scraper-6b97c6d857-cc8fz requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.760: INFO: Pod linkerd-controller-7f457d599-x5dg5 requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.760: INFO: Pod linkerd-destination-65b7586456-xkd4w requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.760: INFO: Pod linkerd-grafana-744cfbd49d-dnzqr requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.760: INFO: Pod linkerd-identity-6d9bf4497f-qfsm4 requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.760: INFO: Pod linkerd-prometheus-f74b98d8-hgtgk requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.760: INFO: Pod linkerd-proxy-injector-76c5cd6fdb-vtp7v requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.760: INFO: Pod linkerd-sp-validator-8489dfcf59-4vvmx requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.760: INFO: Pod linkerd-tap-8478664cb4-r687h requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.760: INFO: Pod linkerd-web-685cd8d7c-dhpj5 requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.760: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-1
Nov  4 09:06:41.760: INFO: Pod sonobuoy-e2e-job-77622933ebe14f87 requesting resource cpu=0m on Node k8s-2
Nov  4 09:06:41.760: INFO: Pod sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-9crmt requesting resource cpu=0m on Node k8s-3
Nov  4 09:06:41.760: INFO: Pod sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-9v4q5 requesting resource cpu=0m on Node k8s-1
Nov  4 09:06:41.760: INFO: Pod sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-z8dpb requesting resource cpu=0m on Node k8s-2
STEP: Starting Pods to consume most of the cluster CPU.
Nov  4 09:06:41.760: INFO: Creating a pod which consumes cpu=630m on Node k8s-1
Nov  4 09:06:41.779: INFO: Creating a pod which consumes cpu=560m on Node k8s-2
Nov  4 09:06:41.794: INFO: Creating a pod which consumes cpu=560m on Node k8s-3
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0da4548b-2754-4ebf-9b3e-f5767b1b8f82.15d3ea6210b53e92], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3786/filler-pod-0da4548b-2754-4ebf-9b3e-f5767b1b8f82 to k8s-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0da4548b-2754-4ebf-9b3e-f5767b1b8f82.15d3ea622ca210ce], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0da4548b-2754-4ebf-9b3e-f5767b1b8f82.15d3ea622f8aed96], Reason = [Created], Message = [Created container filler-pod-0da4548b-2754-4ebf-9b3e-f5767b1b8f82]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0da4548b-2754-4ebf-9b3e-f5767b1b8f82.15d3ea6235443f18], Reason = [Started], Message = [Started container filler-pod-0da4548b-2754-4ebf-9b3e-f5767b1b8f82]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4ab06391-a474-4fae-bfb6-11ead0d0eac3.15d3ea621239aaec], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3786/filler-pod-4ab06391-a474-4fae-bfb6-11ead0d0eac3 to k8s-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4ab06391-a474-4fae-bfb6-11ead0d0eac3.15d3ea6234083c7f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4ab06391-a474-4fae-bfb6-11ead0d0eac3.15d3ea6236b24c3d], Reason = [Created], Message = [Created container filler-pod-4ab06391-a474-4fae-bfb6-11ead0d0eac3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4ab06391-a474-4fae-bfb6-11ead0d0eac3.15d3ea623e58d59b], Reason = [Started], Message = [Started container filler-pod-4ab06391-a474-4fae-bfb6-11ead0d0eac3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8551dd2-cfd4-4741-9198-81900cc314d7.15d3ea621296a78f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3786/filler-pod-a8551dd2-cfd4-4741-9198-81900cc314d7 to k8s-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8551dd2-cfd4-4741-9198-81900cc314d7.15d3ea6234badba9], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8551dd2-cfd4-4741-9198-81900cc314d7.15d3ea6238074923], Reason = [Created], Message = [Created container filler-pod-a8551dd2-cfd4-4741-9198-81900cc314d7]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8551dd2-cfd4-4741-9198-81900cc314d7.15d3ea624304e91d], Reason = [Started], Message = [Started container filler-pod-a8551dd2-cfd4-4741-9198-81900cc314d7]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d3ea628a362d9b], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d3ea628af52ccb], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node k8s-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:06:44.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3786" for this suite.
Nov  4 09:06:50.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:06:50.989: INFO: namespace sched-pred-3786 deletion completed in 6.105378099s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:9.513 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:06:50.990: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6267
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:06:51.867: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:06:54.884: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:06:54.887: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2750-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:07:00.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6267" for this suite.
Nov  4 09:07:06.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:07:06.696: INFO: namespace webhook-6267 deletion completed in 6.101646151s
STEP: Destroying namespace "webhook-6267-markers" for this suite.
Nov  4 09:07:12.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:07:12.790: INFO: namespace webhook-6267-markers deletion completed in 6.094373159s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.816 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:07:12.807: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:07:13.565: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 09:07:15.573: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455233, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455233, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455233, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455233, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:07:18.586: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:07:18.589: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9374-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:07:25.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6836" for this suite.
Nov  4 09:07:31.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:07:31.616: INFO: namespace webhook-6836 deletion completed in 6.107584594s
STEP: Destroying namespace "webhook-6836-markers" for this suite.
Nov  4 09:07:37.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:07:37.732: INFO: namespace webhook-6836-markers deletion completed in 6.116263473s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.942 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:07:37.750: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9657
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-73173c14-7e54-489f-9a15-70bc9875aa87
STEP: Creating a pod to test consume configMaps
Nov  4 09:07:37.913: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2b86702d-b49c-4e12-a4a7-906b42ab0ac5" in namespace "projected-9657" to be "success or failure"
Nov  4 09:07:37.921: INFO: Pod "pod-projected-configmaps-2b86702d-b49c-4e12-a4a7-906b42ab0ac5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.672568ms
Nov  4 09:07:39.923: INFO: Pod "pod-projected-configmaps-2b86702d-b49c-4e12-a4a7-906b42ab0ac5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010577184s
STEP: Saw pod success
Nov  4 09:07:39.924: INFO: Pod "pod-projected-configmaps-2b86702d-b49c-4e12-a4a7-906b42ab0ac5" satisfied condition "success or failure"
Nov  4 09:07:39.926: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-2b86702d-b49c-4e12-a4a7-906b42ab0ac5 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 09:07:39.951: INFO: Waiting for pod pod-projected-configmaps-2b86702d-b49c-4e12-a4a7-906b42ab0ac5 to disappear
Nov  4 09:07:39.953: INFO: Pod pod-projected-configmaps-2b86702d-b49c-4e12-a4a7-906b42ab0ac5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:07:39.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9657" for this suite.
Nov  4 09:07:45.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:07:46.056: INFO: namespace projected-9657 deletion completed in 6.100109287s

• [SLOW TEST:8.307 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:07:46.057: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1690
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Nov  4 09:07:48.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec pod-sharedvolume-6ea2e8a5-a484-4933-ba2f-3b6530d373d2 -c busybox-main-container --namespace=emptydir-1690 -- cat /usr/share/volumeshare/shareddata.txt'
Nov  4 09:07:48.471: INFO: stderr: ""
Nov  4 09:07:48.471: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:07:48.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1690" for this suite.
Nov  4 09:07:54.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:07:54.587: INFO: namespace emptydir-1690 deletion completed in 6.112377482s

• [SLOW TEST:8.530 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:07:54.587: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4635
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 09:07:54.736: INFO: Waiting up to 5m0s for pod "downwardapi-volume-94e384c9-a4c8-40ce-9f38-4ea30df4dc9c" in namespace "projected-4635" to be "success or failure"
Nov  4 09:07:54.745: INFO: Pod "downwardapi-volume-94e384c9-a4c8-40ce-9f38-4ea30df4dc9c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.683076ms
Nov  4 09:07:56.748: INFO: Pod "downwardapi-volume-94e384c9-a4c8-40ce-9f38-4ea30df4dc9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011581901s
STEP: Saw pod success
Nov  4 09:07:56.748: INFO: Pod "downwardapi-volume-94e384c9-a4c8-40ce-9f38-4ea30df4dc9c" satisfied condition "success or failure"
Nov  4 09:07:56.750: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-94e384c9-a4c8-40ce-9f38-4ea30df4dc9c container client-container: <nil>
STEP: delete the pod
Nov  4 09:07:56.773: INFO: Waiting for pod downwardapi-volume-94e384c9-a4c8-40ce-9f38-4ea30df4dc9c to disappear
Nov  4 09:07:56.781: INFO: Pod downwardapi-volume-94e384c9-a4c8-40ce-9f38-4ea30df4dc9c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:07:56.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4635" for this suite.
Nov  4 09:08:02.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:08:02.883: INFO: namespace projected-4635 deletion completed in 6.0985176s

• [SLOW TEST:8.295 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:08:02.883: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1849
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:08:08.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1849" for this suite.
Nov  4 09:08:14.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:08:14.919: INFO: namespace watch-1849 deletion completed in 6.180258032s

• [SLOW TEST:12.035 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:08:14.919: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9361
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-2b2e3143-d7d4-4296-89f8-6fd071f86efe
Nov  4 09:08:15.069: INFO: Pod name my-hostname-basic-2b2e3143-d7d4-4296-89f8-6fd071f86efe: Found 0 pods out of 1
Nov  4 09:08:20.073: INFO: Pod name my-hostname-basic-2b2e3143-d7d4-4296-89f8-6fd071f86efe: Found 1 pods out of 1
Nov  4 09:08:20.073: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-2b2e3143-d7d4-4296-89f8-6fd071f86efe" are running
Nov  4 09:08:20.076: INFO: Pod "my-hostname-basic-2b2e3143-d7d4-4296-89f8-6fd071f86efe-752l7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 09:08:15 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 09:08:16 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 09:08:16 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 09:08:15 +0000 UTC Reason: Message:}])
Nov  4 09:08:20.076: INFO: Trying to dial the pod
Nov  4 09:08:25.087: INFO: Controller my-hostname-basic-2b2e3143-d7d4-4296-89f8-6fd071f86efe: Got expected result from replica 1 [my-hostname-basic-2b2e3143-d7d4-4296-89f8-6fd071f86efe-752l7]: "my-hostname-basic-2b2e3143-d7d4-4296-89f8-6fd071f86efe-752l7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:08:25.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9361" for this suite.
Nov  4 09:08:31.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:08:31.201: INFO: namespace replication-controller-9361 deletion completed in 6.110210282s

• [SLOW TEST:16.282 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:08:31.202: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2781
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Nov  4 09:08:31.350: INFO: Waiting up to 5m0s for pod "client-containers-969bb873-0c9f-4e36-8c8b-5abf4f00c69e" in namespace "containers-2781" to be "success or failure"
Nov  4 09:08:31.364: INFO: Pod "client-containers-969bb873-0c9f-4e36-8c8b-5abf4f00c69e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.610458ms
Nov  4 09:08:33.367: INFO: Pod "client-containers-969bb873-0c9f-4e36-8c8b-5abf4f00c69e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016787342s
STEP: Saw pod success
Nov  4 09:08:33.367: INFO: Pod "client-containers-969bb873-0c9f-4e36-8c8b-5abf4f00c69e" satisfied condition "success or failure"
Nov  4 09:08:33.369: INFO: Trying to get logs from node k8s-1 pod client-containers-969bb873-0c9f-4e36-8c8b-5abf4f00c69e container test-container: <nil>
STEP: delete the pod
Nov  4 09:08:33.396: INFO: Waiting for pod client-containers-969bb873-0c9f-4e36-8c8b-5abf4f00c69e to disappear
Nov  4 09:08:33.398: INFO: Pod client-containers-969bb873-0c9f-4e36-8c8b-5abf4f00c69e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:08:33.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2781" for this suite.
Nov  4 09:08:39.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:08:39.514: INFO: namespace containers-2781 deletion completed in 6.111556613s

• [SLOW TEST:8.313 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:08:39.515: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4681
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  4 09:08:39.677: INFO: Waiting up to 5m0s for pod "pod-da464642-aef8-4718-bb94-0b567dda3a9c" in namespace "emptydir-4681" to be "success or failure"
Nov  4 09:08:39.689: INFO: Pod "pod-da464642-aef8-4718-bb94-0b567dda3a9c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.93316ms
Nov  4 09:08:41.692: INFO: Pod "pod-da464642-aef8-4718-bb94-0b567dda3a9c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01485982s
Nov  4 09:08:43.695: INFO: Pod "pod-da464642-aef8-4718-bb94-0b567dda3a9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017951662s
STEP: Saw pod success
Nov  4 09:08:43.695: INFO: Pod "pod-da464642-aef8-4718-bb94-0b567dda3a9c" satisfied condition "success or failure"
Nov  4 09:08:43.698: INFO: Trying to get logs from node k8s-1 pod pod-da464642-aef8-4718-bb94-0b567dda3a9c container test-container: <nil>
STEP: delete the pod
Nov  4 09:08:43.723: INFO: Waiting for pod pod-da464642-aef8-4718-bb94-0b567dda3a9c to disappear
Nov  4 09:08:43.726: INFO: Pod pod-da464642-aef8-4718-bb94-0b567dda3a9c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:08:43.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4681" for this suite.
Nov  4 09:08:49.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:08:49.827: INFO: namespace emptydir-4681 deletion completed in 6.097070708s

• [SLOW TEST:10.312 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:08:49.827: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5062
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 09:08:49.963: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 09:08:49.973: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 09:08:49.975: INFO: 
Logging pods the kubelet thinks is on node k8s-1 before test
Nov  4 09:08:49.980: INFO: sonobuoy from sonobuoy started at 2019-11-04 08:33:38 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:49.980: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 09:08:49.980: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-9v4q5 from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:08:49.980: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 09:08:49.980: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 09:08:49.980: INFO: traefik-ingress-controller-dpwjm from kube-system started at 2019-11-04 08:59:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:49.980: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 09:08:49.980: INFO: kube-flannel-ds-amd64-mf5hp from kube-system started at 2019-11-04 08:59:44 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:49.980: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 09:08:49.980: INFO: 
Logging pods the kubelet thinks is on node k8s-2 before test
Nov  4 09:08:49.999: INFO: nginx-6db489d4b7-5lbr9 from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:49.999: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:49.999: INFO: nginx-6db489d4b7-rlnhg from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:49.999: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.000: INFO: nginx-6db489d4b7-w6jwg from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.000: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.000: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-z8dpb from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:08:50.000: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 09:08:50.000: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 09:08:50.000: INFO: nginx-6db489d4b7-t97cp from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.000: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.000: INFO: linkerd-prometheus-f74b98d8-hgtgk from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:08:50.000: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:08:50.000: INFO: 	Container prometheus ready: true, restart count 2
Nov  4 09:08:50.000: INFO: nginx-6db489d4b7-kcbjs from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.000: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.000: INFO: nginx-6db489d4b7-hwpf8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.000: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.000: INFO: nginx-6db489d4b7-xds5m from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.000: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.000: INFO: nginx-6db489d4b7-6gqp6 from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.000: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.000: INFO: nginx-6db489d4b7-pbhw4 from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.000: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.001: INFO: nginx-6db489d4b7-x5b7v from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.001: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.001: INFO: linkerd-grafana-744cfbd49d-dnzqr from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:08:50.001: INFO: 	Container grafana ready: true, restart count 2
Nov  4 09:08:50.001: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:08:50.001: INFO: nginx-6db489d4b7-qg6lx from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.001: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.001: INFO: nginx-6db489d4b7-ncpfq from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.001: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.001: INFO: nginx-6db489d4b7-dk2z8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.001: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.001: INFO: nginx-6db489d4b7-qp42l from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.001: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.001: INFO: nginx-6db489d4b7-xmrg5 from default started at 2019-10-31 19:35:15 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.001: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.001: INFO: nginx-6db489d4b7-8j7fq from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.001: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.001: INFO: nginx-6db489d4b7-cgwdq from default started at 2019-11-04 08:59:09 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.002: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.002: INFO: nginx-6db489d4b7-lhjpz from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.002: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.002: INFO: traefik-ingress-controller-2rb4m from kube-system started at 2019-10-31 19:06:43 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.002: INFO: 	Container traefik-ingress-lb ready: true, restart count 2
Nov  4 09:08:50.002: INFO: linkerd-sp-validator-8489dfcf59-4vvmx from linkerd started at 2019-10-31 19:06:42 +0000 UTC (2 container statuses recorded)
Nov  4 09:08:50.002: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:08:50.002: INFO: 	Container sp-validator ready: true, restart count 2
Nov  4 09:08:50.002: INFO: nginx-6db489d4b7-74qqm from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.002: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.002: INFO: linkerd-identity-6d9bf4497f-qfsm4 from linkerd started at 2019-11-04 08:59:09 +0000 UTC (2 container statuses recorded)
Nov  4 09:08:50.002: INFO: 	Container identity ready: true, restart count 0
Nov  4 09:08:50.002: INFO: 	Container linkerd-proxy ready: true, restart count 0
Nov  4 09:08:50.002: INFO: kubernetes-metrics-scraper-6b97c6d857-cc8fz from kubernetes-dashboard started at 2019-11-04 08:59:09 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.002: INFO: 	Container kubernetes-metrics-scraper ready: true, restart count 0
Nov  4 09:08:50.002: INFO: nginx-6db489d4b7-x9chn from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.002: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.002: INFO: nginx-6db489d4b7-2nv6m from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.002: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.002: INFO: nginx-6db489d4b7-ltjcr from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.002: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.003: INFO: kube-flannel-ds-amd64-f44md from kube-system started at 2019-10-31 19:06:43 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.003: INFO: 	Container kube-flannel ready: true, restart count 2
Nov  4 09:08:50.003: INFO: coredns-b7f8c8654-8kwbt from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.003: INFO: 	Container coredns ready: true, restart count 2
Nov  4 09:08:50.003: INFO: nginx-6db489d4b7-q647m from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.003: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.003: INFO: nginx-6db489d4b7-c4xhg from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.003: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.003: INFO: nginx-6db489d4b7-4rl5q from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.003: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.003: INFO: nginx-6db489d4b7-6hht8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.003: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.003: INFO: sonobuoy-e2e-job-77622933ebe14f87 from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:08:50.003: INFO: 	Container e2e ready: true, restart count 0
Nov  4 09:08:50.003: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 09:08:50.003: INFO: linkerd-web-685cd8d7c-dhpj5 from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:08:50.003: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:08:50.003: INFO: 	Container web ready: true, restart count 2
Nov  4 09:08:50.004: INFO: kubernetes-dashboard-bf855c94d-s95bc from kubernetes-dashboard started at 2019-11-04 08:59:09 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.004: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov  4 09:08:50.004: INFO: 
Logging pods the kubelet thinks is on node k8s-3 before test
Nov  4 09:08:50.024: INFO: nginx-6db489d4b7-hq9kk from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.024: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.024: INFO: nginx-6db489d4b7-wx6gd from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.024: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.024: INFO: nginx-6db489d4b7-zwl99 from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.024: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.024: INFO: nginx-6db489d4b7-545v7 from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.024: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.024: INFO: nginx-6db489d4b7-x46qr from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.025: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.025: INFO: linkerd-tap-8478664cb4-r687h from linkerd started at 2019-11-04 08:59:09 +0000 UTC (2 container statuses recorded)
Nov  4 09:08:50.025: INFO: 	Container linkerd-proxy ready: true, restart count 0
Nov  4 09:08:50.025: INFO: 	Container tap ready: true, restart count 0
Nov  4 09:08:50.025: INFO: nginx-6db489d4b7-6xgqq from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.025: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.025: INFO: linkerd-controller-7f457d599-x5dg5 from linkerd started at 2019-10-31 19:06:42 +0000 UTC (3 container statuses recorded)
Nov  4 09:08:50.025: INFO: 	Container destination ready: true, restart count 2
Nov  4 09:08:50.025: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:08:50.025: INFO: 	Container public-api ready: true, restart count 2
Nov  4 09:08:50.025: INFO: nginx-6db489d4b7-hxbjr from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.025: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.025: INFO: nginx-6db489d4b7-qlxbl from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.025: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.025: INFO: nginx-6db489d4b7-4bl92 from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.025: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.025: INFO: nginx-6db489d4b7-q494r from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.025: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.025: INFO: coredns-b7f8c8654-nxpz9 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.025: INFO: 	Container coredns ready: true, restart count 2
Nov  4 09:08:50.025: INFO: nginx-6db489d4b7-4pxjk from default started at 2019-10-31 19:35:14 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.025: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.025: INFO: nginx-6db489d4b7-7m8cn from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.025: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.026: INFO: nginx-6db489d4b7-5zxqm from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.026: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.026: INFO: nginx-6db489d4b7-5mzcb from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.026: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.026: INFO: kube-flannel-ds-amd64-jc2f4 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.026: INFO: 	Container kube-flannel ready: true, restart count 2
Nov  4 09:08:50.026: INFO: nginx-6db489d4b7-nx48l from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.026: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.026: INFO: nginx-6db489d4b7-6dswq from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.026: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.026: INFO: nginx-6db489d4b7-cbv7l from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.026: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.026: INFO: linkerd-destination-65b7586456-xkd4w from linkerd started at 2019-10-31 19:06:42 +0000 UTC (2 container statuses recorded)
Nov  4 09:08:50.026: INFO: 	Container destination ready: true, restart count 2
Nov  4 09:08:50.026: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:08:50.026: INFO: nginx-6db489d4b7-zvzhk from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.026: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.026: INFO: nginx-6db489d4b7-676cx from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.026: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.027: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-9crmt from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:08:50.027: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 09:08:50.027: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 09:08:50.027: INFO: nginx-6db489d4b7-dnpsl from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.027: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.027: INFO: traefik-ingress-controller-m4sr7 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.027: INFO: 	Container traefik-ingress-lb ready: true, restart count 2
Nov  4 09:08:50.027: INFO: linkerd-proxy-injector-76c5cd6fdb-vtp7v from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:08:50.027: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:08:50.027: INFO: 	Container proxy-injector ready: true, restart count 2
Nov  4 09:08:50.027: INFO: nginx-6db489d4b7-zk6l6 from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.027: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:08:50.027: INFO: tiller-deploy-5798768fb-x6ggz from kube-system started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.027: INFO: 	Container tiller ready: true, restart count 0
Nov  4 09:08:50.027: INFO: nginx-6db489d4b7-hkfrg from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.028: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.028: INFO: nginx-6db489d4b7-rfdsm from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.028: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:08:50.028: INFO: nginx-6db489d4b7-wtgl9 from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:08:50.028: INFO: 	Container nginx ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-8dd167d5-9b69-4fa2-b81d-7bc40cd99e3f 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-8dd167d5-9b69-4fa2-b81d-7bc40cd99e3f off the node k8s-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-8dd167d5-9b69-4fa2-b81d-7bc40cd99e3f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:08:58.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5062" for this suite.
Nov  4 09:09:16.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:09:16.283: INFO: namespace sched-pred-5062 deletion completed in 18.130080025s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:26.456 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:09:16.285: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3462
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Nov  4 09:09:16.453: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:09:24.541: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:09:42.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3462" for this suite.
Nov  4 09:09:48.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:09:48.876: INFO: namespace crd-publish-openapi-3462 deletion completed in 6.107076978s

• [SLOW TEST:32.592 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:09:48.877: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5250
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-6f604419-79d3-4a1c-a480-f321202fcce1
STEP: Creating a pod to test consume secrets
Nov  4 09:09:49.104: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b1adbe5e-2df7-4249-9a41-899f3e8c93f4" in namespace "projected-5250" to be "success or failure"
Nov  4 09:09:49.117: INFO: Pod "pod-projected-secrets-b1adbe5e-2df7-4249-9a41-899f3e8c93f4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.641121ms
Nov  4 09:09:51.121: INFO: Pod "pod-projected-secrets-b1adbe5e-2df7-4249-9a41-899f3e8c93f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01619021s
STEP: Saw pod success
Nov  4 09:09:51.121: INFO: Pod "pod-projected-secrets-b1adbe5e-2df7-4249-9a41-899f3e8c93f4" satisfied condition "success or failure"
Nov  4 09:09:51.124: INFO: Trying to get logs from node k8s-1 pod pod-projected-secrets-b1adbe5e-2df7-4249-9a41-899f3e8c93f4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 09:09:51.150: INFO: Waiting for pod pod-projected-secrets-b1adbe5e-2df7-4249-9a41-899f3e8c93f4 to disappear
Nov  4 09:09:51.156: INFO: Pod pod-projected-secrets-b1adbe5e-2df7-4249-9a41-899f3e8c93f4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:09:51.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5250" for this suite.
Nov  4 09:09:57.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:09:57.287: INFO: namespace projected-5250 deletion completed in 6.126924475s

• [SLOW TEST:8.410 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:09:57.287: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4882
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 09:09:57.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4882'
Nov  4 09:09:57.629: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 09:09:57.629: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Nov  4 09:09:59.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete deployment e2e-test-httpd-deployment --namespace=kubectl-4882'
Nov  4 09:09:59.736: INFO: stderr: ""
Nov  4 09:09:59.736: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:09:59.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4882" for this suite.
Nov  4 09:10:27.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:10:27.841: INFO: namespace kubectl-4882 deletion completed in 28.100908224s

• [SLOW TEST:30.554 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:10:27.842: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6794
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-46b746b4-4629-44ad-b26d-579ec9909d03
STEP: Creating a pod to test consume configMaps
Nov  4 09:10:28.008: INFO: Waiting up to 5m0s for pod "pod-configmaps-ad20d3a4-6370-4bf2-a5d4-9b610beaefbf" in namespace "configmap-6794" to be "success or failure"
Nov  4 09:10:28.020: INFO: Pod "pod-configmaps-ad20d3a4-6370-4bf2-a5d4-9b610beaefbf": Phase="Pending", Reason="", readiness=false. Elapsed: 11.892877ms
Nov  4 09:10:30.023: INFO: Pod "pod-configmaps-ad20d3a4-6370-4bf2-a5d4-9b610beaefbf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014984189s
STEP: Saw pod success
Nov  4 09:10:30.023: INFO: Pod "pod-configmaps-ad20d3a4-6370-4bf2-a5d4-9b610beaefbf" satisfied condition "success or failure"
Nov  4 09:10:30.026: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-ad20d3a4-6370-4bf2-a5d4-9b610beaefbf container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 09:10:30.048: INFO: Waiting for pod pod-configmaps-ad20d3a4-6370-4bf2-a5d4-9b610beaefbf to disappear
Nov  4 09:10:30.052: INFO: Pod pod-configmaps-ad20d3a4-6370-4bf2-a5d4-9b610beaefbf no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:10:30.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6794" for this suite.
Nov  4 09:10:36.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:10:36.160: INFO: namespace configmap-6794 deletion completed in 6.104711437s

• [SLOW TEST:8.319 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:10:36.161: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5982
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:10:36.302: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov  4 09:10:36.311: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov  4 09:10:41.315: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  4 09:10:41.315: INFO: Creating deployment "test-rolling-update-deployment"
Nov  4 09:10:41.319: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov  4 09:10:41.326: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov  4 09:10:43.333: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov  4 09:10:43.336: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 09:10:43.346: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-5982 /apis/apps/v1/namespaces/deployment-5982/deployments/test-rolling-update-deployment f083df67-1b6f-4876-84be-13c7846eb1ae 518827 1 2019-11-04 09:10:41 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0061eb918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-11-04 09:10:41 +0000 UTC,LastTransitionTime:2019-11-04 09:10:41 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-11-04 09:10:42 +0000 UTC,LastTransitionTime:2019-11-04 09:10:41 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  4 09:10:43.352: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-5982 /apis/apps/v1/namespaces/deployment-5982/replicasets/test-rolling-update-deployment-55d946486 212af475-43c0-4665-974b-68b57793a7f4 518814 1 2019-11-04 09:10:41 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment f083df67-1b6f-4876-84be-13c7846eb1ae 0xc0061ebea0 0xc0061ebea1}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0061ebf08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  4 09:10:43.352: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov  4 09:10:43.352: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-5982 /apis/apps/v1/namespaces/deployment-5982/replicasets/test-rolling-update-controller 6e3d0f00-5764-4ffe-8325-a69f498aaffc 518826 2 2019-11-04 09:10:36 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment f083df67-1b6f-4876-84be-13c7846eb1ae 0xc0061ebdd7 0xc0061ebdd8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0061ebe38 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 09:10:43.355: INFO: Pod "test-rolling-update-deployment-55d946486-tv7zz" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-tv7zz test-rolling-update-deployment-55d946486- deployment-5982 /api/v1/namespaces/deployment-5982/pods/test-rolling-update-deployment-55d946486-tv7zz 2b502f31-4854-4b3a-8bf5-3fb6f4f76875 518813 0 2019-11-04 09:10:41 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 212af475-43c0-4665-974b-68b57793a7f4 0xc0034163e0 0xc0034163e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-69tdx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-69tdx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-69tdx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:10:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:10:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:10:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:10:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.2.110,StartTime:2019-11-04 09:10:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 09:10:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://2fa08bd1b8ea6427efeabfe79f07a2e7b4facdc0984c001b74458887a1775ea0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.110,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:10:43.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5982" for this suite.
Nov  4 09:10:49.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:10:49.457: INFO: namespace deployment-5982 deletion completed in 6.098094061s

• [SLOW TEST:13.296 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:10:49.457: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-3084
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:10:50.552: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Nov  4 09:10:52.561: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455450, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455450, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455450, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455450, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:10:55.573: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:10:55.575: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:11:01.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3084" for this suite.
Nov  4 09:11:07.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:11:07.408: INFO: namespace crd-webhook-3084 deletion completed in 6.106907458s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:17.966 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:11:07.423: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4285
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-4e94a417-8d31-47af-b518-943901a12ee3
STEP: Creating a pod to test consume configMaps
Nov  4 09:11:07.578: INFO: Waiting up to 5m0s for pod "pod-configmaps-32d7c288-9f13-465f-8c9d-86b1a5c04b30" in namespace "configmap-4285" to be "success or failure"
Nov  4 09:11:07.588: INFO: Pod "pod-configmaps-32d7c288-9f13-465f-8c9d-86b1a5c04b30": Phase="Pending", Reason="", readiness=false. Elapsed: 9.762636ms
Nov  4 09:11:09.591: INFO: Pod "pod-configmaps-32d7c288-9f13-465f-8c9d-86b1a5c04b30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01314253s
STEP: Saw pod success
Nov  4 09:11:09.592: INFO: Pod "pod-configmaps-32d7c288-9f13-465f-8c9d-86b1a5c04b30" satisfied condition "success or failure"
Nov  4 09:11:09.595: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-32d7c288-9f13-465f-8c9d-86b1a5c04b30 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 09:11:09.698: INFO: Waiting for pod pod-configmaps-32d7c288-9f13-465f-8c9d-86b1a5c04b30 to disappear
Nov  4 09:11:09.701: INFO: Pod pod-configmaps-32d7c288-9f13-465f-8c9d-86b1a5c04b30 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:11:09.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4285" for this suite.
Nov  4 09:11:15.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:11:15.799: INFO: namespace configmap-4285 deletion completed in 6.094664413s

• [SLOW TEST:8.376 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:11:15.799: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1983
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  4 09:11:15.946: INFO: Waiting up to 5m0s for pod "pod-d751ef51-c152-421d-b39c-36855a951798" in namespace "emptydir-1983" to be "success or failure"
Nov  4 09:11:15.950: INFO: Pod "pod-d751ef51-c152-421d-b39c-36855a951798": Phase="Pending", Reason="", readiness=false. Elapsed: 4.246512ms
Nov  4 09:11:17.953: INFO: Pod "pod-d751ef51-c152-421d-b39c-36855a951798": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007163357s
STEP: Saw pod success
Nov  4 09:11:17.953: INFO: Pod "pod-d751ef51-c152-421d-b39c-36855a951798" satisfied condition "success or failure"
Nov  4 09:11:17.956: INFO: Trying to get logs from node k8s-1 pod pod-d751ef51-c152-421d-b39c-36855a951798 container test-container: <nil>
STEP: delete the pod
Nov  4 09:11:17.977: INFO: Waiting for pod pod-d751ef51-c152-421d-b39c-36855a951798 to disappear
Nov  4 09:11:17.980: INFO: Pod pod-d751ef51-c152-421d-b39c-36855a951798 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:11:17.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1983" for this suite.
Nov  4 09:11:23.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:11:24.077: INFO: namespace emptydir-1983 deletion completed in 6.093262404s

• [SLOW TEST:8.278 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:11:24.078: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9960
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 09:11:24.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-9960'
Nov  4 09:11:24.317: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 09:11:24.317: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Nov  4 09:11:24.322: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Nov  4 09:11:24.334: INFO: scanned /root for discovery docs: <nil>
Nov  4 09:11:24.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9960'
Nov  4 09:11:40.463: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  4 09:11:40.463: INFO: stdout: "Created e2e-test-httpd-rc-82c3bf1e4d5969d2232e09e56c6e22df\nScaling up e2e-test-httpd-rc-82c3bf1e4d5969d2232e09e56c6e22df from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-82c3bf1e4d5969d2232e09e56c6e22df up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-82c3bf1e4d5969d2232e09e56c6e22df to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Nov  4 09:11:40.463: INFO: stdout: "Created e2e-test-httpd-rc-82c3bf1e4d5969d2232e09e56c6e22df\nScaling up e2e-test-httpd-rc-82c3bf1e4d5969d2232e09e56c6e22df from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-82c3bf1e4d5969d2232e09e56c6e22df up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-82c3bf1e4d5969d2232e09e56c6e22df to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Nov  4 09:11:40.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-9960'
Nov  4 09:11:40.565: INFO: stderr: ""
Nov  4 09:11:40.565: INFO: stdout: "e2e-test-httpd-rc-7qz6g e2e-test-httpd-rc-82c3bf1e4d5969d2232e09e56c6e22df-t6n2d "
STEP: Replicas for run=e2e-test-httpd-rc: expected=1 actual=2
Nov  4 09:11:45.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-9960'
Nov  4 09:11:45.645: INFO: stderr: ""
Nov  4 09:11:45.645: INFO: stdout: "e2e-test-httpd-rc-82c3bf1e4d5969d2232e09e56c6e22df-t6n2d "
Nov  4 09:11:45.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods e2e-test-httpd-rc-82c3bf1e4d5969d2232e09e56c6e22df-t6n2d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9960'
Nov  4 09:11:45.754: INFO: stderr: ""
Nov  4 09:11:45.755: INFO: stdout: "true"
Nov  4 09:11:45.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods e2e-test-httpd-rc-82c3bf1e4d5969d2232e09e56c6e22df-t6n2d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9960'
Nov  4 09:11:45.827: INFO: stderr: ""
Nov  4 09:11:45.827: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Nov  4 09:11:45.827: INFO: e2e-test-httpd-rc-82c3bf1e4d5969d2232e09e56c6e22df-t6n2d is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Nov  4 09:11:45.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete rc e2e-test-httpd-rc --namespace=kubectl-9960'
Nov  4 09:11:45.912: INFO: stderr: ""
Nov  4 09:11:45.912: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:11:45.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9960" for this suite.
Nov  4 09:11:57.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:11:58.031: INFO: namespace kubectl-9960 deletion completed in 12.114600965s

• [SLOW TEST:33.953 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:11:58.032: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8401
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 09:11:58.187: INFO: Waiting up to 5m0s for pod "downward-api-b672a328-88d5-4cdb-a251-598a519569ce" in namespace "downward-api-8401" to be "success or failure"
Nov  4 09:11:58.197: INFO: Pod "downward-api-b672a328-88d5-4cdb-a251-598a519569ce": Phase="Pending", Reason="", readiness=false. Elapsed: 9.264269ms
Nov  4 09:12:00.200: INFO: Pod "downward-api-b672a328-88d5-4cdb-a251-598a519569ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012932765s
STEP: Saw pod success
Nov  4 09:12:00.200: INFO: Pod "downward-api-b672a328-88d5-4cdb-a251-598a519569ce" satisfied condition "success or failure"
Nov  4 09:12:00.205: INFO: Trying to get logs from node k8s-1 pod downward-api-b672a328-88d5-4cdb-a251-598a519569ce container dapi-container: <nil>
STEP: delete the pod
Nov  4 09:12:00.225: INFO: Waiting for pod downward-api-b672a328-88d5-4cdb-a251-598a519569ce to disappear
Nov  4 09:12:00.229: INFO: Pod downward-api-b672a328-88d5-4cdb-a251-598a519569ce no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:12:00.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8401" for this suite.
Nov  4 09:12:06.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:12:06.340: INFO: namespace downward-api-8401 deletion completed in 6.108283573s

• [SLOW TEST:8.308 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:12:06.341: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1647
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1104 09:12:16.518172      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  4 09:12:16.518: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:12:16.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1647" for this suite.
Nov  4 09:12:22.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:12:22.615: INFO: namespace gc-1647 deletion completed in 6.093258131s

• [SLOW TEST:16.274 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:12:22.615: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2660
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:12:23.318: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:12:26.336: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:12:26.339: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Registering the custom resource webhook via the AdmissionRegistration API
Nov  4 09:12:31.423: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:12:32.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2660" for this suite.
Nov  4 09:12:38.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:12:38.233: INFO: namespace webhook-2660 deletion completed in 6.106328328s
STEP: Destroying namespace "webhook-2660-markers" for this suite.
Nov  4 09:12:44.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:12:44.327: INFO: namespace webhook-2660-markers deletion completed in 6.093873841s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.728 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:12:44.343: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1688
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  4 09:12:48.534: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 09:12:48.538: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 09:12:50.539: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 09:12:50.542: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 09:12:52.539: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 09:12:52.542: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 09:12:54.539: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 09:12:54.542: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 09:12:56.539: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 09:12:56.542: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 09:12:58.539: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 09:12:58.542: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 09:13:00.539: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 09:13:00.542: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 09:13:02.539: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 09:13:02.542: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:13:02.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1688" for this suite.
Nov  4 09:13:14.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:13:14.647: INFO: namespace container-lifecycle-hook-1688 deletion completed in 12.095254296s

• [SLOW TEST:30.304 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:13:14.647: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3295
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  4 09:13:18.873: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  4 09:13:18.875: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  4 09:13:20.875: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  4 09:13:20.878: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  4 09:13:22.875: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  4 09:13:22.879: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:13:22.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3295" for this suite.
Nov  4 09:13:34.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:13:34.988: INFO: namespace container-lifecycle-hook-3295 deletion completed in 12.105456837s

• [SLOW TEST:20.341 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:13:34.989: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6576
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 09:13:35.151: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b0f1f974-8032-4cf1-bd9f-0ce65b866802" in namespace "downward-api-6576" to be "success or failure"
Nov  4 09:13:35.155: INFO: Pod "downwardapi-volume-b0f1f974-8032-4cf1-bd9f-0ce65b866802": Phase="Pending", Reason="", readiness=false. Elapsed: 3.751145ms
Nov  4 09:13:37.158: INFO: Pod "downwardapi-volume-b0f1f974-8032-4cf1-bd9f-0ce65b866802": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007069028s
STEP: Saw pod success
Nov  4 09:13:37.158: INFO: Pod "downwardapi-volume-b0f1f974-8032-4cf1-bd9f-0ce65b866802" satisfied condition "success or failure"
Nov  4 09:13:37.160: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-b0f1f974-8032-4cf1-bd9f-0ce65b866802 container client-container: <nil>
STEP: delete the pod
Nov  4 09:13:37.180: INFO: Waiting for pod downwardapi-volume-b0f1f974-8032-4cf1-bd9f-0ce65b866802 to disappear
Nov  4 09:13:37.184: INFO: Pod downwardapi-volume-b0f1f974-8032-4cf1-bd9f-0ce65b866802 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:13:37.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6576" for this suite.
Nov  4 09:13:43.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:13:43.284: INFO: namespace downward-api-6576 deletion completed in 6.097331939s

• [SLOW TEST:8.295 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:13:43.285: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3637
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-jzvw
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 09:13:43.444: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-jzvw" in namespace "subpath-3637" to be "success or failure"
Nov  4 09:13:43.457: INFO: Pod "pod-subpath-test-downwardapi-jzvw": Phase="Pending", Reason="", readiness=false. Elapsed: 12.903134ms
Nov  4 09:13:45.469: INFO: Pod "pod-subpath-test-downwardapi-jzvw": Phase="Running", Reason="", readiness=true. Elapsed: 2.02512723s
Nov  4 09:13:47.472: INFO: Pod "pod-subpath-test-downwardapi-jzvw": Phase="Running", Reason="", readiness=true. Elapsed: 4.028415314s
Nov  4 09:13:49.475: INFO: Pod "pod-subpath-test-downwardapi-jzvw": Phase="Running", Reason="", readiness=true. Elapsed: 6.031281857s
Nov  4 09:13:51.485: INFO: Pod "pod-subpath-test-downwardapi-jzvw": Phase="Running", Reason="", readiness=true. Elapsed: 8.041204091s
Nov  4 09:13:53.488: INFO: Pod "pod-subpath-test-downwardapi-jzvw": Phase="Running", Reason="", readiness=true. Elapsed: 10.044120245s
Nov  4 09:13:55.491: INFO: Pod "pod-subpath-test-downwardapi-jzvw": Phase="Running", Reason="", readiness=true. Elapsed: 12.047166376s
Nov  4 09:13:57.582: INFO: Pod "pod-subpath-test-downwardapi-jzvw": Phase="Running", Reason="", readiness=true. Elapsed: 14.138473444s
Nov  4 09:13:59.585: INFO: Pod "pod-subpath-test-downwardapi-jzvw": Phase="Running", Reason="", readiness=true. Elapsed: 16.141403951s
Nov  4 09:14:01.589: INFO: Pod "pod-subpath-test-downwardapi-jzvw": Phase="Running", Reason="", readiness=true. Elapsed: 18.144870231s
Nov  4 09:14:03.592: INFO: Pod "pod-subpath-test-downwardapi-jzvw": Phase="Running", Reason="", readiness=true. Elapsed: 20.148023014s
Nov  4 09:14:05.596: INFO: Pod "pod-subpath-test-downwardapi-jzvw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.151932084s
STEP: Saw pod success
Nov  4 09:14:05.596: INFO: Pod "pod-subpath-test-downwardapi-jzvw" satisfied condition "success or failure"
Nov  4 09:14:05.600: INFO: Trying to get logs from node k8s-1 pod pod-subpath-test-downwardapi-jzvw container test-container-subpath-downwardapi-jzvw: <nil>
STEP: delete the pod
Nov  4 09:14:05.627: INFO: Waiting for pod pod-subpath-test-downwardapi-jzvw to disappear
Nov  4 09:14:05.640: INFO: Pod pod-subpath-test-downwardapi-jzvw no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-jzvw
Nov  4 09:14:05.640: INFO: Deleting pod "pod-subpath-test-downwardapi-jzvw" in namespace "subpath-3637"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:14:05.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3637" for this suite.
Nov  4 09:14:11.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:14:11.765: INFO: namespace subpath-3637 deletion completed in 6.116993428s

• [SLOW TEST:28.481 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:14:11.766: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8084
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-7b887509-5f02-49d1-96a9-ea0c838b8266 in namespace container-probe-8084
Nov  4 09:14:13.931: INFO: Started pod busybox-7b887509-5f02-49d1-96a9-ea0c838b8266 in namespace container-probe-8084
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 09:14:13.934: INFO: Initial restart count of pod busybox-7b887509-5f02-49d1-96a9-ea0c838b8266 is 0
Nov  4 09:15:06.021: INFO: Restart count of pod container-probe-8084/busybox-7b887509-5f02-49d1-96a9-ea0c838b8266 is now 1 (52.087310129s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:15:06.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8084" for this suite.
Nov  4 09:15:12.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:15:12.147: INFO: namespace container-probe-8084 deletion completed in 6.103260061s

• [SLOW TEST:60.381 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:15:12.148: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1958
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:15:12.292: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  4 09:15:20.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-1958 create -f -'
Nov  4 09:15:21.249: INFO: stderr: ""
Nov  4 09:15:21.249: INFO: stdout: "e2e-test-crd-publish-openapi-9842-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov  4 09:15:21.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-1958 delete e2e-test-crd-publish-openapi-9842-crds test-cr'
Nov  4 09:15:21.376: INFO: stderr: ""
Nov  4 09:15:21.376: INFO: stdout: "e2e-test-crd-publish-openapi-9842-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Nov  4 09:15:21.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-1958 apply -f -'
Nov  4 09:15:21.607: INFO: stderr: ""
Nov  4 09:15:21.607: INFO: stdout: "e2e-test-crd-publish-openapi-9842-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov  4 09:15:21.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-1958 delete e2e-test-crd-publish-openapi-9842-crds test-cr'
Nov  4 09:15:21.737: INFO: stderr: ""
Nov  4 09:15:21.737: INFO: stdout: "e2e-test-crd-publish-openapi-9842-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov  4 09:15:21.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 explain e2e-test-crd-publish-openapi-9842-crds'
Nov  4 09:15:21.975: INFO: stderr: ""
Nov  4 09:15:21.976: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9842-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:15:26.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1958" for this suite.
Nov  4 09:15:32.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:15:32.156: INFO: namespace crd-publish-openapi-1958 deletion completed in 6.096367673s

• [SLOW TEST:20.009 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:15:32.157: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4659
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:15:43.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4659" for this suite.
Nov  4 09:15:49.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:15:49.437: INFO: namespace resourcequota-4659 deletion completed in 6.101347045s

• [SLOW TEST:17.280 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:15:49.437: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1627
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 09:15:49.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1627'
Nov  4 09:15:49.673: INFO: stderr: ""
Nov  4 09:15:49.673: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Nov  4 09:15:49.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete pods e2e-test-httpd-pod --namespace=kubectl-1627'
Nov  4 09:16:01.661: INFO: stderr: ""
Nov  4 09:16:01.661: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:16:01.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1627" for this suite.
Nov  4 09:16:07.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:16:07.801: INFO: namespace kubectl-1627 deletion completed in 6.135083764s

• [SLOW TEST:18.364 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:16:07.804: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9884
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-07a65d97-1749-4193-a2bd-7042f9fd3476
STEP: Creating configMap with name cm-test-opt-upd-44f76a20-909f-424f-a1b1-40e5c60c56e1
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-07a65d97-1749-4193-a2bd-7042f9fd3476
STEP: Updating configmap cm-test-opt-upd-44f76a20-909f-424f-a1b1-40e5c60c56e1
STEP: Creating configMap with name cm-test-opt-create-32c30eee-dbcc-4a2b-b106-97169e11e306
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:16:14.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9884" for this suite.
Nov  4 09:16:42.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:16:42.161: INFO: namespace projected-9884 deletion completed in 28.100363681s

• [SLOW TEST:34.357 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:16:42.161: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7116
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:16:42.704: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 09:16:44.713: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455802, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455802, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455802, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455802, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:16:47.732: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:16:48.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7116" for this suite.
Nov  4 09:16:54.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:16:54.240: INFO: namespace webhook-7116 deletion completed in 6.094807846s
STEP: Destroying namespace "webhook-7116-markers" for this suite.
Nov  4 09:17:00.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:17:00.351: INFO: namespace webhook-7116-markers deletion completed in 6.111158593s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.209 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:17:00.371: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-329
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-5ccec567-0223-4450-8402-404984d0ced4
STEP: Creating a pod to test consume configMaps
Nov  4 09:17:00.527: INFO: Waiting up to 5m0s for pod "pod-configmaps-16cecf32-3a7f-491f-b413-0debb249f47f" in namespace "configmap-329" to be "success or failure"
Nov  4 09:17:00.531: INFO: Pod "pod-configmaps-16cecf32-3a7f-491f-b413-0debb249f47f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.441043ms
Nov  4 09:17:02.534: INFO: Pod "pod-configmaps-16cecf32-3a7f-491f-b413-0debb249f47f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006605558s
STEP: Saw pod success
Nov  4 09:17:02.534: INFO: Pod "pod-configmaps-16cecf32-3a7f-491f-b413-0debb249f47f" satisfied condition "success or failure"
Nov  4 09:17:02.538: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-16cecf32-3a7f-491f-b413-0debb249f47f container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 09:17:02.766: INFO: Waiting for pod pod-configmaps-16cecf32-3a7f-491f-b413-0debb249f47f to disappear
Nov  4 09:17:02.771: INFO: Pod pod-configmaps-16cecf32-3a7f-491f-b413-0debb249f47f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:17:02.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-329" for this suite.
Nov  4 09:17:08.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:17:08.886: INFO: namespace configmap-329 deletion completed in 6.111920369s

• [SLOW TEST:8.515 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:17:08.887: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8073
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:17:10.158: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 09:17:12.170: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455830, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455830, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455830, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708455830, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:17:15.181: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
Nov  4 09:17:15.203: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:17:25.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8073" for this suite.
Nov  4 09:17:31.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:17:31.621: INFO: namespace webhook-8073 deletion completed in 6.107543273s
STEP: Destroying namespace "webhook-8073-markers" for this suite.
Nov  4 09:17:37.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:17:37.750: INFO: namespace webhook-8073-markers deletion completed in 6.128436547s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.880 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:17:37.769: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2855
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2855.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2855.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 09:17:39.955: INFO: DNS probes using dns-2855/dns-test-49183e9d-fc4d-4f7c-91b0-ab2e6a119d2e succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:17:39.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2855" for this suite.
Nov  4 09:17:45.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:17:46.083: INFO: namespace dns-2855 deletion completed in 6.097122654s

• [SLOW TEST:8.314 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:17:46.083: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2533
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Nov  4 09:18:26.251: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:18:26.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1104 09:18:26.251165      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2533" for this suite.
Nov  4 09:18:32.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:18:32.374: INFO: namespace gc-2533 deletion completed in 6.119224466s

• [SLOW TEST:46.290 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:18:32.376: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8867
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:18:49.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8867" for this suite.
Nov  4 09:18:55.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:18:55.689: INFO: namespace resourcequota-8867 deletion completed in 6.113333426s

• [SLOW TEST:23.314 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:18:55.690: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-3265
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:18:55.839: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-e128a25c-4ecc-4f96-9a92-b27fec369a8c" in namespace "security-context-test-3265" to be "success or failure"
Nov  4 09:18:55.852: INFO: Pod "alpine-nnp-false-e128a25c-4ecc-4f96-9a92-b27fec369a8c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.896529ms
Nov  4 09:18:57.856: INFO: Pod "alpine-nnp-false-e128a25c-4ecc-4f96-9a92-b27fec369a8c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01667429s
Nov  4 09:18:59.859: INFO: Pod "alpine-nnp-false-e128a25c-4ecc-4f96-9a92-b27fec369a8c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020031036s
Nov  4 09:18:59.859: INFO: Pod "alpine-nnp-false-e128a25c-4ecc-4f96-9a92-b27fec369a8c" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:18:59.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3265" for this suite.
Nov  4 09:19:05.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:19:05.966: INFO: namespace security-context-test-3265 deletion completed in 6.096809476s

• [SLOW TEST:10.276 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:19:05.966: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2047
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Nov  4 09:19:06.118: INFO: Waiting up to 5m0s for pod "var-expansion-0d69fc0f-5089-4dad-8c5a-c103fedb659e" in namespace "var-expansion-2047" to be "success or failure"
Nov  4 09:19:06.127: INFO: Pod "var-expansion-0d69fc0f-5089-4dad-8c5a-c103fedb659e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.461203ms
Nov  4 09:19:08.130: INFO: Pod "var-expansion-0d69fc0f-5089-4dad-8c5a-c103fedb659e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011707739s
STEP: Saw pod success
Nov  4 09:19:08.130: INFO: Pod "var-expansion-0d69fc0f-5089-4dad-8c5a-c103fedb659e" satisfied condition "success or failure"
Nov  4 09:19:08.133: INFO: Trying to get logs from node k8s-1 pod var-expansion-0d69fc0f-5089-4dad-8c5a-c103fedb659e container dapi-container: <nil>
STEP: delete the pod
Nov  4 09:19:08.154: INFO: Waiting for pod var-expansion-0d69fc0f-5089-4dad-8c5a-c103fedb659e to disappear
Nov  4 09:19:08.158: INFO: Pod var-expansion-0d69fc0f-5089-4dad-8c5a-c103fedb659e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:19:08.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2047" for this suite.
Nov  4 09:19:14.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:19:14.268: INFO: namespace var-expansion-2047 deletion completed in 6.106724627s

• [SLOW TEST:8.302 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:19:14.269: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1545
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-92d07d31-3b46-4b09-b2eb-b01043aa3c03
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:19:16.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1545" for this suite.
Nov  4 09:19:28.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:19:28.569: INFO: namespace configmap-1545 deletion completed in 12.101642071s

• [SLOW TEST:14.300 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:19:28.569: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3201
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Nov  4 09:19:28.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 create -f - --namespace=kubectl-3201'
Nov  4 09:19:28.972: INFO: stderr: ""
Nov  4 09:19:28.972: INFO: stdout: "pod/pause created\n"
Nov  4 09:19:28.972: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov  4 09:19:28.972: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3201" to be "running and ready"
Nov  4 09:19:28.976: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.85325ms
Nov  4 09:19:30.979: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.007468679s
Nov  4 09:19:30.979: INFO: Pod "pause" satisfied condition "running and ready"
Nov  4 09:19:30.979: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Nov  4 09:19:30.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 label pods pause testing-label=testing-label-value --namespace=kubectl-3201'
Nov  4 09:19:31.074: INFO: stderr: ""
Nov  4 09:19:31.074: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov  4 09:19:31.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pod pause -L testing-label --namespace=kubectl-3201'
Nov  4 09:19:31.161: INFO: stderr: ""
Nov  4 09:19:31.161: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov  4 09:19:31.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 label pods pause testing-label- --namespace=kubectl-3201'
Nov  4 09:19:31.254: INFO: stderr: ""
Nov  4 09:19:31.254: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov  4 09:19:31.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pod pause -L testing-label --namespace=kubectl-3201'
Nov  4 09:19:31.330: INFO: stderr: ""
Nov  4 09:19:31.330: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Nov  4 09:19:31.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete --grace-period=0 --force -f - --namespace=kubectl-3201'
Nov  4 09:19:31.421: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 09:19:31.421: INFO: stdout: "pod \"pause\" force deleted\n"
Nov  4 09:19:31.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get rc,svc -l name=pause --no-headers --namespace=kubectl-3201'
Nov  4 09:19:31.507: INFO: stderr: "No resources found in kubectl-3201 namespace.\n"
Nov  4 09:19:31.507: INFO: stdout: ""
Nov  4 09:19:31.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -l name=pause --namespace=kubectl-3201 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  4 09:19:31.593: INFO: stderr: ""
Nov  4 09:19:31.593: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:19:31.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3201" for this suite.
Nov  4 09:19:37.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:19:37.703: INFO: namespace kubectl-3201 deletion completed in 6.106325894s

• [SLOW TEST:9.134 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:19:37.703: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3202
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-2f627fc5-bc27-4212-9f0a-07b7d55d117d
STEP: Creating a pod to test consume configMaps
Nov  4 09:19:37.859: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-34a4e788-d129-41b4-807d-b03eadded9f5" in namespace "projected-3202" to be "success or failure"
Nov  4 09:19:37.865: INFO: Pod "pod-projected-configmaps-34a4e788-d129-41b4-807d-b03eadded9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.144839ms
Nov  4 09:19:39.868: INFO: Pod "pod-projected-configmaps-34a4e788-d129-41b4-807d-b03eadded9f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009496514s
STEP: Saw pod success
Nov  4 09:19:39.868: INFO: Pod "pod-projected-configmaps-34a4e788-d129-41b4-807d-b03eadded9f5" satisfied condition "success or failure"
Nov  4 09:19:39.871: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-34a4e788-d129-41b4-807d-b03eadded9f5 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 09:19:39.953: INFO: Waiting for pod pod-projected-configmaps-34a4e788-d129-41b4-807d-b03eadded9f5 to disappear
Nov  4 09:19:39.955: INFO: Pod pod-projected-configmaps-34a4e788-d129-41b4-807d-b03eadded9f5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:19:39.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3202" for this suite.
Nov  4 09:19:45.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:19:46.061: INFO: namespace projected-3202 deletion completed in 6.102445559s

• [SLOW TEST:8.358 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:19:46.062: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6368
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:19:46.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6368" for this suite.
Nov  4 09:19:52.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:19:52.339: INFO: namespace resourcequota-6368 deletion completed in 6.101926426s

• [SLOW TEST:6.277 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:19:52.340: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5053
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Nov  4 09:19:52.489: INFO: Waiting up to 5m0s for pod "var-expansion-298548f3-c54c-4aba-bf1e-76afb901515d" in namespace "var-expansion-5053" to be "success or failure"
Nov  4 09:19:52.494: INFO: Pod "var-expansion-298548f3-c54c-4aba-bf1e-76afb901515d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.573779ms
Nov  4 09:19:54.497: INFO: Pod "var-expansion-298548f3-c54c-4aba-bf1e-76afb901515d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007491651s
STEP: Saw pod success
Nov  4 09:19:54.497: INFO: Pod "var-expansion-298548f3-c54c-4aba-bf1e-76afb901515d" satisfied condition "success or failure"
Nov  4 09:19:54.500: INFO: Trying to get logs from node k8s-1 pod var-expansion-298548f3-c54c-4aba-bf1e-76afb901515d container dapi-container: <nil>
STEP: delete the pod
Nov  4 09:19:54.521: INFO: Waiting for pod var-expansion-298548f3-c54c-4aba-bf1e-76afb901515d to disappear
Nov  4 09:19:54.529: INFO: Pod var-expansion-298548f3-c54c-4aba-bf1e-76afb901515d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:19:54.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5053" for this suite.
Nov  4 09:20:00.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:20:00.634: INFO: namespace var-expansion-5053 deletion completed in 6.101467472s

• [SLOW TEST:8.294 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:20:00.634: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6498
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-61b0a919-2d17-4d4f-ae19-52673740be7a
STEP: Creating a pod to test consume configMaps
Nov  4 09:20:00.794: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-32c82c67-9507-4a7a-9650-03b052ec28c1" in namespace "projected-6498" to be "success or failure"
Nov  4 09:20:00.796: INFO: Pod "pod-projected-configmaps-32c82c67-9507-4a7a-9650-03b052ec28c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.43636ms
Nov  4 09:20:02.800: INFO: Pod "pod-projected-configmaps-32c82c67-9507-4a7a-9650-03b052ec28c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00563562s
STEP: Saw pod success
Nov  4 09:20:02.800: INFO: Pod "pod-projected-configmaps-32c82c67-9507-4a7a-9650-03b052ec28c1" satisfied condition "success or failure"
Nov  4 09:20:02.802: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-32c82c67-9507-4a7a-9650-03b052ec28c1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 09:20:02.826: INFO: Waiting for pod pod-projected-configmaps-32c82c67-9507-4a7a-9650-03b052ec28c1 to disappear
Nov  4 09:20:02.835: INFO: Pod pod-projected-configmaps-32c82c67-9507-4a7a-9650-03b052ec28c1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:20:02.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6498" for this suite.
Nov  4 09:20:08.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:20:08.997: INFO: namespace projected-6498 deletion completed in 6.155942771s

• [SLOW TEST:8.363 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:20:08.998: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2359
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-xq67
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 09:20:09.157: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xq67" in namespace "subpath-2359" to be "success or failure"
Nov  4 09:20:09.170: INFO: Pod "pod-subpath-test-configmap-xq67": Phase="Pending", Reason="", readiness=false. Elapsed: 12.603975ms
Nov  4 09:20:11.174: INFO: Pod "pod-subpath-test-configmap-xq67": Phase="Running", Reason="", readiness=true. Elapsed: 2.016927507s
Nov  4 09:20:13.178: INFO: Pod "pod-subpath-test-configmap-xq67": Phase="Running", Reason="", readiness=true. Elapsed: 4.020221426s
Nov  4 09:20:15.183: INFO: Pod "pod-subpath-test-configmap-xq67": Phase="Running", Reason="", readiness=true. Elapsed: 6.0256009s
Nov  4 09:20:17.186: INFO: Pod "pod-subpath-test-configmap-xq67": Phase="Running", Reason="", readiness=true. Elapsed: 8.028896216s
Nov  4 09:20:19.189: INFO: Pod "pod-subpath-test-configmap-xq67": Phase="Running", Reason="", readiness=true. Elapsed: 10.031830347s
Nov  4 09:20:21.193: INFO: Pod "pod-subpath-test-configmap-xq67": Phase="Running", Reason="", readiness=true. Elapsed: 12.035409589s
Nov  4 09:20:23.196: INFO: Pod "pod-subpath-test-configmap-xq67": Phase="Running", Reason="", readiness=true. Elapsed: 14.038376052s
Nov  4 09:20:25.199: INFO: Pod "pod-subpath-test-configmap-xq67": Phase="Running", Reason="", readiness=true. Elapsed: 16.041361004s
Nov  4 09:20:27.202: INFO: Pod "pod-subpath-test-configmap-xq67": Phase="Running", Reason="", readiness=true. Elapsed: 18.044167858s
Nov  4 09:20:29.205: INFO: Pod "pod-subpath-test-configmap-xq67": Phase="Running", Reason="", readiness=true. Elapsed: 20.04705344s
Nov  4 09:20:31.207: INFO: Pod "pod-subpath-test-configmap-xq67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.049959752s
STEP: Saw pod success
Nov  4 09:20:31.207: INFO: Pod "pod-subpath-test-configmap-xq67" satisfied condition "success or failure"
Nov  4 09:20:31.210: INFO: Trying to get logs from node k8s-1 pod pod-subpath-test-configmap-xq67 container test-container-subpath-configmap-xq67: <nil>
STEP: delete the pod
Nov  4 09:20:31.229: INFO: Waiting for pod pod-subpath-test-configmap-xq67 to disappear
Nov  4 09:20:31.233: INFO: Pod pod-subpath-test-configmap-xq67 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xq67
Nov  4 09:20:31.233: INFO: Deleting pod "pod-subpath-test-configmap-xq67" in namespace "subpath-2359"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:20:31.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2359" for this suite.
Nov  4 09:20:37.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:20:37.339: INFO: namespace subpath-2359 deletion completed in 6.099582415s

• [SLOW TEST:28.341 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:20:37.339: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7948
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov  4 09:20:37.498: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7948 /api/v1/namespaces/watch-7948/configmaps/e2e-watch-test-resource-version 421c3794-2a7a-423d-8c75-47131e47ee11 521253 0 2019-11-04 09:20:37 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 09:20:37.498: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7948 /api/v1/namespaces/watch-7948/configmaps/e2e-watch-test-resource-version 421c3794-2a7a-423d-8c75-47131e47ee11 521254 0 2019-11-04 09:20:37 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:20:37.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7948" for this suite.
Nov  4 09:20:43.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:20:43.647: INFO: namespace watch-7948 deletion completed in 6.145633745s

• [SLOW TEST:6.308 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:20:43.648: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-2068
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov  4 09:20:47.849: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2068 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:20:47.849: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:20:47.991: INFO: Exec stderr: ""
Nov  4 09:20:47.991: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2068 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:20:47.991: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:20:48.158: INFO: Exec stderr: ""
Nov  4 09:20:48.158: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2068 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:20:48.158: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:20:48.313: INFO: Exec stderr: ""
Nov  4 09:20:48.313: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2068 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:20:48.313: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:20:48.460: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov  4 09:20:48.460: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2068 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:20:48.460: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:20:48.600: INFO: Exec stderr: ""
Nov  4 09:20:48.600: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2068 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:20:48.600: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:20:48.745: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov  4 09:20:48.745: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2068 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:20:48.745: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:20:48.891: INFO: Exec stderr: ""
Nov  4 09:20:48.891: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2068 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:20:48.891: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:20:49.132: INFO: Exec stderr: ""
Nov  4 09:20:49.132: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2068 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:20:49.132: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:20:49.305: INFO: Exec stderr: ""
Nov  4 09:20:49.305: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2068 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:20:49.305: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:20:49.446: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:20:49.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2068" for this suite.
Nov  4 09:21:33.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:21:33.554: INFO: namespace e2e-kubelet-etc-hosts-2068 deletion completed in 44.101470755s

• [SLOW TEST:49.905 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:21:33.554: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9549
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Nov  4 09:21:36.225: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9549 pod-service-account-b48e8faa-da77-41bd-8490-23551840768b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Nov  4 09:21:36.467: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9549 pod-service-account-b48e8faa-da77-41bd-8490-23551840768b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Nov  4 09:21:36.717: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9549 pod-service-account-b48e8faa-da77-41bd-8490-23551840768b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:21:36.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9549" for this suite.
Nov  4 09:21:42.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:21:43.055: INFO: namespace svcaccounts-9549 deletion completed in 6.09790886s

• [SLOW TEST:9.501 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:21:43.055: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6791
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:21:43.197: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  4 09:21:51.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-6791 create -f -'
Nov  4 09:21:52.234: INFO: stderr: ""
Nov  4 09:21:52.234: INFO: stdout: "e2e-test-crd-publish-openapi-2367-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov  4 09:21:52.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-6791 delete e2e-test-crd-publish-openapi-2367-crds test-cr'
Nov  4 09:21:52.382: INFO: stderr: ""
Nov  4 09:21:52.382: INFO: stdout: "e2e-test-crd-publish-openapi-2367-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Nov  4 09:21:52.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-6791 apply -f -'
Nov  4 09:21:52.646: INFO: stderr: ""
Nov  4 09:21:52.646: INFO: stdout: "e2e-test-crd-publish-openapi-2367-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov  4 09:21:52.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-6791 delete e2e-test-crd-publish-openapi-2367-crds test-cr'
Nov  4 09:21:52.774: INFO: stderr: ""
Nov  4 09:21:52.774: INFO: stdout: "e2e-test-crd-publish-openapi-2367-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Nov  4 09:21:52.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 explain e2e-test-crd-publish-openapi-2367-crds'
Nov  4 09:21:52.996: INFO: stderr: ""
Nov  4 09:21:52.996: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2367-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:21:57.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6791" for this suite.
Nov  4 09:22:03.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:22:03.807: INFO: namespace crd-publish-openapi-6791 deletion completed in 6.11670427s

• [SLOW TEST:20.752 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:22:03.807: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3592
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:22:03.960: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:22:09.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3592" for this suite.
Nov  4 09:22:15.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:22:15.649: INFO: namespace custom-resource-definition-3592 deletion completed in 6.107636588s

• [SLOW TEST:11.841 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:22:15.650: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2692
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  4 09:22:18.336: INFO: Successfully updated pod "pod-update-activedeadlineseconds-abcc877d-d169-4026-a6fe-4ec6dc5fd667"
Nov  4 09:22:18.336: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-abcc877d-d169-4026-a6fe-4ec6dc5fd667" in namespace "pods-2692" to be "terminated due to deadline exceeded"
Nov  4 09:22:18.339: INFO: Pod "pod-update-activedeadlineseconds-abcc877d-d169-4026-a6fe-4ec6dc5fd667": Phase="Running", Reason="", readiness=true. Elapsed: 3.453453ms
Nov  4 09:22:20.343: INFO: Pod "pod-update-activedeadlineseconds-abcc877d-d169-4026-a6fe-4ec6dc5fd667": Phase="Running", Reason="", readiness=true. Elapsed: 2.006863217s
Nov  4 09:22:22.346: INFO: Pod "pod-update-activedeadlineseconds-abcc877d-d169-4026-a6fe-4ec6dc5fd667": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.010331944s
Nov  4 09:22:22.346: INFO: Pod "pod-update-activedeadlineseconds-abcc877d-d169-4026-a6fe-4ec6dc5fd667" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:22:22.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2692" for this suite.
Nov  4 09:22:28.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:22:28.449: INFO: namespace pods-2692 deletion completed in 6.098611898s

• [SLOW TEST:12.799 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:22:28.450: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4950
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-4950
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  4 09:22:28.588: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  4 09:22:50.699: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.2.150:8080/dial?request=hostName&protocol=udp&host=10.33.2.149&port=8081&tries=1'] Namespace:pod-network-test-4950 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:22:50.700: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:22:50.858: INFO: Waiting for endpoints: map[]
Nov  4 09:22:50.861: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.2.150:8080/dial?request=hostName&protocol=udp&host=10.33.1.72&port=8081&tries=1'] Namespace:pod-network-test-4950 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:22:50.861: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:22:51.038: INFO: Waiting for endpoints: map[]
Nov  4 09:22:51.043: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.2.150:8080/dial?request=hostName&protocol=udp&host=10.33.0.66&port=8081&tries=1'] Namespace:pod-network-test-4950 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:22:51.043: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:22:51.188: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:22:51.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4950" for this suite.
Nov  4 09:23:03.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:23:03.291: INFO: namespace pod-network-test-4950 deletion completed in 12.09819203s

• [SLOW TEST:34.841 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:23:03.291: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8427
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  4 09:23:03.445: INFO: Waiting up to 5m0s for pod "pod-afd3d81a-9986-4af1-8aba-03727b1c0576" in namespace "emptydir-8427" to be "success or failure"
Nov  4 09:23:03.452: INFO: Pod "pod-afd3d81a-9986-4af1-8aba-03727b1c0576": Phase="Pending", Reason="", readiness=false. Elapsed: 7.530649ms
Nov  4 09:23:05.455: INFO: Pod "pod-afd3d81a-9986-4af1-8aba-03727b1c0576": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010230285s
STEP: Saw pod success
Nov  4 09:23:05.455: INFO: Pod "pod-afd3d81a-9986-4af1-8aba-03727b1c0576" satisfied condition "success or failure"
Nov  4 09:23:05.458: INFO: Trying to get logs from node k8s-1 pod pod-afd3d81a-9986-4af1-8aba-03727b1c0576 container test-container: <nil>
STEP: delete the pod
Nov  4 09:23:05.483: INFO: Waiting for pod pod-afd3d81a-9986-4af1-8aba-03727b1c0576 to disappear
Nov  4 09:23:05.485: INFO: Pod pod-afd3d81a-9986-4af1-8aba-03727b1c0576 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:23:05.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8427" for this suite.
Nov  4 09:23:11.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:23:11.599: INFO: namespace emptydir-8427 deletion completed in 6.110489418s

• [SLOW TEST:8.308 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:23:11.600: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3707
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Nov  4 09:23:11.756: INFO: Waiting up to 5m0s for pod "client-containers-7503fa0a-1c20-4093-833a-379f76f03f5b" in namespace "containers-3707" to be "success or failure"
Nov  4 09:23:11.761: INFO: Pod "client-containers-7503fa0a-1c20-4093-833a-379f76f03f5b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.953856ms
Nov  4 09:23:13.764: INFO: Pod "client-containers-7503fa0a-1c20-4093-833a-379f76f03f5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007851674s
STEP: Saw pod success
Nov  4 09:23:13.764: INFO: Pod "client-containers-7503fa0a-1c20-4093-833a-379f76f03f5b" satisfied condition "success or failure"
Nov  4 09:23:13.767: INFO: Trying to get logs from node k8s-1 pod client-containers-7503fa0a-1c20-4093-833a-379f76f03f5b container test-container: <nil>
STEP: delete the pod
Nov  4 09:23:13.792: INFO: Waiting for pod client-containers-7503fa0a-1c20-4093-833a-379f76f03f5b to disappear
Nov  4 09:23:13.797: INFO: Pod client-containers-7503fa0a-1c20-4093-833a-379f76f03f5b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:23:13.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3707" for this suite.
Nov  4 09:23:19.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:23:19.893: INFO: namespace containers-3707 deletion completed in 6.092449928s

• [SLOW TEST:8.293 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:23:19.893: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3605
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-3605
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3605 to expose endpoints map[]
Nov  4 09:23:20.052: INFO: Get endpoints failed (9.529068ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Nov  4 09:23:21.055: INFO: successfully validated that service multi-endpoint-test in namespace services-3605 exposes endpoints map[] (1.012330359s elapsed)
STEP: Creating pod pod1 in namespace services-3605
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3605 to expose endpoints map[pod1:[100]]
Nov  4 09:23:23.085: INFO: successfully validated that service multi-endpoint-test in namespace services-3605 exposes endpoints map[pod1:[100]] (2.018946403s elapsed)
STEP: Creating pod pod2 in namespace services-3605
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3605 to expose endpoints map[pod1:[100] pod2:[101]]
Nov  4 09:23:24.120: INFO: successfully validated that service multi-endpoint-test in namespace services-3605 exposes endpoints map[pod1:[100] pod2:[101]] (1.022697376s elapsed)
STEP: Deleting pod pod1 in namespace services-3605
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3605 to expose endpoints map[pod2:[101]]
Nov  4 09:23:24.149: INFO: successfully validated that service multi-endpoint-test in namespace services-3605 exposes endpoints map[pod2:[101]] (15.06732ms elapsed)
STEP: Deleting pod pod2 in namespace services-3605
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3605 to expose endpoints map[]
Nov  4 09:23:24.168: INFO: successfully validated that service multi-endpoint-test in namespace services-3605 exposes endpoints map[] (4.391432ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:23:24.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3605" for this suite.
Nov  4 09:23:30.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:23:30.307: INFO: namespace services-3605 deletion completed in 6.113465514s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:10.414 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:23:30.307: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4746
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4746.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4746.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4746.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4746.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4746.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4746.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4746.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4746.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4746.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4746.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4746.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4746.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4746.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 117.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.117_udp@PTR;check="$$(dig +tcp +noall +answer +search 117.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.117_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4746.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4746.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4746.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4746.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4746.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4746.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4746.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4746.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4746.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4746.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4746.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4746.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4746.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 117.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.117_udp@PTR;check="$$(dig +tcp +noall +answer +search 117.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.117_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 09:23:32.525: INFO: Unable to read wheezy_udp@dns-test-service.dns-4746.svc.cluster.local from pod dns-4746/dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522: the server could not find the requested resource (get pods dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522)
Nov  4 09:23:32.527: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4746.svc.cluster.local from pod dns-4746/dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522: the server could not find the requested resource (get pods dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522)
Nov  4 09:23:32.530: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4746.svc.cluster.local from pod dns-4746/dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522: the server could not find the requested resource (get pods dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522)
Nov  4 09:23:32.533: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4746.svc.cluster.local from pod dns-4746/dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522: the server could not find the requested resource (get pods dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522)
Nov  4 09:23:32.551: INFO: Unable to read jessie_udp@dns-test-service.dns-4746.svc.cluster.local from pod dns-4746/dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522: the server could not find the requested resource (get pods dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522)
Nov  4 09:23:32.559: INFO: Unable to read jessie_tcp@dns-test-service.dns-4746.svc.cluster.local from pod dns-4746/dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522: the server could not find the requested resource (get pods dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522)
Nov  4 09:23:32.563: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4746.svc.cluster.local from pod dns-4746/dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522: the server could not find the requested resource (get pods dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522)
Nov  4 09:23:32.568: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4746.svc.cluster.local from pod dns-4746/dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522: the server could not find the requested resource (get pods dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522)
Nov  4 09:23:32.595: INFO: Lookups using dns-4746/dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522 failed for: [wheezy_udp@dns-test-service.dns-4746.svc.cluster.local wheezy_tcp@dns-test-service.dns-4746.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4746.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4746.svc.cluster.local jessie_udp@dns-test-service.dns-4746.svc.cluster.local jessie_tcp@dns-test-service.dns-4746.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4746.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4746.svc.cluster.local]

Nov  4 09:23:37.665: INFO: DNS probes using dns-4746/dns-test-2f2dbc56-5ac5-40cb-8d29-f18a9a9a8522 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:23:37.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4746" for this suite.
Nov  4 09:23:43.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:23:43.883: INFO: namespace dns-4746 deletion completed in 6.099500019s

• [SLOW TEST:13.576 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:23:43.884: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-149
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-3754a8c2-ae39-45ad-adad-147f2f9e6548
STEP: Creating secret with name secret-projected-all-test-volume-79aac670-0e7e-439c-8d78-efd17a5725d6
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov  4 09:23:44.039: INFO: Waiting up to 5m0s for pod "projected-volume-f942cd6a-8652-47da-9a62-3d4123a6a343" in namespace "projected-149" to be "success or failure"
Nov  4 09:23:44.046: INFO: Pod "projected-volume-f942cd6a-8652-47da-9a62-3d4123a6a343": Phase="Pending", Reason="", readiness=false. Elapsed: 6.651945ms
Nov  4 09:23:46.049: INFO: Pod "projected-volume-f942cd6a-8652-47da-9a62-3d4123a6a343": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009483608s
STEP: Saw pod success
Nov  4 09:23:46.049: INFO: Pod "projected-volume-f942cd6a-8652-47da-9a62-3d4123a6a343" satisfied condition "success or failure"
Nov  4 09:23:46.052: INFO: Trying to get logs from node k8s-1 pod projected-volume-f942cd6a-8652-47da-9a62-3d4123a6a343 container projected-all-volume-test: <nil>
STEP: delete the pod
Nov  4 09:23:46.074: INFO: Waiting for pod projected-volume-f942cd6a-8652-47da-9a62-3d4123a6a343 to disappear
Nov  4 09:23:46.079: INFO: Pod projected-volume-f942cd6a-8652-47da-9a62-3d4123a6a343 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:23:46.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-149" for this suite.
Nov  4 09:23:52.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:23:52.184: INFO: namespace projected-149 deletion completed in 6.101824481s

• [SLOW TEST:8.300 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:23:52.187: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5618
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  4 09:23:54.874: INFO: Successfully updated pod "labelsupdatea627c282-a6ae-41d3-a157-c4b1a33d2a6c"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:23:58.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5618" for this suite.
Nov  4 09:24:10.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:24:11.000: INFO: namespace projected-5618 deletion completed in 12.100112078s

• [SLOW TEST:18.814 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:24:11.001: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2014
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  4 09:24:11.136: INFO: PodSpec: initContainers in spec.initContainers
Nov  4 09:24:51.426: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-064f9ba0-6024-48ce-8814-c37ba21869b6", GenerateName:"", Namespace:"init-container-2014", SelfLink:"/api/v1/namespaces/init-container-2014/pods/pod-init-064f9ba0-6024-48ce-8814-c37ba21869b6", UID:"e073ee7d-0bdf-4c6f-b48d-1fc6d0c2b514", ResourceVersion:"522193", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63708456251, loc:(*time.Location)(0x84c02a0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"136949478"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-nzrnl", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc003fb2e00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nzrnl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nzrnl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nzrnl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00506e278), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc007bbf560), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00506e300)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00506e320)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00506e328), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00506e32c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708456251, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708456251, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708456251, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708456251, loc:(*time.Location)(0x84c02a0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.20.20.4", PodIP:"10.33.2.157", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.33.2.157"}}, StartTime:(*v1.Time)(0xc003340380), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0030e4380)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0030e43f0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://95d2ed729537f1e907e242625889cf9bd50455d5896f6502cbdbf364bce91452", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0033403c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0033403a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc00506e3af)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:24:51.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2014" for this suite.
Nov  4 09:25:03.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:25:03.561: INFO: namespace init-container-2014 deletion completed in 12.115785728s

• [SLOW TEST:52.560 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:25:03.562: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1914
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-18b692cf-c919-4c6e-952d-341184143c35
STEP: Creating secret with name s-test-opt-upd-3cb67081-200c-4e78-8060-67c91d71f1a7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-18b692cf-c919-4c6e-952d-341184143c35
STEP: Updating secret s-test-opt-upd-3cb67081-200c-4e78-8060-67c91d71f1a7
STEP: Creating secret with name s-test-opt-create-30fe508f-2f0c-4224-9fe8-4a4d8bebcdd5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:25:09.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1914" for this suite.
Nov  4 09:25:37.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:25:37.933: INFO: namespace projected-1914 deletion completed in 28.123364655s

• [SLOW TEST:34.371 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:25:37.934: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6689
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:25:38.387: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 09:25:40.395: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708456338, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708456338, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708456338, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708456338, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:25:43.407: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Nov  4 09:25:43.426: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:25:43.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6689" for this suite.
Nov  4 09:25:49.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:25:49.549: INFO: namespace webhook-6689 deletion completed in 6.107302837s
STEP: Destroying namespace "webhook-6689-markers" for this suite.
Nov  4 09:25:55.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:25:55.644: INFO: namespace webhook-6689-markers deletion completed in 6.094934419s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.730 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:25:55.667: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8949
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1104 09:25:57.118815      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  4 09:25:57.118: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:25:57.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8949" for this suite.
Nov  4 09:26:03.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:26:03.219: INFO: namespace gc-8949 deletion completed in 6.09660397s

• [SLOW TEST:7.552 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:26:03.219: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-8603
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Nov  4 09:26:03.363: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  4 09:27:03.391: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:27:03.394: INFO: Starting informer...
STEP: Starting pod...
Nov  4 09:27:03.621: INFO: Pod is running on k8s-1. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Nov  4 09:27:03.693: INFO: Pod wasn't evicted. Proceeding
Nov  4 09:27:03.693: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Nov  4 09:28:18.718: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:28:18.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-8603" for this suite.
Nov  4 09:28:30.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:28:30.876: INFO: namespace taint-single-pod-8603 deletion completed in 12.154357478s

• [SLOW TEST:147.657 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:28:30.877: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5556
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:28:31.897: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:28:34.913: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:28:34.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5556" for this suite.
Nov  4 09:28:47.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:28:47.085: INFO: namespace webhook-5556 deletion completed in 12.099608887s
STEP: Destroying namespace "webhook-5556-markers" for this suite.
Nov  4 09:28:53.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:28:53.177: INFO: namespace webhook-5556-markers deletion completed in 6.091879984s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.314 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:28:53.192: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7435
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-eeb7cd46-8e15-4720-89f9-f6a2f5fb2a6e
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-eeb7cd46-8e15-4720-89f9-f6a2f5fb2a6e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:28:57.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7435" for this suite.
Nov  4 09:29:13.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:29:13.595: INFO: namespace projected-7435 deletion completed in 16.11103326s

• [SLOW TEST:20.403 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:29:13.595: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7215
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 09:29:13.747: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 09:29:13.757: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 09:29:13.759: INFO: 
Logging pods the kubelet thinks is on node k8s-1 before test
Nov  4 09:29:13.765: INFO: sonobuoy from sonobuoy started at 2019-11-04 08:33:38 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.765: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 09:29:13.765: INFO: kube-flannel-ds-amd64-9ldh9 from kube-system started at 2019-11-04 09:27:35 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.765: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 09:29:13.765: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-9v4q5 from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:29:13.765: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 09:29:13.765: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 09:29:13.765: INFO: traefik-ingress-controller-m7ffw from kube-system started at 2019-11-04 09:27:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.765: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 09:29:13.765: INFO: 
Logging pods the kubelet thinks is on node k8s-2 before test
Nov  4 09:29:13.777: INFO: linkerd-grafana-744cfbd49d-dnzqr from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:29:13.777: INFO: 	Container grafana ready: true, restart count 2
Nov  4 09:29:13.778: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:29:13.778: INFO: nginx-6db489d4b7-qg6lx from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.778: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.778: INFO: nginx-6db489d4b7-ncpfq from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.778: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.778: INFO: nginx-6db489d4b7-dk2z8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.778: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.778: INFO: nginx-6db489d4b7-qp42l from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.778: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.778: INFO: nginx-6db489d4b7-xmrg5 from default started at 2019-10-31 19:35:15 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.778: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.778: INFO: nginx-6db489d4b7-8j7fq from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.778: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.778: INFO: nginx-6db489d4b7-cgwdq from default started at 2019-11-04 08:59:09 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.778: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.778: INFO: nginx-6db489d4b7-lhjpz from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.778: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.779: INFO: traefik-ingress-controller-2rb4m from kube-system started at 2019-10-31 19:06:43 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.779: INFO: 	Container traefik-ingress-lb ready: true, restart count 2
Nov  4 09:29:13.779: INFO: linkerd-sp-validator-8489dfcf59-4vvmx from linkerd started at 2019-10-31 19:06:42 +0000 UTC (2 container statuses recorded)
Nov  4 09:29:13.779: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:29:13.779: INFO: 	Container sp-validator ready: true, restart count 2
Nov  4 09:29:13.779: INFO: nginx-6db489d4b7-74qqm from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.779: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.779: INFO: linkerd-identity-6d9bf4497f-qfsm4 from linkerd started at 2019-11-04 08:59:09 +0000 UTC (2 container statuses recorded)
Nov  4 09:29:13.779: INFO: 	Container identity ready: true, restart count 0
Nov  4 09:29:13.779: INFO: 	Container linkerd-proxy ready: true, restart count 0
Nov  4 09:29:13.779: INFO: kubernetes-metrics-scraper-6b97c6d857-cc8fz from kubernetes-dashboard started at 2019-11-04 08:59:09 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.779: INFO: 	Container kubernetes-metrics-scraper ready: true, restart count 0
Nov  4 09:29:13.779: INFO: nginx-6db489d4b7-x9chn from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.779: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.779: INFO: nginx-6db489d4b7-2nv6m from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.779: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.780: INFO: nginx-6db489d4b7-ltjcr from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.780: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.780: INFO: sonobuoy-e2e-job-77622933ebe14f87 from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:29:13.780: INFO: 	Container e2e ready: true, restart count 0
Nov  4 09:29:13.780: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 09:29:13.780: INFO: kube-flannel-ds-amd64-f44md from kube-system started at 2019-10-31 19:06:43 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.780: INFO: 	Container kube-flannel ready: true, restart count 2
Nov  4 09:29:13.780: INFO: coredns-b7f8c8654-8kwbt from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.780: INFO: 	Container coredns ready: true, restart count 2
Nov  4 09:29:13.780: INFO: nginx-6db489d4b7-q647m from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.780: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.780: INFO: nginx-6db489d4b7-c4xhg from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.780: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.780: INFO: nginx-6db489d4b7-4rl5q from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.780: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.780: INFO: nginx-6db489d4b7-6hht8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.780: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.781: INFO: linkerd-web-685cd8d7c-dhpj5 from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:29:13.781: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:29:13.781: INFO: 	Container web ready: true, restart count 2
Nov  4 09:29:13.781: INFO: kubernetes-dashboard-bf855c94d-s95bc from kubernetes-dashboard started at 2019-11-04 08:59:09 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.781: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov  4 09:29:13.781: INFO: nginx-6db489d4b7-5lbr9 from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.781: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.781: INFO: nginx-6db489d4b7-rlnhg from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.781: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.781: INFO: nginx-6db489d4b7-w6jwg from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.781: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.781: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-z8dpb from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:29:13.781: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 09:29:13.781: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 09:29:13.781: INFO: nginx-6db489d4b7-t97cp from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.781: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.781: INFO: nginx-6db489d4b7-x5b7v from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.781: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.781: INFO: linkerd-prometheus-f74b98d8-hgtgk from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:29:13.782: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:29:13.782: INFO: 	Container prometheus ready: true, restart count 2
Nov  4 09:29:13.782: INFO: nginx-6db489d4b7-kcbjs from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.782: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.782: INFO: nginx-6db489d4b7-hwpf8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.782: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.782: INFO: nginx-6db489d4b7-xds5m from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.782: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.782: INFO: nginx-6db489d4b7-6gqp6 from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.782: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.782: INFO: nginx-6db489d4b7-pbhw4 from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.782: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.782: INFO: 
Logging pods the kubelet thinks is on node k8s-3 before test
Nov  4 09:29:13.796: INFO: nginx-6db489d4b7-zvzhk from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.796: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.796: INFO: nginx-6db489d4b7-676cx from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.797: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.797: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-9crmt from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:29:13.797: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 09:29:13.797: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 09:29:13.797: INFO: nginx-6db489d4b7-dnpsl from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.797: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.797: INFO: linkerd-destination-65b7586456-xkd4w from linkerd started at 2019-10-31 19:06:42 +0000 UTC (2 container statuses recorded)
Nov  4 09:29:13.797: INFO: 	Container destination ready: true, restart count 2
Nov  4 09:29:13.797: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:29:13.797: INFO: linkerd-proxy-injector-76c5cd6fdb-vtp7v from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:29:13.798: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:29:13.798: INFO: 	Container proxy-injector ready: true, restart count 2
Nov  4 09:29:13.798: INFO: nginx-6db489d4b7-zk6l6 from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.798: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.798: INFO: tiller-deploy-5798768fb-x6ggz from kube-system started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.798: INFO: 	Container tiller ready: true, restart count 0
Nov  4 09:29:13.798: INFO: nginx-6db489d4b7-hkfrg from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.798: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.798: INFO: traefik-ingress-controller-m4sr7 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.799: INFO: 	Container traefik-ingress-lb ready: true, restart count 2
Nov  4 09:29:13.799: INFO: nginx-6db489d4b7-wtgl9 from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.799: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.799: INFO: nginx-6db489d4b7-rfdsm from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.799: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.799: INFO: nginx-6db489d4b7-wx6gd from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.799: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.799: INFO: nginx-6db489d4b7-zwl99 from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.800: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.800: INFO: nginx-6db489d4b7-hq9kk from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.800: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.800: INFO: nginx-6db489d4b7-x46qr from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.800: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.800: INFO: linkerd-tap-8478664cb4-r687h from linkerd started at 2019-11-04 08:59:09 +0000 UTC (2 container statuses recorded)
Nov  4 09:29:13.800: INFO: 	Container linkerd-proxy ready: true, restart count 0
Nov  4 09:29:13.800: INFO: 	Container tap ready: true, restart count 0
Nov  4 09:29:13.800: INFO: nginx-6db489d4b7-6xgqq from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.800: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.800: INFO: nginx-6db489d4b7-545v7 from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.800: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.800: INFO: nginx-6db489d4b7-hxbjr from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.801: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.801: INFO: nginx-6db489d4b7-qlxbl from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.801: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.801: INFO: nginx-6db489d4b7-4bl92 from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.801: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.801: INFO: nginx-6db489d4b7-q494r from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.801: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.801: INFO: linkerd-controller-7f457d599-x5dg5 from linkerd started at 2019-10-31 19:06:42 +0000 UTC (3 container statuses recorded)
Nov  4 09:29:13.801: INFO: 	Container destination ready: true, restart count 2
Nov  4 09:29:13.801: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:29:13.801: INFO: 	Container public-api ready: true, restart count 2
Nov  4 09:29:13.801: INFO: nginx-6db489d4b7-4pxjk from default started at 2019-10-31 19:35:14 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.801: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.801: INFO: nginx-6db489d4b7-7m8cn from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.801: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.801: INFO: nginx-6db489d4b7-5zxqm from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.801: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.801: INFO: nginx-6db489d4b7-5mzcb from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.802: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:29:13.802: INFO: coredns-b7f8c8654-nxpz9 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.802: INFO: 	Container coredns ready: true, restart count 2
Nov  4 09:29:13.802: INFO: nginx-6db489d4b7-nx48l from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.802: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.802: INFO: nginx-6db489d4b7-6dswq from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.802: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.802: INFO: nginx-6db489d4b7-cbv7l from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.802: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:29:13.802: INFO: kube-flannel-ds-amd64-jc2f4 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:29:13.802: INFO: 	Container kube-flannel ready: true, restart count 2
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d3eb9cde960b59], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d3eb9cdf43565e], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:29:14.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7215" for this suite.
Nov  4 09:29:20.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:29:20.990: INFO: namespace sched-pred-7215 deletion completed in 6.111842321s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.394 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:29:20.990: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1496
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-1496
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-1496
STEP: creating replication controller externalsvc in namespace services-1496
I1104 09:29:21.308212      19 runners.go:184] Created replication controller with name: externalsvc, namespace: services-1496, replica count: 2
I1104 09:29:24.358666      19 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Nov  4 09:29:24.383: INFO: Creating new exec pod
Nov  4 09:29:26.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=services-1496 execpodv2ftw -- /bin/sh -x -c nslookup clusterip-service'
Nov  4 09:29:26.699: INFO: stderr: "+ nslookup clusterip-service\n"
Nov  4 09:29:26.699: INFO: stdout: "Server:\t\t10.32.0.10\nAddress:\t10.32.0.10#53\n\nclusterip-service.services-1496.svc.cluster.local\tcanonical name = externalsvc.services-1496.svc.cluster.local.\nName:\texternalsvc.services-1496.svc.cluster.local\nAddress: 10.32.0.223\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1496, will wait for the garbage collector to delete the pods
Nov  4 09:29:26.760: INFO: Deleting ReplicationController externalsvc took: 7.313402ms
Nov  4 09:29:27.260: INFO: Terminating ReplicationController externalsvc pods took: 500.216827ms
Nov  4 09:29:41.789: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:29:41.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1496" for this suite.
Nov  4 09:29:47.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:29:47.914: INFO: namespace services-1496 deletion completed in 6.103731255s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:26.924 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:29:47.915: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2780
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:29:48.066: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-b227705b-f206-471a-a025-4dda05867c38" in namespace "security-context-test-2780" to be "success or failure"
Nov  4 09:29:48.068: INFO: Pod "busybox-privileged-false-b227705b-f206-471a-a025-4dda05867c38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.625985ms
Nov  4 09:29:50.072: INFO: Pod "busybox-privileged-false-b227705b-f206-471a-a025-4dda05867c38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006135424s
Nov  4 09:29:50.072: INFO: Pod "busybox-privileged-false-b227705b-f206-471a-a025-4dda05867c38" satisfied condition "success or failure"
Nov  4 09:29:50.080: INFO: Got logs for pod "busybox-privileged-false-b227705b-f206-471a-a025-4dda05867c38": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:29:50.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2780" for this suite.
Nov  4 09:29:56.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:29:56.186: INFO: namespace security-context-test-2780 deletion completed in 6.101705037s

• [SLOW TEST:8.271 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:29:56.187: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3603
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 09:29:56.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-3603'
Nov  4 09:29:56.435: INFO: stderr: ""
Nov  4 09:29:56.435: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Nov  4 09:30:01.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pod e2e-test-httpd-pod --namespace=kubectl-3603 -o json'
Nov  4 09:30:01.568: INFO: stderr: ""
Nov  4 09:30:01.568: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-11-04T09:29:56Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3603\",\n        \"resourceVersion\": \"523226\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-3603/pods/e2e-test-httpd-pod\",\n        \"uid\": \"105b1479-c2d8-47b4-b373-3aa483d6f33f\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-tb682\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8s-1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-tb682\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-tb682\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-04T09:29:56Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-04T09:29:57Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-04T09:29:57Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-04T09:29:56Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://822ec8b454ca5e31170a20d81d8eeaa98447ddf5c3fce8089db5fa1c90c5cc51\",\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-11-04T09:29:57Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.20.20.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.33.2.170\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.33.2.170\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-11-04T09:29:56Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov  4 09:30:01.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 replace -f - --namespace=kubectl-3603'
Nov  4 09:30:01.869: INFO: stderr: ""
Nov  4 09:30:01.869: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Nov  4 09:30:01.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete pods e2e-test-httpd-pod --namespace=kubectl-3603'
Nov  4 09:30:03.866: INFO: stderr: ""
Nov  4 09:30:03.866: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:30:03.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3603" for this suite.
Nov  4 09:30:09.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:30:09.990: INFO: namespace kubectl-3603 deletion completed in 6.119064909s

• [SLOW TEST:13.803 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:30:09.990: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4239
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:30:10.128: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:30:12.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4239" for this suite.
Nov  4 09:30:56.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:30:56.495: INFO: namespace pods-4239 deletion completed in 44.327104501s

• [SLOW TEST:46.505 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:30:56.496: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7765
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-jj5p
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 09:30:56.866: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-jj5p" in namespace "subpath-7765" to be "success or failure"
Nov  4 09:30:56.875: INFO: Pod "pod-subpath-test-secret-jj5p": Phase="Pending", Reason="", readiness=false. Elapsed: 8.982164ms
Nov  4 09:30:58.878: INFO: Pod "pod-subpath-test-secret-jj5p": Phase="Running", Reason="", readiness=true. Elapsed: 2.011925074s
Nov  4 09:31:00.881: INFO: Pod "pod-subpath-test-secret-jj5p": Phase="Running", Reason="", readiness=true. Elapsed: 4.015083085s
Nov  4 09:31:02.885: INFO: Pod "pod-subpath-test-secret-jj5p": Phase="Running", Reason="", readiness=true. Elapsed: 6.018711648s
Nov  4 09:31:04.895: INFO: Pod "pod-subpath-test-secret-jj5p": Phase="Running", Reason="", readiness=true. Elapsed: 8.028866954s
Nov  4 09:31:06.904: INFO: Pod "pod-subpath-test-secret-jj5p": Phase="Running", Reason="", readiness=true. Elapsed: 10.037758212s
Nov  4 09:31:08.910: INFO: Pod "pod-subpath-test-secret-jj5p": Phase="Running", Reason="", readiness=true. Elapsed: 12.044145438s
Nov  4 09:31:10.913: INFO: Pod "pod-subpath-test-secret-jj5p": Phase="Running", Reason="", readiness=true. Elapsed: 14.047149312s
Nov  4 09:31:12.917: INFO: Pod "pod-subpath-test-secret-jj5p": Phase="Running", Reason="", readiness=true. Elapsed: 16.050836881s
Nov  4 09:31:14.920: INFO: Pod "pod-subpath-test-secret-jj5p": Phase="Running", Reason="", readiness=true. Elapsed: 18.054106864s
Nov  4 09:31:16.924: INFO: Pod "pod-subpath-test-secret-jj5p": Phase="Running", Reason="", readiness=true. Elapsed: 20.057519488s
Nov  4 09:31:18.927: INFO: Pod "pod-subpath-test-secret-jj5p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.060583281s
STEP: Saw pod success
Nov  4 09:31:18.927: INFO: Pod "pod-subpath-test-secret-jj5p" satisfied condition "success or failure"
Nov  4 09:31:18.930: INFO: Trying to get logs from node k8s-1 pod pod-subpath-test-secret-jj5p container test-container-subpath-secret-jj5p: <nil>
STEP: delete the pod
Nov  4 09:31:18.990: INFO: Waiting for pod pod-subpath-test-secret-jj5p to disappear
Nov  4 09:31:18.992: INFO: Pod pod-subpath-test-secret-jj5p no longer exists
STEP: Deleting pod pod-subpath-test-secret-jj5p
Nov  4 09:31:18.992: INFO: Deleting pod "pod-subpath-test-secret-jj5p" in namespace "subpath-7765"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:31:18.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7765" for this suite.
Nov  4 09:31:25.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:31:25.094: INFO: namespace subpath-7765 deletion completed in 6.095366411s

• [SLOW TEST:28.598 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:31:25.095: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8884
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:31:25.451: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov  4 09:31:25.470: INFO: Number of nodes with available pods: 0
Nov  4 09:31:25.470: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 09:31:26.477: INFO: Number of nodes with available pods: 0
Nov  4 09:31:26.477: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 09:31:27.479: INFO: Number of nodes with available pods: 3
Nov  4 09:31:27.479: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov  4 09:31:27.537: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:27.537: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:27.537: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:28.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:28.544: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:28.544: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:29.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:29.544: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:29.544: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:30.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:30.544: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:30.544: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:30.544: INFO: Pod daemon-set-wbcdf is not available
Nov  4 09:31:31.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:31.544: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:31.544: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:31.544: INFO: Pod daemon-set-wbcdf is not available
Nov  4 09:31:32.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:32.544: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:32.544: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:32.544: INFO: Pod daemon-set-wbcdf is not available
Nov  4 09:31:33.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:33.544: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:33.544: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:33.544: INFO: Pod daemon-set-wbcdf is not available
Nov  4 09:31:34.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:34.544: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:34.544: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:34.544: INFO: Pod daemon-set-wbcdf is not available
Nov  4 09:31:35.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:35.544: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:35.544: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:35.544: INFO: Pod daemon-set-wbcdf is not available
Nov  4 09:31:36.545: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:36.545: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:36.545: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:36.545: INFO: Pod daemon-set-wbcdf is not available
Nov  4 09:31:37.545: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:37.545: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:37.545: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:37.545: INFO: Pod daemon-set-wbcdf is not available
Nov  4 09:31:38.545: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:38.545: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:38.545: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:38.545: INFO: Pod daemon-set-wbcdf is not available
Nov  4 09:31:39.545: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:39.545: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:39.545: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:39.545: INFO: Pod daemon-set-wbcdf is not available
Nov  4 09:31:40.545: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:40.545: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:40.545: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:40.545: INFO: Pod daemon-set-wbcdf is not available
Nov  4 09:31:41.545: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:41.545: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:41.545: INFO: Wrong image for pod: daemon-set-wbcdf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:41.545: INFO: Pod daemon-set-wbcdf is not available
Nov  4 09:31:42.546: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:42.546: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:42.546: INFO: Pod daemon-set-mld72 is not available
Nov  4 09:31:43.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:43.545: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:43.545: INFO: Pod daemon-set-mld72 is not available
Nov  4 09:31:44.545: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:44.545: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:44.545: INFO: Pod daemon-set-mld72 is not available
Nov  4 09:31:45.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:45.544: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:45.544: INFO: Pod daemon-set-mld72 is not available
Nov  4 09:31:46.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:46.545: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:46.545: INFO: Pod daemon-set-g7s4s is not available
Nov  4 09:31:47.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:47.544: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:47.544: INFO: Pod daemon-set-g7s4s is not available
Nov  4 09:31:48.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:48.544: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:48.544: INFO: Pod daemon-set-g7s4s is not available
Nov  4 09:31:49.545: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:49.545: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:49.545: INFO: Pod daemon-set-g7s4s is not available
Nov  4 09:31:50.545: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:50.545: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:50.545: INFO: Pod daemon-set-g7s4s is not available
Nov  4 09:31:51.545: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:51.545: INFO: Wrong image for pod: daemon-set-g7s4s. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:51.545: INFO: Pod daemon-set-g7s4s is not available
Nov  4 09:31:52.545: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:52.545: INFO: Pod daemon-set-6mp8n is not available
Nov  4 09:31:53.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:53.544: INFO: Pod daemon-set-6mp8n is not available
Nov  4 09:31:54.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:54.544: INFO: Pod daemon-set-6mp8n is not available
Nov  4 09:31:55.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:56.635: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:56.635: INFO: Pod daemon-set-6dp68 is not available
Nov  4 09:31:57.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:57.545: INFO: Pod daemon-set-6dp68 is not available
Nov  4 09:31:58.545: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:58.545: INFO: Pod daemon-set-6dp68 is not available
Nov  4 09:31:59.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:31:59.544: INFO: Pod daemon-set-6dp68 is not available
Nov  4 09:32:00.544: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:32:00.545: INFO: Pod daemon-set-6dp68 is not available
Nov  4 09:32:01.545: INFO: Wrong image for pod: daemon-set-6dp68. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 09:32:01.545: INFO: Pod daemon-set-6dp68 is not available
Nov  4 09:32:02.544: INFO: Pod daemon-set-stgss is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Nov  4 09:32:02.555: INFO: Number of nodes with available pods: 2
Nov  4 09:32:02.555: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 09:32:03.562: INFO: Number of nodes with available pods: 3
Nov  4 09:32:03.562: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8884, will wait for the garbage collector to delete the pods
Nov  4 09:32:03.638: INFO: Deleting DaemonSet.extensions daemon-set took: 11.586299ms
Nov  4 09:32:04.138: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.181643ms
Nov  4 09:32:11.741: INFO: Number of nodes with available pods: 0
Nov  4 09:32:11.741: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 09:32:11.744: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8884/daemonsets","resourceVersion":"523652"},"items":null}

Nov  4 09:32:11.747: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8884/pods","resourceVersion":"523652"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:32:11.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8884" for this suite.
Nov  4 09:32:17.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:32:17.858: INFO: namespace daemonsets-8884 deletion completed in 6.096872142s

• [SLOW TEST:52.763 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:32:17.859: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9334
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-4310ec43-066c-41fa-b105-f502c2fa0e5d
STEP: Creating a pod to test consume secrets
Nov  4 09:32:18.011: INFO: Waiting up to 5m0s for pod "pod-secrets-0151ce8f-ced8-4718-83d8-66a91de8f3bc" in namespace "secrets-9334" to be "success or failure"
Nov  4 09:32:18.014: INFO: Pod "pod-secrets-0151ce8f-ced8-4718-83d8-66a91de8f3bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.830691ms
Nov  4 09:32:20.017: INFO: Pod "pod-secrets-0151ce8f-ced8-4718-83d8-66a91de8f3bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006494107s
STEP: Saw pod success
Nov  4 09:32:20.018: INFO: Pod "pod-secrets-0151ce8f-ced8-4718-83d8-66a91de8f3bc" satisfied condition "success or failure"
Nov  4 09:32:20.020: INFO: Trying to get logs from node k8s-1 pod pod-secrets-0151ce8f-ced8-4718-83d8-66a91de8f3bc container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 09:32:20.041: INFO: Waiting for pod pod-secrets-0151ce8f-ced8-4718-83d8-66a91de8f3bc to disappear
Nov  4 09:32:20.043: INFO: Pod pod-secrets-0151ce8f-ced8-4718-83d8-66a91de8f3bc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:32:20.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9334" for this suite.
Nov  4 09:32:26.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:32:26.146: INFO: namespace secrets-9334 deletion completed in 6.099045509s

• [SLOW TEST:8.287 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:32:26.147: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9542
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  4 09:32:26.296: INFO: Waiting up to 5m0s for pod "pod-60fab537-377f-4bba-a568-699e3766ee81" in namespace "emptydir-9542" to be "success or failure"
Nov  4 09:32:26.300: INFO: Pod "pod-60fab537-377f-4bba-a568-699e3766ee81": Phase="Pending", Reason="", readiness=false. Elapsed: 3.311858ms
Nov  4 09:32:28.303: INFO: Pod "pod-60fab537-377f-4bba-a568-699e3766ee81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006345746s
STEP: Saw pod success
Nov  4 09:32:28.303: INFO: Pod "pod-60fab537-377f-4bba-a568-699e3766ee81" satisfied condition "success or failure"
Nov  4 09:32:28.306: INFO: Trying to get logs from node k8s-1 pod pod-60fab537-377f-4bba-a568-699e3766ee81 container test-container: <nil>
STEP: delete the pod
Nov  4 09:32:28.326: INFO: Waiting for pod pod-60fab537-377f-4bba-a568-699e3766ee81 to disappear
Nov  4 09:32:28.330: INFO: Pod pod-60fab537-377f-4bba-a568-699e3766ee81 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:32:28.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9542" for this suite.
Nov  4 09:32:34.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:32:34.441: INFO: namespace emptydir-9542 deletion completed in 6.107487701s

• [SLOW TEST:8.294 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:32:34.441: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2968
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2968
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-2968
I1104 09:32:34.666258      19 runners.go:184] Created replication controller with name: externalname-service, namespace: services-2968, replica count: 2
Nov  4 09:32:37.716: INFO: Creating new exec pod
I1104 09:32:37.716724      19 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 09:32:40.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=services-2968 execpodv76vc -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov  4 09:32:41.115: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov  4 09:32:41.115: INFO: stdout: ""
Nov  4 09:32:41.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=services-2968 execpodv76vc -- /bin/sh -x -c nc -zv -t -w 2 10.32.0.13 80'
Nov  4 09:32:41.338: INFO: stderr: "+ nc -zv -t -w 2 10.32.0.13 80\nConnection to 10.32.0.13 80 port [tcp/http] succeeded!\n"
Nov  4 09:32:41.338: INFO: stdout: ""
Nov  4 09:32:41.338: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:32:41.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2968" for this suite.
Nov  4 09:32:47.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:32:47.464: INFO: namespace services-2968 deletion completed in 6.095305234s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.023 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:32:47.464: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5676
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Nov  4 09:32:47.625: INFO: Waiting up to 5m0s for pod "pod-f94c6f09-f8dc-4d2d-b3d3-223ee08e1bfa" in namespace "emptydir-5676" to be "success or failure"
Nov  4 09:32:47.637: INFO: Pod "pod-f94c6f09-f8dc-4d2d-b3d3-223ee08e1bfa": Phase="Pending", Reason="", readiness=false. Elapsed: 12.198524ms
Nov  4 09:32:49.640: INFO: Pod "pod-f94c6f09-f8dc-4d2d-b3d3-223ee08e1bfa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014683693s
STEP: Saw pod success
Nov  4 09:32:49.640: INFO: Pod "pod-f94c6f09-f8dc-4d2d-b3d3-223ee08e1bfa" satisfied condition "success or failure"
Nov  4 09:32:49.643: INFO: Trying to get logs from node k8s-1 pod pod-f94c6f09-f8dc-4d2d-b3d3-223ee08e1bfa container test-container: <nil>
STEP: delete the pod
Nov  4 09:32:49.674: INFO: Waiting for pod pod-f94c6f09-f8dc-4d2d-b3d3-223ee08e1bfa to disappear
Nov  4 09:32:49.676: INFO: Pod pod-f94c6f09-f8dc-4d2d-b3d3-223ee08e1bfa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:32:49.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5676" for this suite.
Nov  4 09:32:55.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:32:55.785: INFO: namespace emptydir-5676 deletion completed in 6.104293665s

• [SLOW TEST:8.321 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:32:55.786: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-477
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:32:55.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-477" for this suite.
Nov  4 09:33:01.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:33:02.066: INFO: namespace kubelet-test-477 deletion completed in 6.091085725s

• [SLOW TEST:6.280 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:33:02.068: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8482
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-7d8jq in namespace proxy-8482
I1104 09:33:02.235926      19 runners.go:184] Created replication controller with name: proxy-service-7d8jq, namespace: proxy-8482, replica count: 1
I1104 09:33:03.286318      19 runners.go:184] proxy-service-7d8jq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1104 09:33:04.286493      19 runners.go:184] proxy-service-7d8jq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 09:33:05.286670      19 runners.go:184] proxy-service-7d8jq Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 09:33:05.289: INFO: setup took 3.074596703s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov  4 09:33:05.312: INFO: (0) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 22.279233ms)
Nov  4 09:33:05.313: INFO: (0) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 22.254047ms)
Nov  4 09:33:05.315: INFO: (0) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 25.663388ms)
Nov  4 09:33:05.316: INFO: (0) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 25.245527ms)
Nov  4 09:33:05.316: INFO: (0) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 26.199338ms)
Nov  4 09:33:05.318: INFO: (0) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 27.374902ms)
Nov  4 09:33:05.319: INFO: (0) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 28.12944ms)
Nov  4 09:33:05.319: INFO: (0) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 28.708184ms)
Nov  4 09:33:05.320: INFO: (0) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 30.333333ms)
Nov  4 09:33:05.320: INFO: (0) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 30.307845ms)
Nov  4 09:33:05.321: INFO: (0) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 31.3496ms)
Nov  4 09:33:05.322: INFO: (0) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 32.311575ms)
Nov  4 09:33:05.324: INFO: (0) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 33.051975ms)
Nov  4 09:33:05.326: INFO: (0) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 36.241257ms)
Nov  4 09:33:05.327: INFO: (0) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 37.369438ms)
Nov  4 09:33:05.328: INFO: (0) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 37.685496ms)
Nov  4 09:33:05.339: INFO: (1) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 11.254604ms)
Nov  4 09:33:05.344: INFO: (1) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 15.322975ms)
Nov  4 09:33:05.346: INFO: (1) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 16.539511ms)
Nov  4 09:33:05.346: INFO: (1) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 16.659721ms)
Nov  4 09:33:05.349: INFO: (1) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 20.335904ms)
Nov  4 09:33:05.349: INFO: (1) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 20.356316ms)
Nov  4 09:33:05.350: INFO: (1) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 20.848943ms)
Nov  4 09:33:05.350: INFO: (1) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 21.599555ms)
Nov  4 09:33:05.350: INFO: (1) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 21.067916ms)
Nov  4 09:33:05.351: INFO: (1) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 21.662766ms)
Nov  4 09:33:05.351: INFO: (1) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 22.532009ms)
Nov  4 09:33:05.353: INFO: (1) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 24.362411ms)
Nov  4 09:33:05.353: INFO: (1) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 24.498222ms)
Nov  4 09:33:05.354: INFO: (1) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 24.969575ms)
Nov  4 09:33:05.354: INFO: (1) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 24.99342ms)
Nov  4 09:33:05.355: INFO: (1) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 26.437362ms)
Nov  4 09:33:05.364: INFO: (2) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 9.5548ms)
Nov  4 09:33:05.369: INFO: (2) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 13.558833ms)
Nov  4 09:33:05.370: INFO: (2) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 14.140631ms)
Nov  4 09:33:05.376: INFO: (2) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 19.978545ms)
Nov  4 09:33:05.376: INFO: (2) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 20.53757ms)
Nov  4 09:33:05.376: INFO: (2) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 21.603046ms)
Nov  4 09:33:05.377: INFO: (2) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 21.310135ms)
Nov  4 09:33:05.377: INFO: (2) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 21.317193ms)
Nov  4 09:33:05.378: INFO: (2) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 22.660255ms)
Nov  4 09:33:05.378: INFO: (2) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 21.777888ms)
Nov  4 09:33:05.378: INFO: (2) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 23.350617ms)
Nov  4 09:33:05.379: INFO: (2) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 23.71452ms)
Nov  4 09:33:05.381: INFO: (2) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 24.887302ms)
Nov  4 09:33:05.381: INFO: (2) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 26.05294ms)
Nov  4 09:33:05.382: INFO: (2) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 26.781491ms)
Nov  4 09:33:05.382: INFO: (2) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 27.057011ms)
Nov  4 09:33:05.395: INFO: (3) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 11.518637ms)
Nov  4 09:33:05.396: INFO: (3) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 13.88379ms)
Nov  4 09:33:05.397: INFO: (3) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 12.794609ms)
Nov  4 09:33:05.399: INFO: (3) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 16.167767ms)
Nov  4 09:33:05.401: INFO: (3) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 18.589292ms)
Nov  4 09:33:05.402: INFO: (3) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 17.943192ms)
Nov  4 09:33:05.403: INFO: (3) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 19.905983ms)
Nov  4 09:33:05.406: INFO: (3) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 23.700957ms)
Nov  4 09:33:05.407: INFO: (3) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 23.064472ms)
Nov  4 09:33:05.407: INFO: (3) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 24.032984ms)
Nov  4 09:33:05.407: INFO: (3) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 24.028483ms)
Nov  4 09:33:05.408: INFO: (3) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 24.947882ms)
Nov  4 09:33:05.408: INFO: (3) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 24.373871ms)
Nov  4 09:33:05.412: INFO: (3) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 28.831438ms)
Nov  4 09:33:05.413: INFO: (3) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 29.168276ms)
Nov  4 09:33:05.413: INFO: (3) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 29.458347ms)
Nov  4 09:33:05.428: INFO: (4) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 14.492099ms)
Nov  4 09:33:05.428: INFO: (4) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 14.607196ms)
Nov  4 09:33:05.429: INFO: (4) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 15.448122ms)
Nov  4 09:33:05.433: INFO: (4) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 18.253676ms)
Nov  4 09:33:05.438: INFO: (4) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 23.647046ms)
Nov  4 09:33:05.438: INFO: (4) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 23.656177ms)
Nov  4 09:33:05.438: INFO: (4) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 23.46607ms)
Nov  4 09:33:05.438: INFO: (4) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 24.351138ms)
Nov  4 09:33:05.439: INFO: (4) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 24.453666ms)
Nov  4 09:33:05.439: INFO: (4) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 25.545464ms)
Nov  4 09:33:05.440: INFO: (4) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 24.805917ms)
Nov  4 09:33:05.440: INFO: (4) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 26.275993ms)
Nov  4 09:33:05.440: INFO: (4) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 25.879273ms)
Nov  4 09:33:05.442: INFO: (4) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 26.735058ms)
Nov  4 09:33:05.442: INFO: (4) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 28.621175ms)
Nov  4 09:33:05.443: INFO: (4) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 28.345518ms)
Nov  4 09:33:05.472: INFO: (5) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 28.304148ms)
Nov  4 09:33:05.477: INFO: (5) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 33.545799ms)
Nov  4 09:33:05.480: INFO: (5) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 36.719849ms)
Nov  4 09:33:05.481: INFO: (5) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 37.148003ms)
Nov  4 09:33:05.481: INFO: (5) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 37.644112ms)
Nov  4 09:33:05.481: INFO: (5) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 37.35184ms)
Nov  4 09:33:05.482: INFO: (5) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 37.727406ms)
Nov  4 09:33:05.483: INFO: (5) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 39.008686ms)
Nov  4 09:33:05.483: INFO: (5) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 38.679211ms)
Nov  4 09:33:05.483: INFO: (5) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 38.554329ms)
Nov  4 09:33:05.483: INFO: (5) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 39.943254ms)
Nov  4 09:33:05.483: INFO: (5) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 39.285504ms)
Nov  4 09:33:05.486: INFO: (5) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 43.199463ms)
Nov  4 09:33:05.487: INFO: (5) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 43.303656ms)
Nov  4 09:33:05.487: INFO: (5) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 44.426529ms)
Nov  4 09:33:05.488: INFO: (5) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 44.672164ms)
Nov  4 09:33:05.499: INFO: (6) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 10.224434ms)
Nov  4 09:33:05.502: INFO: (6) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 12.744173ms)
Nov  4 09:33:05.502: INFO: (6) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 14.103096ms)
Nov  4 09:33:05.502: INFO: (6) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 14.35609ms)
Nov  4 09:33:05.507: INFO: (6) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 18.006934ms)
Nov  4 09:33:05.512: INFO: (6) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 23.323536ms)
Nov  4 09:33:05.512: INFO: (6) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 23.848213ms)
Nov  4 09:33:05.514: INFO: (6) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 25.323357ms)
Nov  4 09:33:05.519: INFO: (6) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 29.858309ms)
Nov  4 09:33:05.519: INFO: (6) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 30.919547ms)
Nov  4 09:33:05.519: INFO: (6) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 30.362222ms)
Nov  4 09:33:05.519: INFO: (6) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 30.960738ms)
Nov  4 09:33:05.519: INFO: (6) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 31.521288ms)
Nov  4 09:33:05.520: INFO: (6) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 31.007382ms)
Nov  4 09:33:05.520: INFO: (6) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 31.731946ms)
Nov  4 09:33:05.520: INFO: (6) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 31.585915ms)
Nov  4 09:33:05.537: INFO: (7) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 16.423467ms)
Nov  4 09:33:05.542: INFO: (7) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 20.787291ms)
Nov  4 09:33:05.542: INFO: (7) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 21.742272ms)
Nov  4 09:33:05.542: INFO: (7) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 21.214512ms)
Nov  4 09:33:05.543: INFO: (7) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 22.199544ms)
Nov  4 09:33:05.543: INFO: (7) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 21.758111ms)
Nov  4 09:33:05.543: INFO: (7) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 21.578395ms)
Nov  4 09:33:05.543: INFO: (7) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 23.057815ms)
Nov  4 09:33:05.544: INFO: (7) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 22.567375ms)
Nov  4 09:33:05.544: INFO: (7) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 22.991673ms)
Nov  4 09:33:05.557: INFO: (7) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 36.357945ms)
Nov  4 09:33:05.557: INFO: (7) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 36.184698ms)
Nov  4 09:33:05.558: INFO: (7) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 36.715219ms)
Nov  4 09:33:05.558: INFO: (7) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 37.03434ms)
Nov  4 09:33:05.558: INFO: (7) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 36.552579ms)
Nov  4 09:33:05.558: INFO: (7) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 37.693149ms)
Nov  4 09:33:05.575: INFO: (8) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 16.234443ms)
Nov  4 09:33:05.579: INFO: (8) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 19.815701ms)
Nov  4 09:33:05.580: INFO: (8) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 21.371233ms)
Nov  4 09:33:05.584: INFO: (8) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 24.749866ms)
Nov  4 09:33:05.588: INFO: (8) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 29.211771ms)
Nov  4 09:33:05.590: INFO: (8) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 31.556677ms)
Nov  4 09:33:05.595: INFO: (8) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 35.564631ms)
Nov  4 09:33:05.595: INFO: (8) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 36.153997ms)
Nov  4 09:33:05.598: INFO: (8) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 39.735351ms)
Nov  4 09:33:05.600: INFO: (8) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 41.651617ms)
Nov  4 09:33:05.601: INFO: (8) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 41.963557ms)
Nov  4 09:33:05.601: INFO: (8) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 42.034798ms)
Nov  4 09:33:05.601: INFO: (8) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 42.002682ms)
Nov  4 09:33:05.602: INFO: (8) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 43.812285ms)
Nov  4 09:33:05.603: INFO: (8) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 43.592922ms)
Nov  4 09:33:05.605: INFO: (8) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 45.568937ms)
Nov  4 09:33:05.618: INFO: (9) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 11.947621ms)
Nov  4 09:33:05.621: INFO: (9) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 14.855497ms)
Nov  4 09:33:05.622: INFO: (9) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 17.659923ms)
Nov  4 09:33:05.623: INFO: (9) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 17.140122ms)
Nov  4 09:33:05.631: INFO: (9) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 25.055565ms)
Nov  4 09:33:05.632: INFO: (9) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 26.888279ms)
Nov  4 09:33:05.632: INFO: (9) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 26.373947ms)
Nov  4 09:33:05.632: INFO: (9) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 27.40967ms)
Nov  4 09:33:05.633: INFO: (9) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 26.222178ms)
Nov  4 09:33:05.633: INFO: (9) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 26.557859ms)
Nov  4 09:33:05.635: INFO: (9) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 28.534519ms)
Nov  4 09:33:05.637: INFO: (9) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 30.593291ms)
Nov  4 09:33:05.637: INFO: (9) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 31.317662ms)
Nov  4 09:33:05.638: INFO: (9) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 31.64773ms)
Nov  4 09:33:05.638: INFO: (9) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 31.800682ms)
Nov  4 09:33:05.638: INFO: (9) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 33.055765ms)
Nov  4 09:33:05.657: INFO: (10) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 18.096419ms)
Nov  4 09:33:05.658: INFO: (10) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 19.329877ms)
Nov  4 09:33:05.659: INFO: (10) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 20.731698ms)
Nov  4 09:33:05.659: INFO: (10) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 20.571043ms)
Nov  4 09:33:05.663: INFO: (10) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 25.366246ms)
Nov  4 09:33:05.664: INFO: (10) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 25.314747ms)
Nov  4 09:33:05.667: INFO: (10) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 27.543945ms)
Nov  4 09:33:05.670: INFO: (10) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 30.749735ms)
Nov  4 09:33:05.671: INFO: (10) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 31.935445ms)
Nov  4 09:33:05.671: INFO: (10) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 32.759911ms)
Nov  4 09:33:05.671: INFO: (10) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 32.859417ms)
Nov  4 09:33:05.672: INFO: (10) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 33.454472ms)
Nov  4 09:33:05.675: INFO: (10) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 36.304055ms)
Nov  4 09:33:05.675: INFO: (10) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 36.422315ms)
Nov  4 09:33:05.676: INFO: (10) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 36.771642ms)
Nov  4 09:33:05.676: INFO: (10) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 37.592583ms)
Nov  4 09:33:05.695: INFO: (11) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 18.934376ms)
Nov  4 09:33:05.695: INFO: (11) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 18.46106ms)
Nov  4 09:33:05.696: INFO: (11) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 19.41457ms)
Nov  4 09:33:05.696: INFO: (11) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 19.288745ms)
Nov  4 09:33:05.696: INFO: (11) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 19.780245ms)
Nov  4 09:33:05.705: INFO: (11) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 27.965406ms)
Nov  4 09:33:05.705: INFO: (11) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 28.03168ms)
Nov  4 09:33:05.705: INFO: (11) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 29.01897ms)
Nov  4 09:33:05.707: INFO: (11) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 29.601292ms)
Nov  4 09:33:05.707: INFO: (11) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 30.293478ms)
Nov  4 09:33:05.711: INFO: (11) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 34.193981ms)
Nov  4 09:33:05.711: INFO: (11) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 34.546275ms)
Nov  4 09:33:05.711: INFO: (11) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 34.942631ms)
Nov  4 09:33:05.712: INFO: (11) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 34.727ms)
Nov  4 09:33:05.713: INFO: (11) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 35.819776ms)
Nov  4 09:33:05.715: INFO: (11) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 38.120158ms)
Nov  4 09:33:05.728: INFO: (12) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 13.585339ms)
Nov  4 09:33:05.739: INFO: (12) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 23.311356ms)
Nov  4 09:33:05.740: INFO: (12) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 24.56959ms)
Nov  4 09:33:05.742: INFO: (12) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 27.416366ms)
Nov  4 09:33:05.743: INFO: (12) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 27.180629ms)
Nov  4 09:33:05.743: INFO: (12) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 27.13802ms)
Nov  4 09:33:05.743: INFO: (12) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 28.192698ms)
Nov  4 09:33:05.747: INFO: (12) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 30.982491ms)
Nov  4 09:33:05.747: INFO: (12) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 32.216072ms)
Nov  4 09:33:05.747: INFO: (12) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 31.899636ms)
Nov  4 09:33:05.748: INFO: (12) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 32.289652ms)
Nov  4 09:33:05.749: INFO: (12) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 33.840993ms)
Nov  4 09:33:05.751: INFO: (12) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 35.981547ms)
Nov  4 09:33:05.751: INFO: (12) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 35.644158ms)
Nov  4 09:33:05.752: INFO: (12) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 36.444067ms)
Nov  4 09:33:05.753: INFO: (12) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 37.799059ms)
Nov  4 09:33:05.769: INFO: (13) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 14.980501ms)
Nov  4 09:33:05.774: INFO: (13) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 20.288246ms)
Nov  4 09:33:05.775: INFO: (13) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 20.561189ms)
Nov  4 09:33:05.777: INFO: (13) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 23.458261ms)
Nov  4 09:33:05.777: INFO: (13) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 23.55459ms)
Nov  4 09:33:05.777: INFO: (13) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 23.227618ms)
Nov  4 09:33:05.778: INFO: (13) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 24.846539ms)
Nov  4 09:33:05.779: INFO: (13) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 24.867299ms)
Nov  4 09:33:05.781: INFO: (13) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 27.789317ms)
Nov  4 09:33:05.781: INFO: (13) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 27.083332ms)
Nov  4 09:33:05.782: INFO: (13) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 27.745478ms)
Nov  4 09:33:05.783: INFO: (13) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 28.774065ms)
Nov  4 09:33:05.783: INFO: (13) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 28.965189ms)
Nov  4 09:33:05.785: INFO: (13) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 30.89041ms)
Nov  4 09:33:05.786: INFO: (13) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 32.312082ms)
Nov  4 09:33:05.787: INFO: (13) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 32.49477ms)
Nov  4 09:33:05.798: INFO: (14) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 11.672965ms)
Nov  4 09:33:05.811: INFO: (14) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 23.779137ms)
Nov  4 09:33:05.812: INFO: (14) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 24.692873ms)
Nov  4 09:33:05.813: INFO: (14) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 25.609202ms)
Nov  4 09:33:05.813: INFO: (14) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 25.517212ms)
Nov  4 09:33:05.813: INFO: (14) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 26.140534ms)
Nov  4 09:33:05.813: INFO: (14) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 26.689371ms)
Nov  4 09:33:05.814: INFO: (14) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 26.924018ms)
Nov  4 09:33:05.814: INFO: (14) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 26.542455ms)
Nov  4 09:33:05.814: INFO: (14) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 27.172975ms)
Nov  4 09:33:05.815: INFO: (14) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 28.214064ms)
Nov  4 09:33:05.816: INFO: (14) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 28.50359ms)
Nov  4 09:33:05.819: INFO: (14) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 32.002977ms)
Nov  4 09:33:05.820: INFO: (14) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 32.03201ms)
Nov  4 09:33:05.820: INFO: (14) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 32.955946ms)
Nov  4 09:33:05.820: INFO: (14) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 33.501109ms)
Nov  4 09:33:05.836: INFO: (15) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 14.861133ms)
Nov  4 09:33:05.837: INFO: (15) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 16.899392ms)
Nov  4 09:33:05.838: INFO: (15) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 16.815476ms)
Nov  4 09:33:05.843: INFO: (15) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 22.107437ms)
Nov  4 09:33:05.844: INFO: (15) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 23.150462ms)
Nov  4 09:33:05.844: INFO: (15) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 22.985783ms)
Nov  4 09:33:05.845: INFO: (15) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 23.973944ms)
Nov  4 09:33:05.851: INFO: (15) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 29.777486ms)
Nov  4 09:33:05.851: INFO: (15) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 30.231126ms)
Nov  4 09:33:05.852: INFO: (15) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 30.935406ms)
Nov  4 09:33:05.852: INFO: (15) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 30.893941ms)
Nov  4 09:33:05.852: INFO: (15) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 31.490597ms)
Nov  4 09:33:05.852: INFO: (15) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 30.979766ms)
Nov  4 09:33:05.855: INFO: (15) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 33.246615ms)
Nov  4 09:33:05.855: INFO: (15) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 33.989622ms)
Nov  4 09:33:05.856: INFO: (15) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 34.652201ms)
Nov  4 09:33:05.876: INFO: (16) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 17.576267ms)
Nov  4 09:33:05.876: INFO: (16) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 17.442622ms)
Nov  4 09:33:05.876: INFO: (16) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 20.071595ms)
Nov  4 09:33:05.877: INFO: (16) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 20.560521ms)
Nov  4 09:33:05.883: INFO: (16) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 25.077351ms)
Nov  4 09:33:05.885: INFO: (16) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 28.760356ms)
Nov  4 09:33:05.885: INFO: (16) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 27.041511ms)
Nov  4 09:33:05.886: INFO: (16) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 27.732398ms)
Nov  4 09:33:05.886: INFO: (16) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 29.567476ms)
Nov  4 09:33:05.886: INFO: (16) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 29.524327ms)
Nov  4 09:33:05.887: INFO: (16) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 30.276808ms)
Nov  4 09:33:05.888: INFO: (16) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 29.373188ms)
Nov  4 09:33:05.889: INFO: (16) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 32.610656ms)
Nov  4 09:33:05.889: INFO: (16) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 32.786166ms)
Nov  4 09:33:05.890: INFO: (16) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 33.664256ms)
Nov  4 09:33:05.891: INFO: (16) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 32.746266ms)
Nov  4 09:33:05.907: INFO: (17) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 15.213758ms)
Nov  4 09:33:05.909: INFO: (17) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 17.547603ms)
Nov  4 09:33:05.913: INFO: (17) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 20.729317ms)
Nov  4 09:33:05.914: INFO: (17) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 22.72621ms)
Nov  4 09:33:05.914: INFO: (17) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 23.135934ms)
Nov  4 09:33:05.919: INFO: (17) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 26.736628ms)
Nov  4 09:33:05.919: INFO: (17) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 26.757417ms)
Nov  4 09:33:05.919: INFO: (17) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 27.924733ms)
Nov  4 09:33:05.920: INFO: (17) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 27.599012ms)
Nov  4 09:33:05.922: INFO: (17) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 30.664962ms)
Nov  4 09:33:05.923: INFO: (17) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 30.490687ms)
Nov  4 09:33:05.924: INFO: (17) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 32.587334ms)
Nov  4 09:33:05.927: INFO: (17) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 35.353591ms)
Nov  4 09:33:05.927: INFO: (17) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 35.64018ms)
Nov  4 09:33:05.927: INFO: (17) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 36.09812ms)
Nov  4 09:33:05.928: INFO: (17) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 36.515147ms)
Nov  4 09:33:05.945: INFO: (18) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 16.805908ms)
Nov  4 09:33:05.951: INFO: (18) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 21.921624ms)
Nov  4 09:33:05.951: INFO: (18) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 22.939931ms)
Nov  4 09:33:05.952: INFO: (18) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 23.158602ms)
Nov  4 09:33:05.952: INFO: (18) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 23.018008ms)
Nov  4 09:33:05.952: INFO: (18) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 22.950522ms)
Nov  4 09:33:05.953: INFO: (18) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 24.897307ms)
Nov  4 09:33:05.954: INFO: (18) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 25.71366ms)
Nov  4 09:33:05.958: INFO: (18) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 29.441871ms)
Nov  4 09:33:05.958: INFO: (18) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 30.134009ms)
Nov  4 09:33:05.959: INFO: (18) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 30.264735ms)
Nov  4 09:33:05.960: INFO: (18) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 31.18349ms)
Nov  4 09:33:05.962: INFO: (18) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 32.534123ms)
Nov  4 09:33:05.962: INFO: (18) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 32.952218ms)
Nov  4 09:33:05.964: INFO: (18) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 34.765703ms)
Nov  4 09:33:05.964: INFO: (18) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 35.571319ms)
Nov  4 09:33:05.980: INFO: (19) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:162/proxy/: bar (200; 15.281504ms)
Nov  4 09:33:05.983: INFO: (19) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:1080/proxy/rewriteme">test<... (200; 18.820955ms)
Nov  4 09:33:05.991: INFO: (19) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:443/proxy/tlsrewritem... (200; 25.284614ms)
Nov  4 09:33:05.991: INFO: (19) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:1080/proxy/rewriteme">... (200; 25.918937ms)
Nov  4 09:33:05.991: INFO: (19) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:462/proxy/: tls qux (200; 26.697408ms)
Nov  4 09:33:05.992: INFO: (19) /api/v1/namespaces/proxy-8482/pods/https:proxy-service-7d8jq-lb776:460/proxy/: tls baz (200; 26.118559ms)
Nov  4 09:33:05.992: INFO: (19) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776:160/proxy/: foo (200; 26.6749ms)
Nov  4 09:33:05.992: INFO: (19) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:162/proxy/: bar (200; 26.835001ms)
Nov  4 09:33:05.994: INFO: (19) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname2/proxy/: bar (200; 29.076542ms)
Nov  4 09:33:05.995: INFO: (19) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname2/proxy/: tls qux (200; 30.26428ms)
Nov  4 09:33:05.997: INFO: (19) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname1/proxy/: foo (200; 32.012365ms)
Nov  4 09:33:05.997: INFO: (19) /api/v1/namespaces/proxy-8482/pods/http:proxy-service-7d8jq-lb776:160/proxy/: foo (200; 31.561304ms)
Nov  4 09:33:05.997: INFO: (19) /api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/: <a href="/api/v1/namespaces/proxy-8482/pods/proxy-service-7d8jq-lb776/proxy/rewriteme">test</a> (200; 32.43271ms)
Nov  4 09:33:05.998: INFO: (19) /api/v1/namespaces/proxy-8482/services/https:proxy-service-7d8jq:tlsportname1/proxy/: tls baz (200; 33.435718ms)
Nov  4 09:33:06.000: INFO: (19) /api/v1/namespaces/proxy-8482/services/proxy-service-7d8jq:portname2/proxy/: bar (200; 34.797207ms)
Nov  4 09:33:06.001: INFO: (19) /api/v1/namespaces/proxy-8482/services/http:proxy-service-7d8jq:portname1/proxy/: foo (200; 35.851722ms)
STEP: deleting ReplicationController proxy-service-7d8jq in namespace proxy-8482, will wait for the garbage collector to delete the pods
Nov  4 09:33:06.060: INFO: Deleting ReplicationController proxy-service-7d8jq took: 7.329998ms
Nov  4 09:33:06.561: INFO: Terminating ReplicationController proxy-service-7d8jq pods took: 500.21682ms
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:33:08.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8482" for this suite.
Nov  4 09:33:14.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:33:14.362: INFO: namespace proxy-8482 deletion completed in 6.096787958s

• [SLOW TEST:12.294 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:33:14.363: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4286
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Nov  4 09:33:14.499: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:33:38.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4286" for this suite.
Nov  4 09:33:44.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:33:44.395: INFO: namespace crd-publish-openapi-4286 deletion completed in 6.105144623s

• [SLOW TEST:30.033 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:33:44.396: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-4738
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov  4 09:33:46.590: INFO: &Pod{ObjectMeta:{send-events-a13447ac-d3f4-4a0b-9b34-c8893b0f3501  events-4738 /api/v1/namespaces/events-4738/pods/send-events-a13447ac-d3f4-4a0b-9b34-c8893b0f3501 7890fe83-5fb3-4d42-a737-3c226e019a66 524120 0 2019-11-04 09:33:44 +0000 UTC <nil> <nil> map[name:foo time:554378041] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-k2zk6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-k2zk6,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-k2zk6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:33:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:33:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:33:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:33:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.2.182,StartTime:2019-11-04 09:33:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 09:33:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:containerd://6a86adc6c8f3c5cf146b2063b21218b2c2630058a6327802dedd4c87ffab4c2f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.182,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Nov  4 09:33:48.593: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov  4 09:33:50.596: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:33:50.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4738" for this suite.
Nov  4 09:34:34.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:34:34.795: INFO: namespace events-4738 deletion completed in 44.183046865s

• [SLOW TEST:50.399 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:34:34.797: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7678
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-3fa09cb4-96d0-4eb9-8f76-bbd2fae9d457
STEP: Creating a pod to test consume secrets
Nov  4 09:34:34.993: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-491cb2c8-09c9-4c63-93b8-318a0c869bc6" in namespace "projected-7678" to be "success or failure"
Nov  4 09:34:35.035: INFO: Pod "pod-projected-secrets-491cb2c8-09c9-4c63-93b8-318a0c869bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 42.203915ms
Nov  4 09:34:37.042: INFO: Pod "pod-projected-secrets-491cb2c8-09c9-4c63-93b8-318a0c869bc6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.049170681s
STEP: Saw pod success
Nov  4 09:34:37.043: INFO: Pod "pod-projected-secrets-491cb2c8-09c9-4c63-93b8-318a0c869bc6" satisfied condition "success or failure"
Nov  4 09:34:37.047: INFO: Trying to get logs from node k8s-1 pod pod-projected-secrets-491cb2c8-09c9-4c63-93b8-318a0c869bc6 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 09:34:37.075: INFO: Waiting for pod pod-projected-secrets-491cb2c8-09c9-4c63-93b8-318a0c869bc6 to disappear
Nov  4 09:34:37.085: INFO: Pod pod-projected-secrets-491cb2c8-09c9-4c63-93b8-318a0c869bc6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:34:37.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7678" for this suite.
Nov  4 09:34:43.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:34:43.291: INFO: namespace projected-7678 deletion completed in 6.198456052s

• [SLOW TEST:8.494 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:34:43.293: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4084
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-a931ec6a-891a-470a-9de5-eec46f66f897
STEP: Creating a pod to test consume secrets
Nov  4 09:34:43.506: INFO: Waiting up to 5m0s for pod "pod-secrets-e298856c-fb44-49ef-8b89-640d204ae14f" in namespace "secrets-4084" to be "success or failure"
Nov  4 09:34:43.525: INFO: Pod "pod-secrets-e298856c-fb44-49ef-8b89-640d204ae14f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.932699ms
Nov  4 09:34:45.531: INFO: Pod "pod-secrets-e298856c-fb44-49ef-8b89-640d204ae14f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015493194s
STEP: Saw pod success
Nov  4 09:34:45.531: INFO: Pod "pod-secrets-e298856c-fb44-49ef-8b89-640d204ae14f" satisfied condition "success or failure"
Nov  4 09:34:45.535: INFO: Trying to get logs from node k8s-1 pod pod-secrets-e298856c-fb44-49ef-8b89-640d204ae14f container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 09:34:45.562: INFO: Waiting for pod pod-secrets-e298856c-fb44-49ef-8b89-640d204ae14f to disappear
Nov  4 09:34:45.568: INFO: Pod pod-secrets-e298856c-fb44-49ef-8b89-640d204ae14f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:34:45.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4084" for this suite.
Nov  4 09:34:51.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:34:51.786: INFO: namespace secrets-4084 deletion completed in 6.213498553s

• [SLOW TEST:8.494 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:34:51.789: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7163
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 09:34:51.996: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 09:34:52.013: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 09:34:52.016: INFO: 
Logging pods the kubelet thinks is on node k8s-1 before test
Nov  4 09:34:52.027: INFO: sonobuoy from sonobuoy started at 2019-11-04 08:33:38 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.027: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 09:34:52.027: INFO: kube-flannel-ds-amd64-9ldh9 from kube-system started at 2019-11-04 09:27:35 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.027: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 09:34:52.027: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-9v4q5 from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:34:52.027: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 09:34:52.027: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 09:34:52.027: INFO: traefik-ingress-controller-m7ffw from kube-system started at 2019-11-04 09:27:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.027: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 09:34:52.027: INFO: 
Logging pods the kubelet thinks is on node k8s-2 before test
Nov  4 09:34:52.079: INFO: nginx-6db489d4b7-2nv6m from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.079: INFO: nginx-6db489d4b7-ltjcr from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.079: INFO: nginx-6db489d4b7-4rl5q from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.079: INFO: nginx-6db489d4b7-6hht8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.079: INFO: sonobuoy-e2e-job-77622933ebe14f87 from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container e2e ready: true, restart count 0
Nov  4 09:34:52.079: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 09:34:52.079: INFO: kube-flannel-ds-amd64-f44md from kube-system started at 2019-10-31 19:06:43 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container kube-flannel ready: true, restart count 2
Nov  4 09:34:52.079: INFO: coredns-b7f8c8654-8kwbt from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container coredns ready: true, restart count 2
Nov  4 09:34:52.079: INFO: nginx-6db489d4b7-q647m from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.079: INFO: nginx-6db489d4b7-c4xhg from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.079: INFO: linkerd-web-685cd8d7c-dhpj5 from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:34:52.079: INFO: 	Container web ready: true, restart count 2
Nov  4 09:34:52.079: INFO: kubernetes-dashboard-bf855c94d-s95bc from kubernetes-dashboard started at 2019-11-04 08:59:09 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov  4 09:34:52.079: INFO: nginx-6db489d4b7-t97cp from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.079: INFO: nginx-6db489d4b7-5lbr9 from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.079: INFO: nginx-6db489d4b7-rlnhg from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.079: INFO: nginx-6db489d4b7-w6jwg from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.079: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.079: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-z8dpb from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 09:34:52.080: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 09:34:52.080: INFO: nginx-6db489d4b7-6gqp6 from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.080: INFO: nginx-6db489d4b7-pbhw4 from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.080: INFO: nginx-6db489d4b7-x5b7v from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.080: INFO: linkerd-prometheus-f74b98d8-hgtgk from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:34:52.080: INFO: 	Container prometheus ready: true, restart count 2
Nov  4 09:34:52.080: INFO: nginx-6db489d4b7-kcbjs from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.080: INFO: nginx-6db489d4b7-hwpf8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.080: INFO: nginx-6db489d4b7-xds5m from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.080: INFO: nginx-6db489d4b7-qp42l from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.080: INFO: linkerd-grafana-744cfbd49d-dnzqr from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container grafana ready: true, restart count 2
Nov  4 09:34:52.080: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:34:52.080: INFO: nginx-6db489d4b7-qg6lx from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.080: INFO: nginx-6db489d4b7-ncpfq from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.080: INFO: nginx-6db489d4b7-dk2z8 from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.080: INFO: nginx-6db489d4b7-xmrg5 from default started at 2019-10-31 19:35:15 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.080: INFO: nginx-6db489d4b7-8j7fq from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.080: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.081: INFO: nginx-6db489d4b7-cgwdq from default started at 2019-11-04 08:59:09 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.081: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.081: INFO: nginx-6db489d4b7-lhjpz from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.081: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.081: INFO: kubernetes-metrics-scraper-6b97c6d857-cc8fz from kubernetes-dashboard started at 2019-11-04 08:59:09 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.081: INFO: 	Container kubernetes-metrics-scraper ready: true, restart count 0
Nov  4 09:34:52.081: INFO: nginx-6db489d4b7-x9chn from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.081: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.081: INFO: traefik-ingress-controller-2rb4m from kube-system started at 2019-10-31 19:06:43 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.081: INFO: 	Container traefik-ingress-lb ready: true, restart count 2
Nov  4 09:34:52.082: INFO: linkerd-sp-validator-8489dfcf59-4vvmx from linkerd started at 2019-10-31 19:06:42 +0000 UTC (2 container statuses recorded)
Nov  4 09:34:52.082: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:34:52.082: INFO: 	Container sp-validator ready: true, restart count 2
Nov  4 09:34:52.082: INFO: nginx-6db489d4b7-74qqm from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.082: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.083: INFO: linkerd-identity-6d9bf4497f-qfsm4 from linkerd started at 2019-11-04 08:59:09 +0000 UTC (2 container statuses recorded)
Nov  4 09:34:52.083: INFO: 	Container identity ready: true, restart count 0
Nov  4 09:34:52.083: INFO: 	Container linkerd-proxy ready: true, restart count 0
Nov  4 09:34:52.083: INFO: 
Logging pods the kubelet thinks is on node k8s-3 before test
Nov  4 09:34:52.102: INFO: kube-flannel-ds-amd64-jc2f4 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.102: INFO: 	Container kube-flannel ready: true, restart count 2
Nov  4 09:34:52.102: INFO: nginx-6db489d4b7-nx48l from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.103: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.103: INFO: nginx-6db489d4b7-6dswq from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.103: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.103: INFO: nginx-6db489d4b7-cbv7l from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.103: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.103: INFO: linkerd-destination-65b7586456-xkd4w from linkerd started at 2019-10-31 19:06:42 +0000 UTC (2 container statuses recorded)
Nov  4 09:34:52.103: INFO: 	Container destination ready: true, restart count 2
Nov  4 09:34:52.103: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:34:52.103: INFO: nginx-6db489d4b7-zvzhk from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.104: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.104: INFO: nginx-6db489d4b7-676cx from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.104: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.105: INFO: sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-9crmt from sonobuoy started at 2019-11-04 08:33:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:34:52.106: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 09:34:52.106: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 09:34:52.106: INFO: nginx-6db489d4b7-dnpsl from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.106: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.107: INFO: traefik-ingress-controller-m4sr7 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.107: INFO: 	Container traefik-ingress-lb ready: true, restart count 2
Nov  4 09:34:52.107: INFO: linkerd-proxy-injector-76c5cd6fdb-vtp7v from linkerd started at 2019-10-31 19:06:43 +0000 UTC (2 container statuses recorded)
Nov  4 09:34:52.109: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:34:52.109: INFO: 	Container proxy-injector ready: true, restart count 2
Nov  4 09:34:52.109: INFO: nginx-6db489d4b7-zk6l6 from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.109: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.109: INFO: tiller-deploy-5798768fb-x6ggz from kube-system started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.109: INFO: 	Container tiller ready: true, restart count 0
Nov  4 09:34:52.109: INFO: nginx-6db489d4b7-hkfrg from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.109: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.109: INFO: nginx-6db489d4b7-rfdsm from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.110: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.110: INFO: nginx-6db489d4b7-wtgl9 from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.110: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.110: INFO: nginx-6db489d4b7-hq9kk from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.110: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.110: INFO: nginx-6db489d4b7-wx6gd from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.110: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.110: INFO: nginx-6db489d4b7-zwl99 from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.110: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.110: INFO: nginx-6db489d4b7-545v7 from default started at 2019-10-31 19:35:18 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.111: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.111: INFO: nginx-6db489d4b7-x46qr from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.111: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.111: INFO: linkerd-tap-8478664cb4-r687h from linkerd started at 2019-11-04 08:59:09 +0000 UTC (2 container statuses recorded)
Nov  4 09:34:52.112: INFO: 	Container linkerd-proxy ready: true, restart count 0
Nov  4 09:34:52.112: INFO: 	Container tap ready: true, restart count 0
Nov  4 09:34:52.112: INFO: nginx-6db489d4b7-6xgqq from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.112: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.112: INFO: linkerd-controller-7f457d599-x5dg5 from linkerd started at 2019-10-31 19:06:42 +0000 UTC (3 container statuses recorded)
Nov  4 09:34:52.112: INFO: 	Container destination ready: true, restart count 2
Nov  4 09:34:52.112: INFO: 	Container linkerd-proxy ready: true, restart count 2
Nov  4 09:34:52.112: INFO: 	Container public-api ready: true, restart count 2
Nov  4 09:34:52.113: INFO: nginx-6db489d4b7-hxbjr from default started at 2019-10-31 19:35:17 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.113: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.115: INFO: nginx-6db489d4b7-qlxbl from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.115: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.115: INFO: nginx-6db489d4b7-4bl92 from default started at 2019-10-31 19:35:19 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.115: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.115: INFO: nginx-6db489d4b7-q494r from default started at 2019-11-04 08:59:10 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.115: INFO: 	Container nginx ready: true, restart count 0
Nov  4 09:34:52.115: INFO: coredns-b7f8c8654-nxpz9 from kube-system started at 2019-10-31 19:06:42 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.115: INFO: 	Container coredns ready: true, restart count 2
Nov  4 09:34:52.115: INFO: nginx-6db489d4b7-4pxjk from default started at 2019-10-31 19:35:14 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.115: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.116: INFO: nginx-6db489d4b7-7m8cn from default started at 2019-10-31 19:35:16 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.116: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.116: INFO: nginx-6db489d4b7-5zxqm from default started at 2019-10-31 19:35:20 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.116: INFO: 	Container nginx ready: true, restart count 1
Nov  4 09:34:52.116: INFO: nginx-6db489d4b7-5mzcb from default started at 2019-11-04 08:59:11 +0000 UTC (1 container statuses recorded)
Nov  4 09:34:52.116: INFO: 	Container nginx ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-82312afc-92ed-43a3-bc0a-e8642e945128 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-82312afc-92ed-43a3-bc0a-e8642e945128 off the node k8s-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-82312afc-92ed-43a3-bc0a-e8642e945128
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:39:58.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7163" for this suite.
Nov  4 09:40:08.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:40:08.380: INFO: namespace sched-pred-7163 deletion completed in 10.104958442s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:316.592 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:40:08.381: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6178
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:40:08.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6178" for this suite.
Nov  4 09:40:20.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:40:20.664: INFO: namespace pods-6178 deletion completed in 12.109509898s

• [SLOW TEST:12.283 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:40:20.666: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4155
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:40:31.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4155" for this suite.
Nov  4 09:40:37.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:40:37.962: INFO: namespace resourcequota-4155 deletion completed in 6.098600333s

• [SLOW TEST:17.296 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:40:37.964: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3840
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:40:38.099: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Nov  4 09:40:40.130: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:40:40.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3840" for this suite.
Nov  4 09:40:46.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:40:46.238: INFO: namespace replication-controller-3840 deletion completed in 6.101924872s

• [SLOW TEST:8.275 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:40:46.239: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7657
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:40:59.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7657" for this suite.
Nov  4 09:41:05.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:41:05.562: INFO: namespace resourcequota-7657 deletion completed in 6.101170441s

• [SLOW TEST:19.323 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:41:05.562: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8445
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-cc5301ae-a69f-42e9-98a4-2cce4345eec2
STEP: Creating a pod to test consume configMaps
Nov  4 09:41:05.724: INFO: Waiting up to 5m0s for pod "pod-configmaps-3d3a054b-924d-4331-9995-aa4a668a51a3" in namespace "configmap-8445" to be "success or failure"
Nov  4 09:41:05.730: INFO: Pod "pod-configmaps-3d3a054b-924d-4331-9995-aa4a668a51a3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.306889ms
Nov  4 09:41:07.733: INFO: Pod "pod-configmaps-3d3a054b-924d-4331-9995-aa4a668a51a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009259767s
STEP: Saw pod success
Nov  4 09:41:07.733: INFO: Pod "pod-configmaps-3d3a054b-924d-4331-9995-aa4a668a51a3" satisfied condition "success or failure"
Nov  4 09:41:07.736: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-3d3a054b-924d-4331-9995-aa4a668a51a3 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 09:41:07.766: INFO: Waiting for pod pod-configmaps-3d3a054b-924d-4331-9995-aa4a668a51a3 to disappear
Nov  4 09:41:07.770: INFO: Pod pod-configmaps-3d3a054b-924d-4331-9995-aa4a668a51a3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:41:07.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8445" for this suite.
Nov  4 09:41:13.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:41:13.873: INFO: namespace configmap-8445 deletion completed in 6.100023759s

• [SLOW TEST:8.311 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:41:13.874: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-668
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  4 09:41:18.082: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 09:41:18.089: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 09:41:20.090: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 09:41:20.093: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 09:41:22.090: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 09:41:22.093: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 09:41:24.090: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 09:41:24.093: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 09:41:26.090: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 09:41:26.093: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 09:41:28.090: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 09:41:28.093: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 09:41:30.090: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 09:41:30.093: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 09:41:32.090: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 09:41:32.093: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:41:32.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-668" for this suite.
Nov  4 09:41:44.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:41:44.203: INFO: namespace container-lifecycle-hook-668 deletion completed in 12.099778012s

• [SLOW TEST:30.329 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:41:44.203: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2959
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1104 09:42:14.386523      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  4 09:42:14.386: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:42:14.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2959" for this suite.
Nov  4 09:42:20.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:42:20.479: INFO: namespace gc-2959 deletion completed in 6.089621507s

• [SLOW TEST:36.276 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:42:20.479: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8464
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov  4 09:42:20.630: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8464 /api/v1/namespaces/watch-8464/configmaps/e2e-watch-test-watch-closed 08e75b31-dd76-45bf-a013-1bd4205630a8 525431 0 2019-11-04 09:42:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 09:42:20.630: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8464 /api/v1/namespaces/watch-8464/configmaps/e2e-watch-test-watch-closed 08e75b31-dd76-45bf-a013-1bd4205630a8 525432 0 2019-11-04 09:42:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov  4 09:42:20.646: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8464 /api/v1/namespaces/watch-8464/configmaps/e2e-watch-test-watch-closed 08e75b31-dd76-45bf-a013-1bd4205630a8 525433 0 2019-11-04 09:42:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 09:42:20.648: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8464 /api/v1/namespaces/watch-8464/configmaps/e2e-watch-test-watch-closed 08e75b31-dd76-45bf-a013-1bd4205630a8 525434 0 2019-11-04 09:42:20 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:42:20.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8464" for this suite.
Nov  4 09:42:26.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:42:26.771: INFO: namespace watch-8464 deletion completed in 6.117902989s

• [SLOW TEST:6.292 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:42:26.772: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6784
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6784
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-6784
Nov  4 09:42:26.931: INFO: Found 0 stateful pods, waiting for 1
Nov  4 09:42:36.934: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 09:42:36.957: INFO: Deleting all statefulset in ns statefulset-6784
Nov  4 09:42:36.962: INFO: Scaling statefulset ss to 0
Nov  4 09:42:56.996: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 09:42:56.999: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:42:57.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6784" for this suite.
Nov  4 09:43:03.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:43:03.122: INFO: namespace statefulset-6784 deletion completed in 6.101826433s

• [SLOW TEST:36.351 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:43:03.123: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1721
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 09:43:03.289: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1e9e2a05-166a-497a-8f96-47c29f832fb3" in namespace "downward-api-1721" to be "success or failure"
Nov  4 09:43:03.293: INFO: Pod "downwardapi-volume-1e9e2a05-166a-497a-8f96-47c29f832fb3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.686858ms
Nov  4 09:43:05.296: INFO: Pod "downwardapi-volume-1e9e2a05-166a-497a-8f96-47c29f832fb3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007836512s
STEP: Saw pod success
Nov  4 09:43:05.297: INFO: Pod "downwardapi-volume-1e9e2a05-166a-497a-8f96-47c29f832fb3" satisfied condition "success or failure"
Nov  4 09:43:05.299: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-1e9e2a05-166a-497a-8f96-47c29f832fb3 container client-container: <nil>
STEP: delete the pod
Nov  4 09:43:05.319: INFO: Waiting for pod downwardapi-volume-1e9e2a05-166a-497a-8f96-47c29f832fb3 to disappear
Nov  4 09:43:05.321: INFO: Pod downwardapi-volume-1e9e2a05-166a-497a-8f96-47c29f832fb3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:43:05.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1721" for this suite.
Nov  4 09:43:11.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:43:11.430: INFO: namespace downward-api-1721 deletion completed in 6.104555912s

• [SLOW TEST:8.308 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:43:11.431: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8389
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov  4 09:43:11.605: INFO: Waiting up to 5m0s for pod "pod-e3aae2b0-06c0-4322-888c-ae93eedadc73" in namespace "emptydir-8389" to be "success or failure"
Nov  4 09:43:11.618: INFO: Pod "pod-e3aae2b0-06c0-4322-888c-ae93eedadc73": Phase="Pending", Reason="", readiness=false. Elapsed: 12.615583ms
Nov  4 09:43:13.621: INFO: Pod "pod-e3aae2b0-06c0-4322-888c-ae93eedadc73": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015839568s
STEP: Saw pod success
Nov  4 09:43:13.621: INFO: Pod "pod-e3aae2b0-06c0-4322-888c-ae93eedadc73" satisfied condition "success or failure"
Nov  4 09:43:13.627: INFO: Trying to get logs from node k8s-1 pod pod-e3aae2b0-06c0-4322-888c-ae93eedadc73 container test-container: <nil>
STEP: delete the pod
Nov  4 09:43:13.659: INFO: Waiting for pod pod-e3aae2b0-06c0-4322-888c-ae93eedadc73 to disappear
Nov  4 09:43:13.661: INFO: Pod pod-e3aae2b0-06c0-4322-888c-ae93eedadc73 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:43:13.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8389" for this suite.
Nov  4 09:43:19.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:43:19.767: INFO: namespace emptydir-8389 deletion completed in 6.102344965s

• [SLOW TEST:8.336 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:43:19.767: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8277
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-041fbacf-e41c-4318-8144-0f121480fb9d in namespace container-probe-8277
Nov  4 09:43:21.921: INFO: Started pod liveness-041fbacf-e41c-4318-8144-0f121480fb9d in namespace container-probe-8277
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 09:43:21.924: INFO: Initial restart count of pod liveness-041fbacf-e41c-4318-8144-0f121480fb9d is 0
Nov  4 09:43:35.947: INFO: Restart count of pod container-probe-8277/liveness-041fbacf-e41c-4318-8144-0f121480fb9d is now 1 (14.02302288s elapsed)
Nov  4 09:43:55.978: INFO: Restart count of pod container-probe-8277/liveness-041fbacf-e41c-4318-8144-0f121480fb9d is now 2 (34.054474677s elapsed)
Nov  4 09:44:16.008: INFO: Restart count of pod container-probe-8277/liveness-041fbacf-e41c-4318-8144-0f121480fb9d is now 3 (54.084727441s elapsed)
Nov  4 09:44:36.037: INFO: Restart count of pod container-probe-8277/liveness-041fbacf-e41c-4318-8144-0f121480fb9d is now 4 (1m14.113490398s elapsed)
Nov  4 09:45:38.128: INFO: Restart count of pod container-probe-8277/liveness-041fbacf-e41c-4318-8144-0f121480fb9d is now 5 (2m16.204593913s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:45:38.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8277" for this suite.
Nov  4 09:45:44.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:45:44.284: INFO: namespace container-probe-8277 deletion completed in 6.132456696s

• [SLOW TEST:144.517 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:45:44.284: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3557
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  4 09:45:44.437: INFO: Waiting up to 5m0s for pod "pod-577ef059-9800-4eb3-95a7-09444221f519" in namespace "emptydir-3557" to be "success or failure"
Nov  4 09:45:44.448: INFO: Pod "pod-577ef059-9800-4eb3-95a7-09444221f519": Phase="Pending", Reason="", readiness=false. Elapsed: 10.333557ms
Nov  4 09:45:46.450: INFO: Pod "pod-577ef059-9800-4eb3-95a7-09444221f519": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013262012s
STEP: Saw pod success
Nov  4 09:45:46.451: INFO: Pod "pod-577ef059-9800-4eb3-95a7-09444221f519" satisfied condition "success or failure"
Nov  4 09:45:46.454: INFO: Trying to get logs from node k8s-1 pod pod-577ef059-9800-4eb3-95a7-09444221f519 container test-container: <nil>
STEP: delete the pod
Nov  4 09:45:46.487: INFO: Waiting for pod pod-577ef059-9800-4eb3-95a7-09444221f519 to disappear
Nov  4 09:45:46.502: INFO: Pod pod-577ef059-9800-4eb3-95a7-09444221f519 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:45:46.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3557" for this suite.
Nov  4 09:45:52.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:45:52.617: INFO: namespace emptydir-3557 deletion completed in 6.1113468s

• [SLOW TEST:8.333 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:45:52.619: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4027
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:46:52.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4027" for this suite.
Nov  4 09:47:04.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:47:04.879: INFO: namespace container-probe-4027 deletion completed in 12.099033862s

• [SLOW TEST:72.260 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:47:04.879: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2000
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  4 09:47:05.041: INFO: Waiting up to 5m0s for pod "pod-b41150ef-6cf8-4f1b-a556-1730b5b403a1" in namespace "emptydir-2000" to be "success or failure"
Nov  4 09:47:05.044: INFO: Pod "pod-b41150ef-6cf8-4f1b-a556-1730b5b403a1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.049542ms
Nov  4 09:47:07.048: INFO: Pod "pod-b41150ef-6cf8-4f1b-a556-1730b5b403a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00647152s
STEP: Saw pod success
Nov  4 09:47:07.048: INFO: Pod "pod-b41150ef-6cf8-4f1b-a556-1730b5b403a1" satisfied condition "success or failure"
Nov  4 09:47:07.051: INFO: Trying to get logs from node k8s-1 pod pod-b41150ef-6cf8-4f1b-a556-1730b5b403a1 container test-container: <nil>
STEP: delete the pod
Nov  4 09:47:07.072: INFO: Waiting for pod pod-b41150ef-6cf8-4f1b-a556-1730b5b403a1 to disappear
Nov  4 09:47:07.077: INFO: Pod pod-b41150ef-6cf8-4f1b-a556-1730b5b403a1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:47:07.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2000" for this suite.
Nov  4 09:47:13.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:47:13.181: INFO: namespace emptydir-2000 deletion completed in 6.100910197s

• [SLOW TEST:8.302 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:47:13.183: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7113
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:47:13.322: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Nov  4 09:47:22.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-7113 create -f -'
Nov  4 09:47:22.812: INFO: stderr: ""
Nov  4 09:47:22.812: INFO: stdout: "e2e-test-crd-publish-openapi-2521-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov  4 09:47:22.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-7113 delete e2e-test-crd-publish-openapi-2521-crds test-foo'
Nov  4 09:47:23.032: INFO: stderr: ""
Nov  4 09:47:23.032: INFO: stdout: "e2e-test-crd-publish-openapi-2521-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Nov  4 09:47:23.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-7113 apply -f -'
Nov  4 09:47:23.300: INFO: stderr: ""
Nov  4 09:47:23.300: INFO: stdout: "e2e-test-crd-publish-openapi-2521-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov  4 09:47:23.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-7113 delete e2e-test-crd-publish-openapi-2521-crds test-foo'
Nov  4 09:47:23.388: INFO: stderr: ""
Nov  4 09:47:23.388: INFO: stdout: "e2e-test-crd-publish-openapi-2521-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Nov  4 09:47:23.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-7113 create -f -'
Nov  4 09:47:23.592: INFO: rc: 1
Nov  4 09:47:23.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-7113 apply -f -'
Nov  4 09:47:23.818: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Nov  4 09:47:23.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-7113 create -f -'
Nov  4 09:47:24.011: INFO: rc: 1
Nov  4 09:47:24.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-7113 apply -f -'
Nov  4 09:47:24.230: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Nov  4 09:47:24.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 explain e2e-test-crd-publish-openapi-2521-crds'
Nov  4 09:47:24.437: INFO: stderr: ""
Nov  4 09:47:24.437: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2521-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Nov  4 09:47:24.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 explain e2e-test-crd-publish-openapi-2521-crds.metadata'
Nov  4 09:47:24.654: INFO: stderr: ""
Nov  4 09:47:24.654: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2521-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Nov  4 09:47:24.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 explain e2e-test-crd-publish-openapi-2521-crds.spec'
Nov  4 09:47:24.893: INFO: stderr: ""
Nov  4 09:47:24.893: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2521-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Nov  4 09:47:24.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 explain e2e-test-crd-publish-openapi-2521-crds.spec.bars'
Nov  4 09:47:25.127: INFO: stderr: ""
Nov  4 09:47:25.127: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2521-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Nov  4 09:47:25.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 explain e2e-test-crd-publish-openapi-2521-crds.spec.bars2'
Nov  4 09:47:25.292: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:47:29.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7113" for this suite.
Nov  4 09:47:35.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:47:35.457: INFO: namespace crd-publish-openapi-7113 deletion completed in 6.096195642s

• [SLOW TEST:22.274 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:47:35.457: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6904
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6904
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  4 09:47:35.604: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  4 09:47:59.710: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.33.1.78 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6904 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:47:59.710: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:48:00.864: INFO: Found all expected endpoints: [netserver-0]
Nov  4 09:48:00.868: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.33.2.202 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6904 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:48:00.868: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:48:02.012: INFO: Found all expected endpoints: [netserver-1]
Nov  4 09:48:02.016: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.33.0.70 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6904 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 09:48:02.016: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 09:48:03.150: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:48:03.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6904" for this suite.
Nov  4 09:48:15.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:48:15.258: INFO: namespace pod-network-test-6904 deletion completed in 12.103262398s

• [SLOW TEST:39.800 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:48:15.258: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6812
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6812
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-6812
I1104 09:48:15.447019      19 runners.go:184] Created replication controller with name: externalname-service, namespace: services-6812, replica count: 2
Nov  4 09:48:18.497: INFO: Creating new exec pod
I1104 09:48:18.497399      19 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 09:48:21.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=services-6812 execpodrzbvp -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov  4 09:48:21.782: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov  4 09:48:21.782: INFO: stdout: ""
Nov  4 09:48:21.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=services-6812 execpodrzbvp -- /bin/sh -x -c nc -zv -t -w 2 10.32.0.251 80'
Nov  4 09:48:22.028: INFO: stderr: "+ nc -zv -t -w 2 10.32.0.251 80\nConnection to 10.32.0.251 80 port [tcp/http] succeeded!\n"
Nov  4 09:48:22.028: INFO: stdout: ""
Nov  4 09:48:22.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=services-6812 execpodrzbvp -- /bin/sh -x -c nc -zv -t -w 2 10.20.20.4 32496'
Nov  4 09:48:22.265: INFO: stderr: "+ nc -zv -t -w 2 10.20.20.4 32496\nConnection to 10.20.20.4 32496 port [tcp/32496] succeeded!\n"
Nov  4 09:48:22.265: INFO: stdout: ""
Nov  4 09:48:22.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=services-6812 execpodrzbvp -- /bin/sh -x -c nc -zv -t -w 2 10.20.20.5 32496'
Nov  4 09:48:22.496: INFO: stderr: "+ nc -zv -t -w 2 10.20.20.5 32496\nConnection to 10.20.20.5 32496 port [tcp/32496] succeeded!\n"
Nov  4 09:48:22.496: INFO: stdout: ""
Nov  4 09:48:22.497: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:48:22.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6812" for this suite.
Nov  4 09:48:28.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:48:28.621: INFO: namespace services-6812 deletion completed in 6.090950336s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.363 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:48:28.622: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5573
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-5df1b6e2-c20e-4776-969a-606dce682da8
STEP: Creating a pod to test consume configMaps
Nov  4 09:48:28.790: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-27394440-14ef-4507-9eb3-305b3cc8a9cb" in namespace "projected-5573" to be "success or failure"
Nov  4 09:48:28.793: INFO: Pod "pod-projected-configmaps-27394440-14ef-4507-9eb3-305b3cc8a9cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.484374ms
Nov  4 09:48:30.796: INFO: Pod "pod-projected-configmaps-27394440-14ef-4507-9eb3-305b3cc8a9cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005433744s
STEP: Saw pod success
Nov  4 09:48:30.796: INFO: Pod "pod-projected-configmaps-27394440-14ef-4507-9eb3-305b3cc8a9cb" satisfied condition "success or failure"
Nov  4 09:48:30.798: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-27394440-14ef-4507-9eb3-305b3cc8a9cb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 09:48:30.824: INFO: Waiting for pod pod-projected-configmaps-27394440-14ef-4507-9eb3-305b3cc8a9cb to disappear
Nov  4 09:48:30.830: INFO: Pod pod-projected-configmaps-27394440-14ef-4507-9eb3-305b3cc8a9cb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:48:30.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5573" for this suite.
Nov  4 09:48:36.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:48:36.926: INFO: namespace projected-5573 deletion completed in 6.093549295s

• [SLOW TEST:8.305 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:48:36.927: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8190
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-8190
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8190
STEP: creating replication controller externalsvc in namespace services-8190
I1104 09:48:37.106313      19 runners.go:184] Created replication controller with name: externalsvc, namespace: services-8190, replica count: 2
I1104 09:48:40.156779      19 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Nov  4 09:48:40.183: INFO: Creating new exec pod
Nov  4 09:48:42.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=services-8190 execpodbg5rk -- /bin/sh -x -c nslookup nodeport-service'
Nov  4 09:48:42.437: INFO: stderr: "+ nslookup nodeport-service\n"
Nov  4 09:48:42.437: INFO: stdout: "Server:\t\t10.32.0.10\nAddress:\t10.32.0.10#53\n\nnodeport-service.services-8190.svc.cluster.local\tcanonical name = externalsvc.services-8190.svc.cluster.local.\nName:\texternalsvc.services-8190.svc.cluster.local\nAddress: 10.32.0.144\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8190, will wait for the garbage collector to delete the pods
Nov  4 09:48:42.499: INFO: Deleting ReplicationController externalsvc took: 7.189855ms
Nov  4 09:48:43.000: INFO: Terminating ReplicationController externalsvc pods took: 500.219221ms
Nov  4 09:48:51.825: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:48:51.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8190" for this suite.
Nov  4 09:48:59.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:48:59.943: INFO: namespace services-8190 deletion completed in 8.100163635s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:23.016 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:48:59.943: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1551
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:49:00.095: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov  4 09:49:05.098: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  4 09:49:05.098: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov  4 09:49:07.102: INFO: Creating deployment "test-rollover-deployment"
Nov  4 09:49:07.111: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov  4 09:49:09.117: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov  4 09:49:09.122: INFO: Ensure that both replica sets have 1 created replica
Nov  4 09:49:09.127: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov  4 09:49:09.137: INFO: Updating deployment test-rollover-deployment
Nov  4 09:49:09.137: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov  4 09:49:11.144: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov  4 09:49:11.149: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov  4 09:49:11.154: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 09:49:11.154: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457750, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 09:49:13.161: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 09:49:13.161: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457750, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 09:49:15.160: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 09:49:15.160: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457750, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 09:49:17.160: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 09:49:17.160: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457750, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 09:49:19.160: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 09:49:19.160: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457750, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457747, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 09:49:21.160: INFO: 
Nov  4 09:49:21.160: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 09:49:21.170: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-1551 /apis/apps/v1/namespaces/deployment-1551/deployments/test-rollover-deployment 3d7b5d95-951b-453b-841a-33735bd997b7 526803 2 2019-11-04 09:49:07 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002ae45d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-11-04 09:49:07 +0000 UTC,LastTransitionTime:2019-11-04 09:49:07 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-11-04 09:49:20 +0000 UTC,LastTransitionTime:2019-11-04 09:49:07 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  4 09:49:21.173: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-1551 /apis/apps/v1/namespaces/deployment-1551/replicasets/test-rollover-deployment-7d7dc6548c be6a7736-69d0-475c-a3b9-36a1b6a9e497 526792 2 2019-11-04 09:49:09 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 3d7b5d95-951b-453b-841a-33735bd997b7 0xc002ae4d67 0xc002ae4d68}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002ae4e58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  4 09:49:21.173: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov  4 09:49:21.173: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-1551 /apis/apps/v1/namespaces/deployment-1551/replicasets/test-rollover-controller edca68c7-e38b-484c-9f48-d5a0e1c17e61 526802 2 2019-11-04 09:49:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 3d7b5d95-951b-453b-841a-33735bd997b7 0xc002ae4c47 0xc002ae4c48}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002ae4cd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 09:49:21.173: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-1551 /apis/apps/v1/namespaces/deployment-1551/replicasets/test-rollover-deployment-f6c94f66c dca808d5-a017-4175-9948-9c1792d0f11a 526758 2 2019-11-04 09:49:07 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 3d7b5d95-951b-453b-841a-33735bd997b7 0xc002ae4f40 0xc002ae4f41}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002ae5068 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 09:49:21.177: INFO: Pod "test-rollover-deployment-7d7dc6548c-z4vdn" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-z4vdn test-rollover-deployment-7d7dc6548c- deployment-1551 /api/v1/namespaces/deployment-1551/pods/test-rollover-deployment-7d7dc6548c-z4vdn f2dffbf2-686c-4e5e-af96-dafdb30aa82a 526771 0 2019-11-04 09:49:09 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c be6a7736-69d0-475c-a3b9-36a1b6a9e497 0xc002ae5797 0xc002ae5798}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hq7ht,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hq7ht,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hq7ht,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:49:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:49:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:49:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:49:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.2.212,StartTime:2019-11-04 09:49:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 09:49:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://3b79b0e39db96b23e98fd34decb66ff711ce181c8439e14ad5a6ebf2e296e828,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.212,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:49:21.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1551" for this suite.
Nov  4 09:49:27.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:49:27.277: INFO: namespace deployment-1551 deletion completed in 6.095096919s

• [SLOW TEST:27.333 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:49:27.277: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6799
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  4 09:49:27.473: INFO: Number of nodes with available pods: 0
Nov  4 09:49:27.473: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 09:49:28.479: INFO: Number of nodes with available pods: 0
Nov  4 09:49:28.479: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 09:49:29.482: INFO: Number of nodes with available pods: 2
Nov  4 09:49:29.482: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 09:49:30.479: INFO: Number of nodes with available pods: 3
Nov  4 09:49:30.479: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov  4 09:49:30.501: INFO: Number of nodes with available pods: 2
Nov  4 09:49:30.501: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 09:49:31.509: INFO: Number of nodes with available pods: 2
Nov  4 09:49:31.509: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 09:49:32.508: INFO: Number of nodes with available pods: 2
Nov  4 09:49:32.508: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 09:49:33.509: INFO: Number of nodes with available pods: 2
Nov  4 09:49:33.509: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 09:49:34.509: INFO: Number of nodes with available pods: 2
Nov  4 09:49:34.509: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 09:49:35.509: INFO: Number of nodes with available pods: 2
Nov  4 09:49:35.509: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 09:49:36.509: INFO: Number of nodes with available pods: 2
Nov  4 09:49:36.509: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 09:49:37.510: INFO: Number of nodes with available pods: 2
Nov  4 09:49:37.510: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 09:49:38.509: INFO: Number of nodes with available pods: 2
Nov  4 09:49:38.509: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 09:49:39.510: INFO: Number of nodes with available pods: 2
Nov  4 09:49:39.510: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 09:49:40.509: INFO: Number of nodes with available pods: 2
Nov  4 09:49:40.510: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 09:49:41.510: INFO: Number of nodes with available pods: 2
Nov  4 09:49:41.510: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 09:49:42.508: INFO: Number of nodes with available pods: 2
Nov  4 09:49:42.509: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 09:49:43.509: INFO: Number of nodes with available pods: 3
Nov  4 09:49:43.509: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6799, will wait for the garbage collector to delete the pods
Nov  4 09:49:43.575: INFO: Deleting DaemonSet.extensions daemon-set took: 8.966358ms
Nov  4 09:49:44.075: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.233491ms
Nov  4 09:49:51.777: INFO: Number of nodes with available pods: 0
Nov  4 09:49:51.777: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 09:49:51.780: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6799/daemonsets","resourceVersion":"526970"},"items":null}

Nov  4 09:49:51.783: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6799/pods","resourceVersion":"526970"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:49:51.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6799" for this suite.
Nov  4 09:49:57.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:49:57.908: INFO: namespace daemonsets-6799 deletion completed in 6.104259506s

• [SLOW TEST:30.631 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:49:57.909: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1358
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-52052c8a-32d4-4a00-8d41-31eda7a678f9
STEP: Creating a pod to test consume configMaps
Nov  4 09:49:58.062: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-394a3afd-089c-4ce7-9ca3-524d550e70ac" in namespace "projected-1358" to be "success or failure"
Nov  4 09:49:58.064: INFO: Pod "pod-projected-configmaps-394a3afd-089c-4ce7-9ca3-524d550e70ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.190681ms
Nov  4 09:50:00.070: INFO: Pod "pod-projected-configmaps-394a3afd-089c-4ce7-9ca3-524d550e70ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007548741s
STEP: Saw pod success
Nov  4 09:50:00.070: INFO: Pod "pod-projected-configmaps-394a3afd-089c-4ce7-9ca3-524d550e70ac" satisfied condition "success or failure"
Nov  4 09:50:00.073: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-394a3afd-089c-4ce7-9ca3-524d550e70ac container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 09:50:00.097: INFO: Waiting for pod pod-projected-configmaps-394a3afd-089c-4ce7-9ca3-524d550e70ac to disappear
Nov  4 09:50:00.103: INFO: Pod pod-projected-configmaps-394a3afd-089c-4ce7-9ca3-524d550e70ac no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:50:00.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1358" for this suite.
Nov  4 09:50:06.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:50:06.211: INFO: namespace projected-1358 deletion completed in 6.104483316s

• [SLOW TEST:8.302 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:50:06.212: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3960
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:50:07.230: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 09:50:09.239: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457807, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457807, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457807, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708457807, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:50:12.250: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:50:24.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3960" for this suite.
Nov  4 09:50:30.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:50:30.475: INFO: namespace webhook-3960 deletion completed in 6.094589655s
STEP: Destroying namespace "webhook-3960-markers" for this suite.
Nov  4 09:50:36.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:50:36.581: INFO: namespace webhook-3960-markers deletion completed in 6.105742246s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.384 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:50:36.596: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3496
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:50:36.732: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  4 09:50:45.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-3496 create -f -'
Nov  4 09:50:45.659: INFO: stderr: ""
Nov  4 09:50:45.659: INFO: stdout: "e2e-test-crd-publish-openapi-2560-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov  4 09:50:45.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-3496 delete e2e-test-crd-publish-openapi-2560-crds test-cr'
Nov  4 09:50:45.794: INFO: stderr: ""
Nov  4 09:50:45.794: INFO: stdout: "e2e-test-crd-publish-openapi-2560-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Nov  4 09:50:45.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-3496 apply -f -'
Nov  4 09:50:45.979: INFO: stderr: ""
Nov  4 09:50:45.979: INFO: stdout: "e2e-test-crd-publish-openapi-2560-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov  4 09:50:45.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=crd-publish-openapi-3496 delete e2e-test-crd-publish-openapi-2560-crds test-cr'
Nov  4 09:50:46.111: INFO: stderr: ""
Nov  4 09:50:46.111: INFO: stdout: "e2e-test-crd-publish-openapi-2560-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov  4 09:50:46.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 explain e2e-test-crd-publish-openapi-2560-crds'
Nov  4 09:50:46.324: INFO: stderr: ""
Nov  4 09:50:46.324: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2560-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:50:49.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3496" for this suite.
Nov  4 09:50:55.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:50:56.655: INFO: namespace crd-publish-openapi-3496 deletion completed in 6.779326526s

• [SLOW TEST:20.059 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:50:56.656: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5311
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:50:56.824: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov  4 09:50:56.833: INFO: Number of nodes with available pods: 0
Nov  4 09:50:56.833: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov  4 09:50:56.854: INFO: Number of nodes with available pods: 0
Nov  4 09:50:56.854: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 09:50:57.857: INFO: Number of nodes with available pods: 1
Nov  4 09:50:57.857: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov  4 09:50:57.875: INFO: Number of nodes with available pods: 1
Nov  4 09:50:57.875: INFO: Number of running nodes: 0, number of available pods: 1
Nov  4 09:50:58.878: INFO: Number of nodes with available pods: 0
Nov  4 09:50:58.878: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov  4 09:50:58.892: INFO: Number of nodes with available pods: 0
Nov  4 09:50:58.892: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 09:50:59.895: INFO: Number of nodes with available pods: 0
Nov  4 09:50:59.895: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 09:51:00.896: INFO: Number of nodes with available pods: 0
Nov  4 09:51:00.896: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 09:51:01.895: INFO: Number of nodes with available pods: 0
Nov  4 09:51:01.895: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 09:51:02.895: INFO: Number of nodes with available pods: 0
Nov  4 09:51:02.895: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 09:51:03.895: INFO: Number of nodes with available pods: 1
Nov  4 09:51:03.895: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5311, will wait for the garbage collector to delete the pods
Nov  4 09:51:03.961: INFO: Deleting DaemonSet.extensions daemon-set took: 8.544163ms
Nov  4 09:51:04.461: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.159907ms
Nov  4 09:51:07.770: INFO: Number of nodes with available pods: 0
Nov  4 09:51:07.770: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 09:51:07.772: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5311/daemonsets","resourceVersion":"527308"},"items":null}

Nov  4 09:51:07.775: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5311/pods","resourceVersion":"527308"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:51:07.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5311" for this suite.
Nov  4 09:51:13.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:51:13.895: INFO: namespace daemonsets-5311 deletion completed in 6.091916507s

• [SLOW TEST:17.239 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:51:13.896: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2920
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  4 09:51:16.570: INFO: Successfully updated pod "labelsupdated95cce27-0a9a-4902-86e2-ca96dbea8cf7"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:51:20.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2920" for this suite.
Nov  4 09:51:32.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:51:32.693: INFO: namespace downward-api-2920 deletion completed in 12.099382383s

• [SLOW TEST:18.797 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:51:32.693: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9695
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Nov  4 09:51:32.832: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-416373942 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:51:32.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9695" for this suite.
Nov  4 09:51:38.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:51:39.062: INFO: namespace kubectl-9695 deletion completed in 6.160196202s

• [SLOW TEST:6.369 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:51:39.063: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9595
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Nov  4 09:51:39.199: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Nov  4 09:51:39.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 create -f - --namespace=kubectl-9595'
Nov  4 09:51:39.431: INFO: stderr: ""
Nov  4 09:51:39.431: INFO: stdout: "service/redis-slave created\n"
Nov  4 09:51:39.431: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Nov  4 09:51:39.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 create -f - --namespace=kubectl-9595'
Nov  4 09:51:39.715: INFO: stderr: ""
Nov  4 09:51:39.715: INFO: stdout: "service/redis-master created\n"
Nov  4 09:51:39.715: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov  4 09:51:39.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 create -f - --namespace=kubectl-9595'
Nov  4 09:51:40.005: INFO: stderr: ""
Nov  4 09:51:40.005: INFO: stdout: "service/frontend created\n"
Nov  4 09:51:40.005: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Nov  4 09:51:40.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 create -f - --namespace=kubectl-9595'
Nov  4 09:51:40.339: INFO: stderr: ""
Nov  4 09:51:40.339: INFO: stdout: "deployment.apps/frontend created\n"
Nov  4 09:51:40.339: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov  4 09:51:40.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 create -f - --namespace=kubectl-9595'
Nov  4 09:51:40.702: INFO: stderr: ""
Nov  4 09:51:40.702: INFO: stdout: "deployment.apps/redis-master created\n"
Nov  4 09:51:40.703: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Nov  4 09:51:40.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 create -f - --namespace=kubectl-9595'
Nov  4 09:51:41.012: INFO: stderr: ""
Nov  4 09:51:41.012: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Nov  4 09:51:41.012: INFO: Waiting for all frontend pods to be Running.
Nov  4 09:52:06.063: INFO: Waiting for frontend to serve content.
Nov  4 09:52:06.077: INFO: Trying to add a new entry to the guestbook.
Nov  4 09:52:06.086: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Nov  4 09:52:06.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete --grace-period=0 --force -f - --namespace=kubectl-9595'
Nov  4 09:52:06.198: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 09:52:06.198: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 09:52:06.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete --grace-period=0 --force -f - --namespace=kubectl-9595'
Nov  4 09:52:06.337: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 09:52:06.337: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 09:52:06.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete --grace-period=0 --force -f - --namespace=kubectl-9595'
Nov  4 09:52:06.555: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 09:52:06.555: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 09:52:06.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete --grace-period=0 --force -f - --namespace=kubectl-9595'
Nov  4 09:52:06.647: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 09:52:06.647: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 09:52:06.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete --grace-period=0 --force -f - --namespace=kubectl-9595'
Nov  4 09:52:06.731: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 09:52:06.732: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 09:52:06.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete --grace-period=0 --force -f - --namespace=kubectl-9595'
Nov  4 09:52:06.812: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 09:52:06.812: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:52:06.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9595" for this suite.
Nov  4 09:52:12.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:52:12.912: INFO: namespace kubectl-9595 deletion completed in 6.096671419s

• [SLOW TEST:33.849 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:52:12.913: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1045
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:52:29.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1045" for this suite.
Nov  4 09:52:35.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:52:35.271: INFO: namespace resourcequota-1045 deletion completed in 6.103523031s

• [SLOW TEST:22.358 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:52:35.272: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7346
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 09:52:35.430: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d81fd4f5-0d29-44d3-b23f-efc35691b588" in namespace "projected-7346" to be "success or failure"
Nov  4 09:52:35.433: INFO: Pod "downwardapi-volume-d81fd4f5-0d29-44d3-b23f-efc35691b588": Phase="Pending", Reason="", readiness=false. Elapsed: 3.546252ms
Nov  4 09:52:37.436: INFO: Pod "downwardapi-volume-d81fd4f5-0d29-44d3-b23f-efc35691b588": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006226093s
STEP: Saw pod success
Nov  4 09:52:37.436: INFO: Pod "downwardapi-volume-d81fd4f5-0d29-44d3-b23f-efc35691b588" satisfied condition "success or failure"
Nov  4 09:52:37.439: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-d81fd4f5-0d29-44d3-b23f-efc35691b588 container client-container: <nil>
STEP: delete the pod
Nov  4 09:52:37.459: INFO: Waiting for pod downwardapi-volume-d81fd4f5-0d29-44d3-b23f-efc35691b588 to disappear
Nov  4 09:52:37.464: INFO: Pod downwardapi-volume-d81fd4f5-0d29-44d3-b23f-efc35691b588 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:52:37.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7346" for this suite.
Nov  4 09:52:43.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:52:43.588: INFO: namespace projected-7346 deletion completed in 6.12069809s

• [SLOW TEST:8.316 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:52:43.589: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4421
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4421
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4421
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4421
Nov  4 09:52:43.753: INFO: Found 0 stateful pods, waiting for 1
Nov  4 09:52:53.757: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov  4 09:52:53.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-4421 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 09:52:53.992: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 09:52:53.992: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 09:52:53.992: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 09:52:53.995: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  4 09:53:03.999: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 09:53:03.999: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 09:53:04.012: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999914s
Nov  4 09:53:05.015: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.99597725s
Nov  4 09:53:06.019: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.9924811s
Nov  4 09:53:07.022: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.989195719s
Nov  4 09:53:08.026: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.985911917s
Nov  4 09:53:09.030: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.982195044s
Nov  4 09:53:10.034: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.977393479s
Nov  4 09:53:11.037: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.973931112s
Nov  4 09:53:12.041: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.970533885s
Nov  4 09:53:13.044: INFO: Verifying statefulset ss doesn't scale past 1 for another 967.088136ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4421
Nov  4 09:53:14.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-4421 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 09:53:14.294: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 09:53:14.294: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 09:53:14.295: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 09:53:14.298: INFO: Found 1 stateful pods, waiting for 3
Nov  4 09:53:24.302: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 09:53:24.302: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 09:53:24.302: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov  4 09:53:24.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-4421 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 09:53:24.526: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 09:53:24.526: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 09:53:24.526: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 09:53:24.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-4421 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 09:53:24.777: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 09:53:24.777: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 09:53:24.777: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 09:53:24.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-4421 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 09:53:25.050: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 09:53:25.050: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 09:53:25.050: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 09:53:25.050: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 09:53:25.054: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov  4 09:53:35.060: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 09:53:35.060: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 09:53:35.060: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 09:53:35.072: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999269s
Nov  4 09:53:36.076: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996378309s
Nov  4 09:53:37.080: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992225814s
Nov  4 09:53:38.084: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987971582s
Nov  4 09:53:39.098: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984355143s
Nov  4 09:53:40.103: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.969997539s
Nov  4 09:53:41.106: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.965210091s
Nov  4 09:53:42.111: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96179452s
Nov  4 09:53:43.115: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.956939793s
Nov  4 09:53:44.119: INFO: Verifying statefulset ss doesn't scale past 3 for another 953.111499ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4421
Nov  4 09:53:45.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-4421 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 09:53:45.397: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 09:53:45.397: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 09:53:45.397: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 09:53:45.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-4421 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 09:53:45.630: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 09:53:45.631: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 09:53:45.631: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 09:53:45.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-4421 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 09:53:45.990: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 09:53:45.990: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 09:53:45.990: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 09:53:45.990: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 09:54:16.003: INFO: Deleting all statefulset in ns statefulset-4421
Nov  4 09:54:16.007: INFO: Scaling statefulset ss to 0
Nov  4 09:54:16.015: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 09:54:16.018: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:54:16.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4421" for this suite.
Nov  4 09:54:22.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:54:22.151: INFO: namespace statefulset-4421 deletion completed in 6.114992682s

• [SLOW TEST:98.563 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:54:22.152: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6955
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Nov  4 09:54:22.312: INFO: Waiting up to 5m0s for pod "client-containers-ab2bcdd2-7315-4599-86d8-647bd951ff41" in namespace "containers-6955" to be "success or failure"
Nov  4 09:54:22.316: INFO: Pod "client-containers-ab2bcdd2-7315-4599-86d8-647bd951ff41": Phase="Pending", Reason="", readiness=false. Elapsed: 3.440729ms
Nov  4 09:54:24.319: INFO: Pod "client-containers-ab2bcdd2-7315-4599-86d8-647bd951ff41": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006783792s
STEP: Saw pod success
Nov  4 09:54:24.319: INFO: Pod "client-containers-ab2bcdd2-7315-4599-86d8-647bd951ff41" satisfied condition "success or failure"
Nov  4 09:54:24.322: INFO: Trying to get logs from node k8s-1 pod client-containers-ab2bcdd2-7315-4599-86d8-647bd951ff41 container test-container: <nil>
STEP: delete the pod
Nov  4 09:54:24.349: INFO: Waiting for pod client-containers-ab2bcdd2-7315-4599-86d8-647bd951ff41 to disappear
Nov  4 09:54:24.354: INFO: Pod client-containers-ab2bcdd2-7315-4599-86d8-647bd951ff41 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:54:24.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6955" for this suite.
Nov  4 09:54:30.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:54:30.467: INFO: namespace containers-6955 deletion completed in 6.110212907s

• [SLOW TEST:8.315 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:54:30.468: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3376
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:54:31.078: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:54:34.095: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
Nov  4 09:54:34.115: INFO: Waiting for webhook configuration to be ready...
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:54:34.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3376" for this suite.
Nov  4 09:54:40.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:54:40.372: INFO: namespace webhook-3376 deletion completed in 6.10911737s
STEP: Destroying namespace "webhook-3376-markers" for this suite.
Nov  4 09:54:46.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:54:46.466: INFO: namespace webhook-3376-markers deletion completed in 6.094209532s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.012 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:54:46.480: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2677
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Nov  4 09:54:48.657: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-416373942 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov  4 09:54:53.739: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:54:53.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2677" for this suite.
Nov  4 09:54:59.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:54:59.855: INFO: namespace pods-2677 deletion completed in 6.10562336s

• [SLOW TEST:13.375 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:54:59.855: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4026
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  4 09:55:04.057: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  4 09:55:04.062: INFO: Pod pod-with-poststart-http-hook still exists
Nov  4 09:55:06.062: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  4 09:55:06.066: INFO: Pod pod-with-poststart-http-hook still exists
Nov  4 09:55:08.062: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  4 09:55:08.066: INFO: Pod pod-with-poststart-http-hook still exists
Nov  4 09:55:10.062: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  4 09:55:10.066: INFO: Pod pod-with-poststart-http-hook still exists
Nov  4 09:55:12.063: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  4 09:55:12.066: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:55:12.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4026" for this suite.
Nov  4 09:55:24.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:55:24.163: INFO: namespace container-lifecycle-hook-4026 deletion completed in 12.093947798s

• [SLOW TEST:24.308 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:55:24.165: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1260
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-282b64dc-7484-4ec2-86a8-ec9f2bfcfd09 in namespace container-probe-1260
Nov  4 09:55:26.319: INFO: Started pod liveness-282b64dc-7484-4ec2-86a8-ec9f2bfcfd09 in namespace container-probe-1260
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 09:55:26.322: INFO: Initial restart count of pod liveness-282b64dc-7484-4ec2-86a8-ec9f2bfcfd09 is 0
Nov  4 09:55:42.352: INFO: Restart count of pod container-probe-1260/liveness-282b64dc-7484-4ec2-86a8-ec9f2bfcfd09 is now 1 (16.029689489s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:55:42.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1260" for this suite.
Nov  4 09:55:48.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:55:48.476: INFO: namespace container-probe-1260 deletion completed in 6.101410987s

• [SLOW TEST:24.312 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:55:48.477: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5587
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Nov  4 09:55:48.623: INFO: Pod name pod-release: Found 0 pods out of 1
Nov  4 09:55:53.626: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:55:53.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5587" for this suite.
Nov  4 09:55:59.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:55:59.797: INFO: namespace replication-controller-5587 deletion completed in 6.125783149s

• [SLOW TEST:11.320 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:55:59.798: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7977
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7977.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7977.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7977.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7977.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7977.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7977.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7977.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7977.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7977.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7977.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 09:56:03.981: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local from pod dns-7977/dns-test-74adfa10-4022-4863-aec9-30d8d544133a: the server could not find the requested resource (get pods dns-test-74adfa10-4022-4863-aec9-30d8d544133a)
Nov  4 09:56:03.984: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local from pod dns-7977/dns-test-74adfa10-4022-4863-aec9-30d8d544133a: the server could not find the requested resource (get pods dns-test-74adfa10-4022-4863-aec9-30d8d544133a)
Nov  4 09:56:03.987: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7977.svc.cluster.local from pod dns-7977/dns-test-74adfa10-4022-4863-aec9-30d8d544133a: the server could not find the requested resource (get pods dns-test-74adfa10-4022-4863-aec9-30d8d544133a)
Nov  4 09:56:03.989: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7977.svc.cluster.local from pod dns-7977/dns-test-74adfa10-4022-4863-aec9-30d8d544133a: the server could not find the requested resource (get pods dns-test-74adfa10-4022-4863-aec9-30d8d544133a)
Nov  4 09:56:03.998: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local from pod dns-7977/dns-test-74adfa10-4022-4863-aec9-30d8d544133a: the server could not find the requested resource (get pods dns-test-74adfa10-4022-4863-aec9-30d8d544133a)
Nov  4 09:56:04.001: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local from pod dns-7977/dns-test-74adfa10-4022-4863-aec9-30d8d544133a: the server could not find the requested resource (get pods dns-test-74adfa10-4022-4863-aec9-30d8d544133a)
Nov  4 09:56:04.003: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7977.svc.cluster.local from pod dns-7977/dns-test-74adfa10-4022-4863-aec9-30d8d544133a: the server could not find the requested resource (get pods dns-test-74adfa10-4022-4863-aec9-30d8d544133a)
Nov  4 09:56:04.006: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7977.svc.cluster.local from pod dns-7977/dns-test-74adfa10-4022-4863-aec9-30d8d544133a: the server could not find the requested resource (get pods dns-test-74adfa10-4022-4863-aec9-30d8d544133a)
Nov  4 09:56:04.013: INFO: Lookups using dns-7977/dns-test-74adfa10-4022-4863-aec9-30d8d544133a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7977.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7977.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7977.svc.cluster.local jessie_udp@dns-test-service-2.dns-7977.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7977.svc.cluster.local]

Nov  4 09:56:09.059: INFO: DNS probes using dns-7977/dns-test-74adfa10-4022-4863-aec9-30d8d544133a succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:56:09.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7977" for this suite.
Nov  4 09:56:15.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:56:15.234: INFO: namespace dns-7977 deletion completed in 6.107885495s

• [SLOW TEST:15.436 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:56:15.236: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5518
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 09:56:15.392: INFO: Waiting up to 5m0s for pod "downwardapi-volume-646bfa52-7e1e-49b7-808c-434e404121f9" in namespace "projected-5518" to be "success or failure"
Nov  4 09:56:15.395: INFO: Pod "downwardapi-volume-646bfa52-7e1e-49b7-808c-434e404121f9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.138931ms
Nov  4 09:56:17.398: INFO: Pod "downwardapi-volume-646bfa52-7e1e-49b7-808c-434e404121f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006167317s
STEP: Saw pod success
Nov  4 09:56:17.399: INFO: Pod "downwardapi-volume-646bfa52-7e1e-49b7-808c-434e404121f9" satisfied condition "success or failure"
Nov  4 09:56:17.401: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-646bfa52-7e1e-49b7-808c-434e404121f9 container client-container: <nil>
STEP: delete the pod
Nov  4 09:56:17.422: INFO: Waiting for pod downwardapi-volume-646bfa52-7e1e-49b7-808c-434e404121f9 to disappear
Nov  4 09:56:17.425: INFO: Pod downwardapi-volume-646bfa52-7e1e-49b7-808c-434e404121f9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:56:17.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5518" for this suite.
Nov  4 09:56:23.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:56:23.552: INFO: namespace projected-5518 deletion completed in 6.12311946s

• [SLOW TEST:8.317 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:56:23.553: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6395
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Nov  4 09:56:23.702: INFO: Waiting up to 5m0s for pod "var-expansion-cd33ff87-062d-4d2a-a19e-ccc9cbc88516" in namespace "var-expansion-6395" to be "success or failure"
Nov  4 09:56:23.714: INFO: Pod "var-expansion-cd33ff87-062d-4d2a-a19e-ccc9cbc88516": Phase="Pending", Reason="", readiness=false. Elapsed: 12.31577ms
Nov  4 09:56:25.717: INFO: Pod "var-expansion-cd33ff87-062d-4d2a-a19e-ccc9cbc88516": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014981347s
STEP: Saw pod success
Nov  4 09:56:25.717: INFO: Pod "var-expansion-cd33ff87-062d-4d2a-a19e-ccc9cbc88516" satisfied condition "success or failure"
Nov  4 09:56:25.720: INFO: Trying to get logs from node k8s-1 pod var-expansion-cd33ff87-062d-4d2a-a19e-ccc9cbc88516 container dapi-container: <nil>
STEP: delete the pod
Nov  4 09:56:25.753: INFO: Waiting for pod var-expansion-cd33ff87-062d-4d2a-a19e-ccc9cbc88516 to disappear
Nov  4 09:56:25.756: INFO: Pod var-expansion-cd33ff87-062d-4d2a-a19e-ccc9cbc88516 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:56:25.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6395" for this suite.
Nov  4 09:56:31.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:56:31.867: INFO: namespace var-expansion-6395 deletion completed in 6.107192324s

• [SLOW TEST:8.314 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:56:31.868: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2355
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:56:32.707: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458192, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458192, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458192, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458192, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:56:35.727: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:56:36.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2355" for this suite.
Nov  4 09:56:42.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:56:42.124: INFO: namespace webhook-2355 deletion completed in 6.097822272s
STEP: Destroying namespace "webhook-2355-markers" for this suite.
Nov  4 09:56:48.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:56:48.222: INFO: namespace webhook-2355-markers deletion completed in 6.098071909s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.366 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:56:48.236: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6781
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:56:48.877: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:56:51.892: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:56:51.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6781" for this suite.
Nov  4 09:56:57.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:56:58.071: INFO: namespace webhook-6781 deletion completed in 6.102604437s
STEP: Destroying namespace "webhook-6781-markers" for this suite.
Nov  4 09:57:04.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:57:04.168: INFO: namespace webhook-6781-markers deletion completed in 6.096109257s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.947 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:57:04.183: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1991
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:57:06.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1991" for this suite.
Nov  4 09:57:12.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:57:12.558: INFO: namespace emptydir-wrapper-1991 deletion completed in 6.162534349s

• [SLOW TEST:8.376 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:57:12.560: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8019
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:57:12.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8019" for this suite.
Nov  4 09:57:18.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:57:18.824: INFO: namespace services-8019 deletion completed in 6.107042666s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.264 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:57:18.826: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-1606
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:57:18.961: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Creating first CR 
Nov  4 09:57:24.090: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T09:57:24Z generation:1 name:name1 resourceVersion:529079 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:b65909cc-2fab-47bc-89cf-43fde176848d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Nov  4 09:57:34.096: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T09:57:34Z generation:1 name:name2 resourceVersion:529096 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:8a80b3f2-3f8c-4004-917b-99f9b0f900ee] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Nov  4 09:57:44.102: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T09:57:24Z generation:2 name:name1 resourceVersion:529113 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:b65909cc-2fab-47bc-89cf-43fde176848d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Nov  4 09:57:54.108: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T09:57:34Z generation:2 name:name2 resourceVersion:529130 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:8a80b3f2-3f8c-4004-917b-99f9b0f900ee] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Nov  4 09:58:04.116: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T09:57:24Z generation:2 name:name1 resourceVersion:529147 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:b65909cc-2fab-47bc-89cf-43fde176848d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Nov  4 09:58:14.124: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T09:57:34Z generation:2 name:name2 resourceVersion:529164 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:8a80b3f2-3f8c-4004-917b-99f9b0f900ee] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:58:24.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-1606" for this suite.
Nov  4 09:58:31.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:58:31.106: INFO: namespace crd-watch-1606 deletion completed in 6.335070902s

• [SLOW TEST:72.280 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:58:31.108: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8766
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:58:31.846: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:58:34.861: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:58:34.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8766" for this suite.
Nov  4 09:58:40.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:58:40.977: INFO: namespace webhook-8766 deletion completed in 6.105721876s
STEP: Destroying namespace "webhook-8766-markers" for this suite.
Nov  4 09:58:46.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:58:47.082: INFO: namespace webhook-8766-markers deletion completed in 6.104428041s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.989 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:58:47.097: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5178
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 09:58:47.742: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458327, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458327, loc:(*time.Location)(0x84c02a0)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-86d95b659d\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458327, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458327, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Nov  4 09:58:49.745: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458327, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458327, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458327, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458327, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 09:58:52.756: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:58:52.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5178" for this suite.
Nov  4 09:58:58.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:58:58.960: INFO: namespace webhook-5178 deletion completed in 6.113395246s
STEP: Destroying namespace "webhook-5178-markers" for this suite.
Nov  4 09:59:04.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:59:05.066: INFO: namespace webhook-5178-markers deletion completed in 6.105258225s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.984 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:59:05.081: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2945
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:59:05.227: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov  4 09:59:10.230: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  4 09:59:10.230: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 09:59:10.248: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-2945 /apis/apps/v1/namespaces/deployment-2945/deployments/test-cleanup-deployment 20ac7aa1-fc99-46ed-bce6-2176ac5de82e 529420 1 2019-11-04 09:59:10 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006a3a018 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Nov  4 09:59:10.255: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-2945 /apis/apps/v1/namespaces/deployment-2945/replicasets/test-cleanup-deployment-65db99849b e1679a7b-c820-4343-ac03-772e0d25c207 529422 1 2019-11-04 09:59:10 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 20ac7aa1-fc99-46ed-bce6-2176ac5de82e 0xc006a3a487 0xc006a3a488}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006a3a4e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 09:59:10.255: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Nov  4 09:59:10.255: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-2945 /apis/apps/v1/namespaces/deployment-2945/replicasets/test-cleanup-controller 4d028112-7482-41da-9bc2-257befd1e150 529421 1 2019-11-04 09:59:05 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 20ac7aa1-fc99-46ed-bce6-2176ac5de82e 0xc006a3a3b7 0xc006a3a3b8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc006a3a418 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  4 09:59:10.260: INFO: Pod "test-cleanup-controller-k77rz" is available:
&Pod{ObjectMeta:{test-cleanup-controller-k77rz test-cleanup-controller- deployment-2945 /api/v1/namespaces/deployment-2945/pods/test-cleanup-controller-k77rz 4c069a42-e2ea-4419-ab7e-a0e8f9853b12 529409 0 2019-11-04 09:59:05 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 4d028112-7482-41da-9bc2-257befd1e150 0xc006a3a937 0xc006a3a938}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnxpl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnxpl,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnxpl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:59:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:59:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:59:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 09:59:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.2.244,StartTime:2019-11-04 09:59:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 09:59:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://a37c2afb8c7563a3f373442ea955386bed8c4d759b336ff297724a9d35920682,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.244,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:59:10.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2945" for this suite.
Nov  4 09:59:16.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:59:16.379: INFO: namespace deployment-2945 deletion completed in 6.10846495s

• [SLOW TEST:11.297 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:59:16.379: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1700
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 09:59:16.518: INFO: Creating ReplicaSet my-hostname-basic-f8ea632d-0d0b-4f4c-b45e-2eceec0fe27a
Nov  4 09:59:16.527: INFO: Pod name my-hostname-basic-f8ea632d-0d0b-4f4c-b45e-2eceec0fe27a: Found 0 pods out of 1
Nov  4 09:59:21.533: INFO: Pod name my-hostname-basic-f8ea632d-0d0b-4f4c-b45e-2eceec0fe27a: Found 1 pods out of 1
Nov  4 09:59:21.533: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f8ea632d-0d0b-4f4c-b45e-2eceec0fe27a" is running
Nov  4 09:59:21.535: INFO: Pod "my-hostname-basic-f8ea632d-0d0b-4f4c-b45e-2eceec0fe27a-nmbrn" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 09:59:16 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 09:59:18 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 09:59:18 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 09:59:16 +0000 UTC Reason: Message:}])
Nov  4 09:59:21.535: INFO: Trying to dial the pod
Nov  4 09:59:26.545: INFO: Controller my-hostname-basic-f8ea632d-0d0b-4f4c-b45e-2eceec0fe27a: Got expected result from replica 1 [my-hostname-basic-f8ea632d-0d0b-4f4c-b45e-2eceec0fe27a-nmbrn]: "my-hostname-basic-f8ea632d-0d0b-4f4c-b45e-2eceec0fe27a-nmbrn", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:59:26.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1700" for this suite.
Nov  4 09:59:32.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:59:32.651: INFO: namespace replicaset-1700 deletion completed in 6.101347073s

• [SLOW TEST:16.271 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:59:32.651: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5596
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-ea495e77-9281-4cec-a2df-5083875a6c3a
STEP: Creating a pod to test consume secrets
Nov  4 09:59:32.828: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3e5479db-74e5-405f-b2c2-2bc2f6b8b685" in namespace "projected-5596" to be "success or failure"
Nov  4 09:59:32.835: INFO: Pod "pod-projected-secrets-3e5479db-74e5-405f-b2c2-2bc2f6b8b685": Phase="Pending", Reason="", readiness=false. Elapsed: 6.575773ms
Nov  4 09:59:34.838: INFO: Pod "pod-projected-secrets-3e5479db-74e5-405f-b2c2-2bc2f6b8b685": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009663029s
STEP: Saw pod success
Nov  4 09:59:34.838: INFO: Pod "pod-projected-secrets-3e5479db-74e5-405f-b2c2-2bc2f6b8b685" satisfied condition "success or failure"
Nov  4 09:59:34.840: INFO: Trying to get logs from node k8s-1 pod pod-projected-secrets-3e5479db-74e5-405f-b2c2-2bc2f6b8b685 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 09:59:34.871: INFO: Waiting for pod pod-projected-secrets-3e5479db-74e5-405f-b2c2-2bc2f6b8b685 to disappear
Nov  4 09:59:34.876: INFO: Pod pod-projected-secrets-3e5479db-74e5-405f-b2c2-2bc2f6b8b685 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:59:34.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5596" for this suite.
Nov  4 09:59:40.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:59:40.978: INFO: namespace projected-5596 deletion completed in 6.099168208s

• [SLOW TEST:8.327 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:59:40.979: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-473
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  4 09:59:41.129: INFO: Waiting up to 5m0s for pod "pod-c3797205-d2f4-4e87-ab21-c6276087a709" in namespace "emptydir-473" to be "success or failure"
Nov  4 09:59:41.133: INFO: Pod "pod-c3797205-d2f4-4e87-ab21-c6276087a709": Phase="Pending", Reason="", readiness=false. Elapsed: 4.103268ms
Nov  4 09:59:43.135: INFO: Pod "pod-c3797205-d2f4-4e87-ab21-c6276087a709": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006814072s
STEP: Saw pod success
Nov  4 09:59:43.136: INFO: Pod "pod-c3797205-d2f4-4e87-ab21-c6276087a709" satisfied condition "success or failure"
Nov  4 09:59:43.138: INFO: Trying to get logs from node k8s-1 pod pod-c3797205-d2f4-4e87-ab21-c6276087a709 container test-container: <nil>
STEP: delete the pod
Nov  4 09:59:43.158: INFO: Waiting for pod pod-c3797205-d2f4-4e87-ab21-c6276087a709 to disappear
Nov  4 09:59:43.161: INFO: Pod pod-c3797205-d2f4-4e87-ab21-c6276087a709 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 09:59:43.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-473" for this suite.
Nov  4 09:59:49.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 09:59:49.265: INFO: namespace emptydir-473 deletion completed in 6.099255684s

• [SLOW TEST:8.286 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 09:59:49.266: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:00:00.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2240" for this suite.
Nov  4 10:00:06.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:00:06.571: INFO: namespace resourcequota-2240 deletion completed in 6.099054359s

• [SLOW TEST:17.305 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:00:06.571: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2969
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 10:00:06.709: INFO: Creating deployment "webserver-deployment"
Nov  4 10:00:06.715: INFO: Waiting for observed generation 1
Nov  4 10:00:08.723: INFO: Waiting for all required pods to come up
Nov  4 10:00:08.727: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov  4 10:00:10.756: INFO: Waiting for deployment "webserver-deployment" to complete
Nov  4 10:00:10.762: INFO: Updating deployment "webserver-deployment" with a non-existent image
Nov  4 10:00:10.771: INFO: Updating deployment webserver-deployment
Nov  4 10:00:10.771: INFO: Waiting for observed generation 2
Nov  4 10:00:12.781: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov  4 10:00:12.783: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov  4 10:00:12.786: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov  4 10:00:12.793: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov  4 10:00:12.793: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov  4 10:00:12.796: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov  4 10:00:12.800: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Nov  4 10:00:12.800: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Nov  4 10:00:12.816: INFO: Updating deployment webserver-deployment
Nov  4 10:00:12.816: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Nov  4 10:00:12.821: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov  4 10:00:12.829: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 10:00:14.851: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-2969 /apis/apps/v1/namespaces/deployment-2969/deployments/webserver-deployment 4c58c1e2-2900-46a6-9386-77599f02690c 530001 3 2019-11-04 10:00:06 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0064ed0c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-11-04 10:00:12 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-11-04 10:00:13 +0000 UTC,LastTransitionTime:2019-11-04 10:00:06 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Nov  4 10:00:14.854: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-2969 /apis/apps/v1/namespaces/deployment-2969/replicasets/webserver-deployment-c7997dcc8 f77f3510-991f-42d8-90de-db85b507d18b 529980 3 2019-11-04 10:00:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 4c58c1e2-2900-46a6-9386-77599f02690c 0xc0064ed5e7 0xc0064ed5e8}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0064ed658 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 10:00:14.854: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Nov  4 10:00:14.854: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-2969 /apis/apps/v1/namespaces/deployment-2969/replicasets/webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 529996 3 2019-11-04 10:00:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 4c58c1e2-2900-46a6-9386-77599f02690c 0xc0064ed527 0xc0064ed528}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0064ed588 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Nov  4 10:00:14.864: INFO: Pod "webserver-deployment-595b5b9587-44zlj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-44zlj webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-44zlj 887fd39b-0d00-4645-a6ee-7bfdfe87131b 529984 0 2019-11-04 10:00:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc0064edb47 0xc0064edb48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:,StartTime:2019-11-04 10:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.864: INFO: Pod "webserver-deployment-595b5b9587-9j5vz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9j5vz webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-9j5vz 97b7b317-7094-42ce-a16a-dde31b776baf 529941 0 2019-11-04 10:00:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc0064edca0 0xc0064edca1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 10:00:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.864: INFO: Pod "webserver-deployment-595b5b9587-bc8tv" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bc8tv webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-bc8tv 405690da-915a-4ba4-b6ad-1358a68a241b 529909 0 2019-11-04 10:00:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc0064eddf0 0xc0064eddf1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 10:00:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.865: INFO: Pod "webserver-deployment-595b5b9587-bn45j" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bn45j webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-bn45j a27c61ea-3e35-4738-986b-b2996c66544e 529784 0 2019-11-04 10:00:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc0064edf40 0xc0064edf41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:10.33.1.83,StartTime:2019-11-04 10:00:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 10:00:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://dd6b5508b711154ba43c456db7ca839f8f171c2c3ce3bc88b40e8c4c3b80ccac,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.1.83,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.865: INFO: Pod "webserver-deployment-595b5b9587-bzzkf" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bzzkf webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-bzzkf e2a65f24-ff1d-40a7-b133-230d1bf06161 529998 0 2019-11-04 10:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f520c0 0xc002f520c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:,StartTime:2019-11-04 10:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.865: INFO: Pod "webserver-deployment-595b5b9587-ckqdd" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ckqdd webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-ckqdd b926f9a5-6b09-4f0e-aab1-821fba4e83bc 530007 0 2019-11-04 10:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f522e0 0xc002f522e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:,StartTime:2019-11-04 10:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.865: INFO: Pod "webserver-deployment-595b5b9587-d7wpr" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-d7wpr webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-d7wpr 3cefc783-adcc-4e7a-82ca-ffa9f30585b0 529790 0 2019-11-04 10:00:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f526c0 0xc002f526c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:10.33.0.78,StartTime:2019-11-04 10:00:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 10:00:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://fffe2e3f2d8b25f4b5b2292f933cd9abf7a595a0ef5138750ea17b4e7e17224b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.0.78,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.865: INFO: Pod "webserver-deployment-595b5b9587-dzf2r" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-dzf2r webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-dzf2r 31c2e91b-eb7d-4646-8b74-944f9fdf6e09 529781 0 2019-11-04 10:00:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f52870 0xc002f52871}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:10.33.1.84,StartTime:2019-11-04 10:00:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 10:00:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://8525dcc56061cc853cfe66b24df8f2a6533f00b8141bfac89ac5ec5c0966a1ca,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.1.84,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.866: INFO: Pod "webserver-deployment-595b5b9587-gjwnr" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gjwnr webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-gjwnr ff7a5b2c-c63b-4751-bcb7-e9426d0c75a4 529975 0 2019-11-04 10:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f529f0 0xc002f529f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 10:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.866: INFO: Pod "webserver-deployment-595b5b9587-kjsj9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kjsj9 webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-kjsj9 0d9d340c-56fa-4ceb-b39e-1d02b6bb0318 529978 0 2019-11-04 10:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f52b40 0xc002f52b41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.866: INFO: Pod "webserver-deployment-595b5b9587-l9t9q" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-l9t9q webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-l9t9q 873d6659-ba97-4511-91d0-e1dd8011734d 530011 0 2019-11-04 10:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f52c50 0xc002f52c51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:,StartTime:2019-11-04 10:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.866: INFO: Pod "webserver-deployment-595b5b9587-lx7p9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-lx7p9 webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-lx7p9 152f5e38-da78-457e-9c68-8fd9431c11d7 530021 0 2019-11-04 10:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f52da0 0xc002f52da1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 10:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.867: INFO: Pod "webserver-deployment-595b5b9587-mgmxt" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mgmxt webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-mgmxt 3da482f6-8085-49f8-ba59-97c9913f3fea 529773 0 2019-11-04 10:00:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f52ef0 0xc002f52ef1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.2.249,StartTime:2019-11-04 10:00:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 10:00:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://60f3dddd4595285ec531d80995835b12915854b76577ad527ab99ebc5ee764c0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.249,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.867: INFO: Pod "webserver-deployment-595b5b9587-mjsbd" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mjsbd webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-mjsbd b7cec83e-cfeb-46cb-8d36-deed31fc1325 530002 0 2019-11-04 10:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f53060 0xc002f53061}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:,StartTime:2019-11-04 10:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.867: INFO: Pod "webserver-deployment-595b5b9587-pqpdz" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pqpdz webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-pqpdz 858de67b-aec7-4540-9bbb-1c326411d98c 529787 0 2019-11-04 10:00:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f531b0 0xc002f531b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:10.33.0.79,StartTime:2019-11-04 10:00:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 10:00:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://785208a4d0dd9db94e6b84cb59cec438d5cb52c9199430a15bb0f18d70094cba,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.0.79,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.867: INFO: Pod "webserver-deployment-595b5b9587-qp9s8" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qp9s8 webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-qp9s8 c0e1648a-4ea1-4e10-ab2a-f4fbb1d4bfd5 530019 0 2019-11-04 10:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f53320 0xc002f53321}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:,StartTime:2019-11-04 10:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.867: INFO: Pod "webserver-deployment-595b5b9587-sj7j9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sj7j9 webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-sj7j9 5a332580-8db4-4a80-87ff-8a983226b4ec 529753 0 2019-11-04 10:00:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f53470 0xc002f53471}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:10.33.1.82,StartTime:2019-11-04 10:00:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 10:00:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://282eff3a2f64a748384a74db7ac7eb54ed9c0bf020665af63d400ae847f7c076,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.1.82,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.869: INFO: Pod "webserver-deployment-595b5b9587-t4dqr" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-t4dqr webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-t4dqr a494e075-77b9-47f2-a543-39c552a5a15e 529993 0 2019-11-04 10:00:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f535e0 0xc002f535e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:,StartTime:2019-11-04 10:00:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.870: INFO: Pod "webserver-deployment-595b5b9587-tknhj" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tknhj webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-tknhj 77ebe984-bc0b-4f07-9051-81a4cdb5d50f 529797 0 2019-11-04 10:00:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f53730 0xc002f53731}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.2.252,StartTime:2019-11-04 10:00:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 10:00:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://b31d5d11e2df812d1ea05769346b3f5347f0adc1be97c4e38c730fceee38a173,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.252,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.870: INFO: Pod "webserver-deployment-595b5b9587-xqh5c" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xqh5c webserver-deployment-595b5b9587- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-595b5b9587-xqh5c 29071c91-6020-4f21-807a-99f169713c32 529793 0 2019-11-04 10:00:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 28d9e609-ac2f-4a31-9153-64b1afb3fed0 0xc002f538a0 0xc002f538a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:10.33.0.77,StartTime:2019-11-04 10:00:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 10:00:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://0a749463a803b0eaaf3464103d9c57cff2d48d45d979ddc4fc0b3afde791a991,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.0.77,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.870: INFO: Pod "webserver-deployment-c7997dcc8-8bg26" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8bg26 webserver-deployment-c7997dcc8- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-c7997dcc8-8bg26 e65a062d-a616-42b7-bc85-e3947352febd 529883 0 2019-11-04 10:00:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f77f3510-991f-42d8-90de-db85b507d18b 0xc002f53a20 0xc002f53a21}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:10.33.1.85,StartTime:2019-11-04 10:00:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.1.85,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.870: INFO: Pod "webserver-deployment-c7997dcc8-bqgtt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-bqgtt webserver-deployment-c7997dcc8- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-c7997dcc8-bqgtt 15a1fe53-04c5-461b-b17e-9d767ec65dda 529917 0 2019-11-04 10:00:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f77f3510-991f-42d8-90de-db85b507d18b 0xc002f53bc0 0xc002f53bc1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:10.33.0.80,StartTime:2019-11-04 10:00:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.0.80,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.871: INFO: Pod "webserver-deployment-c7997dcc8-bxj9v" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-bxj9v webserver-deployment-c7997dcc8- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-c7997dcc8-bxj9v 56851133-15e5-434f-bb3c-3e9ef7a10f59 530004 0 2019-11-04 10:00:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f77f3510-991f-42d8-90de-db85b507d18b 0xc002f53d60 0xc002f53d61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:,StartTime:2019-11-04 10:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.871: INFO: Pod "webserver-deployment-c7997dcc8-d2vhq" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-d2vhq webserver-deployment-c7997dcc8- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-c7997dcc8-d2vhq a9cb4587-d334-4db2-ad58-85c3c7bb71c4 529957 0 2019-11-04 10:00:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f77f3510-991f-42d8-90de-db85b507d18b 0xc002f53ee0 0xc002f53ee1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 10:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.872: INFO: Pod "webserver-deployment-c7997dcc8-fvz4w" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-fvz4w webserver-deployment-c7997dcc8- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-c7997dcc8-fvz4w 3bf9d138-2f04-4ce6-93b2-bab1e50b248b 529933 0 2019-11-04 10:00:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f77f3510-991f-42d8-90de-db85b507d18b 0xc002ef40e0 0xc002ef40e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 10:00:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.872: INFO: Pod "webserver-deployment-c7997dcc8-gs8g8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gs8g8 webserver-deployment-c7997dcc8- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-c7997dcc8-gs8g8 71b5c366-8787-41c2-a6e5-ccb350a6b636 529994 0 2019-11-04 10:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f77f3510-991f-42d8-90de-db85b507d18b 0xc002ef4280 0xc002ef4281}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 10:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.872: INFO: Pod "webserver-deployment-c7997dcc8-lk4q8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lk4q8 webserver-deployment-c7997dcc8- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-c7997dcc8-lk4q8 4712e9a1-9686-401c-b1ae-56b95632eb12 530012 0 2019-11-04 10:00:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f77f3510-991f-42d8-90de-db85b507d18b 0xc002ef4570 0xc002ef4571}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.2.254,StartTime:2019-11-04 10:00:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.254,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.872: INFO: Pod "webserver-deployment-c7997dcc8-llw6t" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-llw6t webserver-deployment-c7997dcc8- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-c7997dcc8-llw6t 79997d67-03e2-4ccb-8765-aae24090be55 529936 0 2019-11-04 10:00:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f77f3510-991f-42d8-90de-db85b507d18b 0xc002ef47f0 0xc002ef47f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:,StartTime:2019-11-04 10:00:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.873: INFO: Pod "webserver-deployment-c7997dcc8-ndtqc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-ndtqc webserver-deployment-c7997dcc8- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-c7997dcc8-ndtqc 75c20b78-d9f8-4cb4-b65a-c2beb25584a8 529926 0 2019-11-04 10:00:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f77f3510-991f-42d8-90de-db85b507d18b 0xc002ef4c70 0xc002ef4c71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:,StartTime:2019-11-04 10:00:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.873: INFO: Pod "webserver-deployment-c7997dcc8-r8qmq" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-r8qmq webserver-deployment-c7997dcc8- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-c7997dcc8-r8qmq 302ecdc3-375c-4f8d-8da9-a218b9898233 529954 0 2019-11-04 10:00:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f77f3510-991f-42d8-90de-db85b507d18b 0xc002ef5340 0xc002ef5341}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:10.33.0.81,StartTime:2019-11-04 10:00:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.0.81,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.873: INFO: Pod "webserver-deployment-c7997dcc8-shcxp" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-shcxp webserver-deployment-c7997dcc8- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-c7997dcc8-shcxp d109dfc0-a864-4996-86b7-1fb25288f358 529961 0 2019-11-04 10:00:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f77f3510-991f-42d8-90de-db85b507d18b 0xc002ef5500 0xc002ef5501}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:,StartTime:2019-11-04 10:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.876: INFO: Pod "webserver-deployment-c7997dcc8-v84zz" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-v84zz webserver-deployment-c7997dcc8- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-c7997dcc8-v84zz ed506a04-bd41-4dd7-acca-20e9ea219c0d 529999 0 2019-11-04 10:00:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f77f3510-991f-42d8-90de-db85b507d18b 0xc002ef5990 0xc002ef5991}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:,StartTime:2019-11-04 10:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 10:00:14.876: INFO: Pod "webserver-deployment-c7997dcc8-zjzn2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-zjzn2 webserver-deployment-c7997dcc8- deployment-2969 /api/v1/namespaces/deployment-2969/pods/webserver-deployment-c7997dcc8-zjzn2 286128cf-f4df-45cb-b4ff-3f81316e7688 530018 0 2019-11-04 10:00:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f77f3510-991f-42d8-90de-db85b507d18b 0xc002ef5bb0 0xc002ef5bb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqnf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqnf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqnf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:00:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.2.253,StartTime:2019-11-04 10:00:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.253,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:00:14.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2969" for this suite.
Nov  4 10:00:22.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:00:23.003: INFO: namespace deployment-2969 deletion completed in 8.123773233s

• [SLOW TEST:16.432 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:00:23.003: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7762
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-f4781e91-2dea-4017-8785-75d4b5323fef
STEP: Creating a pod to test consume secrets
Nov  4 10:00:23.185: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a9a72f77-8f5f-4652-ac8b-de2b77849525" in namespace "projected-7762" to be "success or failure"
Nov  4 10:00:23.219: INFO: Pod "pod-projected-secrets-a9a72f77-8f5f-4652-ac8b-de2b77849525": Phase="Pending", Reason="", readiness=false. Elapsed: 34.245046ms
Nov  4 10:00:25.222: INFO: Pod "pod-projected-secrets-a9a72f77-8f5f-4652-ac8b-de2b77849525": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037300849s
Nov  4 10:00:27.225: INFO: Pod "pod-projected-secrets-a9a72f77-8f5f-4652-ac8b-de2b77849525": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040093846s
STEP: Saw pod success
Nov  4 10:00:27.225: INFO: Pod "pod-projected-secrets-a9a72f77-8f5f-4652-ac8b-de2b77849525" satisfied condition "success or failure"
Nov  4 10:00:27.228: INFO: Trying to get logs from node k8s-1 pod pod-projected-secrets-a9a72f77-8f5f-4652-ac8b-de2b77849525 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 10:00:27.247: INFO: Waiting for pod pod-projected-secrets-a9a72f77-8f5f-4652-ac8b-de2b77849525 to disappear
Nov  4 10:00:27.253: INFO: Pod pod-projected-secrets-a9a72f77-8f5f-4652-ac8b-de2b77849525 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:00:27.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7762" for this suite.
Nov  4 10:00:33.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:00:33.350: INFO: namespace projected-7762 deletion completed in 6.093036876s

• [SLOW TEST:10.347 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:00:33.351: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1557
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 10:00:33.500: INFO: Waiting up to 5m0s for pod "busybox-user-65534-1f5f057a-4900-4148-9ac5-e75ce543f447" in namespace "security-context-test-1557" to be "success or failure"
Nov  4 10:00:33.504: INFO: Pod "busybox-user-65534-1f5f057a-4900-4148-9ac5-e75ce543f447": Phase="Pending", Reason="", readiness=false. Elapsed: 4.44187ms
Nov  4 10:00:35.507: INFO: Pod "busybox-user-65534-1f5f057a-4900-4148-9ac5-e75ce543f447": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007807419s
Nov  4 10:00:35.507: INFO: Pod "busybox-user-65534-1f5f057a-4900-4148-9ac5-e75ce543f447" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:00:35.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1557" for this suite.
Nov  4 10:00:41.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:00:41.615: INFO: namespace security-context-test-1557 deletion completed in 6.103329861s

• [SLOW TEST:8.264 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:00:41.616: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2581
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-2581/configmap-test-7cfa6e3e-d43b-4bb7-8fb7-346050e8d773
STEP: Creating a pod to test consume configMaps
Nov  4 10:00:41.776: INFO: Waiting up to 5m0s for pod "pod-configmaps-09b3403e-00a2-48d7-91d5-e1d5294c79be" in namespace "configmap-2581" to be "success or failure"
Nov  4 10:00:41.781: INFO: Pod "pod-configmaps-09b3403e-00a2-48d7-91d5-e1d5294c79be": Phase="Pending", Reason="", readiness=false. Elapsed: 4.750027ms
Nov  4 10:00:43.784: INFO: Pod "pod-configmaps-09b3403e-00a2-48d7-91d5-e1d5294c79be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008130418s
STEP: Saw pod success
Nov  4 10:00:43.784: INFO: Pod "pod-configmaps-09b3403e-00a2-48d7-91d5-e1d5294c79be" satisfied condition "success or failure"
Nov  4 10:00:43.787: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-09b3403e-00a2-48d7-91d5-e1d5294c79be container env-test: <nil>
STEP: delete the pod
Nov  4 10:00:43.809: INFO: Waiting for pod pod-configmaps-09b3403e-00a2-48d7-91d5-e1d5294c79be to disappear
Nov  4 10:00:43.812: INFO: Pod pod-configmaps-09b3403e-00a2-48d7-91d5-e1d5294c79be no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:00:43.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2581" for this suite.
Nov  4 10:00:49.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:00:49.919: INFO: namespace configmap-2581 deletion completed in 6.103985401s

• [SLOW TEST:8.303 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:00:49.920: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7808
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-1562
STEP: Creating secret with name secret-test-37b98ca8-0524-4355-820f-809f46519fbe
STEP: Creating a pod to test consume secrets
Nov  4 10:00:50.295: INFO: Waiting up to 5m0s for pod "pod-secrets-60c1f6da-3187-4dbc-b38f-e2d3301070dc" in namespace "secrets-7808" to be "success or failure"
Nov  4 10:00:50.308: INFO: Pod "pod-secrets-60c1f6da-3187-4dbc-b38f-e2d3301070dc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.300129ms
Nov  4 10:00:52.311: INFO: Pod "pod-secrets-60c1f6da-3187-4dbc-b38f-e2d3301070dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015564524s
STEP: Saw pod success
Nov  4 10:00:52.311: INFO: Pod "pod-secrets-60c1f6da-3187-4dbc-b38f-e2d3301070dc" satisfied condition "success or failure"
Nov  4 10:00:52.313: INFO: Trying to get logs from node k8s-1 pod pod-secrets-60c1f6da-3187-4dbc-b38f-e2d3301070dc container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 10:00:52.344: INFO: Waiting for pod pod-secrets-60c1f6da-3187-4dbc-b38f-e2d3301070dc to disappear
Nov  4 10:00:52.350: INFO: Pod pod-secrets-60c1f6da-3187-4dbc-b38f-e2d3301070dc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:00:52.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7808" for this suite.
Nov  4 10:00:58.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:00:58.455: INFO: namespace secrets-7808 deletion completed in 6.102688821s
STEP: Destroying namespace "secret-namespace-1562" for this suite.
Nov  4 10:01:04.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:01:04.550: INFO: namespace secret-namespace-1562 deletion completed in 6.093954706s

• [SLOW TEST:14.630 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:01:04.550: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5466
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Nov  4 10:01:04.688: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-416373942 proxy --unix-socket=/tmp/kubectl-proxy-unix700451037/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:01:04.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5466" for this suite.
Nov  4 10:01:10.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:01:10.869: INFO: namespace kubectl-5466 deletion completed in 6.114441105s

• [SLOW TEST:6.319 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:01:10.869: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7611
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7611
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Nov  4 10:01:11.027: INFO: Found 0 stateful pods, waiting for 3
Nov  4 10:01:21.047: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 10:01:21.047: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 10:01:21.047: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 10:01:21.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-7611 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 10:01:21.424: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 10:01:21.424: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 10:01:21.424: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov  4 10:01:31.453: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov  4 10:01:41.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-7611 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 10:01:41.711: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 10:01:41.711: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 10:01:41.711: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 10:02:01.729: INFO: Waiting for StatefulSet statefulset-7611/ss2 to complete update
STEP: Rolling back to a previous revision
Nov  4 10:02:11.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-7611 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 10:02:12.001: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 10:02:12.001: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 10:02:12.001: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 10:02:22.031: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov  4 10:02:22.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-7611 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 10:02:22.326: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 10:02:22.326: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 10:02:22.326: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 10:02:22.337: INFO: Waiting for StatefulSet statefulset-7611/ss2 to complete update
Nov  4 10:02:22.337: INFO: Waiting for Pod statefulset-7611/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov  4 10:02:22.337: INFO: Waiting for Pod statefulset-7611/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov  4 10:02:22.337: INFO: Waiting for Pod statefulset-7611/ss2-2 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov  4 10:02:32.344: INFO: Waiting for StatefulSet statefulset-7611/ss2 to complete update
Nov  4 10:02:32.344: INFO: Waiting for Pod statefulset-7611/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov  4 10:02:32.344: INFO: Waiting for Pod statefulset-7611/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov  4 10:02:42.343: INFO: Waiting for StatefulSet statefulset-7611/ss2 to complete update
Nov  4 10:02:42.343: INFO: Waiting for Pod statefulset-7611/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov  4 10:02:52.348: INFO: Waiting for StatefulSet statefulset-7611/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 10:03:02.342: INFO: Deleting all statefulset in ns statefulset-7611
Nov  4 10:03:02.345: INFO: Scaling statefulset ss2 to 0
Nov  4 10:03:32.361: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 10:03:32.363: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:03:32.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7611" for this suite.
Nov  4 10:03:38.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:03:38.505: INFO: namespace statefulset-7611 deletion completed in 6.123407876s

• [SLOW TEST:147.636 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:03:38.505: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7185
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-7185/secret-test-b8c4118f-227b-49bf-a9d4-b402a55c1abe
STEP: Creating a pod to test consume secrets
Nov  4 10:03:38.685: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b62ebce-5954-4795-83e7-f403fc806962" in namespace "secrets-7185" to be "success or failure"
Nov  4 10:03:38.696: INFO: Pod "pod-configmaps-8b62ebce-5954-4795-83e7-f403fc806962": Phase="Pending", Reason="", readiness=false. Elapsed: 11.676037ms
Nov  4 10:03:40.700: INFO: Pod "pod-configmaps-8b62ebce-5954-4795-83e7-f403fc806962": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014838408s
STEP: Saw pod success
Nov  4 10:03:40.700: INFO: Pod "pod-configmaps-8b62ebce-5954-4795-83e7-f403fc806962" satisfied condition "success or failure"
Nov  4 10:03:40.703: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-8b62ebce-5954-4795-83e7-f403fc806962 container env-test: <nil>
STEP: delete the pod
Nov  4 10:03:40.726: INFO: Waiting for pod pod-configmaps-8b62ebce-5954-4795-83e7-f403fc806962 to disappear
Nov  4 10:03:40.730: INFO: Pod pod-configmaps-8b62ebce-5954-4795-83e7-f403fc806962 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:03:40.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7185" for this suite.
Nov  4 10:03:46.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:03:46.846: INFO: namespace secrets-7185 deletion completed in 6.110813362s

• [SLOW TEST:8.341 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:03:46.846: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9358
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-fd5t
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 10:03:47.003: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-fd5t" in namespace "subpath-9358" to be "success or failure"
Nov  4 10:03:47.007: INFO: Pod "pod-subpath-test-projected-fd5t": Phase="Pending", Reason="", readiness=false. Elapsed: 3.742248ms
Nov  4 10:03:49.009: INFO: Pod "pod-subpath-test-projected-fd5t": Phase="Running", Reason="", readiness=true. Elapsed: 2.006180191s
Nov  4 10:03:51.012: INFO: Pod "pod-subpath-test-projected-fd5t": Phase="Running", Reason="", readiness=true. Elapsed: 4.00948424s
Nov  4 10:03:53.016: INFO: Pod "pod-subpath-test-projected-fd5t": Phase="Running", Reason="", readiness=true. Elapsed: 6.01284721s
Nov  4 10:03:55.019: INFO: Pod "pod-subpath-test-projected-fd5t": Phase="Running", Reason="", readiness=true. Elapsed: 8.01622703s
Nov  4 10:03:57.112: INFO: Pod "pod-subpath-test-projected-fd5t": Phase="Running", Reason="", readiness=true. Elapsed: 10.108932324s
Nov  4 10:03:59.115: INFO: Pod "pod-subpath-test-projected-fd5t": Phase="Running", Reason="", readiness=true. Elapsed: 12.112058296s
Nov  4 10:04:01.118: INFO: Pod "pod-subpath-test-projected-fd5t": Phase="Running", Reason="", readiness=true. Elapsed: 14.115118722s
Nov  4 10:04:03.121: INFO: Pod "pod-subpath-test-projected-fd5t": Phase="Running", Reason="", readiness=true. Elapsed: 16.118642469s
Nov  4 10:04:05.125: INFO: Pod "pod-subpath-test-projected-fd5t": Phase="Running", Reason="", readiness=true. Elapsed: 18.122289095s
Nov  4 10:04:07.129: INFO: Pod "pod-subpath-test-projected-fd5t": Phase="Running", Reason="", readiness=true. Elapsed: 20.126050388s
Nov  4 10:04:09.132: INFO: Pod "pod-subpath-test-projected-fd5t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.129498191s
STEP: Saw pod success
Nov  4 10:04:09.132: INFO: Pod "pod-subpath-test-projected-fd5t" satisfied condition "success or failure"
Nov  4 10:04:09.135: INFO: Trying to get logs from node k8s-1 pod pod-subpath-test-projected-fd5t container test-container-subpath-projected-fd5t: <nil>
STEP: delete the pod
Nov  4 10:04:09.170: INFO: Waiting for pod pod-subpath-test-projected-fd5t to disappear
Nov  4 10:04:09.173: INFO: Pod pod-subpath-test-projected-fd5t no longer exists
STEP: Deleting pod pod-subpath-test-projected-fd5t
Nov  4 10:04:09.173: INFO: Deleting pod "pod-subpath-test-projected-fd5t" in namespace "subpath-9358"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:04:09.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9358" for this suite.
Nov  4 10:04:15.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:04:15.272: INFO: namespace subpath-9358 deletion completed in 6.09143087s

• [SLOW TEST:28.426 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:04:15.272: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8550
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Nov  4 10:04:15.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 create -f - --namespace=kubectl-8550'
Nov  4 10:04:15.681: INFO: stderr: ""
Nov  4 10:04:15.681: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 10:04:15.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8550'
Nov  4 10:04:15.799: INFO: stderr: ""
Nov  4 10:04:15.799: INFO: stdout: "update-demo-nautilus-b6jlr update-demo-nautilus-h9csg "
Nov  4 10:04:15.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-b6jlr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8550'
Nov  4 10:04:15.903: INFO: stderr: ""
Nov  4 10:04:15.903: INFO: stdout: ""
Nov  4 10:04:15.903: INFO: update-demo-nautilus-b6jlr is created but not running
Nov  4 10:04:20.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8550'
Nov  4 10:04:20.988: INFO: stderr: ""
Nov  4 10:04:20.988: INFO: stdout: "update-demo-nautilus-b6jlr update-demo-nautilus-h9csg "
Nov  4 10:04:20.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-b6jlr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8550'
Nov  4 10:04:21.064: INFO: stderr: ""
Nov  4 10:04:21.064: INFO: stdout: "true"
Nov  4 10:04:21.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-b6jlr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8550'
Nov  4 10:04:21.139: INFO: stderr: ""
Nov  4 10:04:21.139: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 10:04:21.139: INFO: validating pod update-demo-nautilus-b6jlr
Nov  4 10:04:21.144: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 10:04:21.144: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 10:04:21.144: INFO: update-demo-nautilus-b6jlr is verified up and running
Nov  4 10:04:21.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-h9csg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8550'
Nov  4 10:04:21.232: INFO: stderr: ""
Nov  4 10:04:21.232: INFO: stdout: "true"
Nov  4 10:04:21.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-h9csg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8550'
Nov  4 10:04:21.311: INFO: stderr: ""
Nov  4 10:04:21.311: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 10:04:21.311: INFO: validating pod update-demo-nautilus-h9csg
Nov  4 10:04:21.316: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 10:04:21.316: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 10:04:21.316: INFO: update-demo-nautilus-h9csg is verified up and running
STEP: using delete to clean up resources
Nov  4 10:04:21.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete --grace-period=0 --force -f - --namespace=kubectl-8550'
Nov  4 10:04:21.397: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 10:04:21.397: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  4 10:04:21.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8550'
Nov  4 10:04:21.497: INFO: stderr: "No resources found in kubectl-8550 namespace.\n"
Nov  4 10:04:21.497: INFO: stdout: ""
Nov  4 10:04:21.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -l name=update-demo --namespace=kubectl-8550 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  4 10:04:21.579: INFO: stderr: ""
Nov  4 10:04:21.579: INFO: stdout: "update-demo-nautilus-b6jlr\nupdate-demo-nautilus-h9csg\n"
Nov  4 10:04:22.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8550'
Nov  4 10:04:22.216: INFO: stderr: "No resources found in kubectl-8550 namespace.\n"
Nov  4 10:04:22.216: INFO: stdout: ""
Nov  4 10:04:22.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -l name=update-demo --namespace=kubectl-8550 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  4 10:04:22.302: INFO: stderr: ""
Nov  4 10:04:22.302: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:04:22.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8550" for this suite.
Nov  4 10:04:34.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:04:34.407: INFO: namespace kubectl-8550 deletion completed in 12.101316651s

• [SLOW TEST:19.135 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:04:34.408: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-7694
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov  4 10:04:35.027: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Nov  4 10:04:37.036: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458675, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458675, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458675, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708458675, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 10:04:40.054: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 10:04:40.057: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:04:46.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7694" for this suite.
Nov  4 10:04:52.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:04:52.900: INFO: namespace crd-webhook-7694 deletion completed in 6.100933081s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:18.507 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:04:52.916: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1528
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 10:04:53.069: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec8d28c8-53e3-4683-8a54-4f1ac2f8328f" in namespace "projected-1528" to be "success or failure"
Nov  4 10:04:53.078: INFO: Pod "downwardapi-volume-ec8d28c8-53e3-4683-8a54-4f1ac2f8328f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.510766ms
Nov  4 10:04:55.081: INFO: Pod "downwardapi-volume-ec8d28c8-53e3-4683-8a54-4f1ac2f8328f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011823205s
STEP: Saw pod success
Nov  4 10:04:55.081: INFO: Pod "downwardapi-volume-ec8d28c8-53e3-4683-8a54-4f1ac2f8328f" satisfied condition "success or failure"
Nov  4 10:04:55.084: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-ec8d28c8-53e3-4683-8a54-4f1ac2f8328f container client-container: <nil>
STEP: delete the pod
Nov  4 10:04:55.109: INFO: Waiting for pod downwardapi-volume-ec8d28c8-53e3-4683-8a54-4f1ac2f8328f to disappear
Nov  4 10:04:55.111: INFO: Pod downwardapi-volume-ec8d28c8-53e3-4683-8a54-4f1ac2f8328f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:04:55.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1528" for this suite.
Nov  4 10:05:01.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:05:01.219: INFO: namespace projected-1528 deletion completed in 6.103979795s

• [SLOW TEST:8.304 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:05:01.221: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9922
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9922
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9922
STEP: Creating statefulset with conflicting port in namespace statefulset-9922
STEP: Waiting until pod test-pod will start running in namespace statefulset-9922
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9922
Nov  4 10:05:03.405: INFO: Observed stateful pod in namespace: statefulset-9922, name: ss-0, uid: c5584af7-65c0-4d70-b8e5-08b1b7ead99d, status phase: Pending. Waiting for statefulset controller to delete.
Nov  4 10:05:03.991: INFO: Observed stateful pod in namespace: statefulset-9922, name: ss-0, uid: c5584af7-65c0-4d70-b8e5-08b1b7ead99d, status phase: Failed. Waiting for statefulset controller to delete.
Nov  4 10:05:03.999: INFO: Observed stateful pod in namespace: statefulset-9922, name: ss-0, uid: c5584af7-65c0-4d70-b8e5-08b1b7ead99d, status phase: Failed. Waiting for statefulset controller to delete.
Nov  4 10:05:04.007: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9922
STEP: Removing pod with conflicting port in namespace statefulset-9922
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9922 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 10:05:06.039: INFO: Deleting all statefulset in ns statefulset-9922
Nov  4 10:05:06.042: INFO: Scaling statefulset ss to 0
Nov  4 10:05:16.056: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 10:05:16.058: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:05:16.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9922" for this suite.
Nov  4 10:05:22.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:05:22.190: INFO: namespace statefulset-9922 deletion completed in 6.111738076s

• [SLOW TEST:20.969 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:05:22.190: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4796
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 10:05:22.380: INFO: Waiting up to 5m0s for pod "downward-api-368cbe44-781b-444f-ba9c-83ac6bc97e20" in namespace "downward-api-4796" to be "success or failure"
Nov  4 10:05:22.384: INFO: Pod "downward-api-368cbe44-781b-444f-ba9c-83ac6bc97e20": Phase="Pending", Reason="", readiness=false. Elapsed: 3.312613ms
Nov  4 10:05:24.387: INFO: Pod "downward-api-368cbe44-781b-444f-ba9c-83ac6bc97e20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006414088s
STEP: Saw pod success
Nov  4 10:05:24.387: INFO: Pod "downward-api-368cbe44-781b-444f-ba9c-83ac6bc97e20" satisfied condition "success or failure"
Nov  4 10:05:24.389: INFO: Trying to get logs from node k8s-1 pod downward-api-368cbe44-781b-444f-ba9c-83ac6bc97e20 container dapi-container: <nil>
STEP: delete the pod
Nov  4 10:05:24.414: INFO: Waiting for pod downward-api-368cbe44-781b-444f-ba9c-83ac6bc97e20 to disappear
Nov  4 10:05:24.418: INFO: Pod downward-api-368cbe44-781b-444f-ba9c-83ac6bc97e20 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:05:24.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4796" for this suite.
Nov  4 10:05:30.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:05:30.633: INFO: namespace downward-api-4796 deletion completed in 6.206482777s

• [SLOW TEST:8.443 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:05:30.634: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5723
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  4 10:05:30.785: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:05:33.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5723" for this suite.
Nov  4 10:05:39.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:05:40.071: INFO: namespace init-container-5723 deletion completed in 6.109636457s

• [SLOW TEST:9.437 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:05:40.071: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6938
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Nov  4 10:05:40.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 --namespace=kubectl-6938 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov  4 10:05:42.040: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov  4 10:05:42.040: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:05:44.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6938" for this suite.
Nov  4 10:05:50.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:05:50.151: INFO: namespace kubectl-6938 deletion completed in 6.101201719s

• [SLOW TEST:10.080 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:05:50.152: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9336
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-rgdj
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 10:05:50.313: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rgdj" in namespace "subpath-9336" to be "success or failure"
Nov  4 10:05:50.329: INFO: Pod "pod-subpath-test-configmap-rgdj": Phase="Pending", Reason="", readiness=false. Elapsed: 15.368484ms
Nov  4 10:05:52.332: INFO: Pod "pod-subpath-test-configmap-rgdj": Phase="Running", Reason="", readiness=true. Elapsed: 2.018524496s
Nov  4 10:05:54.335: INFO: Pod "pod-subpath-test-configmap-rgdj": Phase="Running", Reason="", readiness=true. Elapsed: 4.021419956s
Nov  4 10:05:56.472: INFO: Pod "pod-subpath-test-configmap-rgdj": Phase="Running", Reason="", readiness=true. Elapsed: 6.158825348s
Nov  4 10:05:58.476: INFO: Pod "pod-subpath-test-configmap-rgdj": Phase="Running", Reason="", readiness=true. Elapsed: 8.162051048s
Nov  4 10:06:00.479: INFO: Pod "pod-subpath-test-configmap-rgdj": Phase="Running", Reason="", readiness=true. Elapsed: 10.165494466s
Nov  4 10:06:02.482: INFO: Pod "pod-subpath-test-configmap-rgdj": Phase="Running", Reason="", readiness=true. Elapsed: 12.168765869s
Nov  4 10:06:04.485: INFO: Pod "pod-subpath-test-configmap-rgdj": Phase="Running", Reason="", readiness=true. Elapsed: 14.171647624s
Nov  4 10:06:06.488: INFO: Pod "pod-subpath-test-configmap-rgdj": Phase="Running", Reason="", readiness=true. Elapsed: 16.174712752s
Nov  4 10:06:08.492: INFO: Pod "pod-subpath-test-configmap-rgdj": Phase="Running", Reason="", readiness=true. Elapsed: 18.178042488s
Nov  4 10:06:10.494: INFO: Pod "pod-subpath-test-configmap-rgdj": Phase="Running", Reason="", readiness=true. Elapsed: 20.180666958s
Nov  4 10:06:12.498: INFO: Pod "pod-subpath-test-configmap-rgdj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.184233159s
STEP: Saw pod success
Nov  4 10:06:12.498: INFO: Pod "pod-subpath-test-configmap-rgdj" satisfied condition "success or failure"
Nov  4 10:06:12.500: INFO: Trying to get logs from node k8s-1 pod pod-subpath-test-configmap-rgdj container test-container-subpath-configmap-rgdj: <nil>
STEP: delete the pod
Nov  4 10:06:12.521: INFO: Waiting for pod pod-subpath-test-configmap-rgdj to disappear
Nov  4 10:06:12.527: INFO: Pod pod-subpath-test-configmap-rgdj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rgdj
Nov  4 10:06:12.527: INFO: Deleting pod "pod-subpath-test-configmap-rgdj" in namespace "subpath-9336"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:06:12.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9336" for this suite.
Nov  4 10:06:18.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:06:18.631: INFO: namespace subpath-9336 deletion completed in 6.09845852s

• [SLOW TEST:28.479 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:06:18.632: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:06:20.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8262" for this suite.
Nov  4 10:06:28.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:06:28.934: INFO: namespace containers-8262 deletion completed in 8.141375634s

• [SLOW TEST:10.303 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:06:28.937: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6229
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 10:06:29.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 version'
Nov  4 10:06:29.143: INFO: stderr: ""
Nov  4 10:06:29.143: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:18:23Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:09:08Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:06:29.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6229" for this suite.
Nov  4 10:06:35.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:06:35.246: INFO: namespace kubectl-6229 deletion completed in 6.099100213s

• [SLOW TEST:6.309 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:06:35.246: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6270
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov  4 10:06:35.398: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6270 /api/v1/namespaces/watch-6270/configmaps/e2e-watch-test-configmap-a 67ab2ef8-ff6b-470f-8462-4ae0238726ae 532233 0 2019-11-04 10:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 10:06:35.398: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6270 /api/v1/namespaces/watch-6270/configmaps/e2e-watch-test-configmap-a 67ab2ef8-ff6b-470f-8462-4ae0238726ae 532233 0 2019-11-04 10:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov  4 10:06:45.406: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6270 /api/v1/namespaces/watch-6270/configmaps/e2e-watch-test-configmap-a 67ab2ef8-ff6b-470f-8462-4ae0238726ae 532250 0 2019-11-04 10:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  4 10:06:45.406: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6270 /api/v1/namespaces/watch-6270/configmaps/e2e-watch-test-configmap-a 67ab2ef8-ff6b-470f-8462-4ae0238726ae 532250 0 2019-11-04 10:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov  4 10:06:55.414: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6270 /api/v1/namespaces/watch-6270/configmaps/e2e-watch-test-configmap-a 67ab2ef8-ff6b-470f-8462-4ae0238726ae 532267 0 2019-11-04 10:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 10:06:55.414: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6270 /api/v1/namespaces/watch-6270/configmaps/e2e-watch-test-configmap-a 67ab2ef8-ff6b-470f-8462-4ae0238726ae 532267 0 2019-11-04 10:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov  4 10:07:05.423: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6270 /api/v1/namespaces/watch-6270/configmaps/e2e-watch-test-configmap-a 67ab2ef8-ff6b-470f-8462-4ae0238726ae 532284 0 2019-11-04 10:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 10:07:05.423: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6270 /api/v1/namespaces/watch-6270/configmaps/e2e-watch-test-configmap-a 67ab2ef8-ff6b-470f-8462-4ae0238726ae 532284 0 2019-11-04 10:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov  4 10:07:15.431: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6270 /api/v1/namespaces/watch-6270/configmaps/e2e-watch-test-configmap-b 8dff320f-5359-4e5e-939c-5eb66b77a0ae 532301 0 2019-11-04 10:07:15 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 10:07:15.432: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6270 /api/v1/namespaces/watch-6270/configmaps/e2e-watch-test-configmap-b 8dff320f-5359-4e5e-939c-5eb66b77a0ae 532301 0 2019-11-04 10:07:15 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov  4 10:07:25.442: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6270 /api/v1/namespaces/watch-6270/configmaps/e2e-watch-test-configmap-b 8dff320f-5359-4e5e-939c-5eb66b77a0ae 532321 0 2019-11-04 10:07:15 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 10:07:25.442: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6270 /api/v1/namespaces/watch-6270/configmaps/e2e-watch-test-configmap-b 8dff320f-5359-4e5e-939c-5eb66b77a0ae 532321 0 2019-11-04 10:07:15 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:07:35.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6270" for this suite.
Nov  4 10:07:41.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:07:41.543: INFO: namespace watch-6270 deletion completed in 6.096194335s

• [SLOW TEST:66.297 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:07:41.544: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9487
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-6583aa32-b28e-447b-8c17-c3e34e17e42d
STEP: Creating a pod to test consume configMaps
Nov  4 10:07:41.699: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3e2b0154-f0e0-4a71-8a9b-8da46a3eefd6" in namespace "projected-9487" to be "success or failure"
Nov  4 10:07:41.712: INFO: Pod "pod-projected-configmaps-3e2b0154-f0e0-4a71-8a9b-8da46a3eefd6": Phase="Pending", Reason="", readiness=false. Elapsed: 13.067262ms
Nov  4 10:07:43.716: INFO: Pod "pod-projected-configmaps-3e2b0154-f0e0-4a71-8a9b-8da46a3eefd6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016571131s
STEP: Saw pod success
Nov  4 10:07:43.716: INFO: Pod "pod-projected-configmaps-3e2b0154-f0e0-4a71-8a9b-8da46a3eefd6" satisfied condition "success or failure"
Nov  4 10:07:43.718: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-3e2b0154-f0e0-4a71-8a9b-8da46a3eefd6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 10:07:43.741: INFO: Waiting for pod pod-projected-configmaps-3e2b0154-f0e0-4a71-8a9b-8da46a3eefd6 to disappear
Nov  4 10:07:43.743: INFO: Pod pod-projected-configmaps-3e2b0154-f0e0-4a71-8a9b-8da46a3eefd6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:07:43.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9487" for this suite.
Nov  4 10:07:49.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:07:49.840: INFO: namespace projected-9487 deletion completed in 6.092400444s

• [SLOW TEST:8.296 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:07:49.841: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-288
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Nov  4 10:07:49.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 create -f - --namespace=kubectl-288'
Nov  4 10:07:50.270: INFO: stderr: ""
Nov  4 10:07:50.270: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 10:07:50.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-288'
Nov  4 10:07:50.419: INFO: stderr: ""
Nov  4 10:07:50.419: INFO: stdout: "update-demo-nautilus-9tggf update-demo-nautilus-tz9rr "
Nov  4 10:07:50.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-9tggf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-288'
Nov  4 10:07:50.505: INFO: stderr: ""
Nov  4 10:07:50.505: INFO: stdout: ""
Nov  4 10:07:50.505: INFO: update-demo-nautilus-9tggf is created but not running
Nov  4 10:07:55.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-288'
Nov  4 10:07:55.593: INFO: stderr: ""
Nov  4 10:07:55.593: INFO: stdout: "update-demo-nautilus-9tggf update-demo-nautilus-tz9rr "
Nov  4 10:07:55.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-9tggf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-288'
Nov  4 10:07:55.676: INFO: stderr: ""
Nov  4 10:07:55.676: INFO: stdout: "true"
Nov  4 10:07:55.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-9tggf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-288'
Nov  4 10:07:55.753: INFO: stderr: ""
Nov  4 10:07:55.753: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 10:07:55.753: INFO: validating pod update-demo-nautilus-9tggf
Nov  4 10:07:55.757: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 10:07:55.757: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 10:07:55.757: INFO: update-demo-nautilus-9tggf is verified up and running
Nov  4 10:07:55.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-tz9rr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-288'
Nov  4 10:07:55.830: INFO: stderr: ""
Nov  4 10:07:55.830: INFO: stdout: "true"
Nov  4 10:07:55.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-nautilus-tz9rr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-288'
Nov  4 10:07:55.908: INFO: stderr: ""
Nov  4 10:07:55.908: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 10:07:55.908: INFO: validating pod update-demo-nautilus-tz9rr
Nov  4 10:07:55.918: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 10:07:55.918: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 10:07:55.918: INFO: update-demo-nautilus-tz9rr is verified up and running
STEP: rolling-update to new replication controller
Nov  4 10:07:55.919: INFO: scanned /root for discovery docs: <nil>
Nov  4 10:07:55.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-288'
Nov  4 10:08:18.412: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  4 10:08:18.412: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 10:08:18.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-288'
Nov  4 10:08:18.506: INFO: stderr: ""
Nov  4 10:08:18.506: INFO: stdout: "update-demo-kitten-sn9lk update-demo-kitten-srtz9 "
Nov  4 10:08:18.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-kitten-sn9lk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-288'
Nov  4 10:08:18.589: INFO: stderr: ""
Nov  4 10:08:18.589: INFO: stdout: "true"
Nov  4 10:08:18.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-kitten-sn9lk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-288'
Nov  4 10:08:18.665: INFO: stderr: ""
Nov  4 10:08:18.665: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  4 10:08:18.665: INFO: validating pod update-demo-kitten-sn9lk
Nov  4 10:08:18.669: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  4 10:08:18.669: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  4 10:08:18.669: INFO: update-demo-kitten-sn9lk is verified up and running
Nov  4 10:08:18.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-kitten-srtz9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-288'
Nov  4 10:08:18.747: INFO: stderr: ""
Nov  4 10:08:18.747: INFO: stdout: "true"
Nov  4 10:08:18.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 get pods update-demo-kitten-srtz9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-288'
Nov  4 10:08:18.832: INFO: stderr: ""
Nov  4 10:08:18.832: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  4 10:08:18.832: INFO: validating pod update-demo-kitten-srtz9
Nov  4 10:08:18.837: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  4 10:08:18.837: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  4 10:08:18.837: INFO: update-demo-kitten-srtz9 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:08:18.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-288" for this suite.
Nov  4 10:08:30.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:08:30.944: INFO: namespace kubectl-288 deletion completed in 12.104278709s

• [SLOW TEST:41.103 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:08:30.945: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-2800
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-2800
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2800
STEP: Deleting pre-stop pod
Nov  4 10:08:40.138: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:08:40.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2800" for this suite.
Nov  4 10:09:24.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:09:24.252: INFO: namespace prestop-2800 deletion completed in 44.098838363s

• [SLOW TEST:53.308 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:09:24.253: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7087
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-7087
STEP: creating replication controller nodeport-test in namespace services-7087
I1104 10:09:24.414160      19 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-7087, replica count: 2
Nov  4 10:09:27.464: INFO: Creating new exec pod
I1104 10:09:27.464533      19 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 10:09:30.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=services-7087 execpodvmjzx -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Nov  4 10:09:30.730: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov  4 10:09:30.730: INFO: stdout: ""
Nov  4 10:09:30.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=services-7087 execpodvmjzx -- /bin/sh -x -c nc -zv -t -w 2 10.32.0.174 80'
Nov  4 10:09:30.990: INFO: stderr: "+ nc -zv -t -w 2 10.32.0.174 80\nConnection to 10.32.0.174 80 port [tcp/http] succeeded!\n"
Nov  4 10:09:30.990: INFO: stdout: ""
Nov  4 10:09:30.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=services-7087 execpodvmjzx -- /bin/sh -x -c nc -zv -t -w 2 10.20.20.4 30402'
Nov  4 10:09:31.235: INFO: stderr: "+ nc -zv -t -w 2 10.20.20.4 30402\nConnection to 10.20.20.4 30402 port [tcp/30402] succeeded!\n"
Nov  4 10:09:31.235: INFO: stdout: ""
Nov  4 10:09:31.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=services-7087 execpodvmjzx -- /bin/sh -x -c nc -zv -t -w 2 10.20.20.5 30402'
Nov  4 10:09:31.464: INFO: stderr: "+ nc -zv -t -w 2 10.20.20.5 30402\nConnection to 10.20.20.5 30402 port [tcp/30402] succeeded!\n"
Nov  4 10:09:31.464: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:09:31.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7087" for this suite.
Nov  4 10:09:37.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:09:37.574: INFO: namespace services-7087 deletion completed in 6.105539812s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.321 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:09:37.575: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7183
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 10:09:37.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 create -f - --namespace=kubectl-7183'
Nov  4 10:09:37.928: INFO: stderr: ""
Nov  4 10:09:37.928: INFO: stdout: "replicationcontroller/redis-master created\n"
Nov  4 10:09:37.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 create -f - --namespace=kubectl-7183'
Nov  4 10:09:38.135: INFO: stderr: ""
Nov  4 10:09:38.135: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  4 10:09:39.138: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 10:09:39.138: INFO: Found 0 / 1
Nov  4 10:09:40.138: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 10:09:40.138: INFO: Found 0 / 1
Nov  4 10:09:41.138: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 10:09:41.138: INFO: Found 1 / 1
Nov  4 10:09:41.138: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  4 10:09:41.141: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 10:09:41.141: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  4 10:09:41.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 describe pod redis-master-t6vpw --namespace=kubectl-7183'
Nov  4 10:09:41.243: INFO: stderr: ""
Nov  4 10:09:41.243: INFO: stdout: "Name:         redis-master-t6vpw\nNamespace:    kubectl-7183\nPriority:     0\nNode:         k8s-1/10.20.20.4\nStart Time:   Mon, 04 Nov 2019 10:09:37 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.33.2.39\nIPs:\n  IP:           10.33.2.39\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://78e9bf0eb9a291bf0ac9c77934b680f4214c69365de325feda6ea821c0dab215\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 04 Nov 2019 10:09:39 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-g4d2g (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-g4d2g:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-g4d2g\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From               Message\n  ----    ------     ----       ----               -------\n  Normal  Scheduled  <unknown>  default-scheduler  Successfully assigned kubectl-7183/redis-master-t6vpw to k8s-1\n  Normal  Pulled     2s         kubelet, k8s-1     Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    2s         kubelet, k8s-1     Created container redis-master\n  Normal  Started    2s         kubelet, k8s-1     Started container redis-master\n"
Nov  4 10:09:41.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 describe rc redis-master --namespace=kubectl-7183'
Nov  4 10:09:41.345: INFO: stderr: ""
Nov  4 10:09:41.345: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-7183\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  InjectionSkipped  4s    linkerd-proxy-injector  Linkerd sidecar proxy injection skipped: neither the namespace nor the pod have the annotation \"linkerd.io/inject:enabled\"\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-t6vpw\n"
Nov  4 10:09:41.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 describe service redis-master --namespace=kubectl-7183'
Nov  4 10:09:41.438: INFO: stderr: ""
Nov  4 10:09:41.438: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-7183\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.32.0.165\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.33.2.39:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov  4 10:09:41.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 describe node k8s-1'
Nov  4 10:09:41.549: INFO: stderr: ""
Nov  4 10:09:41.549: INFO: stdout: "Name:               k8s-1\nRoles:              worker\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=k8s-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/worker=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"d2:a9:96:29:78:d8\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.20.20.4\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 31 Oct 2019 18:57:32 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 04 Nov 2019 10:09:22 +0000   Thu, 31 Oct 2019 18:57:32 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 04 Nov 2019 10:09:22 +0000   Thu, 31 Oct 2019 18:57:32 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 04 Nov 2019 10:09:22 +0000   Thu, 31 Oct 2019 18:57:32 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 04 Nov 2019 10:09:22 +0000   Thu, 31 Oct 2019 19:58:32 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.20.20.4\n  Hostname:    k8s-1\nCapacity:\n cpu:                1\n ephemeral-storage:  50633164Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3941368Ki\n pods:               110\nAllocatable:\n cpu:                1\n ephemeral-storage:  46663523866\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3838968Ki\n pods:               110\nSystem Info:\n Machine ID:                 cc2068ba24d3480bbedd969acc9f4cd8\n System UUID:                CC2068BA-24D3-480B-BEDD-969ACC9F4CD8\n Boot ID:                    d09220bc-d25b-4e25-a20a-37bd1af80e1f\n Kernel Version:             4.15.0-38-generic\n OS Image:                   Ubuntu 18.04.1 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.10\n Kubelet Version:            v1.16.1\n Kube-Proxy Version:         v1.16.1\nPodCIDR:                     10.33.2.0/24\nPodCIDRs:                    10.33.2.0/24\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                kube-flannel-ds-amd64-9ldh9                                100m (10%)    100m (10%)  50Mi (1%)        50Mi (1%)      42m\n  kube-system                traefik-ingress-controller-m7ffw                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\n  kubectl-7183               redis-master-t6vpw                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  sonobuoy                   sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         96m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-4df82ea1941d4274-9v4q5    0 (0%)        0 (0%)      0 (0%)           0 (0%)         95m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                100m (10%)  100m (10%)\n  memory             50Mi (1%)   50Mi (1%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Nov  4 10:09:41.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 describe namespace kubectl-7183'
Nov  4 10:09:41.640: INFO: stderr: ""
Nov  4 10:09:41.640: INFO: stdout: "Name:         kubectl-7183\nLabels:       e2e-framework=kubectl\n              e2e-run=4865970f-d2d3-4475-9ffb-48eaf5ccf058\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:09:41.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7183" for this suite.
Nov  4 10:09:53.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:09:53.755: INFO: namespace kubectl-7183 deletion completed in 12.110651341s

• [SLOW TEST:16.181 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:09:53.756: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7272
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 10:09:53.903: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8267b034-b066-4477-abae-9b8caf7a3cf4" in namespace "projected-7272" to be "success or failure"
Nov  4 10:09:53.916: INFO: Pod "downwardapi-volume-8267b034-b066-4477-abae-9b8caf7a3cf4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.864966ms
Nov  4 10:09:55.920: INFO: Pod "downwardapi-volume-8267b034-b066-4477-abae-9b8caf7a3cf4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016522645s
STEP: Saw pod success
Nov  4 10:09:55.920: INFO: Pod "downwardapi-volume-8267b034-b066-4477-abae-9b8caf7a3cf4" satisfied condition "success or failure"
Nov  4 10:09:55.923: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-8267b034-b066-4477-abae-9b8caf7a3cf4 container client-container: <nil>
STEP: delete the pod
Nov  4 10:09:55.947: INFO: Waiting for pod downwardapi-volume-8267b034-b066-4477-abae-9b8caf7a3cf4 to disappear
Nov  4 10:09:55.951: INFO: Pod downwardapi-volume-8267b034-b066-4477-abae-9b8caf7a3cf4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:09:55.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7272" for this suite.
Nov  4 10:10:01.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:10:02.053: INFO: namespace projected-7272 deletion completed in 6.098139108s

• [SLOW TEST:8.297 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:10:02.054: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1990
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1990
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-1990
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1990
Nov  4 10:10:02.229: INFO: Found 0 stateful pods, waiting for 1
Nov  4 10:10:12.233: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov  4 10:10:12.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-1990 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 10:10:12.493: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 10:10:12.493: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 10:10:12.494: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 10:10:12.497: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  4 10:10:22.500: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 10:10:22.500: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 10:10:22.515: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 10:10:22.515: INFO: ss-0  k8s-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  }]
Nov  4 10:10:22.515: INFO: 
Nov  4 10:10:22.515: INFO: StatefulSet ss has not reached scale 3, at 1
Nov  4 10:10:23.529: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997484194s
Nov  4 10:10:24.532: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.983488875s
Nov  4 10:10:25.536: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.980045759s
Nov  4 10:10:26.540: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.976118481s
Nov  4 10:10:27.544: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972515724s
Nov  4 10:10:28.547: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.968487427s
Nov  4 10:10:29.551: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.965000745s
Nov  4 10:10:30.554: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.961618692s
Nov  4 10:10:31.558: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.901575ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1990
Nov  4 10:10:32.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-1990 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 10:10:32.823: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 10:10:32.823: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 10:10:32.823: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 10:10:32.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-1990 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 10:10:33.053: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov  4 10:10:33.053: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 10:10:33.053: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 10:10:33.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-1990 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 10:10:33.286: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov  4 10:10:33.286: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 10:10:33.286: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 10:10:33.289: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 10:10:33.289: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 10:10:33.289: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov  4 10:10:33.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-1990 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 10:10:33.509: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 10:10:33.509: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 10:10:33.509: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 10:10:33.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-1990 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 10:10:33.757: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 10:10:33.757: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 10:10:33.757: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 10:10:33.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 exec --namespace=statefulset-1990 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 10:10:33.990: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 10:10:33.990: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 10:10:33.990: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 10:10:33.990: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 10:10:33.992: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov  4 10:10:43.998: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 10:10:43.998: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 10:10:43.998: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 10:10:44.010: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 10:10:44.010: INFO: ss-0  k8s-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  }]
Nov  4 10:10:44.010: INFO: ss-1  k8s-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:44.010: INFO: ss-2  k8s-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:44.010: INFO: 
Nov  4 10:10:44.010: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  4 10:10:45.014: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 10:10:45.014: INFO: ss-0  k8s-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  }]
Nov  4 10:10:45.014: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:45.014: INFO: ss-2  k8s-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:45.014: INFO: 
Nov  4 10:10:45.014: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  4 10:10:46.017: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 10:10:46.017: INFO: ss-0  k8s-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  }]
Nov  4 10:10:46.017: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:46.018: INFO: ss-2  k8s-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:46.018: INFO: 
Nov  4 10:10:46.018: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  4 10:10:47.021: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 10:10:47.021: INFO: ss-0  k8s-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  }]
Nov  4 10:10:47.021: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:47.021: INFO: ss-2  k8s-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:47.021: INFO: 
Nov  4 10:10:47.021: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  4 10:10:48.025: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 10:10:48.025: INFO: ss-0  k8s-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  }]
Nov  4 10:10:48.025: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:48.025: INFO: ss-2  k8s-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:48.025: INFO: 
Nov  4 10:10:48.025: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  4 10:10:49.030: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 10:10:49.030: INFO: ss-0  k8s-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  }]
Nov  4 10:10:49.031: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:49.031: INFO: ss-2  k8s-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:49.031: INFO: 
Nov  4 10:10:49.031: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  4 10:10:50.035: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 10:10:50.035: INFO: ss-0  k8s-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  }]
Nov  4 10:10:50.035: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:50.035: INFO: ss-2  k8s-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:50.035: INFO: 
Nov  4 10:10:50.035: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  4 10:10:51.039: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 10:10:51.039: INFO: ss-0  k8s-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:02 +0000 UTC  }]
Nov  4 10:10:51.039: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:51.039: INFO: ss-2  k8s-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 10:10:22 +0000 UTC  }]
Nov  4 10:10:51.039: INFO: 
Nov  4 10:10:51.039: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  4 10:10:52.042: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.965566941s
Nov  4 10:10:53.046: INFO: Verifying statefulset ss doesn't scale past 0 for another 962.282809ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1990
Nov  4 10:10:54.049: INFO: Scaling statefulset ss to 0
Nov  4 10:10:54.057: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 10:10:54.060: INFO: Deleting all statefulset in ns statefulset-1990
Nov  4 10:10:54.062: INFO: Scaling statefulset ss to 0
Nov  4 10:10:54.069: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 10:10:54.072: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:10:54.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1990" for this suite.
Nov  4 10:11:00.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:11:00.193: INFO: namespace statefulset-1990 deletion completed in 6.098011599s

• [SLOW TEST:58.140 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:11:00.195: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-141
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Nov  4 10:11:00.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-141 -- logs-generator --log-lines-total 100 --run-duration 20s'
Nov  4 10:11:00.442: INFO: stderr: ""
Nov  4 10:11:00.442: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Nov  4 10:11:00.442: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Nov  4 10:11:00.442: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-141" to be "running and ready, or succeeded"
Nov  4 10:11:00.445: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.384435ms
Nov  4 10:11:02.448: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.005596515s
Nov  4 10:11:02.448: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Nov  4 10:11:02.448: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Nov  4 10:11:02.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 logs logs-generator logs-generator --namespace=kubectl-141'
Nov  4 10:11:02.546: INFO: stderr: ""
Nov  4 10:11:02.546: INFO: stdout: "I1104 10:11:01.051284       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/vg6t 308\nI1104 10:11:01.251574       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/wngm 450\nI1104 10:11:01.451441       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/6vb 350\nI1104 10:11:01.651467       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/mjc 474\nI1104 10:11:01.851434       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/xmmh 342\nI1104 10:11:02.051512       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/kxsv 465\nI1104 10:11:02.251418       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/nbf 356\nI1104 10:11:02.451495       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/tth 432\n"
STEP: limiting log lines
Nov  4 10:11:02.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 logs logs-generator logs-generator --namespace=kubectl-141 --tail=1'
Nov  4 10:11:02.629: INFO: stderr: ""
Nov  4 10:11:02.629: INFO: stdout: "I1104 10:11:02.451495       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/tth 432\n"
STEP: limiting log bytes
Nov  4 10:11:02.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 logs logs-generator logs-generator --namespace=kubectl-141 --limit-bytes=1'
Nov  4 10:11:02.718: INFO: stderr: ""
Nov  4 10:11:02.718: INFO: stdout: "I"
STEP: exposing timestamps
Nov  4 10:11:02.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 logs logs-generator logs-generator --namespace=kubectl-141 --tail=1 --timestamps'
Nov  4 10:11:02.805: INFO: stderr: ""
Nov  4 10:11:02.805: INFO: stdout: "2019-11-04T10:11:02.651528447Z I1104 10:11:02.651436       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/gs9 345\n"
STEP: restricting to a time range
Nov  4 10:11:05.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 logs logs-generator logs-generator --namespace=kubectl-141 --since=1s'
Nov  4 10:11:05.397: INFO: stderr: ""
Nov  4 10:11:05.397: INFO: stdout: "I1104 10:11:04.451441       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/j4k 286\nI1104 10:11:04.651542       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/992k 306\nI1104 10:11:04.851460       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/c78 549\nI1104 10:11:05.051439       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/wxc 282\nI1104 10:11:05.251471       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/rzjn 506\n"
Nov  4 10:11:05.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 logs logs-generator logs-generator --namespace=kubectl-141 --since=24h'
Nov  4 10:11:05.486: INFO: stderr: ""
Nov  4 10:11:05.486: INFO: stdout: "I1104 10:11:01.051284       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/vg6t 308\nI1104 10:11:01.251574       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/wngm 450\nI1104 10:11:01.451441       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/6vb 350\nI1104 10:11:01.651467       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/mjc 474\nI1104 10:11:01.851434       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/xmmh 342\nI1104 10:11:02.051512       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/kxsv 465\nI1104 10:11:02.251418       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/nbf 356\nI1104 10:11:02.451495       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/tth 432\nI1104 10:11:02.651436       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/gs9 345\nI1104 10:11:02.851549       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/f7jf 447\nI1104 10:11:03.051522       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/zr9 343\nI1104 10:11:03.251568       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/66k 205\nI1104 10:11:03.451525       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/8nml 469\nI1104 10:11:03.651451       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/mrmc 511\nI1104 10:11:03.851430       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/rnt7 507\nI1104 10:11:04.051392       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/ksv 375\nI1104 10:11:04.251458       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/vbhl 563\nI1104 10:11:04.451441       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/j4k 286\nI1104 10:11:04.651542       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/992k 306\nI1104 10:11:04.851460       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/c78 549\nI1104 10:11:05.051439       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/wxc 282\nI1104 10:11:05.251471       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/rzjn 506\nI1104 10:11:05.451450       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/tc8 257\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Nov  4 10:11:05.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete pod logs-generator --namespace=kubectl-141'
Nov  4 10:11:11.656: INFO: stderr: ""
Nov  4 10:11:11.656: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:11:11.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-141" for this suite.
Nov  4 10:11:17.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:11:17.760: INFO: namespace kubectl-141 deletion completed in 6.099433133s

• [SLOW TEST:17.565 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:11:17.761: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5241
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Nov  4 10:11:17.903: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
Nov  4 10:11:26.477: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:11:44.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5241" for this suite.
Nov  4 10:11:50.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:11:50.525: INFO: namespace crd-publish-openapi-5241 deletion completed in 6.090535836s

• [SLOW TEST:32.764 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:11:50.525: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1071
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 10:11:50.678: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-856562f7-a69a-49f3-95bd-2bf734456ada" in namespace "security-context-test-1071" to be "success or failure"
Nov  4 10:11:50.683: INFO: Pod "busybox-readonly-false-856562f7-a69a-49f3-95bd-2bf734456ada": Phase="Pending", Reason="", readiness=false. Elapsed: 5.712705ms
Nov  4 10:11:52.686: INFO: Pod "busybox-readonly-false-856562f7-a69a-49f3-95bd-2bf734456ada": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008208776s
Nov  4 10:11:52.686: INFO: Pod "busybox-readonly-false-856562f7-a69a-49f3-95bd-2bf734456ada" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:11:52.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1071" for this suite.
Nov  4 10:11:58.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:11:58.797: INFO: namespace security-context-test-1071 deletion completed in 6.107198574s

• [SLOW TEST:8.272 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:11:58.798: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-934
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Nov  4 10:11:58.939: INFO: namespace kubectl-934
Nov  4 10:11:58.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 create -f - --namespace=kubectl-934'
Nov  4 10:11:59.257: INFO: stderr: ""
Nov  4 10:11:59.257: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  4 10:12:00.266: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 10:12:00.266: INFO: Found 0 / 1
Nov  4 10:12:01.261: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 10:12:01.261: INFO: Found 1 / 1
Nov  4 10:12:01.261: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  4 10:12:01.264: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 10:12:01.264: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  4 10:12:01.264: INFO: wait on redis-master startup in kubectl-934 
Nov  4 10:12:01.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 logs redis-master-zf2dw redis-master --namespace=kubectl-934'
Nov  4 10:12:01.350: INFO: stderr: ""
Nov  4 10:12:01.350: INFO: stdout: "1:C 04 Nov 2019 10:11:59.890 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 04 Nov 2019 10:11:59.890 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 04 Nov 2019 10:11:59.890 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 04 Nov 2019 10:11:59.891 * Running mode=standalone, port=6379.\n1:M 04 Nov 2019 10:11:59.892 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Nov 2019 10:11:59.892 # Server initialized\n1:M 04 Nov 2019 10:11:59.892 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Nov 2019 10:11:59.892 * Ready to accept connections\n"
STEP: exposing RC
Nov  4 10:12:01.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-934'
Nov  4 10:12:01.450: INFO: stderr: ""
Nov  4 10:12:01.450: INFO: stdout: "service/rm2 exposed\n"
Nov  4 10:12:01.454: INFO: Service rm2 in namespace kubectl-934 found.
STEP: exposing service
Nov  4 10:12:03.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-934'
Nov  4 10:12:03.571: INFO: stderr: ""
Nov  4 10:12:03.571: INFO: stdout: "service/rm3 exposed\n"
Nov  4 10:12:03.574: INFO: Service rm3 in namespace kubectl-934 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:12:05.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-934" for this suite.
Nov  4 10:12:33.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:12:33.703: INFO: namespace kubectl-934 deletion completed in 28.11997181s

• [SLOW TEST:34.905 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:12:33.704: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-727
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Nov  4 10:12:33.846: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov  4 10:12:40.894: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:12:40.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-727" for this suite.
Nov  4 10:12:46.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:12:47.002: INFO: namespace pods-727 deletion completed in 6.100051034s

• [SLOW TEST:13.298 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:12:47.003: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2696
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 10:12:47.140: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:12:52.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2696" for this suite.
Nov  4 10:12:58.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:12:58.883: INFO: namespace custom-resource-definition-2696 deletion completed in 6.386852687s

• [SLOW TEST:11.880 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:12:58.884: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7199
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 10:12:59.916: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708459179, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708459179, loc:(*time.Location)(0x84c02a0)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-86d95b659d\""}}, CollisionCount:(*int32)(nil)}
Nov  4 10:13:01.919: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708459179, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708459179, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708459179, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708459179, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 10:13:04.927: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:13:04.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7199" for this suite.
Nov  4 10:13:10.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:13:11.062: INFO: namespace webhook-7199 deletion completed in 6.098022862s
STEP: Destroying namespace "webhook-7199-markers" for this suite.
Nov  4 10:13:17.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:13:17.161: INFO: namespace webhook-7199-markers deletion completed in 6.098351268s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.290 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:13:17.175: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8104
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:13:38.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8104" for this suite.
Nov  4 10:13:44.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:13:44.766: INFO: namespace container-runtime-8104 deletion completed in 6.130632772s

• [SLOW TEST:27.592 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:13:44.767: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8483
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-3a4be68a-c827-4b08-af1a-7d9369289aec
STEP: Creating configMap with name cm-test-opt-upd-a5209442-689f-4fbd-82d8-89774585f755
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-3a4be68a-c827-4b08-af1a-7d9369289aec
STEP: Updating configmap cm-test-opt-upd-a5209442-689f-4fbd-82d8-89774585f755
STEP: Creating configMap with name cm-test-opt-create-18b132ad-8652-4592-8fd5-aeb5ac3f71d0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:13:51.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8483" for this suite.
Nov  4 10:14:19.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:14:19.109: INFO: namespace configmap-8483 deletion completed in 28.099304779s

• [SLOW TEST:34.342 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:14:19.110: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2711
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-ea91c794-f959-4156-a61f-d7155dc14b77
STEP: Creating a pod to test consume configMaps
Nov  4 10:14:19.269: INFO: Waiting up to 5m0s for pod "pod-configmaps-4fcf1e1f-d033-40d8-9bca-0af664114613" in namespace "configmap-2711" to be "success or failure"
Nov  4 10:14:19.273: INFO: Pod "pod-configmaps-4fcf1e1f-d033-40d8-9bca-0af664114613": Phase="Pending", Reason="", readiness=false. Elapsed: 3.406367ms
Nov  4 10:14:21.277: INFO: Pod "pod-configmaps-4fcf1e1f-d033-40d8-9bca-0af664114613": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007468166s
STEP: Saw pod success
Nov  4 10:14:21.277: INFO: Pod "pod-configmaps-4fcf1e1f-d033-40d8-9bca-0af664114613" satisfied condition "success or failure"
Nov  4 10:14:21.280: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-4fcf1e1f-d033-40d8-9bca-0af664114613 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 10:14:21.300: INFO: Waiting for pod pod-configmaps-4fcf1e1f-d033-40d8-9bca-0af664114613 to disappear
Nov  4 10:14:21.309: INFO: Pod pod-configmaps-4fcf1e1f-d033-40d8-9bca-0af664114613 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:14:21.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2711" for this suite.
Nov  4 10:14:27.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:14:27.414: INFO: namespace configmap-2711 deletion completed in 6.101300765s

• [SLOW TEST:8.304 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:14:27.414: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6334
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 10:14:27.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-6334'
Nov  4 10:14:27.707: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 10:14:27.708: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Nov  4 10:14:29.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete deployment e2e-test-httpd-deployment --namespace=kubectl-6334'
Nov  4 10:14:29.815: INFO: stderr: ""
Nov  4 10:14:29.815: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:14:29.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6334" for this suite.
Nov  4 10:14:57.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:14:57.920: INFO: namespace kubectl-6334 deletion completed in 28.100994503s

• [SLOW TEST:30.506 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:14:57.920: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9962
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 10:14:58.075: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c8e375dc-182c-4579-b5b5-7a073cb96126" in namespace "projected-9962" to be "success or failure"
Nov  4 10:14:58.078: INFO: Pod "downwardapi-volume-c8e375dc-182c-4579-b5b5-7a073cb96126": Phase="Pending", Reason="", readiness=false. Elapsed: 3.257054ms
Nov  4 10:15:00.081: INFO: Pod "downwardapi-volume-c8e375dc-182c-4579-b5b5-7a073cb96126": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006183546s
STEP: Saw pod success
Nov  4 10:15:00.082: INFO: Pod "downwardapi-volume-c8e375dc-182c-4579-b5b5-7a073cb96126" satisfied condition "success or failure"
Nov  4 10:15:00.084: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-c8e375dc-182c-4579-b5b5-7a073cb96126 container client-container: <nil>
STEP: delete the pod
Nov  4 10:15:00.103: INFO: Waiting for pod downwardapi-volume-c8e375dc-182c-4579-b5b5-7a073cb96126 to disappear
Nov  4 10:15:00.106: INFO: Pod downwardapi-volume-c8e375dc-182c-4579-b5b5-7a073cb96126 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:15:00.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9962" for this suite.
Nov  4 10:15:06.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:15:06.211: INFO: namespace projected-9962 deletion completed in 6.101633888s

• [SLOW TEST:8.291 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:15:06.212: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4562
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 10:15:06.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-4562'
Nov  4 10:15:06.437: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 10:15:06.437: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Nov  4 10:15:08.445: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-2xp5g]
Nov  4 10:15:08.446: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-2xp5g" in namespace "kubectl-4562" to be "running and ready"
Nov  4 10:15:08.448: INFO: Pod "e2e-test-httpd-rc-2xp5g": Phase="Running", Reason="", readiness=true. Elapsed: 2.198523ms
Nov  4 10:15:08.448: INFO: Pod "e2e-test-httpd-rc-2xp5g" satisfied condition "running and ready"
Nov  4 10:15:08.448: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-2xp5g]
Nov  4 10:15:08.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 logs rc/e2e-test-httpd-rc --namespace=kubectl-4562'
Nov  4 10:15:08.545: INFO: stderr: ""
Nov  4 10:15:08.545: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.33.2.55. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.33.2.55. Set the 'ServerName' directive globally to suppress this message\n[Mon Nov 04 10:15:07.053170 2019] [mpm_event:notice] [pid 1:tid 140276896025448] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Mon Nov 04 10:15:07.053199 2019] [core:notice] [pid 1:tid 140276896025448] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Nov  4 10:15:08.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete rc e2e-test-httpd-rc --namespace=kubectl-4562'
Nov  4 10:15:08.634: INFO: stderr: ""
Nov  4 10:15:08.634: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:15:08.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4562" for this suite.
Nov  4 10:15:14.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:15:14.740: INFO: namespace kubectl-4562 deletion completed in 6.101209056s

• [SLOW TEST:8.528 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:15:14.740: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1803
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-e07dfcb5-4dbe-46d0-a7f0-32ea7b160a21
STEP: Creating a pod to test consume configMaps
Nov  4 10:15:14.900: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9a59079d-a297-4289-874c-d4748842ef8f" in namespace "projected-1803" to be "success or failure"
Nov  4 10:15:15.109: INFO: Pod "pod-projected-configmaps-9a59079d-a297-4289-874c-d4748842ef8f": Phase="Pending", Reason="", readiness=false. Elapsed: 208.813026ms
Nov  4 10:15:17.111: INFO: Pod "pod-projected-configmaps-9a59079d-a297-4289-874c-d4748842ef8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.211448596s
STEP: Saw pod success
Nov  4 10:15:17.111: INFO: Pod "pod-projected-configmaps-9a59079d-a297-4289-874c-d4748842ef8f" satisfied condition "success or failure"
Nov  4 10:15:17.114: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-9a59079d-a297-4289-874c-d4748842ef8f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 10:15:17.133: INFO: Waiting for pod pod-projected-configmaps-9a59079d-a297-4289-874c-d4748842ef8f to disappear
Nov  4 10:15:17.141: INFO: Pod pod-projected-configmaps-9a59079d-a297-4289-874c-d4748842ef8f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:15:17.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1803" for this suite.
Nov  4 10:15:23.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:15:23.241: INFO: namespace projected-1803 deletion completed in 6.095751758s

• [SLOW TEST:8.501 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:15:23.242: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7522
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  4 10:15:25.404: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:15:25.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7522" for this suite.
Nov  4 10:15:31.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:15:31.549: INFO: namespace container-runtime-7522 deletion completed in 6.121675733s

• [SLOW TEST:8.307 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:15:31.549: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7533
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 10:15:31.757: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ffa2a9ef-7957-42e3-b319-f514fd6de3b5" in namespace "projected-7533" to be "success or failure"
Nov  4 10:15:31.759: INFO: Pod "downwardapi-volume-ffa2a9ef-7957-42e3-b319-f514fd6de3b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069722ms
Nov  4 10:15:33.762: INFO: Pod "downwardapi-volume-ffa2a9ef-7957-42e3-b319-f514fd6de3b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00522376s
STEP: Saw pod success
Nov  4 10:15:33.762: INFO: Pod "downwardapi-volume-ffa2a9ef-7957-42e3-b319-f514fd6de3b5" satisfied condition "success or failure"
Nov  4 10:15:33.765: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-ffa2a9ef-7957-42e3-b319-f514fd6de3b5 container client-container: <nil>
STEP: delete the pod
Nov  4 10:15:33.785: INFO: Waiting for pod downwardapi-volume-ffa2a9ef-7957-42e3-b319-f514fd6de3b5 to disappear
Nov  4 10:15:33.787: INFO: Pod downwardapi-volume-ffa2a9ef-7957-42e3-b319-f514fd6de3b5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:15:33.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7533" for this suite.
Nov  4 10:15:39.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:15:39.895: INFO: namespace projected-7533 deletion completed in 6.103713576s

• [SLOW TEST:8.346 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:15:39.896: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-223
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1104 10:15:50.110861      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  4 10:15:50.110: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:15:50.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-223" for this suite.
Nov  4 10:15:56.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:15:56.559: INFO: namespace gc-223 deletion completed in 6.444677246s

• [SLOW TEST:16.663 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:15:56.559: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-826
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3229
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5382
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:16:02.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-826" for this suite.
Nov  4 10:16:09.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:16:09.131: INFO: namespace namespaces-826 deletion completed in 6.128110561s
STEP: Destroying namespace "nsdeletetest-3229" for this suite.
Nov  4 10:16:09.133: INFO: Namespace nsdeletetest-3229 was already deleted
STEP: Destroying namespace "nsdeletetest-5382" for this suite.
Nov  4 10:16:15.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:16:15.240: INFO: namespace nsdeletetest-5382 deletion completed in 6.106520429s

• [SLOW TEST:18.681 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:16:15.241: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5168
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 10:16:15.390: INFO: Creating deployment "test-recreate-deployment"
Nov  4 10:16:15.396: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov  4 10:16:15.404: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Nov  4 10:16:17.410: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov  4 10:16:17.413: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708459375, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708459375, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708459375, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708459375, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 10:16:19.416: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov  4 10:16:19.426: INFO: Updating deployment test-recreate-deployment
Nov  4 10:16:19.426: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 10:16:19.551: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-5168 /apis/apps/v1/namespaces/deployment-5168/deployments/test-recreate-deployment 0b779fee-4f5e-492a-8e34-de03d09b1882 534662 2 2019-11-04 10:16:15 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002fe2f88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-11-04 10:16:19 +0000 UTC,LastTransitionTime:2019-11-04 10:16:19 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-11-04 10:16:19 +0000 UTC,LastTransitionTime:2019-11-04 10:16:15 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Nov  4 10:16:19.558: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-5168 /apis/apps/v1/namespaces/deployment-5168/replicasets/test-recreate-deployment-5f94c574ff c5e2b9cc-9095-46c4-9f81-347e7b7b5e00 534660 1 2019-11-04 10:16:19 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 0b779fee-4f5e-492a-8e34-de03d09b1882 0xc002fe3617 0xc002fe3618}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002fe3678 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 10:16:19.558: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov  4 10:16:19.558: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-5168 /apis/apps/v1/namespaces/deployment-5168/replicasets/test-recreate-deployment-68fc85c7bb a613b766-83e3-4605-87a2-4ff73a14911d 534650 2 2019-11-04 10:16:15 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 0b779fee-4f5e-492a-8e34-de03d09b1882 0xc002fe36e7 0xc002fe36e8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002fe3748 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 10:16:19.561: INFO: Pod "test-recreate-deployment-5f94c574ff-szfhq" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-szfhq test-recreate-deployment-5f94c574ff- deployment-5168 /api/v1/namespaces/deployment-5168/pods/test-recreate-deployment-5f94c574ff-szfhq af070226-1147-47df-a1c0-191af2796342 534663 0 2019-11-04 10:16:19 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff c5e2b9cc-9095-46c4-9f81-347e7b7b5e00 0xc002fe3c07 0xc002fe3c08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6ntk9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6ntk9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6ntk9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:16:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:16:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:16:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 10:16:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 10:16:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:16:19.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5168" for this suite.
Nov  4 10:16:25.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:16:25.677: INFO: namespace deployment-5168 deletion completed in 6.111739158s

• [SLOW TEST:10.437 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:16:25.678: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6757
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:16:29.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6757" for this suite.
Nov  4 10:16:35.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:16:35.947: INFO: namespace kubelet-test-6757 deletion completed in 6.1024521s

• [SLOW TEST:10.269 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:16:35.947: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-7445
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:16:36.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-7445" for this suite.
Nov  4 10:16:42.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:16:42.192: INFO: namespace tables-7445 deletion completed in 6.101156389s

• [SLOW TEST:6.245 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:16:42.193: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4447
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:16:44.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4447" for this suite.
Nov  4 10:17:34.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:17:34.473: INFO: namespace kubelet-test-4447 deletion completed in 50.110734135s

• [SLOW TEST:52.280 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:17:34.473: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-4417
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-4417
I1104 10:17:34.617909      19 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4417, replica count: 1
I1104 10:17:35.668257      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1104 10:17:36.668522      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 10:17:36.784: INFO: Created: latency-svc-zvm7b
Nov  4 10:17:36.792: INFO: Got endpoints: latency-svc-zvm7b [24.187911ms]
Nov  4 10:17:36.854: INFO: Created: latency-svc-p85q7
Nov  4 10:17:36.856: INFO: Created: latency-svc-5sqtt
Nov  4 10:17:36.856: INFO: Got endpoints: latency-svc-5sqtt [63.803537ms]
Nov  4 10:17:36.859: INFO: Got endpoints: latency-svc-p85q7 [64.590979ms]
Nov  4 10:17:36.878: INFO: Created: latency-svc-7kbfc
Nov  4 10:17:36.888: INFO: Got endpoints: latency-svc-7kbfc [95.098901ms]
Nov  4 10:17:36.901: INFO: Created: latency-svc-7jlhv
Nov  4 10:17:36.903: INFO: Created: latency-svc-g8s57
Nov  4 10:17:36.905: INFO: Got endpoints: latency-svc-7jlhv [111.708737ms]
Nov  4 10:17:36.908: INFO: Got endpoints: latency-svc-g8s57 [115.079709ms]
Nov  4 10:17:36.915: INFO: Created: latency-svc-r9x6w
Nov  4 10:17:36.931: INFO: Created: latency-svc-t9g2q
Nov  4 10:17:36.934: INFO: Got endpoints: latency-svc-r9x6w [140.230099ms]
Nov  4 10:17:37.565: INFO: Got endpoints: latency-svc-t9g2q [771.176982ms]
Nov  4 10:17:37.569: INFO: Created: latency-svc-bzbj5
Nov  4 10:17:37.576: INFO: Created: latency-svc-ll2lz
Nov  4 10:17:37.583: INFO: Created: latency-svc-cdnc4
Nov  4 10:17:37.585: INFO: Got endpoints: latency-svc-bzbj5 [791.725311ms]
Nov  4 10:17:37.588: INFO: Got endpoints: latency-svc-ll2lz [794.763292ms]
Nov  4 10:17:37.596: INFO: Got endpoints: latency-svc-cdnc4 [801.782907ms]
Nov  4 10:17:37.604: INFO: Created: latency-svc-d46kh
Nov  4 10:17:37.612: INFO: Got endpoints: latency-svc-d46kh [817.800282ms]
Nov  4 10:17:37.616: INFO: Created: latency-svc-79b82
Nov  4 10:17:37.619: INFO: Got endpoints: latency-svc-79b82 [824.821935ms]
Nov  4 10:17:37.631: INFO: Created: latency-svc-p58fk
Nov  4 10:17:37.638: INFO: Got endpoints: latency-svc-p58fk [843.859535ms]
Nov  4 10:17:37.646: INFO: Created: latency-svc-zfrdl
Nov  4 10:17:37.652: INFO: Got endpoints: latency-svc-zfrdl [857.952768ms]
Nov  4 10:17:37.658: INFO: Created: latency-svc-h67cv
Nov  4 10:17:37.664: INFO: Got endpoints: latency-svc-h67cv [869.875459ms]
Nov  4 10:17:37.671: INFO: Created: latency-svc-4xr58
Nov  4 10:17:37.673: INFO: Got endpoints: latency-svc-4xr58 [816.319187ms]
Nov  4 10:17:37.687: INFO: Created: latency-svc-5m769
Nov  4 10:17:37.692: INFO: Got endpoints: latency-svc-5m769 [832.994438ms]
Nov  4 10:17:37.700: INFO: Created: latency-svc-k89cz
Nov  4 10:17:37.703: INFO: Got endpoints: latency-svc-k89cz [814.921661ms]
Nov  4 10:17:37.713: INFO: Created: latency-svc-vj5jz
Nov  4 10:17:37.715: INFO: Got endpoints: latency-svc-vj5jz [810.234415ms]
Nov  4 10:17:37.725: INFO: Created: latency-svc-gw5nq
Nov  4 10:17:37.729: INFO: Got endpoints: latency-svc-gw5nq [820.242494ms]
Nov  4 10:17:37.733: INFO: Created: latency-svc-m6gqz
Nov  4 10:17:37.739: INFO: Got endpoints: latency-svc-m6gqz [805.58003ms]
Nov  4 10:17:37.744: INFO: Created: latency-svc-rd5hx
Nov  4 10:17:37.751: INFO: Got endpoints: latency-svc-rd5hx [186.265657ms]
Nov  4 10:17:37.755: INFO: Created: latency-svc-rgrb5
Nov  4 10:17:37.759: INFO: Created: latency-svc-hk2zk
Nov  4 10:17:37.760: INFO: Got endpoints: latency-svc-rgrb5 [174.13634ms]
Nov  4 10:17:37.769: INFO: Created: latency-svc-mq9jk
Nov  4 10:17:37.782: INFO: Created: latency-svc-j8g7x
Nov  4 10:17:37.783: INFO: Got endpoints: latency-svc-hk2zk [194.317607ms]
Nov  4 10:17:37.784: INFO: Got endpoints: latency-svc-mq9jk [188.090252ms]
Nov  4 10:17:37.793: INFO: Created: latency-svc-7mhhm
Nov  4 10:17:37.797: INFO: Got endpoints: latency-svc-j8g7x [185.102937ms]
Nov  4 10:17:37.803: INFO: Got endpoints: latency-svc-7mhhm [184.301567ms]
Nov  4 10:17:37.807: INFO: Created: latency-svc-wglnr
Nov  4 10:17:37.817: INFO: Got endpoints: latency-svc-wglnr [178.754359ms]
Nov  4 10:17:37.817: INFO: Created: latency-svc-cq8fp
Nov  4 10:17:37.825: INFO: Created: latency-svc-xf5mn
Nov  4 10:17:37.827: INFO: Got endpoints: latency-svc-cq8fp [29.901288ms]
Nov  4 10:17:37.835: INFO: Created: latency-svc-hg5dt
Nov  4 10:17:37.836: INFO: Got endpoints: latency-svc-xf5mn [183.359928ms]
Nov  4 10:17:37.845: INFO: Created: latency-svc-d6lg5
Nov  4 10:17:37.848: INFO: Got endpoints: latency-svc-hg5dt [183.657599ms]
Nov  4 10:17:37.854: INFO: Created: latency-svc-jgjdb
Nov  4 10:17:37.858: INFO: Got endpoints: latency-svc-d6lg5 [185.250002ms]
Nov  4 10:17:37.865: INFO: Created: latency-svc-jkrlq
Nov  4 10:17:37.866: INFO: Got endpoints: latency-svc-jgjdb [173.879675ms]
Nov  4 10:17:37.874: INFO: Got endpoints: latency-svc-jkrlq [171.288682ms]
Nov  4 10:17:37.880: INFO: Created: latency-svc-h9xzx
Nov  4 10:17:37.885: INFO: Got endpoints: latency-svc-h9xzx [169.72713ms]
Nov  4 10:17:37.891: INFO: Created: latency-svc-8wf2s
Nov  4 10:17:37.894: INFO: Got endpoints: latency-svc-8wf2s [165.684952ms]
Nov  4 10:17:37.904: INFO: Created: latency-svc-z8kkh
Nov  4 10:17:37.907: INFO: Got endpoints: latency-svc-z8kkh [167.788441ms]
Nov  4 10:17:37.916: INFO: Created: latency-svc-glslw
Nov  4 10:17:37.920: INFO: Got endpoints: latency-svc-glslw [169.229753ms]
Nov  4 10:17:37.929: INFO: Created: latency-svc-9xnx2
Nov  4 10:17:37.932: INFO: Got endpoints: latency-svc-9xnx2 [172.843577ms]
Nov  4 10:17:37.938: INFO: Created: latency-svc-pxchw
Nov  4 10:17:37.944: INFO: Got endpoints: latency-svc-pxchw [161.003295ms]
Nov  4 10:17:37.948: INFO: Created: latency-svc-t5skm
Nov  4 10:17:37.954: INFO: Created: latency-svc-n4nmg
Nov  4 10:17:37.956: INFO: Got endpoints: latency-svc-t5skm [172.541972ms]
Nov  4 10:17:37.965: INFO: Got endpoints: latency-svc-n4nmg [161.740964ms]
Nov  4 10:17:37.968: INFO: Created: latency-svc-4tcm2
Nov  4 10:17:37.975: INFO: Got endpoints: latency-svc-4tcm2 [158.522352ms]
Nov  4 10:17:37.979: INFO: Created: latency-svc-bqzq7
Nov  4 10:17:38.018: INFO: Created: latency-svc-8jvhf
Nov  4 10:17:38.025: INFO: Got endpoints: latency-svc-bqzq7 [198.2991ms]
Nov  4 10:17:38.039: INFO: Got endpoints: latency-svc-8jvhf [203.519617ms]
Nov  4 10:17:38.058: INFO: Created: latency-svc-kmdsw
Nov  4 10:17:38.065: INFO: Got endpoints: latency-svc-kmdsw [217.325364ms]
Nov  4 10:17:38.083: INFO: Created: latency-svc-2jhqz
Nov  4 10:17:38.094: INFO: Created: latency-svc-j4884
Nov  4 10:17:38.108: INFO: Created: latency-svc-rqmj2
Nov  4 10:17:38.121: INFO: Got endpoints: latency-svc-2jhqz [262.584267ms]
Nov  4 10:17:38.128: INFO: Created: latency-svc-wksrd
Nov  4 10:17:38.133: INFO: Created: latency-svc-z72n4
Nov  4 10:17:38.139: INFO: Created: latency-svc-5xwkn
Nov  4 10:17:38.147: INFO: Created: latency-svc-hw8qg
Nov  4 10:17:38.152: INFO: Created: latency-svc-ffvqf
Nov  4 10:17:38.158: INFO: Created: latency-svc-78lz7
Nov  4 10:17:38.164: INFO: Got endpoints: latency-svc-j4884 [297.811339ms]
Nov  4 10:17:38.171: INFO: Created: latency-svc-9k7nc
Nov  4 10:17:38.175: INFO: Created: latency-svc-mw4qh
Nov  4 10:17:38.181: INFO: Created: latency-svc-9fb6t
Nov  4 10:17:38.189: INFO: Created: latency-svc-5646p
Nov  4 10:17:38.199: INFO: Created: latency-svc-mn2dq
Nov  4 10:17:38.206: INFO: Created: latency-svc-jftpl
Nov  4 10:17:38.223: INFO: Created: latency-svc-wq7mz
Nov  4 10:17:38.235: INFO: Created: latency-svc-ctnlc
Nov  4 10:17:38.235: INFO: Got endpoints: latency-svc-rqmj2 [360.687454ms]
Nov  4 10:17:38.255: INFO: Created: latency-svc-7lz6m
Nov  4 10:17:38.272: INFO: Got endpoints: latency-svc-wksrd [386.426607ms]
Nov  4 10:17:38.281: INFO: Created: latency-svc-629gv
Nov  4 10:17:38.310: INFO: Got endpoints: latency-svc-z72n4 [415.50973ms]
Nov  4 10:17:38.319: INFO: Created: latency-svc-hg7f6
Nov  4 10:17:38.360: INFO: Got endpoints: latency-svc-5xwkn [452.689618ms]
Nov  4 10:17:38.368: INFO: Created: latency-svc-nnggp
Nov  4 10:17:38.410: INFO: Got endpoints: latency-svc-hw8qg [489.550196ms]
Nov  4 10:17:38.420: INFO: Created: latency-svc-f568v
Nov  4 10:17:38.461: INFO: Got endpoints: latency-svc-ffvqf [527.859678ms]
Nov  4 10:17:38.470: INFO: Created: latency-svc-z9vk7
Nov  4 10:17:38.509: INFO: Got endpoints: latency-svc-78lz7 [565.488437ms]
Nov  4 10:17:38.520: INFO: Created: latency-svc-n6xh5
Nov  4 10:17:38.560: INFO: Got endpoints: latency-svc-9k7nc [603.363999ms]
Nov  4 10:17:38.570: INFO: Created: latency-svc-fqgd6
Nov  4 10:17:38.610: INFO: Got endpoints: latency-svc-mw4qh [644.927938ms]
Nov  4 10:17:38.619: INFO: Created: latency-svc-d4jlr
Nov  4 10:17:38.660: INFO: Got endpoints: latency-svc-9fb6t [684.417334ms]
Nov  4 10:17:38.668: INFO: Created: latency-svc-kdx9z
Nov  4 10:17:38.709: INFO: Got endpoints: latency-svc-5646p [684.17714ms]
Nov  4 10:17:38.719: INFO: Created: latency-svc-tl85r
Nov  4 10:17:38.760: INFO: Got endpoints: latency-svc-mn2dq [721.118583ms]
Nov  4 10:17:38.768: INFO: Created: latency-svc-vz8g8
Nov  4 10:17:38.810: INFO: Got endpoints: latency-svc-jftpl [744.954117ms]
Nov  4 10:17:38.818: INFO: Created: latency-svc-298pf
Nov  4 10:17:38.860: INFO: Got endpoints: latency-svc-wq7mz [738.889169ms]
Nov  4 10:17:38.867: INFO: Created: latency-svc-kdttp
Nov  4 10:17:38.921: INFO: Got endpoints: latency-svc-ctnlc [757.228719ms]
Nov  4 10:17:38.931: INFO: Created: latency-svc-hwwnt
Nov  4 10:17:38.960: INFO: Got endpoints: latency-svc-7lz6m [725.167097ms]
Nov  4 10:17:38.970: INFO: Created: latency-svc-zfm2x
Nov  4 10:17:39.010: INFO: Got endpoints: latency-svc-629gv [738.536066ms]
Nov  4 10:17:39.021: INFO: Created: latency-svc-tzvrk
Nov  4 10:17:39.060: INFO: Got endpoints: latency-svc-hg7f6 [750.039159ms]
Nov  4 10:17:39.069: INFO: Created: latency-svc-g46qd
Nov  4 10:17:39.110: INFO: Got endpoints: latency-svc-nnggp [749.720274ms]
Nov  4 10:17:39.120: INFO: Created: latency-svc-8w78q
Nov  4 10:17:39.161: INFO: Got endpoints: latency-svc-f568v [750.954254ms]
Nov  4 10:17:39.169: INFO: Created: latency-svc-hwl89
Nov  4 10:17:39.210: INFO: Got endpoints: latency-svc-z9vk7 [749.533425ms]
Nov  4 10:17:39.219: INFO: Created: latency-svc-hw22t
Nov  4 10:17:39.260: INFO: Got endpoints: latency-svc-n6xh5 [750.143413ms]
Nov  4 10:17:39.270: INFO: Created: latency-svc-vh2fj
Nov  4 10:17:39.337: INFO: Got endpoints: latency-svc-fqgd6 [777.593457ms]
Nov  4 10:17:39.347: INFO: Created: latency-svc-fxd46
Nov  4 10:17:39.360: INFO: Got endpoints: latency-svc-d4jlr [749.989126ms]
Nov  4 10:17:39.369: INFO: Created: latency-svc-x7xn9
Nov  4 10:17:39.410: INFO: Got endpoints: latency-svc-kdx9z [750.297141ms]
Nov  4 10:17:39.419: INFO: Created: latency-svc-9nwcv
Nov  4 10:17:39.461: INFO: Got endpoints: latency-svc-tl85r [751.510242ms]
Nov  4 10:17:39.470: INFO: Created: latency-svc-f6wbz
Nov  4 10:17:39.510: INFO: Got endpoints: latency-svc-vz8g8 [749.380864ms]
Nov  4 10:17:39.537: INFO: Created: latency-svc-lwk2d
Nov  4 10:17:39.560: INFO: Got endpoints: latency-svc-298pf [749.775268ms]
Nov  4 10:17:39.570: INFO: Created: latency-svc-9jr24
Nov  4 10:17:39.610: INFO: Got endpoints: latency-svc-kdttp [749.985142ms]
Nov  4 10:17:39.617: INFO: Created: latency-svc-qvnlv
Nov  4 10:17:39.661: INFO: Got endpoints: latency-svc-hwwnt [739.732006ms]
Nov  4 10:17:39.670: INFO: Created: latency-svc-ppd8r
Nov  4 10:17:39.711: INFO: Got endpoints: latency-svc-zfm2x [750.149231ms]
Nov  4 10:17:39.720: INFO: Created: latency-svc-7mtc8
Nov  4 10:17:39.760: INFO: Got endpoints: latency-svc-tzvrk [749.577856ms]
Nov  4 10:17:39.770: INFO: Created: latency-svc-xlt4f
Nov  4 10:17:39.811: INFO: Got endpoints: latency-svc-g46qd [750.54512ms]
Nov  4 10:17:39.821: INFO: Created: latency-svc-44hcm
Nov  4 10:17:39.861: INFO: Got endpoints: latency-svc-8w78q [751.04275ms]
Nov  4 10:17:39.871: INFO: Created: latency-svc-xhrvk
Nov  4 10:17:39.911: INFO: Got endpoints: latency-svc-hwl89 [749.812758ms]
Nov  4 10:17:39.920: INFO: Created: latency-svc-25dnb
Nov  4 10:17:39.961: INFO: Got endpoints: latency-svc-hw22t [750.70992ms]
Nov  4 10:17:39.971: INFO: Created: latency-svc-zwjbd
Nov  4 10:17:40.010: INFO: Got endpoints: latency-svc-vh2fj [750.524725ms]
Nov  4 10:17:40.019: INFO: Created: latency-svc-sz5bq
Nov  4 10:17:40.061: INFO: Got endpoints: latency-svc-fxd46 [722.780327ms]
Nov  4 10:17:40.069: INFO: Created: latency-svc-bq29q
Nov  4 10:17:40.110: INFO: Got endpoints: latency-svc-x7xn9 [750.119537ms]
Nov  4 10:17:40.120: INFO: Created: latency-svc-7pb2g
Nov  4 10:17:40.160: INFO: Got endpoints: latency-svc-9nwcv [750.251725ms]
Nov  4 10:17:40.172: INFO: Created: latency-svc-c4gm8
Nov  4 10:17:40.210: INFO: Got endpoints: latency-svc-f6wbz [748.729757ms]
Nov  4 10:17:40.218: INFO: Created: latency-svc-rbggk
Nov  4 10:17:40.260: INFO: Got endpoints: latency-svc-lwk2d [750.1388ms]
Nov  4 10:17:40.270: INFO: Created: latency-svc-k954k
Nov  4 10:17:40.310: INFO: Got endpoints: latency-svc-9jr24 [750.174791ms]
Nov  4 10:17:40.321: INFO: Created: latency-svc-qrbv8
Nov  4 10:17:40.370: INFO: Got endpoints: latency-svc-qvnlv [760.608521ms]
Nov  4 10:17:40.385: INFO: Created: latency-svc-xf42j
Nov  4 10:17:40.410: INFO: Got endpoints: latency-svc-ppd8r [749.109998ms]
Nov  4 10:17:40.420: INFO: Created: latency-svc-r6vdn
Nov  4 10:17:40.460: INFO: Got endpoints: latency-svc-7mtc8 [749.360945ms]
Nov  4 10:17:40.472: INFO: Created: latency-svc-rb4xt
Nov  4 10:17:40.510: INFO: Got endpoints: latency-svc-xlt4f [750.277412ms]
Nov  4 10:17:40.518: INFO: Created: latency-svc-z77xp
Nov  4 10:17:40.561: INFO: Got endpoints: latency-svc-44hcm [749.943761ms]
Nov  4 10:17:40.570: INFO: Created: latency-svc-hwttr
Nov  4 10:17:40.611: INFO: Got endpoints: latency-svc-xhrvk [750.124646ms]
Nov  4 10:17:40.622: INFO: Created: latency-svc-bblhv
Nov  4 10:17:40.660: INFO: Got endpoints: latency-svc-25dnb [749.437738ms]
Nov  4 10:17:40.669: INFO: Created: latency-svc-h785m
Nov  4 10:17:40.711: INFO: Got endpoints: latency-svc-zwjbd [750.136703ms]
Nov  4 10:17:40.721: INFO: Created: latency-svc-d9khd
Nov  4 10:17:40.761: INFO: Got endpoints: latency-svc-sz5bq [750.706971ms]
Nov  4 10:17:40.776: INFO: Created: latency-svc-lmkch
Nov  4 10:17:40.812: INFO: Got endpoints: latency-svc-bq29q [751.741882ms]
Nov  4 10:17:40.824: INFO: Created: latency-svc-sxr2z
Nov  4 10:17:40.860: INFO: Got endpoints: latency-svc-7pb2g [750.033072ms]
Nov  4 10:17:40.872: INFO: Created: latency-svc-n6f4w
Nov  4 10:17:40.911: INFO: Got endpoints: latency-svc-c4gm8 [750.006507ms]
Nov  4 10:17:40.925: INFO: Created: latency-svc-f5ksp
Nov  4 10:17:40.960: INFO: Got endpoints: latency-svc-rbggk [749.575254ms]
Nov  4 10:17:40.969: INFO: Created: latency-svc-8ftcl
Nov  4 10:17:41.010: INFO: Got endpoints: latency-svc-k954k [749.53557ms]
Nov  4 10:17:41.019: INFO: Created: latency-svc-fxfcw
Nov  4 10:17:41.060: INFO: Got endpoints: latency-svc-qrbv8 [749.485883ms]
Nov  4 10:17:41.072: INFO: Created: latency-svc-glgx6
Nov  4 10:17:41.112: INFO: Got endpoints: latency-svc-xf42j [741.456781ms]
Nov  4 10:17:41.120: INFO: Created: latency-svc-xshb4
Nov  4 10:17:41.161: INFO: Got endpoints: latency-svc-r6vdn [750.748776ms]
Nov  4 10:17:41.172: INFO: Created: latency-svc-8j9hd
Nov  4 10:17:41.210: INFO: Got endpoints: latency-svc-rb4xt [749.749285ms]
Nov  4 10:17:41.220: INFO: Created: latency-svc-4cjd7
Nov  4 10:17:41.260: INFO: Got endpoints: latency-svc-z77xp [750.127601ms]
Nov  4 10:17:41.269: INFO: Created: latency-svc-rdv6j
Nov  4 10:17:41.310: INFO: Got endpoints: latency-svc-hwttr [749.395779ms]
Nov  4 10:17:41.319: INFO: Created: latency-svc-ffvb6
Nov  4 10:17:41.360: INFO: Got endpoints: latency-svc-bblhv [748.966217ms]
Nov  4 10:17:41.370: INFO: Created: latency-svc-8q6rq
Nov  4 10:17:41.410: INFO: Got endpoints: latency-svc-h785m [749.43098ms]
Nov  4 10:17:41.418: INFO: Created: latency-svc-f85f4
Nov  4 10:17:41.460: INFO: Got endpoints: latency-svc-d9khd [748.875667ms]
Nov  4 10:17:41.469: INFO: Created: latency-svc-ffwkm
Nov  4 10:17:41.511: INFO: Got endpoints: latency-svc-lmkch [749.827833ms]
Nov  4 10:17:41.521: INFO: Created: latency-svc-t2c5m
Nov  4 10:17:41.560: INFO: Got endpoints: latency-svc-sxr2z [747.869773ms]
Nov  4 10:17:41.568: INFO: Created: latency-svc-555xc
Nov  4 10:17:41.610: INFO: Got endpoints: latency-svc-n6f4w [749.321173ms]
Nov  4 10:17:41.618: INFO: Created: latency-svc-brzcf
Nov  4 10:17:41.660: INFO: Got endpoints: latency-svc-f5ksp [749.624956ms]
Nov  4 10:17:41.670: INFO: Created: latency-svc-5rcc2
Nov  4 10:17:41.714: INFO: Got endpoints: latency-svc-8ftcl [754.402629ms]
Nov  4 10:17:41.723: INFO: Created: latency-svc-f4kx6
Nov  4 10:17:41.760: INFO: Got endpoints: latency-svc-fxfcw [750.098425ms]
Nov  4 10:17:41.768: INFO: Created: latency-svc-c7brt
Nov  4 10:17:41.811: INFO: Got endpoints: latency-svc-glgx6 [750.765052ms]
Nov  4 10:17:41.829: INFO: Created: latency-svc-8xrpp
Nov  4 10:17:41.861: INFO: Got endpoints: latency-svc-xshb4 [748.578538ms]
Nov  4 10:17:41.869: INFO: Created: latency-svc-pdm2v
Nov  4 10:17:41.910: INFO: Got endpoints: latency-svc-8j9hd [749.094355ms]
Nov  4 10:17:41.920: INFO: Created: latency-svc-psbqz
Nov  4 10:17:41.960: INFO: Got endpoints: latency-svc-4cjd7 [749.708403ms]
Nov  4 10:17:41.971: INFO: Created: latency-svc-fqx4g
Nov  4 10:17:42.011: INFO: Got endpoints: latency-svc-rdv6j [750.414167ms]
Nov  4 10:17:42.019: INFO: Created: latency-svc-kq57d
Nov  4 10:17:42.060: INFO: Got endpoints: latency-svc-ffvb6 [749.830701ms]
Nov  4 10:17:42.070: INFO: Created: latency-svc-tn72t
Nov  4 10:17:42.111: INFO: Got endpoints: latency-svc-8q6rq [750.502847ms]
Nov  4 10:17:42.121: INFO: Created: latency-svc-htthm
Nov  4 10:17:42.161: INFO: Got endpoints: latency-svc-f85f4 [750.539668ms]
Nov  4 10:17:42.170: INFO: Created: latency-svc-m64p4
Nov  4 10:17:42.212: INFO: Got endpoints: latency-svc-ffwkm [751.854512ms]
Nov  4 10:17:42.222: INFO: Created: latency-svc-jrttq
Nov  4 10:17:42.260: INFO: Got endpoints: latency-svc-t2c5m [749.196175ms]
Nov  4 10:17:42.271: INFO: Created: latency-svc-wvxmd
Nov  4 10:17:42.310: INFO: Got endpoints: latency-svc-555xc [749.950452ms]
Nov  4 10:17:42.319: INFO: Created: latency-svc-68b5d
Nov  4 10:17:42.360: INFO: Got endpoints: latency-svc-brzcf [749.927134ms]
Nov  4 10:17:42.369: INFO: Created: latency-svc-mp9cs
Nov  4 10:17:42.411: INFO: Got endpoints: latency-svc-5rcc2 [750.211944ms]
Nov  4 10:17:42.421: INFO: Created: latency-svc-6896r
Nov  4 10:17:42.461: INFO: Got endpoints: latency-svc-f4kx6 [746.460051ms]
Nov  4 10:17:42.469: INFO: Created: latency-svc-r67q4
Nov  4 10:17:42.510: INFO: Got endpoints: latency-svc-c7brt [749.824361ms]
Nov  4 10:17:42.519: INFO: Created: latency-svc-zfn4t
Nov  4 10:17:42.560: INFO: Got endpoints: latency-svc-8xrpp [749.25866ms]
Nov  4 10:17:42.572: INFO: Created: latency-svc-mxlnk
Nov  4 10:17:42.610: INFO: Got endpoints: latency-svc-pdm2v [749.010113ms]
Nov  4 10:17:42.618: INFO: Created: latency-svc-wnq4b
Nov  4 10:17:42.660: INFO: Got endpoints: latency-svc-psbqz [750.148745ms]
Nov  4 10:17:42.670: INFO: Created: latency-svc-dsstb
Nov  4 10:17:42.711: INFO: Got endpoints: latency-svc-fqx4g [750.848118ms]
Nov  4 10:17:42.721: INFO: Created: latency-svc-xjk4x
Nov  4 10:17:42.760: INFO: Got endpoints: latency-svc-kq57d [748.637541ms]
Nov  4 10:17:42.768: INFO: Created: latency-svc-mrdkn
Nov  4 10:17:42.810: INFO: Got endpoints: latency-svc-tn72t [749.973737ms]
Nov  4 10:17:42.819: INFO: Created: latency-svc-67vs5
Nov  4 10:17:42.860: INFO: Got endpoints: latency-svc-htthm [749.095713ms]
Nov  4 10:17:42.869: INFO: Created: latency-svc-b8wxb
Nov  4 10:17:42.909: INFO: Got endpoints: latency-svc-m64p4 [748.747228ms]
Nov  4 10:17:42.919: INFO: Created: latency-svc-6kj5j
Nov  4 10:17:42.960: INFO: Got endpoints: latency-svc-jrttq [748.067986ms]
Nov  4 10:17:42.969: INFO: Created: latency-svc-bc6f6
Nov  4 10:17:43.010: INFO: Got endpoints: latency-svc-wvxmd [749.750829ms]
Nov  4 10:17:43.019: INFO: Created: latency-svc-hxk8j
Nov  4 10:17:43.060: INFO: Got endpoints: latency-svc-68b5d [750.03464ms]
Nov  4 10:17:43.069: INFO: Created: latency-svc-27q26
Nov  4 10:17:43.110: INFO: Got endpoints: latency-svc-mp9cs [750.357635ms]
Nov  4 10:17:43.121: INFO: Created: latency-svc-xht9b
Nov  4 10:17:43.160: INFO: Got endpoints: latency-svc-6896r [749.745913ms]
Nov  4 10:17:43.170: INFO: Created: latency-svc-qrp8p
Nov  4 10:17:43.210: INFO: Got endpoints: latency-svc-r67q4 [749.419166ms]
Nov  4 10:17:43.219: INFO: Created: latency-svc-scchd
Nov  4 10:17:43.260: INFO: Got endpoints: latency-svc-zfn4t [750.061925ms]
Nov  4 10:17:43.270: INFO: Created: latency-svc-b9fnk
Nov  4 10:17:43.311: INFO: Got endpoints: latency-svc-mxlnk [750.819295ms]
Nov  4 10:17:43.321: INFO: Created: latency-svc-bn7hn
Nov  4 10:17:43.360: INFO: Got endpoints: latency-svc-wnq4b [749.670093ms]
Nov  4 10:17:43.369: INFO: Created: latency-svc-7xz7x
Nov  4 10:17:43.410: INFO: Got endpoints: latency-svc-dsstb [749.17319ms]
Nov  4 10:17:43.418: INFO: Created: latency-svc-qpbxv
Nov  4 10:17:43.463: INFO: Got endpoints: latency-svc-xjk4x [752.315782ms]
Nov  4 10:17:43.549: INFO: Got endpoints: latency-svc-mrdkn [789.251375ms]
Nov  4 10:17:43.557: INFO: Created: latency-svc-8rzzw
Nov  4 10:17:43.576: INFO: Got endpoints: latency-svc-67vs5 [766.195542ms]
Nov  4 10:17:43.584: INFO: Created: latency-svc-mqtmt
Nov  4 10:17:43.596: INFO: Created: latency-svc-thv7k
Nov  4 10:17:43.612: INFO: Got endpoints: latency-svc-b8wxb [751.532333ms]
Nov  4 10:17:43.634: INFO: Created: latency-svc-gvbtn
Nov  4 10:17:43.660: INFO: Got endpoints: latency-svc-6kj5j [750.850576ms]
Nov  4 10:17:43.669: INFO: Created: latency-svc-blrtd
Nov  4 10:17:43.710: INFO: Got endpoints: latency-svc-bc6f6 [749.917065ms]
Nov  4 10:17:43.719: INFO: Created: latency-svc-7kxjl
Nov  4 10:17:43.760: INFO: Got endpoints: latency-svc-hxk8j [749.467127ms]
Nov  4 10:17:43.770: INFO: Created: latency-svc-hvj8n
Nov  4 10:17:43.811: INFO: Got endpoints: latency-svc-27q26 [750.369634ms]
Nov  4 10:17:43.820: INFO: Created: latency-svc-tltk5
Nov  4 10:17:43.860: INFO: Got endpoints: latency-svc-xht9b [749.564924ms]
Nov  4 10:17:43.868: INFO: Created: latency-svc-gdwlr
Nov  4 10:17:43.910: INFO: Got endpoints: latency-svc-qrp8p [749.444527ms]
Nov  4 10:17:43.920: INFO: Created: latency-svc-v7fhl
Nov  4 10:17:43.960: INFO: Got endpoints: latency-svc-scchd [749.691416ms]
Nov  4 10:17:43.969: INFO: Created: latency-svc-jxgpr
Nov  4 10:17:44.010: INFO: Got endpoints: latency-svc-b9fnk [749.490136ms]
Nov  4 10:17:44.019: INFO: Created: latency-svc-c87kr
Nov  4 10:17:44.060: INFO: Got endpoints: latency-svc-bn7hn [748.801967ms]
Nov  4 10:17:44.073: INFO: Created: latency-svc-mzt62
Nov  4 10:17:44.111: INFO: Got endpoints: latency-svc-7xz7x [750.918782ms]
Nov  4 10:17:44.119: INFO: Created: latency-svc-rg8zx
Nov  4 10:17:44.160: INFO: Got endpoints: latency-svc-qpbxv [750.671046ms]
Nov  4 10:17:44.169: INFO: Created: latency-svc-fpv26
Nov  4 10:17:44.210: INFO: Got endpoints: latency-svc-8rzzw [746.930634ms]
Nov  4 10:17:44.219: INFO: Created: latency-svc-rl6qv
Nov  4 10:17:44.260: INFO: Got endpoints: latency-svc-mqtmt [710.910433ms]
Nov  4 10:17:44.269: INFO: Created: latency-svc-ztgjw
Nov  4 10:17:44.310: INFO: Got endpoints: latency-svc-thv7k [733.563275ms]
Nov  4 10:17:44.319: INFO: Created: latency-svc-x2zf9
Nov  4 10:17:44.360: INFO: Got endpoints: latency-svc-gvbtn [748.740287ms]
Nov  4 10:17:44.370: INFO: Created: latency-svc-jwfnj
Nov  4 10:17:44.410: INFO: Got endpoints: latency-svc-blrtd [749.263969ms]
Nov  4 10:17:44.418: INFO: Created: latency-svc-8ddkn
Nov  4 10:17:44.461: INFO: Got endpoints: latency-svc-7kxjl [750.32426ms]
Nov  4 10:17:44.471: INFO: Created: latency-svc-zzf95
Nov  4 10:17:44.510: INFO: Got endpoints: latency-svc-hvj8n [750.131472ms]
Nov  4 10:17:44.520: INFO: Created: latency-svc-rr9dt
Nov  4 10:17:44.560: INFO: Got endpoints: latency-svc-tltk5 [748.801179ms]
Nov  4 10:17:44.568: INFO: Created: latency-svc-2q6v2
Nov  4 10:17:44.610: INFO: Got endpoints: latency-svc-gdwlr [750.100668ms]
Nov  4 10:17:44.619: INFO: Created: latency-svc-9z9kr
Nov  4 10:17:44.661: INFO: Got endpoints: latency-svc-v7fhl [750.549102ms]
Nov  4 10:17:44.670: INFO: Created: latency-svc-zpctk
Nov  4 10:17:44.710: INFO: Got endpoints: latency-svc-jxgpr [749.612471ms]
Nov  4 10:17:44.717: INFO: Created: latency-svc-r96m7
Nov  4 10:17:44.760: INFO: Got endpoints: latency-svc-c87kr [750.105074ms]
Nov  4 10:17:44.770: INFO: Created: latency-svc-ljj8f
Nov  4 10:17:44.812: INFO: Got endpoints: latency-svc-mzt62 [752.008603ms]
Nov  4 10:17:44.826: INFO: Created: latency-svc-2kftq
Nov  4 10:17:44.860: INFO: Got endpoints: latency-svc-rg8zx [749.216258ms]
Nov  4 10:17:44.868: INFO: Created: latency-svc-hm2qh
Nov  4 10:17:44.910: INFO: Got endpoints: latency-svc-fpv26 [749.848507ms]
Nov  4 10:17:44.933: INFO: Created: latency-svc-cjx59
Nov  4 10:17:44.962: INFO: Got endpoints: latency-svc-rl6qv [751.496653ms]
Nov  4 10:17:44.976: INFO: Created: latency-svc-z9sss
Nov  4 10:17:45.010: INFO: Got endpoints: latency-svc-ztgjw [749.749144ms]
Nov  4 10:17:45.018: INFO: Created: latency-svc-fv2sx
Nov  4 10:17:45.060: INFO: Got endpoints: latency-svc-x2zf9 [750.381917ms]
Nov  4 10:17:45.110: INFO: Got endpoints: latency-svc-jwfnj [749.803926ms]
Nov  4 10:17:45.160: INFO: Got endpoints: latency-svc-8ddkn [750.255642ms]
Nov  4 10:17:45.211: INFO: Got endpoints: latency-svc-zzf95 [750.451531ms]
Nov  4 10:17:45.260: INFO: Got endpoints: latency-svc-rr9dt [749.919349ms]
Nov  4 10:17:45.311: INFO: Got endpoints: latency-svc-2q6v2 [751.35084ms]
Nov  4 10:17:45.361: INFO: Got endpoints: latency-svc-9z9kr [751.006662ms]
Nov  4 10:17:45.410: INFO: Got endpoints: latency-svc-zpctk [749.890382ms]
Nov  4 10:17:45.460: INFO: Got endpoints: latency-svc-r96m7 [750.134079ms]
Nov  4 10:17:45.511: INFO: Got endpoints: latency-svc-ljj8f [750.517529ms]
Nov  4 10:17:45.561: INFO: Got endpoints: latency-svc-2kftq [748.450611ms]
Nov  4 10:17:45.610: INFO: Got endpoints: latency-svc-hm2qh [750.054411ms]
Nov  4 10:17:45.660: INFO: Got endpoints: latency-svc-cjx59 [749.437557ms]
Nov  4 10:17:45.711: INFO: Got endpoints: latency-svc-z9sss [748.414742ms]
Nov  4 10:17:45.760: INFO: Got endpoints: latency-svc-fv2sx [750.117735ms]
Nov  4 10:17:45.760: INFO: Latencies: [29.901288ms 63.803537ms 64.590979ms 95.098901ms 111.708737ms 115.079709ms 140.230099ms 158.522352ms 161.003295ms 161.740964ms 165.684952ms 167.788441ms 169.229753ms 169.72713ms 171.288682ms 172.541972ms 172.843577ms 173.879675ms 174.13634ms 178.754359ms 183.359928ms 183.657599ms 184.301567ms 185.102937ms 185.250002ms 186.265657ms 188.090252ms 194.317607ms 198.2991ms 203.519617ms 217.325364ms 262.584267ms 297.811339ms 360.687454ms 386.426607ms 415.50973ms 452.689618ms 489.550196ms 527.859678ms 565.488437ms 603.363999ms 644.927938ms 684.17714ms 684.417334ms 710.910433ms 721.118583ms 722.780327ms 725.167097ms 733.563275ms 738.536066ms 738.889169ms 739.732006ms 741.456781ms 744.954117ms 746.460051ms 746.930634ms 747.869773ms 748.067986ms 748.414742ms 748.450611ms 748.578538ms 748.637541ms 748.729757ms 748.740287ms 748.747228ms 748.801179ms 748.801967ms 748.875667ms 748.966217ms 749.010113ms 749.094355ms 749.095713ms 749.109998ms 749.17319ms 749.196175ms 749.216258ms 749.25866ms 749.263969ms 749.321173ms 749.360945ms 749.380864ms 749.395779ms 749.419166ms 749.43098ms 749.437557ms 749.437738ms 749.444527ms 749.467127ms 749.485883ms 749.490136ms 749.533425ms 749.53557ms 749.564924ms 749.575254ms 749.577856ms 749.612471ms 749.624956ms 749.670093ms 749.691416ms 749.708403ms 749.720274ms 749.745913ms 749.749144ms 749.749285ms 749.750829ms 749.775268ms 749.803926ms 749.812758ms 749.824361ms 749.827833ms 749.830701ms 749.848507ms 749.890382ms 749.917065ms 749.919349ms 749.927134ms 749.943761ms 749.950452ms 749.973737ms 749.985142ms 749.989126ms 750.006507ms 750.033072ms 750.03464ms 750.039159ms 750.054411ms 750.061925ms 750.098425ms 750.100668ms 750.105074ms 750.117735ms 750.119537ms 750.124646ms 750.127601ms 750.131472ms 750.134079ms 750.136703ms 750.1388ms 750.143413ms 750.148745ms 750.149231ms 750.174791ms 750.211944ms 750.251725ms 750.255642ms 750.277412ms 750.297141ms 750.32426ms 750.357635ms 750.369634ms 750.381917ms 750.414167ms 750.451531ms 750.502847ms 750.517529ms 750.524725ms 750.539668ms 750.54512ms 750.549102ms 750.671046ms 750.706971ms 750.70992ms 750.748776ms 750.765052ms 750.819295ms 750.848118ms 750.850576ms 750.918782ms 750.954254ms 751.006662ms 751.04275ms 751.35084ms 751.496653ms 751.510242ms 751.532333ms 751.741882ms 751.854512ms 752.008603ms 752.315782ms 754.402629ms 757.228719ms 760.608521ms 766.195542ms 771.176982ms 777.593457ms 789.251375ms 791.725311ms 794.763292ms 801.782907ms 805.58003ms 810.234415ms 814.921661ms 816.319187ms 817.800282ms 820.242494ms 824.821935ms 832.994438ms 843.859535ms 857.952768ms 869.875459ms]
Nov  4 10:17:45.760: INFO: 50 %ile: 749.720274ms
Nov  4 10:17:45.760: INFO: 90 %ile: 757.228719ms
Nov  4 10:17:45.760: INFO: 99 %ile: 857.952768ms
Nov  4 10:17:45.760: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:17:45.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-4417" for this suite.
Nov  4 10:17:57.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:17:57.868: INFO: namespace svc-latency-4417 deletion completed in 12.102840648s

• [SLOW TEST:23.395 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:17:57.869: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2060
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 10:17:58.540: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov  4 10:18:00.549: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708459478, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708459478, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708459478, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708459478, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 10:18:03.561: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Nov  4 10:18:04.561: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Nov  4 10:18:05.561: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Nov  4 10:18:06.561: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Nov  4 10:18:07.561: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 10:18:07.564: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6457-crds.webhook.example.com via the AdmissionRegistration API
Nov  4 10:18:12.658: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:18:13.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2060" for this suite.
Nov  4 10:18:19.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:18:19.889: INFO: namespace webhook-2060 deletion completed in 6.343091766s
STEP: Destroying namespace "webhook-2060-markers" for this suite.
Nov  4 10:18:25.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:18:25.994: INFO: namespace webhook-2060-markers deletion completed in 6.105290744s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.138 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:18:26.007: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1627
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 10:18:26.684: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 10:18:29.701: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:18:29.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1627" for this suite.
Nov  4 10:18:35.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:18:35.883: INFO: namespace webhook-1627 deletion completed in 6.107695027s
STEP: Destroying namespace "webhook-1627-markers" for this suite.
Nov  4 10:18:41.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:18:41.977: INFO: namespace webhook-1627-markers deletion completed in 6.094586994s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.984 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:18:41.992: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4003
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-4003/configmap-test-e06ea415-debd-4aa4-aa08-103f21da89d8
STEP: Creating a pod to test consume configMaps
Nov  4 10:18:42.156: INFO: Waiting up to 5m0s for pod "pod-configmaps-5258731e-9145-405d-bc9c-67281e38b5d9" in namespace "configmap-4003" to be "success or failure"
Nov  4 10:18:42.169: INFO: Pod "pod-configmaps-5258731e-9145-405d-bc9c-67281e38b5d9": Phase="Pending", Reason="", readiness=false. Elapsed: 13.449856ms
Nov  4 10:18:44.172: INFO: Pod "pod-configmaps-5258731e-9145-405d-bc9c-67281e38b5d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016021861s
STEP: Saw pod success
Nov  4 10:18:44.172: INFO: Pod "pod-configmaps-5258731e-9145-405d-bc9c-67281e38b5d9" satisfied condition "success or failure"
Nov  4 10:18:44.174: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-5258731e-9145-405d-bc9c-67281e38b5d9 container env-test: <nil>
STEP: delete the pod
Nov  4 10:18:44.200: INFO: Waiting for pod pod-configmaps-5258731e-9145-405d-bc9c-67281e38b5d9 to disappear
Nov  4 10:18:44.204: INFO: Pod pod-configmaps-5258731e-9145-405d-bc9c-67281e38b5d9 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:18:44.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4003" for this suite.
Nov  4 10:18:50.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:18:50.333: INFO: namespace configmap-4003 deletion completed in 6.12464137s

• [SLOW TEST:8.341 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:18:50.334: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6303
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  4 10:18:53.044: INFO: Successfully updated pod "pod-update-94d7ca2e-e4da-4f5c-a965-6ba9d706476e"
STEP: verifying the updated pod is in kubernetes
Nov  4 10:18:53.051: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:18:53.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6303" for this suite.
Nov  4 10:19:05.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:19:05.146: INFO: namespace pods-6303 deletion completed in 12.091596233s

• [SLOW TEST:14.813 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:19:05.147: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-789
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 10:19:21.311: INFO: Container started at 2019-11-04 10:19:05 +0000 UTC, pod became ready at 2019-11-04 10:19:20 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:19:21.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-789" for this suite.
Nov  4 10:19:33.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:19:33.416: INFO: namespace container-probe-789 deletion completed in 12.100829053s

• [SLOW TEST:28.270 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:19:33.417: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5478
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:19:49.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5478" for this suite.
Nov  4 10:19:55.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:19:55.708: INFO: namespace resourcequota-5478 deletion completed in 6.100051417s

• [SLOW TEST:22.290 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:19:55.708: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1656
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-b80930a4-5d33-4ed1-ada4-08407d7d9cf5
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-b80930a4-5d33-4ed1-ada4-08407d7d9cf5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:19:59.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1656" for this suite.
Nov  4 10:20:27.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:20:28.013: INFO: namespace configmap-1656 deletion completed in 28.098251645s

• [SLOW TEST:32.305 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:20:28.014: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 10:20:28.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-2709'
Nov  4 10:20:28.249: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 10:20:28.249: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Nov  4 10:20:28.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-416373942 delete jobs e2e-test-httpd-job --namespace=kubectl-2709'
Nov  4 10:20:28.358: INFO: stderr: ""
Nov  4 10:20:28.358: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:20:28.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2709" for this suite.
Nov  4 10:20:34.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:20:34.460: INFO: namespace kubectl-2709 deletion completed in 6.098033413s

• [SLOW TEST:6.446 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:20:34.461: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1572
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  4 10:20:34.598: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:20:36.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1572" for this suite.
Nov  4 10:20:42.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:20:42.457: INFO: namespace init-container-1572 deletion completed in 6.10175762s

• [SLOW TEST:7.996 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:20:42.460: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-5850
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Nov  4 10:20:42.851: INFO: Pod name wrapped-volume-race-f586df54-270b-4440-9f30-bb82ee0dc398: Found 0 pods out of 5
Nov  4 10:20:47.857: INFO: Pod name wrapped-volume-race-f586df54-270b-4440-9f30-bb82ee0dc398: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f586df54-270b-4440-9f30-bb82ee0dc398 in namespace emptydir-wrapper-5850, will wait for the garbage collector to delete the pods
Nov  4 10:20:57.936: INFO: Deleting ReplicationController wrapped-volume-race-f586df54-270b-4440-9f30-bb82ee0dc398 took: 7.865104ms
Nov  4 10:20:58.036: INFO: Terminating ReplicationController wrapped-volume-race-f586df54-270b-4440-9f30-bb82ee0dc398 pods took: 100.182882ms
STEP: Creating RC which spawns configmap-volume pods
Nov  4 10:21:41.856: INFO: Pod name wrapped-volume-race-857c7bb3-4900-4f2b-9f1d-97845fdaf0af: Found 0 pods out of 5
Nov  4 10:21:46.868: INFO: Pod name wrapped-volume-race-857c7bb3-4900-4f2b-9f1d-97845fdaf0af: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-857c7bb3-4900-4f2b-9f1d-97845fdaf0af in namespace emptydir-wrapper-5850, will wait for the garbage collector to delete the pods
Nov  4 10:21:59.227: INFO: Deleting ReplicationController wrapped-volume-race-857c7bb3-4900-4f2b-9f1d-97845fdaf0af took: 7.665983ms
Nov  4 10:21:59.727: INFO: Terminating ReplicationController wrapped-volume-race-857c7bb3-4900-4f2b-9f1d-97845fdaf0af pods took: 500.203966ms
STEP: Creating RC which spawns configmap-volume pods
Nov  4 10:22:41.744: INFO: Pod name wrapped-volume-race-acb53465-8779-44d2-b24d-555912c92855: Found 0 pods out of 5
Nov  4 10:22:46.751: INFO: Pod name wrapped-volume-race-acb53465-8779-44d2-b24d-555912c92855: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-acb53465-8779-44d2-b24d-555912c92855 in namespace emptydir-wrapper-5850, will wait for the garbage collector to delete the pods
Nov  4 10:22:56.828: INFO: Deleting ReplicationController wrapped-volume-race-acb53465-8779-44d2-b24d-555912c92855 took: 7.137504ms
Nov  4 10:22:57.329: INFO: Terminating ReplicationController wrapped-volume-race-acb53465-8779-44d2-b24d-555912c92855 pods took: 500.228333ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:23:34.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5850" for this suite.
Nov  4 10:23:42.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:23:42.299: INFO: namespace emptydir-wrapper-5850 deletion completed in 8.11823022s

• [SLOW TEST:179.840 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:23:42.300: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2185
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 10:23:42.476: INFO: Create a RollingUpdate DaemonSet
Nov  4 10:23:42.482: INFO: Check that daemon pods launch on every node of the cluster
Nov  4 10:23:42.491: INFO: Number of nodes with available pods: 0
Nov  4 10:23:42.491: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 10:23:43.498: INFO: Number of nodes with available pods: 1
Nov  4 10:23:43.498: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 10:23:44.498: INFO: Number of nodes with available pods: 3
Nov  4 10:23:44.498: INFO: Number of running nodes: 3, number of available pods: 3
Nov  4 10:23:44.498: INFO: Update the DaemonSet to trigger a rollout
Nov  4 10:23:44.506: INFO: Updating DaemonSet daemon-set
Nov  4 10:23:48.521: INFO: Roll back the DaemonSet before rollout is complete
Nov  4 10:23:48.529: INFO: Updating DaemonSet daemon-set
Nov  4 10:23:48.529: INFO: Make sure DaemonSet rollback is complete
Nov  4 10:23:48.535: INFO: Wrong image for pod: daemon-set-r2bps. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov  4 10:23:48.535: INFO: Pod daemon-set-r2bps is not available
Nov  4 10:23:49.556: INFO: Wrong image for pod: daemon-set-r2bps. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov  4 10:23:49.557: INFO: Pod daemon-set-r2bps is not available
Nov  4 10:23:50.556: INFO: Pod daemon-set-4ps4m is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2185, will wait for the garbage collector to delete the pods
Nov  4 10:23:50.628: INFO: Deleting DaemonSet.extensions daemon-set took: 9.389943ms
Nov  4 10:23:51.129: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.189561ms
Nov  4 10:24:01.931: INFO: Number of nodes with available pods: 0
Nov  4 10:24:01.931: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 10:24:01.933: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2185/daemonsets","resourceVersion":"538179"},"items":null}

Nov  4 10:24:01.936: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2185/pods","resourceVersion":"538179"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:24:01.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2185" for this suite.
Nov  4 10:24:07.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:24:08.048: INFO: namespace daemonsets-2185 deletion completed in 6.096674556s

• [SLOW TEST:25.749 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:24:08.049: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4501
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 10:24:08.196: INFO: (0) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.10809ms)
Nov  4 10:24:08.199: INFO: (1) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.867482ms)
Nov  4 10:24:08.202: INFO: (2) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.882739ms)
Nov  4 10:24:08.205: INFO: (3) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.10717ms)
Nov  4 10:24:08.208: INFO: (4) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.757969ms)
Nov  4 10:24:08.211: INFO: (5) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.998702ms)
Nov  4 10:24:08.219: INFO: (6) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.151257ms)
Nov  4 10:24:08.222: INFO: (7) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.040597ms)
Nov  4 10:24:08.226: INFO: (8) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.552983ms)
Nov  4 10:24:08.229: INFO: (9) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.199101ms)
Nov  4 10:24:08.232: INFO: (10) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.78337ms)
Nov  4 10:24:08.235: INFO: (11) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.706886ms)
Nov  4 10:24:08.238: INFO: (12) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.42209ms)
Nov  4 10:24:08.242: INFO: (13) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.377587ms)
Nov  4 10:24:08.245: INFO: (14) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.968737ms)
Nov  4 10:24:08.248: INFO: (15) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.168456ms)
Nov  4 10:24:08.251: INFO: (16) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.518175ms)
Nov  4 10:24:08.256: INFO: (17) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.218133ms)
Nov  4 10:24:08.265: INFO: (18) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.26329ms)
Nov  4 10:24:08.273: INFO: (19) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.911317ms)
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:24:08.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4501" for this suite.
Nov  4 10:24:14.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:24:14.385: INFO: namespace proxy-4501 deletion completed in 6.107578892s

• [SLOW TEST:6.337 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:24:14.386: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4212
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 10:24:14.600: INFO: Waiting up to 5m0s for pod "downward-api-ca84a70b-7146-47ec-8d43-d7d0e46d65d6" in namespace "downward-api-4212" to be "success or failure"
Nov  4 10:24:14.606: INFO: Pod "downward-api-ca84a70b-7146-47ec-8d43-d7d0e46d65d6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020975ms
Nov  4 10:24:16.609: INFO: Pod "downward-api-ca84a70b-7146-47ec-8d43-d7d0e46d65d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009237401s
STEP: Saw pod success
Nov  4 10:24:16.609: INFO: Pod "downward-api-ca84a70b-7146-47ec-8d43-d7d0e46d65d6" satisfied condition "success or failure"
Nov  4 10:24:16.612: INFO: Trying to get logs from node k8s-1 pod downward-api-ca84a70b-7146-47ec-8d43-d7d0e46d65d6 container dapi-container: <nil>
STEP: delete the pod
Nov  4 10:24:16.634: INFO: Waiting for pod downward-api-ca84a70b-7146-47ec-8d43-d7d0e46d65d6 to disappear
Nov  4 10:24:16.637: INFO: Pod downward-api-ca84a70b-7146-47ec-8d43-d7d0e46d65d6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:24:16.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4212" for this suite.
Nov  4 10:24:22.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:24:22.740: INFO: namespace downward-api-4212 deletion completed in 6.098503763s

• [SLOW TEST:8.354 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:24:22.741: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7830
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-62e47239-dd57-482c-8a30-2caad440ae1a
STEP: Creating a pod to test consume secrets
Nov  4 10:24:22.910: INFO: Waiting up to 5m0s for pod "pod-secrets-d15c852c-c83e-407f-9217-49ec27f67bdb" in namespace "secrets-7830" to be "success or failure"
Nov  4 10:24:22.913: INFO: Pod "pod-secrets-d15c852c-c83e-407f-9217-49ec27f67bdb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.525453ms
Nov  4 10:24:24.916: INFO: Pod "pod-secrets-d15c852c-c83e-407f-9217-49ec27f67bdb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005862483s
STEP: Saw pod success
Nov  4 10:24:24.916: INFO: Pod "pod-secrets-d15c852c-c83e-407f-9217-49ec27f67bdb" satisfied condition "success or failure"
Nov  4 10:24:24.918: INFO: Trying to get logs from node k8s-1 pod pod-secrets-d15c852c-c83e-407f-9217-49ec27f67bdb container secret-env-test: <nil>
STEP: delete the pod
Nov  4 10:24:24.940: INFO: Waiting for pod pod-secrets-d15c852c-c83e-407f-9217-49ec27f67bdb to disappear
Nov  4 10:24:24.943: INFO: Pod pod-secrets-d15c852c-c83e-407f-9217-49ec27f67bdb no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:24:24.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7830" for this suite.
Nov  4 10:24:30.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:24:31.050: INFO: namespace secrets-7830 deletion completed in 6.103970142s

• [SLOW TEST:8.309 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:24:31.051: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3637
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:24:38.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3637" for this suite.
Nov  4 10:24:44.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:24:44.329: INFO: namespace resourcequota-3637 deletion completed in 6.102148582s

• [SLOW TEST:13.278 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:24:44.331: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6506
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-61f2f1d3-22f2-4ecf-965c-a514f438068a
STEP: Creating a pod to test consume secrets
Nov  4 10:24:44.488: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d8b3d632-9e00-4cde-9d1f-4d71ea5f0319" in namespace "projected-6506" to be "success or failure"
Nov  4 10:24:44.493: INFO: Pod "pod-projected-secrets-d8b3d632-9e00-4cde-9d1f-4d71ea5f0319": Phase="Pending", Reason="", readiness=false. Elapsed: 4.800265ms
Nov  4 10:24:46.496: INFO: Pod "pod-projected-secrets-d8b3d632-9e00-4cde-9d1f-4d71ea5f0319": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008009684s
STEP: Saw pod success
Nov  4 10:24:46.497: INFO: Pod "pod-projected-secrets-d8b3d632-9e00-4cde-9d1f-4d71ea5f0319" satisfied condition "success or failure"
Nov  4 10:24:46.499: INFO: Trying to get logs from node k8s-1 pod pod-projected-secrets-d8b3d632-9e00-4cde-9d1f-4d71ea5f0319 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 10:24:46.522: INFO: Waiting for pod pod-projected-secrets-d8b3d632-9e00-4cde-9d1f-4d71ea5f0319 to disappear
Nov  4 10:24:46.526: INFO: Pod pod-projected-secrets-d8b3d632-9e00-4cde-9d1f-4d71ea5f0319 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:24:46.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6506" for this suite.
Nov  4 10:24:52.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:24:52.650: INFO: namespace projected-6506 deletion completed in 6.120118805s

• [SLOW TEST:8.318 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 10:24:52.650: INFO: >>> kubeConfig: /tmp/kubeconfig-416373942
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4640
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  4 10:24:52.835: INFO: Number of nodes with available pods: 0
Nov  4 10:24:52.836: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 10:24:53.842: INFO: Number of nodes with available pods: 1
Nov  4 10:24:53.842: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 10:24:54.936: INFO: Number of nodes with available pods: 3
Nov  4 10:24:54.936: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov  4 10:24:54.961: INFO: Number of nodes with available pods: 2
Nov  4 10:24:54.961: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 10:24:55.967: INFO: Number of nodes with available pods: 2
Nov  4 10:24:55.967: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 10:24:56.971: INFO: Number of nodes with available pods: 3
Nov  4 10:24:56.972: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4640, will wait for the garbage collector to delete the pods
Nov  4 10:24:57.040: INFO: Deleting DaemonSet.extensions daemon-set took: 9.658923ms
Nov  4 10:24:57.540: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.177988ms
Nov  4 10:25:01.743: INFO: Number of nodes with available pods: 0
Nov  4 10:25:01.743: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 10:25:01.746: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4640/daemonsets","resourceVersion":"538504"},"items":null}

Nov  4 10:25:01.748: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4640/pods","resourceVersion":"538504"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 10:25:01.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4640" for this suite.
Nov  4 10:25:07.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 10:25:07.859: INFO: namespace daemonsets-4640 deletion completed in 6.096381789s

• [SLOW TEST:15.209 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSNov  4 10:25:07.861: INFO: Running AfterSuite actions on all nodes
Nov  4 10:25:07.861: INFO: Running AfterSuite actions on node 1
Nov  4 10:25:07.861: INFO: Skipping dumping logs from cluster

Ran 276 of 4897 Specs in 6658.857 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4621 Skipped
PASS

Ginkgo ran 1 suite in 1h51m0.699017464s
Test Suite Passed

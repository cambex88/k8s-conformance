May 30 22:24:52.232: INFO: Overriding default scale value of zero to 1
May 30 22:24:52.233: INFO: Overriding default milliseconds value of zero to 5000
I0530 22:24:52.406338      16 test_context.go:382] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-884905328
I0530 22:24:52.408841      16 e2e.go:333] Starting e2e run "be51798a-8329-11e9-a3e0-52e03c2e65ea" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1559255091 - Will randomize all specs
Will run 166 of 996 specs

May 30 22:24:52.490: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:24:52.493: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 30 22:24:52.524: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 30 22:24:52.646: INFO: 21 / 21 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 30 22:24:52.646: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
May 30 22:24:52.650: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 30 22:24:53.627: INFO: Dumping network health container logs from all nodes to file /tmp/results/nethealth.txt
May 30 22:24:53.632: INFO: e2e test version: v1.11.3
May 30 22:24:53.633: INFO: kube-apiserver version: v1.11.10
SSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:24:53.633: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
May 30 22:24:53.865: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name cm-test-opt-del-bf5925d1-8329-11e9-a3e0-52e03c2e65ea
STEP: Creating configMap with name cm-test-opt-upd-bf592607-8329-11e9-a3e0-52e03c2e65ea
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-bf5925d1-8329-11e9-a3e0-52e03c2e65ea
STEP: Updating configmap cm-test-opt-upd-bf592607-8329-11e9-a3e0-52e03c2e65ea
STEP: Creating configMap with name cm-test-opt-create-bf592631-8329-11e9-a3e0-52e03c2e65ea
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:26:22.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b24z9" for this suite.
May 30 22:26:44.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:26:44.991: INFO: namespace: e2e-tests-projected-b24z9, resource: bindings, ignored listing per whitelist
May 30 22:26:44.993: INFO: namespace e2e-tests-projected-b24z9 deletion completed in 22.104066202s

• [SLOW TEST:111.360 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:26:44.994: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-01a1c99a-832a-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume secrets
May 30 22:26:45.086: INFO: Waiting up to 5m0s for pod "pod-secrets-01a2619e-832a-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-secrets-fq6cd" to be "success or failure"
May 30 22:26:45.090: INFO: Pod "pod-secrets-01a2619e-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.238803ms
May 30 22:26:47.093: INFO: Pod "pod-secrets-01a2619e-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007456144s
May 30 22:26:49.097: INFO: Pod "pod-secrets-01a2619e-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010639285s
May 30 22:26:51.100: INFO: Pod "pod-secrets-01a2619e-832a-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014082126s
STEP: Saw pod success
May 30 22:26:51.100: INFO: Pod "pod-secrets-01a2619e-832a-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:26:51.102: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-secrets-01a2619e-832a-11e9-a3e0-52e03c2e65ea container secret-env-test: <nil>
STEP: delete the pod
May 30 22:26:51.153: INFO: Waiting for pod pod-secrets-01a2619e-832a-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:26:51.157: INFO: Pod pod-secrets-01a2619e-832a-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:26:51.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fq6cd" for this suite.
May 30 22:26:57.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:26:57.240: INFO: namespace: e2e-tests-secrets-fq6cd, resource: bindings, ignored listing per whitelist
May 30 22:26:57.252: INFO: namespace e2e-tests-secrets-fq6cd deletion completed in 6.092475783s

• [SLOW TEST:12.258 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:26:57.252: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:199
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:26:57.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7gjql" for this suite.
May 30 22:27:19.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:27:19.516: INFO: namespace: e2e-tests-pods-7gjql, resource: bindings, ignored listing per whitelist
May 30 22:27:19.645: INFO: namespace e2e-tests-pods-7gjql deletion completed in 22.274361138s

• [SLOW TEST:22.392 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:27:19.646: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 30 22:27:29.755: INFO: Waiting up to 5m0s for pod "client-envvars-1c41cc4f-832a-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-pods-sgv6x" to be "success or failure"
May 30 22:27:29.759: INFO: Pod "client-envvars-1c41cc4f-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.378003ms
May 30 22:27:31.765: INFO: Pod "client-envvars-1c41cc4f-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009983047s
May 30 22:27:33.768: INFO: Pod "client-envvars-1c41cc4f-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013460389s
May 30 22:27:35.772: INFO: Pod "client-envvars-1c41cc4f-832a-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016998632s
STEP: Saw pod success
May 30 22:27:35.772: INFO: Pod "client-envvars-1c41cc4f-832a-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:27:35.774: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod client-envvars-1c41cc4f-832a-11e9-a3e0-52e03c2e65ea container env3cont: <nil>
STEP: delete the pod
May 30 22:27:35.790: INFO: Waiting for pod client-envvars-1c41cc4f-832a-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:27:35.793: INFO: Pod client-envvars-1c41cc4f-832a-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:27:35.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-sgv6x" for this suite.
May 30 22:27:57.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:27:57.884: INFO: namespace: e2e-tests-pods-sgv6x, resource: bindings, ignored listing per whitelist
May 30 22:27:57.889: INFO: namespace e2e-tests-pods-sgv6x deletion completed in 22.092995807s

• [SLOW TEST:38.243 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:27:57.892: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 30 22:27:57.988: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:27:57.992: INFO: Number of nodes with available pods: 0
May 30 22:27:57.992: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:27:58.996: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:27:58.999: INFO: Number of nodes with available pods: 0
May 30 22:27:58.999: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:00.005: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:00.008: INFO: Number of nodes with available pods: 0
May 30 22:28:00.008: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:01.009: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:01.013: INFO: Number of nodes with available pods: 1
May 30 22:28:01.013: INFO: Node k8s-linuxpool-35502656-1 is running more than one daemon pod
May 30 22:28:01.996: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:02.000: INFO: Number of nodes with available pods: 2
May 30 22:28:02.000: INFO: Node k8s-linuxpool-35502656-1 is running more than one daemon pod
May 30 22:28:02.997: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:02.999: INFO: Number of nodes with available pods: 3
May 30 22:28:03.000: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 30 22:28:03.013: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:03.018: INFO: Number of nodes with available pods: 2
May 30 22:28:03.018: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:04.022: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:04.025: INFO: Number of nodes with available pods: 2
May 30 22:28:04.025: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:05.022: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:05.024: INFO: Number of nodes with available pods: 2
May 30 22:28:05.025: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:06.022: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:06.025: INFO: Number of nodes with available pods: 2
May 30 22:28:06.025: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:07.022: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:07.027: INFO: Number of nodes with available pods: 2
May 30 22:28:07.027: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:08.025: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:08.029: INFO: Number of nodes with available pods: 2
May 30 22:28:08.029: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:09.022: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:09.025: INFO: Number of nodes with available pods: 2
May 30 22:28:09.025: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:10.022: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:10.025: INFO: Number of nodes with available pods: 2
May 30 22:28:10.025: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:11.022: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:11.024: INFO: Number of nodes with available pods: 2
May 30 22:28:11.024: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:12.022: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:12.025: INFO: Number of nodes with available pods: 2
May 30 22:28:12.025: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:13.022: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:13.025: INFO: Number of nodes with available pods: 2
May 30 22:28:13.025: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:14.022: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:14.025: INFO: Number of nodes with available pods: 2
May 30 22:28:14.025: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:15.022: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:15.025: INFO: Number of nodes with available pods: 2
May 30 22:28:15.025: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:16.022: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:16.025: INFO: Number of nodes with available pods: 2
May 30 22:28:16.025: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:28:17.022: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:28:17.024: INFO: Number of nodes with available pods: 3
May 30 22:28:17.025: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-47s5s, will wait for the garbage collector to delete the pods
May 30 22:28:17.090: INFO: Deleting {extensions DaemonSet} daemon-set took: 10.206208ms
May 30 22:28:17.190: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.196772ms
May 30 22:28:20.692: INFO: Number of nodes with available pods: 0
May 30 22:28:20.692: INFO: Number of running nodes: 0, number of available pods: 0
May 30 22:28:20.696: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-47s5s/daemonsets","resourceVersion":"1692"},"items":null}

May 30 22:28:20.698: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-47s5s/pods","resourceVersion":"1692"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:28:20.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-47s5s" for this suite.
May 30 22:28:26.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:28:26.761: INFO: namespace: e2e-tests-daemonsets-47s5s, resource: bindings, ignored listing per whitelist
May 30 22:28:26.798: INFO: namespace e2e-tests-daemonsets-47s5s deletion completed in 6.088210388s

• [SLOW TEST:28.906 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:28:26.798: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1276
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
May 30 22:28:26.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 run e2e-test-nginx-rc --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=run/v1 --namespace=e2e-tests-kubectl-2kvn2'
May 30 22:28:27.264: INFO: stderr: ""
May 30 22:28:27.264: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
May 30 22:28:27.274: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
May 30 22:28:27.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 rolling-update e2e-test-nginx-rc --update-period=1s --image=k8s.gcr.io/nginx-slim-amd64:0.20 --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-2kvn2'
May 30 22:28:43.065: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 30 22:28:43.065: INFO: stdout: "Created e2e-test-nginx-rc-2ae4c48141e6f80be0a6b1d6241a8536\nScaling up e2e-test-nginx-rc-2ae4c48141e6f80be0a6b1d6241a8536 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-2ae4c48141e6f80be0a6b1d6241a8536 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-2ae4c48141e6f80be0a6b1d6241a8536 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 30 22:28:43.065: INFO: stdout: "Created e2e-test-nginx-rc-2ae4c48141e6f80be0a6b1d6241a8536\nScaling up e2e-test-nginx-rc-2ae4c48141e6f80be0a6b1d6241a8536 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-2ae4c48141e6f80be0a6b1d6241a8536 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-2ae4c48141e6f80be0a6b1d6241a8536 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 30 22:28:43.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-2kvn2'
May 30 22:28:43.184: INFO: stderr: ""
May 30 22:28:43.184: INFO: stdout: "e2e-test-nginx-rc-2ae4c48141e6f80be0a6b1d6241a8536-gcflt "
May 30 22:28:43.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods e2e-test-nginx-rc-2ae4c48141e6f80be0a6b1d6241a8536-gcflt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2kvn2'
May 30 22:28:43.299: INFO: stderr: ""
May 30 22:28:43.299: INFO: stdout: "true"
May 30 22:28:43.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods e2e-test-nginx-rc-2ae4c48141e6f80be0a6b1d6241a8536-gcflt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2kvn2'
May 30 22:28:43.423: INFO: stderr: ""
May 30 22:28:43.423: INFO: stdout: "k8s.gcr.io/nginx-slim-amd64:0.20"
May 30 22:28:43.423: INFO: e2e-test-nginx-rc-2ae4c48141e6f80be0a6b1d6241a8536-gcflt is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1282
May 30 22:28:43.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-2kvn2'
May 30 22:28:43.539: INFO: stderr: ""
May 30 22:28:43.539: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:28:43.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2kvn2" for this suite.
May 30 22:28:49.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:28:49.582: INFO: namespace: e2e-tests-kubectl-2kvn2, resource: bindings, ignored listing per whitelist
May 30 22:28:49.639: INFO: namespace e2e-tests-kubectl-2kvn2 deletion completed in 6.095603174s

• [SLOW TEST:22.840 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:28:49.639: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating pod
May 30 22:28:53.737: INFO: Pod pod-hostip-4bec626d-832a-11e9-a3e0-52e03c2e65ea has hostIP: 10.240.0.4
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:28:53.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9bq8q" for this suite.
May 30 22:29:15.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:29:15.808: INFO: namespace: e2e-tests-pods-9bq8q, resource: bindings, ignored listing per whitelist
May 30 22:29:15.832: INFO: namespace e2e-tests-pods-9bq8q deletion completed in 22.092197132s

• [SLOW TEST:26.193 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:29:15.833: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-5b88d24d-832a-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume secrets
May 30 22:29:15.916: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5b8932fe-832a-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-wsvzx" to be "success or failure"
May 30 22:29:15.919: INFO: Pod "pod-projected-secrets-5b8932fe-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.879304ms
May 30 22:29:17.922: INFO: Pod "pod-projected-secrets-5b8932fe-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006195683s
May 30 22:29:19.925: INFO: Pod "pod-projected-secrets-5b8932fe-832a-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009387354s
STEP: Saw pod success
May 30 22:29:19.925: INFO: Pod "pod-projected-secrets-5b8932fe-832a-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:29:19.927: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-projected-secrets-5b8932fe-832a-11e9-a3e0-52e03c2e65ea container projected-secret-volume-test: <nil>
STEP: delete the pod
May 30 22:29:19.943: INFO: Waiting for pod pod-projected-secrets-5b8932fe-832a-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:29:19.945: INFO: Pod pod-projected-secrets-5b8932fe-832a-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:29:19.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wsvzx" for this suite.
May 30 22:29:25.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:29:26.011: INFO: namespace: e2e-tests-projected-wsvzx, resource: bindings, ignored listing per whitelist
May 30 22:29:26.043: INFO: namespace e2e-tests-projected-wsvzx deletion completed in 6.095107275s

• [SLOW TEST:10.210 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:29:26.043: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-61a06c1e-832a-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 22:29:26.138: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-61a0ecbf-832a-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-hlzdm" to be "success or failure"
May 30 22:29:26.140: INFO: Pod "pod-projected-configmaps-61a0ecbf-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.445303ms
May 30 22:29:28.143: INFO: Pod "pod-projected-configmaps-61a0ecbf-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005040438s
May 30 22:29:30.146: INFO: Pod "pod-projected-configmaps-61a0ecbf-832a-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008396967s
STEP: Saw pod success
May 30 22:29:30.146: INFO: Pod "pod-projected-configmaps-61a0ecbf-832a-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:29:30.149: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-projected-configmaps-61a0ecbf-832a-11e9-a3e0-52e03c2e65ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 30 22:29:30.224: INFO: Waiting for pod pod-projected-configmaps-61a0ecbf-832a-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:29:30.227: INFO: Pod pod-projected-configmaps-61a0ecbf-832a-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:29:30.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hlzdm" for this suite.
May 30 22:29:36.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:29:36.289: INFO: namespace: e2e-tests-projected-hlzdm, resource: bindings, ignored listing per whitelist
May 30 22:29:36.322: INFO: namespace e2e-tests-projected-hlzdm deletion completed in 6.090514641s

• [SLOW TEST:10.278 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:29:36.322: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on node default medium
May 30 22:29:36.444: INFO: Waiting up to 5m0s for pod "pod-67c5c868-832a-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-emptydir-8kzkn" to be "success or failure"
May 30 22:29:36.449: INFO: Pod "pod-67c5c868-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.270405ms
May 30 22:29:38.453: INFO: Pod "pod-67c5c868-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008621302s
May 30 22:29:40.456: INFO: Pod "pod-67c5c868-832a-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01177219s
STEP: Saw pod success
May 30 22:29:40.456: INFO: Pod "pod-67c5c868-832a-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:29:40.458: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-67c5c868-832a-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 22:29:40.474: INFO: Waiting for pod pod-67c5c868-832a-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:29:40.476: INFO: Pod pod-67c5c868-832a-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:29:40.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8kzkn" for this suite.
May 30 22:29:46.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:29:46.548: INFO: namespace: e2e-tests-emptydir-8kzkn, resource: bindings, ignored listing per whitelist
May 30 22:29:46.567: INFO: namespace e2e-tests-emptydir-8kzkn deletion completed in 6.087348316s

• [SLOW TEST:10.245 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:29:46.569: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
May 30 22:29:50.670: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-6ddb8812-832a-11e9-a3e0-52e03c2e65ea", GenerateName:"", Namespace:"e2e-tests-pods-ffkzc", SelfLink:"/api/v1/namespaces/e2e-tests-pods-ffkzc/pods/pod-submit-remove-6ddb8812-832a-11e9-a3e0-52e03c2e65ea", UID:"6ddd3042-832a-11e9-9b52-001dd80c000f", ResourceVersion:"2053", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63694852186, loc:(*time.Location)(0x642e6e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"647968926"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-6ggdd", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc42102c980), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"k8s.gcr.io/nginx-slim-amd64:0.20", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6ggdd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc42129d298), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-linuxpool-35502656-0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4210250e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42129d2e0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42129d350)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc42129d358), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694852186, loc:(*time.Location)(0x642e6e0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694852188, loc:(*time.Location)(0x642e6e0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694852186, loc:(*time.Location)(0x642e6e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.240.0.4", PodIP:"10.244.1.11", StartTime:(*v1.Time)(0xc421377280), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4213772a0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"k8s.gcr.io/nginx-slim-amd64:0.20", ImageID:"docker-pullable://k8s.gcr.io/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b", ContainerID:"docker://84ef0d7648bd8a0fcd62163986c7fb0b9b780f071917b99d385155974bd00d09"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:30:04.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ffkzc" for this suite.
May 30 22:30:10.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:30:10.100: INFO: namespace: e2e-tests-pods-ffkzc, resource: bindings, ignored listing per whitelist
May 30 22:30:10.176: INFO: namespace e2e-tests-pods-ffkzc deletion completed in 6.109422582s

• [SLOW TEST:23.608 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:30:10.177: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 30 22:30:10.281: INFO: Waiting up to 5m0s for pod "pod-7bf06b7e-832a-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-emptydir-bs55w" to be "success or failure"
May 30 22:30:10.291: INFO: Pod "pod-7bf06b7e-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 9.096612ms
May 30 22:30:12.294: INFO: Pod "pod-7bf06b7e-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012354483s
May 30 22:30:14.297: INFO: Pod "pod-7bf06b7e-832a-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015729148s
STEP: Saw pod success
May 30 22:30:14.297: INFO: Pod "pod-7bf06b7e-832a-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:30:14.299: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-7bf06b7e-832a-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 22:30:14.317: INFO: Waiting for pod pod-7bf06b7e-832a-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:30:14.320: INFO: Pod pod-7bf06b7e-832a-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:30:14.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bs55w" for this suite.
May 30 22:30:20.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:30:20.358: INFO: namespace: e2e-tests-emptydir-bs55w, resource: bindings, ignored listing per whitelist
May 30 22:30:20.417: INFO: namespace e2e-tests-emptydir-bs55w deletion completed in 6.093858755s

• [SLOW TEST:10.240 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:30:20.417: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-zrjb7
May 30 22:30:30.504: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-zrjb7
STEP: checking the pod's current state and verifying that restartCount is present
May 30 22:30:30.506: INFO: Initial restart count of pod liveness-http is 0
May 30 22:30:46.535: INFO: Restart count of pod e2e-tests-container-probe-zrjb7/liveness-http is now 1 (16.028464869s elapsed)
May 30 22:31:06.567: INFO: Restart count of pod e2e-tests-container-probe-zrjb7/liveness-http is now 2 (36.060848265s elapsed)
May 30 22:31:26.659: INFO: Restart count of pod e2e-tests-container-probe-zrjb7/liveness-http is now 3 (56.152805574s elapsed)
May 30 22:31:48.713: INFO: Restart count of pod e2e-tests-container-probe-zrjb7/liveness-http is now 4 (1m18.206719821s elapsed)
May 30 22:32:48.864: INFO: Restart count of pod e2e-tests-container-probe-zrjb7/liveness-http is now 5 (2m18.358211243s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:32:48.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zrjb7" for this suite.
May 30 22:32:54.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:32:54.956: INFO: namespace: e2e-tests-container-probe-zrjb7, resource: bindings, ignored listing per whitelist
May 30 22:32:54.961: INFO: namespace e2e-tests-container-probe-zrjb7 deletion completed in 6.082734664s

• [SLOW TEST:154.544 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:32:54.961: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 30 22:33:21.050: INFO: Container started at 2019-05-30 22:32:57 +0000 UTC, pod became ready at 2019-05-30 22:33:20 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:33:21.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fhwgr" for this suite.
May 30 22:33:43.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:33:43.102: INFO: namespace: e2e-tests-container-probe-fhwgr, resource: bindings, ignored listing per whitelist
May 30 22:33:43.188: INFO: namespace e2e-tests-container-probe-fhwgr deletion completed in 22.134863945s

• [SLOW TEST:48.227 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:33:43.190: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
May 30 22:33:43.268: INFO: Waiting up to 5m0s for pod "downward-api-fae40d6b-832a-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-downward-api-llwgp" to be "success or failure"
May 30 22:33:43.271: INFO: Pod "downward-api-fae40d6b-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.952003ms
May 30 22:33:45.275: INFO: Pod "downward-api-fae40d6b-832a-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00688418s
May 30 22:33:47.278: INFO: Pod "downward-api-fae40d6b-832a-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010226153s
STEP: Saw pod success
May 30 22:33:47.278: INFO: Pod "downward-api-fae40d6b-832a-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:33:47.280: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod downward-api-fae40d6b-832a-11e9-a3e0-52e03c2e65ea container dapi-container: <nil>
STEP: delete the pod
May 30 22:33:47.296: INFO: Waiting for pod downward-api-fae40d6b-832a-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:33:47.298: INFO: Pod downward-api-fae40d6b-832a-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:33:47.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-llwgp" for this suite.
May 30 22:33:53.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:33:53.397: INFO: namespace: e2e-tests-downward-api-llwgp, resource: bindings, ignored listing per whitelist
May 30 22:33:53.457: INFO: namespace e2e-tests-downward-api-llwgp deletion completed in 6.155913646s

• [SLOW TEST:10.268 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:33:53.458: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-0102bb36-832b-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 22:33:53.538: INFO: Waiting up to 5m0s for pod "pod-configmaps-010353fc-832b-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-configmap-5s55q" to be "success or failure"
May 30 22:33:53.543: INFO: Pod "pod-configmaps-010353fc-832b-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.912804ms
May 30 22:33:55.546: INFO: Pod "pod-configmaps-010353fc-832b-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007976366s
May 30 22:33:57.549: INFO: Pod "pod-configmaps-010353fc-832b-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010903324s
STEP: Saw pod success
May 30 22:33:57.549: INFO: Pod "pod-configmaps-010353fc-832b-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:33:57.552: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-configmaps-010353fc-832b-11e9-a3e0-52e03c2e65ea container configmap-volume-test: <nil>
STEP: delete the pod
May 30 22:33:57.569: INFO: Waiting for pod pod-configmaps-010353fc-832b-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:33:57.573: INFO: Pod pod-configmaps-010353fc-832b-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:33:57.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5s55q" for this suite.
May 30 22:34:03.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:34:03.611: INFO: namespace: e2e-tests-configmap-5s55q, resource: bindings, ignored listing per whitelist
May 30 22:34:03.668: INFO: namespace e2e-tests-configmap-5s55q deletion completed in 6.091702639s

• [SLOW TEST:10.210 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:34:03.668: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5d2tf A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-5d2tf;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5d2tf A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-5d2tf;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5d2tf.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-5d2tf.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5d2tf.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-5d2tf.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5d2tf.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-5d2tf.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5d2tf.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5d2tf.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5d2tf.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-5d2tf.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5d2tf.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-5d2tf.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-5d2tf.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 109.52.0.10.in-addr.arpa. PTR)" && echo OK > /results/10.0.52.109_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 109.52.0.10.in-addr.arpa. PTR)" && echo OK > /results/10.0.52.109_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5d2tf A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-5d2tf;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5d2tf A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-5d2tf;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5d2tf.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-5d2tf.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5d2tf.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-5d2tf.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5d2tf.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5d2tf.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5d2tf.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5d2tf.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5d2tf.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-5d2tf.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5d2tf.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-5d2tf.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-5d2tf.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 109.52.0.10.in-addr.arpa. PTR)" && echo OK > /results/10.0.52.109_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 109.52.0.10.in-addr.arpa. PTR)" && echo OK > /results/10.0.52.109_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 30 22:34:33.908: INFO: DNS probes using dns-test-071d5bf9-832b-11e9-a3e0-52e03c2e65ea succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:34:33.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-5d2tf" for this suite.
May 30 22:34:39.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:34:40.042: INFO: namespace: e2e-tests-dns-5d2tf, resource: bindings, ignored listing per whitelist
May 30 22:34:40.073: INFO: namespace e2e-tests-dns-5d2tf deletion completed in 6.099475001s

• [SLOW TEST:36.405 seconds]
[sig-network] DNS
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:34:40.073: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on node default medium
May 30 22:34:40.158: INFO: Waiting up to 5m0s for pod "pod-1cccc25f-832b-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-emptydir-tjlrm" to be "success or failure"
May 30 22:34:40.161: INFO: Pod "pod-1cccc25f-832b-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.825403ms
May 30 22:34:42.164: INFO: Pod "pod-1cccc25f-832b-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005853503s
May 30 22:34:44.167: INFO: Pod "pod-1cccc25f-832b-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00914s
STEP: Saw pod success
May 30 22:34:44.167: INFO: Pod "pod-1cccc25f-832b-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:34:44.169: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-1cccc25f-832b-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 22:34:44.188: INFO: Waiting for pod pod-1cccc25f-832b-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:34:44.190: INFO: Pod pod-1cccc25f-832b-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:34:44.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tjlrm" for this suite.
May 30 22:34:50.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:34:50.219: INFO: namespace: e2e-tests-emptydir-tjlrm, resource: bindings, ignored listing per whitelist
May 30 22:34:50.297: INFO: namespace e2e-tests-emptydir-tjlrm deletion completed in 6.103582467s

• [SLOW TEST:10.224 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:34:50.299: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-4qcdk
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-4qcdk
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-4qcdk
May 30 22:34:50.411: INFO: Found 0 stateful pods, waiting for 1
May 30 22:35:00.415: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 30 22:35:00.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 30 22:35:00.689: INFO: stderr: ""
May 30 22:35:00.689: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 30 22:35:00.689: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 30 22:35:00.693: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 30 22:35:10.696: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 30 22:35:10.696: INFO: Waiting for statefulset status.replicas updated to 0
May 30 22:35:10.710: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 30 22:35:10.710: INFO: ss-0  k8s-linuxpool-35502656-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  }]
May 30 22:35:10.710: INFO: ss-1                            Pending         []
May 30 22:35:10.710: INFO: 
May 30 22:35:10.710: INFO: StatefulSet ss has not reached scale 3, at 2
May 30 22:35:11.714: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995876365s
May 30 22:35:12.717: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99217603s
May 30 22:35:13.720: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989290997s
May 30 22:35:14.724: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.985811663s
May 30 22:35:15.728: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98173843s
May 30 22:35:16.731: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.977951897s
May 30 22:35:17.735: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.974637665s
May 30 22:35:18.739: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.970751533s
May 30 22:35:19.743: INFO: Verifying statefulset ss doesn't scale past 3 for another 967.112302ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-4qcdk
May 30 22:35:20.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:35:21.019: INFO: stderr: ""
May 30 22:35:21.019: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 30 22:35:21.019: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 30 22:35:21.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:35:21.356: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
May 30 22:35:21.356: INFO: stdout: ""
May 30 22:35:21.356: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
May 30 22:35:21.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:35:21.603: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
May 30 22:35:21.603: INFO: stdout: ""
May 30 22:35:21.603: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
May 30 22:35:21.606: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
May 30 22:35:31.610: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 30 22:35:31.610: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 30 22:35:31.610: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 30 22:35:31.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 30 22:35:31.884: INFO: stderr: ""
May 30 22:35:31.884: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 30 22:35:31.884: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 30 22:35:31.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 30 22:35:32.171: INFO: stderr: ""
May 30 22:35:32.171: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 30 22:35:32.171: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 30 22:35:32.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 30 22:35:32.443: INFO: stderr: ""
May 30 22:35:32.443: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 30 22:35:32.443: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 30 22:35:32.443: INFO: Waiting for statefulset status.replicas updated to 0
May 30 22:35:32.445: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 30 22:35:42.451: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 30 22:35:42.451: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 30 22:35:42.451: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 30 22:35:42.464: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 30 22:35:42.464: INFO: ss-0  k8s-linuxpool-35502656-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  }]
May 30 22:35:42.464: INFO: ss-1  k8s-linuxpool-35502656-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:42.464: INFO: ss-2  k8s-linuxpool-35502656-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:42.464: INFO: 
May 30 22:35:42.464: INFO: StatefulSet ss has not reached scale 0, at 3
May 30 22:35:43.468: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 30 22:35:43.468: INFO: ss-0  k8s-linuxpool-35502656-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  }]
May 30 22:35:43.468: INFO: ss-1  k8s-linuxpool-35502656-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:43.468: INFO: ss-2  k8s-linuxpool-35502656-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:43.468: INFO: 
May 30 22:35:43.468: INFO: StatefulSet ss has not reached scale 0, at 3
May 30 22:35:44.471: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 30 22:35:44.471: INFO: ss-0  k8s-linuxpool-35502656-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  }]
May 30 22:35:44.471: INFO: ss-1  k8s-linuxpool-35502656-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:44.471: INFO: ss-2  k8s-linuxpool-35502656-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:44.471: INFO: 
May 30 22:35:44.471: INFO: StatefulSet ss has not reached scale 0, at 3
May 30 22:35:45.475: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 30 22:35:45.475: INFO: ss-0  k8s-linuxpool-35502656-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  }]
May 30 22:35:45.475: INFO: ss-1  k8s-linuxpool-35502656-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:45.475: INFO: ss-2  k8s-linuxpool-35502656-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:45.475: INFO: 
May 30 22:35:45.475: INFO: StatefulSet ss has not reached scale 0, at 3
May 30 22:35:46.478: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 30 22:35:46.478: INFO: ss-0  k8s-linuxpool-35502656-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  }]
May 30 22:35:46.478: INFO: ss-1  k8s-linuxpool-35502656-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:46.478: INFO: ss-2  k8s-linuxpool-35502656-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:46.478: INFO: 
May 30 22:35:46.478: INFO: StatefulSet ss has not reached scale 0, at 3
May 30 22:35:47.482: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 30 22:35:47.482: INFO: ss-0  k8s-linuxpool-35502656-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  }]
May 30 22:35:47.482: INFO: ss-1  k8s-linuxpool-35502656-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:47.482: INFO: ss-2  k8s-linuxpool-35502656-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:47.482: INFO: 
May 30 22:35:47.482: INFO: StatefulSet ss has not reached scale 0, at 3
May 30 22:35:48.486: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 30 22:35:48.486: INFO: ss-0  k8s-linuxpool-35502656-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  }]
May 30 22:35:48.486: INFO: ss-1  k8s-linuxpool-35502656-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:48.486: INFO: ss-2  k8s-linuxpool-35502656-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:48.486: INFO: 
May 30 22:35:48.486: INFO: StatefulSet ss has not reached scale 0, at 3
May 30 22:35:49.490: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 30 22:35:49.490: INFO: ss-0  k8s-linuxpool-35502656-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  }]
May 30 22:35:49.490: INFO: ss-1  k8s-linuxpool-35502656-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:49.490: INFO: ss-2  k8s-linuxpool-35502656-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:49.490: INFO: 
May 30 22:35:49.490: INFO: StatefulSet ss has not reached scale 0, at 3
May 30 22:35:50.493: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 30 22:35:50.493: INFO: ss-0  k8s-linuxpool-35502656-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  }]
May 30 22:35:50.493: INFO: ss-1  k8s-linuxpool-35502656-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:50.493: INFO: ss-2  k8s-linuxpool-35502656-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:50.493: INFO: 
May 30 22:35:50.493: INFO: StatefulSet ss has not reached scale 0, at 3
May 30 22:35:51.517: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 30 22:35:51.517: INFO: ss-0  k8s-linuxpool-35502656-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:34:50 +0000 UTC  }]
May 30 22:35:51.517: INFO: ss-1  k8s-linuxpool-35502656-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:51.517: INFO: ss-2  k8s-linuxpool-35502656-1  Pending  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 22:35:10 +0000 UTC  }]
May 30 22:35:51.517: INFO: 
May 30 22:35:51.517: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-4qcdk
May 30 22:35:52.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:35:52.720: INFO: rc: 1
May 30 22:35:52.721: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc4216fc660 exit status 1 <nil> <nil> true [0xc4218cb598 0xc4218cb5b0 0xc4218cb5c8] [0xc4218cb598 0xc4218cb5b0 0xc4218cb5c8] [0xc4218cb5a8 0xc4218cb5c0] [0x8f9b60 0x8f9b60] 0xc4220ec180 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

May 30 22:36:02.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:36:02.847: INFO: rc: 1
May 30 22:36:02.847: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216fcab0 exit status 1 <nil> <nil> true [0xc4218cb5d0 0xc4218cb5e8 0xc4218cb600] [0xc4218cb5d0 0xc4218cb5e8 0xc4218cb600] [0xc4218cb5e0 0xc4218cb5f8] [0x8f9b60 0x8f9b60] 0xc4220ec780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:36:12.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:36:12.961: INFO: rc: 1
May 30 22:36:12.961: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421d0ab40 exit status 1 <nil> <nil> true [0xc421351708 0xc421351720 0xc421351738] [0xc421351708 0xc421351720 0xc421351738] [0xc421351718 0xc421351730] [0x8f9b60 0x8f9b60] 0xc4212a9a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:36:22.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:36:23.076: INFO: rc: 1
May 30 22:36:23.076: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421d0af90 exit status 1 <nil> <nil> true [0xc421351740 0xc421351758 0xc421351770] [0xc421351740 0xc421351758 0xc421351770] [0xc421351750 0xc421351768] [0x8f9b60 0x8f9b60] 0xc4212a9c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:36:33.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:36:33.195: INFO: rc: 1
May 30 22:36:33.195: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4216fcf60 exit status 1 <nil> <nil> true [0xc4218cb608 0xc4218cb620 0xc4218cb638] [0xc4218cb608 0xc4218cb620 0xc4218cb638] [0xc4218cb618 0xc4218cb630] [0x8f9b60 0x8f9b60] 0xc4220ecb40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:36:43.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:36:43.300: INFO: rc: 1
May 30 22:36:43.300: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421438420 exit status 1 <nil> <nil> true [0xc421350010 0xc421350050 0xc421350068] [0xc421350010 0xc421350050 0xc421350068] [0xc421350038 0xc421350060] [0x8f9b60 0x8f9b60] 0xc420be0060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:36:53.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:36:53.407: INFO: rc: 1
May 30 22:36:53.407: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42077fcb0 exit status 1 <nil> <nil> true [0xc4218ca000 0xc4218ca018 0xc4218ca030] [0xc4218ca000 0xc4218ca018 0xc4218ca030] [0xc4218ca010 0xc4218ca028] [0x8f9b60 0x8f9b60] 0xc421c16240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:37:03.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:37:03.499: INFO: rc: 1
May 30 22:37:03.499: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421438810 exit status 1 <nil> <nil> true [0xc421350070 0xc421350088 0xc4213500a0] [0xc421350070 0xc421350088 0xc4213500a0] [0xc421350080 0xc421350098] [0x8f9b60 0x8f9b60] 0xc420be0180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:37:13.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:37:13.610: INFO: rc: 1
May 30 22:37:13.610: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421438c00 exit status 1 <nil> <nil> true [0xc4213500a8 0xc4213500c0 0xc4213500d8] [0xc4213500a8 0xc4213500c0 0xc4213500d8] [0xc4213500b8 0xc4213500d0] [0x8f9b60 0x8f9b60] 0xc420be02a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:37:23.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:37:23.713: INFO: rc: 1
May 30 22:37:23.713: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421438ff0 exit status 1 <nil> <nil> true [0xc4213500e0 0xc4213500f8 0xc421350110] [0xc4213500e0 0xc4213500f8 0xc421350110] [0xc4213500f0 0xc421350108] [0x8f9b60 0x8f9b60] 0xc420be03c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:37:33.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:37:33.818: INFO: rc: 1
May 30 22:37:33.818: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4214393e0 exit status 1 <nil> <nil> true [0xc421350118 0xc421350130 0xc421350160] [0xc421350118 0xc421350130 0xc421350160] [0xc421350128 0xc421350148] [0x8f9b60 0x8f9b60] 0xc420be04e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:37:43.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:37:43.933: INFO: rc: 1
May 30 22:37:43.933: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4209f42d0 exit status 1 <nil> <nil> true [0xc4218ca038 0xc4218ca050 0xc4218ca068] [0xc4218ca038 0xc4218ca050 0xc4218ca068] [0xc4218ca048 0xc4218ca060] [0x8f9b60 0x8f9b60] 0xc421c16420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:37:53.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:37:54.049: INFO: rc: 1
May 30 22:37:54.049: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4214397d0 exit status 1 <nil> <nil> true [0xc421350168 0xc421350180 0xc421350198] [0xc421350168 0xc421350180 0xc421350198] [0xc421350178 0xc421350190] [0x8f9b60 0x8f9b60] 0xc420be0600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:38:04.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:38:04.152: INFO: rc: 1
May 30 22:38:04.152: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421439bc0 exit status 1 <nil> <nil> true [0xc4213501a0 0xc4213501b8 0xc4213501d0] [0xc4213501a0 0xc4213501b8 0xc4213501d0] [0xc4213501b0 0xc4213501c8] [0x8f9b60 0x8f9b60] 0xc420be0720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:38:14.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:38:14.259: INFO: rc: 1
May 30 22:38:14.259: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421439fb0 exit status 1 <nil> <nil> true [0xc4213501d8 0xc4213501f0 0xc421350208] [0xc4213501d8 0xc4213501f0 0xc421350208] [0xc4213501e8 0xc421350200] [0x8f9b60 0x8f9b60] 0xc420be0840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:38:24.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:38:24.365: INFO: rc: 1
May 30 22:38:24.365: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4209f4930 exit status 1 <nil> <nil> true [0xc4218ca070 0xc4218ca088 0xc4218ca0a0] [0xc4218ca070 0xc4218ca088 0xc4218ca0a0] [0xc4218ca080 0xc4218ca098] [0x8f9b60 0x8f9b60] 0xc421c16720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:38:34.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:38:34.467: INFO: rc: 1
May 30 22:38:34.468: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421a28360 exit status 1 <nil> <nil> true [0xc421350210 0xc421350228 0xc421350240] [0xc421350210 0xc421350228 0xc421350240] [0xc421350220 0xc421350238] [0x8f9b60 0x8f9b60] 0xc420be0960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:38:44.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:38:44.590: INFO: rc: 1
May 30 22:38:44.590: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42077eba0 exit status 1 <nil> <nil> true [0xc4218ca008 0xc4218ca020 0xc4218ca038] [0xc4218ca008 0xc4218ca020 0xc4218ca038] [0xc4218ca018 0xc4218ca030] [0x8f9b60 0x8f9b60] 0xc421c16240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:38:54.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:38:54.696: INFO: rc: 1
May 30 22:38:54.696: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421438450 exit status 1 <nil> <nil> true [0xc421350000 0xc421350038 0xc421350060] [0xc421350000 0xc421350038 0xc421350060] [0xc421350030 0xc421350058] [0x8f9b60 0x8f9b60] 0xc420be0060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:39:04.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:39:04.798: INFO: rc: 1
May 30 22:39:04.798: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4209f41e0 exit status 1 <nil> <nil> true [0xc4218ca040 0xc4218ca058 0xc4218ca070] [0xc4218ca040 0xc4218ca058 0xc4218ca070] [0xc4218ca050 0xc4218ca068] [0x8f9b60 0x8f9b60] 0xc421c16420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:39:14.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:39:14.899: INFO: rc: 1
May 30 22:39:14.899: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421438840 exit status 1 <nil> <nil> true [0xc421350068 0xc421350080 0xc421350098] [0xc421350068 0xc421350080 0xc421350098] [0xc421350078 0xc421350090] [0x8f9b60 0x8f9b60] 0xc420be0180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:39:24.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:39:25.003: INFO: rc: 1
May 30 22:39:25.003: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421438c30 exit status 1 <nil> <nil> true [0xc4213500a0 0xc4213500b8 0xc4213500d0] [0xc4213500a0 0xc4213500b8 0xc4213500d0] [0xc4213500b0 0xc4213500c8] [0x8f9b60 0x8f9b60] 0xc420be02a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:39:35.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:39:35.115: INFO: rc: 1
May 30 22:39:35.115: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421439050 exit status 1 <nil> <nil> true [0xc4213500d8 0xc4213500f0 0xc421350108] [0xc4213500d8 0xc4213500f0 0xc421350108] [0xc4213500e8 0xc421350100] [0x8f9b60 0x8f9b60] 0xc420be03c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:39:45.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:39:45.228: INFO: rc: 1
May 30 22:39:45.228: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421439470 exit status 1 <nil> <nil> true [0xc421350110 0xc421350128 0xc421350148] [0xc421350110 0xc421350128 0xc421350148] [0xc421350120 0xc421350138] [0x8f9b60 0x8f9b60] 0xc420be04e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:39:55.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:39:55.335: INFO: rc: 1
May 30 22:39:55.335: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4209f4900 exit status 1 <nil> <nil> true [0xc4218ca078 0xc4218ca090 0xc4218ca0a8] [0xc4218ca078 0xc4218ca090 0xc4218ca0a8] [0xc4218ca088 0xc4218ca0a0] [0x8f9b60 0x8f9b60] 0xc421c16720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:40:05.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:40:05.429: INFO: rc: 1
May 30 22:40:05.429: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4209f4de0 exit status 1 <nil> <nil> true [0xc4218ca0b0 0xc4218ca0c8 0xc4218ca0e0] [0xc4218ca0b0 0xc4218ca0c8 0xc4218ca0e0] [0xc4218ca0c0 0xc4218ca0d8] [0x8f9b60 0x8f9b60] 0xc421c16960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:40:15.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:40:15.531: INFO: rc: 1
May 30 22:40:15.531: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421439890 exit status 1 <nil> <nil> true [0xc421350160 0xc421350178 0xc421350190] [0xc421350160 0xc421350178 0xc421350190] [0xc421350170 0xc421350188] [0x8f9b60 0x8f9b60] 0xc420be0600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:40:25.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:40:25.654: INFO: rc: 1
May 30 22:40:25.654: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421439c80 exit status 1 <nil> <nil> true [0xc421350198 0xc4213501b0 0xc4213501c8] [0xc421350198 0xc4213501b0 0xc4213501c8] [0xc4213501a8 0xc4213501c0] [0x8f9b60 0x8f9b60] 0xc420be0720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:40:35.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:40:35.762: INFO: rc: 1
May 30 22:40:35.762: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421a280f0 exit status 1 <nil> <nil> true [0xc4213501d0 0xc4213501e8 0xc421350200] [0xc4213501d0 0xc4213501e8 0xc421350200] [0xc4213501e0 0xc4213501f8] [0x8f9b60 0x8f9b60] 0xc420be0840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:40:45.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:40:45.866: INFO: rc: 1
May 30 22:40:45.868: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421a28150 exit status 1 <nil> <nil> true [0xc4218ca0e8 0xc4218ca100 0xc4218ca118] [0xc4218ca0e8 0xc4218ca100 0xc4218ca118] [0xc4218ca0f8 0xc4218ca110] [0x8f9b60 0x8f9b60] 0xc420be0900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 30 22:40:55.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-4qcdk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:40:55.985: INFO: rc: 1
May 30 22:40:55.985: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
May 30 22:40:55.985: INFO: Scaling statefulset ss to 0
May 30 22:40:55.993: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 30 22:40:55.995: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4qcdk
May 30 22:40:55.997: INFO: Scaling statefulset ss to 0
May 30 22:40:56.003: INFO: Waiting for statefulset status.replicas updated to 0
May 30 22:40:56.005: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:40:56.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4qcdk" for this suite.
May 30 22:41:02.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:41:02.056: INFO: namespace: e2e-tests-statefulset-4qcdk, resource: bindings, ignored listing per whitelist
May 30 22:41:02.194: INFO: namespace e2e-tests-statefulset-4qcdk deletion completed in 6.176778535s

• [SLOW TEST:371.896 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:41:02.194: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on node default medium
May 30 22:41:02.361: INFO: Waiting up to 5m0s for pod "pod-00983031-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-emptydir-gbwcl" to be "success or failure"
May 30 22:41:02.363: INFO: Pod "pod-00983031-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.440902ms
May 30 22:41:04.366: INFO: Pod "pod-00983031-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005038966s
May 30 22:41:06.369: INFO: Pod "pod-00983031-832c-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008229429s
STEP: Saw pod success
May 30 22:41:06.369: INFO: Pod "pod-00983031-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:41:06.371: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-00983031-832c-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 22:41:06.388: INFO: Waiting for pod pod-00983031-832c-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:41:06.390: INFO: Pod pod-00983031-832c-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:41:06.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gbwcl" for this suite.
May 30 22:41:12.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:41:12.464: INFO: namespace: e2e-tests-emptydir-gbwcl, resource: bindings, ignored listing per whitelist
May 30 22:41:12.513: INFO: namespace e2e-tests-emptydir-gbwcl deletion completed in 6.118686679s

• [SLOW TEST:10.319 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:41:12.514: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 30 22:41:12.636: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:41:13.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-4vksr" for this suite.
May 30 22:41:19.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:41:19.868: INFO: namespace: e2e-tests-custom-resource-definition-4vksr, resource: bindings, ignored listing per whitelist
May 30 22:41:19.868: INFO: namespace e2e-tests-custom-resource-definition-4vksr deletion completed in 6.133987784s

• [SLOW TEST:7.354 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:41:19.869: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Starting the proxy
May 30 22:41:19.962: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-884905328 proxy --unix-socket=/tmp/kubectl-proxy-unix279766031/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:41:20.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jf8cp" for this suite.
May 30 22:41:26.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:41:26.125: INFO: namespace: e2e-tests-kubectl-jf8cp, resource: bindings, ignored listing per whitelist
May 30 22:41:26.145: INFO: namespace e2e-tests-kubectl-jf8cp deletion completed in 6.093568947s

• [SLOW TEST:6.277 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:41:26.146: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override all
May 30 22:41:26.227: INFO: Waiting up to 5m0s for pod "client-containers-0ed61435-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-containers-rnrtm" to be "success or failure"
May 30 22:41:26.233: INFO: Pod "client-containers-0ed61435-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.942205ms
May 30 22:41:28.237: INFO: Pod "client-containers-0ed61435-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009797764s
May 30 22:41:30.240: INFO: Pod "client-containers-0ed61435-832c-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012775421s
STEP: Saw pod success
May 30 22:41:30.240: INFO: Pod "client-containers-0ed61435-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:41:30.242: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod client-containers-0ed61435-832c-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 22:41:30.327: INFO: Waiting for pod client-containers-0ed61435-832c-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:41:30.329: INFO: Pod client-containers-0ed61435-832c-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:41:30.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-rnrtm" for this suite.
May 30 22:41:36.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:41:36.363: INFO: namespace: e2e-tests-containers-rnrtm, resource: bindings, ignored listing per whitelist
May 30 22:41:36.423: INFO: namespace e2e-tests-containers-rnrtm deletion completed in 6.091036137s

• [SLOW TEST:10.278 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:41:36.423: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 30 22:41:36.512: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-frp24,SelfLink:/api/v1/namespaces/e2e-tests-watch-frp24/configmaps/e2e-watch-test-configmap-a,UID:14f8d615-832c-11e9-9b52-001dd80c000f,ResourceVersion:3671,Generation:0,CreationTimestamp:2019-05-30 22:41:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 30 22:41:36.512: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-frp24,SelfLink:/api/v1/namespaces/e2e-tests-watch-frp24/configmaps/e2e-watch-test-configmap-a,UID:14f8d615-832c-11e9-9b52-001dd80c000f,ResourceVersion:3671,Generation:0,CreationTimestamp:2019-05-30 22:41:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 30 22:41:46.518: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-frp24,SelfLink:/api/v1/namespaces/e2e-tests-watch-frp24/configmaps/e2e-watch-test-configmap-a,UID:14f8d615-832c-11e9-9b52-001dd80c000f,ResourceVersion:3687,Generation:0,CreationTimestamp:2019-05-30 22:41:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 30 22:41:46.518: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-frp24,SelfLink:/api/v1/namespaces/e2e-tests-watch-frp24/configmaps/e2e-watch-test-configmap-a,UID:14f8d615-832c-11e9-9b52-001dd80c000f,ResourceVersion:3687,Generation:0,CreationTimestamp:2019-05-30 22:41:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 30 22:41:56.524: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-frp24,SelfLink:/api/v1/namespaces/e2e-tests-watch-frp24/configmaps/e2e-watch-test-configmap-a,UID:14f8d615-832c-11e9-9b52-001dd80c000f,ResourceVersion:3703,Generation:0,CreationTimestamp:2019-05-30 22:41:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 30 22:41:56.524: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-frp24,SelfLink:/api/v1/namespaces/e2e-tests-watch-frp24/configmaps/e2e-watch-test-configmap-a,UID:14f8d615-832c-11e9-9b52-001dd80c000f,ResourceVersion:3703,Generation:0,CreationTimestamp:2019-05-30 22:41:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 30 22:42:06.529: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-frp24,SelfLink:/api/v1/namespaces/e2e-tests-watch-frp24/configmaps/e2e-watch-test-configmap-a,UID:14f8d615-832c-11e9-9b52-001dd80c000f,ResourceVersion:3723,Generation:0,CreationTimestamp:2019-05-30 22:41:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 30 22:42:06.529: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-frp24,SelfLink:/api/v1/namespaces/e2e-tests-watch-frp24/configmaps/e2e-watch-test-configmap-a,UID:14f8d615-832c-11e9-9b52-001dd80c000f,ResourceVersion:3723,Generation:0,CreationTimestamp:2019-05-30 22:41:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 30 22:42:16.539: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-frp24,SelfLink:/api/v1/namespaces/e2e-tests-watch-frp24/configmaps/e2e-watch-test-configmap-b,UID:2cd3a975-832c-11e9-9b52-001dd80c000f,ResourceVersion:3739,Generation:0,CreationTimestamp:2019-05-30 22:42:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 30 22:42:16.539: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-frp24,SelfLink:/api/v1/namespaces/e2e-tests-watch-frp24/configmaps/e2e-watch-test-configmap-b,UID:2cd3a975-832c-11e9-9b52-001dd80c000f,ResourceVersion:3739,Generation:0,CreationTimestamp:2019-05-30 22:42:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 30 22:42:26.544: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-frp24,SelfLink:/api/v1/namespaces/e2e-tests-watch-frp24/configmaps/e2e-watch-test-configmap-b,UID:2cd3a975-832c-11e9-9b52-001dd80c000f,ResourceVersion:3753,Generation:0,CreationTimestamp:2019-05-30 22:42:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 30 22:42:26.545: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-frp24,SelfLink:/api/v1/namespaces/e2e-tests-watch-frp24/configmaps/e2e-watch-test-configmap-b,UID:2cd3a975-832c-11e9-9b52-001dd80c000f,ResourceVersion:3753,Generation:0,CreationTimestamp:2019-05-30 22:42:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:42:36.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-frp24" for this suite.
May 30 22:42:42.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:42:42.623: INFO: namespace: e2e-tests-watch-frp24, resource: bindings, ignored listing per whitelist
May 30 22:42:42.643: INFO: namespace e2e-tests-watch-frp24 deletion completed in 6.094350197s

• [SLOW TEST:66.220 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:42:42.643: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-3c6df56c-832c-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 22:42:42.725: INFO: Waiting up to 5m0s for pod "pod-configmaps-3c6e57ba-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-configmap-ncbk8" to be "success or failure"
May 30 22:42:42.730: INFO: Pod "pod-configmaps-3c6e57ba-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.913504ms
May 30 22:42:44.733: INFO: Pod "pod-configmaps-3c6e57ba-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007694645s
May 30 22:42:46.736: INFO: Pod "pod-configmaps-3c6e57ba-832c-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010645087s
STEP: Saw pod success
May 30 22:42:46.736: INFO: Pod "pod-configmaps-3c6e57ba-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:42:46.738: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-configmaps-3c6e57ba-832c-11e9-a3e0-52e03c2e65ea container configmap-volume-test: <nil>
STEP: delete the pod
May 30 22:42:46.754: INFO: Waiting for pod pod-configmaps-3c6e57ba-832c-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:42:46.756: INFO: Pod pod-configmaps-3c6e57ba-832c-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:42:46.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ncbk8" for this suite.
May 30 22:42:52.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:42:52.815: INFO: namespace: e2e-tests-configmap-ncbk8, resource: bindings, ignored listing per whitelist
May 30 22:42:52.843: INFO: namespace e2e-tests-configmap-ncbk8 deletion completed in 6.083433682s

• [SLOW TEST:10.199 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:42:52.843: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-42877d5b-832c-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 22:42:52.957: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4287fefe-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-9q8hf" to be "success or failure"
May 30 22:42:52.963: INFO: Pod "pod-projected-configmaps-4287fefe-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.387305ms
May 30 22:42:54.966: INFO: Pod "pod-projected-configmaps-4287fefe-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009582246s
May 30 22:42:56.969: INFO: Pod "pod-projected-configmaps-4287fefe-832c-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012265485s
STEP: Saw pod success
May 30 22:42:56.969: INFO: Pod "pod-projected-configmaps-4287fefe-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:42:56.972: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-projected-configmaps-4287fefe-832c-11e9-a3e0-52e03c2e65ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 30 22:42:56.989: INFO: Waiting for pod pod-projected-configmaps-4287fefe-832c-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:42:56.993: INFO: Pod pod-projected-configmaps-4287fefe-832c-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:42:56.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9q8hf" for this suite.
May 30 22:43:03.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:43:03.018: INFO: namespace: e2e-tests-projected-9q8hf, resource: bindings, ignored listing per whitelist
May 30 22:43:03.077: INFO: namespace e2e-tests-projected-9q8hf deletion completed in 6.081676377s

• [SLOW TEST:10.234 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:43:03.077: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-489cd19c-832c-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume secrets
May 30 22:43:03.162: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-489d41e0-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-ftv74" to be "success or failure"
May 30 22:43:03.164: INFO: Pod "pod-projected-secrets-489d41e0-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019002ms
May 30 22:43:05.167: INFO: Pod "pod-projected-secrets-489d41e0-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00510554s
May 30 22:43:07.170: INFO: Pod "pod-projected-secrets-489d41e0-832c-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007999078s
STEP: Saw pod success
May 30 22:43:07.170: INFO: Pod "pod-projected-secrets-489d41e0-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:43:07.172: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-projected-secrets-489d41e0-832c-11e9-a3e0-52e03c2e65ea container projected-secret-volume-test: <nil>
STEP: delete the pod
May 30 22:43:07.187: INFO: Waiting for pod pod-projected-secrets-489d41e0-832c-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:43:07.189: INFO: Pod pod-projected-secrets-489d41e0-832c-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:43:07.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ftv74" for this suite.
May 30 22:43:13.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:43:13.279: INFO: namespace: e2e-tests-projected-ftv74, resource: bindings, ignored listing per whitelist
May 30 22:43:13.297: INFO: namespace e2e-tests-projected-ftv74 deletion completed in 6.10483959s

• [SLOW TEST:10.220 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:43:13.297: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 30 22:43:13.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 version --client'
May 30 22:43:13.476: INFO: stderr: ""
May 30 22:43:13.476: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.3\", GitCommit:\"a4529464e4629c21224b3d52edfe0ea91b072862\", GitTreeState:\"clean\", BuildDate:\"2018-09-09T18:02:47Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 30 22:43:13.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-qh4lv'
May 30 22:43:14.121: INFO: stderr: ""
May 30 22:43:14.121: INFO: stdout: "replicationcontroller/redis-master created\n"
May 30 22:43:14.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-qh4lv'
May 30 22:43:14.579: INFO: stderr: ""
May 30 22:43:14.579: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
May 30 22:43:15.583: INFO: Selector matched 1 pods for map[app:redis]
May 30 22:43:15.583: INFO: Found 0 / 1
May 30 22:43:16.582: INFO: Selector matched 1 pods for map[app:redis]
May 30 22:43:16.582: INFO: Found 0 / 1
May 30 22:43:17.582: INFO: Selector matched 1 pods for map[app:redis]
May 30 22:43:17.582: INFO: Found 0 / 1
May 30 22:43:18.583: INFO: Selector matched 1 pods for map[app:redis]
May 30 22:43:18.583: INFO: Found 1 / 1
May 30 22:43:18.583: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 30 22:43:18.585: INFO: Selector matched 1 pods for map[app:redis]
May 30 22:43:18.585: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 30 22:43:18.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 describe pod redis-master-2w24c --namespace=e2e-tests-kubectl-qh4lv'
May 30 22:43:18.706: INFO: stderr: ""
May 30 22:43:18.706: INFO: stdout: "Name:               redis-master-2w24c\nNamespace:          e2e-tests-kubectl-qh4lv\nPriority:           0\nPriorityClassName:  <none>\nNode:               k8s-linuxpool-35502656-0/10.240.0.4\nStart Time:         Thu, 30 May 2019 22:43:14 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.1.18\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://45675777a797d77d6964cc73ea9a02116975dfb51facbe261d332afa085f43d1\n    Image:          gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis-amd64@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 30 May 2019 22:43:17 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-tv8wj (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-tv8wj:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-tv8wj\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                               Message\n  ----    ------     ----  ----                               -------\n  Normal  Scheduled  4s    default-scheduler                  Successfully assigned e2e-tests-kubectl-qh4lv/redis-master-2w24c to k8s-linuxpool-35502656-0\n  Normal  Pulling    3s    kubelet, k8s-linuxpool-35502656-0  pulling image \"gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\"\n  Normal  Pulled     2s    kubelet, k8s-linuxpool-35502656-0  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\"\n  Normal  Created    1s    kubelet, k8s-linuxpool-35502656-0  Created container\n  Normal  Started    1s    kubelet, k8s-linuxpool-35502656-0  Started container\n"
May 30 22:43:18.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 describe rc redis-master --namespace=e2e-tests-kubectl-qh4lv'
May 30 22:43:18.829: INFO: stderr: ""
May 30 22:43:18.829: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-qh4lv\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-2w24c\n"
May 30 22:43:18.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 describe service redis-master --namespace=e2e-tests-kubectl-qh4lv'
May 30 22:43:18.946: INFO: stderr: ""
May 30 22:43:18.946: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-qh4lv\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.0.89.71\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.1.18:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 30 22:43:18.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 describe node k8s-linuxpool-35502656-0'
May 30 22:43:19.085: INFO: stderr: ""
May 30 22:43:19.085: INFO: stdout: "Name:               k8s-linuxpool-35502656-0\nRoles:              agent\nLabels:             agentpool=linuxpool\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_D2_v2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=redmond\n                    failure-domain.beta.kubernetes.io/zone=0\n                    kubernetes.azure.com/cluster=rgk8s-26985\n                    kubernetes.io/hostname=k8s-linuxpool-35502656-0\n                    kubernetes.io/role=agent\n                    node-role.kubernetes.io/agent=\n                    storageprofile=managed\n                    storagetier=Standard_LRS\nAnnotations:        flannel.alpha.coreos.com/backend-data={\"VtepMAC\":\"8e:06:1f:b8:ad:9e\"}\n                    flannel.alpha.coreos.com/backend-type=vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager=true\n                    flannel.alpha.coreos.com/public-ip=10.240.0.4\n                    node.alpha.kubernetes.io/ttl=0\n                    volumes.kubernetes.io/controller-managed-attach-detach=true\nCreationTimestamp:  Thu, 30 May 2019 22:21:39 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Thu, 30 May 2019 22:43:14 +0000   Thu, 30 May 2019 22:21:32 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Thu, 30 May 2019 22:43:14 +0000   Thu, 30 May 2019 22:21:32 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 30 May 2019 22:43:14 +0000   Thu, 30 May 2019 22:21:32 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 30 May 2019 22:43:14 +0000   Thu, 30 May 2019 22:21:32 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 30 May 2019 22:43:14 +0000   Thu, 30 May 2019 22:22:29 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.240.0.4\n  Hostname:    k8s-linuxpool-35502656-0\nCapacity:\n cpu:                2\n ephemeral-storage:  203234980Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             7137156Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  187301357258\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             6369156Ki\n pods:               110\nSystem Info:\n Machine ID:                 f815325ede874839b56964d442742264\n System UUID:                8A1CAD87-BBB1-3E43-ADE0-9929042C5E87\n Boot ID:                    74f603f7-0914-47f2-85e6-fc9b172004ed\n Kernel Version:             4.15.0-1022-azure\n OS Image:                   Ubuntu 16.04.6 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://3.0.5\n Kubelet Version:            v1.11.10\n Kube-Proxy Version:         v1.11.10\nPodCIDR:                     10.244.1.0/24\nProviderID:                  azure:///subscriptions/751df60b-8fe7-44ff-b2e7-b3a118855ea4/resourceGroups/rgk8s-26985/providers/Microsoft.Compute/virtualMachines/k8s-linuxpool-35502656-0\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  e2e-tests-kubectl-qh4lv    redis-master-2w24c                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-e2e-job-3baf2c430e984a69                          0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-261c7e37e22c4229-8qlhf    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                azure-ip-masq-agent-smv6c                                  50m (2%)      50m (2%)    50Mi (0%)        250Mi (4%)\n  kube-system                kube-flannel-ds-9zr2x                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-z8rb2                                           100m (5%)     0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests   Limits\n  --------  --------   ------\n  cpu       150m (7%)  50m (2%)\n  memory    50Mi (0%)  250Mi (4%)\nEvents:\n  Type    Reason                   Age                From                                  Message\n  ----    ------                   ----               ----                                  -------\n  Normal  NodeAllocatableEnforced  24m                kubelet, k8s-linuxpool-35502656-0     Updated Node Allocatable limit across pods\n  Normal  NodeHasSufficientPID     24m (x5 over 24m)  kubelet, k8s-linuxpool-35502656-0     Node k8s-linuxpool-35502656-0 status is now: NodeHasSufficientPID\n  Normal  NodeHasSufficientDisk    24m (x6 over 24m)  kubelet, k8s-linuxpool-35502656-0     Node k8s-linuxpool-35502656-0 status is now: NodeHasSufficientDisk\n  Normal  NodeHasSufficientMemory  24m (x6 over 24m)  kubelet, k8s-linuxpool-35502656-0     Node k8s-linuxpool-35502656-0 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    24m (x6 over 24m)  kubelet, k8s-linuxpool-35502656-0     Node k8s-linuxpool-35502656-0 status is now: NodeHasNoDiskPressure\n  Normal  Starting                 21m                kube-proxy, k8s-linuxpool-35502656-0  Starting kube-proxy.\n"
May 30 22:43:19.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 describe namespace e2e-tests-kubectl-qh4lv'
May 30 22:43:19.210: INFO: stderr: ""
May 30 22:43:19.210: INFO: stdout: "Name:         e2e-tests-kubectl-qh4lv\nLabels:       e2e-framework=kubectl\n              e2e-run=be51798a-8329-11e9-a3e0-52e03c2e65ea\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:43:19.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qh4lv" for this suite.
May 30 22:43:41.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:43:41.290: INFO: namespace: e2e-tests-kubectl-qh4lv, resource: bindings, ignored listing per whitelist
May 30 22:43:41.298: INFO: namespace e2e-tests-kubectl-qh4lv deletion completed in 22.084753618s

• [SLOW TEST:28.001 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:43:41.298: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-5f6e1a21-832c-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 22:43:41.446: INFO: Waiting up to 5m0s for pod "pod-configmaps-5f6ee475-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-configmap-25g2x" to be "success or failure"
May 30 22:43:41.449: INFO: Pod "pod-configmaps-5f6ee475-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.221802ms
May 30 22:43:43.452: INFO: Pod "pod-configmaps-5f6ee475-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005604734s
May 30 22:43:45.455: INFO: Pod "pod-configmaps-5f6ee475-832c-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008860966s
STEP: Saw pod success
May 30 22:43:45.456: INFO: Pod "pod-configmaps-5f6ee475-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:43:45.458: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-configmaps-5f6ee475-832c-11e9-a3e0-52e03c2e65ea container configmap-volume-test: <nil>
STEP: delete the pod
May 30 22:43:45.470: INFO: Waiting for pod pod-configmaps-5f6ee475-832c-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:43:45.472: INFO: Pod pod-configmaps-5f6ee475-832c-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:43:45.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-25g2x" for this suite.
May 30 22:43:51.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:43:51.544: INFO: namespace: e2e-tests-configmap-25g2x, resource: bindings, ignored listing per whitelist
May 30 22:43:51.573: INFO: namespace e2e-tests-configmap-25g2x deletion completed in 6.097631267s

• [SLOW TEST:10.275 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:43:51.575: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 30 22:43:51.664: INFO: Waiting up to 5m0s for pod "pod-6585e9c8-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-emptydir-hrvgb" to be "success or failure"
May 30 22:43:51.668: INFO: Pod "pod-6585e9c8-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.982303ms
May 30 22:43:53.671: INFO: Pod "pod-6585e9c8-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007099134s
May 30 22:43:55.674: INFO: Pod "pod-6585e9c8-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010382865s
May 30 22:43:57.677: INFO: Pod "pod-6585e9c8-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013314296s
May 30 22:43:59.680: INFO: Pod "pod-6585e9c8-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016349125s
May 30 22:44:01.688: INFO: Pod "pod-6585e9c8-832c-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.024054659s
STEP: Saw pod success
May 30 22:44:01.688: INFO: Pod "pod-6585e9c8-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:44:01.693: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-6585e9c8-832c-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 22:44:01.720: INFO: Waiting for pod pod-6585e9c8-832c-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:44:01.724: INFO: Pod pod-6585e9c8-832c-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:44:01.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hrvgb" for this suite.
May 30 22:44:07.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:44:07.768: INFO: namespace: e2e-tests-emptydir-hrvgb, resource: bindings, ignored listing per whitelist
May 30 22:44:07.829: INFO: namespace e2e-tests-emptydir-hrvgb deletion completed in 6.099430262s

• [SLOW TEST:16.254 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:44:07.829: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 22:44:07.911: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6f34faff-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-k7cq2" to be "success or failure"
May 30 22:44:07.914: INFO: Pod "downwardapi-volume-6f34faff-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.944002ms
May 30 22:44:09.917: INFO: Pod "downwardapi-volume-6f34faff-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006293331s
May 30 22:44:11.921: INFO: Pod "downwardapi-volume-6f34faff-832c-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009424859s
STEP: Saw pod success
May 30 22:44:11.921: INFO: Pod "downwardapi-volume-6f34faff-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:44:11.923: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod downwardapi-volume-6f34faff-832c-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 22:44:11.939: INFO: Waiting for pod downwardapi-volume-6f34faff-832c-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:44:11.942: INFO: Pod downwardapi-volume-6f34faff-832c-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:44:11.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k7cq2" for this suite.
May 30 22:44:17.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:44:17.961: INFO: namespace: e2e-tests-projected-k7cq2, resource: bindings, ignored listing per whitelist
May 30 22:44:18.021: INFO: namespace e2e-tests-projected-k7cq2 deletion completed in 6.076324439s

• [SLOW TEST:10.192 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:44:18.022: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-75482f57-832c-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 22:44:18.105: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7548b340-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-sxsvp" to be "success or failure"
May 30 22:44:18.110: INFO: Pod "pod-projected-configmaps-7548b340-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.222304ms
May 30 22:44:20.113: INFO: Pod "pod-projected-configmaps-7548b340-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007794632s
May 30 22:44:22.117: INFO: Pod "pod-projected-configmaps-7548b340-832c-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011409659s
STEP: Saw pod success
May 30 22:44:22.117: INFO: Pod "pod-projected-configmaps-7548b340-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:44:22.119: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-projected-configmaps-7548b340-832c-11e9-a3e0-52e03c2e65ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 30 22:44:22.153: INFO: Waiting for pod pod-projected-configmaps-7548b340-832c-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:44:22.156: INFO: Pod pod-projected-configmaps-7548b340-832c-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:44:22.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sxsvp" for this suite.
May 30 22:44:28.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:44:28.199: INFO: namespace: e2e-tests-projected-sxsvp, resource: bindings, ignored listing per whitelist
May 30 22:44:28.306: INFO: namespace e2e-tests-projected-sxsvp deletion completed in 6.147807193s

• [SLOW TEST:10.284 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:44:28.307: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
May 30 22:44:28.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 run e2e-test-nginx-pod --generator=run-pod/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-vdqvs'
May 30 22:44:28.588: INFO: stderr: ""
May 30 22:44:28.588: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May 30 22:44:33.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-vdqvs -o json'
May 30 22:44:33.747: INFO: stderr: ""
May 30 22:44:33.747: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-05-30T22:44:28Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-vdqvs\",\n        \"resourceVersion\": \"4185\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-vdqvs/pods/e2e-test-nginx-pod\",\n        \"uid\": \"7b889cf6-832c-11e9-9b52-001dd80c000f\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/nginx-slim-amd64:0.20\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-z8ggt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"k8s-linuxpool-35502656-1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-z8ggt\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-z8ggt\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-30T22:44:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-30T22:44:30Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": null,\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-30T22:44:28Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://652156f0acb1827afd798182a0d5e299288fc27c7c425d7bfd8881b8665dbcaa\",\n                \"image\": \"k8s.gcr.io/nginx-slim-amd64:0.20\",\n                \"imageID\": \"docker-pullable://k8s.gcr.io/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-30T22:44:30Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.240.0.6\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.3.25\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-30T22:44:28Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 30 22:44:33.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 replace -f - --namespace=e2e-tests-kubectl-vdqvs'
May 30 22:44:33.993: INFO: stderr: ""
May 30 22:44:33.993: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image busybox
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1485
May 30 22:44:33.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-vdqvs'
May 30 22:44:41.462: INFO: stderr: ""
May 30 22:44:41.462: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:44:41.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vdqvs" for this suite.
May 30 22:44:47.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:44:47.555: INFO: namespace: e2e-tests-kubectl-vdqvs, resource: bindings, ignored listing per whitelist
May 30 22:44:47.563: INFO: namespace e2e-tests-kubectl-vdqvs deletion completed in 6.097459946s

• [SLOW TEST:19.257 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:44:47.564: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-k4hbs
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-k4hbs
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-k4hbs
May 30 22:44:47.665: INFO: Found 0 stateful pods, waiting for 1
May 30 22:44:57.669: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 30 22:44:57.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-k4hbs ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 30 22:44:57.918: INFO: stderr: ""
May 30 22:44:57.918: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 30 22:44:57.918: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 30 22:44:57.921: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 30 22:45:07.925: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 30 22:45:07.925: INFO: Waiting for statefulset status.replicas updated to 0
May 30 22:45:07.936: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999998s
May 30 22:45:08.939: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997178187s
May 30 22:45:09.942: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994356675s
May 30 22:45:10.945: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.991243264s
May 30 22:45:11.985: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.987649951s
May 30 22:45:12.988: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.94832151s
May 30 22:45:13.991: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.945026598s
May 30 22:45:14.994: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.941964286s
May 30 22:45:15.998: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.938613174s
May 30 22:45:17.002: INFO: Verifying statefulset ss doesn't scale past 1 for another 934.752861ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-k4hbs
May 30 22:45:18.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-k4hbs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:45:18.276: INFO: stderr: ""
May 30 22:45:18.276: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 30 22:45:18.276: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 30 22:45:18.279: INFO: Found 1 stateful pods, waiting for 3
May 30 22:45:28.283: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 30 22:45:28.283: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 30 22:45:28.283: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 30 22:45:28.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-k4hbs ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 30 22:45:28.561: INFO: stderr: ""
May 30 22:45:28.561: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 30 22:45:28.561: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 30 22:45:28.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-k4hbs ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 30 22:45:28.937: INFO: stderr: ""
May 30 22:45:28.937: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 30 22:45:28.937: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 30 22:45:28.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-k4hbs ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 30 22:45:29.198: INFO: stderr: ""
May 30 22:45:29.198: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 30 22:45:29.198: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 30 22:45:29.198: INFO: Waiting for statefulset status.replicas updated to 0
May 30 22:45:29.201: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
May 30 22:45:39.208: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 30 22:45:39.208: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 30 22:45:39.208: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 30 22:45:39.218: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999998s
May 30 22:45:40.222: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996468189s
May 30 22:45:41.227: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992237377s
May 30 22:45:42.234: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987682265s
May 30 22:45:43.238: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980442151s
May 30 22:45:44.241: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.97640804s
May 30 22:45:45.244: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972908629s
May 30 22:45:46.248: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.969708018s
May 30 22:45:47.252: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.966098208s
May 30 22:45:48.257: INFO: Verifying statefulset ss doesn't scale past 3 for another 961.719296ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-k4hbs
May 30 22:45:49.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-k4hbs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:45:49.524: INFO: stderr: ""
May 30 22:45:49.524: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 30 22:45:49.524: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 30 22:45:49.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-k4hbs ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:45:49.798: INFO: stderr: ""
May 30 22:45:49.799: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 30 22:45:49.799: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 30 22:45:49.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-k4hbs ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 22:45:50.051: INFO: stderr: ""
May 30 22:45:50.051: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 30 22:45:50.051: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 30 22:45:50.051: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 30 22:46:30.067: INFO: Deleting all statefulset in ns e2e-tests-statefulset-k4hbs
May 30 22:46:30.070: INFO: Scaling statefulset ss to 0
May 30 22:46:30.077: INFO: Waiting for statefulset status.replicas updated to 0
May 30 22:46:30.079: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:46:30.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-k4hbs" for this suite.
May 30 22:46:36.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:46:36.179: INFO: namespace: e2e-tests-statefulset-k4hbs, resource: bindings, ignored listing per whitelist
May 30 22:46:36.185: INFO: namespace e2e-tests-statefulset-k4hbs deletion completed in 6.089868801s

• [SLOW TEST:108.621 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:46:36.185: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 30 22:46:40.800: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c7a2deeb-832c-11e9-a3e0-52e03c2e65ea"
May 30 22:46:40.800: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c7a2deeb-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-pods-n7knt" to be "terminated due to deadline exceeded"
May 30 22:46:40.806: INFO: Pod "pod-update-activedeadlineseconds-c7a2deeb-832c-11e9-a3e0-52e03c2e65ea": Phase="Running", Reason="", readiness=true. Elapsed: 5.815382ms
May 30 22:46:42.809: INFO: Pod "pod-update-activedeadlineseconds-c7a2deeb-832c-11e9-a3e0-52e03c2e65ea": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.009052082s
May 30 22:46:42.809: INFO: Pod "pod-update-activedeadlineseconds-c7a2deeb-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:46:42.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-n7knt" for this suite.
May 30 22:46:48.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:46:48.881: INFO: namespace: e2e-tests-pods-n7knt, resource: bindings, ignored listing per whitelist
May 30 22:46:48.900: INFO: namespace e2e-tests-pods-n7knt deletion completed in 6.087241025s

• [SLOW TEST:12.715 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:46:48.900: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
May 30 22:46:53.561: INFO: Successfully updated pod "labelsupdatecf3f0931-832c-11e9-a3e0-52e03c2e65ea"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:46:55.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-g8rj4" for this suite.
May 30 22:47:17.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:47:17.610: INFO: namespace: e2e-tests-downward-api-g8rj4, resource: bindings, ignored listing per whitelist
May 30 22:47:17.670: INFO: namespace e2e-tests-downward-api-g8rj4 deletion completed in 22.090959983s

• [SLOW TEST:28.770 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:47:17.670: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-map-e060ee40-832c-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume secrets
May 30 22:47:17.786: INFO: Waiting up to 5m0s for pod "pod-secrets-e0619a3b-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-secrets-szwmb" to be "success or failure"
May 30 22:47:17.795: INFO: Pod "pod-secrets-e0619a3b-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 9.402773ms
May 30 22:47:19.798: INFO: Pod "pod-secrets-e0619a3b-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012337849s
May 30 22:47:21.802: INFO: Pod "pod-secrets-e0619a3b-832c-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015640449s
STEP: Saw pod success
May 30 22:47:21.802: INFO: Pod "pod-secrets-e0619a3b-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:47:21.804: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-secrets-e0619a3b-832c-11e9-a3e0-52e03c2e65ea container secret-volume-test: <nil>
STEP: delete the pod
May 30 22:47:21.823: INFO: Waiting for pod pod-secrets-e0619a3b-832c-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:47:21.826: INFO: Pod pod-secrets-e0619a3b-832c-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:47:21.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-szwmb" for this suite.
May 30 22:47:27.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:47:27.903: INFO: namespace: e2e-tests-secrets-szwmb, resource: bindings, ignored listing per whitelist
May 30 22:47:27.910: INFO: namespace e2e-tests-secrets-szwmb deletion completed in 6.081406052s

• [SLOW TEST:10.240 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:47:27.910: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 22:47:27.987: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6762697-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-5hszs" to be "success or failure"
May 30 22:47:27.995: INFO: Pod "downwardapi-volume-e6762697-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 8.593477ms
May 30 22:47:29.998: INFO: Pod "downwardapi-volume-e6762697-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011220579s
May 30 22:47:32.001: INFO: Pod "downwardapi-volume-e6762697-832c-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014241704s
STEP: Saw pod success
May 30 22:47:32.001: INFO: Pod "downwardapi-volume-e6762697-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:47:32.004: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod downwardapi-volume-e6762697-832c-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 22:47:32.018: INFO: Waiting for pod downwardapi-volume-e6762697-832c-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:47:32.020: INFO: Pod downwardapi-volume-e6762697-832c-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:47:32.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5hszs" for this suite.
May 30 22:47:38.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:47:38.097: INFO: namespace: e2e-tests-projected-5hszs, resource: bindings, ignored listing per whitelist
May 30 22:47:38.112: INFO: namespace e2e-tests-projected-5hszs deletion completed in 6.089034907s

• [SLOW TEST:10.201 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:47:38.112: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 30 22:47:38.201: INFO: (0) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 5.046687ms)
May 30 22:47:38.204: INFO: (1) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.573791ms)
May 30 22:47:38.208: INFO: (2) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.355891ms)
May 30 22:47:38.211: INFO: (3) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.200292ms)
May 30 22:47:38.214: INFO: (4) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.314291ms)
May 30 22:47:38.218: INFO: (5) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.71449ms)
May 30 22:47:38.222: INFO: (6) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.87789ms)
May 30 22:47:38.225: INFO: (7) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.316391ms)
May 30 22:47:38.229: INFO: (8) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.064889ms)
May 30 22:47:38.233: INFO: (9) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.48879ms)
May 30 22:47:38.237: INFO: (10) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.77399ms)
May 30 22:47:38.241: INFO: (11) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.74879ms)
May 30 22:47:38.244: INFO: (12) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.66419ms)
May 30 22:47:38.248: INFO: (13) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.60799ms)
May 30 22:47:38.251: INFO: (14) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.406591ms)
May 30 22:47:38.255: INFO: (15) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.94349ms)
May 30 22:47:38.259: INFO: (16) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.289991ms)
May 30 22:47:38.262: INFO: (17) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.48669ms)
May 30 22:47:38.268: INFO: (18) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 5.107486ms)
May 30 22:47:38.271: INFO: (19) /api/v1/nodes/k8s-linuxpool-35502656-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.172592ms)
[AfterEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:47:38.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-snqmv" for this suite.
May 30 22:47:44.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:47:44.352: INFO: namespace: e2e-tests-proxy-snqmv, resource: bindings, ignored listing per whitelist
May 30 22:47:44.357: INFO: namespace e2e-tests-proxy-snqmv deletion completed in 6.083789647s

• [SLOW TEST:6.245 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:47:44.360: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-f0447639-832c-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 22:47:44.443: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f044f90a-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-bdk8d" to be "success or failure"
May 30 22:47:44.448: INFO: Pod "pod-projected-configmaps-f044f90a-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.988687ms
May 30 22:47:46.451: INFO: Pod "pod-projected-configmaps-f044f90a-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007829485s
May 30 22:47:48.454: INFO: Pod "pod-projected-configmaps-f044f90a-832c-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010913206s
STEP: Saw pod success
May 30 22:47:48.454: INFO: Pod "pod-projected-configmaps-f044f90a-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:47:48.456: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-projected-configmaps-f044f90a-832c-11e9-a3e0-52e03c2e65ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 30 22:47:48.470: INFO: Waiting for pod pod-projected-configmaps-f044f90a-832c-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:47:48.472: INFO: Pod pod-projected-configmaps-f044f90a-832c-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:47:48.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bdk8d" for this suite.
May 30 22:47:54.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:47:54.511: INFO: namespace: e2e-tests-projected-bdk8d, resource: bindings, ignored listing per whitelist
May 30 22:47:54.568: INFO: namespace e2e-tests-projected-bdk8d deletion completed in 6.092060888s

• [SLOW TEST:10.208 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:47:54.568: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-f65a3122-832c-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume secrets
May 30 22:47:54.653: INFO: Waiting up to 5m0s for pod "pod-secrets-f65a988c-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-secrets-z9tnd" to be "success or failure"
May 30 22:47:54.657: INFO: Pod "pod-secrets-f65a988c-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.465391ms
May 30 22:47:56.659: INFO: Pod "pod-secrets-f65a988c-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006008109s
May 30 22:47:58.662: INFO: Pod "pod-secrets-f65a988c-832c-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009074348s
STEP: Saw pod success
May 30 22:47:58.662: INFO: Pod "pod-secrets-f65a988c-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:47:58.664: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-secrets-f65a988c-832c-11e9-a3e0-52e03c2e65ea container secret-volume-test: <nil>
STEP: delete the pod
May 30 22:47:58.678: INFO: Waiting for pod pod-secrets-f65a988c-832c-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:47:58.683: INFO: Pod pod-secrets-f65a988c-832c-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:47:58.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-z9tnd" for this suite.
May 30 22:48:04.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:48:04.723: INFO: namespace: e2e-tests-secrets-z9tnd, resource: bindings, ignored listing per whitelist
May 30 22:48:04.780: INFO: namespace e2e-tests-secrets-z9tnd deletion completed in 6.093150544s

• [SLOW TEST:10.212 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:48:04.782: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test use defaults
May 30 22:48:04.860: INFO: Waiting up to 5m0s for pod "client-containers-fc70dcc8-832c-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-containers-vbpp7" to be "success or failure"
May 30 22:48:04.868: INFO: Pod "client-containers-fc70dcc8-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 7.119682ms
May 30 22:48:06.871: INFO: Pod "client-containers-fc70dcc8-832c-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010529414s
May 30 22:48:08.874: INFO: Pod "client-containers-fc70dcc8-832c-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013634769s
STEP: Saw pod success
May 30 22:48:08.875: INFO: Pod "client-containers-fc70dcc8-832c-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:48:08.877: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod client-containers-fc70dcc8-832c-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 22:48:08.910: INFO: Waiting for pod client-containers-fc70dcc8-832c-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:48:08.912: INFO: Pod client-containers-fc70dcc8-832c-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:48:08.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-vbpp7" for this suite.
May 30 22:48:14.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:48:14.973: INFO: namespace: e2e-tests-containers-vbpp7, resource: bindings, ignored listing per whitelist
May 30 22:48:15.014: INFO: namespace e2e-tests-containers-vbpp7 deletion completed in 6.097260084s

• [SLOW TEST:10.232 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:48:15.014: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir volume type on tmpfs
May 30 22:48:15.103: INFO: Waiting up to 5m0s for pod "pod-028b94cc-832d-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-emptydir-q2rws" to be "success or failure"
May 30 22:48:15.108: INFO: Pod "pod-028b94cc-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.403089ms
May 30 22:48:17.112: INFO: Pod "pod-028b94cc-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008693734s
May 30 22:48:19.116: INFO: Pod "pod-028b94cc-832d-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012144703s
STEP: Saw pod success
May 30 22:48:19.116: INFO: Pod "pod-028b94cc-832d-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:48:19.118: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-028b94cc-832d-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 22:48:19.135: INFO: Waiting for pod pod-028b94cc-832d-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:48:19.138: INFO: Pod pod-028b94cc-832d-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:48:19.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-q2rws" for this suite.
May 30 22:48:25.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:48:25.171: INFO: namespace: e2e-tests-emptydir-q2rws, resource: bindings, ignored listing per whitelist
May 30 22:48:25.227: INFO: namespace e2e-tests-emptydir-q2rws deletion completed in 6.085575957s

• [SLOW TEST:10.213 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:48:25.227: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 30 22:48:25.320: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:48:25.322: INFO: Number of nodes with available pods: 0
May 30 22:48:25.322: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:48:26.406: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:48:26.410: INFO: Number of nodes with available pods: 0
May 30 22:48:26.410: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:48:27.325: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:48:27.328: INFO: Number of nodes with available pods: 0
May 30 22:48:27.328: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:48:28.326: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:48:28.328: INFO: Number of nodes with available pods: 3
May 30 22:48:28.328: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 30 22:48:28.347: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:48:28.350: INFO: Number of nodes with available pods: 2
May 30 22:48:28.350: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:48:29.354: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:48:29.357: INFO: Number of nodes with available pods: 2
May 30 22:48:29.357: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:48:30.354: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:48:30.357: INFO: Number of nodes with available pods: 2
May 30 22:48:30.357: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:48:31.354: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:48:31.357: INFO: Number of nodes with available pods: 2
May 30 22:48:31.357: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:48:32.354: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:48:32.356: INFO: Number of nodes with available pods: 3
May 30 22:48:32.357: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-k4k5g, will wait for the garbage collector to delete the pods
May 30 22:48:32.419: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.628587ms
May 30 22:48:32.519: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.212861ms
May 30 22:48:44.122: INFO: Number of nodes with available pods: 0
May 30 22:48:44.122: INFO: Number of running nodes: 0, number of available pods: 0
May 30 22:48:44.125: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-k4k5g/daemonsets","resourceVersion":"5097"},"items":null}

May 30 22:48:44.127: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-k4k5g/pods","resourceVersion":"5097"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:48:44.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-k4k5g" for this suite.
May 30 22:48:50.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:48:50.187: INFO: namespace: e2e-tests-daemonsets-k4k5g, resource: bindings, ignored listing per whitelist
May 30 22:48:50.227: INFO: namespace e2e-tests-daemonsets-k4k5g deletion completed in 6.085904468s

• [SLOW TEST:24.999 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:48:50.227: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: starting the proxy server
May 30 22:48:50.307: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-884905328 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:48:50.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tptxq" for this suite.
May 30 22:48:56.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:48:56.476: INFO: namespace: e2e-tests-kubectl-tptxq, resource: bindings, ignored listing per whitelist
May 30 22:48:56.539: INFO: namespace e2e-tests-kubectl-tptxq deletion completed in 6.140071342s

• [SLOW TEST:6.312 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:48:56.540: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-1b551188-832d-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 22:48:56.698: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1b5630bf-832d-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-klcdl" to be "success or failure"
May 30 22:48:56.702: INFO: Pod "pod-projected-configmaps-1b5630bf-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.829391ms
May 30 22:48:58.704: INFO: Pod "pod-projected-configmaps-1b5630bf-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006528982s
May 30 22:49:00.707: INFO: Pod "pod-projected-configmaps-1b5630bf-832d-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008944394s
STEP: Saw pod success
May 30 22:49:00.707: INFO: Pod "pod-projected-configmaps-1b5630bf-832d-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:49:00.709: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-projected-configmaps-1b5630bf-832d-11e9-a3e0-52e03c2e65ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 30 22:49:00.726: INFO: Waiting for pod pod-projected-configmaps-1b5630bf-832d-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:49:00.728: INFO: Pod pod-projected-configmaps-1b5630bf-832d-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:49:00.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-klcdl" for this suite.
May 30 22:49:06.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:49:06.783: INFO: namespace: e2e-tests-projected-klcdl, resource: bindings, ignored listing per whitelist
May 30 22:49:06.820: INFO: namespace e2e-tests-projected-klcdl deletion completed in 6.088807878s

• [SLOW TEST:10.280 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:49:06.820: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 30 22:49:06.905: INFO: Waiting up to 5m0s for pod "pod-216be88f-832d-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-emptydir-qdxxg" to be "success or failure"
May 30 22:49:06.908: INFO: Pod "pod-216be88f-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.557093ms
May 30 22:49:08.912: INFO: Pod "pod-216be88f-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007170485s
May 30 22:49:10.915: INFO: Pod "pod-216be88f-832d-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010789397s
STEP: Saw pod success
May 30 22:49:10.916: INFO: Pod "pod-216be88f-832d-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:49:10.918: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-216be88f-832d-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 22:49:10.933: INFO: Waiting for pod pod-216be88f-832d-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:49:10.935: INFO: Pod pod-216be88f-832d-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:49:10.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qdxxg" for this suite.
May 30 22:49:16.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:49:17.023: INFO: namespace: e2e-tests-emptydir-qdxxg, resource: bindings, ignored listing per whitelist
May 30 22:49:17.029: INFO: namespace e2e-tests-emptydir-qdxxg deletion completed in 6.090787283s

• [SLOW TEST:10.209 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:49:17.029: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 30 22:49:17.108: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
May 30 22:49:17.114: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4nqds/daemonsets","resourceVersion":"5246"},"items":null}

May 30 22:49:17.116: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4nqds/pods","resourceVersion":"5246"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:49:17.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4nqds" for this suite.
May 30 22:49:23.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:49:23.258: INFO: namespace: e2e-tests-daemonsets-4nqds, resource: bindings, ignored listing per whitelist
May 30 22:49:23.266: INFO: namespace e2e-tests-daemonsets-4nqds deletion completed in 6.138809267s

S [SKIPPING] [6.237 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684

  May 30 22:49:17.108: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:305
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:49:23.267: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a replication controller
May 30 22:49:23.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-k2trs'
May 30 22:49:23.646: INFO: stderr: ""
May 30 22:49:23.647: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 30 22:49:23.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k2trs'
May 30 22:49:23.771: INFO: stderr: ""
May 30 22:49:23.771: INFO: stdout: "update-demo-nautilus-8msph update-demo-nautilus-vwv8j "
May 30 22:49:23.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-8msph -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k2trs'
May 30 22:49:23.884: INFO: stderr: ""
May 30 22:49:23.884: INFO: stdout: ""
May 30 22:49:23.884: INFO: update-demo-nautilus-8msph is created but not running
May 30 22:49:28.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k2trs'
May 30 22:49:28.996: INFO: stderr: ""
May 30 22:49:28.996: INFO: stdout: "update-demo-nautilus-8msph update-demo-nautilus-vwv8j "
May 30 22:49:28.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-8msph -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k2trs'
May 30 22:49:29.108: INFO: stderr: ""
May 30 22:49:29.108: INFO: stdout: "true"
May 30 22:49:29.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-8msph -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k2trs'
May 30 22:49:29.225: INFO: stderr: ""
May 30 22:49:29.226: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 30 22:49:29.226: INFO: validating pod update-demo-nautilus-8msph
May 30 22:49:29.230: INFO: got data: {
  "image": "nautilus.jpg"
}

May 30 22:49:29.230: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 30 22:49:29.230: INFO: update-demo-nautilus-8msph is verified up and running
May 30 22:49:29.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-vwv8j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k2trs'
May 30 22:49:29.328: INFO: stderr: ""
May 30 22:49:29.328: INFO: stdout: "true"
May 30 22:49:29.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-vwv8j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k2trs'
May 30 22:49:29.453: INFO: stderr: ""
May 30 22:49:29.453: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 30 22:49:29.453: INFO: validating pod update-demo-nautilus-vwv8j
May 30 22:49:29.457: INFO: got data: {
  "image": "nautilus.jpg"
}

May 30 22:49:29.457: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 30 22:49:29.457: INFO: update-demo-nautilus-vwv8j is verified up and running
STEP: using delete to clean up resources
May 30 22:49:29.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-k2trs'
May 30 22:49:29.584: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 30 22:49:29.584: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 30 22:49:29.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-k2trs'
May 30 22:49:29.707: INFO: stderr: "No resources found.\n"
May 30 22:49:29.707: INFO: stdout: ""
May 30 22:49:29.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -l name=update-demo --namespace=e2e-tests-kubectl-k2trs -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 30 22:49:29.816: INFO: stderr: ""
May 30 22:49:29.816: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:49:29.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k2trs" for this suite.
May 30 22:49:51.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:49:51.899: INFO: namespace: e2e-tests-kubectl-k2trs, resource: bindings, ignored listing per whitelist
May 30 22:49:51.904: INFO: namespace e2e-tests-kubectl-k2trs deletion completed in 22.085340328s

• [SLOW TEST:28.638 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:49:51.904: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0530 22:50:02.066250      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 30 22:50:02.066: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:50:02.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-r5rt8" for this suite.
May 30 22:50:08.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:50:08.113: INFO: namespace: e2e-tests-gc-r5rt8, resource: bindings, ignored listing per whitelist
May 30 22:50:08.161: INFO: namespace e2e-tests-gc-r5rt8 deletion completed in 6.092485344s

• [SLOW TEST:16.257 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:50:08.161: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: executing a command with run --rm and attach with stdin
May 30 22:50:08.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 --namespace=e2e-tests-kubectl-8ntkh run e2e-test-rm-busybox-job --image=busybox --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 30 22:50:11.880: INFO: stderr: "If you don't see a command prompt, try pressing enter.\n"
May 30 22:50:11.880: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:50:13.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8ntkh" for this suite.
May 30 22:50:19.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:50:19.922: INFO: namespace: e2e-tests-kubectl-8ntkh, resource: bindings, ignored listing per whitelist
May 30 22:50:19.977: INFO: namespace e2e-tests-kubectl-8ntkh deletion completed in 6.089340767s

• [SLOW TEST:11.816 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:50:19.977: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
May 30 22:50:20.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-78cd2'
May 30 22:50:20.188: INFO: stderr: ""
May 30 22:50:20.188: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1449
May 30 22:50:20.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-78cd2'
May 30 22:50:24.061: INFO: stderr: ""
May 30 22:50:24.061: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:50:24.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-78cd2" for this suite.
May 30 22:50:30.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:50:30.154: INFO: namespace: e2e-tests-kubectl-78cd2, resource: bindings, ignored listing per whitelist
May 30 22:50:30.160: INFO: namespace e2e-tests-kubectl-78cd2 deletion completed in 6.095288625s

• [SLOW TEST:10.182 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:50:30.161: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on node default medium
May 30 22:50:30.293: INFO: Waiting up to 5m0s for pod "pod-531fe9ec-832d-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-emptydir-2w8ds" to be "success or failure"
May 30 22:50:30.298: INFO: Pod "pod-531fe9ec-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.32109ms
May 30 22:50:32.302: INFO: Pod "pod-531fe9ec-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009134352s
May 30 22:50:34.305: INFO: Pod "pod-531fe9ec-832d-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012299933s
STEP: Saw pod success
May 30 22:50:34.305: INFO: Pod "pod-531fe9ec-832d-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:50:34.308: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-531fe9ec-832d-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 22:50:34.326: INFO: Waiting for pod pod-531fe9ec-832d-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:50:34.328: INFO: Pod pod-531fe9ec-832d-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:50:34.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2w8ds" for this suite.
May 30 22:50:40.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:50:40.385: INFO: namespace: e2e-tests-emptydir-2w8ds, resource: bindings, ignored listing per whitelist
May 30 22:50:40.432: INFO: namespace e2e-tests-emptydir-2w8ds deletion completed in 6.099499283s

• [SLOW TEST:10.271 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:50:40.432: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 30 22:50:40.566: INFO: Creating ReplicaSet my-hostname-basic-59403f1b-832d-11e9-a3e0-52e03c2e65ea
May 30 22:50:40.574: INFO: Pod name my-hostname-basic-59403f1b-832d-11e9-a3e0-52e03c2e65ea: Found 0 pods out of 1
May 30 22:50:45.578: INFO: Pod name my-hostname-basic-59403f1b-832d-11e9-a3e0-52e03c2e65ea: Found 1 pods out of 1
May 30 22:50:45.578: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-59403f1b-832d-11e9-a3e0-52e03c2e65ea" is running
May 30 22:50:45.580: INFO: Pod "my-hostname-basic-59403f1b-832d-11e9-a3e0-52e03c2e65ea-ssx9z" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-30 22:50:40 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-30 22:50:42 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-30 22:50:40 +0000 UTC Reason: Message:}])
May 30 22:50:45.581: INFO: Trying to dial the pod
May 30 22:50:50.652: INFO: Controller my-hostname-basic-59403f1b-832d-11e9-a3e0-52e03c2e65ea: Got expected result from replica 1 [my-hostname-basic-59403f1b-832d-11e9-a3e0-52e03c2e65ea-ssx9z]: "my-hostname-basic-59403f1b-832d-11e9-a3e0-52e03c2e65ea-ssx9z", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:50:50.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-7jsnq" for this suite.
May 30 22:50:56.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:50:56.759: INFO: namespace: e2e-tests-replicaset-7jsnq, resource: bindings, ignored listing per whitelist
May 30 22:50:56.767: INFO: namespace e2e-tests-replicaset-7jsnq deletion completed in 6.111673372s

• [SLOW TEST:16.335 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:50:56.769: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap e2e-tests-configmap-zdqdz/configmap-test-62f42490-832d-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 22:50:56.852: INFO: Waiting up to 5m0s for pod "pod-configmaps-62f4978b-832d-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-configmap-zdqdz" to be "success or failure"
May 30 22:50:56.864: INFO: Pod "pod-configmaps-62f4978b-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 12.065579ms
May 30 22:50:58.866: INFO: Pod "pod-configmaps-62f4978b-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014705964s
May 30 22:51:00.871: INFO: Pod "pod-configmaps-62f4978b-832d-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019319661s
STEP: Saw pod success
May 30 22:51:00.871: INFO: Pod "pod-configmaps-62f4978b-832d-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:51:00.875: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-configmaps-62f4978b-832d-11e9-a3e0-52e03c2e65ea container env-test: <nil>
STEP: delete the pod
May 30 22:51:00.922: INFO: Waiting for pod pod-configmaps-62f4978b-832d-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:51:00.929: INFO: Pod pod-configmaps-62f4978b-832d-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:51:00.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zdqdz" for this suite.
May 30 22:51:06.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:51:07.056: INFO: namespace: e2e-tests-configmap-zdqdz, resource: bindings, ignored listing per whitelist
May 30 22:51:07.062: INFO: namespace e2e-tests-configmap-zdqdz deletion completed in 6.130396394s

• [SLOW TEST:10.293 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:51:07.062: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-6xdxh
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 30 22:51:07.135: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 30 22:51:33.263: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.1.38 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-6xdxh PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:51:33.263: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:51:34.405: INFO: Found all expected endpoints: [netserver-0]
May 30 22:51:34.408: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.0.15 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-6xdxh PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:51:34.408: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:51:35.567: INFO: Found all expected endpoints: [netserver-1]
May 30 22:51:35.569: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.3.45 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-6xdxh PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:51:35.569: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:51:36.715: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:51:36.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-6xdxh" for this suite.
May 30 22:51:58.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:51:58.764: INFO: namespace: e2e-tests-pod-network-test-6xdxh, resource: bindings, ignored listing per whitelist
May 30 22:51:58.805: INFO: namespace e2e-tests-pod-network-test-6xdxh deletion completed in 22.086261958s

• [SLOW TEST:51.743 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:51:58.806: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name projected-secret-test-87edd6fa-832d-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume secrets
May 30 22:51:58.887: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-87ee4a24-832d-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-pbsqv" to be "success or failure"
May 30 22:51:58.893: INFO: Pod "pod-projected-secrets-87ee4a24-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.283091ms
May 30 22:52:00.896: INFO: Pod "pod-projected-secrets-87ee4a24-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009162346s
May 30 22:52:02.899: INFO: Pod "pod-projected-secrets-87ee4a24-832d-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012092116s
STEP: Saw pod success
May 30 22:52:02.899: INFO: Pod "pod-projected-secrets-87ee4a24-832d-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:52:02.901: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-projected-secrets-87ee4a24-832d-11e9-a3e0-52e03c2e65ea container secret-volume-test: <nil>
STEP: delete the pod
May 30 22:52:02.920: INFO: Waiting for pod pod-projected-secrets-87ee4a24-832d-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:52:02.923: INFO: Pod pod-projected-secrets-87ee4a24-832d-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:52:02.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pbsqv" for this suite.
May 30 22:52:08.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:52:08.983: INFO: namespace: e2e-tests-projected-pbsqv, resource: bindings, ignored listing per whitelist
May 30 22:52:09.015: INFO: namespace e2e-tests-projected-pbsqv deletion completed in 6.08868218s

• [SLOW TEST:10.209 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:52:09.016: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 22:52:09.154: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8e0cb41d-832d-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-downward-api-4bmsn" to be "success or failure"
May 30 22:52:09.158: INFO: Pod "downwardapi-volume-8e0cb41d-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.708695ms
May 30 22:52:11.161: INFO: Pod "downwardapi-volume-8e0cb41d-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006687023s
May 30 22:52:13.164: INFO: Pod "downwardapi-volume-8e0cb41d-832d-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009771464s
STEP: Saw pod success
May 30 22:52:13.164: INFO: Pod "downwardapi-volume-8e0cb41d-832d-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:52:13.166: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod downwardapi-volume-8e0cb41d-832d-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 22:52:13.224: INFO: Waiting for pod downwardapi-volume-8e0cb41d-832d-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:52:13.226: INFO: Pod downwardapi-volume-8e0cb41d-832d-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:52:13.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4bmsn" for this suite.
May 30 22:52:19.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:52:19.258: INFO: namespace: e2e-tests-downward-api-4bmsn, resource: bindings, ignored listing per whitelist
May 30 22:52:19.391: INFO: namespace e2e-tests-downward-api-4bmsn deletion completed in 6.161570097s

• [SLOW TEST:10.375 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:52:19.393: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 30 22:52:25.501: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xv4cr PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:52:25.501: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:52:25.633: INFO: Exec stderr: ""
May 30 22:52:25.633: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xv4cr PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:52:25.633: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:52:25.772: INFO: Exec stderr: ""
May 30 22:52:25.772: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xv4cr PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:52:25.772: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:52:25.918: INFO: Exec stderr: ""
May 30 22:52:25.918: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xv4cr PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:52:25.918: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:52:26.049: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 30 22:52:26.049: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xv4cr PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:52:26.049: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:52:26.254: INFO: Exec stderr: ""
May 30 22:52:26.254: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xv4cr PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:52:26.254: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:52:26.381: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 30 22:52:26.381: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xv4cr PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:52:26.381: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:52:26.543: INFO: Exec stderr: ""
May 30 22:52:26.543: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xv4cr PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:52:26.543: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:52:26.683: INFO: Exec stderr: ""
May 30 22:52:26.683: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xv4cr PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:52:26.683: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:52:26.813: INFO: Exec stderr: ""
May 30 22:52:26.813: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xv4cr PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:52:26.813: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:52:26.987: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:52:26.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-xv4cr" for this suite.
May 30 22:53:17.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:53:17.049: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-xv4cr, resource: bindings, ignored listing per whitelist
May 30 22:53:17.091: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-xv4cr deletion completed in 50.099992879s

• [SLOW TEST:57.698 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:53:17.092: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-b6989f26-832d-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume secrets
May 30 22:53:17.182: INFO: Waiting up to 5m0s for pod "pod-secrets-b6991e19-832d-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-secrets-rdmk7" to be "success or failure"
May 30 22:53:17.186: INFO: Pod "pod-secrets-b6991e19-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.105496ms
May 30 22:53:19.188: INFO: Pod "pod-secrets-b6991e19-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005969071s
May 30 22:53:21.191: INFO: Pod "pod-secrets-b6991e19-832d-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008768158s
STEP: Saw pod success
May 30 22:53:21.191: INFO: Pod "pod-secrets-b6991e19-832d-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:53:21.193: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-secrets-b6991e19-832d-11e9-a3e0-52e03c2e65ea container secret-volume-test: <nil>
STEP: delete the pod
May 30 22:53:21.213: INFO: Waiting for pod pod-secrets-b6991e19-832d-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:53:21.220: INFO: Pod pod-secrets-b6991e19-832d-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:53:21.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rdmk7" for this suite.
May 30 22:53:27.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:53:27.250: INFO: namespace: e2e-tests-secrets-rdmk7, resource: bindings, ignored listing per whitelist
May 30 22:53:27.319: INFO: namespace e2e-tests-secrets-rdmk7 deletion completed in 6.095830931s

• [SLOW TEST:10.227 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:53:27.319: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 30 22:53:27.411: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 30 22:53:27.417: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:27.420: INFO: Number of nodes with available pods: 0
May 30 22:53:27.420: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:53:28.424: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:28.426: INFO: Number of nodes with available pods: 0
May 30 22:53:28.426: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:53:29.424: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:29.429: INFO: Number of nodes with available pods: 0
May 30 22:53:29.429: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 22:53:30.424: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:30.426: INFO: Number of nodes with available pods: 3
May 30 22:53:30.426: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 30 22:53:30.446: INFO: Wrong image for pod: daemon-set-lsbs8. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:30.446: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:30.446: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:30.451: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:31.454: INFO: Wrong image for pod: daemon-set-lsbs8. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:31.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:31.454: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:31.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:32.455: INFO: Wrong image for pod: daemon-set-lsbs8. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:32.455: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:32.455: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:32.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:33.455: INFO: Wrong image for pod: daemon-set-lsbs8. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:33.455: INFO: Pod daemon-set-lsbs8 is not available
May 30 22:53:33.455: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:33.455: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:33.458: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:34.454: INFO: Wrong image for pod: daemon-set-lsbs8. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:34.454: INFO: Pod daemon-set-lsbs8 is not available
May 30 22:53:34.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:34.454: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:34.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:35.454: INFO: Wrong image for pod: daemon-set-lsbs8. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:35.454: INFO: Pod daemon-set-lsbs8 is not available
May 30 22:53:35.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:35.454: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:35.458: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:36.456: INFO: Wrong image for pod: daemon-set-lsbs8. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:36.456: INFO: Pod daemon-set-lsbs8 is not available
May 30 22:53:36.456: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:36.456: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:36.460: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:37.454: INFO: Wrong image for pod: daemon-set-lsbs8. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:37.454: INFO: Pod daemon-set-lsbs8 is not available
May 30 22:53:37.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:37.454: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:37.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:38.455: INFO: Wrong image for pod: daemon-set-lsbs8. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:38.455: INFO: Pod daemon-set-lsbs8 is not available
May 30 22:53:38.455: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:38.455: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:38.458: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:39.454: INFO: Wrong image for pod: daemon-set-lsbs8. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:39.455: INFO: Pod daemon-set-lsbs8 is not available
May 30 22:53:39.455: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:39.455: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:39.458: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:40.454: INFO: Wrong image for pod: daemon-set-lsbs8. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:40.455: INFO: Pod daemon-set-lsbs8 is not available
May 30 22:53:40.455: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:40.455: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:40.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:41.454: INFO: Wrong image for pod: daemon-set-lsbs8. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:41.454: INFO: Pod daemon-set-lsbs8 is not available
May 30 22:53:41.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:41.454: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:41.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:42.454: INFO: Wrong image for pod: daemon-set-lsbs8. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:42.454: INFO: Pod daemon-set-lsbs8 is not available
May 30 22:53:42.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:42.454: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:42.458: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:43.454: INFO: Wrong image for pod: daemon-set-lsbs8. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:43.454: INFO: Pod daemon-set-lsbs8 is not available
May 30 22:53:43.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:43.454: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:43.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:44.454: INFO: Pod daemon-set-c6f9n is not available
May 30 22:53:44.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:44.454: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:44.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:45.454: INFO: Pod daemon-set-c6f9n is not available
May 30 22:53:45.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:45.454: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:45.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:46.458: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:46.458: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:46.461: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:47.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:47.454: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:47.456: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:48.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:48.455: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:48.455: INFO: Pod daemon-set-zk6x4 is not available
May 30 22:53:48.458: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:49.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:49.454: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:49.454: INFO: Pod daemon-set-zk6x4 is not available
May 30 22:53:49.458: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:50.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:50.454: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:50.454: INFO: Pod daemon-set-zk6x4 is not available
May 30 22:53:50.458: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:51.455: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:51.455: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:51.455: INFO: Pod daemon-set-zk6x4 is not available
May 30 22:53:51.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:52.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:52.454: INFO: Wrong image for pod: daemon-set-zk6x4. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:52.454: INFO: Pod daemon-set-zk6x4 is not available
May 30 22:53:52.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:53.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:53.454: INFO: Pod daemon-set-tmmbn is not available
May 30 22:53:53.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:54.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:54.454: INFO: Pod daemon-set-tmmbn is not available
May 30 22:53:54.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:55.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:55.454: INFO: Pod daemon-set-tmmbn is not available
May 30 22:53:55.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:56.463: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:56.463: INFO: Pod daemon-set-tmmbn is not available
May 30 22:53:56.466: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:57.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:57.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:58.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:58.454: INFO: Pod daemon-set-rsfbh is not available
May 30 22:53:58.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:53:59.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:53:59.454: INFO: Pod daemon-set-rsfbh is not available
May 30 22:53:59.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:54:00.454: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:54:00.454: INFO: Pod daemon-set-rsfbh is not available
May 30 22:54:00.457: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:54:01.459: INFO: Wrong image for pod: daemon-set-rsfbh. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 30 22:54:01.459: INFO: Pod daemon-set-rsfbh is not available
May 30 22:54:01.465: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:54:02.456: INFO: Pod daemon-set-kd7qj is not available
May 30 22:54:02.459: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
May 30 22:54:02.462: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:54:02.466: INFO: Number of nodes with available pods: 2
May 30 22:54:02.466: INFO: Node k8s-linuxpool-35502656-1 is running more than one daemon pod
May 30 22:54:03.470: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:54:03.472: INFO: Number of nodes with available pods: 2
May 30 22:54:03.472: INFO: Node k8s-linuxpool-35502656-1 is running more than one daemon pod
May 30 22:54:04.470: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:54:04.473: INFO: Number of nodes with available pods: 2
May 30 22:54:04.473: INFO: Node k8s-linuxpool-35502656-1 is running more than one daemon pod
May 30 22:54:05.472: INFO: DaemonSet pods can't tolerate node k8s-master-35502656-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 30 22:54:05.475: INFO: Number of nodes with available pods: 3
May 30 22:54:05.475: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-926vt, will wait for the garbage collector to delete the pods
May 30 22:54:05.550: INFO: Deleting {extensions DaemonSet} daemon-set took: 6.407793ms
May 30 22:54:05.650: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.280492ms
May 30 22:54:14.152: INFO: Number of nodes with available pods: 0
May 30 22:54:14.152: INFO: Number of running nodes: 0, number of available pods: 0
May 30 22:54:14.154: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-926vt/daemonsets","resourceVersion":"6459"},"items":null}

May 30 22:54:14.156: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-926vt/pods","resourceVersion":"6459"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:54:14.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-926vt" for this suite.
May 30 22:54:20.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:54:20.248: INFO: namespace: e2e-tests-daemonsets-926vt, resource: bindings, ignored listing per whitelist
May 30 22:54:20.254: INFO: namespace e2e-tests-daemonsets-926vt deletion completed in 6.087804367s

• [SLOW TEST:52.935 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:54:20.255: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1371
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
May 30 22:54:20.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-pw2d7'
May 30 22:54:20.765: INFO: stderr: ""
May 30 22:54:20.765: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1376
May 30 22:54:20.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-pw2d7'
May 30 22:54:20.939: INFO: stderr: ""
May 30 22:54:20.939: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:54:20.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pw2d7" for this suite.
May 30 22:54:42.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:54:43.020: INFO: namespace: e2e-tests-kubectl-pw2d7, resource: bindings, ignored listing per whitelist
May 30 22:54:43.031: INFO: namespace e2e-tests-kubectl-pw2d7 deletion completed in 22.0885094s

• [SLOW TEST:22.776 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:54:43.032: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 22:54:43.120: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e9d1ee1e-832d-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-downward-api-j4krm" to be "success or failure"
May 30 22:54:43.126: INFO: Pod "downwardapi-volume-e9d1ee1e-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.764695ms
May 30 22:54:45.129: INFO: Pod "downwardapi-volume-e9d1ee1e-832d-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008209455s
May 30 22:54:47.131: INFO: Pod "downwardapi-volume-e9d1ee1e-832d-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010864826s
STEP: Saw pod success
May 30 22:54:47.131: INFO: Pod "downwardapi-volume-e9d1ee1e-832d-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:54:47.134: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod downwardapi-volume-e9d1ee1e-832d-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 22:54:47.146: INFO: Waiting for pod downwardapi-volume-e9d1ee1e-832d-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:54:47.148: INFO: Pod downwardapi-volume-e9d1ee1e-832d-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:54:47.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j4krm" for this suite.
May 30 22:54:53.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:54:53.289: INFO: namespace: e2e-tests-downward-api-j4krm, resource: bindings, ignored listing per whitelist
May 30 22:54:53.292: INFO: namespace e2e-tests-downward-api-j4krm deletion completed in 6.140231849s

• [SLOW TEST:10.260 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:54:53.292: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 30 22:54:53.382: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-9mpfk,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mpfk/configmaps/e2e-watch-test-watch-closed,UID:eff06548-832d-11e9-9b52-001dd80c000f,ResourceVersion:6609,Generation:0,CreationTimestamp:2019-05-30 22:54:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 30 22:54:53.382: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-9mpfk,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mpfk/configmaps/e2e-watch-test-watch-closed,UID:eff06548-832d-11e9-9b52-001dd80c000f,ResourceVersion:6611,Generation:0,CreationTimestamp:2019-05-30 22:54:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 30 22:54:53.392: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-9mpfk,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mpfk/configmaps/e2e-watch-test-watch-closed,UID:eff06548-832d-11e9-9b52-001dd80c000f,ResourceVersion:6612,Generation:0,CreationTimestamp:2019-05-30 22:54:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 30 22:54:53.393: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-9mpfk,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mpfk/configmaps/e2e-watch-test-watch-closed,UID:eff06548-832d-11e9-9b52-001dd80c000f,ResourceVersion:6613,Generation:0,CreationTimestamp:2019-05-30 22:54:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:54:53.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-9mpfk" for this suite.
May 30 22:54:59.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:54:59.442: INFO: namespace: e2e-tests-watch-9mpfk, resource: bindings, ignored listing per whitelist
May 30 22:54:59.532: INFO: namespace e2e-tests-watch-9mpfk deletion completed in 6.135447051s

• [SLOW TEST:6.241 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:54:59.534: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating Redis RC
May 30 22:54:59.641: INFO: namespace e2e-tests-kubectl-4qdwh
May 30 22:54:59.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-4qdwh'
May 30 22:54:59.938: INFO: stderr: ""
May 30 22:54:59.938: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 30 22:55:00.941: INFO: Selector matched 1 pods for map[app:redis]
May 30 22:55:00.941: INFO: Found 0 / 1
May 30 22:55:01.948: INFO: Selector matched 1 pods for map[app:redis]
May 30 22:55:01.948: INFO: Found 0 / 1
May 30 22:55:02.942: INFO: Selector matched 1 pods for map[app:redis]
May 30 22:55:02.942: INFO: Found 1 / 1
May 30 22:55:02.942: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 30 22:55:02.944: INFO: Selector matched 1 pods for map[app:redis]
May 30 22:55:02.944: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 30 22:55:02.944: INFO: wait on redis-master startup in e2e-tests-kubectl-4qdwh 
May 30 22:55:02.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 logs redis-master-hlvb8 redis-master --namespace=e2e-tests-kubectl-4qdwh'
May 30 22:55:03.075: INFO: stderr: ""
May 30 22:55:03.075: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 May 22:55:02.118 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 May 22:55:02.118 # Server started, Redis version 3.2.12\n1:M 30 May 22:55:02.118 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 May 22:55:02.118 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May 30 22:55:03.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-4qdwh'
May 30 22:55:03.204: INFO: stderr: ""
May 30 22:55:03.204: INFO: stdout: "service/rm2 exposed\n"
May 30 22:55:03.210: INFO: Service rm2 in namespace e2e-tests-kubectl-4qdwh found.
STEP: exposing service
May 30 22:55:05.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-4qdwh'
May 30 22:55:05.355: INFO: stderr: ""
May 30 22:55:05.355: INFO: stdout: "service/rm3 exposed\n"
May 30 22:55:05.358: INFO: Service rm3 in namespace e2e-tests-kubectl-4qdwh found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:55:07.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4qdwh" for this suite.
May 30 22:55:29.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:55:29.412: INFO: namespace: e2e-tests-kubectl-4qdwh, resource: bindings, ignored listing per whitelist
May 30 22:55:29.448: INFO: namespace e2e-tests-kubectl-4qdwh deletion completed in 22.083230106s

• [SLOW TEST:29.915 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create services for rc  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:55:29.450: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 30 22:55:29.547: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-xh4lz,SelfLink:/api/v1/namespaces/e2e-tests-watch-xh4lz/configmaps/e2e-watch-test-resource-version,UID:057d30f2-832e-11e9-9b52-001dd80c000f,ResourceVersion:6730,Generation:0,CreationTimestamp:2019-05-30 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 30 22:55:29.547: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-xh4lz,SelfLink:/api/v1/namespaces/e2e-tests-watch-xh4lz/configmaps/e2e-watch-test-resource-version,UID:057d30f2-832e-11e9-9b52-001dd80c000f,ResourceVersion:6731,Generation:0,CreationTimestamp:2019-05-30 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:55:29.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-xh4lz" for this suite.
May 30 22:55:35.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:55:35.592: INFO: namespace: e2e-tests-watch-xh4lz, resource: bindings, ignored listing per whitelist
May 30 22:55:35.641: INFO: namespace e2e-tests-watch-xh4lz deletion completed in 6.09037973s

• [SLOW TEST:6.191 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:55:35.641: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 22:55:35.711: INFO: Waiting up to 5m0s for pod "downwardapi-volume-092b1e7c-832e-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-nwxbr" to be "success or failure"
May 30 22:55:35.718: INFO: Pod "downwardapi-volume-092b1e7c-832e-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.678894ms
May 30 22:55:37.721: INFO: Pod "downwardapi-volume-092b1e7c-832e-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009721413s
May 30 22:55:39.724: INFO: Pod "downwardapi-volume-092b1e7c-832e-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012526242s
STEP: Saw pod success
May 30 22:55:39.724: INFO: Pod "downwardapi-volume-092b1e7c-832e-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:55:39.726: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod downwardapi-volume-092b1e7c-832e-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 22:55:39.751: INFO: Waiting for pod downwardapi-volume-092b1e7c-832e-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:55:39.754: INFO: Pod downwardapi-volume-092b1e7c-832e-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:55:39.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nwxbr" for this suite.
May 30 22:55:45.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:55:45.807: INFO: namespace: e2e-tests-projected-nwxbr, resource: bindings, ignored listing per whitelist
May 30 22:55:45.846: INFO: namespace e2e-tests-projected-nwxbr deletion completed in 6.089609776s

• [SLOW TEST:10.205 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:55:45.847: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1316
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
May 30 22:55:45.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 run e2e-test-nginx-deployment --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-2gjpl'
May 30 22:55:46.049: INFO: stderr: ""
May 30 22:55:46.049: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1321
May 30 22:55:50.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-2gjpl'
May 30 22:55:50.267: INFO: stderr: ""
May 30 22:55:50.267: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:55:50.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2gjpl" for this suite.
May 30 22:55:56.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:55:56.319: INFO: namespace: e2e-tests-kubectl-2gjpl, resource: bindings, ignored listing per whitelist
May 30 22:55:56.375: INFO: namespace e2e-tests-kubectl-2gjpl deletion completed in 6.103168011s

• [SLOW TEST:10.528 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:55:56.377: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 Pods, got 2 Pods
STEP: Gathering metrics
W0530 22:55:57.498085      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 30 22:55:57.498: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:55:57.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mw5rf" for this suite.
May 30 22:56:03.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:56:03.557: INFO: namespace: e2e-tests-gc-mw5rf, resource: bindings, ignored listing per whitelist
May 30 22:56:03.648: INFO: namespace e2e-tests-gc-mw5rf deletion completed in 6.146966476s

• [SLOW TEST:7.272 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:56:03.651: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating service endpoint-test2 in namespace e2e-tests-services-5k2hw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5k2hw to expose endpoints map[]
May 30 22:56:03.749: INFO: Get endpoints failed (5.699095ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
May 30 22:56:04.752: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5k2hw exposes endpoints map[] (1.008686916s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-5k2hw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5k2hw to expose endpoints map[pod1:[80]]
May 30 22:56:07.773: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5k2hw exposes endpoints map[pod1:[80]] (3.01725797s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-5k2hw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5k2hw to expose endpoints map[pod1:[80] pod2:[80]]
May 30 22:56:10.806: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5k2hw exposes endpoints map[pod1:[80] pod2:[80]] (3.029684081s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-5k2hw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5k2hw to expose endpoints map[pod2:[80]]
May 30 22:56:10.820: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5k2hw exposes endpoints map[pod2:[80]] (9.444693ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-5k2hw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5k2hw to expose endpoints map[]
May 30 22:56:11.840: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5k2hw exposes endpoints map[] (1.012709429s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:56:11.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-5k2hw" for this suite.
May 30 22:56:33.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:56:33.915: INFO: namespace: e2e-tests-services-5k2hw, resource: bindings, ignored listing per whitelist
May 30 22:56:34.000: INFO: namespace e2e-tests-services-5k2hw deletion completed in 22.136553907s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:30.349 seconds]
[sig-network] Services
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:56:34.000: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-rkvxc
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 30 22:56:34.101: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 30 22:56:58.210: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.0.20:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rkvxc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:56:58.210: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:56:58.353: INFO: Found all expected endpoints: [netserver-0]
May 30 22:56:58.356: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.3.52:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rkvxc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:56:58.356: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:56:58.497: INFO: Found all expected endpoints: [netserver-1]
May 30 22:56:58.500: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.1.48:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rkvxc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:56:58.500: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:56:58.646: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:56:58.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-rkvxc" for this suite.
May 30 22:57:20.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:57:20.675: INFO: namespace: e2e-tests-pod-network-test-rkvxc, resource: bindings, ignored listing per whitelist
May 30 22:57:20.738: INFO: namespace e2e-tests-pod-network-test-rkvxc deletion completed in 22.08759375s

• [SLOW TEST:46.738 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:57:20.738: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override command
May 30 22:57:20.818: INFO: Waiting up to 5m0s for pod "client-containers-47d11778-832e-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-containers-2kx27" to be "success or failure"
May 30 22:57:20.824: INFO: Pod "client-containers-47d11778-832e-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.742096ms
May 30 22:57:22.827: INFO: Pod "client-containers-47d11778-832e-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00950046s
May 30 22:57:24.832: INFO: Pod "client-containers-47d11778-832e-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013838531s
STEP: Saw pod success
May 30 22:57:24.832: INFO: Pod "client-containers-47d11778-832e-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:57:24.834: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod client-containers-47d11778-832e-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 22:57:24.852: INFO: Waiting for pod client-containers-47d11778-832e-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:57:24.854: INFO: Pod client-containers-47d11778-832e-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:57:24.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2kx27" for this suite.
May 30 22:57:30.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:57:30.892: INFO: namespace: e2e-tests-containers-2kx27, resource: bindings, ignored listing per whitelist
May 30 22:57:30.945: INFO: namespace e2e-tests-containers-2kx27 deletion completed in 6.087529313s

• [SLOW TEST:10.207 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:57:30.947: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
May 30 22:57:35.656: INFO: Successfully updated pod "labelsupdate4df60d07-832e-11e9-a3e0-52e03c2e65ea"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:57:37.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b2h7w" for this suite.
May 30 22:57:59.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:57:59.756: INFO: namespace: e2e-tests-projected-b2h7w, resource: bindings, ignored listing per whitelist
May 30 22:57:59.771: INFO: namespace e2e-tests-projected-b2h7w deletion completed in 22.097729964s

• [SLOW TEST:28.825 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:57:59.771: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-map-5f17596a-832e-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume secrets
May 30 22:57:59.875: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5f181619-832e-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-n27cw" to be "success or failure"
May 30 22:57:59.886: INFO: Pod "pod-projected-secrets-5f181619-832e-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 10.799094ms
May 30 22:58:01.889: INFO: Pod "pod-projected-secrets-5f181619-832e-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0141859s
May 30 22:58:03.893: INFO: Pod "pod-projected-secrets-5f181619-832e-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017554814s
STEP: Saw pod success
May 30 22:58:03.893: INFO: Pod "pod-projected-secrets-5f181619-832e-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:58:03.895: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-projected-secrets-5f181619-832e-11e9-a3e0-52e03c2e65ea container projected-secret-volume-test: <nil>
STEP: delete the pod
May 30 22:58:03.912: INFO: Waiting for pod pod-projected-secrets-5f181619-832e-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:58:03.914: INFO: Pod pod-projected-secrets-5f181619-832e-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:58:03.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n27cw" for this suite.
May 30 22:58:09.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:58:09.977: INFO: namespace: e2e-tests-projected-n27cw, resource: bindings, ignored listing per whitelist
May 30 22:58:10.013: INFO: namespace e2e-tests-projected-n27cw deletion completed in 6.096492838s

• [SLOW TEST:10.242 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:58:10.014: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1180
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
May 30 22:58:10.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 run e2e-test-nginx-deployment --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-z5mgt'
May 30 22:58:10.224: INFO: stderr: ""
May 30 22:58:10.224: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1186
May 30 22:58:12.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-z5mgt'
May 30 22:58:12.350: INFO: stderr: ""
May 30 22:58:12.350: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:58:12.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z5mgt" for this suite.
May 30 22:58:18.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:58:18.385: INFO: namespace: e2e-tests-kubectl-z5mgt, resource: bindings, ignored listing per whitelist
May 30 22:58:18.444: INFO: namespace e2e-tests-kubectl-z5mgt deletion completed in 6.09054583s

• [SLOW TEST:8.431 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:58:18.447: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-6a353320-832e-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 22:58:18.521: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6a35b558-832e-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-vtvz4" to be "success or failure"
May 30 22:58:18.524: INFO: Pod "pod-projected-configmaps-6a35b558-832e-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.239499ms
May 30 22:58:20.526: INFO: Pod "pod-projected-configmaps-6a35b558-832e-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005156971s
May 30 22:58:22.529: INFO: Pod "pod-projected-configmaps-6a35b558-832e-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008197549s
STEP: Saw pod success
May 30 22:58:22.530: INFO: Pod "pod-projected-configmaps-6a35b558-832e-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:58:22.532: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-projected-configmaps-6a35b558-832e-11e9-a3e0-52e03c2e65ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 30 22:58:22.544: INFO: Waiting for pod pod-projected-configmaps-6a35b558-832e-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:58:22.547: INFO: Pod pod-projected-configmaps-6a35b558-832e-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:58:22.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vtvz4" for this suite.
May 30 22:58:28.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:58:28.630: INFO: namespace: e2e-tests-projected-vtvz4, resource: bindings, ignored listing per whitelist
May 30 22:58:28.651: INFO: namespace e2e-tests-projected-vtvz4 deletion completed in 6.100985831s

• [SLOW TEST:10.204 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:58:28.651: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 22:58:28.731: INFO: Waiting up to 5m0s for pod "downwardapi-volume-704bccc8-832e-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-downward-api-59kcw" to be "success or failure"
May 30 22:58:28.739: INFO: Pod "downwardapi-volume-704bccc8-832e-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 8.113896ms
May 30 22:58:30.743: INFO: Pod "downwardapi-volume-704bccc8-832e-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012104002s
May 30 22:58:32.746: INFO: Pod "downwardapi-volume-704bccc8-832e-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014846215s
STEP: Saw pod success
May 30 22:58:32.746: INFO: Pod "downwardapi-volume-704bccc8-832e-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 22:58:32.748: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod downwardapi-volume-704bccc8-832e-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 22:58:32.769: INFO: Waiting for pod downwardapi-volume-704bccc8-832e-11e9-a3e0-52e03c2e65ea to disappear
May 30 22:58:32.773: INFO: Pod downwardapi-volume-704bccc8-832e-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:58:32.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-59kcw" for this suite.
May 30 22:58:38.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:58:38.872: INFO: namespace: e2e-tests-downward-api-59kcw, resource: bindings, ignored listing per whitelist
May 30 22:58:38.874: INFO: namespace e2e-tests-downward-api-59kcw deletion completed in 6.098286936s

• [SLOW TEST:10.223 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:58:38.875: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-t28nw
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 30 22:58:38.970: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 30 22:59:03.053: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.56:8080/dial?request=hostName&protocol=udp&host=10.244.0.21&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-t28nw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:59:03.053: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:59:03.189: INFO: Waiting for endpoints: map[]
May 30 22:59:03.192: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.56:8080/dial?request=hostName&protocol=udp&host=10.244.1.55&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-t28nw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:59:03.192: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:59:03.343: INFO: Waiting for endpoints: map[]
May 30 22:59:03.347: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.56:8080/dial?request=hostName&protocol=udp&host=10.244.3.56&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-t28nw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 22:59:03.347: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 22:59:03.502: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:59:03.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-t28nw" for this suite.
May 30 22:59:25.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 22:59:25.541: INFO: namespace: e2e-tests-pod-network-test-t28nw, resource: bindings, ignored listing per whitelist
May 30 22:59:25.597: INFO: namespace e2e-tests-pod-network-test-t28nw deletion completed in 22.091152418s

• [SLOW TEST:46.723 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 22:59:25.597: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating server pod server in namespace e2e-tests-prestop-8qjng
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-8qjng
STEP: Deleting pre-stop pod
May 30 22:59:42.722: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 22:59:42.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-8qjng" for this suite.
May 30 23:00:22.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:00:22.768: INFO: namespace: e2e-tests-prestop-8qjng, resource: bindings, ignored listing per whitelist
May 30 23:00:22.827: INFO: namespace e2e-tests-prestop-8qjng deletion completed in 40.090818983s

• [SLOW TEST:57.230 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:00:22.827: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-tpmvm
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-tpmvm to expose endpoints map[]
May 30 23:00:22.934: INFO: Get endpoints failed (4.001799ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
May 30 23:00:23.937: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-tpmvm exposes endpoints map[] (1.007156371s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-tpmvm
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-tpmvm to expose endpoints map[pod1:[100]]
May 30 23:00:26.971: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-tpmvm exposes endpoints map[pod1:[100]] (3.028802119s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-tpmvm
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-tpmvm to expose endpoints map[pod1:[100] pod2:[101]]
May 30 23:00:30.038: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-tpmvm exposes endpoints map[pod1:[100] pod2:[101]] (3.063222821s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-tpmvm
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-tpmvm to expose endpoints map[pod2:[101]]
May 30 23:00:31.069: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-tpmvm exposes endpoints map[pod2:[101]] (1.021278476s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-tpmvm
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-tpmvm to expose endpoints map[]
May 30 23:00:32.081: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-tpmvm exposes endpoints map[] (1.007455682s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:00:32.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-tpmvm" for this suite.
May 30 23:00:38.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:00:38.202: INFO: namespace: e2e-tests-services-tpmvm, resource: bindings, ignored listing per whitelist
May 30 23:00:38.208: INFO: namespace e2e-tests-services-tpmvm deletion completed in 6.089654208s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:15.381 seconds]
[sig-network] Services
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:00:38.208: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-cjmrn
May 30 23:00:42.345: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-cjmrn
STEP: checking the pod's current state and verifying that restartCount is present
May 30 23:00:42.347: INFO: Initial restart count of pod liveness-http is 0
May 30 23:00:58.374: INFO: Restart count of pod e2e-tests-container-probe-cjmrn/liveness-http is now 1 (16.026953231s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:00:58.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cjmrn" for this suite.
May 30 23:01:04.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:01:04.455: INFO: namespace: e2e-tests-container-probe-cjmrn, resource: bindings, ignored listing per whitelist
May 30 23:01:04.468: INFO: namespace e2e-tests-container-probe-cjmrn deletion completed in 6.082506012s

• [SLOW TEST:26.259 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:01:04.468: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 23:01:04.545: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cd2b031c-832e-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-downward-api-xv5rd" to be "success or failure"
May 30 23:01:04.551: INFO: Pod "downwardapi-volume-cd2b031c-832e-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.782398ms
May 30 23:01:06.555: INFO: Pod "downwardapi-volume-cd2b031c-832e-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009125653s
May 30 23:01:08.559: INFO: Pod "downwardapi-volume-cd2b031c-832e-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013882812s
STEP: Saw pod success
May 30 23:01:08.560: INFO: Pod "downwardapi-volume-cd2b031c-832e-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:01:08.562: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod downwardapi-volume-cd2b031c-832e-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 23:01:08.580: INFO: Waiting for pod downwardapi-volume-cd2b031c-832e-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:01:08.582: INFO: Pod downwardapi-volume-cd2b031c-832e-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:01:08.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xv5rd" for this suite.
May 30 23:01:14.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:01:14.636: INFO: namespace: e2e-tests-downward-api-xv5rd, resource: bindings, ignored listing per whitelist
May 30 23:01:14.677: INFO: namespace e2e-tests-downward-api-xv5rd deletion completed in 6.091370785s

• [SLOW TEST:10.209 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:01:14.678: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
May 30 23:01:14.756: INFO: Waiting up to 1m0s for all nodes to be ready
May 30 23:02:14.787: INFO: Waiting for terminating namespaces to be deleted...
May 30 23:02:14.791: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 30 23:02:14.804: INFO: 21 / 21 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 30 23:02:14.804: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
May 30 23:02:14.807: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 30 23:02:14.808: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-35502656-0 before test
May 30 23:02:14.812: INFO: sonobuoy-e2e-job-3baf2c430e984a69 from heptio-sonobuoy started at 2019-05-30 22:23:55 +0000 UTC (2 container statuses recorded)
May 30 23:02:14.812: INFO: 	Container e2e ready: true, restart count 0
May 30 23:02:14.812: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 30 23:02:14.812: INFO: sonobuoy-systemd-logs-daemon-set-261c7e37e22c4229-8qlhf from heptio-sonobuoy started at 2019-05-30 22:23:55 +0000 UTC (2 container statuses recorded)
May 30 23:02:14.812: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
May 30 23:02:14.812: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 30 23:02:14.812: INFO: kube-flannel-ds-9zr2x from kube-system started at 2019-05-30 22:22:00 +0000 UTC (2 container statuses recorded)
May 30 23:02:14.812: INFO: 	Container install-cni ready: true, restart count 0
May 30 23:02:14.812: INFO: 	Container kube-flannel ready: true, restart count 1
May 30 23:02:14.812: INFO: azure-ip-masq-agent-smv6c from kube-system started at 2019-05-30 22:22:04 +0000 UTC (1 container statuses recorded)
May 30 23:02:14.812: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 30 23:02:14.812: INFO: kube-proxy-z8rb2 from kube-system started at 2019-05-30 22:22:06 +0000 UTC (1 container statuses recorded)
May 30 23:02:14.812: INFO: 	Container kube-proxy ready: true, restart count 0
May 30 23:02:14.812: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-35502656-1 before test
May 30 23:02:14.817: INFO: kube-flannel-ds-4vsxq from kube-system started at 2019-05-30 22:22:00 +0000 UTC (2 container statuses recorded)
May 30 23:02:14.817: INFO: 	Container install-cni ready: true, restart count 0
May 30 23:02:14.817: INFO: 	Container kube-flannel ready: true, restart count 1
May 30 23:02:14.817: INFO: azure-ip-masq-agent-kjjv4 from kube-system started at 2019-05-30 22:22:04 +0000 UTC (1 container statuses recorded)
May 30 23:02:14.817: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 30 23:02:14.817: INFO: kube-proxy-htm6x from kube-system started at 2019-05-30 22:22:06 +0000 UTC (1 container statuses recorded)
May 30 23:02:14.817: INFO: 	Container kube-proxy ready: true, restart count 0
May 30 23:02:14.817: INFO: sonobuoy-systemd-logs-daemon-set-261c7e37e22c4229-x5q4v from heptio-sonobuoy started at 2019-05-30 22:23:56 +0000 UTC (2 container statuses recorded)
May 30 23:02:14.817: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
May 30 23:02:14.817: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 30 23:02:14.817: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-30 22:23:50 +0000 UTC (1 container statuses recorded)
May 30 23:02:14.817: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 30 23:02:14.817: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-35502656-2 before test
May 30 23:02:14.854: INFO: kube-flannel-ds-sqz6f from kube-system started at 2019-05-30 22:22:00 +0000 UTC (2 container statuses recorded)
May 30 23:02:14.854: INFO: 	Container install-cni ready: true, restart count 0
May 30 23:02:14.854: INFO: 	Container kube-flannel ready: true, restart count 0
May 30 23:02:14.854: INFO: azure-ip-masq-agent-fsw9b from kube-system started at 2019-05-30 22:22:04 +0000 UTC (1 container statuses recorded)
May 30 23:02:14.854: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 30 23:02:14.855: INFO: heapster-656495f65d-qxhm2 from kube-system started at 2019-05-30 22:22:19 +0000 UTC (2 container statuses recorded)
May 30 23:02:14.855: INFO: 	Container heapster ready: true, restart count 0
May 30 23:02:14.855: INFO: 	Container heapster-nanny ready: true, restart count 0
May 30 23:02:14.855: INFO: sonobuoy-systemd-logs-daemon-set-261c7e37e22c4229-nrn2p from heptio-sonobuoy started at 2019-05-30 22:23:55 +0000 UTC (2 container statuses recorded)
May 30 23:02:14.855: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
May 30 23:02:14.855: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 30 23:02:14.855: INFO: kube-proxy-wvb9t from kube-system started at 2019-05-30 22:22:06 +0000 UTC (1 container statuses recorded)
May 30 23:02:14.855: INFO: 	Container kube-proxy ready: true, restart count 0
May 30 23:02:14.855: INFO: metrics-server-5fdc668b9b-dg829 from kube-system started at 2019-05-30 22:22:19 +0000 UTC (1 container statuses recorded)
May 30 23:02:14.855: INFO: 	Container metrics-server ready: true, restart count 0
May 30 23:02:14.855: INFO: kube-dns-5f74bfc48d-wm2n9 from kube-system started at 2019-05-30 22:22:19 +0000 UTC (3 container statuses recorded)
May 30 23:02:14.855: INFO: 	Container dnsmasq ready: true, restart count 0
May 30 23:02:14.855: INFO: 	Container kubedns ready: true, restart count 0
May 30 23:02:14.855: INFO: 	Container sidecar ready: true, restart count 0
May 30 23:02:14.855: INFO: kubernetes-dashboard-7b5859758b-pc5gq from kube-system started at 2019-05-30 22:22:19 +0000 UTC (1 container statuses recorded)
May 30 23:02:14.855: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 30 23:02:14.855: INFO: tiller-deploy-88c69b9b-tp65w from kube-system started at 2019-05-30 22:22:19 +0000 UTC (1 container statuses recorded)
May 30 23:02:14.855: INFO: 	Container tiller ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f97b3867-832e-11e9-a3e0-52e03c2e65ea 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-f97b3867-832e-11e9-a3e0-52e03c2e65ea off the node k8s-linuxpool-35502656-0
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f97b3867-832e-11e9-a3e0-52e03c2e65ea
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:02:22.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-vrpf2" for this suite.
May 30 23:02:30.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:02:30.984: INFO: namespace: e2e-tests-sched-pred-vrpf2, resource: bindings, ignored listing per whitelist
May 30 23:02:31.036: INFO: namespace e2e-tests-sched-pred-vrpf2 deletion completed in 8.103078742s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

• [SLOW TEST:76.358 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:02:31.036: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating replication controller my-hostname-basic-00c5200b-832f-11e9-a3e0-52e03c2e65ea
May 30 23:02:31.118: INFO: Pod name my-hostname-basic-00c5200b-832f-11e9-a3e0-52e03c2e65ea: Found 0 pods out of 1
May 30 23:02:36.121: INFO: Pod name my-hostname-basic-00c5200b-832f-11e9-a3e0-52e03c2e65ea: Found 1 pods out of 1
May 30 23:02:36.121: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-00c5200b-832f-11e9-a3e0-52e03c2e65ea" are running
May 30 23:02:36.123: INFO: Pod "my-hostname-basic-00c5200b-832f-11e9-a3e0-52e03c2e65ea-9pv4m" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-30 23:02:31 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-30 23:02:33 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-30 23:02:31 +0000 UTC Reason: Message:}])
May 30 23:02:36.123: INFO: Trying to dial the pod
May 30 23:02:41.133: INFO: Controller my-hostname-basic-00c5200b-832f-11e9-a3e0-52e03c2e65ea: Got expected result from replica 1 [my-hostname-basic-00c5200b-832f-11e9-a3e0-52e03c2e65ea-9pv4m]: "my-hostname-basic-00c5200b-832f-11e9-a3e0-52e03c2e65ea-9pv4m", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:02:41.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-bxfkw" for this suite.
May 30 23:02:47.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:02:47.196: INFO: namespace: e2e-tests-replication-controller-bxfkw, resource: bindings, ignored listing per whitelist
May 30 23:02:47.221: INFO: namespace e2e-tests-replication-controller-bxfkw deletion completed in 6.084973212s

• [SLOW TEST:16.185 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:02:47.222: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
May 30 23:02:47.301: INFO: Waiting up to 5m0s for pod "downward-api-0a6a64c4-832f-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-downward-api-kxp4f" to be "success or failure"
May 30 23:02:47.305: INFO: Pod "downward-api-0a6a64c4-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.121199ms
May 30 23:02:49.308: INFO: Pod "downward-api-0a6a64c4-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007049683s
May 30 23:02:51.312: INFO: Pod "downward-api-0a6a64c4-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01052957s
May 30 23:02:53.315: INFO: Pod "downward-api-0a6a64c4-832f-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014021562s
STEP: Saw pod success
May 30 23:02:53.315: INFO: Pod "downward-api-0a6a64c4-832f-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:02:53.317: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod downward-api-0a6a64c4-832f-11e9-a3e0-52e03c2e65ea container dapi-container: <nil>
STEP: delete the pod
May 30 23:02:53.332: INFO: Waiting for pod downward-api-0a6a64c4-832f-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:02:53.341: INFO: Pod downward-api-0a6a64c4-832f-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:02:53.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kxp4f" for this suite.
May 30 23:02:59.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:02:59.446: INFO: namespace: e2e-tests-downward-api-kxp4f, resource: bindings, ignored listing per whitelist
May 30 23:02:59.488: INFO: namespace e2e-tests-downward-api-kxp4f deletion completed in 6.14268688s

• [SLOW TEST:12.266 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:02:59.488: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-11bb588e-832f-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume secrets
May 30 23:02:59.579: INFO: Waiting up to 5m0s for pod "pod-secrets-11bbd230-832f-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-secrets-scxmq" to be "success or failure"
May 30 23:02:59.582: INFO: Pod "pod-secrets-11bbd230-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.8719ms
May 30 23:03:01.585: INFO: Pod "pod-secrets-11bbd230-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005945908s
May 30 23:03:03.599: INFO: Pod "pod-secrets-11bbd230-832f-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019573318s
STEP: Saw pod success
May 30 23:03:03.599: INFO: Pod "pod-secrets-11bbd230-832f-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:03:03.601: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-secrets-11bbd230-832f-11e9-a3e0-52e03c2e65ea container secret-volume-test: <nil>
STEP: delete the pod
May 30 23:03:03.615: INFO: Waiting for pod pod-secrets-11bbd230-832f-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:03:03.617: INFO: Pod pod-secrets-11bbd230-832f-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:03:03.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-scxmq" for this suite.
May 30 23:03:09.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:03:09.689: INFO: namespace: e2e-tests-secrets-scxmq, resource: bindings, ignored listing per whitelist
May 30 23:03:09.721: INFO: namespace e2e-tests-secrets-scxmq deletion completed in 6.099863447s

• [SLOW TEST:10.233 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:03:09.723: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-fp7v7
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-fp7v7
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-fp7v7
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-fp7v7
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-fp7v7
May 30 23:03:13.851: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-fp7v7, name: ss-0, uid: 17e3ee05-832f-11e9-9b52-001dd80c000f, status phase: Pending. Waiting for statefulset controller to delete.
May 30 23:03:14.052: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-fp7v7, name: ss-0, uid: 17e3ee05-832f-11e9-9b52-001dd80c000f, status phase: Failed. Waiting for statefulset controller to delete.
May 30 23:03:14.059: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-fp7v7, name: ss-0, uid: 17e3ee05-832f-11e9-9b52-001dd80c000f, status phase: Failed. Waiting for statefulset controller to delete.
May 30 23:03:14.066: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-fp7v7
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-fp7v7
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-fp7v7 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 30 23:03:18.089: INFO: Deleting all statefulset in ns e2e-tests-statefulset-fp7v7
May 30 23:03:18.092: INFO: Scaling statefulset ss to 0
May 30 23:03:28.106: INFO: Waiting for statefulset status.replicas updated to 0
May 30 23:03:28.108: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:03:28.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-fp7v7" for this suite.
May 30 23:03:34.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:03:34.176: INFO: namespace: e2e-tests-statefulset-fp7v7, resource: bindings, ignored listing per whitelist
May 30 23:03:34.208: INFO: namespace e2e-tests-statefulset-fp7v7 deletion completed in 6.08658119s

• [SLOW TEST:24.485 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:03:34.208: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 30 23:03:34.293: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 30 23:03:34.299: INFO: Number of nodes with available pods: 0
May 30 23:03:34.299: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 30 23:03:34.320: INFO: Number of nodes with available pods: 0
May 30 23:03:34.320: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 23:03:35.323: INFO: Number of nodes with available pods: 0
May 30 23:03:35.323: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 23:03:36.323: INFO: Number of nodes with available pods: 0
May 30 23:03:36.323: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 23:03:37.323: INFO: Number of nodes with available pods: 1
May 30 23:03:37.323: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 30 23:03:37.342: INFO: Number of nodes with available pods: 1
May 30 23:03:37.342: INFO: Number of running nodes: 0, number of available pods: 1
May 30 23:03:38.345: INFO: Number of nodes with available pods: 0
May 30 23:03:38.345: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 30 23:03:38.353: INFO: Number of nodes with available pods: 0
May 30 23:03:38.353: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 23:03:39.356: INFO: Number of nodes with available pods: 0
May 30 23:03:39.357: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 23:03:40.357: INFO: Number of nodes with available pods: 0
May 30 23:03:40.357: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 23:03:41.357: INFO: Number of nodes with available pods: 0
May 30 23:03:41.357: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 23:03:42.357: INFO: Number of nodes with available pods: 0
May 30 23:03:42.357: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 23:03:43.357: INFO: Number of nodes with available pods: 0
May 30 23:03:43.357: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 23:03:44.356: INFO: Number of nodes with available pods: 0
May 30 23:03:44.356: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 23:03:45.357: INFO: Number of nodes with available pods: 0
May 30 23:03:45.357: INFO: Node k8s-linuxpool-35502656-0 is running more than one daemon pod
May 30 23:03:46.356: INFO: Number of nodes with available pods: 1
May 30 23:03:46.356: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-zxv5j, will wait for the garbage collector to delete the pods
May 30 23:03:46.418: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.1394ms
May 30 23:03:46.518: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.173289ms
May 30 23:03:54.221: INFO: Number of nodes with available pods: 0
May 30 23:03:54.221: INFO: Number of running nodes: 0, number of available pods: 0
May 30 23:03:54.223: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zxv5j/daemonsets","resourceVersion":"8437"},"items":null}

May 30 23:03:54.225: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zxv5j/pods","resourceVersion":"8437"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:03:54.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-zxv5j" for this suite.
May 30 23:04:00.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:04:00.411: INFO: namespace: e2e-tests-daemonsets-zxv5j, resource: bindings, ignored listing per whitelist
May 30 23:04:00.436: INFO: namespace e2e-tests-daemonsets-zxv5j deletion completed in 6.195104524s

• [SLOW TEST:26.228 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:04:00.437: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-361a5786-832f-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume secrets
May 30 23:04:00.604: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-361b928a-832f-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-89g8t" to be "success or failure"
May 30 23:04:00.610: INFO: Pod "pod-projected-secrets-361b928a-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.054299ms
May 30 23:04:02.613: INFO: Pod "pod-projected-secrets-361b928a-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00823982s
May 30 23:04:04.616: INFO: Pod "pod-projected-secrets-361b928a-832f-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011336345s
STEP: Saw pod success
May 30 23:04:04.616: INFO: Pod "pod-projected-secrets-361b928a-832f-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:04:04.619: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-projected-secrets-361b928a-832f-11e9-a3e0-52e03c2e65ea container projected-secret-volume-test: <nil>
STEP: delete the pod
May 30 23:04:04.635: INFO: Waiting for pod pod-projected-secrets-361b928a-832f-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:04:04.638: INFO: Pod pod-projected-secrets-361b928a-832f-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:04:04.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-89g8t" for this suite.
May 30 23:04:10.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:04:10.718: INFO: namespace: e2e-tests-projected-89g8t, resource: bindings, ignored listing per whitelist
May 30 23:04:10.727: INFO: namespace e2e-tests-projected-89g8t deletion completed in 6.086399589s

• [SLOW TEST:10.291 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:04:10.729: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-map-3c30dea4-832f-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume secrets
May 30 23:04:10.815: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3c315807-832f-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-sbwwr" to be "success or failure"
May 30 23:04:10.818: INFO: Pod "pod-projected-secrets-3c315807-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.8254ms
May 30 23:04:12.821: INFO: Pod "pod-projected-secrets-3c315807-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006278438s
May 30 23:04:14.825: INFO: Pod "pod-projected-secrets-3c315807-832f-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00970808s
STEP: Saw pod success
May 30 23:04:14.825: INFO: Pod "pod-projected-secrets-3c315807-832f-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:04:14.827: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-projected-secrets-3c315807-832f-11e9-a3e0-52e03c2e65ea container projected-secret-volume-test: <nil>
STEP: delete the pod
May 30 23:04:14.840: INFO: Waiting for pod pod-projected-secrets-3c315807-832f-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:04:14.843: INFO: Pod pod-projected-secrets-3c315807-832f-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:04:14.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sbwwr" for this suite.
May 30 23:04:20.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:04:20.905: INFO: namespace: e2e-tests-projected-sbwwr, resource: bindings, ignored listing per whitelist
May 30 23:04:20.938: INFO: namespace e2e-tests-projected-sbwwr deletion completed in 6.092078241s

• [SLOW TEST:10.209 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:04:20.940: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-upd-42474f51-832f-11e9-a3e0-52e03c2e65ea
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-42474f51-832f-11e9-a3e0-52e03c2e65ea
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:05:41.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6289j" for this suite.
May 30 23:06:03.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:06:03.433: INFO: namespace: e2e-tests-configmap-6289j, resource: bindings, ignored listing per whitelist
May 30 23:06:03.483: INFO: namespace e2e-tests-configmap-6289j deletion completed in 22.092896242s

• [SLOW TEST:102.544 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:06:03.484: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 30 23:06:03.598: INFO: Waiting up to 5m0s for pod "pod-7f6a4768-832f-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-emptydir-7cj5k" to be "success or failure"
May 30 23:06:03.601: INFO: Pod "pod-7f6a4768-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.3972ms
May 30 23:06:05.604: INFO: Pod "pod-7f6a4768-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006061912s
May 30 23:06:07.607: INFO: Pod "pod-7f6a4768-832f-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009443526s
STEP: Saw pod success
May 30 23:06:07.607: INFO: Pod "pod-7f6a4768-832f-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:06:07.609: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-7f6a4768-832f-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 23:06:07.622: INFO: Waiting for pod pod-7f6a4768-832f-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:06:07.625: INFO: Pod pod-7f6a4768-832f-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:06:07.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7cj5k" for this suite.
May 30 23:06:13.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:06:13.680: INFO: namespace: e2e-tests-emptydir-7cj5k, resource: bindings, ignored listing per whitelist
May 30 23:06:13.709: INFO: namespace e2e-tests-emptydir-7cj5k deletion completed in 6.081801961s

• [SLOW TEST:10.226 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:06:13.711: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 23:06:13.789: INFO: Waiting up to 5m0s for pod "downwardapi-volume-857dba99-832f-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-downward-api-wcwvt" to be "success or failure"
May 30 23:06:13.794: INFO: Pod "downwardapi-volume-857dba99-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.1101ms
May 30 23:06:15.798: INFO: Pod "downwardapi-volume-857dba99-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008774125s
May 30 23:06:17.801: INFO: Pod "downwardapi-volume-857dba99-832f-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011914153s
STEP: Saw pod success
May 30 23:06:17.801: INFO: Pod "downwardapi-volume-857dba99-832f-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:06:17.803: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod downwardapi-volume-857dba99-832f-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 23:06:17.817: INFO: Waiting for pod downwardapi-volume-857dba99-832f-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:06:17.820: INFO: Pod downwardapi-volume-857dba99-832f-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:06:17.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wcwvt" for this suite.
May 30 23:06:23.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:06:23.848: INFO: namespace: e2e-tests-downward-api-wcwvt, resource: bindings, ignored listing per whitelist
May 30 23:06:23.910: INFO: namespace e2e-tests-downward-api-wcwvt deletion completed in 6.087098202s

• [SLOW TEST:10.200 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:06:23.911: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
May 30 23:06:23.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 run e2e-test-nginx-rc --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=run/v1 --namespace=e2e-tests-kubectl-dfd4t'
May 30 23:06:24.441: INFO: stderr: ""
May 30 23:06:24.441: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May 30 23:06:24.449: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-bnwgd]
May 30 23:06:24.449: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-bnwgd" in namespace "e2e-tests-kubectl-dfd4t" to be "running and ready"
May 30 23:06:24.453: INFO: Pod "e2e-test-nginx-rc-bnwgd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.4701ms
May 30 23:06:26.457: INFO: Pod "e2e-test-nginx-rc-bnwgd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007556239s
May 30 23:06:28.459: INFO: Pod "e2e-test-nginx-rc-bnwgd": Phase="Running", Reason="", readiness=true. Elapsed: 4.010218982s
May 30 23:06:28.459: INFO: Pod "e2e-test-nginx-rc-bnwgd" satisfied condition "running and ready"
May 30 23:06:28.459: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-bnwgd]
May 30 23:06:28.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dfd4t'
May 30 23:06:28.592: INFO: stderr: ""
May 30 23:06:28.592: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1221
May 30 23:06:28.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dfd4t'
May 30 23:06:28.707: INFO: stderr: ""
May 30 23:06:28.707: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:06:28.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dfd4t" for this suite.
May 30 23:06:50.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:06:50.778: INFO: namespace: e2e-tests-kubectl-dfd4t, resource: bindings, ignored listing per whitelist
May 30 23:06:50.802: INFO: namespace e2e-tests-kubectl-dfd4t deletion completed in 22.090787743s

• [SLOW TEST:26.891 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:06:50.802: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
May 30 23:06:51.400: INFO: Waiting up to 5m0s for pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-j6lpf" in namespace "e2e-tests-svcaccounts-ck4hs" to be "success or failure"
May 30 23:06:51.406: INFO: Pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-j6lpf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.9525ms
May 30 23:06:53.409: INFO: Pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-j6lpf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008857574s
May 30 23:06:55.412: INFO: Pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-j6lpf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011817451s
STEP: Saw pod success
May 30 23:06:55.412: INFO: Pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-j6lpf" satisfied condition "success or failure"
May 30 23:06:55.414: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-j6lpf container token-test: <nil>
STEP: delete the pod
May 30 23:06:55.431: INFO: Waiting for pod pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-j6lpf to disappear
May 30 23:06:55.435: INFO: Pod pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-j6lpf no longer exists
STEP: Creating a pod to test consume service account root CA
May 30 23:06:55.438: INFO: Waiting up to 5m0s for pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-swzmf" in namespace "e2e-tests-svcaccounts-ck4hs" to be "success or failure"
May 30 23:06:55.447: INFO: Pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-swzmf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.2094ms
May 30 23:06:57.450: INFO: Pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-swzmf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011198579s
May 30 23:06:59.453: INFO: Pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-swzmf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014465461s
STEP: Saw pod success
May 30 23:06:59.453: INFO: Pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-swzmf" satisfied condition "success or failure"
May 30 23:06:59.455: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-swzmf container root-ca-test: <nil>
STEP: delete the pod
May 30 23:06:59.472: INFO: Waiting for pod pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-swzmf to disappear
May 30 23:06:59.474: INFO: Pod pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-swzmf no longer exists
STEP: Creating a pod to test consume service account namespace
May 30 23:06:59.477: INFO: Waiting up to 5m0s for pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-zr8hg" in namespace "e2e-tests-svcaccounts-ck4hs" to be "success or failure"
May 30 23:06:59.480: INFO: Pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-zr8hg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.4288ms
May 30 23:07:01.483: INFO: Pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-zr8hg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005570985s
May 30 23:07:03.486: INFO: Pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-zr8hg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008976572s
STEP: Saw pod success
May 30 23:07:03.486: INFO: Pod "pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-zr8hg" satisfied condition "success or failure"
May 30 23:07:03.488: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-zr8hg container namespace-test: <nil>
STEP: delete the pod
May 30 23:07:03.543: INFO: Waiting for pod pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-zr8hg to disappear
May 30 23:07:03.545: INFO: Pod pod-service-account-9be8cad1-832f-11e9-a3e0-52e03c2e65ea-zr8hg no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:07:03.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-ck4hs" for this suite.
May 30 23:07:09.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:07:09.621: INFO: namespace: e2e-tests-svcaccounts-ck4hs, resource: bindings, ignored listing per whitelist
May 30 23:07:09.635: INFO: namespace e2e-tests-svcaccounts-ck4hs deletion completed in 6.08672378s

• [SLOW TEST:18.833 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:07:09.635: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test substitution in container's command
May 30 23:07:09.719: INFO: Waiting up to 5m0s for pod "var-expansion-a6d41a9a-832f-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-var-expansion-565pt" to be "success or failure"
May 30 23:07:09.724: INFO: Pod "var-expansion-a6d41a9a-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.0905ms
May 30 23:07:11.727: INFO: Pod "var-expansion-a6d41a9a-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008112697s
May 30 23:07:13.730: INFO: Pod "var-expansion-a6d41a9a-832f-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010800796s
STEP: Saw pod success
May 30 23:07:13.730: INFO: Pod "var-expansion-a6d41a9a-832f-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:07:13.732: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod var-expansion-a6d41a9a-832f-11e9-a3e0-52e03c2e65ea container dapi-container: <nil>
STEP: delete the pod
May 30 23:07:13.746: INFO: Waiting for pod var-expansion-a6d41a9a-832f-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:07:13.748: INFO: Pod var-expansion-a6d41a9a-832f-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:07:13.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-565pt" for this suite.
May 30 23:07:19.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:07:19.776: INFO: namespace: e2e-tests-var-expansion-565pt, resource: bindings, ignored listing per whitelist
May 30 23:07:19.842: INFO: namespace e2e-tests-var-expansion-565pt deletion completed in 6.090671917s

• [SLOW TEST:10.207 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:07:19.842: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
May 30 23:07:24.457: INFO: Successfully updated pod "annotationupdateace95e04-832f-11e9-a3e0-52e03c2e65ea"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:07:26.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fv5vs" for this suite.
May 30 23:07:48.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:07:48.554: INFO: namespace: e2e-tests-projected-fv5vs, resource: bindings, ignored listing per whitelist
May 30 23:07:48.607: INFO: namespace e2e-tests-projected-fv5vs deletion completed in 22.130803416s

• [SLOW TEST:28.765 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:07:48.607: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 30 23:07:48.748: INFO: Waiting up to 5m0s for pod "pod-be1753d3-832f-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-emptydir-mrhnz" to be "success or failure"
May 30 23:07:48.755: INFO: Pod "pod-be1753d3-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 7.69ms
May 30 23:07:50.758: INFO: Pod "pod-be1753d3-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010312443s
May 30 23:07:52.761: INFO: Pod "pod-be1753d3-832f-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013314088s
STEP: Saw pod success
May 30 23:07:52.761: INFO: Pod "pod-be1753d3-832f-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:07:52.763: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-be1753d3-832f-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 23:07:52.805: INFO: Waiting for pod pod-be1753d3-832f-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:07:52.808: INFO: Pod pod-be1753d3-832f-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:07:52.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mrhnz" for this suite.
May 30 23:07:58.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:07:58.888: INFO: namespace: e2e-tests-emptydir-mrhnz, resource: bindings, ignored listing per whitelist
May 30 23:07:58.898: INFO: namespace e2e-tests-emptydir-mrhnz deletion completed in 6.086152051s

• [SLOW TEST:10.291 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:07:58.898: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 30 23:07:58.977: INFO: Waiting up to 5m0s for pod "pod-c4306222-832f-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-emptydir-v7hmz" to be "success or failure"
May 30 23:07:58.979: INFO: Pod "pod-c4306222-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 1.936901ms
May 30 23:08:00.982: INFO: Pod "pod-c4306222-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005374154s
May 30 23:08:02.986: INFO: Pod "pod-c4306222-832f-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00873161s
STEP: Saw pod success
May 30 23:08:02.986: INFO: Pod "pod-c4306222-832f-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:08:02.988: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-c4306222-832f-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 23:08:03.004: INFO: Waiting for pod pod-c4306222-832f-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:08:03.006: INFO: Pod pod-c4306222-832f-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:08:03.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-v7hmz" for this suite.
May 30 23:08:09.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:08:09.050: INFO: namespace: e2e-tests-emptydir-v7hmz, resource: bindings, ignored listing per whitelist
May 30 23:08:09.095: INFO: namespace e2e-tests-emptydir-v7hmz deletion completed in 6.085084685s

• [SLOW TEST:10.197 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:08:09.095: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-ca444449-832f-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 23:08:09.178: INFO: Waiting up to 5m0s for pod "pod-configmaps-ca44cca0-832f-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-configmap-ctbrk" to be "success or failure"
May 30 23:08:09.183: INFO: Pod "pod-configmaps-ca44cca0-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.057901ms
May 30 23:08:11.186: INFO: Pod "pod-configmaps-ca44cca0-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007962565s
May 30 23:08:13.189: INFO: Pod "pod-configmaps-ca44cca0-832f-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010777932s
STEP: Saw pod success
May 30 23:08:13.189: INFO: Pod "pod-configmaps-ca44cca0-832f-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:08:13.191: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-configmaps-ca44cca0-832f-11e9-a3e0-52e03c2e65ea container configmap-volume-test: <nil>
STEP: delete the pod
May 30 23:08:13.206: INFO: Waiting for pod pod-configmaps-ca44cca0-832f-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:08:13.209: INFO: Pod pod-configmaps-ca44cca0-832f-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:08:13.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ctbrk" for this suite.
May 30 23:08:19.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:08:19.260: INFO: namespace: e2e-tests-configmap-ctbrk, resource: bindings, ignored listing per whitelist
May 30 23:08:19.323: INFO: namespace e2e-tests-configmap-ctbrk deletion completed in 6.110812321s

• [SLOW TEST:10.228 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:08:19.323: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
May 30 23:08:19.405: INFO: Waiting up to 5m0s for pod "downward-api-d05d3b57-832f-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-downward-api-bp56p" to be "success or failure"
May 30 23:08:19.407: INFO: Pod "downward-api-d05d3b57-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.2817ms
May 30 23:08:21.411: INFO: Pod "downward-api-d05d3b57-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005574875s
May 30 23:08:23.484: INFO: Pod "downward-api-d05d3b57-832f-11e9-a3e0-52e03c2e65ea": Phase="Running", Reason="", readiness=true. Elapsed: 4.07935456s
May 30 23:08:25.488: INFO: Pod "downward-api-d05d3b57-832f-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.083028339s
STEP: Saw pod success
May 30 23:08:25.488: INFO: Pod "downward-api-d05d3b57-832f-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:08:25.491: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod downward-api-d05d3b57-832f-11e9-a3e0-52e03c2e65ea container dapi-container: <nil>
STEP: delete the pod
May 30 23:08:25.513: INFO: Waiting for pod downward-api-d05d3b57-832f-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:08:25.515: INFO: Pod downward-api-d05d3b57-832f-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:08:25.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bp56p" for this suite.
May 30 23:08:31.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:08:31.563: INFO: namespace: e2e-tests-downward-api-bp56p, resource: bindings, ignored listing per whitelist
May 30 23:08:31.607: INFO: namespace e2e-tests-downward-api-bp56p deletion completed in 6.089190558s

• [SLOW TEST:12.284 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:08:31.608: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir volume type on node default medium
May 30 23:08:31.689: INFO: Waiting up to 5m0s for pod "pod-d7af93d7-832f-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-emptydir-9dbb2" to be "success or failure"
May 30 23:08:31.694: INFO: Pod "pod-d7af93d7-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.726901ms
May 30 23:08:33.696: INFO: Pod "pod-d7af93d7-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007454188s
May 30 23:08:35.755: INFO: Pod "pod-d7af93d7-832f-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066396284s
STEP: Saw pod success
May 30 23:08:35.755: INFO: Pod "pod-d7af93d7-832f-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:08:35.757: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-d7af93d7-832f-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 23:08:35.782: INFO: Waiting for pod pod-d7af93d7-832f-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:08:35.784: INFO: Pod pod-d7af93d7-832f-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:08:35.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9dbb2" for this suite.
May 30 23:08:41.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:08:41.844: INFO: namespace: e2e-tests-emptydir-9dbb2, resource: bindings, ignored listing per whitelist
May 30 23:08:41.878: INFO: namespace e2e-tests-emptydir-9dbb2 deletion completed in 6.09118549s

• [SLOW TEST:10.271 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:08:41.881: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-s4t5w in namespace e2e-tests-proxy-2g2jn
I0530 23:08:41.982902      16 runners.go:177] Created replication controller with name: proxy-service-s4t5w, namespace: e2e-tests-proxy-2g2jn, replica count: 1
I0530 23:08:43.036169      16 runners.go:177] proxy-service-s4t5w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0530 23:08:44.036335      16 runners.go:177] proxy-service-s4t5w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0530 23:08:45.036759      16 runners.go:177] proxy-service-s4t5w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0530 23:08:46.036941      16 runners.go:177] proxy-service-s4t5w Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0530 23:08:47.037140      16 runners.go:177] proxy-service-s4t5w Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0530 23:08:48.037348      16 runners.go:177] proxy-service-s4t5w Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0530 23:08:49.037535      16 runners.go:177] proxy-service-s4t5w Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0530 23:08:50.037751      16 runners.go:177] proxy-service-s4t5w Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0530 23:08:51.037940      16 runners.go:177] proxy-service-s4t5w Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0530 23:08:52.038172      16 runners.go:177] proxy-service-s4t5w Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0530 23:08:53.038355      16 runners.go:177] proxy-service-s4t5w Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0530 23:08:54.038563      16 runners.go:177] proxy-service-s4t5w Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0530 23:08:55.038728      16 runners.go:177] proxy-service-s4t5w Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0530 23:08:56.038943      16 runners.go:177] proxy-service-s4t5w Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 30 23:08:56.042: INFO: setup took 14.086560039s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 30 23:08:56.073: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 30.983503ms)
May 30 23:08:56.074: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 30.984403ms)
May 30 23:08:56.074: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 30.916703ms)
May 30 23:08:56.074: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 30.903203ms)
May 30 23:08:56.074: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 30.997903ms)
May 30 23:08:56.074: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 31.123703ms)
May 30 23:08:56.074: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 31.282903ms)
May 30 23:08:56.074: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 31.250103ms)
May 30 23:08:56.074: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 31.359203ms)
May 30 23:08:56.074: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 31.488403ms)
May 30 23:08:56.074: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 31.130603ms)
May 30 23:08:56.074: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 31.471503ms)
May 30 23:08:56.074: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 31.794403ms)
May 30 23:08:56.075: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 32.010203ms)
May 30 23:08:56.075: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 31.930103ms)
May 30 23:08:56.075: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 32.561303ms)
May 30 23:08:56.081: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 5.255801ms)
May 30 23:08:56.081: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 6.190001ms)
May 30 23:08:56.081: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 6.010901ms)
May 30 23:08:56.082: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 6.189201ms)
May 30 23:08:56.085: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 9.207301ms)
May 30 23:08:56.086: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 10.440401ms)
May 30 23:08:56.087: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 10.590201ms)
May 30 23:08:56.088: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 11.526601ms)
May 30 23:08:56.088: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 11.641101ms)
May 30 23:08:56.088: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 11.502801ms)
May 30 23:08:56.088: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 12.222602ms)
May 30 23:08:56.089: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 12.590802ms)
May 30 23:08:56.089: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 13.224202ms)
May 30 23:08:56.090: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 13.239302ms)
May 30 23:08:56.091: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 14.265602ms)
May 30 23:08:56.092: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 15.254102ms)
May 30 23:08:56.099: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 7.337201ms)
May 30 23:08:56.100: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 7.290101ms)
May 30 23:08:56.100: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 7.428601ms)
May 30 23:08:56.102: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 9.826501ms)
May 30 23:08:56.102: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 9.730801ms)
May 30 23:08:56.102: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 9.904001ms)
May 30 23:08:56.105: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 12.948201ms)
May 30 23:08:56.105: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 12.644401ms)
May 30 23:08:56.105: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 12.916901ms)
May 30 23:08:56.105: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 12.729801ms)
May 30 23:08:56.105: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 12.960001ms)
May 30 23:08:56.105: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 12.914801ms)
May 30 23:08:56.105: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 13.090301ms)
May 30 23:08:56.105: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 12.785501ms)
May 30 23:08:56.105: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 12.847101ms)
May 30 23:08:56.105: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 12.756001ms)
May 30 23:08:56.113: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 7.165601ms)
May 30 23:08:56.114: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 8.419201ms)
May 30 23:08:56.114: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 8.815101ms)
May 30 23:08:56.114: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 8.472101ms)
May 30 23:08:56.114: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 8.539401ms)
May 30 23:08:56.116: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 10.245801ms)
May 30 23:08:56.116: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 10.038301ms)
May 30 23:08:56.116: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 10.330101ms)
May 30 23:08:56.119: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 12.893902ms)
May 30 23:08:56.119: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 13.233502ms)
May 30 23:08:56.119: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 13.075002ms)
May 30 23:08:56.119: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 13.529302ms)
May 30 23:08:56.120: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 14.317002ms)
May 30 23:08:56.120: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 14.553302ms)
May 30 23:08:56.121: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 14.780002ms)
May 30 23:08:56.121: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 14.511202ms)
May 30 23:08:56.125: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 4.8187ms)
May 30 23:08:56.127: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 6.138901ms)
May 30 23:08:56.128: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 7.062501ms)
May 30 23:08:56.128: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 7.425301ms)
May 30 23:08:56.129: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 7.832301ms)
May 30 23:08:56.129: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 8.236201ms)
May 30 23:08:56.131: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 9.911301ms)
May 30 23:08:56.132: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 11.357201ms)
May 30 23:08:56.133: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 11.538201ms)
May 30 23:08:56.133: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 11.405501ms)
May 30 23:08:56.133: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 11.587601ms)
May 30 23:08:56.134: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 13.358901ms)
May 30 23:08:56.134: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 13.173501ms)
May 30 23:08:56.134: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 13.381401ms)
May 30 23:08:56.134: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 13.412901ms)
May 30 23:08:56.135: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 13.697201ms)
May 30 23:08:56.142: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 6.784901ms)
May 30 23:08:56.147: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 10.667601ms)
May 30 23:08:56.147: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 11.200202ms)
May 30 23:08:56.147: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 10.659801ms)
May 30 23:08:56.147: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 10.844201ms)
May 30 23:08:56.148: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 10.439101ms)
May 30 23:08:56.149: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 11.691201ms)
May 30 23:08:56.149: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 12.610301ms)
May 30 23:08:56.149: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 14.329102ms)
May 30 23:08:56.150: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 12.825901ms)
May 30 23:08:56.151: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 15.994502ms)
May 30 23:08:56.152: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 15.135401ms)
May 30 23:08:56.152: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 15.529701ms)
May 30 23:08:56.152: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 14.710201ms)
May 30 23:08:56.153: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 15.667101ms)
May 30 23:08:56.153: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 15.540701ms)
May 30 23:08:56.160: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 7.426001ms)
May 30 23:08:56.161: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 7.059501ms)
May 30 23:08:56.161: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 6.753201ms)
May 30 23:08:56.161: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 7.609601ms)
May 30 23:08:56.161: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 7.977301ms)
May 30 23:08:56.166: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 12.610902ms)
May 30 23:08:56.166: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 11.777602ms)
May 30 23:08:56.166: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 13.156302ms)
May 30 23:08:56.167: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 13.456302ms)
May 30 23:08:56.167: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 12.956502ms)
May 30 23:08:56.171: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 16.312502ms)
May 30 23:08:56.171: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 17.166102ms)
May 30 23:08:56.171: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 17.499902ms)
May 30 23:08:56.171: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 17.275502ms)
May 30 23:08:56.171: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 17.396102ms)
May 30 23:08:56.172: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 18.430502ms)
May 30 23:08:56.185: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 12.629202ms)
May 30 23:08:56.187: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 14.915502ms)
May 30 23:08:56.188: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 15.320002ms)
May 30 23:08:56.188: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 15.422102ms)
May 30 23:08:56.188: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 16.035902ms)
May 30 23:08:56.188: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 15.594302ms)
May 30 23:08:56.189: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 16.345802ms)
May 30 23:08:56.189: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 16.378102ms)
May 30 23:08:56.189: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 17.079302ms)
May 30 23:08:56.190: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 17.557702ms)
May 30 23:08:56.190: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 17.122102ms)
May 30 23:08:56.190: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 17.712102ms)
May 30 23:08:56.190: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 17.355902ms)
May 30 23:08:56.192: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 19.874302ms)
May 30 23:08:56.192: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 19.701102ms)
May 30 23:08:56.192: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 19.531902ms)
May 30 23:08:56.198: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 5.845701ms)
May 30 23:08:56.198: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 5.858001ms)
May 30 23:08:56.201: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 8.7562ms)
May 30 23:08:56.202: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 8.9164ms)
May 30 23:08:56.202: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 8.7631ms)
May 30 23:08:56.202: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 8.8671ms)
May 30 23:08:56.202: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 8.9246ms)
May 30 23:08:56.202: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 8.911ms)
May 30 23:08:56.202: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 8.7862ms)
May 30 23:08:56.205: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 11.877501ms)
May 30 23:08:56.205: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 12.458501ms)
May 30 23:08:56.206: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 13.535601ms)
May 30 23:08:56.207: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 13.980401ms)
May 30 23:08:56.207: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 14.212101ms)
May 30 23:08:56.209: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 15.751601ms)
May 30 23:08:56.210: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 17.167301ms)
May 30 23:08:56.221: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 10.850302ms)
May 30 23:08:56.222: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 11.192602ms)
May 30 23:08:56.223: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 12.702702ms)
May 30 23:08:56.223: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 12.652502ms)
May 30 23:08:56.223: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 12.804502ms)
May 30 23:08:56.223: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 12.654002ms)
May 30 23:08:56.223: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 12.541802ms)
May 30 23:08:56.223: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 12.784702ms)
May 30 23:08:56.223: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 12.752702ms)
May 30 23:08:56.223: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 12.786202ms)
May 30 23:08:56.223: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 12.755102ms)
May 30 23:08:56.223: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 13.286202ms)
May 30 23:08:56.225: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 14.196702ms)
May 30 23:08:56.225: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 14.445402ms)
May 30 23:08:56.225: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 14.905002ms)
May 30 23:08:56.226: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 15.128702ms)
May 30 23:08:56.233: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 7.447401ms)
May 30 23:08:56.234: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 8.271901ms)
May 30 23:08:56.234: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 8.463401ms)
May 30 23:08:56.234: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 8.393201ms)
May 30 23:08:56.237: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 10.752301ms)
May 30 23:08:56.237: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 10.789301ms)
May 30 23:08:56.237: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 10.780701ms)
May 30 23:08:56.237: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 10.910901ms)
May 30 23:08:56.238: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 11.919001ms)
May 30 23:08:56.240: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 14.433502ms)
May 30 23:08:56.240: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 14.534902ms)
May 30 23:08:56.241: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 14.564102ms)
May 30 23:08:56.241: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 14.947102ms)
May 30 23:08:56.241: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 15.213402ms)
May 30 23:08:56.241: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 15.406302ms)
May 30 23:08:56.243: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 17.194902ms)
May 30 23:08:56.249: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 5.8406ms)
May 30 23:08:56.250: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 5.814101ms)
May 30 23:08:56.250: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 6.059301ms)
May 30 23:08:56.250: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 6.391801ms)
May 30 23:08:56.252: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 8.087001ms)
May 30 23:08:56.254: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 10.191501ms)
May 30 23:08:56.254: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 10.432501ms)
May 30 23:08:56.256: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 12.025401ms)
May 30 23:08:56.256: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 12.307001ms)
May 30 23:08:56.256: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 11.904001ms)
May 30 23:08:56.257: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 13.226101ms)
May 30 23:08:56.259: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 15.000501ms)
May 30 23:08:56.259: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 15.216301ms)
May 30 23:08:56.259: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 15.097102ms)
May 30 23:08:56.259: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 15.351102ms)
May 30 23:08:56.259: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 15.686902ms)
May 30 23:08:56.265: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 4.8461ms)
May 30 23:08:56.266: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 6.1024ms)
May 30 23:08:56.266: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 6.8578ms)
May 30 23:08:56.268: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 8.4145ms)
May 30 23:08:56.268: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 8.5412ms)
May 30 23:08:56.268: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 8.481ms)
May 30 23:08:56.268: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 8.6262ms)
May 30 23:08:56.274: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 14.113701ms)
May 30 23:08:56.274: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 14.634801ms)
May 30 23:08:56.274: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 14.241801ms)
May 30 23:08:56.275: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 15.540301ms)
May 30 23:08:56.276: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 15.885901ms)
May 30 23:08:56.276: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 15.876901ms)
May 30 23:08:56.276: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 15.874501ms)
May 30 23:08:56.276: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 16.465801ms)
May 30 23:08:56.276: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 16.518601ms)
May 30 23:08:56.282: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 5.390301ms)
May 30 23:08:56.283: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 6.646401ms)
May 30 23:08:56.284: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 6.953501ms)
May 30 23:08:56.284: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 7.598001ms)
May 30 23:08:56.288: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 10.891102ms)
May 30 23:08:56.288: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 10.794802ms)
May 30 23:08:56.288: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 10.977502ms)
May 30 23:08:56.289: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 11.221102ms)
May 30 23:08:56.289: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 11.682502ms)
May 30 23:08:56.289: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 12.018202ms)
May 30 23:08:56.289: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 11.747602ms)
May 30 23:08:56.290: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 12.440902ms)
May 30 23:08:56.290: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 12.675202ms)
May 30 23:08:56.291: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 14.092302ms)
May 30 23:08:56.291: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 14.203802ms)
May 30 23:08:56.292: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 14.912202ms)
May 30 23:08:56.304: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 11.433901ms)
May 30 23:08:56.304: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 11.852701ms)
May 30 23:08:56.304: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 11.557401ms)
May 30 23:08:56.304: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 11.680901ms)
May 30 23:08:56.304: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 11.981001ms)
May 30 23:08:56.305: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 12.279401ms)
May 30 23:08:56.305: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 12.376601ms)
May 30 23:08:56.305: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 12.322501ms)
May 30 23:08:56.305: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 13.120801ms)
May 30 23:08:56.305: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 13.101501ms)
May 30 23:08:56.305: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 13.260701ms)
May 30 23:08:56.308: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 16.247202ms)
May 30 23:08:56.308: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 16.311402ms)
May 30 23:08:56.308: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 16.262602ms)
May 30 23:08:56.310: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 17.630602ms)
May 30 23:08:56.310: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 17.630302ms)
May 30 23:08:56.319: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 7.961201ms)
May 30 23:08:56.321: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 9.720501ms)
May 30 23:08:56.321: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 10.067201ms)
May 30 23:08:56.321: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 10.290601ms)
May 30 23:08:56.321: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 10.077201ms)
May 30 23:08:56.321: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 10.289901ms)
May 30 23:08:56.321: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 10.001601ms)
May 30 23:08:56.321: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 10.145301ms)
May 30 23:08:56.321: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 10.506201ms)
May 30 23:08:56.321: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 10.135101ms)
May 30 23:08:56.321: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 9.989801ms)
May 30 23:08:56.321: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 10.937001ms)
May 30 23:08:56.321: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 11.237801ms)
May 30 23:08:56.322: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 11.492201ms)
May 30 23:08:56.322: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 10.610301ms)
May 30 23:08:56.323: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 12.146401ms)
May 30 23:08:56.329: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 5.998601ms)
May 30 23:08:56.330: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 6.685401ms)
May 30 23:08:56.332: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 7.993301ms)
May 30 23:08:56.332: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 8.093501ms)
May 30 23:08:56.332: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 8.423801ms)
May 30 23:08:56.332: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 8.261001ms)
May 30 23:08:56.332: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 8.403101ms)
May 30 23:08:56.335: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 11.127701ms)
May 30 23:08:56.335: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 10.397501ms)
May 30 23:08:56.335: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 11.107402ms)
May 30 23:08:56.335: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 11.228402ms)
May 30 23:08:56.335: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 10.907502ms)
May 30 23:08:56.336: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 12.452102ms)
May 30 23:08:56.336: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 12.815502ms)
May 30 23:08:56.337: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 13.498602ms)
May 30 23:08:56.337: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 14.333702ms)
May 30 23:08:56.347: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 9.103901ms)
May 30 23:08:56.347: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 9.629301ms)
May 30 23:08:56.349: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 10.697801ms)
May 30 23:08:56.349: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 11.030601ms)
May 30 23:08:56.349: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 10.668901ms)
May 30 23:08:56.349: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 10.614901ms)
May 30 23:08:56.350: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 12.305401ms)
May 30 23:08:56.350: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 12.570201ms)
May 30 23:08:56.350: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 12.309901ms)
May 30 23:08:56.351: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 12.370201ms)
May 30 23:08:56.351: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 13.631501ms)
May 30 23:08:56.351: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 13.794301ms)
May 30 23:08:56.351: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 13.359301ms)
May 30 23:08:56.351: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 13.121701ms)
May 30 23:08:56.351: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 13.073101ms)
May 30 23:08:56.352: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 13.384901ms)
May 30 23:08:56.361: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 9.418701ms)
May 30 23:08:56.362: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 10.482001ms)
May 30 23:08:56.362: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 10.387001ms)
May 30 23:08:56.362: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 10.689201ms)
May 30 23:08:56.362: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 10.290401ms)
May 30 23:08:56.363: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 11.090001ms)
May 30 23:08:56.363: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 10.894401ms)
May 30 23:08:56.363: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 10.579001ms)
May 30 23:08:56.364: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 11.442502ms)
May 30 23:08:56.364: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 11.364602ms)
May 30 23:08:56.364: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 12.481102ms)
May 30 23:08:56.366: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 13.554002ms)
May 30 23:08:56.366: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 13.710202ms)
May 30 23:08:56.366: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 13.514802ms)
May 30 23:08:56.366: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 13.417802ms)
May 30 23:08:56.366: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 13.835202ms)
May 30 23:08:56.377: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 10.870501ms)
May 30 23:08:56.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:443/proxy/... (200; 10.990601ms)
May 30 23:08:56.378: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname2/proxy/: bar (200; 12.448701ms)
May 30 23:08:56.379: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname2/proxy/: tls qux (200; 12.083701ms)
May 30 23:08:56.379: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:462/proxy/: tls qux (200; 12.326301ms)
May 30 23:08:56.379: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 13.002701ms)
May 30 23:08:56.379: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname1/proxy/: foo (200; 12.337601ms)
May 30 23:08:56.380: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/http:proxy-service-s4t5w-w7gjw:1080/proxy/... (200; 13.324701ms)
May 30 23:08:56.380: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:160/proxy/: foo (200; 13.981401ms)
May 30 23:08:56.380: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/https:proxy-service-s4t5w:tlsportname1/proxy/: tls baz (200; 13.808601ms)
May 30 23:08:56.380: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/https:proxy-service-s4t5w-w7gjw:460/proxy/: tls baz (200; 13.706701ms)
May 30 23:08:56.381: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw/proxy/rewriteme"... (200; 14.192001ms)
May 30 23:08:56.381: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/proxy-service-s4t5w:portname1/proxy/: foo (200; 14.520001ms)
May 30 23:08:56.381: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:1080/proxy/rewri... (200; 14.098701ms)
May 30 23:08:56.381: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/pods/proxy-service-s4t5w-w7gjw:162/proxy/: bar (200; 14.212201ms)
May 30 23:08:56.381: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2g2jn/services/http:proxy-service-s4t5w:portname2/proxy/: bar (200; 14.326701ms)
STEP: deleting { ReplicationController} proxy-service-s4t5w in namespace e2e-tests-proxy-2g2jn, will wait for the garbage collector to delete the pods
May 30 23:08:56.438: INFO: Deleting { ReplicationController} proxy-service-s4t5w took: 4.4899ms
May 30 23:08:56.538: INFO: Terminating { ReplicationController} proxy-service-s4t5w pods took: 100.152911ms
[AfterEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:09:04.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-2g2jn" for this suite.
May 30 23:09:10.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:09:10.247: INFO: namespace: e2e-tests-proxy-2g2jn, resource: bindings, ignored listing per whitelist
May 30 23:09:10.270: INFO: namespace e2e-tests-proxy-2g2jn deletion completed in 6.12815438s

• [SLOW TEST:28.389 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:09:10.270: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 23:09:10.352: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eebb0b6b-832f-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-downward-api-xjb8w" to be "success or failure"
May 30 23:09:10.356: INFO: Pod "downwardapi-volume-eebb0b6b-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.5383ms
May 30 23:09:12.359: INFO: Pod "downwardapi-volume-eebb0b6b-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007631526s
May 30 23:09:14.362: INFO: Pod "downwardapi-volume-eebb0b6b-832f-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010796454s
STEP: Saw pod success
May 30 23:09:14.362: INFO: Pod "downwardapi-volume-eebb0b6b-832f-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:09:14.365: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod downwardapi-volume-eebb0b6b-832f-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 23:09:14.379: INFO: Waiting for pod downwardapi-volume-eebb0b6b-832f-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:09:14.383: INFO: Pod downwardapi-volume-eebb0b6b-832f-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:09:14.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xjb8w" for this suite.
May 30 23:09:20.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:09:20.437: INFO: namespace: e2e-tests-downward-api-xjb8w, resource: bindings, ignored listing per whitelist
May 30 23:09:20.470: INFO: namespace e2e-tests-downward-api-xjb8w deletion completed in 6.082604005s

• [SLOW TEST:10.201 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:09:20.473: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 23:09:20.553: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f4cfd179-832f-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-downward-api-txhft" to be "success or failure"
May 30 23:09:20.567: INFO: Pod "downwardapi-volume-f4cfd179-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 14.009401ms
May 30 23:09:22.570: INFO: Pod "downwardapi-volume-f4cfd179-832f-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017006237s
May 30 23:09:24.573: INFO: Pod "downwardapi-volume-f4cfd179-832f-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019870475s
STEP: Saw pod success
May 30 23:09:24.573: INFO: Pod "downwardapi-volume-f4cfd179-832f-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:09:24.575: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod downwardapi-volume-f4cfd179-832f-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 23:09:24.593: INFO: Waiting for pod downwardapi-volume-f4cfd179-832f-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:09:24.595: INFO: Pod downwardapi-volume-f4cfd179-832f-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:09:24.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-txhft" for this suite.
May 30 23:09:30.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:09:30.626: INFO: namespace: e2e-tests-downward-api-txhft, resource: bindings, ignored listing per whitelist
May 30 23:09:30.684: INFO: namespace e2e-tests-downward-api-txhft deletion completed in 6.086233634s

• [SLOW TEST:10.212 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:09:30.687: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 30 23:09:30.790: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"fae9483c-832f-11e9-9b52-001dd80c000f", Controller:(*bool)(0xc420cc69f6), BlockOwnerDeletion:(*bool)(0xc420cc69f7)}}
May 30 23:09:30.799: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"fae7aacc-832f-11e9-9b52-001dd80c000f", Controller:(*bool)(0xc4218f4ede), BlockOwnerDeletion:(*bool)(0xc4218f4edf)}}
May 30 23:09:30.809: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"fae82334-832f-11e9-9b52-001dd80c000f", Controller:(*bool)(0xc4218f5486), BlockOwnerDeletion:(*bool)(0xc4218f5487)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:09:35.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9hh9l" for this suite.
May 30 23:09:41.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:09:41.853: INFO: namespace: e2e-tests-gc-9hh9l, resource: bindings, ignored listing per whitelist
May 30 23:09:41.916: INFO: namespace e2e-tests-gc-9hh9l deletion completed in 6.096711366s

• [SLOW TEST:11.229 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:09:41.917: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 30 23:09:41.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 version'
May 30 23:09:42.105: INFO: stderr: ""
May 30 23:09:42.105: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.3\", GitCommit:\"a4529464e4629c21224b3d52edfe0ea91b072862\", GitTreeState:\"clean\", BuildDate:\"2018-09-09T18:02:47Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.10\", GitCommit:\"09efea25364a96ffe47916970a7d88e0f08fceaa\", GitTreeState:\"clean\", BuildDate:\"2019-05-06T21:50:59Z\", GoVersion:\"go1.10.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:09:42.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s94pg" for this suite.
May 30 23:09:48.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:09:48.133: INFO: namespace: e2e-tests-kubectl-s94pg, resource: bindings, ignored listing per whitelist
May 30 23:09:48.193: INFO: namespace e2e-tests-kubectl-s94pg deletion completed in 6.083342782s

• [SLOW TEST:6.277 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:09:48.194: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: validating cluster-info
May 30 23:09:48.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 cluster-info'
May 30 23:09:48.380: INFO: stderr: ""
May 30 23:09:48.380: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\x1b[0;32mtiller-deploy\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443/api/v1/namespaces/kube-system/services/tiller-deploy:tiller/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:09:48.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v8l79" for this suite.
May 30 23:09:54.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:09:54.478: INFO: namespace: e2e-tests-kubectl-v8l79, resource: bindings, ignored listing per whitelist
May 30 23:09:54.484: INFO: namespace e2e-tests-kubectl-v8l79 deletion completed in 6.099610201s

• [SLOW TEST:6.290 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:09:54.484: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-m4tsk
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 30 23:09:54.567: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 30 23:10:18.640: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.79:8080/dial?request=hostName&protocol=http&host=10.244.0.23&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-m4tsk PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 23:10:18.640: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 23:10:18.783: INFO: Waiting for endpoints: map[]
May 30 23:10:18.785: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.79:8080/dial?request=hostName&protocol=http&host=10.244.3.76&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-m4tsk PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 23:10:18.785: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 23:10:18.929: INFO: Waiting for endpoints: map[]
May 30 23:10:18.931: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.79:8080/dial?request=hostName&protocol=http&host=10.244.1.78&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-m4tsk PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 23:10:18.931: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
May 30 23:10:19.089: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:10:19.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-m4tsk" for this suite.
May 30 23:10:41.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:10:41.117: INFO: namespace: e2e-tests-pod-network-test-m4tsk, resource: bindings, ignored listing per whitelist
May 30 23:10:41.185: INFO: namespace e2e-tests-pod-network-test-m4tsk deletion completed in 22.092201562s

• [SLOW TEST:46.700 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:10:41.185: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 23:10:41.265: INFO: Waiting up to 5m0s for pod "downwardapi-volume-24eb84d6-8330-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-c7rnd" to be "success or failure"
May 30 23:10:41.269: INFO: Pod "downwardapi-volume-24eb84d6-8330-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.768101ms
May 30 23:10:43.271: INFO: Pod "downwardapi-volume-24eb84d6-8330-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006241106s
May 30 23:10:45.275: INFO: Pod "downwardapi-volume-24eb84d6-8330-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010199413s
STEP: Saw pod success
May 30 23:10:45.275: INFO: Pod "downwardapi-volume-24eb84d6-8330-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:10:45.277: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod downwardapi-volume-24eb84d6-8330-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 23:10:45.290: INFO: Waiting for pod downwardapi-volume-24eb84d6-8330-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:10:45.293: INFO: Pod downwardapi-volume-24eb84d6-8330-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:10:45.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c7rnd" for this suite.
May 30 23:10:51.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:10:51.373: INFO: namespace: e2e-tests-projected-c7rnd, resource: bindings, ignored listing per whitelist
May 30 23:10:51.398: INFO: namespace e2e-tests-projected-c7rnd deletion completed in 6.100448245s

• [SLOW TEST:10.213 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:10:51.398: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 23:10:51.480: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b024ebf-8330-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-downward-api-ddzzw" to be "success or failure"
May 30 23:10:51.490: INFO: Pod "downwardapi-volume-2b024ebf-8330-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 9.236402ms
May 30 23:10:53.493: INFO: Pod "downwardapi-volume-2b024ebf-8330-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012250615s
May 30 23:10:55.495: INFO: Pod "downwardapi-volume-2b024ebf-8330-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014989631s
STEP: Saw pod success
May 30 23:10:55.495: INFO: Pod "downwardapi-volume-2b024ebf-8330-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:10:55.498: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod downwardapi-volume-2b024ebf-8330-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 23:10:55.513: INFO: Waiting for pod downwardapi-volume-2b024ebf-8330-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:10:55.517: INFO: Pod downwardapi-volume-2b024ebf-8330-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:10:55.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ddzzw" for this suite.
May 30 23:11:01.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:11:01.681: INFO: namespace: e2e-tests-downward-api-ddzzw, resource: bindings, ignored listing per whitelist
May 30 23:11:01.704: INFO: namespace e2e-tests-downward-api-ddzzw deletion completed in 6.183608283s

• [SLOW TEST:10.306 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:11:01.705: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1053
STEP: creating an rc
May 30 23:11:01.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-hg7rn'
May 30 23:11:02.063: INFO: stderr: ""
May 30 23:11:02.063: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Waiting for Redis master to start.
May 30 23:11:03.066: INFO: Selector matched 1 pods for map[app:redis]
May 30 23:11:03.066: INFO: Found 0 / 1
May 30 23:11:04.066: INFO: Selector matched 1 pods for map[app:redis]
May 30 23:11:04.066: INFO: Found 0 / 1
May 30 23:11:05.069: INFO: Selector matched 1 pods for map[app:redis]
May 30 23:11:05.069: INFO: Found 1 / 1
May 30 23:11:05.069: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 30 23:11:05.072: INFO: Selector matched 1 pods for map[app:redis]
May 30 23:11:05.072: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May 30 23:11:05.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 logs redis-master-j4wmb redis-master --namespace=e2e-tests-kubectl-hg7rn'
May 30 23:11:05.196: INFO: stderr: ""
May 30 23:11:05.196: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 May 23:11:03.963 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 May 23:11:03.963 # Server started, Redis version 3.2.12\n1:M 30 May 23:11:03.963 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 May 23:11:03.963 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May 30 23:11:05.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 log redis-master-j4wmb redis-master --namespace=e2e-tests-kubectl-hg7rn --tail=1'
May 30 23:11:05.336: INFO: stderr: ""
May 30 23:11:05.336: INFO: stdout: "1:M 30 May 23:11:03.963 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May 30 23:11:05.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 log redis-master-j4wmb redis-master --namespace=e2e-tests-kubectl-hg7rn --limit-bytes=1'
May 30 23:11:05.458: INFO: stderr: ""
May 30 23:11:05.458: INFO: stdout: " "
STEP: exposing timestamps
May 30 23:11:05.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 log redis-master-j4wmb redis-master --namespace=e2e-tests-kubectl-hg7rn --tail=1 --timestamps'
May 30 23:11:05.586: INFO: stderr: ""
May 30 23:11:05.586: INFO: stdout: "2019-05-30T23:11:03.963857571Z 1:M 30 May 23:11:03.963 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May 30 23:11:08.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 log redis-master-j4wmb redis-master --namespace=e2e-tests-kubectl-hg7rn --since=1s'
May 30 23:11:08.216: INFO: stderr: ""
May 30 23:11:08.216: INFO: stdout: ""
May 30 23:11:08.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 log redis-master-j4wmb redis-master --namespace=e2e-tests-kubectl-hg7rn --since=24h'
May 30 23:11:08.346: INFO: stderr: ""
May 30 23:11:08.346: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 30 May 23:11:03.963 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 30 May 23:11:03.963 # Server started, Redis version 3.2.12\n1:M 30 May 23:11:03.963 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 30 May 23:11:03.963 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1058
STEP: using delete to clean up resources
May 30 23:11:08.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hg7rn'
May 30 23:11:08.455: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 30 23:11:08.455: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 30 23:11:08.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-hg7rn'
May 30 23:11:08.601: INFO: stderr: "No resources found.\n"
May 30 23:11:08.601: INFO: stdout: ""
May 30 23:11:08.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -l name=nginx --namespace=e2e-tests-kubectl-hg7rn -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 30 23:11:08.730: INFO: stderr: ""
May 30 23:11:08.731: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:11:08.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hg7rn" for this suite.
May 30 23:11:14.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:11:14.803: INFO: namespace: e2e-tests-kubectl-hg7rn, resource: bindings, ignored listing per whitelist
May 30 23:11:14.830: INFO: namespace e2e-tests-kubectl-hg7rn deletion completed in 6.094322499s

• [SLOW TEST:13.125 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:11:14.831: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-4j6rp
May 30 23:11:18.916: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-4j6rp
STEP: checking the pod's current state and verifying that restartCount is present
May 30 23:11:18.918: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:15:19.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4j6rp" for this suite.
May 30 23:15:25.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:15:25.378: INFO: namespace: e2e-tests-container-probe-4j6rp, resource: bindings, ignored listing per whitelist
May 30 23:15:25.450: INFO: namespace e2e-tests-container-probe-4j6rp deletion completed in 6.106861556s

• [SLOW TEST:250.619 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:15:25.450: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a replication controller
May 30 23:15:25.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:25.743: INFO: stderr: ""
May 30 23:15:25.743: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 30 23:15:25.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:25.861: INFO: stderr: ""
May 30 23:15:25.861: INFO: stdout: "update-demo-nautilus-5jglg update-demo-nautilus-j9lq8 "
May 30 23:15:25.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-5jglg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:25.991: INFO: stderr: ""
May 30 23:15:25.992: INFO: stdout: ""
May 30 23:15:25.992: INFO: update-demo-nautilus-5jglg is created but not running
May 30 23:15:30.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:31.117: INFO: stderr: ""
May 30 23:15:31.117: INFO: stdout: "update-demo-nautilus-5jglg update-demo-nautilus-j9lq8 "
May 30 23:15:31.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-5jglg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:31.228: INFO: stderr: ""
May 30 23:15:31.229: INFO: stdout: "true"
May 30 23:15:31.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-5jglg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:31.345: INFO: stderr: ""
May 30 23:15:31.345: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 30 23:15:31.345: INFO: validating pod update-demo-nautilus-5jglg
May 30 23:15:31.349: INFO: got data: {
  "image": "nautilus.jpg"
}

May 30 23:15:31.349: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 30 23:15:31.349: INFO: update-demo-nautilus-5jglg is verified up and running
May 30 23:15:31.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-j9lq8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:31.466: INFO: stderr: ""
May 30 23:15:31.466: INFO: stdout: "true"
May 30 23:15:31.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-j9lq8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:31.582: INFO: stderr: ""
May 30 23:15:31.582: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 30 23:15:31.582: INFO: validating pod update-demo-nautilus-j9lq8
May 30 23:15:31.587: INFO: got data: {
  "image": "nautilus.jpg"
}

May 30 23:15:31.587: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 30 23:15:31.587: INFO: update-demo-nautilus-j9lq8 is verified up and running
STEP: scaling down the replication controller
May 30 23:15:31.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:32.738: INFO: stderr: ""
May 30 23:15:32.738: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 30 23:15:32.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:32.863: INFO: stderr: ""
May 30 23:15:32.863: INFO: stdout: "update-demo-nautilus-5jglg update-demo-nautilus-j9lq8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 30 23:15:37.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:37.983: INFO: stderr: ""
May 30 23:15:37.983: INFO: stdout: "update-demo-nautilus-5jglg update-demo-nautilus-j9lq8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 30 23:15:42.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:43.102: INFO: stderr: ""
May 30 23:15:43.102: INFO: stdout: "update-demo-nautilus-5jglg update-demo-nautilus-j9lq8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 30 23:15:48.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:48.216: INFO: stderr: ""
May 30 23:15:48.216: INFO: stdout: "update-demo-nautilus-5jglg "
May 30 23:15:48.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-5jglg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:48.324: INFO: stderr: ""
May 30 23:15:48.325: INFO: stdout: "true"
May 30 23:15:48.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-5jglg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:48.427: INFO: stderr: ""
May 30 23:15:48.427: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 30 23:15:48.427: INFO: validating pod update-demo-nautilus-5jglg
May 30 23:15:48.430: INFO: got data: {
  "image": "nautilus.jpg"
}

May 30 23:15:48.430: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 30 23:15:48.430: INFO: update-demo-nautilus-5jglg is verified up and running
STEP: scaling up the replication controller
May 30 23:15:48.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:49.581: INFO: stderr: ""
May 30 23:15:49.582: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 30 23:15:49.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:49.693: INFO: stderr: ""
May 30 23:15:49.693: INFO: stdout: "update-demo-nautilus-5jglg update-demo-nautilus-zpqxt "
May 30 23:15:49.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-5jglg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:49.843: INFO: stderr: ""
May 30 23:15:49.843: INFO: stdout: "true"
May 30 23:15:49.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-5jglg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:49.979: INFO: stderr: ""
May 30 23:15:49.979: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 30 23:15:49.979: INFO: validating pod update-demo-nautilus-5jglg
May 30 23:15:49.983: INFO: got data: {
  "image": "nautilus.jpg"
}

May 30 23:15:49.983: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 30 23:15:49.983: INFO: update-demo-nautilus-5jglg is verified up and running
May 30 23:15:49.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-zpqxt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:50.106: INFO: stderr: ""
May 30 23:15:50.106: INFO: stdout: ""
May 30 23:15:50.106: INFO: update-demo-nautilus-zpqxt is created but not running
May 30 23:15:55.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:55.236: INFO: stderr: ""
May 30 23:15:55.236: INFO: stdout: "update-demo-nautilus-5jglg update-demo-nautilus-zpqxt "
May 30 23:15:55.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-5jglg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:55.363: INFO: stderr: ""
May 30 23:15:55.364: INFO: stdout: "true"
May 30 23:15:55.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-5jglg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:55.483: INFO: stderr: ""
May 30 23:15:55.483: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 30 23:15:55.483: INFO: validating pod update-demo-nautilus-5jglg
May 30 23:15:55.486: INFO: got data: {
  "image": "nautilus.jpg"
}

May 30 23:15:55.486: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 30 23:15:55.486: INFO: update-demo-nautilus-5jglg is verified up and running
May 30 23:15:55.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-zpqxt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:55.599: INFO: stderr: ""
May 30 23:15:55.599: INFO: stdout: "true"
May 30 23:15:55.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-zpqxt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:55.711: INFO: stderr: ""
May 30 23:15:55.711: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 30 23:15:55.711: INFO: validating pod update-demo-nautilus-zpqxt
May 30 23:15:55.714: INFO: got data: {
  "image": "nautilus.jpg"
}

May 30 23:15:55.715: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 30 23:15:55.715: INFO: update-demo-nautilus-zpqxt is verified up and running
STEP: using delete to clean up resources
May 30 23:15:55.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:55.830: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 30 23:15:55.830: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 30 23:15:55.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-6pfgk'
May 30 23:15:55.977: INFO: stderr: "No resources found.\n"
May 30 23:15:55.977: INFO: stdout: ""
May 30 23:15:55.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -l name=update-demo --namespace=e2e-tests-kubectl-6pfgk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 30 23:15:56.103: INFO: stderr: ""
May 30 23:15:56.103: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:15:56.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6pfgk" for this suite.
May 30 23:16:18.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:16:18.165: INFO: namespace: e2e-tests-kubectl-6pfgk, resource: bindings, ignored listing per whitelist
May 30 23:16:18.200: INFO: namespace e2e-tests-kubectl-6pfgk deletion completed in 22.093016784s

• [SLOW TEST:52.750 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:16:18.200: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
May 30 23:16:18.333: INFO: Waiting up to 1m0s for all nodes to be ready
May 30 23:17:18.360: INFO: Waiting for terminating namespaces to be deleted...
May 30 23:17:18.364: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 30 23:17:18.376: INFO: 21 / 21 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 30 23:17:18.376: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
May 30 23:17:18.383: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 30 23:17:18.383: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-35502656-0 before test
May 30 23:17:18.389: INFO: kube-proxy-z8rb2 from kube-system started at 2019-05-30 22:22:06 +0000 UTC (1 container statuses recorded)
May 30 23:17:18.389: INFO: 	Container kube-proxy ready: true, restart count 0
May 30 23:17:18.389: INFO: sonobuoy-e2e-job-3baf2c430e984a69 from heptio-sonobuoy started at 2019-05-30 22:23:55 +0000 UTC (2 container statuses recorded)
May 30 23:17:18.389: INFO: 	Container e2e ready: true, restart count 0
May 30 23:17:18.389: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 30 23:17:18.389: INFO: sonobuoy-systemd-logs-daemon-set-261c7e37e22c4229-8qlhf from heptio-sonobuoy started at 2019-05-30 22:23:55 +0000 UTC (2 container statuses recorded)
May 30 23:17:18.389: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
May 30 23:17:18.389: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 30 23:17:18.389: INFO: kube-flannel-ds-9zr2x from kube-system started at 2019-05-30 22:22:00 +0000 UTC (2 container statuses recorded)
May 30 23:17:18.390: INFO: 	Container install-cni ready: true, restart count 0
May 30 23:17:18.390: INFO: 	Container kube-flannel ready: true, restart count 1
May 30 23:17:18.390: INFO: azure-ip-masq-agent-smv6c from kube-system started at 2019-05-30 22:22:04 +0000 UTC (1 container statuses recorded)
May 30 23:17:18.390: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 30 23:17:18.390: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-35502656-1 before test
May 30 23:17:18.396: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-30 22:23:50 +0000 UTC (1 container statuses recorded)
May 30 23:17:18.396: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 30 23:17:18.396: INFO: kube-flannel-ds-4vsxq from kube-system started at 2019-05-30 22:22:00 +0000 UTC (2 container statuses recorded)
May 30 23:17:18.396: INFO: 	Container install-cni ready: true, restart count 0
May 30 23:17:18.396: INFO: 	Container kube-flannel ready: true, restart count 1
May 30 23:17:18.396: INFO: azure-ip-masq-agent-kjjv4 from kube-system started at 2019-05-30 22:22:04 +0000 UTC (1 container statuses recorded)
May 30 23:17:18.396: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 30 23:17:18.396: INFO: kube-proxy-htm6x from kube-system started at 2019-05-30 22:22:06 +0000 UTC (1 container statuses recorded)
May 30 23:17:18.396: INFO: 	Container kube-proxy ready: true, restart count 0
May 30 23:17:18.396: INFO: sonobuoy-systemd-logs-daemon-set-261c7e37e22c4229-x5q4v from heptio-sonobuoy started at 2019-05-30 22:23:56 +0000 UTC (2 container statuses recorded)
May 30 23:17:18.396: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
May 30 23:17:18.396: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 30 23:17:18.396: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-35502656-2 before test
May 30 23:17:18.403: INFO: heapster-656495f65d-qxhm2 from kube-system started at 2019-05-30 22:22:19 +0000 UTC (2 container statuses recorded)
May 30 23:17:18.403: INFO: 	Container heapster ready: true, restart count 0
May 30 23:17:18.403: INFO: 	Container heapster-nanny ready: true, restart count 0
May 30 23:17:18.403: INFO: sonobuoy-systemd-logs-daemon-set-261c7e37e22c4229-nrn2p from heptio-sonobuoy started at 2019-05-30 22:23:55 +0000 UTC (2 container statuses recorded)
May 30 23:17:18.403: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
May 30 23:17:18.403: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 30 23:17:18.403: INFO: kube-flannel-ds-sqz6f from kube-system started at 2019-05-30 22:22:00 +0000 UTC (2 container statuses recorded)
May 30 23:17:18.403: INFO: 	Container install-cni ready: true, restart count 0
May 30 23:17:18.403: INFO: 	Container kube-flannel ready: true, restart count 0
May 30 23:17:18.403: INFO: azure-ip-masq-agent-fsw9b from kube-system started at 2019-05-30 22:22:04 +0000 UTC (1 container statuses recorded)
May 30 23:17:18.403: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 30 23:17:18.403: INFO: kube-dns-5f74bfc48d-wm2n9 from kube-system started at 2019-05-30 22:22:19 +0000 UTC (3 container statuses recorded)
May 30 23:17:18.403: INFO: 	Container dnsmasq ready: true, restart count 0
May 30 23:17:18.403: INFO: 	Container kubedns ready: true, restart count 0
May 30 23:17:18.403: INFO: 	Container sidecar ready: true, restart count 0
May 30 23:17:18.403: INFO: kubernetes-dashboard-7b5859758b-pc5gq from kube-system started at 2019-05-30 22:22:19 +0000 UTC (1 container statuses recorded)
May 30 23:17:18.403: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 30 23:17:18.403: INFO: tiller-deploy-88c69b9b-tp65w from kube-system started at 2019-05-30 22:22:19 +0000 UTC (1 container statuses recorded)
May 30 23:17:18.403: INFO: 	Container tiller ready: true, restart count 0
May 30 23:17:18.403: INFO: kube-proxy-wvb9t from kube-system started at 2019-05-30 22:22:06 +0000 UTC (1 container statuses recorded)
May 30 23:17:18.403: INFO: 	Container kube-proxy ready: true, restart count 0
May 30 23:17:18.403: INFO: metrics-server-5fdc668b9b-dg829 from kube-system started at 2019-05-30 22:22:19 +0000 UTC (1 container statuses recorded)
May 30 23:17:18.403: INFO: 	Container metrics-server ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: verifying the node has the label node k8s-linuxpool-35502656-0
STEP: verifying the node has the label node k8s-linuxpool-35502656-1
STEP: verifying the node has the label node k8s-linuxpool-35502656-2
May 30 23:17:18.517: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-linuxpool-35502656-1
May 30 23:17:18.517: INFO: Pod sonobuoy-e2e-job-3baf2c430e984a69 requesting resource cpu=0m on Node k8s-linuxpool-35502656-0
May 30 23:17:18.517: INFO: Pod sonobuoy-systemd-logs-daemon-set-261c7e37e22c4229-8qlhf requesting resource cpu=0m on Node k8s-linuxpool-35502656-0
May 30 23:17:18.517: INFO: Pod sonobuoy-systemd-logs-daemon-set-261c7e37e22c4229-nrn2p requesting resource cpu=0m on Node k8s-linuxpool-35502656-2
May 30 23:17:18.517: INFO: Pod sonobuoy-systemd-logs-daemon-set-261c7e37e22c4229-x5q4v requesting resource cpu=0m on Node k8s-linuxpool-35502656-1
May 30 23:17:18.517: INFO: Pod azure-ip-masq-agent-fsw9b requesting resource cpu=50m on Node k8s-linuxpool-35502656-2
May 30 23:17:18.517: INFO: Pod azure-ip-masq-agent-kjjv4 requesting resource cpu=50m on Node k8s-linuxpool-35502656-1
May 30 23:17:18.517: INFO: Pod azure-ip-masq-agent-smv6c requesting resource cpu=50m on Node k8s-linuxpool-35502656-0
May 30 23:17:18.517: INFO: Pod heapster-656495f65d-qxhm2 requesting resource cpu=176m on Node k8s-linuxpool-35502656-2
May 30 23:17:18.517: INFO: Pod kube-dns-5f74bfc48d-wm2n9 requesting resource cpu=260m on Node k8s-linuxpool-35502656-2
May 30 23:17:18.517: INFO: Pod kube-flannel-ds-4vsxq requesting resource cpu=0m on Node k8s-linuxpool-35502656-1
May 30 23:17:18.517: INFO: Pod kube-flannel-ds-9zr2x requesting resource cpu=0m on Node k8s-linuxpool-35502656-0
May 30 23:17:18.517: INFO: Pod kube-flannel-ds-sqz6f requesting resource cpu=0m on Node k8s-linuxpool-35502656-2
May 30 23:17:18.517: INFO: Pod kube-proxy-htm6x requesting resource cpu=100m on Node k8s-linuxpool-35502656-1
May 30 23:17:18.517: INFO: Pod kube-proxy-wvb9t requesting resource cpu=100m on Node k8s-linuxpool-35502656-2
May 30 23:17:18.517: INFO: Pod kube-proxy-z8rb2 requesting resource cpu=100m on Node k8s-linuxpool-35502656-0
May 30 23:17:18.517: INFO: Pod kubernetes-dashboard-7b5859758b-pc5gq requesting resource cpu=300m on Node k8s-linuxpool-35502656-2
May 30 23:17:18.517: INFO: Pod metrics-server-5fdc668b9b-dg829 requesting resource cpu=0m on Node k8s-linuxpool-35502656-2
May 30 23:17:18.517: INFO: Pod tiller-deploy-88c69b9b-tp65w requesting resource cpu=50m on Node k8s-linuxpool-35502656-2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-11b44dd8-8331-11e9-a3e0-52e03c2e65ea.15a3991b4dca8b53], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-vhvv6/filler-pod-11b44dd8-8331-11e9-a3e0-52e03c2e65ea to k8s-linuxpool-35502656-0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-11b44dd8-8331-11e9-a3e0-52e03c2e65ea.15a3991ba2fb269b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-11b44dd8-8331-11e9-a3e0-52e03c2e65ea.15a3991bbc040e55], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-11b44dd8-8331-11e9-a3e0-52e03c2e65ea.15a3991bca108773], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-11b6bd92-8331-11e9-a3e0-52e03c2e65ea.15a3991b4e6d6eb1], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-vhvv6/filler-pod-11b6bd92-8331-11e9-a3e0-52e03c2e65ea to k8s-linuxpool-35502656-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-11b6bd92-8331-11e9-a3e0-52e03c2e65ea.15a3991ba794fe54], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-11b6bd92-8331-11e9-a3e0-52e03c2e65ea.15a3991bc41c7172], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-11b6bd92-8331-11e9-a3e0-52e03c2e65ea.15a3991bdc5c83f5], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-11b6bd92-8331-11e9-a3e0-52e03c2e65ea.15a3991be888b8a4], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-11b818ad-8331-11e9-a3e0-52e03c2e65ea.15a3991b4f88d269], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-vhvv6/filler-pod-11b818ad-8331-11e9-a3e0-52e03c2e65ea to k8s-linuxpool-35502656-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-11b818ad-8331-11e9-a3e0-52e03c2e65ea.15a3991ba8a839be], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-11b818ad-8331-11e9-a3e0-52e03c2e65ea.15a3991bbbb89561], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-11b818ad-8331-11e9-a3e0-52e03c2e65ea.15a3991bca96ebf1], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15a3991c3f3f5292], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 3 Insufficient cpu.]
STEP: removing the label node off the node k8s-linuxpool-35502656-0
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-linuxpool-35502656-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-linuxpool-35502656-2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:17:23.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-vhvv6" for this suite.
May 30 23:17:29.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:17:29.725: INFO: namespace: e2e-tests-sched-pred-vhvv6, resource: bindings, ignored listing per whitelist
May 30 23:17:29.748: INFO: namespace e2e-tests-sched-pred-vhvv6 deletion completed in 6.086320705s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

• [SLOW TEST:71.548 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:17:29.751: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-887wm
I0530 23:17:29.830479      16 runners.go:177] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-887wm, replica count: 1
I0530 23:17:30.880945      16 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0530 23:17:31.881171      16 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0530 23:17:32.881401      16 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 30 23:17:32.991: INFO: Created: latency-svc-4m2mt
May 30 23:17:33.006: INFO: Got endpoints: latency-svc-4m2mt [24.993507ms]
May 30 23:17:33.025: INFO: Created: latency-svc-smbbp
May 30 23:17:33.031: INFO: Got endpoints: latency-svc-smbbp [24.668206ms]
May 30 23:17:33.039: INFO: Created: latency-svc-t8224
May 30 23:17:33.039: INFO: Got endpoints: latency-svc-t8224 [32.152308ms]
May 30 23:17:33.044: INFO: Created: latency-svc-wxkcp
May 30 23:17:33.054: INFO: Got endpoints: latency-svc-wxkcp [47.655213ms]
May 30 23:17:33.054: INFO: Created: latency-svc-q556p
May 30 23:17:33.058: INFO: Created: latency-svc-w9d6h
May 30 23:17:33.073: INFO: Got endpoints: latency-svc-w9d6h [65.779517ms]
May 30 23:17:33.073: INFO: Got endpoints: latency-svc-q556p [65.605918ms]
May 30 23:17:33.073: INFO: Created: latency-svc-9bp42
May 30 23:17:33.081: INFO: Got endpoints: latency-svc-9bp42 [73.89952ms]
May 30 23:17:33.084: INFO: Created: latency-svc-svq29
May 30 23:17:33.092: INFO: Got endpoints: latency-svc-svq29 [84.514622ms]
May 30 23:17:33.092: INFO: Created: latency-svc-n2ls2
May 30 23:17:33.152: INFO: Got endpoints: latency-svc-n2ls2 [144.304138ms]
May 30 23:17:33.156: INFO: Created: latency-svc-52xmp
May 30 23:17:33.167: INFO: Created: latency-svc-x2ns8
May 30 23:17:33.171: INFO: Got endpoints: latency-svc-52xmp [163.006444ms]
May 30 23:17:33.172: INFO: Created: latency-svc-2qnlx
May 30 23:17:33.177: INFO: Got endpoints: latency-svc-x2ns8 [169.491645ms]
May 30 23:17:33.182: INFO: Created: latency-svc-9nztz
May 30 23:17:33.185: INFO: Got endpoints: latency-svc-2qnlx [177.084547ms]
May 30 23:17:33.207: INFO: Created: latency-svc-6h59x
May 30 23:17:33.213: INFO: Created: latency-svc-w7gzl
May 30 23:17:33.216: INFO: Got endpoints: latency-svc-9nztz [208.398555ms]
May 30 23:17:33.221: INFO: Got endpoints: latency-svc-w7gzl [213.347057ms]
May 30 23:17:33.225: INFO: Got endpoints: latency-svc-6h59x [217.399758ms]
May 30 23:17:33.249: INFO: Created: latency-svc-pj86c
May 30 23:17:33.269: INFO: Got endpoints: latency-svc-pj86c [261.42357ms]
May 30 23:17:33.276: INFO: Created: latency-svc-tvjnx
May 30 23:17:33.287: INFO: Got endpoints: latency-svc-tvjnx [256.253368ms]
May 30 23:17:33.288: INFO: Created: latency-svc-9np7r
May 30 23:17:33.291: INFO: Created: latency-svc-g9pqg
May 30 23:17:33.301: INFO: Got endpoints: latency-svc-g9pqg [246.995865ms]
May 30 23:17:33.301: INFO: Got endpoints: latency-svc-9np7r [262.80847ms]
May 30 23:17:33.305: INFO: Created: latency-svc-7cwwj
May 30 23:17:33.311: INFO: Created: latency-svc-ct96j
May 30 23:17:33.320: INFO: Got endpoints: latency-svc-ct96j [247.313865ms]
May 30 23:17:33.321: INFO: Got endpoints: latency-svc-7cwwj [248.330866ms]
May 30 23:17:33.342: INFO: Created: latency-svc-nbbzv
May 30 23:17:33.342: INFO: Got endpoints: latency-svc-nbbzv [261.447169ms]
May 30 23:17:33.343: INFO: Created: latency-svc-8clfz
May 30 23:17:33.343: INFO: Created: latency-svc-9l5wj
May 30 23:17:33.352: INFO: Created: latency-svc-q8jpv
May 30 23:17:33.354: INFO: Got endpoints: latency-svc-9l5wj [262.786269ms]
May 30 23:17:33.356: INFO: Got endpoints: latency-svc-8clfz [204.261255ms]
May 30 23:17:33.357: INFO: Created: latency-svc-ptmrk
May 30 23:17:33.364: INFO: Created: latency-svc-l9bwm
May 30 23:17:33.433: INFO: Created: latency-svc-5rq5k
May 30 23:17:33.434: INFO: Got endpoints: latency-svc-l9bwm [249.159566ms]
May 30 23:17:33.434: INFO: Got endpoints: latency-svc-q8jpv [263.256769ms]
May 30 23:17:33.435: INFO: Got endpoints: latency-svc-ptmrk [257.602868ms]
May 30 23:17:33.454: INFO: Created: latency-svc-xt2lv
May 30 23:17:33.455: INFO: Got endpoints: latency-svc-5rq5k [238.762664ms]
May 30 23:17:33.461: INFO: Created: latency-svc-bnbpg
May 30 23:17:33.463: INFO: Got endpoints: latency-svc-xt2lv [241.783764ms]
May 30 23:17:33.471: INFO: Got endpoints: latency-svc-bnbpg [245.153465ms]
May 30 23:17:33.471: INFO: Created: latency-svc-92zb5
May 30 23:17:33.475: INFO: Got endpoints: latency-svc-92zb5 [205.766154ms]
May 30 23:17:33.481: INFO: Created: latency-svc-tr7tq
May 30 23:17:33.481: INFO: Got endpoints: latency-svc-tr7tq [193.286952ms]
May 30 23:17:33.485: INFO: Created: latency-svc-49jw9
May 30 23:17:33.490: INFO: Got endpoints: latency-svc-49jw9 [189.15715ms]
May 30 23:17:33.495: INFO: Created: latency-svc-zp9p5
May 30 23:17:33.503: INFO: Created: latency-svc-grql8
May 30 23:17:33.509: INFO: Got endpoints: latency-svc-zp9p5 [207.419455ms]
May 30 23:17:33.515: INFO: Got endpoints: latency-svc-grql8 [194.627452ms]
May 30 23:17:33.521: INFO: Created: latency-svc-26bng
May 30 23:17:33.525: INFO: Created: latency-svc-m2vpw
May 30 23:17:33.531: INFO: Created: latency-svc-qkmjw
May 30 23:17:33.533: INFO: Got endpoints: latency-svc-26bng [212.231357ms]
May 30 23:17:33.539: INFO: Got endpoints: latency-svc-m2vpw [196.216452ms]
May 30 23:17:33.551: INFO: Created: latency-svc-587s6
May 30 23:17:33.554: INFO: Got endpoints: latency-svc-qkmjw [198.956753ms]
May 30 23:17:33.566: INFO: Created: latency-svc-6lfhf
May 30 23:17:33.569: INFO: Got endpoints: latency-svc-587s6 [212.717856ms]
May 30 23:17:33.579: INFO: Created: latency-svc-9ddjw
May 30 23:17:33.580: INFO: Got endpoints: latency-svc-6lfhf [145.783539ms]
May 30 23:17:33.582: INFO: Created: latency-svc-2v4cf
May 30 23:17:33.586: INFO: Got endpoints: latency-svc-9ddjw [151.786841ms]
May 30 23:17:33.591: INFO: Created: latency-svc-58nnr
May 30 23:17:33.615: INFO: Got endpoints: latency-svc-2v4cf [180.083847ms]
May 30 23:17:33.615: INFO: Created: latency-svc-f4dc8
May 30 23:17:33.621: INFO: Created: latency-svc-26vwq
May 30 23:17:33.628: INFO: Created: latency-svc-bm8fq
May 30 23:17:33.636: INFO: Created: latency-svc-z52p9
May 30 23:17:33.662: INFO: Got endpoints: latency-svc-58nnr [207.525655ms]
May 30 23:17:33.667: INFO: Created: latency-svc-45mcz
May 30 23:17:33.673: INFO: Created: latency-svc-wf49j
May 30 23:17:33.679: INFO: Created: latency-svc-4pggc
May 30 23:17:33.686: INFO: Created: latency-svc-s9xgm
May 30 23:17:33.697: INFO: Created: latency-svc-bwsz5
May 30 23:17:33.702: INFO: Created: latency-svc-9mntd
May 30 23:17:33.707: INFO: Created: latency-svc-tm2hw
May 30 23:17:33.710: INFO: Got endpoints: latency-svc-f4dc8 [247.110966ms]
May 30 23:17:33.725: INFO: Created: latency-svc-bdw55
May 30 23:17:33.725: INFO: Created: latency-svc-b6swp
May 30 23:17:33.728: INFO: Created: latency-svc-b4dpg
May 30 23:17:33.736: INFO: Created: latency-svc-7vfnc
May 30 23:17:33.747: INFO: Got endpoints: latency-svc-26vwq [276.059873ms]
May 30 23:17:33.750: INFO: Created: latency-svc-hql7h
May 30 23:17:33.758: INFO: Created: latency-svc-lgrbs
May 30 23:17:33.794: INFO: Got endpoints: latency-svc-bm8fq [318.299785ms]
May 30 23:17:33.804: INFO: Created: latency-svc-tlf7s
May 30 23:17:33.848: INFO: Got endpoints: latency-svc-z52p9 [366.976097ms]
May 30 23:17:33.873: INFO: Created: latency-svc-qkzrj
May 30 23:17:33.896: INFO: Got endpoints: latency-svc-45mcz [405.085008ms]
May 30 23:17:33.909: INFO: Created: latency-svc-d7g49
May 30 23:17:33.946: INFO: Got endpoints: latency-svc-wf49j [437.083516ms]
May 30 23:17:33.961: INFO: Created: latency-svc-r646b
May 30 23:17:33.996: INFO: Got endpoints: latency-svc-4pggc [480.912227ms]
May 30 23:17:34.010: INFO: Created: latency-svc-zzd7x
May 30 23:17:34.048: INFO: Got endpoints: latency-svc-s9xgm [514.850236ms]
May 30 23:17:34.060: INFO: Created: latency-svc-mngdr
May 30 23:17:34.097: INFO: Got endpoints: latency-svc-bwsz5 [557.947448ms]
May 30 23:17:34.108: INFO: Created: latency-svc-cr9cp
May 30 23:17:34.150: INFO: Got endpoints: latency-svc-9mntd [595.928858ms]
May 30 23:17:34.166: INFO: Created: latency-svc-68fjn
May 30 23:17:34.195: INFO: Got endpoints: latency-svc-tm2hw [625.647666ms]
May 30 23:17:34.206: INFO: Created: latency-svc-vshwf
May 30 23:17:34.309: INFO: Got endpoints: latency-svc-b6swp [722.202491ms]
May 30 23:17:34.310: INFO: Got endpoints: latency-svc-bdw55 [730.039294ms]
May 30 23:17:34.321: INFO: Created: latency-svc-xbfnf
May 30 23:17:34.330: INFO: Created: latency-svc-l2wdp
May 30 23:17:34.345: INFO: Got endpoints: latency-svc-b4dpg [729.681994ms]
May 30 23:17:34.353: INFO: Created: latency-svc-dhvz2
May 30 23:17:34.396: INFO: Got endpoints: latency-svc-7vfnc [733.716695ms]
May 30 23:17:34.413: INFO: Created: latency-svc-5h2m9
May 30 23:17:34.444: INFO: Got endpoints: latency-svc-hql7h [733.416994ms]
May 30 23:17:34.455: INFO: Created: latency-svc-9pqfl
May 30 23:17:34.493: INFO: Got endpoints: latency-svc-lgrbs [746.625398ms]
May 30 23:17:34.511: INFO: Created: latency-svc-psrl6
May 30 23:17:34.544: INFO: Got endpoints: latency-svc-tlf7s [750.090199ms]
May 30 23:17:34.557: INFO: Created: latency-svc-dr7tw
May 30 23:17:34.597: INFO: Got endpoints: latency-svc-qkzrj [748.530199ms]
May 30 23:17:34.614: INFO: Created: latency-svc-f8szj
May 30 23:17:34.648: INFO: Got endpoints: latency-svc-d7g49 [751.984199ms]
May 30 23:17:34.659: INFO: Created: latency-svc-8p72k
May 30 23:17:34.695: INFO: Got endpoints: latency-svc-r646b [748.661599ms]
May 30 23:17:34.704: INFO: Created: latency-svc-m846k
May 30 23:17:34.745: INFO: Got endpoints: latency-svc-zzd7x [747.884098ms]
May 30 23:17:34.758: INFO: Created: latency-svc-gptmd
May 30 23:17:34.795: INFO: Got endpoints: latency-svc-mngdr [747.089798ms]
May 30 23:17:34.809: INFO: Created: latency-svc-dj7pw
May 30 23:17:34.845: INFO: Got endpoints: latency-svc-cr9cp [748.000099ms]
May 30 23:17:34.880: INFO: Created: latency-svc-z4bvk
May 30 23:17:34.895: INFO: Got endpoints: latency-svc-68fjn [745.321398ms]
May 30 23:17:34.908: INFO: Created: latency-svc-dvgjv
May 30 23:17:34.945: INFO: Got endpoints: latency-svc-vshwf [750.081799ms]
May 30 23:17:34.961: INFO: Created: latency-svc-dn45w
May 30 23:17:34.999: INFO: Got endpoints: latency-svc-xbfnf [690.460583ms]
May 30 23:17:35.016: INFO: Created: latency-svc-hvrsq
May 30 23:17:35.048: INFO: Got endpoints: latency-svc-l2wdp [737.489095ms]
May 30 23:17:35.061: INFO: Created: latency-svc-rnqjd
May 30 23:17:35.129: INFO: Got endpoints: latency-svc-dhvz2 [784.375208ms]
May 30 23:17:35.142: INFO: Created: latency-svc-hvltq
May 30 23:17:35.152: INFO: Got endpoints: latency-svc-5h2m9 [756.1032ms]
May 30 23:17:35.172: INFO: Created: latency-svc-rwptg
May 30 23:17:35.204: INFO: Got endpoints: latency-svc-9pqfl [760.077002ms]
May 30 23:17:35.215: INFO: Created: latency-svc-gm7tz
May 30 23:17:35.248: INFO: Got endpoints: latency-svc-psrl6 [754.4915ms]
May 30 23:17:35.264: INFO: Created: latency-svc-bz2d9
May 30 23:17:35.295: INFO: Got endpoints: latency-svc-dr7tw [750.793099ms]
May 30 23:17:35.306: INFO: Created: latency-svc-r5qxq
May 30 23:17:35.350: INFO: Got endpoints: latency-svc-f8szj [753.4828ms]
May 30 23:17:35.363: INFO: Created: latency-svc-5wwxj
May 30 23:17:35.394: INFO: Got endpoints: latency-svc-8p72k [745.916098ms]
May 30 23:17:35.404: INFO: Created: latency-svc-c7xr7
May 30 23:17:35.448: INFO: Got endpoints: latency-svc-m846k [752.9175ms]
May 30 23:17:35.466: INFO: Created: latency-svc-t6zch
May 30 23:17:35.493: INFO: Got endpoints: latency-svc-gptmd [748.097699ms]
May 30 23:17:35.505: INFO: Created: latency-svc-79rd9
May 30 23:17:35.544: INFO: Got endpoints: latency-svc-dj7pw [749.027999ms]
May 30 23:17:35.560: INFO: Created: latency-svc-kzxmf
May 30 23:17:35.596: INFO: Got endpoints: latency-svc-z4bvk [750.981199ms]
May 30 23:17:35.604: INFO: Created: latency-svc-rsnzb
May 30 23:17:35.645: INFO: Got endpoints: latency-svc-dvgjv [749.363399ms]
May 30 23:17:35.657: INFO: Created: latency-svc-gk7px
May 30 23:17:35.696: INFO: Got endpoints: latency-svc-dn45w [750.750799ms]
May 30 23:17:35.707: INFO: Created: latency-svc-zcg54
May 30 23:17:35.746: INFO: Got endpoints: latency-svc-hvrsq [746.475698ms]
May 30 23:17:35.767: INFO: Created: latency-svc-dzpsq
May 30 23:17:35.800: INFO: Got endpoints: latency-svc-rnqjd [752.1141ms]
May 30 23:17:35.810: INFO: Created: latency-svc-rrzbg
May 30 23:17:35.846: INFO: Got endpoints: latency-svc-hvltq [716.43589ms]
May 30 23:17:35.859: INFO: Created: latency-svc-8fpmr
May 30 23:17:35.896: INFO: Got endpoints: latency-svc-rwptg [743.988297ms]
May 30 23:17:35.920: INFO: Created: latency-svc-nh8nn
May 30 23:17:35.954: INFO: Got endpoints: latency-svc-gm7tz [749.831999ms]
May 30 23:17:35.963: INFO: Created: latency-svc-v4pzf
May 30 23:17:35.995: INFO: Got endpoints: latency-svc-bz2d9 [747.175999ms]
May 30 23:17:36.006: INFO: Created: latency-svc-6jsd7
May 30 23:17:36.046: INFO: Got endpoints: latency-svc-r5qxq [750.583499ms]
May 30 23:17:36.063: INFO: Created: latency-svc-55kl7
May 30 23:17:36.093: INFO: Got endpoints: latency-svc-5wwxj [743.109697ms]
May 30 23:17:36.103: INFO: Created: latency-svc-2qhrw
May 30 23:17:36.144: INFO: Got endpoints: latency-svc-c7xr7 [750.273299ms]
May 30 23:17:36.155: INFO: Created: latency-svc-sx296
May 30 23:17:36.211: INFO: Got endpoints: latency-svc-t6zch [762.241102ms]
May 30 23:17:36.225: INFO: Created: latency-svc-fh4bn
May 30 23:17:36.245: INFO: Got endpoints: latency-svc-79rd9 [751.106299ms]
May 30 23:17:36.255: INFO: Created: latency-svc-cxpsg
May 30 23:17:36.295: INFO: Got endpoints: latency-svc-kzxmf [750.381199ms]
May 30 23:17:36.305: INFO: Created: latency-svc-4w4hf
May 30 23:17:36.346: INFO: Got endpoints: latency-svc-rsnzb [750.133499ms]
May 30 23:17:36.355: INFO: Created: latency-svc-wsjmj
May 30 23:17:36.396: INFO: Got endpoints: latency-svc-gk7px [750.167399ms]
May 30 23:17:36.412: INFO: Created: latency-svc-hpdjq
May 30 23:17:36.453: INFO: Got endpoints: latency-svc-zcg54 [756.438301ms]
May 30 23:17:36.467: INFO: Created: latency-svc-5tx7w
May 30 23:17:36.494: INFO: Got endpoints: latency-svc-dzpsq [748.052798ms]
May 30 23:17:36.506: INFO: Created: latency-svc-xnt9f
May 30 23:17:36.546: INFO: Got endpoints: latency-svc-rrzbg [746.006598ms]
May 30 23:17:36.558: INFO: Created: latency-svc-zw69w
May 30 23:17:36.595: INFO: Got endpoints: latency-svc-8fpmr [749.117499ms]
May 30 23:17:36.613: INFO: Created: latency-svc-kfsv9
May 30 23:17:36.646: INFO: Got endpoints: latency-svc-nh8nn [749.807799ms]
May 30 23:17:36.659: INFO: Created: latency-svc-h7nj5
May 30 23:17:36.701: INFO: Got endpoints: latency-svc-v4pzf [747.094998ms]
May 30 23:17:36.720: INFO: Created: latency-svc-f69n6
May 30 23:17:36.745: INFO: Got endpoints: latency-svc-6jsd7 [749.562399ms]
May 30 23:17:36.753: INFO: Created: latency-svc-5c5mv
May 30 23:17:36.795: INFO: Got endpoints: latency-svc-55kl7 [749.451299ms]
May 30 23:17:36.803: INFO: Created: latency-svc-n7rvw
May 30 23:17:36.845: INFO: Got endpoints: latency-svc-2qhrw [751.516399ms]
May 30 23:17:36.854: INFO: Created: latency-svc-vmwbh
May 30 23:17:36.902: INFO: Got endpoints: latency-svc-sx296 [756.8843ms]
May 30 23:17:36.915: INFO: Created: latency-svc-75vx8
May 30 23:17:36.946: INFO: Got endpoints: latency-svc-fh4bn [734.927195ms]
May 30 23:17:36.957: INFO: Created: latency-svc-lczhw
May 30 23:17:36.996: INFO: Got endpoints: latency-svc-cxpsg [751.317899ms]
May 30 23:17:37.009: INFO: Created: latency-svc-8m6xd
May 30 23:17:37.045: INFO: Got endpoints: latency-svc-4w4hf [750.250499ms]
May 30 23:17:37.055: INFO: Created: latency-svc-b2br8
May 30 23:17:37.094: INFO: Got endpoints: latency-svc-wsjmj [748.116998ms]
May 30 23:17:37.116: INFO: Created: latency-svc-z42cx
May 30 23:17:37.144: INFO: Got endpoints: latency-svc-hpdjq [748.652799ms]
May 30 23:17:37.159: INFO: Created: latency-svc-ztsk5
May 30 23:17:37.195: INFO: Got endpoints: latency-svc-5tx7w [742.642697ms]
May 30 23:17:37.216: INFO: Created: latency-svc-cdvwb
May 30 23:17:37.248: INFO: Got endpoints: latency-svc-xnt9f [754.1964ms]
May 30 23:17:37.260: INFO: Created: latency-svc-qptn8
May 30 23:17:37.295: INFO: Got endpoints: latency-svc-zw69w [748.917999ms]
May 30 23:17:37.312: INFO: Created: latency-svc-gkbjr
May 30 23:17:37.346: INFO: Got endpoints: latency-svc-kfsv9 [750.797899ms]
May 30 23:17:37.357: INFO: Created: latency-svc-zhg74
May 30 23:17:37.396: INFO: Got endpoints: latency-svc-h7nj5 [749.347299ms]
May 30 23:17:37.413: INFO: Created: latency-svc-wxdhg
May 30 23:17:37.457: INFO: Got endpoints: latency-svc-f69n6 [755.588801ms]
May 30 23:17:37.468: INFO: Created: latency-svc-rznj2
May 30 23:17:37.494: INFO: Got endpoints: latency-svc-5c5mv [748.466498ms]
May 30 23:17:37.504: INFO: Created: latency-svc-2ks8s
May 30 23:17:37.545: INFO: Got endpoints: latency-svc-n7rvw [749.667199ms]
May 30 23:17:37.554: INFO: Created: latency-svc-nqqld
May 30 23:17:37.649: INFO: Got endpoints: latency-svc-vmwbh [804.016514ms]
May 30 23:17:37.662: INFO: Got endpoints: latency-svc-75vx8 [759.732502ms]
May 30 23:17:37.673: INFO: Created: latency-svc-28vvf
May 30 23:17:37.682: INFO: Created: latency-svc-85vw6
May 30 23:17:37.694: INFO: Got endpoints: latency-svc-lczhw [748.153799ms]
May 30 23:17:37.705: INFO: Created: latency-svc-rf5h7
May 30 23:17:37.745: INFO: Got endpoints: latency-svc-8m6xd [748.864599ms]
May 30 23:17:37.769: INFO: Created: latency-svc-gprcn
May 30 23:17:37.794: INFO: Got endpoints: latency-svc-b2br8 [748.809599ms]
May 30 23:17:37.808: INFO: Created: latency-svc-8t2hz
May 30 23:17:37.845: INFO: Got endpoints: latency-svc-z42cx [750.4464ms]
May 30 23:17:37.867: INFO: Created: latency-svc-p559g
May 30 23:17:37.900: INFO: Got endpoints: latency-svc-ztsk5 [755.328ms]
May 30 23:17:37.908: INFO: Created: latency-svc-ffxd6
May 30 23:17:37.946: INFO: Got endpoints: latency-svc-cdvwb [749.3228ms]
May 30 23:17:37.954: INFO: Created: latency-svc-jcmjq
May 30 23:17:37.998: INFO: Got endpoints: latency-svc-qptn8 [749.040399ms]
May 30 23:17:38.009: INFO: Created: latency-svc-8hckj
May 30 23:17:38.050: INFO: Got endpoints: latency-svc-gkbjr [754.8594ms]
May 30 23:17:38.065: INFO: Created: latency-svc-cx4xc
May 30 23:17:38.095: INFO: Got endpoints: latency-svc-zhg74 [749.125499ms]
May 30 23:17:38.105: INFO: Created: latency-svc-5fs6w
May 30 23:17:38.247: INFO: Got endpoints: latency-svc-rznj2 [790.36811ms]
May 30 23:17:38.247: INFO: Got endpoints: latency-svc-wxdhg [851.861127ms]
May 30 23:17:38.248: INFO: Got endpoints: latency-svc-2ks8s [754.425201ms]
May 30 23:17:38.259: INFO: Created: latency-svc-xsblh
May 30 23:17:38.266: INFO: Created: latency-svc-flgbq
May 30 23:17:38.281: INFO: Created: latency-svc-ftjhp
May 30 23:17:38.299: INFO: Got endpoints: latency-svc-nqqld [753.3786ms]
May 30 23:17:38.307: INFO: Created: latency-svc-kwl24
May 30 23:17:38.348: INFO: Got endpoints: latency-svc-28vvf [699.013386ms]
May 30 23:17:38.357: INFO: Created: latency-svc-vzc2t
May 30 23:17:38.395: INFO: Got endpoints: latency-svc-85vw6 [732.779795ms]
May 30 23:17:38.403: INFO: Created: latency-svc-lpt6p
May 30 23:17:38.445: INFO: Got endpoints: latency-svc-rf5h7 [751.080199ms]
May 30 23:17:38.460: INFO: Created: latency-svc-svtrl
May 30 23:17:38.496: INFO: Got endpoints: latency-svc-gprcn [751.0784ms]
May 30 23:17:38.564: INFO: Got endpoints: latency-svc-8t2hz [770.154205ms]
May 30 23:17:38.578: INFO: Created: latency-svc-v6wmn
May 30 23:17:38.578: INFO: Created: latency-svc-pxp76
May 30 23:17:38.597: INFO: Got endpoints: latency-svc-p559g [752.4417ms]
May 30 23:17:38.615: INFO: Created: latency-svc-5smkp
May 30 23:17:38.651: INFO: Got endpoints: latency-svc-ffxd6 [751.2536ms]
May 30 23:17:38.668: INFO: Created: latency-svc-tjqfw
May 30 23:17:38.696: INFO: Got endpoints: latency-svc-jcmjq [749.740299ms]
May 30 23:17:38.705: INFO: Created: latency-svc-ww8m5
May 30 23:17:38.758: INFO: Got endpoints: latency-svc-8hckj [760.321303ms]
May 30 23:17:38.771: INFO: Created: latency-svc-ms2zt
May 30 23:17:38.794: INFO: Got endpoints: latency-svc-cx4xc [743.905098ms]
May 30 23:17:38.806: INFO: Created: latency-svc-8fhbd
May 30 23:17:38.845: INFO: Got endpoints: latency-svc-5fs6w [750.201ms]
May 30 23:17:38.885: INFO: Created: latency-svc-59kx4
May 30 23:17:38.897: INFO: Got endpoints: latency-svc-xsblh [649.201172ms]
May 30 23:17:38.906: INFO: Created: latency-svc-r8m5j
May 30 23:17:38.945: INFO: Got endpoints: latency-svc-flgbq [697.679285ms]
May 30 23:17:38.957: INFO: Created: latency-svc-v6nch
May 30 23:17:38.995: INFO: Got endpoints: latency-svc-ftjhp [746.991899ms]
May 30 23:17:39.007: INFO: Created: latency-svc-xpt64
May 30 23:17:39.063: INFO: Got endpoints: latency-svc-kwl24 [763.790503ms]
May 30 23:17:39.095: INFO: Got endpoints: latency-svc-vzc2t [746.663298ms]
May 30 23:17:39.102: INFO: Created: latency-svc-vvq7c
May 30 23:17:39.108: INFO: Created: latency-svc-js69m
May 30 23:17:39.149: INFO: Got endpoints: latency-svc-lpt6p [753.6539ms]
May 30 23:17:39.162: INFO: Created: latency-svc-btw6d
May 30 23:17:39.197: INFO: Got endpoints: latency-svc-svtrl [751.5734ms]
May 30 23:17:39.212: INFO: Created: latency-svc-jzk9x
May 30 23:17:39.245: INFO: Got endpoints: latency-svc-v6wmn [748.535499ms]
May 30 23:17:39.256: INFO: Created: latency-svc-6r7wc
May 30 23:17:39.294: INFO: Got endpoints: latency-svc-pxp76 [729.498194ms]
May 30 23:17:39.310: INFO: Created: latency-svc-86jv5
May 30 23:17:39.347: INFO: Got endpoints: latency-svc-5smkp [749.801299ms]
May 30 23:17:39.358: INFO: Created: latency-svc-nvp8k
May 30 23:17:39.396: INFO: Got endpoints: latency-svc-tjqfw [743.434398ms]
May 30 23:17:39.406: INFO: Created: latency-svc-gjwxg
May 30 23:17:39.449: INFO: Got endpoints: latency-svc-ww8m5 [753.0214ms]
May 30 23:17:39.460: INFO: Created: latency-svc-lrgpg
May 30 23:17:39.499: INFO: Got endpoints: latency-svc-ms2zt [741.169097ms]
May 30 23:17:39.518: INFO: Created: latency-svc-rbkzl
May 30 23:17:39.544: INFO: Got endpoints: latency-svc-8fhbd [750.1736ms]
May 30 23:17:39.554: INFO: Created: latency-svc-8slbh
May 30 23:17:39.596: INFO: Got endpoints: latency-svc-59kx4 [750.685599ms]
May 30 23:17:39.610: INFO: Created: latency-svc-w6b2c
May 30 23:17:39.645: INFO: Got endpoints: latency-svc-r8m5j [748.124599ms]
May 30 23:17:39.654: INFO: Created: latency-svc-j9rjq
May 30 23:17:39.702: INFO: Got endpoints: latency-svc-v6nch [756.609401ms]
May 30 23:17:39.714: INFO: Created: latency-svc-fdqkm
May 30 23:17:39.751: INFO: Got endpoints: latency-svc-xpt64 [755.172ms]
May 30 23:17:39.772: INFO: Created: latency-svc-x6hrv
May 30 23:17:39.793: INFO: Got endpoints: latency-svc-vvq7c [727.538094ms]
May 30 23:17:39.804: INFO: Created: latency-svc-4f7bn
May 30 23:17:39.863: INFO: Got endpoints: latency-svc-js69m [768.221904ms]
May 30 23:17:39.885: INFO: Created: latency-svc-dpfmg
May 30 23:17:39.898: INFO: Got endpoints: latency-svc-btw6d [748.843199ms]
May 30 23:17:39.906: INFO: Created: latency-svc-jtd6r
May 30 23:17:39.944: INFO: Got endpoints: latency-svc-jzk9x [746.847499ms]
May 30 23:17:39.958: INFO: Created: latency-svc-jpqzz
May 30 23:17:39.996: INFO: Got endpoints: latency-svc-6r7wc [750.7003ms]
May 30 23:17:40.006: INFO: Created: latency-svc-tccvk
May 30 23:17:40.051: INFO: Got endpoints: latency-svc-86jv5 [756.694001ms]
May 30 23:17:40.064: INFO: Created: latency-svc-q29rj
May 30 23:17:40.100: INFO: Got endpoints: latency-svc-nvp8k [752.5561ms]
May 30 23:17:40.133: INFO: Created: latency-svc-cmxjc
May 30 23:17:40.145: INFO: Got endpoints: latency-svc-gjwxg [749.352799ms]
May 30 23:17:40.158: INFO: Created: latency-svc-rsq2g
May 30 23:17:40.199: INFO: Got endpoints: latency-svc-lrgpg [749.6907ms]
May 30 23:17:40.218: INFO: Created: latency-svc-tzmcl
May 30 23:17:40.250: INFO: Got endpoints: latency-svc-rbkzl [750.935199ms]
May 30 23:17:40.272: INFO: Created: latency-svc-grrtz
May 30 23:17:40.294: INFO: Got endpoints: latency-svc-8slbh [749.689799ms]
May 30 23:17:40.304: INFO: Created: latency-svc-jcfd8
May 30 23:17:40.346: INFO: Got endpoints: latency-svc-w6b2c [749.8907ms]
May 30 23:17:40.357: INFO: Created: latency-svc-rnhtf
May 30 23:17:40.397: INFO: Got endpoints: latency-svc-j9rjq [751.7125ms]
May 30 23:17:40.406: INFO: Created: latency-svc-xxhdr
May 30 23:17:40.446: INFO: Got endpoints: latency-svc-fdqkm [744.185398ms]
May 30 23:17:40.455: INFO: Created: latency-svc-hssjw
May 30 23:17:40.495: INFO: Got endpoints: latency-svc-x6hrv [744.193699ms]
May 30 23:17:40.509: INFO: Created: latency-svc-st7hp
May 30 23:17:40.545: INFO: Got endpoints: latency-svc-4f7bn [751.3158ms]
May 30 23:17:40.555: INFO: Created: latency-svc-q88d5
May 30 23:17:40.602: INFO: Got endpoints: latency-svc-dpfmg [739.276997ms]
May 30 23:17:40.621: INFO: Created: latency-svc-8fpbb
May 30 23:17:40.645: INFO: Got endpoints: latency-svc-jtd6r [747.044199ms]
May 30 23:17:40.656: INFO: Created: latency-svc-9rj4l
May 30 23:17:40.694: INFO: Got endpoints: latency-svc-jpqzz [747.8525ms]
May 30 23:17:40.706: INFO: Created: latency-svc-dd5m4
May 30 23:17:40.745: INFO: Got endpoints: latency-svc-tccvk [748.597899ms]
May 30 23:17:40.756: INFO: Created: latency-svc-hv5zc
May 30 23:17:40.799: INFO: Got endpoints: latency-svc-q29rj [748.5705ms]
May 30 23:17:40.808: INFO: Created: latency-svc-qqmxh
May 30 23:17:40.845: INFO: Got endpoints: latency-svc-cmxjc [744.550599ms]
May 30 23:17:40.898: INFO: Got endpoints: latency-svc-rsq2g [751.9804ms]
May 30 23:17:40.946: INFO: Got endpoints: latency-svc-tzmcl [747.158099ms]
May 30 23:17:41.003: INFO: Got endpoints: latency-svc-grrtz [752.843701ms]
May 30 23:17:41.052: INFO: Got endpoints: latency-svc-jcfd8 [757.901902ms]
May 30 23:17:41.100: INFO: Got endpoints: latency-svc-rnhtf [753.452901ms]
May 30 23:17:41.145: INFO: Got endpoints: latency-svc-xxhdr [748.044499ms]
May 30 23:17:41.194: INFO: Got endpoints: latency-svc-hssjw [748.3231ms]
May 30 23:17:41.263: INFO: Got endpoints: latency-svc-st7hp [765.686704ms]
May 30 23:17:41.295: INFO: Got endpoints: latency-svc-q88d5 [749.6935ms]
May 30 23:17:41.344: INFO: Got endpoints: latency-svc-8fpbb [741.704298ms]
May 30 23:17:41.401: INFO: Got endpoints: latency-svc-9rj4l [756.231801ms]
May 30 23:17:41.446: INFO: Got endpoints: latency-svc-dd5m4 [751.9057ms]
May 30 23:17:41.494: INFO: Got endpoints: latency-svc-hv5zc [748.8057ms]
May 30 23:17:41.558: INFO: Got endpoints: latency-svc-qqmxh [758.266102ms]
May 30 23:17:41.558: INFO: Latencies: [24.668206ms 32.152308ms 47.655213ms 65.605918ms 65.779517ms 73.89952ms 84.514622ms 144.304138ms 145.783539ms 151.786841ms 163.006444ms 169.491645ms 177.084547ms 180.083847ms 189.15715ms 193.286952ms 194.627452ms 196.216452ms 198.956753ms 204.261255ms 205.766154ms 207.419455ms 207.525655ms 208.398555ms 212.231357ms 212.717856ms 213.347057ms 217.399758ms 238.762664ms 241.783764ms 245.153465ms 246.995865ms 247.110966ms 247.313865ms 248.330866ms 249.159566ms 256.253368ms 257.602868ms 261.42357ms 261.447169ms 262.786269ms 262.80847ms 263.256769ms 276.059873ms 318.299785ms 366.976097ms 405.085008ms 437.083516ms 480.912227ms 514.850236ms 557.947448ms 595.928858ms 625.647666ms 649.201172ms 690.460583ms 697.679285ms 699.013386ms 716.43589ms 722.202491ms 727.538094ms 729.498194ms 729.681994ms 730.039294ms 732.779795ms 733.416994ms 733.716695ms 734.927195ms 737.489095ms 739.276997ms 741.169097ms 741.704298ms 742.642697ms 743.109697ms 743.434398ms 743.905098ms 743.988297ms 744.185398ms 744.193699ms 744.550599ms 745.321398ms 745.916098ms 746.006598ms 746.475698ms 746.625398ms 746.663298ms 746.847499ms 746.991899ms 747.044199ms 747.089798ms 747.094998ms 747.158099ms 747.175999ms 747.8525ms 747.884098ms 748.000099ms 748.044499ms 748.052798ms 748.097699ms 748.116998ms 748.124599ms 748.153799ms 748.3231ms 748.466498ms 748.530199ms 748.535499ms 748.5705ms 748.597899ms 748.652799ms 748.661599ms 748.8057ms 748.809599ms 748.843199ms 748.864599ms 748.917999ms 749.027999ms 749.040399ms 749.117499ms 749.125499ms 749.3228ms 749.347299ms 749.352799ms 749.363399ms 749.451299ms 749.562399ms 749.667199ms 749.689799ms 749.6907ms 749.6935ms 749.740299ms 749.801299ms 749.807799ms 749.831999ms 749.8907ms 750.081799ms 750.090199ms 750.133499ms 750.167399ms 750.1736ms 750.201ms 750.250499ms 750.273299ms 750.381199ms 750.4464ms 750.583499ms 750.685599ms 750.7003ms 750.750799ms 750.793099ms 750.797899ms 750.935199ms 750.981199ms 751.0784ms 751.080199ms 751.106299ms 751.2536ms 751.3158ms 751.317899ms 751.516399ms 751.5734ms 751.7125ms 751.9057ms 751.9804ms 751.984199ms 752.1141ms 752.4417ms 752.5561ms 752.843701ms 752.9175ms 753.0214ms 753.3786ms 753.452901ms 753.4828ms 753.6539ms 754.1964ms 754.425201ms 754.4915ms 754.8594ms 755.172ms 755.328ms 755.588801ms 756.1032ms 756.231801ms 756.438301ms 756.609401ms 756.694001ms 756.8843ms 757.901902ms 758.266102ms 759.732502ms 760.077002ms 760.321303ms 762.241102ms 763.790503ms 765.686704ms 768.221904ms 770.154205ms 784.375208ms 790.36811ms 804.016514ms 851.861127ms]
May 30 23:17:41.558: INFO: 50 %ile: 748.153799ms
May 30 23:17:41.558: INFO: 90 %ile: 756.1032ms
May 30 23:17:41.558: INFO: 99 %ile: 804.016514ms
May 30 23:17:41.558: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:17:41.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-887wm" for this suite.
May 30 23:18:05.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:18:05.645: INFO: namespace: e2e-tests-svc-latency-887wm, resource: bindings, ignored listing per whitelist
May 30 23:18:05.656: INFO: namespace e2e-tests-svc-latency-887wm deletion completed in 24.090011568s

• [SLOW TEST:35.906 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:18:05.657: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-nxhm4
May 30 23:18:09.750: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-nxhm4
STEP: checking the pod's current state and verifying that restartCount is present
May 30 23:18:09.753: INFO: Initial restart count of pod liveness-exec is 0
May 30 23:19:05.841: INFO: Restart count of pod e2e-tests-container-probe-nxhm4/liveness-exec is now 1 (56.088766762s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:19:05.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-nxhm4" for this suite.
May 30 23:19:11.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:19:11.916: INFO: namespace: e2e-tests-container-probe-nxhm4, resource: bindings, ignored listing per whitelist
May 30 23:19:11.939: INFO: namespace e2e-tests-container-probe-nxhm4 deletion completed in 6.084889506s

• [SLOW TEST:66.282 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:19:11.941: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-555b7fbf-8331-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 23:19:12.028: INFO: Waiting up to 5m0s for pod "pod-configmaps-555be276-8331-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-configmap-qt2r2" to be "success or failure"
May 30 23:19:12.032: INFO: Pod "pod-configmaps-555be276-8331-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075301ms
May 30 23:19:14.035: INFO: Pod "pod-configmaps-555be276-8331-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007102864s
May 30 23:19:16.039: INFO: Pod "pod-configmaps-555be276-8331-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010558628s
STEP: Saw pod success
May 30 23:19:16.039: INFO: Pod "pod-configmaps-555be276-8331-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:19:16.041: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-configmaps-555be276-8331-11e9-a3e0-52e03c2e65ea container configmap-volume-test: <nil>
STEP: delete the pod
May 30 23:19:16.055: INFO: Waiting for pod pod-configmaps-555be276-8331-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:19:16.057: INFO: Pod pod-configmaps-555be276-8331-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:19:16.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qt2r2" for this suite.
May 30 23:19:22.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:19:22.092: INFO: namespace: e2e-tests-configmap-qt2r2, resource: bindings, ignored listing per whitelist
May 30 23:19:22.149: INFO: namespace e2e-tests-configmap-qt2r2 deletion completed in 6.088945617s

• [SLOW TEST:10.209 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:19:22.151: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 23:19:22.228: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b702830-8331-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-4bm2l" to be "success or failure"
May 30 23:19:22.234: INFO: Pod "downwardapi-volume-5b702830-8331-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.769702ms
May 30 23:19:24.237: INFO: Pod "downwardapi-volume-5b702830-8331-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009352168s
May 30 23:19:26.240: INFO: Pod "downwardapi-volume-5b702830-8331-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012252034s
STEP: Saw pod success
May 30 23:19:26.240: INFO: Pod "downwardapi-volume-5b702830-8331-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:19:26.242: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod downwardapi-volume-5b702830-8331-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 23:19:26.319: INFO: Waiting for pod downwardapi-volume-5b702830-8331-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:19:26.321: INFO: Pod downwardapi-volume-5b702830-8331-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:19:26.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4bm2l" for this suite.
May 30 23:19:32.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:19:32.366: INFO: namespace: e2e-tests-projected-4bm2l, resource: bindings, ignored listing per whitelist
May 30 23:19:32.420: INFO: namespace e2e-tests-projected-4bm2l deletion completed in 6.094596628s

• [SLOW TEST:10.269 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:19:32.420: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0530 23:19:42.523760      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 30 23:19:42.523: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:19:42.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-b67tm" for this suite.
May 30 23:19:48.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:19:48.577: INFO: namespace: e2e-tests-gc-b67tm, resource: bindings, ignored listing per whitelist
May 30 23:19:48.652: INFO: namespace e2e-tests-gc-b67tm deletion completed in 6.126045351s

• [SLOW TEST:16.233 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:19:48.653: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 30 23:19:48.774: INFO: (0) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 7.516102ms)
May 30 23:19:48.777: INFO: (1) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.502301ms)
May 30 23:19:48.784: INFO: (2) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 6.645801ms)
May 30 23:19:48.788: INFO: (3) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.459301ms)
May 30 23:19:48.792: INFO: (4) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.522502ms)
May 30 23:19:48.796: INFO: (5) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.305001ms)
May 30 23:19:48.800: INFO: (6) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.138201ms)
May 30 23:19:48.804: INFO: (7) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.235401ms)
May 30 23:19:48.807: INFO: (8) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.265401ms)
May 30 23:19:48.811: INFO: (9) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.028901ms)
May 30 23:19:48.817: INFO: (10) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 5.866402ms)
May 30 23:19:48.822: INFO: (11) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 5.673201ms)
May 30 23:19:48.828: INFO: (12) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 5.361702ms)
May 30 23:19:48.832: INFO: (13) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.387301ms)
May 30 23:19:48.836: INFO: (14) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.937001ms)
May 30 23:19:48.841: INFO: (15) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.093402ms)
May 30 23:19:48.850: INFO: (16) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 8.951202ms)
May 30 23:19:48.853: INFO: (17) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.296001ms)
May 30 23:19:48.857: INFO: (18) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.791101ms)
May 30 23:19:48.862: INFO: (19) /api/v1/nodes/k8s-linuxpool-35502656-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.349302ms)
[AfterEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:19:48.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-7fc6t" for this suite.
May 30 23:19:54.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:19:54.940: INFO: namespace: e2e-tests-proxy-7fc6t, resource: bindings, ignored listing per whitelist
May 30 23:19:54.958: INFO: namespace e2e-tests-proxy-7fc6t deletion completed in 6.092154345s

• [SLOW TEST:6.306 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:19:54.959: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
May 30 23:19:55.043: INFO: Waiting up to 5m0s for pod "downward-api-6eff7ead-8331-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-downward-api-t4j7h" to be "success or failure"
May 30 23:19:55.052: INFO: Pod "downward-api-6eff7ead-8331-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 8.349002ms
May 30 23:19:57.055: INFO: Pod "downward-api-6eff7ead-8331-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012015578s
May 30 23:19:59.058: INFO: Pod "downward-api-6eff7ead-8331-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015104253s
May 30 23:20:01.062: INFO: Pod "downward-api-6eff7ead-8331-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018430229s
STEP: Saw pod success
May 30 23:20:01.062: INFO: Pod "downward-api-6eff7ead-8331-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:20:01.064: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod downward-api-6eff7ead-8331-11e9-a3e0-52e03c2e65ea container dapi-container: <nil>
STEP: delete the pod
May 30 23:20:01.078: INFO: Waiting for pod downward-api-6eff7ead-8331-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:20:01.080: INFO: Pod downward-api-6eff7ead-8331-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:20:01.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t4j7h" for this suite.
May 30 23:20:07.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:20:07.118: INFO: namespace: e2e-tests-downward-api-t4j7h, resource: bindings, ignored listing per whitelist
May 30 23:20:07.167: INFO: namespace e2e-tests-downward-api-t4j7h deletion completed in 6.084059654s

• [SLOW TEST:12.208 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:20:07.167: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0530 23:20:47.278757      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 30 23:20:47.278: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:20:47.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xs9mv" for this suite.
May 30 23:20:53.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:20:53.314: INFO: namespace: e2e-tests-gc-xs9mv, resource: bindings, ignored listing per whitelist
May 30 23:20:53.388: INFO: namespace e2e-tests-gc-xs9mv deletion completed in 6.106383467s

• [SLOW TEST:46.221 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:20:53.388: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-91d2f042-8331-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume secrets
May 30 23:20:53.479: INFO: Waiting up to 5m0s for pod "pod-secrets-91d40c9b-8331-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-secrets-mr5vf" to be "success or failure"
May 30 23:20:53.486: INFO: Pod "pod-secrets-91d40c9b-8331-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 7.341765ms
May 30 23:20:55.494: INFO: Pod "pod-secrets-91d40c9b-8331-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015372161s
May 30 23:20:57.497: INFO: Pod "pod-secrets-91d40c9b-8331-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018154218s
STEP: Saw pod success
May 30 23:20:57.497: INFO: Pod "pod-secrets-91d40c9b-8331-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:20:57.499: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-secrets-91d40c9b-8331-11e9-a3e0-52e03c2e65ea container secret-volume-test: <nil>
STEP: delete the pod
May 30 23:20:57.531: INFO: Waiting for pod pod-secrets-91d40c9b-8331-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:20:57.533: INFO: Pod pod-secrets-91d40c9b-8331-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:20:57.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mr5vf" for this suite.
May 30 23:21:03.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:21:03.615: INFO: namespace: e2e-tests-secrets-mr5vf, resource: bindings, ignored listing per whitelist
May 30 23:21:03.630: INFO: namespace e2e-tests-secrets-mr5vf deletion completed in 6.091423493s

• [SLOW TEST:10.242 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:21:03.632: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-h6ptk
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a new StaefulSet
May 30 23:21:03.725: INFO: Found 0 stateful pods, waiting for 3
May 30 23:21:13.728: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 30 23:21:13.728: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 30 23:21:13.728: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=false
May 30 23:21:23.729: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 30 23:21:23.729: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 30 23:21:23.729: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
May 30 23:21:23.759: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 30 23:21:23.785: INFO: Updating stateful set ss2
May 30 23:21:23.802: INFO: Waiting for Pod e2e-tests-statefulset-h6ptk/ss2-2 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
May 30 23:21:33.808: INFO: Waiting for Pod e2e-tests-statefulset-h6ptk/ss2-2 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
STEP: Restoring Pods to the correct revision when they are deleted
May 30 23:21:43.862: INFO: Found 2 stateful pods, waiting for 3
May 30 23:21:53.865: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 30 23:21:53.865: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 30 23:21:53.865: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 30 23:21:53.886: INFO: Updating stateful set ss2
May 30 23:21:53.899: INFO: Waiting for Pod e2e-tests-statefulset-h6ptk/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
May 30 23:22:03.923: INFO: Updating stateful set ss2
May 30 23:22:03.929: INFO: Waiting for StatefulSet e2e-tests-statefulset-h6ptk/ss2 to complete update
May 30 23:22:03.929: INFO: Waiting for Pod e2e-tests-statefulset-h6ptk/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
May 30 23:22:13.935: INFO: Waiting for StatefulSet e2e-tests-statefulset-h6ptk/ss2 to complete update
May 30 23:22:13.935: INFO: Waiting for Pod e2e-tests-statefulset-h6ptk/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
May 30 23:22:23.935: INFO: Waiting for StatefulSet e2e-tests-statefulset-h6ptk/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 30 23:22:33.935: INFO: Deleting all statefulset in ns e2e-tests-statefulset-h6ptk
May 30 23:22:33.937: INFO: Scaling statefulset ss2 to 0
May 30 23:23:03.952: INFO: Waiting for statefulset status.replicas updated to 0
May 30 23:23:03.954: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:23:03.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-h6ptk" for this suite.
May 30 23:23:09.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:23:10.090: INFO: namespace: e2e-tests-statefulset-h6ptk, resource: bindings, ignored listing per whitelist
May 30 23:23:10.090: INFO: namespace e2e-tests-statefulset-h6ptk deletion completed in 6.116572091s

• [SLOW TEST:126.458 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:23:10.090: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-e34d9b34-8331-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 23:23:10.173: INFO: Waiting up to 5m0s for pod "pod-configmaps-e34e1433-8331-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-configmap-n45rd" to be "success or failure"
May 30 23:23:10.178: INFO: Pod "pod-configmaps-e34e1433-8331-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.322684ms
May 30 23:23:12.180: INFO: Pod "pod-configmaps-e34e1433-8331-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00715404s
May 30 23:23:14.183: INFO: Pod "pod-configmaps-e34e1433-8331-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010135822s
STEP: Saw pod success
May 30 23:23:14.183: INFO: Pod "pod-configmaps-e34e1433-8331-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:23:14.186: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-configmaps-e34e1433-8331-11e9-a3e0-52e03c2e65ea container configmap-volume-test: <nil>
STEP: delete the pod
May 30 23:23:14.205: INFO: Waiting for pod pod-configmaps-e34e1433-8331-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:23:14.208: INFO: Pod pod-configmaps-e34e1433-8331-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:23:14.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-n45rd" for this suite.
May 30 23:23:20.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:23:20.271: INFO: namespace: e2e-tests-configmap-n45rd, resource: bindings, ignored listing per whitelist
May 30 23:23:20.294: INFO: namespace e2e-tests-configmap-n45rd deletion completed in 6.083072739s

• [SLOW TEST:10.205 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:23:20.298: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with configMap that has name projected-configmap-test-upd-e96426bd-8331-11e9-a3e0-52e03c2e65ea
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-e96426bd-8331-11e9-a3e0-52e03c2e65ea
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:24:28.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rw8pd" for this suite.
May 30 23:24:50.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:24:50.703: INFO: namespace: e2e-tests-projected-rw8pd, resource: bindings, ignored listing per whitelist
May 30 23:24:50.767: INFO: namespace e2e-tests-projected-rw8pd deletion completed in 22.084178721s

• [SLOW TEST:90.469 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:24:50.770: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 23:24:50.844: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1f4f4481-8332-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-downward-api-whnv9" to be "success or failure"
May 30 23:24:50.851: INFO: Pod "downwardapi-volume-1f4f4481-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.643579ms
May 30 23:24:52.856: INFO: Pod "downwardapi-volume-1f4f4481-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011644673s
May 30 23:24:54.859: INFO: Pod "downwardapi-volume-1f4f4481-8332-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014708795s
STEP: Saw pod success
May 30 23:24:54.859: INFO: Pod "downwardapi-volume-1f4f4481-8332-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:24:54.862: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod downwardapi-volume-1f4f4481-8332-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 23:24:54.877: INFO: Waiting for pod downwardapi-volume-1f4f4481-8332-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:24:54.879: INFO: Pod downwardapi-volume-1f4f4481-8332-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:24:54.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-whnv9" for this suite.
May 30 23:25:00.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:25:00.934: INFO: namespace: e2e-tests-downward-api-whnv9, resource: bindings, ignored listing per whitelist
May 30 23:25:01.000: INFO: namespace e2e-tests-downward-api-whnv9 deletion completed in 6.117670769s

• [SLOW TEST:10.231 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:25:01.000: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0530 23:25:07.122839      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 30 23:25:07.122: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:25:07.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ktbw9" for this suite.
May 30 23:25:13.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:25:13.154: INFO: namespace: e2e-tests-gc-ktbw9, resource: bindings, ignored listing per whitelist
May 30 23:25:13.215: INFO: namespace e2e-tests-gc-ktbw9 deletion completed in 6.088743763s

• [SLOW TEST:12.214 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:25:13.215: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0530 23:25:43.825029      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 30 23:25:43.825: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:25:43.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-plkvg" for this suite.
May 30 23:25:49.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:25:49.904: INFO: namespace: e2e-tests-gc-plkvg, resource: bindings, ignored listing per whitelist
May 30 23:25:49.916: INFO: namespace e2e-tests-gc-plkvg deletion completed in 6.088836727s

• [SLOW TEST:36.702 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:25:49.917: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-42904a18-8332-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 23:25:49.995: INFO: Waiting up to 5m0s for pod "pod-configmaps-4290ed89-8332-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-configmap-rjgtn" to be "success or failure"
May 30 23:25:49.999: INFO: Pod "pod-configmaps-4290ed89-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.67039ms
May 30 23:25:52.001: INFO: Pod "pod-configmaps-4290ed89-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006370816s
May 30 23:25:54.004: INFO: Pod "pod-configmaps-4290ed89-8332-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009143961s
STEP: Saw pod success
May 30 23:25:54.004: INFO: Pod "pod-configmaps-4290ed89-8332-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:25:54.006: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-configmaps-4290ed89-8332-11e9-a3e0-52e03c2e65ea container configmap-volume-test: <nil>
STEP: delete the pod
May 30 23:25:54.036: INFO: Waiting for pod pod-configmaps-4290ed89-8332-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:25:54.041: INFO: Pod pod-configmaps-4290ed89-8332-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:25:54.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rjgtn" for this suite.
May 30 23:26:00.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:26:00.106: INFO: namespace: e2e-tests-configmap-rjgtn, resource: bindings, ignored listing per whitelist
May 30 23:26:00.140: INFO: namespace e2e-tests-configmap-rjgtn deletion completed in 6.096112216s

• [SLOW TEST:10.224 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:26:00.141: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: validating api versions
May 30 23:26:00.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 api-versions'
May 30 23:26:00.401: INFO: stderr: ""
May 30 23:26:00.401: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:26:00.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jrvxg" for this suite.
May 30 23:26:06.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:26:06.470: INFO: namespace: e2e-tests-kubectl-jrvxg, resource: bindings, ignored listing per whitelist
May 30 23:26:06.497: INFO: namespace e2e-tests-kubectl-jrvxg deletion completed in 6.093094014s

• [SLOW TEST:6.356 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:26:06.498: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 23:26:06.571: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c7206ed-8332-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-sm2km" to be "success or failure"
May 30 23:26:06.579: INFO: Pod "downwardapi-volume-4c7206ed-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 7.610279ms
May 30 23:26:08.582: INFO: Pod "downwardapi-volume-4c7206ed-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010627167s
May 30 23:26:10.585: INFO: Pod "downwardapi-volume-4c7206ed-8332-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013504074s
STEP: Saw pod success
May 30 23:26:10.585: INFO: Pod "downwardapi-volume-4c7206ed-8332-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:26:10.587: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod downwardapi-volume-4c7206ed-8332-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 23:26:10.601: INFO: Waiting for pod downwardapi-volume-4c7206ed-8332-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:26:10.606: INFO: Pod downwardapi-volume-4c7206ed-8332-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:26:10.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sm2km" for this suite.
May 30 23:26:16.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:26:16.655: INFO: namespace: e2e-tests-projected-sm2km, resource: bindings, ignored listing per whitelist
May 30 23:26:16.698: INFO: namespace e2e-tests-projected-sm2km deletion completed in 6.089348822s

• [SLOW TEST:10.201 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:26:16.701: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name s-test-opt-del-5288e145-8332-11e9-a3e0-52e03c2e65ea
STEP: Creating secret with name s-test-opt-upd-5288e17d-8332-11e9-a3e0-52e03c2e65ea
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5288e145-8332-11e9-a3e0-52e03c2e65ea
STEP: Updating secret s-test-opt-upd-5288e17d-8332-11e9-a3e0-52e03c2e65ea
STEP: Creating secret with name s-test-opt-create-5288e192-8332-11e9-a3e0-52e03c2e65ea
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:26:24.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g878z" for this suite.
May 30 23:26:46.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:26:46.933: INFO: namespace: e2e-tests-secrets-g878z, resource: bindings, ignored listing per whitelist
May 30 23:26:46.987: INFO: namespace e2e-tests-secrets-g878z deletion completed in 22.096088624s

• [SLOW TEST:30.286 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:26:46.989: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test substitution in container's args
May 30 23:26:47.080: INFO: Waiting up to 5m0s for pod "var-expansion-6496026d-8332-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-var-expansion-hqhm5" to be "success or failure"
May 30 23:26:47.082: INFO: Pod "var-expansion-6496026d-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.250895ms
May 30 23:26:49.085: INFO: Pod "var-expansion-6496026d-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005335258s
May 30 23:26:51.088: INFO: Pod "var-expansion-6496026d-8332-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008243539s
STEP: Saw pod success
May 30 23:26:51.088: INFO: Pod "var-expansion-6496026d-8332-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:26:51.090: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod var-expansion-6496026d-8332-11e9-a3e0-52e03c2e65ea container dapi-container: <nil>
STEP: delete the pod
May 30 23:26:51.107: INFO: Waiting for pod var-expansion-6496026d-8332-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:26:51.109: INFO: Pod var-expansion-6496026d-8332-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:26:51.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-hqhm5" for this suite.
May 30 23:26:57.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:26:57.161: INFO: namespace: e2e-tests-var-expansion-hqhm5, resource: bindings, ignored listing per whitelist
May 30 23:26:57.191: INFO: namespace e2e-tests-var-expansion-hqhm5 deletion completed in 6.078854877s

• [SLOW TEST:10.203 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:26:57.191: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 23:26:57.271: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6aa9cae5-8332-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-4ghsp" to be "success or failure"
May 30 23:26:57.275: INFO: Pod "downwardapi-volume-6aa9cae5-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.12559ms
May 30 23:26:59.279: INFO: Pod "downwardapi-volume-6aa9cae5-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007406542s
May 30 23:27:01.282: INFO: Pod "downwardapi-volume-6aa9cae5-8332-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011072311s
STEP: Saw pod success
May 30 23:27:01.282: INFO: Pod "downwardapi-volume-6aa9cae5-8332-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:27:01.285: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod downwardapi-volume-6aa9cae5-8332-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 23:27:01.316: INFO: Waiting for pod downwardapi-volume-6aa9cae5-8332-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:27:01.323: INFO: Pod downwardapi-volume-6aa9cae5-8332-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:27:01.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4ghsp" for this suite.
May 30 23:27:07.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:27:07.465: INFO: namespace: e2e-tests-projected-4ghsp, resource: bindings, ignored listing per whitelist
May 30 23:27:07.485: INFO: namespace e2e-tests-projected-4ghsp deletion completed in 6.158383454s

• [SLOW TEST:10.294 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:27:07.488: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:28:07.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-s4knm" for this suite.
May 30 23:28:29.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:28:29.629: INFO: namespace: e2e-tests-container-probe-s4knm, resource: bindings, ignored listing per whitelist
May 30 23:28:29.661: INFO: namespace e2e-tests-container-probe-s4knm deletion completed in 22.083730419s

• [SLOW TEST:82.172 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:28:29.661: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:28:29.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-w6kc8" for this suite.
May 30 23:28:35.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:28:35.805: INFO: namespace: e2e-tests-services-w6kc8, resource: bindings, ignored listing per whitelist
May 30 23:28:35.825: INFO: namespace e2e-tests-services-w6kc8 deletion completed in 6.082424067s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.164 seconds]
[sig-network] Services
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:28:35.828: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name cm-test-opt-del-a57433bf-8332-11e9-a3e0-52e03c2e65ea
STEP: Creating configMap with name cm-test-opt-upd-a57433fc-8332-11e9-a3e0-52e03c2e65ea
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a57433bf-8332-11e9-a3e0-52e03c2e65ea
STEP: Updating configmap cm-test-opt-upd-a57433fc-8332-11e9-a3e0-52e03c2e65ea
STEP: Creating configMap with name cm-test-opt-create-a5743414-8332-11e9-a3e0-52e03c2e65ea
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:28:43.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-42xkr" for this suite.
May 30 23:29:05.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:29:06.055: INFO: namespace: e2e-tests-configmap-42xkr, resource: bindings, ignored listing per whitelist
May 30 23:29:06.077: INFO: namespace e2e-tests-configmap-42xkr deletion completed in 22.093550994s

• [SLOW TEST:30.249 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:29:06.077: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 30 23:29:06.217: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dqt7x,SelfLink:/api/v1/namespaces/e2e-tests-watch-dqt7x/configmaps/e2e-watch-test-label-changed,UID:b785a55a-8332-11e9-9b52-001dd80c000f,ResourceVersion:14816,Generation:0,CreationTimestamp:2019-05-30 23:29:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 30 23:29:06.217: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dqt7x,SelfLink:/api/v1/namespaces/e2e-tests-watch-dqt7x/configmaps/e2e-watch-test-label-changed,UID:b785a55a-8332-11e9-9b52-001dd80c000f,ResourceVersion:14817,Generation:0,CreationTimestamp:2019-05-30 23:29:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 30 23:29:06.218: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dqt7x,SelfLink:/api/v1/namespaces/e2e-tests-watch-dqt7x/configmaps/e2e-watch-test-label-changed,UID:b785a55a-8332-11e9-9b52-001dd80c000f,ResourceVersion:14818,Generation:0,CreationTimestamp:2019-05-30 23:29:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 30 23:29:16.241: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dqt7x,SelfLink:/api/v1/namespaces/e2e-tests-watch-dqt7x/configmaps/e2e-watch-test-label-changed,UID:b785a55a-8332-11e9-9b52-001dd80c000f,ResourceVersion:14835,Generation:0,CreationTimestamp:2019-05-30 23:29:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 30 23:29:16.241: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dqt7x,SelfLink:/api/v1/namespaces/e2e-tests-watch-dqt7x/configmaps/e2e-watch-test-label-changed,UID:b785a55a-8332-11e9-9b52-001dd80c000f,ResourceVersion:14836,Generation:0,CreationTimestamp:2019-05-30 23:29:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 30 23:29:16.241: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dqt7x,SelfLink:/api/v1/namespaces/e2e-tests-watch-dqt7x/configmaps/e2e-watch-test-label-changed,UID:b785a55a-8332-11e9-9b52-001dd80c000f,ResourceVersion:14837,Generation:0,CreationTimestamp:2019-05-30 23:29:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:29:16.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-dqt7x" for this suite.
May 30 23:29:22.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:29:22.269: INFO: namespace: e2e-tests-watch-dqt7x, resource: bindings, ignored listing per whitelist
May 30 23:29:22.327: INFO: namespace e2e-tests-watch-dqt7x deletion completed in 6.080119253s

• [SLOW TEST:16.250 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:29:22.329: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-jvs5r.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-jvs5r.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-jvs5r.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-jvs5r.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-jvs5r.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-jvs5r.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 30 23:29:36.526: INFO: DNS probes using dns-test-c12d5c16-8332-11e9-a3e0-52e03c2e65ea succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:29:36.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-jvs5r" for this suite.
May 30 23:29:42.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:29:42.627: INFO: namespace: e2e-tests-dns-jvs5r, resource: bindings, ignored listing per whitelist
May 30 23:29:42.638: INFO: namespace e2e-tests-dns-jvs5r deletion completed in 6.093600428s

• [SLOW TEST:20.309 seconds]
[sig-network] DNS
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:29:42.638: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name s-test-opt-del-cd483b09-8332-11e9-a3e0-52e03c2e65ea
STEP: Creating secret with name s-test-opt-upd-cd483bcd-8332-11e9-a3e0-52e03c2e65ea
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-cd483b09-8332-11e9-a3e0-52e03c2e65ea
STEP: Updating secret s-test-opt-upd-cd483bcd-8332-11e9-a3e0-52e03c2e65ea
STEP: Creating secret with name s-test-opt-create-cd483bf1-8332-11e9-a3e0-52e03c2e65ea
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:29:50.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pkf4d" for this suite.
May 30 23:30:12.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:30:12.835: INFO: namespace: e2e-tests-projected-pkf4d, resource: bindings, ignored listing per whitelist
May 30 23:30:12.896: INFO: namespace e2e-tests-projected-pkf4d deletion completed in 22.089537605s

• [SLOW TEST:30.258 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:30:12.896: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating secret e2e-tests-secrets-np5hf/secret-test-df50d121-8332-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume secrets
May 30 23:30:12.981: INFO: Waiting up to 5m0s for pod "pod-configmaps-df515d5c-8332-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-secrets-np5hf" to be "success or failure"
May 30 23:30:12.986: INFO: Pod "pod-configmaps-df515d5c-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.330292ms
May 30 23:30:14.989: INFO: Pod "pod-configmaps-df515d5c-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007582265s
May 30 23:30:16.992: INFO: Pod "pod-configmaps-df515d5c-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010682151s
May 30 23:30:18.995: INFO: Pod "pod-configmaps-df515d5c-8332-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013983348s
STEP: Saw pod success
May 30 23:30:18.995: INFO: Pod "pod-configmaps-df515d5c-8332-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:30:18.998: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-configmaps-df515d5c-8332-11e9-a3e0-52e03c2e65ea container env-test: <nil>
STEP: delete the pod
May 30 23:30:19.012: INFO: Waiting for pod pod-configmaps-df515d5c-8332-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:30:19.015: INFO: Pod pod-configmaps-df515d5c-8332-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:30:19.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-np5hf" for this suite.
May 30 23:30:25.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:30:25.058: INFO: namespace: e2e-tests-secrets-np5hf, resource: bindings, ignored listing per whitelist
May 30 23:30:25.101: INFO: namespace e2e-tests-secrets-np5hf deletion completed in 6.082417239s

• [SLOW TEST:12.204 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:30:25.102: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-projected-all-test-volume-e696c028-8332-11e9-a3e0-52e03c2e65ea
STEP: Creating secret with name secret-projected-all-test-volume-e696c018-8332-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test Check all projections for projected volume plugin
May 30 23:30:25.190: INFO: Waiting up to 5m0s for pod "projected-volume-e696bfee-8332-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-5kd2x" to be "success or failure"
May 30 23:30:25.192: INFO: Pod "projected-volume-e696bfee-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207096ms
May 30 23:30:27.196: INFO: Pod "projected-volume-e696bfee-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005266343s
May 30 23:30:29.198: INFO: Pod "projected-volume-e696bfee-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0081665s
May 30 23:30:31.208: INFO: Pod "projected-volume-e696bfee-8332-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018171658s
STEP: Saw pod success
May 30 23:30:31.208: INFO: Pod "projected-volume-e696bfee-8332-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:30:31.211: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod projected-volume-e696bfee-8332-11e9-a3e0-52e03c2e65ea container projected-all-volume-test: <nil>
STEP: delete the pod
May 30 23:30:31.231: INFO: Waiting for pod projected-volume-e696bfee-8332-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:30:31.239: INFO: Pod projected-volume-e696bfee-8332-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:30:31.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5kd2x" for this suite.
May 30 23:30:37.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:30:37.286: INFO: namespace: e2e-tests-projected-5kd2x, resource: bindings, ignored listing per whitelist
May 30 23:30:37.323: INFO: namespace e2e-tests-projected-5kd2x deletion completed in 6.080796457s

• [SLOW TEST:12.221 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:30:37.323: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap e2e-tests-configmap-zvrff/configmap-test-eddfadeb-8332-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 23:30:37.405: INFO: Waiting up to 5m0s for pod "pod-configmaps-ede02188-8332-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-configmap-zvrff" to be "success or failure"
May 30 23:30:37.417: INFO: Pod "pod-configmaps-ede02188-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 11.315581ms
May 30 23:30:39.420: INFO: Pod "pod-configmaps-ede02188-8332-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014424197s
May 30 23:30:41.423: INFO: Pod "pod-configmaps-ede02188-8332-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017564925s
STEP: Saw pod success
May 30 23:30:41.423: INFO: Pod "pod-configmaps-ede02188-8332-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:30:41.425: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-configmaps-ede02188-8332-11e9-a3e0-52e03c2e65ea container env-test: <nil>
STEP: delete the pod
May 30 23:30:41.448: INFO: Waiting for pod pod-configmaps-ede02188-8332-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:30:41.450: INFO: Pod pod-configmaps-ede02188-8332-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:30:41.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zvrff" for this suite.
May 30 23:30:47.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:30:47.506: INFO: namespace: e2e-tests-configmap-zvrff, resource: bindings, ignored listing per whitelist
May 30 23:30:47.545: INFO: namespace e2e-tests-configmap-zvrff deletion completed in 6.090725516s

• [SLOW TEST:10.222 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:30:47.547: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-7qhq8
May 30 23:30:51.653: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-7qhq8
STEP: checking the pod's current state and verifying that restartCount is present
May 30 23:30:51.655: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:34:52.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-7qhq8" for this suite.
May 30 23:34:58.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:34:58.234: INFO: namespace: e2e-tests-container-probe-7qhq8, resource: bindings, ignored listing per whitelist
May 30 23:34:58.277: INFO: namespace e2e-tests-container-probe-7qhq8 deletion completed in 6.092921898s

• [SLOW TEST:250.730 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:34:58.277: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:36
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test hostPath mode
May 30 23:34:58.364: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-wwq8v" to be "success or failure"
May 30 23:34:58.369: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.836095ms
May 30 23:35:00.373: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008915871s
May 30 23:35:02.379: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015175553s
STEP: Saw pod success
May 30 23:35:02.379: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 30 23:35:02.385: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 30 23:35:02.418: INFO: Waiting for pod pod-host-path-test to disappear
May 30 23:35:02.421: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:35:02.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-wwq8v" for this suite.
May 30 23:35:08.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:35:08.467: INFO: namespace: e2e-tests-hostpath-wwq8v, resource: bindings, ignored listing per whitelist
May 30 23:35:08.520: INFO: namespace e2e-tests-hostpath-wwq8v deletion completed in 6.095452601s

• [SLOW TEST:10.243 seconds]
[sig-storage] HostPath
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:33
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:35:08.520: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating Redis RC
May 30 23:35:08.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-gt27q'
May 30 23:35:09.248: INFO: stderr: ""
May 30 23:35:09.248: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 30 23:35:10.251: INFO: Selector matched 1 pods for map[app:redis]
May 30 23:35:10.251: INFO: Found 0 / 1
May 30 23:35:11.251: INFO: Selector matched 1 pods for map[app:redis]
May 30 23:35:11.251: INFO: Found 0 / 1
May 30 23:35:12.251: INFO: Selector matched 1 pods for map[app:redis]
May 30 23:35:12.251: INFO: Found 1 / 1
May 30 23:35:12.251: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 30 23:35:12.253: INFO: Selector matched 1 pods for map[app:redis]
May 30 23:35:12.253: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 30 23:35:12.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 patch pod redis-master-dm966 --namespace=e2e-tests-kubectl-gt27q -p {"metadata":{"annotations":{"x":"y"}}}'
May 30 23:35:12.364: INFO: stderr: ""
May 30 23:35:12.364: INFO: stdout: "pod/redis-master-dm966 patched\n"
STEP: checking annotations
May 30 23:35:12.367: INFO: Selector matched 1 pods for map[app:redis]
May 30 23:35:12.367: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:35:12.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gt27q" for this suite.
May 30 23:35:34.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:35:34.441: INFO: namespace: e2e-tests-kubectl-gt27q, resource: bindings, ignored listing per whitelist
May 30 23:35:34.466: INFO: namespace e2e-tests-kubectl-gt27q deletion completed in 22.096301569s

• [SLOW TEST:25.946 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:35:34.467: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating all guestbook components
May 30 23:35:34.546: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 30 23:35:34.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-r2m7s'
May 30 23:35:34.819: INFO: stderr: ""
May 30 23:35:34.819: INFO: stdout: "service/redis-slave created\n"
May 30 23:35:34.820: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 30 23:35:34.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-r2m7s'
May 30 23:35:35.066: INFO: stderr: ""
May 30 23:35:35.066: INFO: stdout: "service/redis-master created\n"
May 30 23:35:35.066: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 30 23:35:35.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-r2m7s'
May 30 23:35:35.295: INFO: stderr: ""
May 30 23:35:35.295: INFO: stdout: "service/frontend created\n"
May 30 23:35:35.295: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend-amd64:v5
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 30 23:35:35.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-r2m7s'
May 30 23:35:35.536: INFO: stderr: ""
May 30 23:35:35.536: INFO: stdout: "deployment.extensions/frontend created\n"
May 30 23:35:35.536: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 30 23:35:35.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-r2m7s'
May 30 23:35:35.790: INFO: stderr: ""
May 30 23:35:35.790: INFO: stdout: "deployment.extensions/redis-master created\n"
May 30 23:35:35.790: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave-amd64:v2
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 30 23:35:35.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-r2m7s'
May 30 23:35:36.579: INFO: stderr: ""
May 30 23:35:36.579: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
May 30 23:35:36.579: INFO: Waiting for all frontend pods to be Running.
May 30 23:36:11.630: INFO: Waiting for frontend to serve content.
May 30 23:36:11.700: INFO: Trying to add a new entry to the guestbook.
May 30 23:36:11.723: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
May 30 23:36:11.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-r2m7s'
May 30 23:36:11.881: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 30 23:36:11.881: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May 30 23:36:11.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-r2m7s'
May 30 23:36:12.030: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 30 23:36:12.030: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 30 23:36:12.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-r2m7s'
May 30 23:36:12.176: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 30 23:36:12.176: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 30 23:36:12.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-r2m7s'
May 30 23:36:12.295: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 30 23:36:12.295: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 30 23:36:12.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-r2m7s'
May 30 23:36:12.438: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 30 23:36:12.438: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 30 23:36:12.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-r2m7s'
May 30 23:36:12.568: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 30 23:36:12.568: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:36:12.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r2m7s" for this suite.
May 30 23:36:54.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:36:54.637: INFO: namespace: e2e-tests-kubectl-r2m7s, resource: bindings, ignored listing per whitelist
May 30 23:36:54.659: INFO: namespace e2e-tests-kubectl-r2m7s deletion completed in 42.085927173s

• [SLOW TEST:80.192 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:36:54.659: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1012
STEP: creating the pod
May 30 23:36:54.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-2gchb'
May 30 23:36:54.981: INFO: stderr: ""
May 30 23:36:54.981: INFO: stdout: "pod/pause created\n"
May 30 23:36:54.981: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 30 23:36:54.981: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-2gchb" to be "running and ready"
May 30 23:36:54.985: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.892796ms
May 30 23:36:56.988: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00691323s
May 30 23:36:58.991: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.010004569s
May 30 23:36:58.991: INFO: Pod "pause" satisfied condition "running and ready"
May 30 23:36:58.991: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: adding the label testing-label with value testing-label-value to a pod
May 30 23:36:58.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-2gchb'
May 30 23:36:59.109: INFO: stderr: ""
May 30 23:36:59.109: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 30 23:36:59.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pod pause -L testing-label --namespace=e2e-tests-kubectl-2gchb'
May 30 23:36:59.229: INFO: stderr: ""
May 30 23:36:59.229: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          5s        testing-label-value\n"
STEP: removing the label testing-label of a pod
May 30 23:36:59.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 label pods pause testing-label- --namespace=e2e-tests-kubectl-2gchb'
May 30 23:36:59.350: INFO: stderr: ""
May 30 23:36:59.350: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 30 23:36:59.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pod pause -L testing-label --namespace=e2e-tests-kubectl-2gchb'
May 30 23:36:59.462: INFO: stderr: ""
May 30 23:36:59.462: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          5s        \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1018
STEP: using delete to clean up resources
May 30 23:36:59.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2gchb'
May 30 23:36:59.576: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 30 23:36:59.576: INFO: stdout: "pod \"pause\" force deleted\n"
May 30 23:36:59.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-2gchb'
May 30 23:36:59.705: INFO: stderr: "No resources found.\n"
May 30 23:36:59.705: INFO: stdout: ""
May 30 23:36:59.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -l name=pause --namespace=e2e-tests-kubectl-2gchb -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 30 23:36:59.823: INFO: stderr: ""
May 30 23:36:59.823: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:36:59.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2gchb" for this suite.
May 30 23:37:05.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:37:05.879: INFO: namespace: e2e-tests-kubectl-2gchb, resource: bindings, ignored listing per whitelist
May 30 23:37:05.908: INFO: namespace e2e-tests-kubectl-2gchb deletion completed in 6.08121689s

• [SLOW TEST:11.249 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:37:05.909: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 30 23:37:10.503: INFO: Successfully updated pod "pod-update-d57cf787-8333-11e9-a3e0-52e03c2e65ea"
STEP: verifying the updated pod is in kubernetes
May 30 23:37:10.509: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:37:10.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mtzcf" for this suite.
May 30 23:37:32.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:37:32.601: INFO: namespace: e2e-tests-pods-mtzcf, resource: bindings, ignored listing per whitelist
May 30 23:37:32.603: INFO: namespace e2e-tests-pods-mtzcf deletion completed in 22.091332763s

• [SLOW TEST:26.695 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:37:32.604: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-e566e1c5-8333-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume configMaps
May 30 23:37:32.688: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e5675edc-8333-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-s6wkb" to be "success or failure"
May 30 23:37:32.693: INFO: Pod "pod-projected-configmaps-e5675edc-8333-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.069996ms
May 30 23:37:34.696: INFO: Pod "pod-projected-configmaps-e5675edc-8333-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008277928s
May 30 23:37:36.699: INFO: Pod "pod-projected-configmaps-e5675edc-8333-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011474265s
STEP: Saw pod success
May 30 23:37:36.700: INFO: Pod "pod-projected-configmaps-e5675edc-8333-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:37:36.702: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-projected-configmaps-e5675edc-8333-11e9-a3e0-52e03c2e65ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 30 23:37:36.720: INFO: Waiting for pod pod-projected-configmaps-e5675edc-8333-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:37:36.722: INFO: Pod pod-projected-configmaps-e5675edc-8333-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:37:36.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s6wkb" for this suite.
May 30 23:37:42.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:37:42.770: INFO: namespace: e2e-tests-projected-s6wkb, resource: bindings, ignored listing per whitelist
May 30 23:37:42.815: INFO: namespace e2e-tests-projected-s6wkb deletion completed in 6.089947972s

• [SLOW TEST:10.211 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:37:42.815: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the initial replication controller
May 30 23:37:42.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 create -f - --namespace=e2e-tests-kubectl-dbf9d'
May 30 23:37:43.099: INFO: stderr: ""
May 30 23:37:43.099: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 30 23:37:43.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dbf9d'
May 30 23:37:43.221: INFO: stderr: ""
May 30 23:37:43.221: INFO: stdout: "update-demo-nautilus-qch42 update-demo-nautilus-wzx4v "
May 30 23:37:43.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-qch42 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dbf9d'
May 30 23:37:43.327: INFO: stderr: ""
May 30 23:37:43.327: INFO: stdout: ""
May 30 23:37:43.327: INFO: update-demo-nautilus-qch42 is created but not running
May 30 23:37:48.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dbf9d'
May 30 23:37:48.443: INFO: stderr: ""
May 30 23:37:48.443: INFO: stdout: "update-demo-nautilus-qch42 update-demo-nautilus-wzx4v "
May 30 23:37:48.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-qch42 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dbf9d'
May 30 23:37:48.566: INFO: stderr: ""
May 30 23:37:48.566: INFO: stdout: "true"
May 30 23:37:48.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-qch42 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dbf9d'
May 30 23:37:48.684: INFO: stderr: ""
May 30 23:37:48.684: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 30 23:37:48.684: INFO: validating pod update-demo-nautilus-qch42
May 30 23:37:48.688: INFO: got data: {
  "image": "nautilus.jpg"
}

May 30 23:37:48.689: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 30 23:37:48.689: INFO: update-demo-nautilus-qch42 is verified up and running
May 30 23:37:48.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-wzx4v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dbf9d'
May 30 23:37:48.802: INFO: stderr: ""
May 30 23:37:48.802: INFO: stdout: "true"
May 30 23:37:48.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-nautilus-wzx4v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dbf9d'
May 30 23:37:48.920: INFO: stderr: ""
May 30 23:37:48.920: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 30 23:37:48.920: INFO: validating pod update-demo-nautilus-wzx4v
May 30 23:37:48.925: INFO: got data: {
  "image": "nautilus.jpg"
}

May 30 23:37:48.925: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 30 23:37:48.925: INFO: update-demo-nautilus-wzx4v is verified up and running
STEP: rolling-update to new replication controller
May 30 23:37:48.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-dbf9d'
May 30 23:38:11.364: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 30 23:38:11.364: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 30 23:38:11.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dbf9d'
May 30 23:38:11.470: INFO: stderr: ""
May 30 23:38:11.470: INFO: stdout: "update-demo-kitten-5r2f6 update-demo-kitten-tfw8g "
May 30 23:38:11.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-kitten-5r2f6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dbf9d'
May 30 23:38:11.577: INFO: stderr: ""
May 30 23:38:11.577: INFO: stdout: "true"
May 30 23:38:11.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-kitten-5r2f6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dbf9d'
May 30 23:38:11.673: INFO: stderr: ""
May 30 23:38:11.673: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-amd64:1.0"
May 30 23:38:11.673: INFO: validating pod update-demo-kitten-5r2f6
May 30 23:38:11.677: INFO: got data: {
  "image": "kitten.jpg"
}

May 30 23:38:11.677: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 30 23:38:11.677: INFO: update-demo-kitten-5r2f6 is verified up and running
May 30 23:38:11.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-kitten-tfw8g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dbf9d'
May 30 23:38:11.798: INFO: stderr: ""
May 30 23:38:11.798: INFO: stdout: "true"
May 30 23:38:11.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 get pods update-demo-kitten-tfw8g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dbf9d'
May 30 23:38:11.905: INFO: stderr: ""
May 30 23:38:11.905: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-amd64:1.0"
May 30 23:38:11.905: INFO: validating pod update-demo-kitten-tfw8g
May 30 23:38:11.909: INFO: got data: {
  "image": "kitten.jpg"
}

May 30 23:38:11.910: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 30 23:38:11.910: INFO: update-demo-kitten-tfw8g is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:38:11.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dbf9d" for this suite.
May 30 23:38:33.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:38:33.957: INFO: namespace: e2e-tests-kubectl-dbf9d, resource: bindings, ignored listing per whitelist
May 30 23:38:34.002: INFO: namespace e2e-tests-kubectl-dbf9d deletion completed in 22.089579912s

• [SLOW TEST:51.187 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:38:34.002: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-0a00eaf8-8334-11e9-a3e0-52e03c2e65ea,GenerateName:,Namespace:e2e-tests-events-rjfm6,SelfLink:/api/v1/namespaces/e2e-tests-events-rjfm6/pods/send-events-0a00eaf8-8334-11e9-a3e0-52e03c2e65ea,UID:0a01bffc-8334-11e9-9b52-001dd80c000f,ResourceVersion:16397,Generation:0,CreationTimestamp:2019-05-30 23:38:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 88118523,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jqzxw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jqzxw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-jqzxw true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-35502656-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420f19110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420f19130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 23:38:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 23:38:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 23:38:34 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.1.114,StartTime:2019-05-30 23:38:34 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-30 23:38:36 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64@sha256:2dd4032e98a0450d95a0ac71a5e465f542a900812d8c41bc6ca635aed1a5fc91 docker://694f2bfd7936f4acb733d5ac9363a86c64236ec96998f6702db896f12cff9911}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
STEP: checking for scheduler event about the pod
Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:38:42.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-rjfm6" for this suite.
May 30 23:38:48.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:38:48.173: INFO: namespace: e2e-tests-events-rjfm6, resource: bindings, ignored listing per whitelist
May 30 23:38:48.212: INFO: namespace e2e-tests-events-rjfm6 deletion completed in 6.089027139s

• [SLOW TEST:14.209 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:38:48.213: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override arguments
May 30 23:38:48.295: INFO: Waiting up to 5m0s for pod "client-containers-1277b391-8334-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-containers-dcpjj" to be "success or failure"
May 30 23:38:48.299: INFO: Pod "client-containers-1277b391-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.482696ms
May 30 23:38:50.303: INFO: Pod "client-containers-1277b391-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007758906s
May 30 23:38:52.305: INFO: Pod "client-containers-1277b391-8334-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01050082s
STEP: Saw pod success
May 30 23:38:52.305: INFO: Pod "client-containers-1277b391-8334-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:38:52.308: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod client-containers-1277b391-8334-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 23:38:52.321: INFO: Waiting for pod client-containers-1277b391-8334-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:38:52.323: INFO: Pod client-containers-1277b391-8334-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:38:52.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-dcpjj" for this suite.
May 30 23:38:58.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:38:58.386: INFO: namespace: e2e-tests-containers-dcpjj, resource: bindings, ignored listing per whitelist
May 30 23:38:58.419: INFO: namespace e2e-tests-containers-dcpjj deletion completed in 6.091839504s

• [SLOW TEST:10.206 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:38:58.420: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-klrc4
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a new StatefulSet
May 30 23:38:58.508: INFO: Found 0 stateful pods, waiting for 3
May 30 23:39:08.512: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 30 23:39:08.512: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 30 23:39:08.512: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 30 23:39:08.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-klrc4 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 30 23:39:08.786: INFO: stderr: ""
May 30 23:39:08.786: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 30 23:39:08.786: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
May 30 23:39:18.813: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 30 23:39:28.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-klrc4 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 23:39:29.087: INFO: stderr: ""
May 30 23:39:29.087: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 30 23:39:29.087: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 30 23:39:39.103: INFO: Waiting for StatefulSet e2e-tests-statefulset-klrc4/ss2 to complete update
May 30 23:39:39.103: INFO: Waiting for Pod e2e-tests-statefulset-klrc4/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
May 30 23:39:39.103: INFO: Waiting for Pod e2e-tests-statefulset-klrc4/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
May 30 23:39:39.103: INFO: Waiting for Pod e2e-tests-statefulset-klrc4/ss2-2 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
May 30 23:39:49.110: INFO: Waiting for StatefulSet e2e-tests-statefulset-klrc4/ss2 to complete update
May 30 23:39:49.110: INFO: Waiting for Pod e2e-tests-statefulset-klrc4/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
May 30 23:39:49.110: INFO: Waiting for Pod e2e-tests-statefulset-klrc4/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
May 30 23:39:59.109: INFO: Waiting for StatefulSet e2e-tests-statefulset-klrc4/ss2 to complete update
STEP: Rolling back to a previous revision
May 30 23:40:09.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-klrc4 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 30 23:40:09.382: INFO: stderr: ""
May 30 23:40:09.382: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 30 23:40:09.382: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 30 23:40:19.409: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 30 23:40:29.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-884905328 exec --namespace=e2e-tests-statefulset-klrc4 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 30 23:40:29.698: INFO: stderr: ""
May 30 23:40:29.698: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 30 23:40:29.698: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 30 23:40:39.713: INFO: Waiting for StatefulSet e2e-tests-statefulset-klrc4/ss2 to complete update
May 30 23:40:39.713: INFO: Waiting for Pod e2e-tests-statefulset-klrc4/ss2-0 to have revision ss2-76cb68b6ff update revision ss2-56dd5fb9c4
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 30 23:40:49.718: INFO: Deleting all statefulset in ns e2e-tests-statefulset-klrc4
May 30 23:40:49.721: INFO: Scaling statefulset ss2 to 0
May 30 23:41:09.733: INFO: Waiting for statefulset status.replicas updated to 0
May 30 23:41:09.735: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:41:09.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-klrc4" for this suite.
May 30 23:41:15.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:41:15.788: INFO: namespace: e2e-tests-statefulset-klrc4, resource: bindings, ignored listing per whitelist
May 30 23:41:15.844: INFO: namespace e2e-tests-statefulset-klrc4 deletion completed in 6.092673591s

• [SLOW TEST:137.425 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:41:15.844: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 23:41:15.938: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a76f135-8334-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-8hpv4" to be "success or failure"
May 30 23:41:15.944: INFO: Pod "downwardapi-volume-6a76f135-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.353396ms
May 30 23:41:17.947: INFO: Pod "downwardapi-volume-6a76f135-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008765085s
May 30 23:41:19.950: INFO: Pod "downwardapi-volume-6a76f135-8334-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011729077s
STEP: Saw pod success
May 30 23:41:19.950: INFO: Pod "downwardapi-volume-6a76f135-8334-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:41:19.953: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod downwardapi-volume-6a76f135-8334-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 23:41:19.972: INFO: Waiting for pod downwardapi-volume-6a76f135-8334-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:41:19.977: INFO: Pod downwardapi-volume-6a76f135-8334-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:41:19.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8hpv4" for this suite.
May 30 23:41:25.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:41:26.066: INFO: namespace: e2e-tests-projected-8hpv4, resource: bindings, ignored listing per whitelist
May 30 23:41:26.070: INFO: namespace e2e-tests-projected-8hpv4 deletion completed in 6.090058144s

• [SLOW TEST:10.226 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:41:26.070: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-map-708ed971-8334-11e9-a3e0-52e03c2e65ea
STEP: Creating a pod to test consume secrets
May 30 23:41:26.154: INFO: Waiting up to 5m0s for pod "pod-secrets-708f63f0-8334-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-secrets-pvsv9" to be "success or failure"
May 30 23:41:26.160: INFO: Pod "pod-secrets-708f63f0-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.522696ms
May 30 23:41:28.164: INFO: Pod "pod-secrets-708f63f0-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010477001s
May 30 23:41:30.167: INFO: Pod "pod-secrets-708f63f0-8334-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013894109s
STEP: Saw pod success
May 30 23:41:30.168: INFO: Pod "pod-secrets-708f63f0-8334-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:41:30.170: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-secrets-708f63f0-8334-11e9-a3e0-52e03c2e65ea container secret-volume-test: <nil>
STEP: delete the pod
May 30 23:41:30.186: INFO: Waiting for pod pod-secrets-708f63f0-8334-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:41:30.190: INFO: Pod pod-secrets-708f63f0-8334-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:41:30.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pvsv9" for this suite.
May 30 23:41:36.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:41:36.259: INFO: namespace: e2e-tests-secrets-pvsv9, resource: bindings, ignored listing per whitelist
May 30 23:41:36.278: INFO: namespace e2e-tests-secrets-pvsv9 deletion completed in 6.084367596s

• [SLOW TEST:10.208 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:41:36.278: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test env composition
May 30 23:41:36.356: INFO: Waiting up to 5m0s for pod "var-expansion-76a40548-8334-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-var-expansion-bwvnt" to be "success or failure"
May 30 23:41:36.362: INFO: Pod "var-expansion-76a40548-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.210996ms
May 30 23:41:38.365: INFO: Pod "var-expansion-76a40548-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009460517s
May 30 23:41:40.368: INFO: Pod "var-expansion-76a40548-8334-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012696542s
STEP: Saw pod success
May 30 23:41:40.368: INFO: Pod "var-expansion-76a40548-8334-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:41:40.370: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod var-expansion-76a40548-8334-11e9-a3e0-52e03c2e65ea container dapi-container: <nil>
STEP: delete the pod
May 30 23:41:40.427: INFO: Waiting for pod var-expansion-76a40548-8334-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:41:40.430: INFO: Pod var-expansion-76a40548-8334-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:41:40.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-bwvnt" for this suite.
May 30 23:41:46.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:41:46.499: INFO: namespace: e2e-tests-var-expansion-bwvnt, resource: bindings, ignored listing per whitelist
May 30 23:41:46.526: INFO: namespace e2e-tests-var-expansion-bwvnt deletion completed in 6.091786341s

• [SLOW TEST:10.247 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:41:46.526: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
May 30 23:41:46.620: INFO: Waiting up to 5m0s for pod "downward-api-7cc1f6c2-8334-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-downward-api-klc4g" to be "success or failure"
May 30 23:41:46.627: INFO: Pod "downward-api-7cc1f6c2-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.956795ms
May 30 23:41:48.630: INFO: Pod "downward-api-7cc1f6c2-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010225132s
May 30 23:41:50.634: INFO: Pod "downward-api-7cc1f6c2-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013956273s
May 30 23:41:52.637: INFO: Pod "downward-api-7cc1f6c2-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016920716s
May 30 23:41:54.640: INFO: Pod "downward-api-7cc1f6c2-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 8.020635262s
May 30 23:41:56.725: INFO: Pod "downward-api-7cc1f6c2-8334-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.105456661s
STEP: Saw pod success
May 30 23:41:56.725: INFO: Pod "downward-api-7cc1f6c2-8334-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:41:56.728: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod downward-api-7cc1f6c2-8334-11e9-a3e0-52e03c2e65ea container dapi-container: <nil>
STEP: delete the pod
May 30 23:41:56.746: INFO: Waiting for pod downward-api-7cc1f6c2-8334-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:41:56.750: INFO: Pod downward-api-7cc1f6c2-8334-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:41:56.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-klc4g" for this suite.
May 30 23:42:02.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:42:02.789: INFO: namespace: e2e-tests-downward-api-klc4g, resource: bindings, ignored listing per whitelist
May 30 23:42:02.842: INFO: namespace e2e-tests-downward-api-klc4g deletion completed in 6.088591118s

• [SLOW TEST:16.316 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:42:02.845: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: getting the auto-created API token
May 30 23:42:03.444: INFO: created pod pod-service-account-defaultsa
May 30 23:42:03.444: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 30 23:42:03.449: INFO: created pod pod-service-account-mountsa
May 30 23:42:03.449: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 30 23:42:03.452: INFO: created pod pod-service-account-nomountsa
May 30 23:42:03.452: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 30 23:42:03.459: INFO: created pod pod-service-account-defaultsa-mountspec
May 30 23:42:03.459: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 30 23:42:03.470: INFO: created pod pod-service-account-mountsa-mountspec
May 30 23:42:03.470: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 30 23:42:03.481: INFO: created pod pod-service-account-nomountsa-mountspec
May 30 23:42:03.481: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 30 23:42:03.491: INFO: created pod pod-service-account-defaultsa-nomountspec
May 30 23:42:03.491: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 30 23:42:03.501: INFO: created pod pod-service-account-mountsa-nomountspec
May 30 23:42:03.501: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 30 23:42:03.512: INFO: created pod pod-service-account-nomountsa-nomountspec
May 30 23:42:03.512: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:42:03.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-fntd5" for this suite.
May 30 23:42:09.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:42:09.572: INFO: namespace: e2e-tests-svcaccounts-fntd5, resource: bindings, ignored listing per whitelist
May 30 23:42:09.614: INFO: namespace e2e-tests-svcaccounts-fntd5 deletion completed in 6.087926949s

• [SLOW TEST:6.770 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:42:09.615: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 30 23:42:09.691: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8a82858e-8334-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-projected-wr72s" to be "success or failure"
May 30 23:42:09.694: INFO: Pod "downwardapi-volume-8a82858e-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.734198ms
May 30 23:42:11.697: INFO: Pod "downwardapi-volume-8a82858e-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00563997s
May 30 23:42:13.700: INFO: Pod "downwardapi-volume-8a82858e-8334-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008591345s
STEP: Saw pod success
May 30 23:42:13.700: INFO: Pod "downwardapi-volume-8a82858e-8334-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:42:13.702: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod downwardapi-volume-8a82858e-8334-11e9-a3e0-52e03c2e65ea container client-container: <nil>
STEP: delete the pod
May 30 23:42:13.718: INFO: Waiting for pod downwardapi-volume-8a82858e-8334-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:42:13.720: INFO: Pod downwardapi-volume-8a82858e-8334-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:42:13.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wr72s" for this suite.
May 30 23:42:19.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:42:19.807: INFO: namespace: e2e-tests-projected-wr72s, resource: bindings, ignored listing per whitelist
May 30 23:42:19.830: INFO: namespace e2e-tests-projected-wr72s deletion completed in 6.106330683s

• [SLOW TEST:10.215 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:42:19.831: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on node default medium
May 30 23:42:19.921: INFO: Waiting up to 5m0s for pod "pod-909b9e14-8334-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-emptydir-z2zjp" to be "success or failure"
May 30 23:42:19.926: INFO: Pod "pod-909b9e14-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.736497ms
May 30 23:42:21.930: INFO: Pod "pod-909b9e14-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008265284s
May 30 23:42:23.933: INFO: Pod "pod-909b9e14-8334-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011641073s
STEP: Saw pod success
May 30 23:42:23.933: INFO: Pod "pod-909b9e14-8334-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:42:23.935: INFO: Trying to get logs from node k8s-linuxpool-35502656-1 pod pod-909b9e14-8334-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 23:42:23.951: INFO: Waiting for pod pod-909b9e14-8334-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:42:23.953: INFO: Pod pod-909b9e14-8334-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:42:23.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z2zjp" for this suite.
May 30 23:42:29.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:42:29.987: INFO: namespace: e2e-tests-emptydir-z2zjp, resource: bindings, ignored listing per whitelist
May 30 23:42:30.042: INFO: namespace e2e-tests-emptydir-z2zjp deletion completed in 6.08613994s

• [SLOW TEST:10.212 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:42:30.043: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
May 30 23:42:30.121: INFO: Waiting up to 1m0s for all nodes to be ready
May 30 23:43:30.151: INFO: Waiting for terminating namespaces to be deleted...
May 30 23:43:30.157: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 30 23:43:30.167: INFO: 21 / 21 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 30 23:43:30.167: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
May 30 23:43:30.170: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 30 23:43:30.170: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-35502656-0 before test
May 30 23:43:30.184: INFO: kube-flannel-ds-9zr2x from kube-system started at 2019-05-30 22:22:00 +0000 UTC (2 container statuses recorded)
May 30 23:43:30.184: INFO: 	Container install-cni ready: true, restart count 0
May 30 23:43:30.184: INFO: 	Container kube-flannel ready: true, restart count 1
May 30 23:43:30.184: INFO: azure-ip-masq-agent-smv6c from kube-system started at 2019-05-30 22:22:04 +0000 UTC (1 container statuses recorded)
May 30 23:43:30.184: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 30 23:43:30.184: INFO: kube-proxy-z8rb2 from kube-system started at 2019-05-30 22:22:06 +0000 UTC (1 container statuses recorded)
May 30 23:43:30.184: INFO: 	Container kube-proxy ready: true, restart count 0
May 30 23:43:30.184: INFO: sonobuoy-e2e-job-3baf2c430e984a69 from heptio-sonobuoy started at 2019-05-30 22:23:55 +0000 UTC (2 container statuses recorded)
May 30 23:43:30.185: INFO: 	Container e2e ready: true, restart count 0
May 30 23:43:30.185: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 30 23:43:30.185: INFO: sonobuoy-systemd-logs-daemon-set-261c7e37e22c4229-8qlhf from heptio-sonobuoy started at 2019-05-30 22:23:55 +0000 UTC (2 container statuses recorded)
May 30 23:43:30.185: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
May 30 23:43:30.185: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 30 23:43:30.185: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-35502656-1 before test
May 30 23:43:30.190: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-30 22:23:50 +0000 UTC (1 container statuses recorded)
May 30 23:43:30.190: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 30 23:43:30.190: INFO: azure-ip-masq-agent-kjjv4 from kube-system started at 2019-05-30 22:22:04 +0000 UTC (1 container statuses recorded)
May 30 23:43:30.190: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 30 23:43:30.190: INFO: kube-proxy-htm6x from kube-system started at 2019-05-30 22:22:06 +0000 UTC (1 container statuses recorded)
May 30 23:43:30.190: INFO: 	Container kube-proxy ready: true, restart count 0
May 30 23:43:30.190: INFO: sonobuoy-systemd-logs-daemon-set-261c7e37e22c4229-x5q4v from heptio-sonobuoy started at 2019-05-30 22:23:56 +0000 UTC (2 container statuses recorded)
May 30 23:43:30.190: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
May 30 23:43:30.190: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 30 23:43:30.190: INFO: kube-flannel-ds-4vsxq from kube-system started at 2019-05-30 22:22:00 +0000 UTC (2 container statuses recorded)
May 30 23:43:30.190: INFO: 	Container install-cni ready: true, restart count 0
May 30 23:43:30.190: INFO: 	Container kube-flannel ready: true, restart count 1
May 30 23:43:30.190: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-35502656-2 before test
May 30 23:43:30.197: INFO: kube-flannel-ds-sqz6f from kube-system started at 2019-05-30 22:22:00 +0000 UTC (2 container statuses recorded)
May 30 23:43:30.197: INFO: 	Container install-cni ready: true, restart count 0
May 30 23:43:30.197: INFO: 	Container kube-flannel ready: true, restart count 0
May 30 23:43:30.197: INFO: azure-ip-masq-agent-fsw9b from kube-system started at 2019-05-30 22:22:04 +0000 UTC (1 container statuses recorded)
May 30 23:43:30.197: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 30 23:43:30.197: INFO: heapster-656495f65d-qxhm2 from kube-system started at 2019-05-30 22:22:19 +0000 UTC (2 container statuses recorded)
May 30 23:43:30.197: INFO: 	Container heapster ready: true, restart count 0
May 30 23:43:30.197: INFO: 	Container heapster-nanny ready: true, restart count 0
May 30 23:43:30.197: INFO: sonobuoy-systemd-logs-daemon-set-261c7e37e22c4229-nrn2p from heptio-sonobuoy started at 2019-05-30 22:23:55 +0000 UTC (2 container statuses recorded)
May 30 23:43:30.197: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
May 30 23:43:30.197: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 30 23:43:30.197: INFO: kube-proxy-wvb9t from kube-system started at 2019-05-30 22:22:06 +0000 UTC (1 container statuses recorded)
May 30 23:43:30.197: INFO: 	Container kube-proxy ready: true, restart count 0
May 30 23:43:30.197: INFO: metrics-server-5fdc668b9b-dg829 from kube-system started at 2019-05-30 22:22:19 +0000 UTC (1 container statuses recorded)
May 30 23:43:30.197: INFO: 	Container metrics-server ready: true, restart count 0
May 30 23:43:30.197: INFO: kube-dns-5f74bfc48d-wm2n9 from kube-system started at 2019-05-30 22:22:19 +0000 UTC (3 container statuses recorded)
May 30 23:43:30.197: INFO: 	Container dnsmasq ready: true, restart count 0
May 30 23:43:30.197: INFO: 	Container kubedns ready: true, restart count 0
May 30 23:43:30.197: INFO: 	Container sidecar ready: true, restart count 0
May 30 23:43:30.197: INFO: kubernetes-dashboard-7b5859758b-pc5gq from kube-system started at 2019-05-30 22:22:19 +0000 UTC (1 container statuses recorded)
May 30 23:43:30.197: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 30 23:43:30.197: INFO: tiller-deploy-88c69b9b-tp65w from kube-system started at 2019-05-30 22:22:19 +0000 UTC (1 container statuses recorded)
May 30 23:43:30.197: INFO: 	Container tiller ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15a39a893cb7d57a], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:43:31.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-f4bsf" for this suite.
May 30 23:43:37.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:43:37.288: INFO: namespace: e2e-tests-sched-pred-f4bsf, resource: bindings, ignored listing per whitelist
May 30 23:43:37.304: INFO: namespace e2e-tests-sched-pred-f4bsf deletion completed in 6.079158617s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

• [SLOW TEST:67.261 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:43:37.304: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on node default medium
May 30 23:43:37.398: INFO: Waiting up to 5m0s for pod "pod-bec98c23-8334-11e9-a3e0-52e03c2e65ea" in namespace "e2e-tests-emptydir-hlz6g" to be "success or failure"
May 30 23:43:37.401: INFO: Pod "pod-bec98c23-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.459898ms
May 30 23:43:39.404: INFO: Pod "pod-bec98c23-8334-11e9-a3e0-52e03c2e65ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006420589s
May 30 23:43:41.407: INFO: Pod "pod-bec98c23-8334-11e9-a3e0-52e03c2e65ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009374082s
STEP: Saw pod success
May 30 23:43:41.407: INFO: Pod "pod-bec98c23-8334-11e9-a3e0-52e03c2e65ea" satisfied condition "success or failure"
May 30 23:43:41.410: INFO: Trying to get logs from node k8s-linuxpool-35502656-0 pod pod-bec98c23-8334-11e9-a3e0-52e03c2e65ea container test-container: <nil>
STEP: delete the pod
May 30 23:43:41.432: INFO: Waiting for pod pod-bec98c23-8334-11e9-a3e0-52e03c2e65ea to disappear
May 30 23:43:41.434: INFO: Pod pod-bec98c23-8334-11e9-a3e0-52e03c2e65ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:43:41.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hlz6g" for this suite.
May 30 23:43:47.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:43:47.562: INFO: namespace: e2e-tests-emptydir-hlz6g, resource: bindings, ignored listing per whitelist
May 30 23:43:47.589: INFO: namespace e2e-tests-emptydir-hlz6g deletion completed in 6.092921948s

• [SLOW TEST:10.285 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 30 23:43:47.589: INFO: >>> kubeConfig: /tmp/kubeconfig-884905328
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
May 30 23:43:52.203: INFO: Successfully updated pod "annotationupdatec4ea4b7b-8334-11e9-a3e0-52e03c2e65ea"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 30 23:43:54.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-crldx" for this suite.
May 30 23:44:16.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 23:44:16.303: INFO: namespace: e2e-tests-downward-api-crldx, resource: bindings, ignored listing per whitelist
May 30 23:44:16.306: INFO: namespace e2e-tests-downward-api-crldx deletion completed in 22.084778124s

• [SLOW TEST:28.716 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
May 30 23:44:16.306: INFO: Running AfterSuite actions on all node
May 30 23:44:16.306: INFO: Running AfterSuite actions on node 1
May 30 23:44:16.306: INFO: Skipping dumping logs from cluster

Ran 165 of 996 Specs in 4763.817 seconds
SUCCESS! -- 165 Passed | 0 Failed | 0 Pending | 831 Skipped PASS

Ginkgo ran 1 suite in 1h19m24.36672158s
Test Suite Passed

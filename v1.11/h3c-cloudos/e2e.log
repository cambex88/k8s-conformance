Aug 28 09:55:28.347: INFO: Overriding default scale value of zero to 1
Aug 28 09:55:28.347: INFO: Overriding default milliseconds value of zero to 5000
I0828 09:55:28.540286   76809 e2e.go:333] Starting e2e run "e8c54072-c936-11e9-a0e2-288023b0a458" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1566957327 - Will randomize all specs
Will run 167 of 998 specs

I0828 09:55:28.581896   76809 e2e.go:59] The --provider flag is not set.  Treating as a conformance test.  Some tests may not be run.
Aug 28 09:55:28.581: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 09:55:28.587: INFO: Waiting up to 30m0s for all (but 3) nodes to be schedulable
Aug 28 09:55:28.616: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 28 09:55:28.660: INFO: 10 / 10 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 28 09:55:28.660: INFO: expected 1 pod replicas in namespace 'kube-system', 1 are Running and Ready.
Aug 28 09:55:28.666: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Aug 28 09:55:28.666: INFO: Dumping network health container logs from all nodes to file /home/conformance/nethealth.txt
Aug 28 09:55:28.671: INFO: e2e test version: v0.0.0-master+$Format:%h$
Aug 28 09:55:28.673: INFO: kube-apiserver version: v1.11.0+d4cacc0
I0828 09:55:28.673735   76809 e2e.go:59] The --provider flag is not set.  Treating as a conformance test.  Some tests may not be run.
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 09:55:28.673: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
Aug 28 09:55:28.960: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Aug 28 09:55:28.997: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-nbklq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-map-e94fb130-c936-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume secrets
Aug 28 09:55:29.253: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e951844b-c936-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-nbklq" to be "success or failure"
Aug 28 09:55:29.279: INFO: Pod "pod-projected-secrets-e951844b-c936-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 26.385819ms
Aug 28 09:55:31.284: INFO: Pod "pod-projected-secrets-e951844b-c936-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031344938s
Aug 28 09:55:33.289: INFO: Pod "pod-projected-secrets-e951844b-c936-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036328575s
Aug 28 09:55:35.294: INFO: Pod "pod-projected-secrets-e951844b-c936-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.041484536s
STEP: Saw pod success
Aug 28 09:55:35.295: INFO: Pod "pod-projected-secrets-e951844b-c936-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 09:55:35.298: INFO: Trying to get logs from node node-124 pod pod-projected-secrets-e951844b-c936-11e9-a0e2-288023b0a458 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 28 09:55:35.348: INFO: Waiting for pod pod-projected-secrets-e951844b-c936-11e9-a0e2-288023b0a458 to disappear
Aug 28 09:55:35.354: INFO: Pod pod-projected-secrets-e951844b-c936-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 09:55:35.354: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nbklq" for this suite.
Aug 28 09:55:43.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 09:55:43.750: INFO: namespace: e2e-tests-projected-nbklq, resource: bindings, ignored listing per whitelist
Aug 28 09:55:46.452: INFO: namespace e2e-tests-projected-nbklq deletion completed in 11.091163177s

• [SLOW TEST:17.779 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 09:55:46.452: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-z5f2c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 09:55:47.042: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f3ec73cc-c936-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-z5f2c" to be "success or failure"
Aug 28 09:55:47.056: INFO: Pod "downwardapi-volume-f3ec73cc-c936-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 13.601395ms
Aug 28 09:55:49.063: INFO: Pod "downwardapi-volume-f3ec73cc-c936-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021211646s
Aug 28 09:55:51.069: INFO: Pod "downwardapi-volume-f3ec73cc-c936-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026288628s
Aug 28 09:55:53.074: INFO: Pod "downwardapi-volume-f3ec73cc-c936-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031334788s
STEP: Saw pod success
Aug 28 09:55:53.074: INFO: Pod "downwardapi-volume-f3ec73cc-c936-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 09:55:53.077: INFO: Trying to get logs from node node-124 pod downwardapi-volume-f3ec73cc-c936-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 09:55:53.139: INFO: Waiting for pod downwardapi-volume-f3ec73cc-c936-11e9-a0e2-288023b0a458 to disappear
Aug 28 09:55:53.142: INFO: Pod downwardapi-volume-f3ec73cc-c936-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 09:55:53.142: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z5f2c" for this suite.
Aug 28 09:56:01.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 09:56:01.299: INFO: namespace: e2e-tests-projected-z5f2c, resource: bindings, ignored listing per whitelist
Aug 28 09:56:04.259: INFO: namespace e2e-tests-projected-z5f2c deletion completed in 11.109723421s

• [SLOW TEST:17.807 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Events
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 09:56:04.260: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-rnfw2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-feb49b59-c936-11e9-a0e2-288023b0a458,GenerateName:,Namespace:e2e-tests-events-rnfw2,SelfLink:/api/v1/namespaces/e2e-tests-events-rnfw2/pods/send-events-feb49b59-c936-11e9-a0e2-288023b0a458,UID:fec9e6d1-c936-11e9-bbca-288023b0a1ec,ResourceVersion:15108843,Generation:0,CreationTimestamp:2019-08-28 09:56:05 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 17698174,},Annotations:map[string]string{openshift.io/scc: anyuid,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-pp4nh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pp4nh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-pp4nh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:&Capabilities{Add:[],Drop:[MKNOD],},Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{node-role.kubernetes.io/compute: true,},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-124,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:&SELinuxOptions{User:,Role:,Type:,Level:s0:c62,c49,},RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 09:56:05 +0800 CST  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 09:56:10 +0800 CST  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 09:56:05 +0800 CST  }],Message:,Reason:,HostIP:172.16.151.81,PodIP:10.243.0.192,StartTime:2019-08-28 09:56:05 +0800 CST,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-28 09:56:10 +0800 CST,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 docker://sha256:7bb86f470b0f81f88b421acf654b851a66462cb9d3a8b35deae45c5feeecb5b7 docker://3c282e7671e6cb1f52d558eab05ab42b23e2ec81b8dfd66b2f2a2594b3b63f49}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
STEP: checking for scheduler event about the pod
Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 09:56:15.295: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-rnfw2" for this suite.
Aug 28 09:56:39.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 09:56:39.462: INFO: namespace: e2e-tests-events-rnfw2, resource: bindings, ignored listing per whitelist
Aug 28 09:56:42.505: INFO: namespace e2e-tests-events-rnfw2 deletion completed in 27.179631903s

• [SLOW TEST:38.246 seconds]
[k8s.io] [sig-node] Events
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 09:56:42.505: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pxbzx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-155472a7-c937-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 09:56:43.256: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-15601983-c937-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-pxbzx" to be "success or failure"
Aug 28 09:56:43.260: INFO: Pod "pod-projected-configmaps-15601983-c937-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.326736ms
Aug 28 09:56:45.266: INFO: Pod "pod-projected-configmaps-15601983-c937-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009605489s
Aug 28 09:56:47.272: INFO: Pod "pod-projected-configmaps-15601983-c937-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016109986s
Aug 28 09:56:49.277: INFO: Pod "pod-projected-configmaps-15601983-c937-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021300733s
STEP: Saw pod success
Aug 28 09:56:49.278: INFO: Pod "pod-projected-configmaps-15601983-c937-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 09:56:49.281: INFO: Trying to get logs from node node-124 pod pod-projected-configmaps-15601983-c937-11e9-a0e2-288023b0a458 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 28 09:56:49.337: INFO: Waiting for pod pod-projected-configmaps-15601983-c937-11e9-a0e2-288023b0a458 to disappear
Aug 28 09:56:49.340: INFO: Pod pod-projected-configmaps-15601983-c937-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 09:56:49.341: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pxbzx" for this suite.
Aug 28 09:56:57.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 09:56:57.454: INFO: namespace: e2e-tests-projected-pxbzx, resource: bindings, ignored listing per whitelist
Aug 28 09:57:00.488: INFO: namespace e2e-tests-projected-pxbzx deletion completed in 11.140902249s

• [SLOW TEST:17.983 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 09:57:00.488: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bvzd8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-2013758e-c937-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 09:57:01.172: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-201a01e6-c937-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-bvzd8" to be "success or failure"
Aug 28 09:57:01.193: INFO: Pod "pod-projected-configmaps-201a01e6-c937-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 20.900151ms
Aug 28 09:57:03.209: INFO: Pod "pod-projected-configmaps-201a01e6-c937-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036642584s
Aug 28 09:57:05.214: INFO: Pod "pod-projected-configmaps-201a01e6-c937-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041640809s
Aug 28 09:57:07.219: INFO: Pod "pod-projected-configmaps-201a01e6-c937-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.04602904s
Aug 28 09:57:09.224: INFO: Pod "pod-projected-configmaps-201a01e6-c937-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.051002366s
STEP: Saw pod success
Aug 28 09:57:09.224: INFO: Pod "pod-projected-configmaps-201a01e6-c937-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 09:57:09.227: INFO: Trying to get logs from node node-124 pod pod-projected-configmaps-201a01e6-c937-11e9-a0e2-288023b0a458 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 28 09:57:09.286: INFO: Waiting for pod pod-projected-configmaps-201a01e6-c937-11e9-a0e2-288023b0a458 to disappear
Aug 28 09:57:09.290: INFO: Pod pod-projected-configmaps-201a01e6-c937-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 09:57:09.290: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bvzd8" for this suite.
Aug 28 09:57:17.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 09:57:17.543: INFO: namespace: e2e-tests-projected-bvzd8, resource: bindings, ignored listing per whitelist
Aug 28 09:57:20.393: INFO: namespace e2e-tests-projected-bvzd8 deletion completed in 11.095975115s

• [SLOW TEST:19.905 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 09:57:20.394: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-5xqbq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 09:58:20.931: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5xqbq" for this suite.
Aug 28 09:58:44.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 09:58:45.000: INFO: namespace: e2e-tests-container-probe-5xqbq, resource: bindings, ignored listing per whitelist
Aug 28 09:58:48.033: INFO: namespace e2e-tests-container-probe-5xqbq deletion completed in 27.09487377s

• [SLOW TEST:87.640 seconds]
[k8s.io] Probing container
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 09:58:48.033: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6d5ct
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Aug 28 09:58:55.282: INFO: Successfully updated pod "labelsupdate602c76d3-c937-11e9-a0e2-288023b0a458"
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 09:58:57.309: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6d5ct" for this suite.
Aug 28 09:59:21.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 09:59:22.524: INFO: namespace: e2e-tests-projected-6d5ct, resource: bindings, ignored listing per whitelist
Aug 28 09:59:24.423: INFO: namespace e2e-tests-projected-6d5ct deletion completed in 27.107109946s

• [SLOW TEST:36.390 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 09:59:24.423: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-khsts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0828 09:59:34.971050   76809 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 28 09:59:34.971: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 09:59:34.971: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-khsts" for this suite.
Aug 28 09:59:43.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 09:59:43.231: INFO: namespace: e2e-tests-gc-khsts, resource: bindings, ignored listing per whitelist
Aug 28 09:59:46.100: INFO: namespace e2e-tests-gc-khsts deletion completed in 11.123458274s

• [SLOW TEST:21.677 seconds]
[sig-api-machinery] Garbage collector
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 09:59:46.100: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5l9cj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should do a rolling update of a replication controller  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the initial replication controller
Aug 28 09:59:46.510: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-5l9cj'
Aug 28 09:59:47.153: INFO: stderr: ""
Aug 28 09:59:47.154: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 28 09:59:47.154: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5l9cj'
Aug 28 09:59:47.586: INFO: stderr: ""
Aug 28 09:59:47.586: INFO: stdout: "update-demo-nautilus-8hqlp update-demo-nautilus-b4c75 "
Aug 28 09:59:47.586: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-8hqlp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5l9cj'
Aug 28 09:59:48.011: INFO: stderr: ""
Aug 28 09:59:48.011: INFO: stdout: ""
Aug 28 09:59:48.011: INFO: update-demo-nautilus-8hqlp is created but not running
Aug 28 09:59:53.011: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5l9cj'
Aug 28 09:59:53.466: INFO: stderr: ""
Aug 28 09:59:53.466: INFO: stdout: "update-demo-nautilus-8hqlp update-demo-nautilus-b4c75 "
Aug 28 09:59:53.466: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-8hqlp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5l9cj'
Aug 28 09:59:53.978: INFO: stderr: ""
Aug 28 09:59:53.978: INFO: stdout: "true"
Aug 28 09:59:53.978: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-8hqlp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5l9cj'
Aug 28 09:59:54.494: INFO: stderr: ""
Aug 28 09:59:54.494: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Aug 28 09:59:54.494: INFO: validating pod update-demo-nautilus-8hqlp
Aug 28 09:59:54.623: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 28 09:59:54.623: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 28 09:59:54.623: INFO: update-demo-nautilus-8hqlp is verified up and running
Aug 28 09:59:54.623: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-b4c75 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5l9cj'
Aug 28 09:59:55.074: INFO: stderr: ""
Aug 28 09:59:55.074: INFO: stdout: "true"
Aug 28 09:59:55.074: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-b4c75 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5l9cj'
Aug 28 09:59:55.516: INFO: stderr: ""
Aug 28 09:59:55.516: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Aug 28 09:59:55.516: INFO: validating pod update-demo-nautilus-b4c75
Aug 28 09:59:55.598: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 28 09:59:55.598: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 28 09:59:55.598: INFO: update-demo-nautilus-b4c75 is verified up and running
STEP: rolling-update to new replication controller
Aug 28 09:59:55.598: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-5l9cj'
Aug 28 10:00:23.816: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 28 10:00:23.816: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 28 10:00:23.816: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5l9cj'
Aug 28 10:00:24.230: INFO: stderr: ""
Aug 28 10:00:24.230: INFO: stdout: "update-demo-kitten-54vnm update-demo-kitten-tcjpj "
Aug 28 10:00:24.230: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-kitten-54vnm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5l9cj'
Aug 28 10:00:24.616: INFO: stderr: ""
Aug 28 10:00:24.616: INFO: stdout: "true"
Aug 28 10:00:24.616: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-kitten-54vnm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5l9cj'
Aug 28 10:00:24.962: INFO: stderr: ""
Aug 28 10:00:24.962: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-amd64:1.0"
Aug 28 10:00:24.962: INFO: validating pod update-demo-kitten-54vnm
Aug 28 10:00:25.015: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 28 10:00:25.015: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 28 10:00:25.015: INFO: update-demo-kitten-54vnm is verified up and running
Aug 28 10:00:25.015: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-kitten-tcjpj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5l9cj'
Aug 28 10:00:25.378: INFO: stderr: ""
Aug 28 10:00:25.378: INFO: stdout: "true"
Aug 28 10:00:25.378: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-kitten-tcjpj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5l9cj'
Aug 28 10:00:25.790: INFO: stderr: ""
Aug 28 10:00:25.790: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-amd64:1.0"
Aug 28 10:00:25.790: INFO: validating pod update-demo-kitten-tcjpj
Aug 28 10:00:25.830: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 28 10:00:25.830: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 28 10:00:25.830: INFO: update-demo-kitten-tcjpj is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:00:25.831: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5l9cj" for this suite.
Aug 28 10:00:49.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:00:51.237: INFO: namespace: e2e-tests-kubectl-5l9cj, resource: bindings, ignored listing per whitelist
Aug 28 10:00:52.942: INFO: namespace e2e-tests-kubectl-5l9cj deletion completed in 27.101845924s

• [SLOW TEST:66.842 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should do a rolling update of a replication controller  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:00:52.943: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-zn9l4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 28 10:00:53.864: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-zn9l4,SelfLink:/api/v1/namespaces/e2e-tests-watch-zn9l4/configmaps/e2e-watch-test-resource-version,UID:aa8d2989-c937-11e9-bbca-288023b0a1ec,ResourceVersion:15110584,Generation:0,CreationTimestamp:2019-08-28 10:00:53 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 28 10:00:53.864: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-zn9l4,SelfLink:/api/v1/namespaces/e2e-tests-watch-zn9l4/configmaps/e2e-watch-test-resource-version,UID:aa8d2989-c937-11e9-bbca-288023b0a1ec,ResourceVersion:15110587,Generation:0,CreationTimestamp:2019-08-28 10:00:53 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:00:53.864: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zn9l4" for this suite.
Aug 28 10:01:01.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:01:02.060: INFO: namespace: e2e-tests-watch-zn9l4, resource: bindings, ignored listing per whitelist
Aug 28 10:01:04.967: INFO: namespace e2e-tests-watch-zn9l4 deletion completed in 11.095255883s

• [SLOW TEST:12.024 seconds]
[sig-api-machinery] Watchers
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:01:04.967: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-k8ptg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 28 10:01:05.547: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k8ptg,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8ptg/configmaps/e2e-watch-test-configmap-a,UID:b1c39c61-c937-11e9-bbca-288023b0a1ec,ResourceVersion:15110671,Generation:0,CreationTimestamp:2019-08-28 10:01:05 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 28 10:01:05.547: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k8ptg,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8ptg/configmaps/e2e-watch-test-configmap-a,UID:b1c39c61-c937-11e9-bbca-288023b0a1ec,ResourceVersion:15110671,Generation:0,CreationTimestamp:2019-08-28 10:01:05 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 28 10:01:15.583: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k8ptg,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8ptg/configmaps/e2e-watch-test-configmap-a,UID:b1c39c61-c937-11e9-bbca-288023b0a1ec,ResourceVersion:15110714,Generation:0,CreationTimestamp:2019-08-28 10:01:05 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 28 10:01:15.583: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k8ptg,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8ptg/configmaps/e2e-watch-test-configmap-a,UID:b1c39c61-c937-11e9-bbca-288023b0a1ec,ResourceVersion:15110714,Generation:0,CreationTimestamp:2019-08-28 10:01:05 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 28 10:01:25.646: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k8ptg,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8ptg/configmaps/e2e-watch-test-configmap-a,UID:b1c39c61-c937-11e9-bbca-288023b0a1ec,ResourceVersion:15110743,Generation:0,CreationTimestamp:2019-08-28 10:01:05 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 28 10:01:25.646: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k8ptg,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8ptg/configmaps/e2e-watch-test-configmap-a,UID:b1c39c61-c937-11e9-bbca-288023b0a1ec,ResourceVersion:15110743,Generation:0,CreationTimestamp:2019-08-28 10:01:05 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 28 10:01:35.668: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k8ptg,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8ptg/configmaps/e2e-watch-test-configmap-a,UID:b1c39c61-c937-11e9-bbca-288023b0a1ec,ResourceVersion:15110776,Generation:0,CreationTimestamp:2019-08-28 10:01:05 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 28 10:01:35.669: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-k8ptg,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8ptg/configmaps/e2e-watch-test-configmap-a,UID:b1c39c61-c937-11e9-bbca-288023b0a1ec,ResourceVersion:15110776,Generation:0,CreationTimestamp:2019-08-28 10:01:05 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 28 10:01:45.690: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-k8ptg,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8ptg/configmaps/e2e-watch-test-configmap-b,UID:c9c04a6b-c937-11e9-bbca-288023b0a1ec,ResourceVersion:15110809,Generation:0,CreationTimestamp:2019-08-28 10:01:45 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 28 10:01:45.690: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-k8ptg,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8ptg/configmaps/e2e-watch-test-configmap-b,UID:c9c04a6b-c937-11e9-bbca-288023b0a1ec,ResourceVersion:15110809,Generation:0,CreationTimestamp:2019-08-28 10:01:45 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 28 10:01:55.737: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-k8ptg,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8ptg/configmaps/e2e-watch-test-configmap-b,UID:c9c04a6b-c937-11e9-bbca-288023b0a1ec,ResourceVersion:15110839,Generation:0,CreationTimestamp:2019-08-28 10:01:45 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 28 10:01:55.737: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-k8ptg,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8ptg/configmaps/e2e-watch-test-configmap-b,UID:c9c04a6b-c937-11e9-bbca-288023b0a1ec,ResourceVersion:15110839,Generation:0,CreationTimestamp:2019-08-28 10:01:45 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:02:05.738: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-k8ptg" for this suite.
Aug 28 10:02:13.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:02:13.934: INFO: namespace: e2e-tests-watch-k8ptg, resource: bindings, ignored listing per whitelist
Aug 28 10:02:16.839: INFO: namespace e2e-tests-watch-k8ptg deletion completed in 11.095269062s

• [SLOW TEST:71.872 seconds]
[sig-api-machinery] Watchers
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:02:16.840: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-gvttf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 28 10:02:17.346: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 28 10:03:17.436: INFO: Waiting for terminating namespaces to be deleted...
Aug 28 10:03:17.444: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 28 10:03:17.457: INFO: 10 / 10 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 28 10:03:17.457: INFO: expected 1 pod replicas in namespace 'kube-system', 1 are Running and Ready.
Aug 28 10:03:17.461: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Aug 28 10:03:17.461: INFO: 
Logging pods the kubelet thinks is on node node-124 before test
Aug 28 10:03:17.474: INFO: ovs-wbrm7 from openshift-sdn started at 2019-08-15 14:03:49 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.474: INFO: 	Container openvswitch ready: true, restart count 1
Aug 28 10:03:17.474: INFO: os-sys-app-cronjob-1566957600-6r8bv from default started at 2019-08-28 10:00:02 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.474: INFO: 	Container os-sys-app-cronjob ready: false, restart count 0
Aug 28 10:03:17.474: INFO: sdn-bptkv from openshift-sdn started at 2019-08-15 14:03:49 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.474: INFO: 	Container sdn ready: true, restart count 1
Aug 28 10:03:17.474: INFO: os-log-daemonset-7rwz8 from default started at 2019-08-25 20:22:06 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.474: INFO: 	Container oslogmgt ready: true, restart count 0
Aug 28 10:03:17.474: INFO: os-prometheus-prometheus-node-exporter-bhts2 from prometheus-monitoring started at 2019-08-15 14:58:55 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.474: INFO: 	Container node-exporter ready: true, restart count 3
Aug 28 10:03:17.474: INFO: os-app-cronjob-1566957600-hvbkn from cloudos-paas started at 2019-08-28 10:00:02 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.474: INFO: 	Container os-app-cronjob ready: false, restart count 0
Aug 28 10:03:17.474: INFO: os-weave-scope-agent-grsw6 from default started at 2019-08-15 14:03:49 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.474: INFO: 	Container scope-agent ready: true, restart count 1
Aug 28 10:03:17.474: INFO: sync-b5rks from openshift-node started at 2019-08-15 14:57:23 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.474: INFO: 	Container sync ready: true, restart count 1
Aug 28 10:03:17.474: INFO: 
Logging pods the kubelet thinks is on node node-128 before test
Aug 28 10:03:17.491: INFO: sync-pbcjr from openshift-node started at 2019-08-15 14:57:23 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container sync ready: true, restart count 1
Aug 28 10:03:17.491: INFO: milk-user-server-55c7c9bc48-qx9vh from space2940252d started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container user-server ready: true, restart count 0
Aug 28 10:03:17.491: INFO: database-server-86c6c767b8-dtnf9 from space2940252d started at 2019-08-15 15:49:51 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container database-server ready: true, restart count 1
Aug 28 10:03:17.491: INFO: istio-telemetry-648598656c-rx95s from cloudos-mesh started at 2019-08-27 15:45:55 +0800 CST (2 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 10:03:17.491: INFO: 	Container mixer ready: true, restart count 9
Aug 28 10:03:17.491: INFO: os-weave-scope-agent-dh6qh from default started at 2019-08-15 14:16:07 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container scope-agent ready: true, restart count 1
Aug 28 10:03:17.491: INFO: front-server-c6d86d655-qknsn from space2940252d started at 2019-08-15 15:49:51 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container front-server ready: true, restart count 2
Aug 28 10:03:17.491: INFO: milk-warehouse-server-667f499dbb-vbptx from space80d22279 started at 2019-08-27 16:49:36 +0800 CST (2 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 10:03:17.491: INFO: 	Container warehouse-server ready: true, restart count 0
Aug 28 10:03:17.491: INFO: os-prometheus-prometheus-node-exporter-j5r86 from prometheus-monitoring started at 2019-08-15 14:59:26 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container node-exporter ready: true, restart count 72
Aug 28 10:03:17.491: INFO: milk-order-server-6557776f4c-mnb25 from space2940252d started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container order-server ready: true, restart count 0
Aug 28 10:03:17.491: INFO: milk-order-server-6557776f4c-27rlx from space80d22279 started at 2019-08-15 15:47:24 +0800 CST (2 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container istio-proxy ready: true, restart count 1
Aug 28 10:03:17.491: INFO: 	Container order-server ready: true, restart count 2
Aug 28 10:03:17.491: INFO: milk-warehouse-server-667f499dbb-6jd9h from space2940252d started at 2019-08-15 15:49:51 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container warehouse-server ready: true, restart count 2
Aug 28 10:03:17.491: INFO: ovs-78jnp from openshift-sdn started at 2019-08-15 14:16:07 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container openvswitch ready: true, restart count 1
Aug 28 10:03:17.491: INFO: os-log-daemonset-x56ph from default started at 2019-08-15 14:16:07 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container oslogmgt ready: true, restart count 1
Aug 28 10:03:17.491: INFO: sdn-gszh2 from openshift-sdn started at 2019-08-15 14:16:07 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container sdn ready: true, restart count 1
Aug 28 10:03:17.491: INFO: database-server-86c6c767b8-gc4nr from space80d22279 started at 2019-08-15 15:47:25 +0800 CST (2 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container database-server ready: true, restart count 2
Aug 28 10:03:17.491: INFO: 	Container istio-proxy ready: true, restart count 1
Aug 28 10:03:17.491: INFO: front-server-c6d86d655-wzhpp from space80d22279 started at 2019-08-15 15:47:25 +0800 CST (2 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container front-server ready: true, restart count 2
Aug 28 10:03:17.491: INFO: 	Container istio-proxy ready: true, restart count 1
Aug 28 10:03:17.491: INFO: milk-brands-server-569d5bb9fc-f69dc from space2940252d started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.491: INFO: 	Container brands-server ready: true, restart count 0
Aug 28 10:03:17.491: INFO: 
Logging pods the kubelet thinks is on node node-137 before test
Aug 28 10:03:17.510: INFO: os-weave-scope-app-67464966f6-xqkp8 from default started at 2019-08-25 20:20:27 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container app ready: true, restart count 0
Aug 28 10:03:17.510: INFO: ovs-t6trh from openshift-sdn started at 2019-08-15 14:29:55 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container openvswitch ready: true, restart count 1
Aug 28 10:03:17.510: INFO: heapster-s76t8 from openshift-infra started at 2019-08-25 20:20:30 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container heapster ready: true, restart count 0
Aug 28 10:03:17.510: INFO: redis-proxy-76ff84c585-d2wwt from default started at 2019-08-25 20:18:14 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container haproxy ready: true, restart count 0
Aug 28 10:03:17.510: INFO: milk-user-server-55c7c9bc48-2dzp5 from space80d22279 started at 2019-08-27 16:49:36 +0800 CST (2 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 10:03:17.510: INFO: 	Container user-server ready: true, restart count 0
Aug 28 10:03:17.510: INFO: os-weave-scope-agent-9h5l2 from default started at 2019-08-15 14:29:56 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container scope-agent ready: true, restart count 1
Aug 28 10:03:17.510: INFO: os-log-daemonset-wcd7s from default started at 2019-08-15 14:29:56 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container oslogmgt ready: true, restart count 1
Aug 28 10:03:17.510: INFO: database-server-86c6c767b8-7n4hn from space80d22279 started at 2019-08-27 16:49:36 +0800 CST (2 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container database-server ready: true, restart count 0
Aug 28 10:03:17.510: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 10:03:17.510: INFO: sync-4l8lz from openshift-node started at 2019-08-15 14:57:27 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container sync ready: true, restart count 1
Aug 28 10:03:17.510: INFO: milk-brands-server-569d5bb9fc-d5fg7 from space80d22279 started at 2019-08-26 15:22:38 +0800 CST (2 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container brands-server ready: true, restart count 0
Aug 28 10:03:17.510: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 10:03:17.510: INFO: redisoperator-d96dc9d-ljrtt from default started at 2019-08-25 20:18:14 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container operator ready: true, restart count 0
Aug 28 10:03:17.510: INFO: os-prometheus-kube-state-metrics-9d46ff684-gl2g8 from prometheus-monitoring started at 2019-08-25 20:19:09 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container kube-state-metrics ready: true, restart count 0
Aug 28 10:03:17.510: INFO: istio-policy-68879ddc88-rv7wl from cloudos-mesh started at 2019-08-15 14:36:43 +0800 CST (2 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container istio-proxy ready: true, restart count 1
Aug 28 10:03:17.510: INFO: 	Container mixer ready: true, restart count 287
Aug 28 10:03:17.510: INFO: os-prometheus-prometheus-node-exporter-mvf5c from prometheus-monitoring started at 2019-08-15 15:00:11 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container node-exporter ready: true, restart count 4
Aug 28 10:03:17.510: INFO: metrics-server-57ff6c6465-dccxw from openshift-metrics-server started at 2019-08-25 20:18:15 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container metrics-server ready: true, restart count 0
Aug 28 10:03:17.510: INFO: database-server-86c6c767b8-k8d4s from space2940252d started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container database-server ready: true, restart count 0
Aug 28 10:03:17.510: INFO: sdn-fzp9m from openshift-sdn started at 2019-08-15 14:29:56 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container sdn ready: true, restart count 1
Aug 28 10:03:17.510: INFO: fortiotest-7f4b6c6dbc-wtnxn from space58e14a82 started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 10:03:17.510: INFO: 	Container fortiotest ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15bef3d097fdf25a], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 node(s) didn't match node selector, 3 node(s) were unschedulable.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:03:18.618: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-gvttf" for this suite.
Aug 28 10:03:42.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:03:45.494: INFO: namespace: e2e-tests-sched-pred-gvttf, resource: bindings, ignored listing per whitelist
Aug 28 10:03:45.744: INFO: namespace e2e-tests-sched-pred-gvttf deletion completed in 27.119663772s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:88.904 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:03:45.744: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-n4qmk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-119b9fcb-c938-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 10:03:46.367: INFO: Waiting up to 5m0s for pod "pod-configmaps-11a166af-c938-11e9-a0e2-288023b0a458" in namespace "e2e-tests-configmap-n4qmk" to be "success or failure"
Aug 28 10:03:46.371: INFO: Pod "pod-configmaps-11a166af-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.800254ms
Aug 28 10:03:48.376: INFO: Pod "pod-configmaps-11a166af-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009194586s
Aug 28 10:03:50.381: INFO: Pod "pod-configmaps-11a166af-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013432534s
Aug 28 10:03:52.386: INFO: Pod "pod-configmaps-11a166af-c938-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018428823s
STEP: Saw pod success
Aug 28 10:03:52.386: INFO: Pod "pod-configmaps-11a166af-c938-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:03:52.389: INFO: Trying to get logs from node node-124 pod pod-configmaps-11a166af-c938-11e9-a0e2-288023b0a458 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 28 10:03:52.424: INFO: Waiting for pod pod-configmaps-11a166af-c938-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:03:52.428: INFO: Pod pod-configmaps-11a166af-c938-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:03:52.428: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-n4qmk" for this suite.
Aug 28 10:04:00.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:04:01.974: INFO: namespace: e2e-tests-configmap-n4qmk, resource: bindings, ignored listing per whitelist
Aug 28 10:04:03.523: INFO: namespace e2e-tests-configmap-n4qmk deletion completed in 11.088755831s

• [SLOW TEST:17.780 seconds]
[sig-storage] ConfigMap
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:04:03.524: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-q82ft
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check is all data is printed  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 10:04:03.942: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config version'
Aug 28 10:04:04.323: INFO: stderr: ""
Aug 28 10:04:04.323: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11+\", GitVersion:\"v1.11.0+d4cacc0\", GitCommit:\"d4cacc0\", GitTreeState:\"clean\", BuildDate:\"2018-10-15T09:45:30Z\", GoVersion:\"go1.10.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"11+\", GitVersion:\"v1.11.0+d4cacc0\", GitCommit:\"d4cacc0\", GitTreeState:\"clean\", BuildDate:\"2019-02-08T23:07:29Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:04:04.324: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q82ft" for this suite.
Aug 28 10:04:12.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:04:12.986: INFO: namespace: e2e-tests-kubectl-q82ft, resource: bindings, ignored listing per whitelist
Aug 28 10:04:15.484: INFO: namespace e2e-tests-kubectl-q82ft deletion completed in 11.153446083s

• [SLOW TEST:11.960 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check is all data is printed  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:04:15.484: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mbcph
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support --unix-socket=/path  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Starting the proxy
Aug 28 10:04:15.888: INFO: Asynchronously running '/bin/kubectl kubectl --kubeconfig=/root/.kube/config proxy --unix-socket=/tmp/kubectl-proxy-unix982009936/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:04:16.227: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mbcph" for this suite.
Aug 28 10:04:24.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:04:24.334: INFO: namespace: e2e-tests-kubectl-mbcph, resource: bindings, ignored listing per whitelist
Aug 28 10:04:27.348: INFO: namespace e2e-tests-kubectl-mbcph deletion completed in 11.112779363s

• [SLOW TEST:11.864 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support --unix-socket=/path  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:04:27.348: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-s42h6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-2a5b220b-c938-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 10:04:27.885: INFO: Waiting up to 5m0s for pod "pod-configmaps-2a620efc-c938-11e9-a0e2-288023b0a458" in namespace "e2e-tests-configmap-s42h6" to be "success or failure"
Aug 28 10:04:27.898: INFO: Pod "pod-configmaps-2a620efc-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 12.930119ms
Aug 28 10:04:29.903: INFO: Pod "pod-configmaps-2a620efc-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017639382s
Aug 28 10:04:31.908: INFO: Pod "pod-configmaps-2a620efc-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022264835s
Aug 28 10:04:33.913: INFO: Pod "pod-configmaps-2a620efc-c938-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027204111s
STEP: Saw pod success
Aug 28 10:04:33.913: INFO: Pod "pod-configmaps-2a620efc-c938-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:04:33.916: INFO: Trying to get logs from node node-124 pod pod-configmaps-2a620efc-c938-11e9-a0e2-288023b0a458 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 28 10:04:33.963: INFO: Waiting for pod pod-configmaps-2a620efc-c938-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:04:33.967: INFO: Pod pod-configmaps-2a620efc-c938-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:04:33.967: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-s42h6" for this suite.
Aug 28 10:04:42.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:04:42.098: INFO: namespace: e2e-tests-configmap-s42h6, resource: bindings, ignored listing per whitelist
Aug 28 10:04:45.102: INFO: namespace e2e-tests-configmap-s42h6 deletion completed in 11.128561706s

• [SLOW TEST:17.754 seconds]
[sig-storage] ConfigMap
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:04:45.102: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-jshdq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should run and stop simple daemon [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 28 10:04:45.742: INFO: Number of nodes with available pods: 0
Aug 28 10:04:45.742: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:04:46.757: INFO: Number of nodes with available pods: 0
Aug 28 10:04:46.757: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:04:47.760: INFO: Number of nodes with available pods: 0
Aug 28 10:04:47.760: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:04:48.755: INFO: Number of nodes with available pods: 0
Aug 28 10:04:48.755: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:04:49.755: INFO: Number of nodes with available pods: 1
Aug 28 10:04:49.755: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:04:50.754: INFO: Number of nodes with available pods: 1
Aug 28 10:04:50.754: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:04:51.754: INFO: Number of nodes with available pods: 4
Aug 28 10:04:51.754: INFO: Node node-143 is running more than one daemon pod
Aug 28 10:04:52.757: INFO: Number of nodes with available pods: 5
Aug 28 10:04:52.757: INFO: Node node-145 is running more than one daemon pod
Aug 28 10:04:53.755: INFO: Number of nodes with available pods: 6
Aug 28 10:04:53.755: INFO: Number of running nodes: 6, number of available pods: 6
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 28 10:04:53.789: INFO: Number of nodes with available pods: 5
Aug 28 10:04:53.789: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:04:54.802: INFO: Number of nodes with available pods: 5
Aug 28 10:04:54.802: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:04:55.801: INFO: Number of nodes with available pods: 5
Aug 28 10:04:55.801: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:04:56.801: INFO: Number of nodes with available pods: 5
Aug 28 10:04:56.801: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:04:57.802: INFO: Number of nodes with available pods: 5
Aug 28 10:04:57.802: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:04:58.801: INFO: Number of nodes with available pods: 5
Aug 28 10:04:58.801: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:04:59.802: INFO: Number of nodes with available pods: 5
Aug 28 10:04:59.802: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:05:00.800: INFO: Number of nodes with available pods: 5
Aug 28 10:05:00.800: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:05:01.803: INFO: Number of nodes with available pods: 5
Aug 28 10:05:01.803: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:05:02.802: INFO: Number of nodes with available pods: 6
Aug 28 10:05:02.802: INFO: Number of running nodes: 6, number of available pods: 6
[AfterEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-jshdq, will wait for the garbage collector to delete the pods
Aug 28 10:05:02.878: INFO: Deleting {extensions DaemonSet} daemon-set took: 17.054998ms
Aug 28 10:05:02.978: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.214572ms
Aug 28 10:05:16.283: INFO: Number of nodes with available pods: 0
Aug 28 10:05:16.283: INFO: Number of running nodes: 0, number of available pods: 0
Aug 28 10:05:16.305: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-jshdq/daemonsets","resourceVersion":"15111974"},"items":null}

Aug 28 10:05:16.309: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-jshdq/pods","resourceVersion":"15111974"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:05:16.326: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-jshdq" for this suite.
Aug 28 10:05:24.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:05:25.727: INFO: namespace: e2e-tests-daemonsets-jshdq, resource: bindings, ignored listing per whitelist
Aug 28 10:05:27.426: INFO: namespace e2e-tests-daemonsets-jshdq deletion completed in 11.093939847s

• [SLOW TEST:42.324 seconds]
[sig-apps] Daemon set [Serial]
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:05:27.426: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-nhlbz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-map-4e325332-c938-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume secrets
Aug 28 10:05:28.015: INFO: Waiting up to 5m0s for pod "pod-secrets-4e3415f4-c938-11e9-a0e2-288023b0a458" in namespace "e2e-tests-secrets-nhlbz" to be "success or failure"
Aug 28 10:05:28.020: INFO: Pod "pod-secrets-4e3415f4-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.60335ms
Aug 28 10:05:30.025: INFO: Pod "pod-secrets-4e3415f4-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01011889s
Aug 28 10:05:32.031: INFO: Pod "pod-secrets-4e3415f4-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015173873s
Aug 28 10:05:34.036: INFO: Pod "pod-secrets-4e3415f4-c938-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020500534s
STEP: Saw pod success
Aug 28 10:05:34.036: INFO: Pod "pod-secrets-4e3415f4-c938-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:05:34.040: INFO: Trying to get logs from node node-124 pod pod-secrets-4e3415f4-c938-11e9-a0e2-288023b0a458 container secret-volume-test: <nil>
STEP: delete the pod
Aug 28 10:05:34.117: INFO: Waiting for pod pod-secrets-4e3415f4-c938-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:05:34.121: INFO: Pod pod-secrets-4e3415f4-c938-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:05:34.121: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nhlbz" for this suite.
Aug 28 10:05:42.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:05:42.223: INFO: namespace: e2e-tests-secrets-nhlbz, resource: bindings, ignored listing per whitelist
Aug 28 10:05:45.245: INFO: namespace e2e-tests-secrets-nhlbz deletion completed in 11.116502578s

• [SLOW TEST:17.818 seconds]
[sig-storage] Secrets
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:05:45.245: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-h6k7n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Aug 28 10:05:45.996: INFO: Waiting up to 5m0s for pod "downward-api-58ccff36-c938-11e9-a0e2-288023b0a458" in namespace "e2e-tests-downward-api-h6k7n" to be "success or failure"
Aug 28 10:05:46.000: INFO: Pod "downward-api-58ccff36-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.925305ms
Aug 28 10:05:48.006: INFO: Pod "downward-api-58ccff36-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009729549s
Aug 28 10:05:50.012: INFO: Pod "downward-api-58ccff36-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015752859s
Aug 28 10:05:52.017: INFO: Pod "downward-api-58ccff36-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020464933s
Aug 28 10:05:54.025: INFO: Pod "downward-api-58ccff36-c938-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.028138276s
STEP: Saw pod success
Aug 28 10:05:54.025: INFO: Pod "downward-api-58ccff36-c938-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:05:54.028: INFO: Trying to get logs from node node-124 pod downward-api-58ccff36-c938-11e9-a0e2-288023b0a458 container dapi-container: <nil>
STEP: delete the pod
Aug 28 10:05:54.363: INFO: Waiting for pod downward-api-58ccff36-c938-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:05:54.367: INFO: Pod downward-api-58ccff36-c938-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:05:54.367: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-h6k7n" for this suite.
Aug 28 10:06:02.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:06:02.492: INFO: namespace: e2e-tests-downward-api-h6k7n, resource: bindings, ignored listing per whitelist
Aug 28 10:06:05.514: INFO: namespace e2e-tests-downward-api-h6k7n deletion completed in 11.140811347s

• [SLOW TEST:20.269 seconds]
[sig-api-machinery] Downward API
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:06:05.514: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-z529l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update labels on modification [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Aug 28 10:06:13.173: INFO: Successfully updated pod "labelsupdate650c9bf2-c938-11e9-a0e2-288023b0a458"
[AfterEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:06:15.201: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-z529l" for this suite.
Aug 28 10:06:39.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:06:39.420: INFO: namespace: e2e-tests-downward-api-z529l, resource: bindings, ignored listing per whitelist
Aug 28 10:06:42.306: INFO: namespace e2e-tests-downward-api-z529l deletion completed in 27.098393609s

• [SLOW TEST:36.792 seconds]
[sig-storage] Downward API volume
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:06:42.307: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-xxl86
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 10:07:06.878: INFO: Container started at 2019-08-28 10:06:47 +0800 CST, pod became ready at 2019-08-28 10:07:06 +0800 CST
[AfterEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:07:06.879: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xxl86" for this suite.
Aug 28 10:07:30.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:07:31.161: INFO: namespace: e2e-tests-container-probe-xxl86, resource: bindings, ignored listing per whitelist
Aug 28 10:07:34.007: INFO: namespace e2e-tests-container-probe-xxl86 deletion completed in 27.121562496s

• [SLOW TEST:51.700 seconds]
[k8s.io] Probing container
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:07:34.007: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5vqhk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 10:07:34.593: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99a8be6d-c938-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-5vqhk" to be "success or failure"
Aug 28 10:07:34.612: INFO: Pod "downwardapi-volume-99a8be6d-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 18.9343ms
Aug 28 10:07:36.616: INFO: Pod "downwardapi-volume-99a8be6d-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023671592s
Aug 28 10:07:38.620: INFO: Pod "downwardapi-volume-99a8be6d-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027840203s
Aug 28 10:07:40.625: INFO: Pod "downwardapi-volume-99a8be6d-c938-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032482552s
STEP: Saw pod success
Aug 28 10:07:40.625: INFO: Pod "downwardapi-volume-99a8be6d-c938-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:07:40.629: INFO: Trying to get logs from node node-124 pod downwardapi-volume-99a8be6d-c938-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 10:07:40.666: INFO: Waiting for pod downwardapi-volume-99a8be6d-c938-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:07:40.669: INFO: Pod downwardapi-volume-99a8be6d-c938-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:07:40.669: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5vqhk" for this suite.
Aug 28 10:07:48.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:07:51.481: INFO: namespace: e2e-tests-projected-5vqhk, resource: bindings, ignored listing per whitelist
Aug 28 10:07:51.830: INFO: namespace e2e-tests-projected-5vqhk deletion completed in 11.154737771s

• [SLOW TEST:17.823 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:07:51.830: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-64hj4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-64hj4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 28 10:07:52.271: INFO: Waiting up to 10m0s for all (but 3) nodes to be schedulable
STEP: Creating test pods
Aug 28 10:08:18.739: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.243.0.214:8080/dial?request=hostName&protocol=http&host=10.243.0.213&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-64hj4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:08:18.739: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:08:18.966: INFO: Waiting for endpoints: map[]
Aug 28 10:08:18.971: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.243.0.214:8080/dial?request=hostName&protocol=http&host=10.244.1.27&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-64hj4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:08:18.971: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:08:19.119: INFO: Waiting for endpoints: map[]
Aug 28 10:08:19.123: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.243.0.214:8080/dial?request=hostName&protocol=http&host=10.245.0.52&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-64hj4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:08:19.123: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:08:19.266: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:08:19.266: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-64hj4" for this suite.
Aug 28 10:08:43.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:08:45.122: INFO: namespace: e2e-tests-pod-network-test-64hj4, resource: bindings, ignored listing per whitelist
Aug 28 10:08:46.422: INFO: namespace e2e-tests-pod-network-test-64hj4 deletion completed in 27.148110505s

• [SLOW TEST:54.592 seconds]
[sig-network] Networking
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:08:46.422: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-cs9m4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run job
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1371
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Aug 28 10:08:46.818: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-cs9m4'
Aug 28 10:08:47.337: INFO: stderr: ""
Aug 28 10:08:47.337: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1376
Aug 28 10:08:47.341: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-cs9m4'
Aug 28 10:08:47.770: INFO: stderr: ""
Aug 28 10:08:47.770: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:08:47.770: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cs9m4" for this suite.
Aug 28 10:08:55.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:08:55.934: INFO: namespace: e2e-tests-kubectl-cs9m4, resource: bindings, ignored listing per whitelist
Aug 28 10:08:58.902: INFO: namespace e2e-tests-kubectl-cs9m4 deletion completed in 11.106700586s

• [SLOW TEST:12.480 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a job from an image when restart is OnFailure  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:08:58.902: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-st7mw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update annotations on modification [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Aug 28 10:09:06.328: INFO: Successfully updated pod "annotationupdatecc78a065-c938-11e9-a0e2-288023b0a458"
[AfterEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:09:10.367: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-st7mw" for this suite.
Aug 28 10:09:34.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:09:35.035: INFO: namespace: e2e-tests-downward-api-st7mw, resource: bindings, ignored listing per whitelist
Aug 28 10:09:37.487: INFO: namespace e2e-tests-downward-api-st7mw deletion completed in 27.113503924s

• [SLOW TEST:38.585 seconds]
[sig-storage] Downward API volume
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] DNS
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:09:37.488: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-f2n2n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cloudos A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cloudos;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cloudos A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cloudos;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-f2n2n.svc.cloudos)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-f2n2n.svc.cloudos;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-f2n2n.pod.cloudos"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cloudos A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cloudos;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cloudos A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cloudos;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-f2n2n.svc.cloudos)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-f2n2n.svc.cloudos;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-f2n2n.pod.cloudos"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 28 10:09:58.130: INFO: DNS probes using dns-test-e3386478-c938-11e9-a0e2-288023b0a458 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:09:58.165: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-f2n2n" for this suite.
Aug 28 10:10:06.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:10:08.608: INFO: namespace: e2e-tests-dns-f2n2n, resource: bindings, ignored listing per whitelist
Aug 28 10:10:09.260: INFO: namespace e2e-tests-dns-f2n2n deletion completed in 11.088837303s

• [SLOW TEST:31.772 seconds]
[sig-network] DNS
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:10:09.260: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-nhvds
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap e2e-tests-configmap-nhvds/configmap-test-f632d87e-c938-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 10:10:09.809: INFO: Waiting up to 5m0s for pod "pod-configmaps-f6375884-c938-11e9-a0e2-288023b0a458" in namespace "e2e-tests-configmap-nhvds" to be "success or failure"
Aug 28 10:10:09.813: INFO: Pod "pod-configmaps-f6375884-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.301538ms
Aug 28 10:10:11.818: INFO: Pod "pod-configmaps-f6375884-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009064677s
Aug 28 10:10:13.823: INFO: Pod "pod-configmaps-f6375884-c938-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013569991s
Aug 28 10:10:15.830: INFO: Pod "pod-configmaps-f6375884-c938-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020789389s
STEP: Saw pod success
Aug 28 10:10:15.830: INFO: Pod "pod-configmaps-f6375884-c938-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:10:15.834: INFO: Trying to get logs from node node-124 pod pod-configmaps-f6375884-c938-11e9-a0e2-288023b0a458 container env-test: <nil>
STEP: delete the pod
Aug 28 10:10:15.895: INFO: Waiting for pod pod-configmaps-f6375884-c938-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:10:15.902: INFO: Pod pod-configmaps-f6375884-c938-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:10:15.902: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nhvds" for this suite.
Aug 28 10:10:23.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:10:24.138: INFO: namespace: e2e-tests-configmap-nhvds, resource: bindings, ignored listing per whitelist
Aug 28 10:10:26.996: INFO: namespace e2e-tests-configmap-nhvds deletion completed in 11.08808009s

• [SLOW TEST:17.736 seconds]
[sig-api-machinery] ConfigMap
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via environment variable [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:10:26.996: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2ffkk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-00b9c636-c939-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 10:10:27.558: INFO: Waiting up to 5m0s for pod "pod-configmaps-00bc210a-c939-11e9-a0e2-288023b0a458" in namespace "e2e-tests-configmap-2ffkk" to be "success or failure"
Aug 28 10:10:27.561: INFO: Pod "pod-configmaps-00bc210a-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.694655ms
Aug 28 10:10:29.566: INFO: Pod "pod-configmaps-00bc210a-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008347346s
Aug 28 10:10:31.571: INFO: Pod "pod-configmaps-00bc210a-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01330777s
Aug 28 10:10:33.575: INFO: Pod "pod-configmaps-00bc210a-c939-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017695138s
STEP: Saw pod success
Aug 28 10:10:33.575: INFO: Pod "pod-configmaps-00bc210a-c939-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:10:33.580: INFO: Trying to get logs from node node-124 pod pod-configmaps-00bc210a-c939-11e9-a0e2-288023b0a458 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 28 10:10:33.613: INFO: Waiting for pod pod-configmaps-00bc210a-c939-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:10:33.621: INFO: Pod pod-configmaps-00bc210a-c939-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:10:33.621: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2ffkk" for this suite.
Aug 28 10:10:41.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:10:41.815: INFO: namespace: e2e-tests-configmap-2ffkk, resource: bindings, ignored listing per whitelist
Aug 28 10:10:44.749: INFO: namespace e2e-tests-configmap-2ffkk deletion completed in 11.121728315s

• [SLOW TEST:17.753 seconds]
[sig-storage] ConfigMap
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:10:44.749: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-nv7vf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating secret e2e-tests-secrets-nv7vf/secret-test-0b52589c-c939-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume secrets
Aug 28 10:10:45.425: INFO: Waiting up to 5m0s for pod "pod-configmaps-0b555d9d-c939-11e9-a0e2-288023b0a458" in namespace "e2e-tests-secrets-nv7vf" to be "success or failure"
Aug 28 10:10:45.430: INFO: Pod "pod-configmaps-0b555d9d-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.101406ms
Aug 28 10:10:47.434: INFO: Pod "pod-configmaps-0b555d9d-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008954933s
Aug 28 10:10:49.493: INFO: Pod "pod-configmaps-0b555d9d-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.067483476s
Aug 28 10:10:51.498: INFO: Pod "pod-configmaps-0b555d9d-c939-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.072168661s
Aug 28 10:10:53.502: INFO: Pod "pod-configmaps-0b555d9d-c939-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.076553029s
STEP: Saw pod success
Aug 28 10:10:53.502: INFO: Pod "pod-configmaps-0b555d9d-c939-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:10:53.506: INFO: Trying to get logs from node node-124 pod pod-configmaps-0b555d9d-c939-11e9-a0e2-288023b0a458 container env-test: <nil>
STEP: delete the pod
Aug 28 10:10:53.565: INFO: Waiting for pod pod-configmaps-0b555d9d-c939-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:10:53.569: INFO: Pod pod-configmaps-0b555d9d-c939-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:10:53.569: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nv7vf" for this suite.
Aug 28 10:11:01.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:11:02.228: INFO: namespace: e2e-tests-secrets-nv7vf, resource: bindings, ignored listing per whitelist
Aug 28 10:11:04.723: INFO: namespace e2e-tests-secrets-nv7vf deletion completed in 11.148104259s

• [SLOW TEST:19.974 seconds]
[sig-api-machinery] Secrets
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:11:04.723: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5v2nx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run pod
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
[It] should create a pod from an image when restart is Never  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Aug 28 10:11:05.145: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-5v2nx'
Aug 28 10:11:05.591: INFO: stderr: ""
Aug 28 10:11:05.591: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1449
Aug 28 10:11:05.595: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-5v2nx'
Aug 28 10:11:08.809: INFO: stderr: ""
Aug 28 10:11:08.809: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:11:08.809: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5v2nx" for this suite.
Aug 28 10:11:16.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:11:19.591: INFO: namespace: e2e-tests-kubectl-5v2nx, resource: bindings, ignored listing per whitelist
Aug 28 10:11:19.941: INFO: namespace e2e-tests-kubectl-5v2nx deletion completed in 11.124327369s

• [SLOW TEST:15.217 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a pod from an image when restart is Never  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:11:19.941: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-br2cb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Aug 28 10:11:27.119: INFO: Successfully updated pod "annotationupdate20558d4c-c939-11e9-a0e2-288023b0a458"
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:11:31.157: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-br2cb" for this suite.
Aug 28 10:11:55.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:11:55.413: INFO: namespace: e2e-tests-projected-br2cb, resource: bindings, ignored listing per whitelist
Aug 28 10:11:58.274: INFO: namespace e2e-tests-projected-br2cb deletion completed in 27.110291624s

• [SLOW TEST:38.333 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:11:58.274: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-grvc6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 28 10:11:58.757: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 28 10:12:58.840: INFO: Waiting for terminating namespaces to be deleted...
Aug 28 10:12:58.848: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 28 10:12:58.861: INFO: 10 / 10 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 28 10:12:58.861: INFO: expected 1 pod replicas in namespace 'kube-system', 1 are Running and Ready.
Aug 28 10:12:58.865: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Aug 28 10:12:58.865: INFO: 
Logging pods the kubelet thinks is on node node-124 before test
Aug 28 10:12:58.875: INFO: os-weave-scope-agent-grsw6 from default started at 2019-08-15 14:03:49 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.875: INFO: 	Container scope-agent ready: true, restart count 1
Aug 28 10:12:58.875: INFO: sync-b5rks from openshift-node started at 2019-08-15 14:57:23 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.875: INFO: 	Container sync ready: true, restart count 1
Aug 28 10:12:58.875: INFO: ovs-wbrm7 from openshift-sdn started at 2019-08-15 14:03:49 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.875: INFO: 	Container openvswitch ready: true, restart count 1
Aug 28 10:12:58.875: INFO: sdn-bptkv from openshift-sdn started at 2019-08-15 14:03:49 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.875: INFO: 	Container sdn ready: true, restart count 1
Aug 28 10:12:58.875: INFO: os-log-daemonset-7rwz8 from default started at 2019-08-25 20:22:06 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.875: INFO: 	Container oslogmgt ready: true, restart count 0
Aug 28 10:12:58.875: INFO: os-prometheus-prometheus-node-exporter-bhts2 from prometheus-monitoring started at 2019-08-15 14:58:55 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.875: INFO: 	Container node-exporter ready: true, restart count 3
Aug 28 10:12:58.875: INFO: 
Logging pods the kubelet thinks is on node node-128 before test
Aug 28 10:12:58.913: INFO: milk-order-server-6557776f4c-27rlx from space80d22279 started at 2019-08-15 15:47:24 +0800 CST (2 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container istio-proxy ready: true, restart count 1
Aug 28 10:12:58.913: INFO: 	Container order-server ready: true, restart count 2
Aug 28 10:12:58.913: INFO: milk-warehouse-server-667f499dbb-6jd9h from space2940252d started at 2019-08-15 15:49:51 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container warehouse-server ready: true, restart count 2
Aug 28 10:12:58.913: INFO: ovs-78jnp from openshift-sdn started at 2019-08-15 14:16:07 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container openvswitch ready: true, restart count 1
Aug 28 10:12:58.913: INFO: os-log-daemonset-x56ph from default started at 2019-08-15 14:16:07 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container oslogmgt ready: true, restart count 1
Aug 28 10:12:58.913: INFO: sdn-gszh2 from openshift-sdn started at 2019-08-15 14:16:07 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container sdn ready: true, restart count 1
Aug 28 10:12:58.913: INFO: database-server-86c6c767b8-gc4nr from space80d22279 started at 2019-08-15 15:47:25 +0800 CST (2 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container database-server ready: true, restart count 2
Aug 28 10:12:58.913: INFO: 	Container istio-proxy ready: true, restart count 1
Aug 28 10:12:58.913: INFO: front-server-c6d86d655-wzhpp from space80d22279 started at 2019-08-15 15:47:25 +0800 CST (2 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container front-server ready: true, restart count 2
Aug 28 10:12:58.913: INFO: 	Container istio-proxy ready: true, restart count 1
Aug 28 10:12:58.913: INFO: milk-brands-server-569d5bb9fc-f69dc from space2940252d started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container brands-server ready: true, restart count 0
Aug 28 10:12:58.913: INFO: sync-pbcjr from openshift-node started at 2019-08-15 14:57:23 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container sync ready: true, restart count 1
Aug 28 10:12:58.913: INFO: milk-user-server-55c7c9bc48-qx9vh from space2940252d started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container user-server ready: true, restart count 0
Aug 28 10:12:58.913: INFO: database-server-86c6c767b8-dtnf9 from space2940252d started at 2019-08-15 15:49:51 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container database-server ready: true, restart count 1
Aug 28 10:12:58.913: INFO: istio-telemetry-648598656c-rx95s from cloudos-mesh started at 2019-08-27 15:45:55 +0800 CST (2 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 10:12:58.913: INFO: 	Container mixer ready: true, restart count 9
Aug 28 10:12:58.913: INFO: os-weave-scope-agent-dh6qh from default started at 2019-08-15 14:16:07 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container scope-agent ready: true, restart count 1
Aug 28 10:12:58.913: INFO: front-server-c6d86d655-qknsn from space2940252d started at 2019-08-15 15:49:51 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container front-server ready: true, restart count 2
Aug 28 10:12:58.913: INFO: milk-warehouse-server-667f499dbb-vbptx from space80d22279 started at 2019-08-27 16:49:36 +0800 CST (2 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 10:12:58.913: INFO: 	Container warehouse-server ready: true, restart count 0
Aug 28 10:12:58.913: INFO: os-prometheus-prometheus-node-exporter-j5r86 from prometheus-monitoring started at 2019-08-15 14:59:26 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container node-exporter ready: true, restart count 72
Aug 28 10:12:58.913: INFO: milk-order-server-6557776f4c-mnb25 from space2940252d started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.913: INFO: 	Container order-server ready: true, restart count 0
Aug 28 10:12:58.913: INFO: 
Logging pods the kubelet thinks is on node node-137 before test
Aug 28 10:12:58.937: INFO: istio-policy-68879ddc88-rv7wl from cloudos-mesh started at 2019-08-15 14:36:43 +0800 CST (2 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container istio-proxy ready: true, restart count 1
Aug 28 10:12:58.937: INFO: 	Container mixer ready: true, restart count 287
Aug 28 10:12:58.937: INFO: os-prometheus-kube-state-metrics-9d46ff684-gl2g8 from prometheus-monitoring started at 2019-08-25 20:19:09 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container kube-state-metrics ready: true, restart count 0
Aug 28 10:12:58.937: INFO: metrics-server-57ff6c6465-dccxw from openshift-metrics-server started at 2019-08-25 20:18:15 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container metrics-server ready: true, restart count 0
Aug 28 10:12:58.937: INFO: database-server-86c6c767b8-k8d4s from space2940252d started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container database-server ready: true, restart count 0
Aug 28 10:12:58.937: INFO: sdn-fzp9m from openshift-sdn started at 2019-08-15 14:29:56 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container sdn ready: true, restart count 1
Aug 28 10:12:58.937: INFO: os-prometheus-prometheus-node-exporter-mvf5c from prometheus-monitoring started at 2019-08-15 15:00:11 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container node-exporter ready: true, restart count 4
Aug 28 10:12:58.937: INFO: fortiotest-7f4b6c6dbc-wtnxn from space58e14a82 started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container fortiotest ready: true, restart count 0
Aug 28 10:12:58.937: INFO: ovs-t6trh from openshift-sdn started at 2019-08-15 14:29:55 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container openvswitch ready: true, restart count 1
Aug 28 10:12:58.937: INFO: os-weave-scope-app-67464966f6-xqkp8 from default started at 2019-08-25 20:20:27 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container app ready: true, restart count 0
Aug 28 10:12:58.937: INFO: redis-proxy-76ff84c585-d2wwt from default started at 2019-08-25 20:18:14 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container haproxy ready: true, restart count 0
Aug 28 10:12:58.937: INFO: heapster-s76t8 from openshift-infra started at 2019-08-25 20:20:30 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container heapster ready: true, restart count 0
Aug 28 10:12:58.937: INFO: milk-user-server-55c7c9bc48-2dzp5 from space80d22279 started at 2019-08-27 16:49:36 +0800 CST (2 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 10:12:58.937: INFO: 	Container user-server ready: true, restart count 0
Aug 28 10:12:58.937: INFO: os-weave-scope-agent-9h5l2 from default started at 2019-08-15 14:29:56 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container scope-agent ready: true, restart count 1
Aug 28 10:12:58.937: INFO: os-log-daemonset-wcd7s from default started at 2019-08-15 14:29:56 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container oslogmgt ready: true, restart count 1
Aug 28 10:12:58.937: INFO: database-server-86c6c767b8-7n4hn from space80d22279 started at 2019-08-27 16:49:36 +0800 CST (2 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container database-server ready: true, restart count 0
Aug 28 10:12:58.937: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 10:12:58.937: INFO: sync-4l8lz from openshift-node started at 2019-08-15 14:57:27 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container sync ready: true, restart count 1
Aug 28 10:12:58.937: INFO: milk-brands-server-569d5bb9fc-d5fg7 from space80d22279 started at 2019-08-26 15:22:38 +0800 CST (2 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container brands-server ready: true, restart count 0
Aug 28 10:12:58.937: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 10:12:58.937: INFO: redisoperator-d96dc9d-ljrtt from default started at 2019-08-25 20:18:14 +0800 CST (1 container statuses recorded)
Aug 28 10:12:58.937: INFO: 	Container operator ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: verifying the node has the label node node-124
STEP: verifying the node has the label node node-128
STEP: verifying the node has the label node node-137
Aug 28 10:12:59.127: INFO: Pod istio-policy-68879ddc88-rv7wl requesting resource cpu=300m on Node node-137
Aug 28 10:12:59.127: INFO: Pod istio-telemetry-648598656c-rx95s requesting resource cpu=300m on Node node-128
Aug 28 10:12:59.127: INFO: Pod os-log-daemonset-7rwz8 requesting resource cpu=200m on Node node-124
Aug 28 10:12:59.127: INFO: Pod os-log-daemonset-wcd7s requesting resource cpu=200m on Node node-137
Aug 28 10:12:59.127: INFO: Pod os-log-daemonset-x56ph requesting resource cpu=200m on Node node-128
Aug 28 10:12:59.127: INFO: Pod os-weave-scope-agent-9h5l2 requesting resource cpu=200m on Node node-137
Aug 28 10:12:59.127: INFO: Pod os-weave-scope-agent-dh6qh requesting resource cpu=200m on Node node-128
Aug 28 10:12:59.127: INFO: Pod os-weave-scope-agent-grsw6 requesting resource cpu=200m on Node node-124
Aug 28 10:12:59.127: INFO: Pod os-weave-scope-app-67464966f6-xqkp8 requesting resource cpu=200m on Node node-137
Aug 28 10:12:59.127: INFO: Pod redis-proxy-76ff84c585-d2wwt requesting resource cpu=100m on Node node-137
Aug 28 10:12:59.127: INFO: Pod redisoperator-d96dc9d-ljrtt requesting resource cpu=10m on Node node-137
Aug 28 10:12:59.127: INFO: Pod heapster-s76t8 requesting resource cpu=0m on Node node-137
Aug 28 10:12:59.127: INFO: Pod metrics-server-57ff6c6465-dccxw requesting resource cpu=50m on Node node-137
Aug 28 10:12:59.127: INFO: Pod sync-4l8lz requesting resource cpu=50m on Node node-137
Aug 28 10:12:59.127: INFO: Pod sync-b5rks requesting resource cpu=50m on Node node-124
Aug 28 10:12:59.127: INFO: Pod sync-pbcjr requesting resource cpu=50m on Node node-128
Aug 28 10:12:59.127: INFO: Pod ovs-78jnp requesting resource cpu=100m on Node node-128
Aug 28 10:12:59.127: INFO: Pod ovs-t6trh requesting resource cpu=100m on Node node-137
Aug 28 10:12:59.127: INFO: Pod ovs-wbrm7 requesting resource cpu=100m on Node node-124
Aug 28 10:12:59.127: INFO: Pod sdn-bptkv requesting resource cpu=100m on Node node-124
Aug 28 10:12:59.127: INFO: Pod sdn-fzp9m requesting resource cpu=100m on Node node-137
Aug 28 10:12:59.127: INFO: Pod sdn-gszh2 requesting resource cpu=100m on Node node-128
Aug 28 10:12:59.127: INFO: Pod os-prometheus-kube-state-metrics-9d46ff684-gl2g8 requesting resource cpu=100m on Node node-137
Aug 28 10:12:59.127: INFO: Pod os-prometheus-prometheus-node-exporter-bhts2 requesting resource cpu=100m on Node node-124
Aug 28 10:12:59.127: INFO: Pod os-prometheus-prometheus-node-exporter-j5r86 requesting resource cpu=100m on Node node-128
Aug 28 10:12:59.127: INFO: Pod os-prometheus-prometheus-node-exporter-mvf5c requesting resource cpu=100m on Node node-137
Aug 28 10:12:59.127: INFO: Pod database-server-86c6c767b8-dtnf9 requesting resource cpu=600m on Node node-128
Aug 28 10:12:59.127: INFO: Pod database-server-86c6c767b8-k8d4s requesting resource cpu=600m on Node node-137
Aug 28 10:12:59.127: INFO: Pod front-server-c6d86d655-qknsn requesting resource cpu=600m on Node node-128
Aug 28 10:12:59.127: INFO: Pod milk-brands-server-569d5bb9fc-f69dc requesting resource cpu=600m on Node node-128
Aug 28 10:12:59.127: INFO: Pod milk-order-server-6557776f4c-mnb25 requesting resource cpu=600m on Node node-128
Aug 28 10:12:59.127: INFO: Pod milk-user-server-55c7c9bc48-qx9vh requesting resource cpu=600m on Node node-128
Aug 28 10:12:59.127: INFO: Pod milk-warehouse-server-667f499dbb-6jd9h requesting resource cpu=600m on Node node-128
Aug 28 10:12:59.127: INFO: Pod fortiotest-7f4b6c6dbc-wtnxn requesting resource cpu=200m on Node node-137
Aug 28 10:12:59.127: INFO: Pod database-server-86c6c767b8-7n4hn requesting resource cpu=800m on Node node-137
Aug 28 10:12:59.127: INFO: Pod database-server-86c6c767b8-gc4nr requesting resource cpu=800m on Node node-128
Aug 28 10:12:59.127: INFO: Pod front-server-c6d86d655-wzhpp requesting resource cpu=800m on Node node-128
Aug 28 10:12:59.127: INFO: Pod milk-brands-server-569d5bb9fc-d5fg7 requesting resource cpu=800m on Node node-137
Aug 28 10:12:59.127: INFO: Pod milk-order-server-6557776f4c-27rlx requesting resource cpu=800m on Node node-128
Aug 28 10:12:59.127: INFO: Pod milk-user-server-55c7c9bc48-2dzp5 requesting resource cpu=800m on Node node-137
Aug 28 10:12:59.127: INFO: Pod milk-warehouse-server-667f499dbb-vbptx requesting resource cpu=800m on Node node-128
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b297a65-c939-11e9-a0e2-288023b0a458.15bef45802d75931], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-grvc6/filler-pod-5b297a65-c939-11e9-a0e2-288023b0a458 to node-128]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b297a65-c939-11e9-a0e2-288023b0a458.15bef45895d378a1], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b297a65-c939-11e9-a0e2-288023b0a458.15bef458a291b929], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b297a65-c939-11e9-a0e2-288023b0a458.15bef458ad74c089], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b34f8e4-c939-11e9-a0e2-288023b0a458.15bef45806652146], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-grvc6/filler-pod-5b34f8e4-c939-11e9-a0e2-288023b0a458 to node-137]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b34f8e4-c939-11e9-a0e2-288023b0a458.15bef458fe703374], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b34f8e4-c939-11e9-a0e2-288023b0a458.15bef45935168fab], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b34f8e4-c939-11e9-a0e2-288023b0a458.15bef45948c62650], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b3d000e-c939-11e9-a0e2-288023b0a458.15bef4580acadf43], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-grvc6/filler-pod-5b3d000e-c939-11e9-a0e2-288023b0a458 to node-124]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b3d000e-c939-11e9-a0e2-288023b0a458.15bef458d4f8204a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b3d000e-c939-11e9-a0e2-288023b0a458.15bef45914b5b2f0], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b3d000e-c939-11e9-a0e2-288023b0a458.15bef4592cb97b26], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15bef459737f9876], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) were unschedulable.]
STEP: removing the label node off the node node-128
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node-137
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node-124
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:13:06.527: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-grvc6" for this suite.
Aug 28 10:13:30.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:13:30.713: INFO: namespace: e2e-tests-sched-pred-grvc6, resource: bindings, ignored listing per whitelist
Aug 28 10:13:33.653: INFO: namespace e2e-tests-sched-pred-grvc6 deletion completed in 27.109799988s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:95.379 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:13:33.653: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-hzkxg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should get a host IP [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating pod
Aug 28 10:13:40.416: INFO: Pod pod-hostip-700af4da-c939-11e9-a0e2-288023b0a458 has hostIP: 172.16.151.81
[AfterEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:13:40.416: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hzkxg" for this suite.
Aug 28 10:14:04.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:14:04.576: INFO: namespace: e2e-tests-pods-hzkxg, resource: bindings, ignored listing per whitelist
Aug 28 10:14:07.645: INFO: namespace e2e-tests-pods-hzkxg deletion completed in 27.124042479s

• [SLOW TEST:33.992 seconds]
[k8s.io] Pods
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should get a host IP [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:14:07.645: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-zr8lj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 28 10:14:08.130: INFO: Waiting up to 5m0s for pod "pod-843e3615-c939-11e9-a0e2-288023b0a458" in namespace "e2e-tests-emptydir-zr8lj" to be "success or failure"
Aug 28 10:14:08.158: INFO: Pod "pod-843e3615-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 27.740757ms
Aug 28 10:14:10.163: INFO: Pod "pod-843e3615-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032618021s
Aug 28 10:14:12.168: INFO: Pod "pod-843e3615-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03758887s
Aug 28 10:14:14.173: INFO: Pod "pod-843e3615-c939-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042852228s
STEP: Saw pod success
Aug 28 10:14:14.173: INFO: Pod "pod-843e3615-c939-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:14:14.177: INFO: Trying to get logs from node node-124 pod pod-843e3615-c939-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 10:14:14.351: INFO: Waiting for pod pod-843e3615-c939-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:14:14.354: INFO: Pod pod-843e3615-c939-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:14:14.354: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zr8lj" for this suite.
Aug 28 10:14:22.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:14:24.130: INFO: namespace: e2e-tests-emptydir-zr8lj, resource: bindings, ignored listing per whitelist
Aug 28 10:14:25.480: INFO: namespace e2e-tests-emptydir-zr8lj deletion completed in 11.118961013s

• [SLOW TEST:17.835 seconds]
[sig-storage] EmptyDir volumes
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:14:25.480: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-z9hs9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 28 10:14:26.108: INFO: Waiting up to 5m0s for pod "pod-8eef3b3d-c939-11e9-a0e2-288023b0a458" in namespace "e2e-tests-emptydir-z9hs9" to be "success or failure"
Aug 28 10:14:26.112: INFO: Pod "pod-8eef3b3d-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.998701ms
Aug 28 10:14:28.117: INFO: Pod "pod-8eef3b3d-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008883761s
Aug 28 10:14:30.122: INFO: Pod "pod-8eef3b3d-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013606449s
Aug 28 10:14:32.127: INFO: Pod "pod-8eef3b3d-c939-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.018609803s
Aug 28 10:14:34.131: INFO: Pod "pod-8eef3b3d-c939-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.023338499s
STEP: Saw pod success
Aug 28 10:14:34.131: INFO: Pod "pod-8eef3b3d-c939-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:14:34.135: INFO: Trying to get logs from node node-124 pod pod-8eef3b3d-c939-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 10:14:34.231: INFO: Waiting for pod pod-8eef3b3d-c939-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:14:34.235: INFO: Pod pod-8eef3b3d-c939-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:14:34.235: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z9hs9" for this suite.
Aug 28 10:14:42.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:14:43.768: INFO: namespace: e2e-tests-emptydir-z9hs9, resource: bindings, ignored listing per whitelist
Aug 28 10:14:45.370: INFO: namespace e2e-tests-emptydir-z9hs9 deletion completed in 11.126625585s

• [SLOW TEST:19.889 seconds]
[sig-storage] EmptyDir volumes
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:14:45.370: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-7959r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 10:14:45.842: INFO: (0) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 24.961453ms)
Aug 28 10:14:45.847: INFO: (1) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.221972ms)
Aug 28 10:14:45.853: INFO: (2) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.296492ms)
Aug 28 10:14:45.858: INFO: (3) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.300533ms)
Aug 28 10:14:45.864: INFO: (4) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.849595ms)
Aug 28 10:14:45.870: INFO: (5) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.717465ms)
Aug 28 10:14:45.875: INFO: (6) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.702268ms)
Aug 28 10:14:45.880: INFO: (7) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.64903ms)
Aug 28 10:14:45.886: INFO: (8) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.719321ms)
Aug 28 10:14:45.929: INFO: (9) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 42.952388ms)
Aug 28 10:14:45.935: INFO: (10) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.790744ms)
Aug 28 10:14:45.982: INFO: (11) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 47.377766ms)
Aug 28 10:14:45.988: INFO: (12) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.539733ms)
Aug 28 10:14:46.031: INFO: (13) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 43.179635ms)
Aug 28 10:14:46.054: INFO: (14) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 23.180843ms)
Aug 28 10:14:46.063: INFO: (15) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.3458ms)
Aug 28 10:14:46.071: INFO: (16) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.901193ms)
Aug 28 10:14:46.077: INFO: (17) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.99438ms)
Aug 28 10:14:46.082: INFO: (18) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.432326ms)
Aug 28 10:14:46.087: INFO: (19) /api/v1/nodes/node-124/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.188453ms)
[AfterEach] version v1
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:14:46.087: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-7959r" for this suite.
Aug 28 10:14:54.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:14:54.570: INFO: namespace: e2e-tests-proxy-7959r, resource: bindings, ignored listing per whitelist
Aug 28 10:14:54.576: INFO: namespace e2e-tests-proxy-7959r deletion completed in 8.482197797s

• [SLOW TEST:9.207 seconds]
[sig-network] Proxy
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:14:54.577: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-95plq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap e2e-tests-configmap-95plq/configmap-test-a04dfcfb-c939-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 10:14:55.220: INFO: Waiting up to 5m0s for pod "pod-configmaps-a05045ef-c939-11e9-a0e2-288023b0a458" in namespace "e2e-tests-configmap-95plq" to be "success or failure"
Aug 28 10:14:55.224: INFO: Pod "pod-configmaps-a05045ef-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.150346ms
Aug 28 10:14:57.228: INFO: Pod "pod-configmaps-a05045ef-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00881404s
Aug 28 10:14:59.234: INFO: Pod "pod-configmaps-a05045ef-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014516749s
Aug 28 10:15:01.239: INFO: Pod "pod-configmaps-a05045ef-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019475702s
Aug 28 10:15:03.244: INFO: Pod "pod-configmaps-a05045ef-c939-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.024546243s
STEP: Saw pod success
Aug 28 10:15:03.244: INFO: Pod "pod-configmaps-a05045ef-c939-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:15:03.248: INFO: Trying to get logs from node node-124 pod pod-configmaps-a05045ef-c939-11e9-a0e2-288023b0a458 container env-test: <nil>
STEP: delete the pod
Aug 28 10:15:03.319: INFO: Waiting for pod pod-configmaps-a05045ef-c939-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:15:03.328: INFO: Pod pod-configmaps-a05045ef-c939-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:15:03.328: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-95plq" for this suite.
Aug 28 10:15:11.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:15:14.165: INFO: namespace: e2e-tests-configmap-95plq, resource: bindings, ignored listing per whitelist
Aug 28 10:15:14.615: INFO: namespace e2e-tests-configmap-95plq deletion completed in 11.20102926s

• [SLOW TEST:20.039 seconds]
[sig-api-machinery] ConfigMap
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via the environment [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:15:14.616: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9zmz2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide podname only [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 10:15:15.082: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ac2891b7-c939-11e9-a0e2-288023b0a458" in namespace "e2e-tests-downward-api-9zmz2" to be "success or failure"
Aug 28 10:15:15.086: INFO: Pod "downwardapi-volume-ac2891b7-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.914566ms
Aug 28 10:15:17.090: INFO: Pod "downwardapi-volume-ac2891b7-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008319274s
Aug 28 10:15:19.095: INFO: Pod "downwardapi-volume-ac2891b7-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013316314s
Aug 28 10:15:21.106: INFO: Pod "downwardapi-volume-ac2891b7-c939-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.02389917s
Aug 28 10:15:23.113: INFO: Pod "downwardapi-volume-ac2891b7-c939-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.030650029s
STEP: Saw pod success
Aug 28 10:15:23.113: INFO: Pod "downwardapi-volume-ac2891b7-c939-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:15:23.116: INFO: Trying to get logs from node node-124 pod downwardapi-volume-ac2891b7-c939-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 10:15:23.150: INFO: Waiting for pod downwardapi-volume-ac2891b7-c939-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:15:23.154: INFO: Pod downwardapi-volume-ac2891b7-c939-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:15:23.154: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9zmz2" for this suite.
Aug 28 10:15:31.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:15:31.382: INFO: namespace: e2e-tests-downward-api-9zmz2, resource: bindings, ignored listing per whitelist
Aug 28 10:15:34.297: INFO: namespace e2e-tests-downward-api-9zmz2 deletion completed in 11.136162428s

• [SLOW TEST:19.682 seconds]
[sig-storage] Downward API volume
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide podname only [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:15:34.298: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-bxx85
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bxx85
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 28 10:15:34.683: INFO: Waiting up to 10m0s for all (but 3) nodes to be schedulable
STEP: Creating test pods
Aug 28 10:16:09.171: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.243.0.230:8080/dial?request=hostName&protocol=udp&host=10.243.0.229&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-bxx85 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:16:09.171: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:16:09.367: INFO: Waiting for endpoints: map[]
Aug 28 10:16:09.372: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.243.0.230:8080/dial?request=hostName&protocol=udp&host=10.245.0.54&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-bxx85 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:16:09.372: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:16:09.518: INFO: Waiting for endpoints: map[]
Aug 28 10:16:09.523: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.243.0.230:8080/dial?request=hostName&protocol=udp&host=10.244.1.29&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-bxx85 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:16:09.523: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:16:09.663: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:16:09.663: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bxx85" for this suite.
Aug 28 10:16:35.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:16:35.891: INFO: namespace: e2e-tests-pod-network-test-bxx85, resource: bindings, ignored listing per whitelist
Aug 28 10:16:38.797: INFO: namespace e2e-tests-pod-network-test-bxx85 deletion completed in 29.126762491s

• [SLOW TEST:64.500 seconds]
[sig-network] Networking
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:16:38.798: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-x97wr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create a job from an image, then delete the job  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: executing a command with run --rm and attach with stdin
Aug 28 10:16:39.349: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config --namespace=e2e-tests-kubectl-x97wr run e2e-test-rm-busybox-job --image=os-harbor-svc.default.svc.cloudos:443/library/busybox --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug 28 10:16:45.672: INFO: stderr: "If you don't see a command prompt, try pressing enter.\n"
Aug 28 10:16:45.672: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:16:47.679: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x97wr" for this suite.
Aug 28 10:16:57.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:16:57.785: INFO: namespace: e2e-tests-kubectl-x97wr, resource: bindings, ignored listing per whitelist
Aug 28 10:17:00.795: INFO: namespace e2e-tests-kubectl-x97wr deletion completed in 13.1089075s

• [SLOW TEST:21.997 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a job from an image, then delete the job  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:17:00.795: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rd7f7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 10:17:01.371: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb70ac35-c939-11e9-a0e2-288023b0a458" in namespace "e2e-tests-downward-api-rd7f7" to be "success or failure"
Aug 28 10:17:01.376: INFO: Pod "downwardapi-volume-eb70ac35-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.528861ms
Aug 28 10:17:03.384: INFO: Pod "downwardapi-volume-eb70ac35-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012698825s
Aug 28 10:17:05.389: INFO: Pod "downwardapi-volume-eb70ac35-c939-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017633453s
Aug 28 10:17:07.394: INFO: Pod "downwardapi-volume-eb70ac35-c939-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.022353004s
Aug 28 10:17:09.399: INFO: Pod "downwardapi-volume-eb70ac35-c939-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.027655738s
STEP: Saw pod success
Aug 28 10:17:09.399: INFO: Pod "downwardapi-volume-eb70ac35-c939-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:17:09.403: INFO: Trying to get logs from node node-124 pod downwardapi-volume-eb70ac35-c939-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 10:17:09.432: INFO: Waiting for pod downwardapi-volume-eb70ac35-c939-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:17:09.436: INFO: Pod downwardapi-volume-eb70ac35-c939-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:17:09.436: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rd7f7" for this suite.
Aug 28 10:17:17.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:17:18.433: INFO: namespace: e2e-tests-downward-api-rd7f7, resource: bindings, ignored listing per whitelist
Aug 28 10:17:20.536: INFO: namespace e2e-tests-downward-api-rd7f7 deletion completed in 11.093553283s

• [SLOW TEST:19.741 seconds]
[sig-storage] Downward API volume
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] HostPath
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:17:20.536: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-2t8vp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:36
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test hostPath mode
Aug 28 10:17:21.268: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-2t8vp" to be "success or failure"
Aug 28 10:17:21.295: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 27.462444ms
Aug 28 10:17:23.300: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032383466s
Aug 28 10:17:25.305: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037314252s
Aug 28 10:17:27.310: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.04204741s
Aug 28 10:17:29.318: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.050276847s
STEP: Saw pod success
Aug 28 10:17:29.318: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug 28 10:17:29.336: INFO: Trying to get logs from node node-124 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug 28 10:17:29.503: INFO: Waiting for pod pod-host-path-test to disappear
Aug 28 10:17:29.508: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:17:29.508: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-2t8vp" for this suite.
Aug 28 10:17:37.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:17:37.612: INFO: namespace: e2e-tests-hostpath-2t8vp, resource: bindings, ignored listing per whitelist
Aug 28 10:17:40.629: INFO: namespace e2e-tests-hostpath-2t8vp deletion completed in 11.114262265s

• [SLOW TEST:20.093 seconds]
[sig-storage] HostPath
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:33
  should give a volume the correct mode [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:17:40.629: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-xhp9v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 28 10:17:41.169: INFO: Waiting up to 5m0s for pod "pod-03359b2d-c93a-11e9-a0e2-288023b0a458" in namespace "e2e-tests-emptydir-xhp9v" to be "success or failure"
Aug 28 10:17:41.205: INFO: Pod "pod-03359b2d-c93a-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 36.269105ms
Aug 28 10:17:43.230: INFO: Pod "pod-03359b2d-c93a-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061085355s
Aug 28 10:17:45.234: INFO: Pod "pod-03359b2d-c93a-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.065541799s
Aug 28 10:17:47.239: INFO: Pod "pod-03359b2d-c93a-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.070347407s
Aug 28 10:17:49.244: INFO: Pod "pod-03359b2d-c93a-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.075504885s
STEP: Saw pod success
Aug 28 10:17:49.245: INFO: Pod "pod-03359b2d-c93a-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:17:49.248: INFO: Trying to get logs from node node-124 pod pod-03359b2d-c93a-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 10:17:49.332: INFO: Waiting for pod pod-03359b2d-c93a-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:17:49.336: INFO: Pod pod-03359b2d-c93a-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:17:49.336: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xhp9v" for this suite.
Aug 28 10:17:57.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:17:57.565: INFO: namespace: e2e-tests-emptydir-xhp9v, resource: bindings, ignored listing per whitelist
Aug 28 10:18:00.501: INFO: namespace e2e-tests-emptydir-xhp9v deletion completed in 11.157566642s

• [SLOW TEST:19.871 seconds]
[sig-storage] EmptyDir volumes
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:18:00.501: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-dwv4p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 28 10:18:17.156: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dwv4p PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:18:17.156: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:18:17.319: INFO: Exec stderr: ""
Aug 28 10:18:17.319: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dwv4p PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:18:17.319: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:18:17.457: INFO: Exec stderr: ""
Aug 28 10:18:17.457: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dwv4p PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:18:17.457: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:18:17.601: INFO: Exec stderr: ""
Aug 28 10:18:17.601: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dwv4p PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:18:17.601: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:18:17.739: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 28 10:18:17.739: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dwv4p PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:18:17.739: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:18:17.886: INFO: Exec stderr: ""
Aug 28 10:18:17.886: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dwv4p PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:18:17.886: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:18:18.032: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 28 10:18:18.032: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dwv4p PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:18:18.032: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:18:18.170: INFO: Exec stderr: ""
Aug 28 10:18:18.170: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dwv4p PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:18:18.170: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:18:18.318: INFO: Exec stderr: ""
Aug 28 10:18:18.319: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dwv4p PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:18:18.319: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:18:18.462: INFO: Exec stderr: ""
Aug 28 10:18:18.463: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dwv4p PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 10:18:18.463: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 10:18:18.601: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:18:18.601: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-dwv4p" for this suite.
Aug 28 10:19:10.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:19:13.813: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-dwv4p, resource: bindings, ignored listing per whitelist
Aug 28 10:19:13.913: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-dwv4p deletion completed in 55.305536255s

• [SLOW TEST:73.412 seconds]
[k8s.io] KubeletManagedEtcHosts
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:19:13.914: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-2pbmj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 Pods, got 2 Pods
STEP: Gathering metrics
W0828 10:19:15.641927   76809 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 28 10:19:15.642: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:19:15.642: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2pbmj" for this suite.
Aug 28 10:19:23.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:19:23.764: INFO: namespace: e2e-tests-gc-2pbmj, resource: bindings, ignored listing per whitelist
Aug 28 10:19:26.774: INFO: namespace e2e-tests-gc-2pbmj deletion completed in 11.095077944s

• [SLOW TEST:12.861 seconds]
[sig-api-machinery] Garbage collector
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:19:26.774: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-gxp7s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 28 10:19:27.394: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-gxp7s,SelfLink:/api/v1/namespaces/e2e-tests-watch-gxp7s/configmaps/e2e-watch-test-watch-closed,UID:427da485-c93a-11e9-bbca-288023b0a1ec,ResourceVersion:15117064,Generation:0,CreationTimestamp:2019-08-28 10:19:27 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 28 10:19:27.395: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-gxp7s,SelfLink:/api/v1/namespaces/e2e-tests-watch-gxp7s/configmaps/e2e-watch-test-watch-closed,UID:427da485-c93a-11e9-bbca-288023b0a1ec,ResourceVersion:15117069,Generation:0,CreationTimestamp:2019-08-28 10:19:27 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 28 10:19:27.454: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-gxp7s,SelfLink:/api/v1/namespaces/e2e-tests-watch-gxp7s/configmaps/e2e-watch-test-watch-closed,UID:427da485-c93a-11e9-bbca-288023b0a1ec,ResourceVersion:15117072,Generation:0,CreationTimestamp:2019-08-28 10:19:27 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 28 10:19:27.455: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-gxp7s,SelfLink:/api/v1/namespaces/e2e-tests-watch-gxp7s/configmaps/e2e-watch-test-watch-closed,UID:427da485-c93a-11e9-bbca-288023b0a1ec,ResourceVersion:15117073,Generation:0,CreationTimestamp:2019-08-28 10:19:27 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:19:27.455: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-gxp7s" for this suite.
Aug 28 10:19:35.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:19:37.053: INFO: namespace: e2e-tests-watch-gxp7s, resource: bindings, ignored listing per whitelist
Aug 28 10:19:38.581: INFO: namespace e2e-tests-watch-gxp7s deletion completed in 11.119520083s

• [SLOW TEST:11.807 seconds]
[sig-api-machinery] Watchers
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:19:38.581: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-kxld2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating service endpoint-test2 in namespace e2e-tests-services-kxld2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kxld2 to expose endpoints map[]
Aug 28 10:19:39.029: INFO: Get endpoints failed (3.84234ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Aug 28 10:19:40.033: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kxld2 exposes endpoints map[] (1.007975495s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-kxld2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kxld2 to expose endpoints map[pod1:[80]]
Aug 28 10:19:44.183: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.098456212s elapsed, will retry)
Aug 28 10:19:46.201: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kxld2 exposes endpoints map[pod1:[80]] (6.116121741s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-kxld2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kxld2 to expose endpoints map[pod1:[80] pod2:[80]]
Aug 28 10:19:50.321: INFO: Unexpected endpoints: found map[4a22fc7e-c93a-11e9-bbca-288023b0a1ec:[80]], expected map[pod1:[80] pod2:[80]] (4.088474525s elapsed, will retry)
Aug 28 10:19:51.333: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kxld2 exposes endpoints map[pod1:[80] pod2:[80]] (5.100968468s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-kxld2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kxld2 to expose endpoints map[pod2:[80]]
Aug 28 10:19:52.393: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kxld2 exposes endpoints map[pod2:[80]] (1.028994039s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-kxld2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kxld2 to expose endpoints map[]
Aug 28 10:19:53.422: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kxld2 exposes endpoints map[] (1.009870864s elapsed)
[AfterEach] [sig-network] Services
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:19:53.488: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-kxld2" for this suite.
Aug 28 10:20:17.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:20:19.857: INFO: namespace: e2e-tests-services-kxld2, resource: bindings, ignored listing per whitelist
Aug 28 10:20:20.595: INFO: namespace e2e-tests-services-kxld2 deletion completed in 27.098823603s
[AfterEach] [sig-network] Services
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:42.014 seconds]
[sig-network] Services
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:20:20.595: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xmbnp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run deployment
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1316
[It] should create a deployment from an image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Aug 28 10:20:21.023: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config run e2e-test-nginx-deployment --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-xmbnp'
Aug 28 10:20:21.545: INFO: stderr: ""
Aug 28 10:20:21.545: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1321
Aug 28 10:20:25.588: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-xmbnp'
Aug 28 10:20:26.063: INFO: stderr: ""
Aug 28 10:20:26.063: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:20:26.063: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xmbnp" for this suite.
Aug 28 10:21:06.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:21:06.326: INFO: namespace: e2e-tests-kubectl-xmbnp, resource: bindings, ignored listing per whitelist
Aug 28 10:21:09.236: INFO: namespace e2e-tests-kubectl-xmbnp deletion completed in 43.166290635s

• [SLOW TEST:48.641 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a deployment from an image  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Service endpoints latency
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:21:09.236: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-8xnfm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-8xnfm
I0828 10:21:09.658876   76809 runners.go:177] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-8xnfm, replica count: 1
I0828 10:21:10.709353   76809 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0828 10:21:11.709575   76809 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0828 10:21:12.711333   76809 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0828 10:21:13.711548   76809 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0828 10:21:14.711802   76809 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0828 10:21:15.711997   76809 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 28 10:21:15.858: INFO: Created: latency-svc-cklnz
Aug 28 10:21:15.892: INFO: Got endpoints: latency-svc-cklnz [80.500843ms]
Aug 28 10:21:15.932: INFO: Created: latency-svc-sgh28
Aug 28 10:21:15.955: INFO: Got endpoints: latency-svc-sgh28 [62.964571ms]
Aug 28 10:21:15.962: INFO: Created: latency-svc-trt7c
Aug 28 10:21:15.993: INFO: Got endpoints: latency-svc-trt7c [100.04895ms]
Aug 28 10:21:16.008: INFO: Created: latency-svc-65f8v
Aug 28 10:21:16.042: INFO: Got endpoints: latency-svc-65f8v [148.995465ms]
Aug 28 10:21:16.051: INFO: Created: latency-svc-lpznq
Aug 28 10:21:16.077: INFO: Got endpoints: latency-svc-lpznq [184.021515ms]
Aug 28 10:21:16.087: INFO: Created: latency-svc-vtm4j
Aug 28 10:21:16.123: INFO: Got endpoints: latency-svc-vtm4j [230.574843ms]
Aug 28 10:21:16.134: INFO: Created: latency-svc-t4p47
Aug 28 10:21:16.177: INFO: Got endpoints: latency-svc-t4p47 [284.067284ms]
Aug 28 10:21:16.182: INFO: Created: latency-svc-d5xz4
Aug 28 10:21:16.215: INFO: Created: latency-svc-8tf4m
Aug 28 10:21:16.215: INFO: Got endpoints: latency-svc-d5xz4 [322.242622ms]
Aug 28 10:21:16.247: INFO: Got endpoints: latency-svc-8tf4m [354.78719ms]
Aug 28 10:21:16.278: INFO: Created: latency-svc-ppbs4
Aug 28 10:21:16.314: INFO: Got endpoints: latency-svc-ppbs4 [421.022033ms]
Aug 28 10:21:16.322: INFO: Created: latency-svc-wk8x7
Aug 28 10:21:16.356: INFO: Got endpoints: latency-svc-wk8x7 [462.999677ms]
Aug 28 10:21:16.364: INFO: Created: latency-svc-x8wdw
Aug 28 10:21:16.399: INFO: Got endpoints: latency-svc-x8wdw [506.280725ms]
Aug 28 10:21:16.424: INFO: Created: latency-svc-bgjbf
Aug 28 10:21:16.464: INFO: Got endpoints: latency-svc-bgjbf [571.182008ms]
Aug 28 10:21:16.473: INFO: Created: latency-svc-nhsvh
Aug 28 10:21:16.508: INFO: Got endpoints: latency-svc-nhsvh [614.809632ms]
Aug 28 10:21:16.516: INFO: Created: latency-svc-7gtx4
Aug 28 10:21:16.547: INFO: Got endpoints: latency-svc-7gtx4 [653.698023ms]
Aug 28 10:21:16.565: INFO: Created: latency-svc-pwbpx
Aug 28 10:21:16.589: INFO: Got endpoints: latency-svc-pwbpx [696.06642ms]
Aug 28 10:21:16.597: INFO: Created: latency-svc-xhzsf
Aug 28 10:21:16.633: INFO: Got endpoints: latency-svc-xhzsf [677.876535ms]
Aug 28 10:21:16.641: INFO: Created: latency-svc-m62wd
Aug 28 10:21:16.664: INFO: Got endpoints: latency-svc-m62wd [670.896895ms]
Aug 28 10:21:16.685: INFO: Created: latency-svc-brrxx
Aug 28 10:21:16.706: INFO: Got endpoints: latency-svc-brrxx [663.893097ms]
Aug 28 10:21:16.715: INFO: Created: latency-svc-8sb5j
Aug 28 10:21:16.740: INFO: Got endpoints: latency-svc-8sb5j [662.924473ms]
Aug 28 10:21:16.748: INFO: Created: latency-svc-5tds5
Aug 28 10:21:16.773: INFO: Got endpoints: latency-svc-5tds5 [649.260042ms]
Aug 28 10:21:16.793: INFO: Created: latency-svc-fjvr6
Aug 28 10:21:16.806: INFO: Got endpoints: latency-svc-fjvr6 [629.17108ms]
Aug 28 10:21:16.840: INFO: Created: latency-svc-dfzfl
Aug 28 10:21:16.864: INFO: Got endpoints: latency-svc-dfzfl [649.255543ms]
Aug 28 10:21:16.873: INFO: Created: latency-svc-56qft
Aug 28 10:21:16.913: INFO: Got endpoints: latency-svc-56qft [665.84548ms]
Aug 28 10:21:16.923: INFO: Created: latency-svc-dxrr9
Aug 28 10:21:16.948: INFO: Got endpoints: latency-svc-dxrr9 [634.336403ms]
Aug 28 10:21:16.956: INFO: Created: latency-svc-q2cdm
Aug 28 10:21:16.998: INFO: Got endpoints: latency-svc-q2cdm [642.304396ms]
Aug 28 10:21:17.033: INFO: Created: latency-svc-zvl8k
Aug 28 10:21:17.065: INFO: Got endpoints: latency-svc-zvl8k [665.708902ms]
Aug 28 10:21:17.073: INFO: Created: latency-svc-zxh6z
Aug 28 10:21:17.098: INFO: Got endpoints: latency-svc-zxh6z [633.897735ms]
Aug 28 10:21:17.109: INFO: Created: latency-svc-cvjsr
Aug 28 10:21:17.140: INFO: Got endpoints: latency-svc-cvjsr [631.748676ms]
Aug 28 10:21:17.159: INFO: Created: latency-svc-kx8xg
Aug 28 10:21:17.198: INFO: Got endpoints: latency-svc-kx8xg [651.613565ms]
Aug 28 10:21:17.207: INFO: Created: latency-svc-8jqlr
Aug 28 10:21:17.232: INFO: Got endpoints: latency-svc-8jqlr [642.711318ms]
Aug 28 10:21:17.240: INFO: Created: latency-svc-w2nts
Aug 28 10:21:17.265: INFO: Got endpoints: latency-svc-w2nts [631.215115ms]
Aug 28 10:21:17.286: INFO: Created: latency-svc-xqdxf
Aug 28 10:21:17.324: INFO: Got endpoints: latency-svc-xqdxf [659.680813ms]
Aug 28 10:21:17.332: INFO: Created: latency-svc-p9qml
Aug 28 10:21:17.358: INFO: Got endpoints: latency-svc-p9qml [652.749185ms]
Aug 28 10:21:17.364: INFO: Created: latency-svc-c2mll
Aug 28 10:21:17.395: INFO: Got endpoints: latency-svc-c2mll [655.398702ms]
Aug 28 10:21:17.400: INFO: Created: latency-svc-swwsr
Aug 28 10:21:17.433: INFO: Got endpoints: latency-svc-swwsr [660.189555ms]
Aug 28 10:21:17.442: INFO: Created: latency-svc-x9ftc
Aug 28 10:21:17.478: INFO: Got endpoints: latency-svc-x9ftc [672.222029ms]
Aug 28 10:21:17.484: INFO: Created: latency-svc-j95t2
Aug 28 10:21:17.508: INFO: Got endpoints: latency-svc-j95t2 [643.503567ms]
Aug 28 10:21:17.525: INFO: Created: latency-svc-qd7v5
Aug 28 10:21:17.550: INFO: Got endpoints: latency-svc-qd7v5 [637.016314ms]
Aug 28 10:21:17.559: INFO: Created: latency-svc-96fns
Aug 28 10:21:17.592: INFO: Got endpoints: latency-svc-96fns [644.055556ms]
Aug 28 10:21:17.600: INFO: Created: latency-svc-dqvb2
Aug 28 10:21:17.627: INFO: Got endpoints: latency-svc-dqvb2 [629.205993ms]
Aug 28 10:21:17.647: INFO: Created: latency-svc-256vv
Aug 28 10:21:17.669: INFO: Got endpoints: latency-svc-256vv [604.572098ms]
Aug 28 10:21:17.676: INFO: Created: latency-svc-8p762
Aug 28 10:21:17.709: INFO: Got endpoints: latency-svc-8p762 [611.399175ms]
Aug 28 10:21:17.717: INFO: Created: latency-svc-pbcbv
Aug 28 10:21:17.764: INFO: Got endpoints: latency-svc-pbcbv [624.802027ms]
Aug 28 10:21:17.765: INFO: Created: latency-svc-f7wwz
Aug 28 10:21:17.801: INFO: Got endpoints: latency-svc-f7wwz [602.797566ms]
Aug 28 10:21:17.810: INFO: Created: latency-svc-ln9vc
Aug 28 10:21:17.848: INFO: Got endpoints: latency-svc-ln9vc [616.300369ms]
Aug 28 10:21:17.862: INFO: Created: latency-svc-5phkz
Aug 28 10:21:17.908: INFO: Got endpoints: latency-svc-5phkz [643.441376ms]
Aug 28 10:21:17.911: INFO: Created: latency-svc-cg8x5
Aug 28 10:21:17.932: INFO: Got endpoints: latency-svc-cg8x5 [608.387343ms]
Aug 28 10:21:17.942: INFO: Created: latency-svc-qnp6t
Aug 28 10:21:17.968: INFO: Got endpoints: latency-svc-qnp6t [609.742985ms]
Aug 28 10:21:17.982: INFO: Created: latency-svc-6jhv7
Aug 28 10:21:18.017: INFO: Got endpoints: latency-svc-6jhv7 [621.729305ms]
Aug 28 10:21:18.025: INFO: Created: latency-svc-bptrc
Aug 28 10:21:18.093: INFO: Got endpoints: latency-svc-bptrc [660.055834ms]
Aug 28 10:21:18.102: INFO: Created: latency-svc-sjgz2
Aug 28 10:21:18.195: INFO: Created: latency-svc-rws97
Aug 28 10:21:18.195: INFO: Got endpoints: latency-svc-rws97 [687.570335ms]
Aug 28 10:21:18.195: INFO: Got endpoints: latency-svc-sjgz2 [717.074412ms]
Aug 28 10:21:18.252: INFO: Created: latency-svc-r8tb7
Aug 28 10:21:18.275: INFO: Got endpoints: latency-svc-r8tb7 [724.983968ms]
Aug 28 10:21:18.284: INFO: Created: latency-svc-sfrvf
Aug 28 10:21:18.311: INFO: Got endpoints: latency-svc-sfrvf [719.019463ms]
Aug 28 10:21:18.318: INFO: Created: latency-svc-dlgd5
Aug 28 10:21:18.363: INFO: Got endpoints: latency-svc-dlgd5 [735.676351ms]
Aug 28 10:21:18.363: INFO: Created: latency-svc-pj4q9
Aug 28 10:21:18.393: INFO: Got endpoints: latency-svc-pj4q9 [723.998501ms]
Aug 28 10:21:18.401: INFO: Created: latency-svc-9qr9g
Aug 28 10:21:18.425: INFO: Got endpoints: latency-svc-9qr9g [715.345168ms]
Aug 28 10:21:18.431: INFO: Created: latency-svc-qp9j2
Aug 28 10:21:18.465: INFO: Got endpoints: latency-svc-qp9j2 [700.632887ms]
Aug 28 10:21:18.473: INFO: Created: latency-svc-dkdrb
Aug 28 10:21:18.497: INFO: Got endpoints: latency-svc-dkdrb [695.455352ms]
Aug 28 10:21:18.510: INFO: Created: latency-svc-z6kx5
Aug 28 10:21:18.534: INFO: Got endpoints: latency-svc-z6kx5 [685.975186ms]
Aug 28 10:21:18.545: INFO: Created: latency-svc-jx2qd
Aug 28 10:21:18.572: INFO: Got endpoints: latency-svc-jx2qd [664.321583ms]
Aug 28 10:21:18.592: INFO: Created: latency-svc-96nl2
Aug 28 10:21:18.636: INFO: Got endpoints: latency-svc-96nl2 [703.845355ms]
Aug 28 10:21:18.650: INFO: Created: latency-svc-hnpzn
Aug 28 10:21:18.683: INFO: Got endpoints: latency-svc-hnpzn [714.616862ms]
Aug 28 10:21:18.712: INFO: Created: latency-svc-6dh9k
Aug 28 10:21:18.764: INFO: Got endpoints: latency-svc-6dh9k [747.320401ms]
Aug 28 10:21:18.795: INFO: Created: latency-svc-9g8zx
Aug 28 10:21:18.819: INFO: Got endpoints: latency-svc-9g8zx [725.652795ms]
Aug 28 10:21:18.825: INFO: Created: latency-svc-7rjf4
Aug 28 10:21:18.856: INFO: Got endpoints: latency-svc-7rjf4 [660.594794ms]
Aug 28 10:21:18.861: INFO: Created: latency-svc-kb9jh
Aug 28 10:21:18.872: INFO: Got endpoints: latency-svc-kb9jh [676.757634ms]
Aug 28 10:21:18.909: INFO: Created: latency-svc-nwf56
Aug 28 10:21:18.938: INFO: Got endpoints: latency-svc-nwf56 [662.983488ms]
Aug 28 10:21:18.950: INFO: Created: latency-svc-cnfwz
Aug 28 10:21:18.975: INFO: Got endpoints: latency-svc-cnfwz [663.463527ms]
Aug 28 10:21:18.980: INFO: Created: latency-svc-f8qq6
Aug 28 10:21:19.005: INFO: Got endpoints: latency-svc-f8qq6 [641.364843ms]
Aug 28 10:21:19.011: INFO: Created: latency-svc-vl5hf
Aug 28 10:21:19.040: INFO: Got endpoints: latency-svc-vl5hf [646.909459ms]
Aug 28 10:21:19.060: INFO: Created: latency-svc-dcwwj
Aug 28 10:21:19.075: INFO: Got endpoints: latency-svc-dcwwj [650.066796ms]
Aug 28 10:21:19.101: INFO: Created: latency-svc-2d872
Aug 28 10:21:19.124: INFO: Got endpoints: latency-svc-2d872 [659.182917ms]
Aug 28 10:21:19.131: INFO: Created: latency-svc-88257
Aug 28 10:21:19.159: INFO: Got endpoints: latency-svc-88257 [662.83189ms]
Aug 28 10:21:19.160: INFO: Created: latency-svc-gvpjz
Aug 28 10:21:19.202: INFO: Got endpoints: latency-svc-gvpjz [667.471271ms]
Aug 28 10:21:19.209: INFO: Created: latency-svc-48h2j
Aug 28 10:21:19.234: INFO: Got endpoints: latency-svc-48h2j [661.445652ms]
Aug 28 10:21:19.244: INFO: Created: latency-svc-979nd
Aug 28 10:21:19.268: INFO: Got endpoints: latency-svc-979nd [631.968231ms]
Aug 28 10:21:19.274: INFO: Created: latency-svc-j72cd
Aug 28 10:21:19.301: INFO: Got endpoints: latency-svc-j72cd [618.059038ms]
Aug 28 10:21:19.302: INFO: Created: latency-svc-qkzsf
Aug 28 10:21:19.340: INFO: Got endpoints: latency-svc-qkzsf [575.721098ms]
Aug 28 10:21:19.347: INFO: Created: latency-svc-69pjb
Aug 28 10:21:19.373: INFO: Got endpoints: latency-svc-69pjb [553.779681ms]
Aug 28 10:21:19.385: INFO: Created: latency-svc-648ns
Aug 28 10:21:19.410: INFO: Got endpoints: latency-svc-648ns [553.635285ms]
Aug 28 10:21:19.418: INFO: Created: latency-svc-smvbm
Aug 28 10:21:19.443: INFO: Got endpoints: latency-svc-smvbm [570.323071ms]
Aug 28 10:21:19.461: INFO: Created: latency-svc-n49j5
Aug 28 10:21:19.501: INFO: Got endpoints: latency-svc-n49j5 [562.76643ms]
Aug 28 10:21:19.502: INFO: Created: latency-svc-dhhk4
Aug 28 10:21:19.526: INFO: Got endpoints: latency-svc-dhhk4 [551.476283ms]
Aug 28 10:21:19.535: INFO: Created: latency-svc-z6mlk
Aug 28 10:21:19.567: INFO: Got endpoints: latency-svc-z6mlk [562.574405ms]
Aug 28 10:21:19.588: INFO: Created: latency-svc-dvxfr
Aug 28 10:21:19.626: INFO: Got endpoints: latency-svc-dvxfr [585.405403ms]
Aug 28 10:21:19.635: INFO: Created: latency-svc-8lq28
Aug 28 10:21:19.656: INFO: Got endpoints: latency-svc-8lq28 [580.785584ms]
Aug 28 10:21:19.665: INFO: Created: latency-svc-d8ms9
Aug 28 10:21:19.689: INFO: Got endpoints: latency-svc-d8ms9 [564.624824ms]
Aug 28 10:21:19.698: INFO: Created: latency-svc-7b7pc
Aug 28 10:21:19.730: INFO: Got endpoints: latency-svc-7b7pc [569.950714ms]
Aug 28 10:21:19.735: INFO: Created: latency-svc-hdclq
Aug 28 10:21:19.758: INFO: Got endpoints: latency-svc-hdclq [556.282634ms]
Aug 28 10:21:19.765: INFO: Created: latency-svc-6r5kr
Aug 28 10:21:19.788: INFO: Got endpoints: latency-svc-6r5kr [553.576734ms]
Aug 28 10:21:19.805: INFO: Created: latency-svc-pcjdr
Aug 28 10:21:19.826: INFO: Got endpoints: latency-svc-pcjdr [558.204153ms]
Aug 28 10:21:19.835: INFO: Created: latency-svc-jcf7x
Aug 28 10:21:19.868: INFO: Got endpoints: latency-svc-jcf7x [567.124427ms]
Aug 28 10:21:19.885: INFO: Created: latency-svc-m2p9c
Aug 28 10:21:19.916: INFO: Got endpoints: latency-svc-m2p9c [575.774119ms]
Aug 28 10:21:19.923: INFO: Created: latency-svc-9gpgh
Aug 28 10:21:19.955: INFO: Got endpoints: latency-svc-9gpgh [582.488195ms]
Aug 28 10:21:19.960: INFO: Created: latency-svc-tjlcl
Aug 28 10:21:20.009: INFO: Got endpoints: latency-svc-tjlcl [599.211476ms]
Aug 28 10:21:20.015: INFO: Created: latency-svc-7527j
Aug 28 10:21:20.048: INFO: Got endpoints: latency-svc-7527j [605.555766ms]
Aug 28 10:21:20.057: INFO: Created: latency-svc-lfndq
Aug 28 10:21:20.108: INFO: Got endpoints: latency-svc-lfndq [606.279281ms]
Aug 28 10:21:20.118: INFO: Created: latency-svc-hqg5b
Aug 28 10:21:20.159: INFO: Got endpoints: latency-svc-hqg5b [632.257675ms]
Aug 28 10:21:20.165: INFO: Created: latency-svc-gqwtv
Aug 28 10:21:20.208: INFO: Got endpoints: latency-svc-gqwtv [640.251041ms]
Aug 28 10:21:20.220: INFO: Created: latency-svc-g8929
Aug 28 10:21:20.249: INFO: Got endpoints: latency-svc-g8929 [622.92878ms]
Aug 28 10:21:20.257: INFO: Created: latency-svc-rv6xj
Aug 28 10:21:20.285: INFO: Got endpoints: latency-svc-rv6xj [629.027393ms]
Aug 28 10:21:20.324: INFO: Created: latency-svc-cj6c8
Aug 28 10:21:20.348: INFO: Got endpoints: latency-svc-cj6c8 [659.421117ms]
Aug 28 10:21:20.358: INFO: Created: latency-svc-nq9ql
Aug 28 10:21:20.387: INFO: Got endpoints: latency-svc-nq9ql [657.458649ms]
Aug 28 10:21:20.400: INFO: Created: latency-svc-47rj2
Aug 28 10:21:20.447: INFO: Got endpoints: latency-svc-47rj2 [689.418394ms]
Aug 28 10:21:20.449: INFO: Created: latency-svc-mwqjp
Aug 28 10:21:20.473: INFO: Got endpoints: latency-svc-mwqjp [685.788109ms]
Aug 28 10:21:20.482: INFO: Created: latency-svc-ts5t9
Aug 28 10:21:20.516: INFO: Got endpoints: latency-svc-ts5t9 [689.833888ms]
Aug 28 10:21:20.533: INFO: Created: latency-svc-624d4
Aug 28 10:21:20.579: INFO: Got endpoints: latency-svc-624d4 [710.936903ms]
Aug 28 10:21:20.591: INFO: Created: latency-svc-f5lbc
Aug 28 10:21:20.616: INFO: Got endpoints: latency-svc-f5lbc [699.642047ms]
Aug 28 10:21:20.624: INFO: Created: latency-svc-49q7g
Aug 28 10:21:20.659: INFO: Got endpoints: latency-svc-49q7g [703.641442ms]
Aug 28 10:21:20.665: INFO: Created: latency-svc-p8m9n
Aug 28 10:21:20.706: INFO: Got endpoints: latency-svc-p8m9n [697.026841ms]
Aug 28 10:21:20.741: INFO: Created: latency-svc-cjsfl
Aug 28 10:21:20.755: INFO: Got endpoints: latency-svc-cjsfl [706.619524ms]
Aug 28 10:21:20.755: INFO: Created: latency-svc-zfhkd
Aug 28 10:21:20.779: INFO: Got endpoints: latency-svc-zfhkd [671.020395ms]
Aug 28 10:21:20.784: INFO: Created: latency-svc-scmfp
Aug 28 10:21:20.823: INFO: Got endpoints: latency-svc-scmfp [664.27027ms]
Aug 28 10:21:20.835: INFO: Created: latency-svc-r57h7
Aug 28 10:21:20.850: INFO: Got endpoints: latency-svc-r57h7 [642.453546ms]
Aug 28 10:21:20.874: INFO: Created: latency-svc-nnjng
Aug 28 10:21:20.898: INFO: Got endpoints: latency-svc-nnjng [649.52072ms]
Aug 28 10:21:20.922: INFO: Created: latency-svc-gbzrc
Aug 28 10:21:20.952: INFO: Got endpoints: latency-svc-gbzrc [667.036174ms]
Aug 28 10:21:20.959: INFO: Created: latency-svc-f77c6
Aug 28 10:21:20.982: INFO: Got endpoints: latency-svc-f77c6 [633.775104ms]
Aug 28 10:21:20.989: INFO: Created: latency-svc-htng8
Aug 28 10:21:21.030: INFO: Got endpoints: latency-svc-htng8 [643.386055ms]
Aug 28 10:21:21.047: INFO: Created: latency-svc-b67bl
Aug 28 10:21:21.077: INFO: Got endpoints: latency-svc-b67bl [629.648202ms]
Aug 28 10:21:21.085: INFO: Created: latency-svc-htq9v
Aug 28 10:21:21.134: INFO: Got endpoints: latency-svc-htq9v [660.48212ms]
Aug 28 10:21:21.148: INFO: Created: latency-svc-ljdrj
Aug 28 10:21:21.193: INFO: Got endpoints: latency-svc-ljdrj [677.317374ms]
Aug 28 10:21:21.202: INFO: Created: latency-svc-c85dv
Aug 28 10:21:21.227: INFO: Got endpoints: latency-svc-c85dv [647.469407ms]
Aug 28 10:21:21.232: INFO: Created: latency-svc-jgfp7
Aug 28 10:21:21.268: INFO: Got endpoints: latency-svc-jgfp7 [652.756298ms]
Aug 28 10:21:21.274: INFO: Created: latency-svc-nllj4
Aug 28 10:21:21.309: INFO: Got endpoints: latency-svc-nllj4 [649.918971ms]
Aug 28 10:21:21.312: INFO: Created: latency-svc-qdxmg
Aug 28 10:21:21.336: INFO: Got endpoints: latency-svc-qdxmg [629.628115ms]
Aug 28 10:21:21.344: INFO: Created: latency-svc-zh2h9
Aug 28 10:21:21.368: INFO: Got endpoints: latency-svc-zh2h9 [613.358249ms]
Aug 28 10:21:21.377: INFO: Created: latency-svc-785f9
Aug 28 10:21:21.427: INFO: Got endpoints: latency-svc-785f9 [647.744658ms]
Aug 28 10:21:21.430: INFO: Created: latency-svc-bfsd5
Aug 28 10:21:21.461: INFO: Got endpoints: latency-svc-bfsd5 [637.852602ms]
Aug 28 10:21:21.466: INFO: Created: latency-svc-rz9wd
Aug 28 10:21:21.489: INFO: Got endpoints: latency-svc-rz9wd [639.361905ms]
Aug 28 10:21:21.496: INFO: Created: latency-svc-ffqht
Aug 28 10:21:21.526: INFO: Got endpoints: latency-svc-ffqht [627.884427ms]
Aug 28 10:21:21.544: INFO: Created: latency-svc-zrkph
Aug 28 10:21:21.579: INFO: Got endpoints: latency-svc-zrkph [627.273177ms]
Aug 28 10:21:21.586: INFO: Created: latency-svc-wx2xj
Aug 28 10:21:21.609: INFO: Got endpoints: latency-svc-wx2xj [626.760203ms]
Aug 28 10:21:21.611: INFO: Created: latency-svc-sclgc
Aug 28 10:21:21.634: INFO: Got endpoints: latency-svc-sclgc [602.946174ms]
Aug 28 10:21:21.640: INFO: Created: latency-svc-xkmxf
Aug 28 10:21:21.663: INFO: Got endpoints: latency-svc-xkmxf [586.07044ms]
Aug 28 10:21:21.670: INFO: Created: latency-svc-tpqc6
Aug 28 10:21:21.707: INFO: Got endpoints: latency-svc-tpqc6 [572.689816ms]
Aug 28 10:21:21.712: INFO: Created: latency-svc-j2rlb
Aug 28 10:21:21.749: INFO: Got endpoints: latency-svc-j2rlb [555.350936ms]
Aug 28 10:21:21.760: INFO: Created: latency-svc-h95bp
Aug 28 10:21:21.784: INFO: Got endpoints: latency-svc-h95bp [557.15176ms]
Aug 28 10:21:21.789: INFO: Created: latency-svc-h2cln
Aug 28 10:21:21.813: INFO: Got endpoints: latency-svc-h2cln [544.684627ms]
Aug 28 10:21:21.820: INFO: Created: latency-svc-dgjx9
Aug 28 10:21:21.858: INFO: Got endpoints: latency-svc-dgjx9 [549.06009ms]
Aug 28 10:21:21.861: INFO: Created: latency-svc-z7s2q
Aug 28 10:21:21.886: INFO: Got endpoints: latency-svc-z7s2q [549.613491ms]
Aug 28 10:21:21.894: INFO: Created: latency-svc-45clr
Aug 28 10:21:21.922: INFO: Got endpoints: latency-svc-45clr [553.534131ms]
Aug 28 10:21:21.927: INFO: Created: latency-svc-b6t4m
Aug 28 10:21:21.963: INFO: Got endpoints: latency-svc-b6t4m [536.501705ms]
Aug 28 10:21:21.982: INFO: Created: latency-svc-fwvpp
Aug 28 10:21:22.011: INFO: Got endpoints: latency-svc-fwvpp [550.195767ms]
Aug 28 10:21:22.028: INFO: Created: latency-svc-ttpjt
Aug 28 10:21:22.052: INFO: Got endpoints: latency-svc-ttpjt [562.793645ms]
Aug 28 10:21:22.060: INFO: Created: latency-svc-6rdk2
Aug 28 10:21:22.090: INFO: Got endpoints: latency-svc-6rdk2 [563.220185ms]
Aug 28 10:21:22.109: INFO: Created: latency-svc-tsdqx
Aug 28 10:21:22.149: INFO: Got endpoints: latency-svc-tsdqx [569.963662ms]
Aug 28 10:21:22.155: INFO: Created: latency-svc-h2b28
Aug 28 10:21:22.185: INFO: Got endpoints: latency-svc-h2b28 [575.961595ms]
Aug 28 10:21:22.191: INFO: Created: latency-svc-l8tjx
Aug 28 10:21:22.202: INFO: Got endpoints: latency-svc-l8tjx [568.651607ms]
Aug 28 10:21:22.246: INFO: Created: latency-svc-pnbt5
Aug 28 10:21:22.275: INFO: Got endpoints: latency-svc-pnbt5 [611.854278ms]
Aug 28 10:21:22.287: INFO: Created: latency-svc-xg2cp
Aug 28 10:21:22.294: INFO: Got endpoints: latency-svc-xg2cp [587.025343ms]
Aug 28 10:21:22.328: INFO: Created: latency-svc-db8s4
Aug 28 10:21:22.359: INFO: Got endpoints: latency-svc-db8s4 [609.813366ms]
Aug 28 10:21:22.395: INFO: Created: latency-svc-gwwgn
Aug 28 10:21:22.428: INFO: Got endpoints: latency-svc-gwwgn [643.87444ms]
Aug 28 10:21:22.437: INFO: Created: latency-svc-dmvfb
Aug 28 10:21:22.469: INFO: Got endpoints: latency-svc-dmvfb [655.53572ms]
Aug 28 10:21:22.478: INFO: Created: latency-svc-brsd2
Aug 28 10:21:22.511: INFO: Got endpoints: latency-svc-brsd2 [652.970435ms]
Aug 28 10:21:22.533: INFO: Created: latency-svc-bptf5
Aug 28 10:21:22.570: INFO: Got endpoints: latency-svc-bptf5 [684.577839ms]
Aug 28 10:21:22.581: INFO: Created: latency-svc-bj278
Aug 28 10:21:22.611: INFO: Got endpoints: latency-svc-bj278 [688.566695ms]
Aug 28 10:21:22.617: INFO: Created: latency-svc-4mzx9
Aug 28 10:21:22.653: INFO: Got endpoints: latency-svc-4mzx9 [690.284356ms]
Aug 28 10:21:22.659: INFO: Created: latency-svc-4b7qx
Aug 28 10:21:22.701: INFO: Got endpoints: latency-svc-4b7qx [689.197785ms]
Aug 28 10:21:22.712: INFO: Created: latency-svc-5bmrz
Aug 28 10:21:22.730: INFO: Got endpoints: latency-svc-5bmrz [678.094674ms]
Aug 28 10:21:22.737: INFO: Created: latency-svc-6gzhz
Aug 28 10:21:22.785: INFO: Got endpoints: latency-svc-6gzhz [695.302485ms]
Aug 28 10:21:22.785: INFO: Created: latency-svc-xd2t9
Aug 28 10:21:22.812: INFO: Got endpoints: latency-svc-xd2t9 [662.256857ms]
Aug 28 10:21:22.820: INFO: Created: latency-svc-jhpgt
Aug 28 10:21:22.845: INFO: Got endpoints: latency-svc-jhpgt [659.711543ms]
Aug 28 10:21:22.862: INFO: Created: latency-svc-c6xs5
Aug 28 10:21:22.888: INFO: Got endpoints: latency-svc-c6xs5 [685.301593ms]
Aug 28 10:21:22.918: INFO: Created: latency-svc-fxxbt
Aug 28 10:21:22.940: INFO: Got endpoints: latency-svc-fxxbt [664.86355ms]
Aug 28 10:21:22.948: INFO: Created: latency-svc-xvssf
Aug 28 10:21:22.981: INFO: Got endpoints: latency-svc-xvssf [687.546164ms]
Aug 28 10:21:22.991: INFO: Created: latency-svc-jpsvb
Aug 28 10:21:23.025: INFO: Got endpoints: latency-svc-jpsvb [666.196283ms]
Aug 28 10:21:23.032: INFO: Created: latency-svc-jrd24
Aug 28 10:21:23.057: INFO: Got endpoints: latency-svc-jrd24 [629.079106ms]
Aug 28 10:21:23.065: INFO: Created: latency-svc-xjgbq
Aug 28 10:21:23.099: INFO: Got endpoints: latency-svc-xjgbq [629.780662ms]
Aug 28 10:21:23.107: INFO: Created: latency-svc-t46vd
Aug 28 10:21:23.140: INFO: Got endpoints: latency-svc-t46vd [628.989309ms]
Aug 28 10:21:23.148: INFO: Created: latency-svc-xmcm7
Aug 28 10:21:23.173: INFO: Got endpoints: latency-svc-xmcm7 [603.127981ms]
Aug 28 10:21:23.182: INFO: Created: latency-svc-xhtw2
Aug 28 10:21:23.218: INFO: Got endpoints: latency-svc-xhtw2 [606.90408ms]
Aug 28 10:21:23.247: INFO: Created: latency-svc-frjk6
Aug 28 10:21:23.274: INFO: Got endpoints: latency-svc-frjk6 [620.550161ms]
Aug 28 10:21:23.283: INFO: Created: latency-svc-t75mr
Aug 28 10:21:23.307: INFO: Got endpoints: latency-svc-t75mr [606.355442ms]
Aug 28 10:21:23.320: INFO: Created: latency-svc-b9v87
Aug 28 10:21:23.362: INFO: Got endpoints: latency-svc-b9v87 [631.878339ms]
Aug 28 10:21:23.388: INFO: Created: latency-svc-6b97f
Aug 28 10:21:23.416: INFO: Got endpoints: latency-svc-6b97f [630.497708ms]
Aug 28 10:21:23.424: INFO: Created: latency-svc-wxtpq
Aug 28 10:21:23.449: INFO: Got endpoints: latency-svc-wxtpq [637.166151ms]
Aug 28 10:21:23.457: INFO: Created: latency-svc-qxntc
Aug 28 10:21:23.482: INFO: Got endpoints: latency-svc-qxntc [637.162463ms]
Aug 28 10:21:23.486: INFO: Created: latency-svc-nrzv4
Aug 28 10:21:23.530: INFO: Got endpoints: latency-svc-nrzv4 [642.324566ms]
Aug 28 10:21:23.537: INFO: Created: latency-svc-f4mmt
Aug 28 10:21:23.565: INFO: Got endpoints: latency-svc-f4mmt [625.266929ms]
Aug 28 10:21:23.574: INFO: Created: latency-svc-86xmp
Aug 28 10:21:23.618: INFO: Created: latency-svc-6lmn6
Aug 28 10:21:23.618: INFO: Got endpoints: latency-svc-86xmp [636.479653ms]
Aug 28 10:21:23.655: INFO: Got endpoints: latency-svc-6lmn6 [629.876953ms]
Aug 28 10:21:23.662: INFO: Created: latency-svc-n6vq4
Aug 28 10:21:23.691: INFO: Got endpoints: latency-svc-n6vq4 [633.797726ms]
Aug 28 10:21:23.700: INFO: Created: latency-svc-jzs5r
Aug 28 10:21:23.746: INFO: Got endpoints: latency-svc-jzs5r [647.452914ms]
Aug 28 10:21:23.797: INFO: Created: latency-svc-wxpzw
Aug 28 10:21:23.836: INFO: Got endpoints: latency-svc-wxpzw [695.963644ms]
Aug 28 10:21:23.859: INFO: Created: latency-svc-5c52m
Aug 28 10:21:23.903: INFO: Got endpoints: latency-svc-5c52m [729.117768ms]
Aug 28 10:21:23.919: INFO: Created: latency-svc-d5zvs
Aug 28 10:21:23.933: INFO: Got endpoints: latency-svc-d5zvs [715.008815ms]
Aug 28 10:21:23.958: INFO: Created: latency-svc-nlcn2
Aug 28 10:21:23.983: INFO: Got endpoints: latency-svc-nlcn2 [709.288489ms]
Aug 28 10:21:24.002: INFO: Created: latency-svc-c4d77
Aug 28 10:21:24.054: INFO: Got endpoints: latency-svc-c4d77 [746.47855ms]
Aug 28 10:21:24.054: INFO: Created: latency-svc-wxlm4
Aug 28 10:21:24.087: INFO: Got endpoints: latency-svc-wxlm4 [724.216223ms]
Aug 28 10:21:24.095: INFO: Created: latency-svc-85hk2
Aug 28 10:21:24.125: INFO: Got endpoints: latency-svc-85hk2 [709.598305ms]
Aug 28 10:21:24.137: INFO: Created: latency-svc-228h7
Aug 28 10:21:24.164: INFO: Got endpoints: latency-svc-228h7 [714.992337ms]
Aug 28 10:21:24.180: INFO: Created: latency-svc-m7zwh
Aug 28 10:21:24.203: INFO: Got endpoints: latency-svc-m7zwh [720.997912ms]
Aug 28 10:21:24.213: INFO: Created: latency-svc-6qxkl
Aug 28 10:21:24.262: INFO: Created: latency-svc-r45zb
Aug 28 10:21:24.262: INFO: Got endpoints: latency-svc-6qxkl [732.449433ms]
Aug 28 10:21:24.295: INFO: Got endpoints: latency-svc-r45zb [729.368746ms]
Aug 28 10:21:24.303: INFO: Created: latency-svc-9s87q
Aug 28 10:21:24.337: INFO: Got endpoints: latency-svc-9s87q [718.975796ms]
Aug 28 10:21:24.346: INFO: Created: latency-svc-4xfnk
Aug 28 10:21:24.385: INFO: Got endpoints: latency-svc-4xfnk [730.00925ms]
Aug 28 10:21:24.389: INFO: Created: latency-svc-rn67r
Aug 28 10:21:24.407: INFO: Got endpoints: latency-svc-rn67r [715.611119ms]
Aug 28 10:21:24.417: INFO: Created: latency-svc-v7mfd
Aug 28 10:21:24.453: INFO: Got endpoints: latency-svc-v7mfd [707.289446ms]
Aug 28 10:21:24.462: INFO: Created: latency-svc-ls686
Aug 28 10:21:24.470: INFO: Got endpoints: latency-svc-ls686 [633.438794ms]
Aug 28 10:21:24.470: INFO: Latencies: [62.964571ms 100.04895ms 148.995465ms 184.021515ms 230.574843ms 284.067284ms 322.242622ms 354.78719ms 421.022033ms 462.999677ms 506.280725ms 536.501705ms 544.684627ms 549.06009ms 549.613491ms 550.195767ms 551.476283ms 553.534131ms 553.576734ms 553.635285ms 553.779681ms 555.350936ms 556.282634ms 557.15176ms 558.204153ms 562.574405ms 562.76643ms 562.793645ms 563.220185ms 564.624824ms 567.124427ms 568.651607ms 569.950714ms 569.963662ms 570.323071ms 571.182008ms 572.689816ms 575.721098ms 575.774119ms 575.961595ms 580.785584ms 582.488195ms 585.405403ms 586.07044ms 587.025343ms 599.211476ms 602.797566ms 602.946174ms 603.127981ms 604.572098ms 605.555766ms 606.279281ms 606.355442ms 606.90408ms 608.387343ms 609.742985ms 609.813366ms 611.399175ms 611.854278ms 613.358249ms 614.809632ms 616.300369ms 618.059038ms 620.550161ms 621.729305ms 622.92878ms 624.802027ms 625.266929ms 626.760203ms 627.273177ms 627.884427ms 628.989309ms 629.027393ms 629.079106ms 629.17108ms 629.205993ms 629.628115ms 629.648202ms 629.780662ms 629.876953ms 630.497708ms 631.215115ms 631.748676ms 631.878339ms 631.968231ms 632.257675ms 633.438794ms 633.775104ms 633.797726ms 633.897735ms 634.336403ms 636.479653ms 637.016314ms 637.162463ms 637.166151ms 637.852602ms 639.361905ms 640.251041ms 641.364843ms 642.304396ms 642.324566ms 642.453546ms 642.711318ms 643.386055ms 643.441376ms 643.503567ms 643.87444ms 644.055556ms 646.909459ms 647.452914ms 647.469407ms 647.744658ms 649.255543ms 649.260042ms 649.52072ms 649.918971ms 650.066796ms 651.613565ms 652.749185ms 652.756298ms 652.970435ms 653.698023ms 655.398702ms 655.53572ms 657.458649ms 659.182917ms 659.421117ms 659.680813ms 659.711543ms 660.055834ms 660.189555ms 660.48212ms 660.594794ms 661.445652ms 662.256857ms 662.83189ms 662.924473ms 662.983488ms 663.463527ms 663.893097ms 664.27027ms 664.321583ms 664.86355ms 665.708902ms 665.84548ms 666.196283ms 667.036174ms 667.471271ms 670.896895ms 671.020395ms 672.222029ms 676.757634ms 677.317374ms 677.876535ms 678.094674ms 684.577839ms 685.301593ms 685.788109ms 685.975186ms 687.546164ms 687.570335ms 688.566695ms 689.197785ms 689.418394ms 689.833888ms 690.284356ms 695.302485ms 695.455352ms 695.963644ms 696.06642ms 697.026841ms 699.642047ms 700.632887ms 703.641442ms 703.845355ms 706.619524ms 707.289446ms 709.288489ms 709.598305ms 710.936903ms 714.616862ms 714.992337ms 715.008815ms 715.345168ms 715.611119ms 717.074412ms 718.975796ms 719.019463ms 720.997912ms 723.998501ms 724.216223ms 724.983968ms 725.652795ms 729.117768ms 729.368746ms 730.00925ms 732.449433ms 735.676351ms 746.47855ms 747.320401ms]
Aug 28 10:21:24.470: INFO: 50 %ile: 642.324566ms
Aug 28 10:21:24.470: INFO: 90 %ile: 714.616862ms
Aug 28 10:21:24.470: INFO: 99 %ile: 746.47855ms
Aug 28 10:21:24.470: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:21:24.471: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-8xnfm" for this suite.
Aug 28 10:21:58.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:21:58.660: INFO: namespace: e2e-tests-svc-latency-8xnfm, resource: bindings, ignored listing per whitelist
Aug 28 10:22:01.597: INFO: namespace e2e-tests-svc-latency-8xnfm deletion completed in 37.118655522s

• [SLOW TEST:52.361 seconds]
[sig-network] Service endpoints latency
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:22:01.597: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-rhdvc
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 10:22:02.066: INFO: Couldn't get node TTL annotation (using default value of 0): No TTL annotation found on the node
STEP: Creating secret with name s-test-opt-del-9ec771b5-c93a-11e9-a0e2-288023b0a458
STEP: Creating secret with name s-test-opt-upd-9ec77276-c93a-11e9-a0e2-288023b0a458
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-9ec771b5-c93a-11e9-a0e2-288023b0a458
STEP: Updating secret s-test-opt-upd-9ec77276-c93a-11e9-a0e2-288023b0a458
STEP: Creating secret with name s-test-opt-create-9ec772ce-c93a-11e9-a0e2-288023b0a458
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:23:16.797: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rhdvc" for this suite.
Aug 28 10:23:40.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:23:43.786: INFO: namespace: e2e-tests-secrets-rhdvc, resource: bindings, ignored listing per whitelist
Aug 28 10:23:43.937: INFO: namespace e2e-tests-secrets-rhdvc deletion completed in 27.133285995s

• [SLOW TEST:102.340 seconds]
[sig-storage] Secrets
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:23:43.937: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bz9jv
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 28 10:23:44.429: INFO: Waiting up to 5m0s for pod "pod-dbc0905d-c93a-11e9-a0e2-288023b0a458" in namespace "e2e-tests-emptydir-bz9jv" to be "success or failure"
Aug 28 10:23:44.455: INFO: Pod "pod-dbc0905d-c93a-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 25.365635ms
Aug 28 10:23:46.459: INFO: Pod "pod-dbc0905d-c93a-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029812478s
Aug 28 10:23:48.464: INFO: Pod "pod-dbc0905d-c93a-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035087536s
Aug 28 10:23:50.469: INFO: Pod "pod-dbc0905d-c93a-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.039775638s
Aug 28 10:23:52.474: INFO: Pod "pod-dbc0905d-c93a-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.044265304s
STEP: Saw pod success
Aug 28 10:23:52.474: INFO: Pod "pod-dbc0905d-c93a-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:23:52.477: INFO: Trying to get logs from node node-124 pod pod-dbc0905d-c93a-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 10:23:52.534: INFO: Waiting for pod pod-dbc0905d-c93a-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:23:52.538: INFO: Pod pod-dbc0905d-c93a-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:23:52.538: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bz9jv" for this suite.
Aug 28 10:24:00.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:24:02.958: INFO: namespace: e2e-tests-emptydir-bz9jv, resource: bindings, ignored listing per whitelist
Aug 28 10:24:03.656: INFO: namespace e2e-tests-emptydir-bz9jv deletion completed in 11.113426963s

• [SLOW TEST:19.719 seconds]
[sig-storage] EmptyDir volumes
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:24:03.657: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xm8b7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: validating cluster-info
Aug 28 10:24:04.124: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config cluster-info'
Aug 28 10:24:04.562: INFO: stderr: ""
Aug 28 10:24:04.562: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://vip.cluster.local:8443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:24:04.562: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xm8b7" for this suite.
Aug 28 10:24:12.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:24:12.744: INFO: namespace: e2e-tests-kubectl-xm8b7, resource: bindings, ignored listing per whitelist
Aug 28 10:24:15.748: INFO: namespace e2e-tests-kubectl-xm8b7 deletion completed in 11.179016168s

• [SLOW TEST:12.091 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:24:15.748: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8hdrs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-eebb1c25-c93a-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 10:24:16.293: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-eec16eca-c93a-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-8hdrs" to be "success or failure"
Aug 28 10:24:16.297: INFO: Pod "pod-projected-configmaps-eec16eca-c93a-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.851277ms
Aug 28 10:24:18.303: INFO: Pod "pod-projected-configmaps-eec16eca-c93a-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010306514s
Aug 28 10:24:20.330: INFO: Pod "pod-projected-configmaps-eec16eca-c93a-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036978327s
Aug 28 10:24:22.335: INFO: Pod "pod-projected-configmaps-eec16eca-c93a-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.041733854s
Aug 28 10:24:24.341: INFO: Pod "pod-projected-configmaps-eec16eca-c93a-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.048484543s
STEP: Saw pod success
Aug 28 10:24:24.341: INFO: Pod "pod-projected-configmaps-eec16eca-c93a-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:24:24.346: INFO: Trying to get logs from node node-124 pod pod-projected-configmaps-eec16eca-c93a-11e9-a0e2-288023b0a458 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 28 10:24:24.617: INFO: Waiting for pod pod-projected-configmaps-eec16eca-c93a-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:24:24.620: INFO: Pod pod-projected-configmaps-eec16eca-c93a-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:24:24.620: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8hdrs" for this suite.
Aug 28 10:24:32.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:24:33.265: INFO: namespace: e2e-tests-projected-8hdrs, resource: bindings, ignored listing per whitelist
Aug 28 10:24:35.714: INFO: namespace e2e-tests-projected-8hdrs deletion completed in 11.087446613s

• [SLOW TEST:19.967 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:24:35.715: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jhzkg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 10:24:36.226: INFO: Waiting up to 5m0s for pod "downwardapi-volume-faa5c55e-c93a-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-jhzkg" to be "success or failure"
Aug 28 10:24:36.230: INFO: Pod "downwardapi-volume-faa5c55e-c93a-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.188543ms
Aug 28 10:24:38.235: INFO: Pod "downwardapi-volume-faa5c55e-c93a-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009631829s
Aug 28 10:24:40.249: INFO: Pod "downwardapi-volume-faa5c55e-c93a-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023430777s
Aug 28 10:24:42.254: INFO: Pod "downwardapi-volume-faa5c55e-c93a-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028315116s
STEP: Saw pod success
Aug 28 10:24:42.254: INFO: Pod "downwardapi-volume-faa5c55e-c93a-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:24:42.258: INFO: Trying to get logs from node node-124 pod downwardapi-volume-faa5c55e-c93a-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 10:24:42.297: INFO: Waiting for pod downwardapi-volume-faa5c55e-c93a-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:24:42.300: INFO: Pod downwardapi-volume-faa5c55e-c93a-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:24:42.300: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jhzkg" for this suite.
Aug 28 10:24:50.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:24:50.483: INFO: namespace: e2e-tests-projected-jhzkg, resource: bindings, ignored listing per whitelist
Aug 28 10:24:53.442: INFO: namespace e2e-tests-projected-jhzkg deletion completed in 11.125916568s

• [SLOW TEST:17.727 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:24:53.442: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-fzxks
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 28 10:24:54.087: INFO: Waiting up to 5m0s for pod "pod-054760ea-c93b-11e9-a0e2-288023b0a458" in namespace "e2e-tests-emptydir-fzxks" to be "success or failure"
Aug 28 10:24:54.091: INFO: Pod "pod-054760ea-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.233449ms
Aug 28 10:24:56.117: INFO: Pod "pod-054760ea-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030668522s
Aug 28 10:24:58.122: INFO: Pod "pod-054760ea-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035447946s
Aug 28 10:25:00.126: INFO: Pod "pod-054760ea-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.039023811s
Aug 28 10:25:02.131: INFO: Pod "pod-054760ea-c93b-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.043987893s
STEP: Saw pod success
Aug 28 10:25:02.131: INFO: Pod "pod-054760ea-c93b-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:25:02.209: INFO: Trying to get logs from node node-124 pod pod-054760ea-c93b-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 10:25:02.261: INFO: Waiting for pod pod-054760ea-c93b-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:25:02.280: INFO: Pod pod-054760ea-c93b-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:25:02.280: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fzxks" for this suite.
Aug 28 10:25:10.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:25:10.383: INFO: namespace: e2e-tests-emptydir-fzxks, resource: bindings, ignored listing per whitelist
Aug 28 10:25:13.384: INFO: namespace e2e-tests-emptydir-fzxks deletion completed in 11.097271605s

• [SLOW TEST:19.942 seconds]
[sig-storage] EmptyDir volumes
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:25:13.384: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-psh96
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 10:25:13.914: INFO: Waiting up to 5m0s for pod "downwardapi-volume-11133777-c93b-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-psh96" to be "success or failure"
Aug 28 10:25:13.936: INFO: Pod "downwardapi-volume-11133777-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 22.234452ms
Aug 28 10:25:15.942: INFO: Pod "downwardapi-volume-11133777-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027769431s
Aug 28 10:25:18.012: INFO: Pod "downwardapi-volume-11133777-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.097899815s
Aug 28 10:25:20.017: INFO: Pod "downwardapi-volume-11133777-c93b-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.102911402s
STEP: Saw pod success
Aug 28 10:25:20.017: INFO: Pod "downwardapi-volume-11133777-c93b-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:25:20.022: INFO: Trying to get logs from node node-124 pod downwardapi-volume-11133777-c93b-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 10:25:20.071: INFO: Waiting for pod downwardapi-volume-11133777-c93b-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:25:20.075: INFO: Pod downwardapi-volume-11133777-c93b-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:25:20.075: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-psh96" for this suite.
Aug 28 10:25:28.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:25:30.729: INFO: namespace: e2e-tests-projected-psh96, resource: bindings, ignored listing per whitelist
Aug 28 10:25:31.179: INFO: namespace e2e-tests-projected-psh96 deletion completed in 11.096108496s

• [SLOW TEST:17.795 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:25:31.179: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-stltf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-9kjxz in namespace e2e-tests-proxy-stltf
I0828 10:25:31.730780   76809 runners.go:177] Created replication controller with name: proxy-service-9kjxz, namespace: e2e-tests-proxy-stltf, replica count: 1
I0828 10:25:32.781311   76809 runners.go:177] proxy-service-9kjxz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0828 10:25:33.781556   76809 runners.go:177] proxy-service-9kjxz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0828 10:25:34.781819   76809 runners.go:177] proxy-service-9kjxz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0828 10:25:35.782072   76809 runners.go:177] proxy-service-9kjxz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0828 10:25:36.782353   76809 runners.go:177] proxy-service-9kjxz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0828 10:25:37.782588   76809 runners.go:177] proxy-service-9kjxz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0828 10:25:38.782852   76809 runners.go:177] proxy-service-9kjxz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0828 10:25:39.783045   76809 runners.go:177] proxy-service-9kjxz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0828 10:25:40.783275   76809 runners.go:177] proxy-service-9kjxz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0828 10:25:41.783469   76809 runners.go:177] proxy-service-9kjxz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0828 10:25:42.783667   76809 runners.go:177] proxy-service-9kjxz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 28 10:25:42.788: INFO: setup took 11.165224957s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 28 10:25:42.799: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 11.072319ms)
Aug 28 10:25:42.799: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 11.510436ms)
Aug 28 10:25:42.799: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 11.590185ms)
Aug 28 10:25:42.799: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 11.634004ms)
Aug 28 10:25:42.799: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 11.722074ms)
Aug 28 10:25:42.811: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 23.093327ms)
Aug 28 10:25:42.811: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 23.579124ms)
Aug 28 10:25:42.811: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 23.741132ms)
Aug 28 10:25:42.811: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 23.587766ms)
Aug 28 10:25:42.891: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 103.492528ms)
Aug 28 10:25:42.891: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 103.504856ms)
Aug 28 10:25:42.892: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 104.05862ms)
Aug 28 10:25:42.892: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 104.455253ms)
Aug 28 10:25:42.892: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 104.437342ms)
Aug 28 10:25:42.892: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 104.271496ms)
Aug 28 10:25:42.901: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 113.575469ms)
Aug 28 10:25:42.906: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 5.070731ms)
Aug 28 10:25:42.907: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 5.75546ms)
Aug 28 10:25:42.908: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 6.176067ms)
Aug 28 10:25:42.908: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 6.394606ms)
Aug 28 10:25:42.908: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 6.295868ms)
Aug 28 10:25:42.908: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 6.305216ms)
Aug 28 10:25:42.908: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 6.341074ms)
Aug 28 10:25:42.908: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 6.423376ms)
Aug 28 10:25:42.908: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 6.403613ms)
Aug 28 10:25:42.908: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 6.473458ms)
Aug 28 10:25:42.909: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 7.502535ms)
Aug 28 10:25:42.909: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 7.520045ms)
Aug 28 10:25:42.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 8.47491ms)
Aug 28 10:25:42.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 8.359549ms)
Aug 28 10:25:42.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 8.82349ms)
Aug 28 10:25:42.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 8.845746ms)
Aug 28 10:25:42.915: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 4.655908ms)
Aug 28 10:25:42.916: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 5.372811ms)
Aug 28 10:25:42.916: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 5.913587ms)
Aug 28 10:25:42.917: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 6.020206ms)
Aug 28 10:25:42.917: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 6.219336ms)
Aug 28 10:25:42.917: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 7.002366ms)
Aug 28 10:25:42.918: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 6.915105ms)
Aug 28 10:25:42.918: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 6.975618ms)
Aug 28 10:25:42.918: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 7.099161ms)
Aug 28 10:25:42.918: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 7.050438ms)
Aug 28 10:25:42.918: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 7.168212ms)
Aug 28 10:25:42.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 15.367105ms)
Aug 28 10:25:42.927: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 16.332059ms)
Aug 28 10:25:42.928: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 17.344653ms)
Aug 28 10:25:43.013: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 102.571379ms)
Aug 28 10:25:43.013: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 102.704927ms)
Aug 28 10:25:43.218: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 203.854247ms)
Aug 28 10:25:43.218: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 204.06131ms)
Aug 28 10:25:43.218: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 204.022215ms)
Aug 28 10:25:43.218: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 203.958497ms)
Aug 28 10:25:43.219: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 205.065509ms)
Aug 28 10:25:43.219: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 205.209939ms)
Aug 28 10:25:43.219: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 205.001011ms)
Aug 28 10:25:43.219: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 204.962052ms)
Aug 28 10:25:43.219: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 205.511631ms)
Aug 28 10:25:43.219: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 205.505992ms)
Aug 28 10:25:43.310: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 297.073241ms)
Aug 28 10:25:43.312: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 297.982383ms)
Aug 28 10:25:43.312: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 298.183692ms)
Aug 28 10:25:43.312: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 297.95489ms)
Aug 28 10:25:43.314: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 299.708173ms)
Aug 28 10:25:43.314: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 300.210591ms)
Aug 28 10:25:43.320: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 5.822611ms)
Aug 28 10:25:43.321: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 6.683587ms)
Aug 28 10:25:43.321: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 6.712694ms)
Aug 28 10:25:43.322: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 8.205495ms)
Aug 28 10:25:43.322: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 8.113405ms)
Aug 28 10:25:43.322: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 8.123303ms)
Aug 28 10:25:43.322: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 8.371711ms)
Aug 28 10:25:43.323: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 8.439345ms)
Aug 28 10:25:43.323: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 8.497343ms)
Aug 28 10:25:43.323: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 8.620628ms)
Aug 28 10:25:43.323: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 8.676537ms)
Aug 28 10:25:43.323: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 8.764979ms)
Aug 28 10:25:43.323: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 8.820487ms)
Aug 28 10:25:43.323: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 9.017171ms)
Aug 28 10:25:43.323: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 8.860329ms)
Aug 28 10:25:43.323: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 9.017845ms)
Aug 28 10:25:43.334: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 11.117718ms)
Aug 28 10:25:43.335: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 11.44489ms)
Aug 28 10:25:43.335: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 11.610562ms)
Aug 28 10:25:43.490: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 167.164098ms)
Aug 28 10:25:43.491: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 168.009783ms)
Aug 28 10:25:43.491: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 168.187262ms)
Aug 28 10:25:43.491: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 168.02132ms)
Aug 28 10:25:43.491: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 168.068805ms)
Aug 28 10:25:43.491: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 168.220381ms)
Aug 28 10:25:43.491: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 168.104029ms)
Aug 28 10:25:43.492: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 168.369947ms)
Aug 28 10:25:43.492: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 168.350999ms)
Aug 28 10:25:43.492: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 168.476731ms)
Aug 28 10:25:43.492: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 168.447874ms)
Aug 28 10:25:43.492: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 168.422695ms)
Aug 28 10:25:43.497: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 173.659588ms)
Aug 28 10:25:43.506: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 9.295589ms)
Aug 28 10:25:43.506: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 9.507982ms)
Aug 28 10:25:43.507: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 9.761235ms)
Aug 28 10:25:43.507: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 10.017555ms)
Aug 28 10:25:43.510: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 12.671126ms)
Aug 28 10:25:43.510: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 12.707584ms)
Aug 28 10:25:43.510: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 12.571584ms)
Aug 28 10:25:43.510: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 13.506352ms)
Aug 28 10:25:43.513: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 16.326565ms)
Aug 28 10:25:43.513: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 16.286169ms)
Aug 28 10:25:43.514: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 16.983399ms)
Aug 28 10:25:43.514: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 16.961903ms)
Aug 28 10:25:43.514: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 17.2607ms)
Aug 28 10:25:43.514: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 17.279171ms)
Aug 28 10:25:43.514: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 17.335686ms)
Aug 28 10:25:43.514: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 17.323429ms)
Aug 28 10:25:43.519: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 4.858846ms)
Aug 28 10:25:43.520: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 5.239854ms)
Aug 28 10:25:43.520: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 5.327171ms)
Aug 28 10:25:43.520: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 5.658852ms)
Aug 28 10:25:43.520: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 5.716865ms)
Aug 28 10:25:43.527: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 11.961181ms)
Aug 28 10:25:43.527: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 11.976398ms)
Aug 28 10:25:43.527: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 12.05643ms)
Aug 28 10:25:43.527: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 11.975124ms)
Aug 28 10:25:43.527: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 12.063343ms)
Aug 28 10:25:43.527: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 12.022298ms)
Aug 28 10:25:43.527: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 12.179767ms)
Aug 28 10:25:43.527: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 12.100325ms)
Aug 28 10:25:43.527: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 12.176129ms)
Aug 28 10:25:43.527: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 12.268423ms)
Aug 28 10:25:43.527: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 12.126435ms)
Aug 28 10:25:43.532: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 4.815629ms)
Aug 28 10:25:43.532: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 5.338197ms)
Aug 28 10:25:43.532: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 5.507366ms)
Aug 28 10:25:43.532: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 5.47934ms)
Aug 28 10:25:43.533: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 6.297698ms)
Aug 28 10:25:43.534: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 6.577568ms)
Aug 28 10:25:43.534: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 6.611844ms)
Aug 28 10:25:43.534: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 6.746099ms)
Aug 28 10:25:43.534: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 6.715691ms)
Aug 28 10:25:43.534: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 6.780506ms)
Aug 28 10:25:43.534: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 7.337804ms)
Aug 28 10:25:43.534: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 7.22438ms)
Aug 28 10:25:43.534: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 7.252513ms)
Aug 28 10:25:43.535: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 7.890708ms)
Aug 28 10:25:43.535: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 7.871765ms)
Aug 28 10:25:43.535: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 7.968655ms)
Aug 28 10:25:43.614: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 78.57036ms)
Aug 28 10:25:43.617: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 81.766499ms)
Aug 28 10:25:43.618: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 82.910152ms)
Aug 28 10:25:43.618: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 83.066733ms)
Aug 28 10:25:43.618: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 83.224502ms)
Aug 28 10:25:43.619: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 83.608186ms)
Aug 28 10:25:43.620: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 84.597313ms)
Aug 28 10:25:43.620: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 84.577781ms)
Aug 28 10:25:43.620: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 84.555259ms)
Aug 28 10:25:43.620: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 84.710412ms)
Aug 28 10:25:43.620: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 84.684054ms)
Aug 28 10:25:43.620: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 84.852109ms)
Aug 28 10:25:43.620: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 84.955602ms)
Aug 28 10:25:43.620: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 85.111533ms)
Aug 28 10:25:43.620: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 85.391436ms)
Aug 28 10:25:43.621: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 85.776596ms)
Aug 28 10:25:43.690: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 68.833233ms)
Aug 28 10:25:43.690: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 68.958742ms)
Aug 28 10:25:43.690: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 69.160278ms)
Aug 28 10:25:43.690: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 68.999228ms)
Aug 28 10:25:43.691: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 69.772023ms)
Aug 28 10:25:43.691: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 69.935552ms)
Aug 28 10:25:43.691: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 69.782167ms)
Aug 28 10:25:43.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 72.390091ms)
Aug 28 10:25:43.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 72.750376ms)
Aug 28 10:25:43.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 72.850568ms)
Aug 28 10:25:43.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 72.812361ms)
Aug 28 10:25:43.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 72.81835ms)
Aug 28 10:25:43.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 72.801094ms)
Aug 28 10:25:43.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 73.233799ms)
Aug 28 10:25:43.696: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 74.475795ms)
Aug 28 10:25:43.696: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 75.014776ms)
Aug 28 10:25:43.702: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 6.099111ms)
Aug 28 10:25:43.702: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 6.085692ms)
Aug 28 10:25:43.702: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 6.143566ms)
Aug 28 10:25:43.702: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 6.119391ms)
Aug 28 10:25:43.704: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 7.102789ms)
Aug 28 10:25:43.704: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 7.099855ms)
Aug 28 10:25:43.704: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 7.14418ms)
Aug 28 10:25:43.704: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 7.244252ms)
Aug 28 10:25:43.704: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 7.235392ms)
Aug 28 10:25:43.704: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 7.218797ms)
Aug 28 10:25:43.704: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 7.253833ms)
Aug 28 10:25:43.704: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 7.822268ms)
Aug 28 10:25:43.705: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 8.278032ms)
Aug 28 10:25:43.705: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 8.882292ms)
Aug 28 10:25:43.706: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 9.343154ms)
Aug 28 10:25:43.706: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 9.362991ms)
Aug 28 10:25:43.712: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 6.173063ms)
Aug 28 10:25:43.712: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 6.28236ms)
Aug 28 10:25:43.713: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 6.768442ms)
Aug 28 10:25:43.713: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 6.833194ms)
Aug 28 10:25:43.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 7.698959ms)
Aug 28 10:25:43.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 7.758598ms)
Aug 28 10:25:43.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 7.834302ms)
Aug 28 10:25:43.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 8.09828ms)
Aug 28 10:25:43.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 8.272262ms)
Aug 28 10:25:43.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 8.208989ms)
Aug 28 10:25:43.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 8.403898ms)
Aug 28 10:25:43.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 8.306392ms)
Aug 28 10:25:43.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 8.429287ms)
Aug 28 10:25:43.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 8.361299ms)
Aug 28 10:25:43.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 8.413896ms)
Aug 28 10:25:43.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 8.520693ms)
Aug 28 10:25:43.719: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 4.737806ms)
Aug 28 10:25:43.720: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 5.34046ms)
Aug 28 10:25:43.720: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 5.321728ms)
Aug 28 10:25:43.720: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 5.305152ms)
Aug 28 10:25:43.720: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 5.719422ms)
Aug 28 10:25:43.720: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 5.728062ms)
Aug 28 10:25:43.720: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 5.905527ms)
Aug 28 10:25:43.721: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 6.325887ms)
Aug 28 10:25:43.721: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 6.296205ms)
Aug 28 10:25:43.721: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 6.416258ms)
Aug 28 10:25:43.721: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 6.555552ms)
Aug 28 10:25:43.722: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 7.354173ms)
Aug 28 10:25:43.723: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 8.053809ms)
Aug 28 10:25:43.723: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 8.184491ms)
Aug 28 10:25:43.723: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 8.204474ms)
Aug 28 10:25:43.723: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 8.2277ms)
Aug 28 10:25:43.728: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 4.807957ms)
Aug 28 10:25:43.728: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 5.008535ms)
Aug 28 10:25:43.728: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 4.952941ms)
Aug 28 10:25:43.728: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 5.405268ms)
Aug 28 10:25:43.729: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 5.601588ms)
Aug 28 10:25:43.729: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 6.37231ms)
Aug 28 10:25:43.729: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 6.410394ms)
Aug 28 10:25:43.729: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 6.390344ms)
Aug 28 10:25:43.729: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 6.466586ms)
Aug 28 10:25:43.729: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 6.488571ms)
Aug 28 10:25:43.729: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 6.558829ms)
Aug 28 10:25:43.731: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 7.643631ms)
Aug 28 10:25:43.732: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 8.90671ms)
Aug 28 10:25:43.732: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 8.920209ms)
Aug 28 10:25:43.732: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 8.875714ms)
Aug 28 10:25:43.732: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 8.90716ms)
Aug 28 10:25:43.737: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 4.659102ms)
Aug 28 10:25:43.737: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 5.107974ms)
Aug 28 10:25:43.737: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 5.25966ms)
Aug 28 10:25:43.737: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 5.283677ms)
Aug 28 10:25:43.738: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 6.026397ms)
Aug 28 10:25:43.738: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 6.092534ms)
Aug 28 10:25:43.739: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 6.979977ms)
Aug 28 10:25:43.739: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 7.024251ms)
Aug 28 10:25:43.739: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 7.144297ms)
Aug 28 10:25:43.739: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 7.279603ms)
Aug 28 10:25:43.739: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 7.430972ms)
Aug 28 10:25:43.740: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 8.432571ms)
Aug 28 10:25:43.740: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 8.350957ms)
Aug 28 10:25:43.740: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 8.335054ms)
Aug 28 10:25:43.740: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 8.392682ms)
Aug 28 10:25:43.740: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 8.352969ms)
Aug 28 10:25:43.808: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 67.797962ms)
Aug 28 10:25:43.809: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 68.414885ms)
Aug 28 10:25:43.809: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 68.300236ms)
Aug 28 10:25:43.809: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 68.376992ms)
Aug 28 10:25:43.809: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 68.404103ms)
Aug 28 10:25:43.810: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 69.217704ms)
Aug 28 10:25:43.810: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 69.325713ms)
Aug 28 10:25:43.810: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 69.659242ms)
Aug 28 10:25:43.810: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 69.595822ms)
Aug 28 10:25:43.810: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 69.791255ms)
Aug 28 10:25:43.810: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 69.700519ms)
Aug 28 10:25:43.811: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 70.032454ms)
Aug 28 10:25:43.811: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 70.058577ms)
Aug 28 10:25:43.811: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 70.522451ms)
Aug 28 10:25:43.812: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 71.135146ms)
Aug 28 10:25:43.812: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 71.869259ms)
Aug 28 10:25:43.817: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 4.922589ms)
Aug 28 10:25:43.818: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 5.533276ms)
Aug 28 10:25:43.818: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 5.658908ms)
Aug 28 10:25:43.818: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 5.76991ms)
Aug 28 10:25:43.818: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 5.765658ms)
Aug 28 10:25:43.819: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 6.372197ms)
Aug 28 10:25:43.819: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 6.389354ms)
Aug 28 10:25:43.819: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 6.453181ms)
Aug 28 10:25:43.819: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 6.584456ms)
Aug 28 10:25:43.819: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 6.794258ms)
Aug 28 10:25:43.820: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 7.19589ms)
Aug 28 10:25:43.822: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 9.066451ms)
Aug 28 10:25:43.822: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 9.25879ms)
Aug 28 10:25:43.822: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 9.240342ms)
Aug 28 10:25:43.822: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 9.028347ms)
Aug 28 10:25:43.822: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 9.128689ms)
Aug 28 10:25:43.827: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 5.186802ms)
Aug 28 10:25:43.827: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 5.378771ms)
Aug 28 10:25:43.828: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 6.319379ms)
Aug 28 10:25:43.828: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 6.243631ms)
Aug 28 10:25:43.828: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 6.290602ms)
Aug 28 10:25:43.828: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 6.307151ms)
Aug 28 10:25:43.828: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 6.435023ms)
Aug 28 10:25:43.828: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 6.568988ms)
Aug 28 10:25:43.829: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 6.904109ms)
Aug 28 10:25:43.829: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 7.075818ms)
Aug 28 10:25:43.829: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 7.125148ms)
Aug 28 10:25:43.829: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 7.268471ms)
Aug 28 10:25:43.830: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 7.701913ms)
Aug 28 10:25:43.830: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 8.311037ms)
Aug 28 10:25:43.830: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 8.379136ms)
Aug 28 10:25:43.830: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 8.462906ms)
Aug 28 10:25:43.834: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:1080/proxy/... (200; 4.096413ms)
Aug 28 10:25:43.836: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 5.183144ms)
Aug 28 10:25:43.836: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:162/proxy/: bar (200; 5.466562ms)
Aug 28 10:25:43.836: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:462/proxy/: tls qux (200; 5.897013ms)
Aug 28 10:25:43.837: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h/proxy/rewriteme"... (200; 6.339186ms)
Aug 28 10:25:43.837: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:1080/proxy/rewri... (200; 6.471882ms)
Aug 28 10:25:43.838: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 7.030786ms)
Aug 28 10:25:43.838: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:460/proxy/: tls baz (200; 6.992442ms)
Aug 28 10:25:43.838: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-stltf/pods/https:proxy-service-9kjxz-45s7h:443/proxy/... (200; 7.110952ms)
Aug 28 10:25:43.838: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/pods/http:proxy-service-9kjxz-45s7h:160/proxy/: foo (200; 7.284933ms)
Aug 28 10:25:43.838: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname2/proxy/: tls qux (200; 7.512593ms)
Aug 28 10:25:43.839: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/services/https:proxy-service-9kjxz:tlsportname1/proxy/: tls baz (200; 8.733576ms)
Aug 28 10:25:43.839: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname1/proxy/: foo (200; 8.800059ms)
Aug 28 10:25:43.839: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/services/proxy-service-9kjxz:portname2/proxy/: bar (200; 8.778031ms)
Aug 28 10:25:43.839: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname2/proxy/: bar (200; 8.870721ms)
Aug 28 10:25:43.839: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-stltf/services/http:proxy-service-9kjxz:portname1/proxy/: foo (200; 8.845105ms)
STEP: deleting { ReplicationController} proxy-service-9kjxz in namespace e2e-tests-proxy-stltf, will wait for the garbage collector to delete the pods
Aug 28 10:25:43.977: INFO: Deleting { ReplicationController} proxy-service-9kjxz took: 18.861225ms
Aug 28 10:25:44.077: INFO: Terminating { ReplicationController} proxy-service-9kjxz pods took: 100.201894ms
[AfterEach] version v1
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:25:56.277: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-stltf" for this suite.
Aug 28 10:26:04.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:26:04.397: INFO: namespace: e2e-tests-proxy-stltf, resource: bindings, ignored listing per whitelist
Aug 28 10:26:04.710: INFO: namespace e2e-tests-proxy-stltf deletion completed in 8.426374678s

• [SLOW TEST:33.531 seconds]
[sig-network] Proxy
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:26:04.710: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-842th
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-842th
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-842th
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-842th
Aug 28 10:26:05.239: INFO: Found 0 stateful pods, waiting for 1
Aug 28 10:26:15.245: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 28 10:26:15.249: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-842th ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 28 10:26:15.805: INFO: stderr: ""
Aug 28 10:26:15.805: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 28 10:26:15.805: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 28 10:26:15.810: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 28 10:26:25.816: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 28 10:26:25.816: INFO: Waiting for statefulset status.replicas updated to 0
Aug 28 10:26:25.850: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999065s
Aug 28 10:26:26.857: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993929897s
Aug 28 10:26:27.862: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.987854135s
Aug 28 10:26:28.910: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.982499306s
Aug 28 10:26:29.915: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.934772902s
Aug 28 10:26:30.920: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.929714533s
Aug 28 10:26:31.925: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.924304351s
Aug 28 10:26:32.931: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.919069908s
Aug 28 10:26:33.936: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.913319252s
Aug 28 10:26:34.941: INFO: Verifying statefulset ss doesn't scale past 1 for another 908.711008ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-842th
Aug 28 10:26:35.946: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-842th ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 28 10:26:36.507: INFO: stderr: ""
Aug 28 10:26:36.507: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 28 10:26:36.507: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 28 10:26:36.519: INFO: Found 1 stateful pods, waiting for 3
Aug 28 10:26:46.809: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 10:26:46.809: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 10:26:46.809: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=false
Aug 28 10:26:56.525: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 10:26:56.525: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 10:26:56.525: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 28 10:26:56.533: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-842th ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 28 10:26:57.072: INFO: stderr: ""
Aug 28 10:26:57.072: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 28 10:26:57.072: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 28 10:26:57.072: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-842th ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 28 10:26:57.697: INFO: stderr: ""
Aug 28 10:26:57.697: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 28 10:26:57.697: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 28 10:26:57.697: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-842th ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 28 10:26:58.209: INFO: stderr: ""
Aug 28 10:26:58.209: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 28 10:26:58.210: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 28 10:26:58.210: INFO: Waiting for statefulset status.replicas updated to 0
Aug 28 10:26:58.215: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Aug 28 10:27:08.225: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 28 10:27:08.225: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 28 10:27:08.225: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 28 10:27:08.264: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999279s
Aug 28 10:27:09.271: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993756233s
Aug 28 10:27:10.276: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987102305s
Aug 28 10:27:11.282: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981480428s
Aug 28 10:27:12.288: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97560212s
Aug 28 10:27:13.298: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.970041451s
Aug 28 10:27:14.303: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.960003927s
Aug 28 10:27:15.310: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.954539148s
Aug 28 10:27:16.316: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.94843855s
Aug 28 10:27:17.322: INFO: Verifying statefulset ss doesn't scale past 3 for another 941.550638ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-842th
Aug 28 10:27:18.329: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-842th ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 28 10:27:18.862: INFO: stderr: ""
Aug 28 10:27:18.862: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 28 10:27:18.862: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 28 10:27:18.862: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-842th ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 28 10:27:19.431: INFO: stderr: ""
Aug 28 10:27:19.431: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 28 10:27:19.431: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 28 10:27:19.431: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-842th ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 28 10:27:19.941: INFO: stderr: ""
Aug 28 10:27:19.941: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 28 10:27:19.941: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 28 10:27:19.941: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Aug 28 10:27:39.971: INFO: Deleting all statefulset in ns e2e-tests-statefulset-842th
Aug 28 10:27:39.975: INFO: Scaling statefulset ss to 0
Aug 28 10:27:39.988: INFO: Waiting for statefulset status.replicas updated to 0
Aug 28 10:27:39.991: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:27:40.039: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-842th" for this suite.
Aug 28 10:27:48.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:27:49.837: INFO: namespace: e2e-tests-statefulset-842th, resource: bindings, ignored listing per whitelist
Aug 28 10:27:51.137: INFO: namespace e2e-tests-statefulset-842th deletion completed in 11.090455258s

• [SLOW TEST:106.427 seconds]
[sig-apps] StatefulSet
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:27:51.137: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-dx25l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-6f134925-c93b-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume secrets
Aug 28 10:27:51.688: INFO: Waiting up to 5m0s for pod "pod-secrets-6f149129-c93b-11e9-a0e2-288023b0a458" in namespace "e2e-tests-secrets-dx25l" to be "success or failure"
Aug 28 10:27:51.692: INFO: Pod "pod-secrets-6f149129-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.609467ms
Aug 28 10:27:53.699: INFO: Pod "pod-secrets-6f149129-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010832409s
Aug 28 10:27:55.704: INFO: Pod "pod-secrets-6f149129-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015643543s
Aug 28 10:27:57.790: INFO: Pod "pod-secrets-6f149129-c93b-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.102120106s
Aug 28 10:27:59.795: INFO: Pod "pod-secrets-6f149129-c93b-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.107026006s
STEP: Saw pod success
Aug 28 10:27:59.795: INFO: Pod "pod-secrets-6f149129-c93b-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:27:59.799: INFO: Trying to get logs from node node-124 pod pod-secrets-6f149129-c93b-11e9-a0e2-288023b0a458 container secret-volume-test: <nil>
STEP: delete the pod
Aug 28 10:28:00.063: INFO: Waiting for pod pod-secrets-6f149129-c93b-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:28:00.072: INFO: Pod pod-secrets-6f149129-c93b-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:28:00.072: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dx25l" for this suite.
Aug 28 10:28:08.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:28:10.759: INFO: namespace: e2e-tests-secrets-dx25l, resource: bindings, ignored listing per whitelist
Aug 28 10:28:11.358: INFO: namespace e2e-tests-secrets-dx25l deletion completed in 11.280204273s

• [SLOW TEST:20.221 seconds]
[sig-storage] Secrets
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:28:11.359: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xbnrq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 10:28:12.065: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7b37f611-c93b-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-xbnrq" to be "success or failure"
Aug 28 10:28:12.082: INFO: Pod "downwardapi-volume-7b37f611-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 16.596008ms
Aug 28 10:28:14.087: INFO: Pod "downwardapi-volume-7b37f611-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021615764s
Aug 28 10:28:16.091: INFO: Pod "downwardapi-volume-7b37f611-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026274024s
Aug 28 10:28:18.097: INFO: Pod "downwardapi-volume-7b37f611-c93b-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031593561s
STEP: Saw pod success
Aug 28 10:28:18.097: INFO: Pod "downwardapi-volume-7b37f611-c93b-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:28:18.101: INFO: Trying to get logs from node node-124 pod downwardapi-volume-7b37f611-c93b-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 10:28:18.134: INFO: Waiting for pod downwardapi-volume-7b37f611-c93b-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:28:18.138: INFO: Pod downwardapi-volume-7b37f611-c93b-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:28:18.138: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xbnrq" for this suite.
Aug 28 10:28:26.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:28:26.328: INFO: namespace: e2e-tests-projected-xbnrq, resource: bindings, ignored listing per whitelist
Aug 28 10:28:29.252: INFO: namespace e2e-tests-projected-xbnrq deletion completed in 11.107928406s

• [SLOW TEST:17.894 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide podname only [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:28:29.252: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ptcq6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 10:28:29.739: INFO: Waiting up to 5m0s for pod "downwardapi-volume-85d0a4a6-c93b-11e9-a0e2-288023b0a458" in namespace "e2e-tests-downward-api-ptcq6" to be "success or failure"
Aug 28 10:28:29.744: INFO: Pod "downwardapi-volume-85d0a4a6-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.196449ms
Aug 28 10:28:31.748: INFO: Pod "downwardapi-volume-85d0a4a6-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009093393s
Aug 28 10:28:33.753: INFO: Pod "downwardapi-volume-85d0a4a6-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01333316s
Aug 28 10:28:35.809: INFO: Pod "downwardapi-volume-85d0a4a6-c93b-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.069324647s
Aug 28 10:28:37.813: INFO: Pod "downwardapi-volume-85d0a4a6-c93b-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.07393566s
STEP: Saw pod success
Aug 28 10:28:37.813: INFO: Pod "downwardapi-volume-85d0a4a6-c93b-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:28:37.817: INFO: Trying to get logs from node node-124 pod downwardapi-volume-85d0a4a6-c93b-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 10:28:37.964: INFO: Waiting for pod downwardapi-volume-85d0a4a6-c93b-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:28:37.968: INFO: Pod downwardapi-volume-85d0a4a6-c93b-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:28:37.968: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ptcq6" for this suite.
Aug 28 10:28:46.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:28:46.113: INFO: namespace: e2e-tests-downward-api-ptcq6, resource: bindings, ignored listing per whitelist
Aug 28 10:28:49.079: INFO: namespace e2e-tests-downward-api-ptcq6 deletion completed in 11.104703679s

• [SLOW TEST:19.826 seconds]
[sig-storage] Downward API volume
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:28:49.079: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-d897f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 10:28:49.690: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91ad679b-c93b-11e9-a0e2-288023b0a458" in namespace "e2e-tests-downward-api-d897f" to be "success or failure"
Aug 28 10:28:49.713: INFO: Pod "downwardapi-volume-91ad679b-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 23.017908ms
Aug 28 10:28:51.718: INFO: Pod "downwardapi-volume-91ad679b-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028353462s
Aug 28 10:28:53.723: INFO: Pod "downwardapi-volume-91ad679b-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033126827s
Aug 28 10:28:55.727: INFO: Pod "downwardapi-volume-91ad679b-c93b-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037173987s
STEP: Saw pod success
Aug 28 10:28:55.727: INFO: Pod "downwardapi-volume-91ad679b-c93b-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:28:55.731: INFO: Trying to get logs from node node-124 pod downwardapi-volume-91ad679b-c93b-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 10:28:55.771: INFO: Waiting for pod downwardapi-volume-91ad679b-c93b-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:28:55.779: INFO: Pod downwardapi-volume-91ad679b-c93b-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:28:55.780: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d897f" for this suite.
Aug 28 10:29:03.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:29:03.986: INFO: namespace: e2e-tests-downward-api-d897f, resource: bindings, ignored listing per whitelist
Aug 28 10:29:06.867: INFO: namespace e2e-tests-downward-api-d897f deletion completed in 11.081470999s

• [SLOW TEST:17.789 seconds]
[sig-storage] Downward API volume
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:29:06.868: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-d4lcb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0828 10:29:37.875163   76809 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 28 10:29:37.875: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:29:37.875: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-d4lcb" for this suite.
Aug 28 10:29:45.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:29:47.380: INFO: namespace: e2e-tests-gc-d4lcb, resource: bindings, ignored listing per whitelist
Aug 28 10:29:48.981: INFO: namespace e2e-tests-gc-d4lcb deletion completed in 11.100499524s

• [SLOW TEST:42.113 seconds]
[sig-api-machinery] Garbage collector
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:29:48.981: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-x4btv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 10:29:55.663: INFO: Waiting up to 5m0s for pod "client-envvars-b9029a28-c93b-11e9-a0e2-288023b0a458" in namespace "e2e-tests-pods-x4btv" to be "success or failure"
Aug 28 10:29:55.666: INFO: Pod "client-envvars-b9029a28-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.356754ms
Aug 28 10:29:57.670: INFO: Pod "client-envvars-b9029a28-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007273907s
Aug 28 10:29:59.675: INFO: Pod "client-envvars-b9029a28-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011741581s
Aug 28 10:30:01.679: INFO: Pod "client-envvars-b9029a28-c93b-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016428752s
STEP: Saw pod success
Aug 28 10:30:01.679: INFO: Pod "client-envvars-b9029a28-c93b-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:30:01.683: INFO: Trying to get logs from node node-124 pod client-envvars-b9029a28-c93b-11e9-a0e2-288023b0a458 container env3cont: <nil>
STEP: delete the pod
Aug 28 10:30:01.715: INFO: Waiting for pod client-envvars-b9029a28-c93b-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:30:01.724: INFO: Pod client-envvars-b9029a28-c93b-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:30:01.724: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-x4btv" for this suite.
Aug 28 10:30:25.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:30:26.065: INFO: namespace: e2e-tests-pods-x4btv, resource: bindings, ignored listing per whitelist
Aug 28 10:30:28.823: INFO: namespace e2e-tests-pods-x4btv deletion completed in 27.092670477s

• [SLOW TEST:39.842 seconds]
[k8s.io] Pods
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should contain environment variables for services [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:30:28.823: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-kx597
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set mode on item file [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 10:30:29.358: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cd186698-c93b-11e9-a0e2-288023b0a458" in namespace "e2e-tests-downward-api-kx597" to be "success or failure"
Aug 28 10:30:29.395: INFO: Pod "downwardapi-volume-cd186698-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 36.503339ms
Aug 28 10:30:31.400: INFO: Pod "downwardapi-volume-cd186698-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041416345s
Aug 28 10:30:33.405: INFO: Pod "downwardapi-volume-cd186698-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.046670232s
Aug 28 10:30:35.409: INFO: Pod "downwardapi-volume-cd186698-c93b-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.050722508s
STEP: Saw pod success
Aug 28 10:30:35.409: INFO: Pod "downwardapi-volume-cd186698-c93b-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:30:35.412: INFO: Trying to get logs from node node-124 pod downwardapi-volume-cd186698-c93b-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 10:30:35.448: INFO: Waiting for pod downwardapi-volume-cd186698-c93b-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:30:35.452: INFO: Pod downwardapi-volume-cd186698-c93b-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:30:35.452: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kx597" for this suite.
Aug 28 10:30:43.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:30:43.603: INFO: namespace: e2e-tests-downward-api-kx597, resource: bindings, ignored listing per whitelist
Aug 28 10:30:46.555: INFO: namespace e2e-tests-downward-api-kx597 deletion completed in 11.096964383s

• [SLOW TEST:17.732 seconds]
[sig-storage] Downward API volume
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:30:46.556: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-k7hfw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run rc
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
[It] should create an rc from an image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Aug 28 10:30:47.111: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config run e2e-test-nginx-rc --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=run/v1 --namespace=e2e-tests-kubectl-k7hfw'
Aug 28 10:30:47.645: INFO: stderr: ""
Aug 28 10:30:47.645: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug 28 10:30:47.678: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-jq2sm]
Aug 28 10:30:47.679: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-jq2sm" in namespace "e2e-tests-kubectl-k7hfw" to be "running and ready"
Aug 28 10:30:47.722: INFO: Pod "e2e-test-nginx-rc-jq2sm": Phase="Pending", Reason="", readiness=false. Elapsed: 43.469003ms
Aug 28 10:30:49.727: INFO: Pod "e2e-test-nginx-rc-jq2sm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047971471s
Aug 28 10:30:51.731: INFO: Pod "e2e-test-nginx-rc-jq2sm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052433071s
Aug 28 10:30:53.736: INFO: Pod "e2e-test-nginx-rc-jq2sm": Phase="Running", Reason="", readiness=true. Elapsed: 6.057375941s
Aug 28 10:30:53.736: INFO: Pod "e2e-test-nginx-rc-jq2sm" satisfied condition "running and ready"
Aug 28 10:30:53.736: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-jq2sm]
Aug 28 10:30:53.736: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-k7hfw'
Aug 28 10:30:54.223: INFO: stderr: ""
Aug 28 10:30:54.223: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1221
Aug 28 10:30:54.223: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-k7hfw'
Aug 28 10:30:54.642: INFO: stderr: ""
Aug 28 10:30:54.642: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:30:54.642: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k7hfw" for this suite.
Aug 28 10:31:18.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:31:21.195: INFO: namespace: e2e-tests-kubectl-k7hfw, resource: bindings, ignored listing per whitelist
Aug 28 10:31:21.795: INFO: namespace e2e-tests-kubectl-k7hfw deletion completed in 27.141537039s

• [SLOW TEST:35.239 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create an rc from an image  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:31:21.795: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-ghhmp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override command
Aug 28 10:31:22.344: INFO: Waiting up to 5m0s for pod "client-containers-ecab0d97-c93b-11e9-a0e2-288023b0a458" in namespace "e2e-tests-containers-ghhmp" to be "success or failure"
Aug 28 10:31:22.348: INFO: Pod "client-containers-ecab0d97-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.989436ms
Aug 28 10:31:24.352: INFO: Pod "client-containers-ecab0d97-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008346222s
Aug 28 10:31:26.357: INFO: Pod "client-containers-ecab0d97-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013544844s
Aug 28 10:31:28.362: INFO: Pod "client-containers-ecab0d97-c93b-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.018393335s
Aug 28 10:31:30.368: INFO: Pod "client-containers-ecab0d97-c93b-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.023672108s
STEP: Saw pod success
Aug 28 10:31:30.368: INFO: Pod "client-containers-ecab0d97-c93b-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:31:30.372: INFO: Trying to get logs from node node-124 pod client-containers-ecab0d97-c93b-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 10:31:30.569: INFO: Waiting for pod client-containers-ecab0d97-c93b-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:31:30.573: INFO: Pod client-containers-ecab0d97-c93b-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:31:30.573: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-ghhmp" for this suite.
Aug 28 10:31:38.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:31:40.141: INFO: namespace: e2e-tests-containers-ghhmp, resource: bindings, ignored listing per whitelist
Aug 28 10:31:41.686: INFO: namespace e2e-tests-containers-ghhmp deletion completed in 11.106364184s

• [SLOW TEST:19.891 seconds]
[k8s.io] Docker Containers
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:31:41.686: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-g9pmz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 10:31:42.457: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f8868a27-c93b-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-g9pmz" to be "success or failure"
Aug 28 10:31:42.484: INFO: Pod "downwardapi-volume-f8868a27-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 26.759324ms
Aug 28 10:31:44.489: INFO: Pod "downwardapi-volume-f8868a27-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031680593s
Aug 28 10:31:46.493: INFO: Pod "downwardapi-volume-f8868a27-c93b-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036173739s
Aug 28 10:31:48.499: INFO: Pod "downwardapi-volume-f8868a27-c93b-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.041236308s
STEP: Saw pod success
Aug 28 10:31:48.499: INFO: Pod "downwardapi-volume-f8868a27-c93b-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:31:48.502: INFO: Trying to get logs from node node-124 pod downwardapi-volume-f8868a27-c93b-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 10:31:48.545: INFO: Waiting for pod downwardapi-volume-f8868a27-c93b-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:31:48.548: INFO: Pod downwardapi-volume-f8868a27-c93b-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:31:48.548: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g9pmz" for this suite.
Aug 28 10:31:56.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:31:56.687: INFO: namespace: e2e-tests-projected-g9pmz, resource: bindings, ignored listing per whitelist
Aug 28 10:31:59.681: INFO: namespace e2e-tests-projected-g9pmz deletion completed in 11.126639011s

• [SLOW TEST:17.995 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:31:59.681: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-szwgc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [sig-network] Services
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:32:00.109: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-szwgc" for this suite.
Aug 28 10:32:08.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:32:09.804: INFO: namespace: e2e-tests-services-szwgc, resource: bindings, ignored listing per whitelist
Aug 28 10:32:11.354: INFO: namespace e2e-tests-services-szwgc deletion completed in 11.237111439s
[AfterEach] [sig-network] Services
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:11.672 seconds]
[sig-network] Services
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:32:11.354: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-d5srw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-d5srw
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a new StatefulSet
Aug 28 10:32:11.821: INFO: Found 0 stateful pods, waiting for 3
Aug 28 10:32:21.827: INFO: Found 2 stateful pods, waiting for 3
Aug 28 10:32:31.827: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 10:32:31.828: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 10:32:31.828: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 10:32:31.843: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-d5srw ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 28 10:32:32.416: INFO: stderr: ""
Aug 28 10:32:32.416: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 28 10:32:32.416: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
Aug 28 10:32:42.461: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 28 10:32:52.482: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-d5srw ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 28 10:32:53.014: INFO: stderr: ""
Aug 28 10:32:53.014: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 28 10:32:53.014: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 28 10:33:03.052: INFO: Waiting for StatefulSet e2e-tests-statefulset-d5srw/ss2 to complete update
Aug 28 10:33:03.052: INFO: Waiting for Pod e2e-tests-statefulset-d5srw/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Aug 28 10:33:03.052: INFO: Waiting for Pod e2e-tests-statefulset-d5srw/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Aug 28 10:33:03.052: INFO: Waiting for Pod e2e-tests-statefulset-d5srw/ss2-2 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Aug 28 10:33:13.116: INFO: Waiting for StatefulSet e2e-tests-statefulset-d5srw/ss2 to complete update
Aug 28 10:33:13.116: INFO: Waiting for Pod e2e-tests-statefulset-d5srw/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Aug 28 10:33:13.116: INFO: Waiting for Pod e2e-tests-statefulset-d5srw/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Aug 28 10:33:23.061: INFO: Waiting for StatefulSet e2e-tests-statefulset-d5srw/ss2 to complete update
Aug 28 10:33:23.061: INFO: Waiting for Pod e2e-tests-statefulset-d5srw/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Aug 28 10:33:23.061: INFO: Waiting for Pod e2e-tests-statefulset-d5srw/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Aug 28 10:33:33.109: INFO: Waiting for StatefulSet e2e-tests-statefulset-d5srw/ss2 to complete update
Aug 28 10:33:33.109: INFO: Waiting for Pod e2e-tests-statefulset-d5srw/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
STEP: Rolling back to a previous revision
Aug 28 10:33:43.091: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-d5srw ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 28 10:33:43.693: INFO: stderr: ""
Aug 28 10:33:43.693: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 28 10:33:43.693: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 28 10:33:53.752: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 28 10:34:03.795: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-d5srw ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 28 10:34:04.332: INFO: stderr: ""
Aug 28 10:34:04.332: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 28 10:34:04.332: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 28 10:34:34.358: INFO: Waiting for StatefulSet e2e-tests-statefulset-d5srw/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Aug 28 10:34:44.368: INFO: Deleting all statefulset in ns e2e-tests-statefulset-d5srw
Aug 28 10:34:44.372: INFO: Scaling statefulset ss2 to 0
Aug 28 10:35:04.424: INFO: Waiting for statefulset status.replicas updated to 0
Aug 28 10:35:04.428: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:35:04.485: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-d5srw" for this suite.
Aug 28 10:35:12.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:35:12.595: INFO: namespace: e2e-tests-statefulset-d5srw, resource: bindings, ignored listing per whitelist
Aug 28 10:35:15.605: INFO: namespace e2e-tests-statefulset-d5srw deletion completed in 11.112429655s

• [SLOW TEST:184.251 seconds]
[sig-apps] StatefulSet
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should perform rolling updates and roll backs of template modifications [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:35:15.605: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pgjfw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-780a0b72-c93c-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume secrets
Aug 28 10:35:16.204: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-780c80c5-c93c-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-pgjfw" to be "success or failure"
Aug 28 10:35:16.211: INFO: Pod "pod-projected-secrets-780c80c5-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.769079ms
Aug 28 10:35:18.215: INFO: Pod "pod-projected-secrets-780c80c5-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011311243s
Aug 28 10:35:20.220: INFO: Pod "pod-projected-secrets-780c80c5-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015968596s
Aug 28 10:35:22.225: INFO: Pod "pod-projected-secrets-780c80c5-c93c-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021248233s
STEP: Saw pod success
Aug 28 10:35:22.225: INFO: Pod "pod-projected-secrets-780c80c5-c93c-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:35:22.229: INFO: Trying to get logs from node node-124 pod pod-projected-secrets-780c80c5-c93c-11e9-a0e2-288023b0a458 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 28 10:35:22.269: INFO: Waiting for pod pod-projected-secrets-780c80c5-c93c-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:35:22.272: INFO: Pod pod-projected-secrets-780c80c5-c93c-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:35:22.272: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pgjfw" for this suite.
Aug 28 10:35:30.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:35:33.449: INFO: namespace: e2e-tests-projected-pgjfw, resource: bindings, ignored listing per whitelist
Aug 28 10:35:33.449: INFO: namespace e2e-tests-projected-pgjfw deletion completed in 11.170252134s

• [SLOW TEST:17.844 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:35:33.449: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-9vg6r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 28 10:35:34.058: INFO: Waiting up to 5m0s for pod "pod-82aebb6e-c93c-11e9-a0e2-288023b0a458" in namespace "e2e-tests-emptydir-9vg6r" to be "success or failure"
Aug 28 10:35:34.075: INFO: Pod "pod-82aebb6e-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 16.617272ms
Aug 28 10:35:36.092: INFO: Pod "pod-82aebb6e-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033877649s
Aug 28 10:35:38.097: INFO: Pod "pod-82aebb6e-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039285477s
Aug 28 10:35:40.102: INFO: Pod "pod-82aebb6e-c93c-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044115724s
STEP: Saw pod success
Aug 28 10:35:40.102: INFO: Pod "pod-82aebb6e-c93c-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:35:40.106: INFO: Trying to get logs from node node-124 pod pod-82aebb6e-c93c-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 10:35:40.148: INFO: Waiting for pod pod-82aebb6e-c93c-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:35:40.152: INFO: Pod pod-82aebb6e-c93c-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:35:40.152: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9vg6r" for this suite.
Aug 28 10:35:48.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:35:51.221: INFO: namespace: e2e-tests-emptydir-9vg6r, resource: bindings, ignored listing per whitelist
Aug 28 10:35:51.273: INFO: namespace e2e-tests-emptydir-9vg6r deletion completed in 11.113904769s

• [SLOW TEST:17.824 seconds]
[sig-storage] EmptyDir volumes
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] ReplicaSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:35:51.273: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-ll5vw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 10:35:51.852: INFO: Creating ReplicaSet my-hostname-basic-8d5eae81-c93c-11e9-a0e2-288023b0a458
Aug 28 10:35:51.954: INFO: Pod name my-hostname-basic-8d5eae81-c93c-11e9-a0e2-288023b0a458: Found 0 pods out of 1
Aug 28 10:35:56.959: INFO: Pod name my-hostname-basic-8d5eae81-c93c-11e9-a0e2-288023b0a458: Found 1 pods out of 1
Aug 28 10:35:56.959: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-8d5eae81-c93c-11e9-a0e2-288023b0a458" is running
Aug 28 10:35:58.968: INFO: Pod "my-hostname-basic-8d5eae81-c93c-11e9-a0e2-288023b0a458-ng945" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-28 10:35:52 +0800 CST Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-28 10:35:52 +0800 CST Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-8d5eae81-c93c-11e9-a0e2-288023b0a458]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-8d5eae81-c93c-11e9-a0e2-288023b0a458]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-28 10:35:52 +0800 CST Reason: Message:}])
Aug 28 10:35:58.968: INFO: Trying to dial the pod
Aug 28 10:36:04.068: INFO: Controller my-hostname-basic-8d5eae81-c93c-11e9-a0e2-288023b0a458: Got expected result from replica 1 [my-hostname-basic-8d5eae81-c93c-11e9-a0e2-288023b0a458-ng945]: "my-hostname-basic-8d5eae81-c93c-11e9-a0e2-288023b0a458-ng945", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:36:04.068: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-ll5vw" for this suite.
Aug 28 10:36:12.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:36:12.266: INFO: namespace: e2e-tests-replicaset-ll5vw, resource: bindings, ignored listing per whitelist
Aug 28 10:36:15.174: INFO: namespace e2e-tests-replicaset-ll5vw deletion completed in 11.095141107s

• [SLOW TEST:23.901 seconds]
[sig-apps] ReplicaSet
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:36:15.174: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-jxgbj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 28 10:36:22.328: INFO: Successfully updated pod "pod-update-activedeadlineseconds-9b8da9df-c93c-11e9-a0e2-288023b0a458"
Aug 28 10:36:22.328: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-9b8da9df-c93c-11e9-a0e2-288023b0a458" in namespace "e2e-tests-pods-jxgbj" to be "terminated due to deadline exceeded"
Aug 28 10:36:22.332: INFO: Pod "pod-update-activedeadlineseconds-9b8da9df-c93c-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 3.726352ms
Aug 28 10:36:24.336: INFO: Pod "pod-update-activedeadlineseconds-9b8da9df-c93c-11e9-a0e2-288023b0a458": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.007722143s
Aug 28 10:36:24.336: INFO: Pod "pod-update-activedeadlineseconds-9b8da9df-c93c-11e9-a0e2-288023b0a458" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:36:24.336: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-jxgbj" for this suite.
Aug 28 10:36:32.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:36:32.548: INFO: namespace: e2e-tests-pods-jxgbj, resource: bindings, ignored listing per whitelist
Aug 28 10:36:35.508: INFO: namespace e2e-tests-pods-jxgbj deletion completed in 11.160865946s

• [SLOW TEST:20.334 seconds]
[k8s.io] Pods
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:36:35.508: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-htpgw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 28 10:36:36.003: INFO: Waiting up to 5m0s for pod "pod-a79f8076-c93c-11e9-a0e2-288023b0a458" in namespace "e2e-tests-emptydir-htpgw" to be "success or failure"
Aug 28 10:36:36.019: INFO: Pod "pod-a79f8076-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 16.08846ms
Aug 28 10:36:38.024: INFO: Pod "pod-a79f8076-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020684472s
Aug 28 10:36:40.029: INFO: Pod "pod-a79f8076-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025856504s
Aug 28 10:36:42.033: INFO: Pod "pod-a79f8076-c93c-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030440229s
STEP: Saw pod success
Aug 28 10:36:42.033: INFO: Pod "pod-a79f8076-c93c-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:36:42.037: INFO: Trying to get logs from node node-124 pod pod-a79f8076-c93c-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 10:36:42.067: INFO: Waiting for pod pod-a79f8076-c93c-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:36:42.071: INFO: Pod pod-a79f8076-c93c-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:36:42.071: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-htpgw" for this suite.
Aug 28 10:36:50.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:36:50.376: INFO: namespace: e2e-tests-emptydir-htpgw, resource: bindings, ignored listing per whitelist
Aug 28 10:36:53.210: INFO: namespace e2e-tests-emptydir-htpgw deletion completed in 11.131986769s

• [SLOW TEST:17.702 seconds]
[sig-storage] EmptyDir volumes
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:36:53.210: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-l7pkh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-b23190a5-c93c-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume secrets
Aug 28 10:36:53.740: INFO: Waiting up to 5m0s for pod "pod-secrets-b2333d66-c93c-11e9-a0e2-288023b0a458" in namespace "e2e-tests-secrets-l7pkh" to be "success or failure"
Aug 28 10:36:53.757: INFO: Pod "pod-secrets-b2333d66-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 16.53506ms
Aug 28 10:36:55.761: INFO: Pod "pod-secrets-b2333d66-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020720774s
Aug 28 10:36:57.766: INFO: Pod "pod-secrets-b2333d66-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02621307s
Aug 28 10:36:59.771: INFO: Pod "pod-secrets-b2333d66-c93c-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030746096s
STEP: Saw pod success
Aug 28 10:36:59.771: INFO: Pod "pod-secrets-b2333d66-c93c-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:36:59.775: INFO: Trying to get logs from node node-124 pod pod-secrets-b2333d66-c93c-11e9-a0e2-288023b0a458 container secret-volume-test: <nil>
STEP: delete the pod
Aug 28 10:36:59.827: INFO: Waiting for pod pod-secrets-b2333d66-c93c-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:36:59.832: INFO: Pod pod-secrets-b2333d66-c93c-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:36:59.832: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-l7pkh" for this suite.
Aug 28 10:37:07.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:37:08.023: INFO: namespace: e2e-tests-secrets-l7pkh, resource: bindings, ignored listing per whitelist
Aug 28 10:37:10.956: INFO: namespace e2e-tests-secrets-l7pkh deletion completed in 11.117061382s

• [SLOW TEST:17.746 seconds]
[sig-storage] Secrets
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:37:10.956: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-5mk9k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-5mk9k
[It] Should recreate evicted statefulset [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-5mk9k
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-5mk9k
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-5mk9k
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-5mk9k
Aug 28 10:37:19.590: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-5mk9k, name: ss-0, uid: c18ed0ff-c93c-11e9-a17b-288023b0a458, status phase: Pending. Waiting for statefulset controller to delete.
Aug 28 10:37:20.572: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-5mk9k, name: ss-0, uid: c18ed0ff-c93c-11e9-a17b-288023b0a458, status phase: Failed. Waiting for statefulset controller to delete.
Aug 28 10:37:20.587: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-5mk9k, name: ss-0, uid: c18ed0ff-c93c-11e9-a17b-288023b0a458, status phase: Failed. Waiting for statefulset controller to delete.
Aug 28 10:37:20.598: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-5mk9k
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-5mk9k
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-5mk9k and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Aug 28 10:37:28.652: INFO: Deleting all statefulset in ns e2e-tests-statefulset-5mk9k
Aug 28 10:37:28.657: INFO: Scaling statefulset ss to 0
Aug 28 10:37:38.686: INFO: Waiting for statefulset status.replicas updated to 0
Aug 28 10:37:38.689: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:37:38.714: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-5mk9k" for this suite.
Aug 28 10:37:46.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:37:47.210: INFO: namespace: e2e-tests-statefulset-5mk9k, resource: bindings, ignored listing per whitelist
Aug 28 10:37:49.813: INFO: namespace e2e-tests-statefulset-5mk9k deletion completed in 11.092299439s

• [SLOW TEST:38.857 seconds]
[sig-apps] StatefulSet
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Should recreate evicted statefulset [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:37:49.813: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-zqprf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Aug 28 10:37:50.479: INFO: Waiting up to 5m0s for pod "downward-api-d4071bbe-c93c-11e9-a0e2-288023b0a458" in namespace "e2e-tests-downward-api-zqprf" to be "success or failure"
Aug 28 10:37:50.483: INFO: Pod "downward-api-d4071bbe-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00727ms
Aug 28 10:37:52.489: INFO: Pod "downward-api-d4071bbe-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010647355s
Aug 28 10:37:54.494: INFO: Pod "downward-api-d4071bbe-c93c-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014736874s
Aug 28 10:37:56.498: INFO: Pod "downward-api-d4071bbe-c93c-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.018961183s
Aug 28 10:37:58.503: INFO: Pod "downward-api-d4071bbe-c93c-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.023913197s
STEP: Saw pod success
Aug 28 10:37:58.503: INFO: Pod "downward-api-d4071bbe-c93c-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:37:58.507: INFO: Trying to get logs from node node-124 pod downward-api-d4071bbe-c93c-11e9-a0e2-288023b0a458 container dapi-container: <nil>
STEP: delete the pod
Aug 28 10:37:58.685: INFO: Waiting for pod downward-api-d4071bbe-c93c-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:37:58.689: INFO: Pod downward-api-d4071bbe-c93c-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:37:58.689: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zqprf" for this suite.
Aug 28 10:38:06.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:38:06.879: INFO: namespace: e2e-tests-downward-api-zqprf, resource: bindings, ignored listing per whitelist
Aug 28 10:38:09.785: INFO: namespace e2e-tests-downward-api-zqprf deletion completed in 11.089247184s

• [SLOW TEST:19.972 seconds]
[sig-api-machinery] Downward API
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide host IP as an env var [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-auth] ServiceAccounts
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:38:09.785: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-r7tvm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: getting the auto-created API token
Aug 28 10:38:10.893: INFO: created pod pod-service-account-defaultsa
Aug 28 10:38:10.893: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 28 10:38:10.968: INFO: created pod pod-service-account-mountsa
Aug 28 10:38:10.968: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 28 10:38:11.030: INFO: created pod pod-service-account-nomountsa
Aug 28 10:38:11.030: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 28 10:38:11.109: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 28 10:38:11.110: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 28 10:38:11.223: INFO: created pod pod-service-account-mountsa-mountspec
Aug 28 10:38:11.223: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 28 10:38:11.276: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 28 10:38:11.276: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 28 10:38:11.318: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 28 10:38:11.318: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 28 10:38:11.373: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 28 10:38:11.373: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 28 10:38:11.409: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 28 10:38:11.409: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:38:11.409: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-r7tvm" for this suite.
Aug 28 10:38:53.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:38:55.951: INFO: namespace: e2e-tests-svcaccounts-r7tvm, resource: bindings, ignored listing per whitelist
Aug 28 10:38:56.552: INFO: namespace e2e-tests-svcaccounts-r7tvm deletion completed in 45.135637472s

• [SLOW TEST:46.767 seconds]
[sig-auth] ServiceAccounts
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:38:56.552: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kjb45
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 10:38:56.972: INFO: Couldn't get node TTL annotation (using default value of 0): No TTL annotation found on the node
STEP: Creating configMap with name cm-test-opt-del-fbb5d840-c93c-11e9-a0e2-288023b0a458
STEP: Creating configMap with name cm-test-opt-upd-fbb5d8ab-c93c-11e9-a0e2-288023b0a458
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-fbb5d840-c93c-11e9-a0e2-288023b0a458
STEP: Updating configmap cm-test-opt-upd-fbb5d8ab-c93c-11e9-a0e2-288023b0a458
STEP: Creating configMap with name cm-test-opt-create-fbb5d8d0-c93c-11e9-a0e2-288023b0a458
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:40:17.805: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kjb45" for this suite.
Aug 28 10:40:41.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:40:44.202: INFO: namespace: e2e-tests-projected-kjb45, resource: bindings, ignored listing per whitelist
Aug 28 10:40:44.901: INFO: namespace e2e-tests-projected-kjb45 deletion completed in 27.089433912s

• [SLOW TEST:108.349 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:40:44.901: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-jxwqn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should create and stop a replication controller  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a replication controller
Aug 28 10:40:45.315: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-jxwqn'
Aug 28 10:40:45.880: INFO: stderr: ""
Aug 28 10:40:45.880: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 28 10:40:45.880: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jxwqn'
Aug 28 10:40:46.248: INFO: stderr: ""
Aug 28 10:40:46.248: INFO: stdout: "update-demo-nautilus-jd54z update-demo-nautilus-ppr94 "
Aug 28 10:40:46.248: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-jd54z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jxwqn'
Aug 28 10:40:46.672: INFO: stderr: ""
Aug 28 10:40:46.672: INFO: stdout: ""
Aug 28 10:40:46.672: INFO: update-demo-nautilus-jd54z is created but not running
Aug 28 10:40:51.672: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jxwqn'
Aug 28 10:40:52.158: INFO: stderr: ""
Aug 28 10:40:52.158: INFO: stdout: "update-demo-nautilus-jd54z update-demo-nautilus-ppr94 "
Aug 28 10:40:52.158: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-jd54z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jxwqn'
Aug 28 10:40:52.592: INFO: stderr: ""
Aug 28 10:40:52.592: INFO: stdout: "true"
Aug 28 10:40:52.593: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-jd54z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jxwqn'
Aug 28 10:40:52.998: INFO: stderr: ""
Aug 28 10:40:52.998: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Aug 28 10:40:52.998: INFO: validating pod update-demo-nautilus-jd54z
Aug 28 10:40:53.012: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 28 10:40:53.012: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 28 10:40:53.012: INFO: update-demo-nautilus-jd54z is verified up and running
Aug 28 10:40:53.012: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-ppr94 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jxwqn'
Aug 28 10:40:53.416: INFO: stderr: ""
Aug 28 10:40:53.416: INFO: stdout: "true"
Aug 28 10:40:53.416: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-ppr94 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jxwqn'
Aug 28 10:40:53.824: INFO: stderr: ""
Aug 28 10:40:53.824: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Aug 28 10:40:53.824: INFO: validating pod update-demo-nautilus-ppr94
Aug 28 10:40:53.872: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 28 10:40:53.872: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 28 10:40:53.872: INFO: update-demo-nautilus-ppr94 is verified up and running
STEP: using delete to clean up resources
Aug 28 10:40:53.872: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-jxwqn'
Aug 28 10:40:54.269: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 28 10:40:54.269: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 28 10:40:54.269: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-jxwqn'
Aug 28 10:40:54.677: INFO: stderr: "No resources found.\n"
Aug 28 10:40:54.677: INFO: stdout: ""
Aug 28 10:40:54.677: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -l name=update-demo --namespace=e2e-tests-kubectl-jxwqn -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 28 10:40:55.056: INFO: stderr: ""
Aug 28 10:40:55.056: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:40:55.056: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jxwqn" for this suite.
Aug 28 10:41:03.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:41:03.304: INFO: namespace: e2e-tests-kubectl-jxwqn, resource: bindings, ignored listing per whitelist
Aug 28 10:41:06.176: INFO: namespace e2e-tests-kubectl-jxwqn deletion completed in 11.111822312s

• [SLOW TEST:21.275 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create and stop a replication controller  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] DNS
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:41:06.176: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-9kxqw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9kxqw A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-9kxqw;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9kxqw A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-9kxqw;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9kxqw.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-9kxqw.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9kxqw.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-9kxqw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9kxqw.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9kxqw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9kxqw.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9kxqw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9kxqw.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-9kxqw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9kxqw.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-9kxqw.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9kxqw.pod.cloudos"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 144.97.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.97.144_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 144.97.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.97.144_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9kxqw A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-9kxqw;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9kxqw A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-9kxqw;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9kxqw.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-9kxqw.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9kxqw.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-9kxqw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9kxqw.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9kxqw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9kxqw.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9kxqw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9kxqw.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-9kxqw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9kxqw.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-9kxqw.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9kxqw.pod.cloudos"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 144.97.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.97.144_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 144.97.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.97.144_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 28 10:41:26.969: INFO: DNS probes using dns-test-4906e8a2-c93d-11e9-a0e2-288023b0a458 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:41:27.186: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-9kxqw" for this suite.
Aug 28 10:41:35.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:41:37.225: INFO: namespace: e2e-tests-dns-9kxqw, resource: bindings, ignored listing per whitelist
Aug 28 10:41:38.326: INFO: namespace e2e-tests-dns-9kxqw deletion completed in 11.127549932s

• [SLOW TEST:32.150 seconds]
[sig-network] DNS
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:41:38.326: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-2wl2j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-2wl2j
Aug 28 10:41:44.888: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-2wl2j
STEP: checking the pod's current state and verifying that restartCount is present
Aug 28 10:41:44.891: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:45:45.674: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2wl2j" for this suite.
Aug 28 10:45:53.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:45:53.808: INFO: namespace: e2e-tests-container-probe-2wl2j, resource: bindings, ignored listing per whitelist
Aug 28 10:45:56.769: INFO: namespace e2e-tests-container-probe-2wl2j deletion completed in 11.089090179s

• [SLOW TEST:258.443 seconds]
[k8s.io] Probing container
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:45:56.769: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fqxnb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 10:45:57.357: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f635fb6a-c93d-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-fqxnb" to be "success or failure"
Aug 28 10:45:57.362: INFO: Pod "downwardapi-volume-f635fb6a-c93d-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.524092ms
Aug 28 10:45:59.368: INFO: Pod "downwardapi-volume-f635fb6a-c93d-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01053676s
Aug 28 10:46:01.378: INFO: Pod "downwardapi-volume-f635fb6a-c93d-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020933044s
Aug 28 10:46:03.382: INFO: Pod "downwardapi-volume-f635fb6a-c93d-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025152454s
STEP: Saw pod success
Aug 28 10:46:03.382: INFO: Pod "downwardapi-volume-f635fb6a-c93d-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:46:03.386: INFO: Trying to get logs from node node-124 pod downwardapi-volume-f635fb6a-c93d-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 10:46:03.439: INFO: Waiting for pod downwardapi-volume-f635fb6a-c93d-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:46:03.442: INFO: Pod downwardapi-volume-f635fb6a-c93d-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:46:03.443: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fqxnb" for this suite.
Aug 28 10:46:11.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:46:13.140: INFO: namespace: e2e-tests-projected-fqxnb, resource: bindings, ignored listing per whitelist
Aug 28 10:46:14.538: INFO: namespace e2e-tests-projected-fqxnb deletion completed in 11.088302146s

• [SLOW TEST:17.769 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:46:14.538: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-tcz7f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory request [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 10:46:15.064: INFO: Waiting up to 5m0s for pod "downwardapi-volume-00c5c122-c93e-11e9-a0e2-288023b0a458" in namespace "e2e-tests-downward-api-tcz7f" to be "success or failure"
Aug 28 10:46:15.068: INFO: Pod "downwardapi-volume-00c5c122-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.002982ms
Aug 28 10:46:17.073: INFO: Pod "downwardapi-volume-00c5c122-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00843377s
Aug 28 10:46:19.078: INFO: Pod "downwardapi-volume-00c5c122-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013771734s
Aug 28 10:46:21.084: INFO: Pod "downwardapi-volume-00c5c122-c93e-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.01950839s
Aug 28 10:46:23.088: INFO: Pod "downwardapi-volume-00c5c122-c93e-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.024070069s
STEP: Saw pod success
Aug 28 10:46:23.088: INFO: Pod "downwardapi-volume-00c5c122-c93e-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:46:23.092: INFO: Trying to get logs from node node-124 pod downwardapi-volume-00c5c122-c93e-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 10:46:23.139: INFO: Waiting for pod downwardapi-volume-00c5c122-c93e-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:46:23.143: INFO: Pod downwardapi-volume-00c5c122-c93e-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:46:23.143: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tcz7f" for this suite.
Aug 28 10:46:31.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:46:33.247: INFO: namespace: e2e-tests-downward-api-tcz7f, resource: bindings, ignored listing per whitelist
Aug 28 10:46:34.248: INFO: namespace e2e-tests-downward-api-tcz7f deletion completed in 11.098897207s

• [SLOW TEST:19.710 seconds]
[sig-storage] Downward API volume
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:46:34.249: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rqn54
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 10:46:35.245: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0c81d52f-c93e-11e9-a0e2-288023b0a458" in namespace "e2e-tests-downward-api-rqn54" to be "success or failure"
Aug 28 10:46:35.250: INFO: Pod "downwardapi-volume-0c81d52f-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 5.191978ms
Aug 28 10:46:37.255: INFO: Pod "downwardapi-volume-0c81d52f-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010316095s
Aug 28 10:46:39.261: INFO: Pod "downwardapi-volume-0c81d52f-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015780399s
Aug 28 10:46:41.266: INFO: Pod "downwardapi-volume-0c81d52f-c93e-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.020814584s
Aug 28 10:46:43.271: INFO: Pod "downwardapi-volume-0c81d52f-c93e-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.025767944s
STEP: Saw pod success
Aug 28 10:46:43.271: INFO: Pod "downwardapi-volume-0c81d52f-c93e-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:46:43.275: INFO: Trying to get logs from node node-124 pod downwardapi-volume-0c81d52f-c93e-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 10:46:43.310: INFO: Waiting for pod downwardapi-volume-0c81d52f-c93e-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:46:43.313: INFO: Pod downwardapi-volume-0c81d52f-c93e-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:46:43.313: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rqn54" for this suite.
Aug 28 10:46:51.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:46:51.473: INFO: namespace: e2e-tests-downward-api-rqn54, resource: bindings, ignored listing per whitelist
Aug 28 10:46:54.430: INFO: namespace e2e-tests-downward-api-rqn54 deletion completed in 11.109075925s

• [SLOW TEST:20.181 seconds]
[sig-storage] Downward API volume
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:46:54.430: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lx4dv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-map-188df021-c93e-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume secrets
Aug 28 10:46:54.901: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-188f5b49-c93e-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-lx4dv" to be "success or failure"
Aug 28 10:46:54.904: INFO: Pod "pod-projected-secrets-188f5b49-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.210702ms
Aug 28 10:46:56.910: INFO: Pod "pod-projected-secrets-188f5b49-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008879286s
Aug 28 10:46:58.915: INFO: Pod "pod-projected-secrets-188f5b49-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013679631s
Aug 28 10:47:00.920: INFO: Pod "pod-projected-secrets-188f5b49-c93e-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018867678s
STEP: Saw pod success
Aug 28 10:47:00.920: INFO: Pod "pod-projected-secrets-188f5b49-c93e-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:47:00.924: INFO: Trying to get logs from node node-124 pod pod-projected-secrets-188f5b49-c93e-11e9-a0e2-288023b0a458 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 28 10:47:00.977: INFO: Waiting for pod pod-projected-secrets-188f5b49-c93e-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:47:00.982: INFO: Pod pod-projected-secrets-188f5b49-c93e-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:47:00.982: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lx4dv" for this suite.
Aug 28 10:47:09.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:47:09.154: INFO: namespace: e2e-tests-projected-lx4dv, resource: bindings, ignored listing per whitelist
Aug 28 10:47:12.126: INFO: namespace e2e-tests-projected-lx4dv deletion completed in 11.138479943s

• [SLOW TEST:17.696 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:47:12.127: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-kscnc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 28 10:47:12.655: INFO: Waiting up to 5m0s for pod "pod-231b02ba-c93e-11e9-a0e2-288023b0a458" in namespace "e2e-tests-emptydir-kscnc" to be "success or failure"
Aug 28 10:47:12.670: INFO: Pod "pod-231b02ba-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 14.970466ms
Aug 28 10:47:14.675: INFO: Pod "pod-231b02ba-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020283995s
Aug 28 10:47:16.680: INFO: Pod "pod-231b02ba-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025070251s
Aug 28 10:47:18.684: INFO: Pod "pod-231b02ba-c93e-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.029468001s
Aug 28 10:47:20.689: INFO: Pod "pod-231b02ba-c93e-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.033861292s
STEP: Saw pod success
Aug 28 10:47:20.689: INFO: Pod "pod-231b02ba-c93e-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:47:20.692: INFO: Trying to get logs from node node-124 pod pod-231b02ba-c93e-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 10:47:20.747: INFO: Waiting for pod pod-231b02ba-c93e-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:47:20.750: INFO: Pod pod-231b02ba-c93e-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:47:20.750: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kscnc" for this suite.
Aug 28 10:47:28.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:47:30.797: INFO: namespace: e2e-tests-emptydir-kscnc, resource: bindings, ignored listing per whitelist
Aug 28 10:47:31.848: INFO: namespace e2e-tests-emptydir-kscnc deletion completed in 11.091376307s

• [SLOW TEST:19.721 seconds]
[sig-storage] EmptyDir volumes
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:47:31.848: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-l6hbx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run default
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1180
[It] should create an rc or deployment from an image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Aug 28 10:47:32.349: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config run e2e-test-nginx-deployment --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-l6hbx'
Aug 28 10:47:32.835: INFO: stderr: ""
Aug 28 10:47:32.836: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1186
Aug 28 10:47:34.911: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-l6hbx'
Aug 28 10:47:35.294: INFO: stderr: ""
Aug 28 10:47:35.294: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:47:35.294: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l6hbx" for this suite.
Aug 28 10:47:43.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:47:43.478: INFO: namespace: e2e-tests-kubectl-l6hbx, resource: bindings, ignored listing per whitelist
Aug 28 10:47:46.500: INFO: namespace e2e-tests-kubectl-l6hbx deletion completed in 11.19836159s

• [SLOW TEST:14.652 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create an rc or deployment from an image  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:47:46.500: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-84bk2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-37b9a8a4-c93e-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 10:47:47.238: INFO: Waiting up to 5m0s for pod "pod-configmaps-37c11249-c93e-11e9-a0e2-288023b0a458" in namespace "e2e-tests-configmap-84bk2" to be "success or failure"
Aug 28 10:47:47.242: INFO: Pod "pod-configmaps-37c11249-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.970642ms
Aug 28 10:47:49.246: INFO: Pod "pod-configmaps-37c11249-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008195504s
Aug 28 10:47:51.268: INFO: Pod "pod-configmaps-37c11249-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029615531s
Aug 28 10:47:53.272: INFO: Pod "pod-configmaps-37c11249-c93e-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034228309s
STEP: Saw pod success
Aug 28 10:47:53.272: INFO: Pod "pod-configmaps-37c11249-c93e-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:47:53.276: INFO: Trying to get logs from node node-124 pod pod-configmaps-37c11249-c93e-11e9-a0e2-288023b0a458 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 28 10:47:53.323: INFO: Waiting for pod pod-configmaps-37c11249-c93e-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:47:53.326: INFO: Pod pod-configmaps-37c11249-c93e-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:47:53.326: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-84bk2" for this suite.
Aug 28 10:48:01.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:48:03.048: INFO: namespace: e2e-tests-configmap-84bk2, resource: bindings, ignored listing per whitelist
Aug 28 10:48:04.447: INFO: namespace e2e-tests-configmap-84bk2 deletion completed in 11.115543885s

• [SLOW TEST:17.948 seconds]
[sig-storage] ConfigMap
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:48:04.448: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-f2phc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-42460a32-c93e-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 10:48:04.983: INFO: Waiting up to 5m0s for pod "pod-configmaps-4249d013-c93e-11e9-a0e2-288023b0a458" in namespace "e2e-tests-configmap-f2phc" to be "success or failure"
Aug 28 10:48:04.993: INFO: Pod "pod-configmaps-4249d013-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 10.059934ms
Aug 28 10:48:06.997: INFO: Pod "pod-configmaps-4249d013-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014152303s
Aug 28 10:48:09.001: INFO: Pod "pod-configmaps-4249d013-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018825521s
Aug 28 10:48:11.034: INFO: Pod "pod-configmaps-4249d013-c93e-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05128915s
STEP: Saw pod success
Aug 28 10:48:11.034: INFO: Pod "pod-configmaps-4249d013-c93e-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:48:11.038: INFO: Trying to get logs from node node-124 pod pod-configmaps-4249d013-c93e-11e9-a0e2-288023b0a458 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 28 10:48:11.152: INFO: Waiting for pod pod-configmaps-4249d013-c93e-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:48:11.158: INFO: Pod pod-configmaps-4249d013-c93e-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:48:11.158: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-f2phc" for this suite.
Aug 28 10:48:19.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:48:19.232: INFO: namespace: e2e-tests-configmap-f2phc, resource: bindings, ignored listing per whitelist
Aug 28 10:48:22.252: INFO: namespace e2e-tests-configmap-f2phc deletion completed in 11.088247586s

• [SLOW TEST:17.804 seconds]
[sig-storage] ConfigMap
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:48:22.252: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-xggwb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 28 10:48:22.874: INFO: Waiting up to 5m0s for pod "pod-4cf94c9e-c93e-11e9-a0e2-288023b0a458" in namespace "e2e-tests-emptydir-xggwb" to be "success or failure"
Aug 28 10:48:22.878: INFO: Pod "pod-4cf94c9e-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.804813ms
Aug 28 10:48:24.883: INFO: Pod "pod-4cf94c9e-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008700305s
Aug 28 10:48:26.888: INFO: Pod "pod-4cf94c9e-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013868636s
Aug 28 10:48:28.892: INFO: Pod "pod-4cf94c9e-c93e-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017979463s
STEP: Saw pod success
Aug 28 10:48:28.892: INFO: Pod "pod-4cf94c9e-c93e-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:48:28.895: INFO: Trying to get logs from node node-124 pod pod-4cf94c9e-c93e-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 10:48:28.933: INFO: Waiting for pod pod-4cf94c9e-c93e-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:48:28.937: INFO: Pod pod-4cf94c9e-c93e-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:48:28.937: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xggwb" for this suite.
Aug 28 10:48:36.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:48:38.833: INFO: namespace: e2e-tests-emptydir-xggwb, resource: bindings, ignored listing per whitelist
Aug 28 10:48:40.040: INFO: namespace e2e-tests-emptydir-xggwb deletion completed in 11.097714891s

• [SLOW TEST:17.788 seconds]
[sig-storage] EmptyDir volumes
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:48:40.041: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wczrs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 10:48:40.502: INFO: Couldn't get node TTL annotation (using default value of 0): No TTL annotation found on the node
STEP: Creating secret with name s-test-opt-del-57855aa4-c93e-11e9-a0e2-288023b0a458
STEP: Creating secret with name s-test-opt-upd-57855b58-c93e-11e9-a0e2-288023b0a458
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-57855aa4-c93e-11e9-a0e2-288023b0a458
STEP: Updating secret s-test-opt-upd-57855b58-c93e-11e9-a0e2-288023b0a458
STEP: Creating secret with name s-test-opt-create-57855c5e-c93e-11e9-a0e2-288023b0a458
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:50:09.754: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wczrs" for this suite.
Aug 28 10:50:33.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:50:34.001: INFO: namespace: e2e-tests-projected-wczrs, resource: bindings, ignored listing per whitelist
Aug 28 10:50:36.861: INFO: namespace e2e-tests-projected-wczrs deletion completed in 27.101016952s

• [SLOW TEST:116.820 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:50:36.861: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-j85sj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-j85sj
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-j85sj
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-j85sj
Aug 28 10:50:37.336: INFO: Found 0 stateful pods, waiting for 1
Aug 28 10:50:47.345: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 28 10:50:47.349: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-j85sj ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 28 10:50:47.894: INFO: stderr: ""
Aug 28 10:50:47.894: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 28 10:50:47.894: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 28 10:50:47.899: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 28 10:50:57.905: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 28 10:50:57.905: INFO: Waiting for statefulset status.replicas updated to 0
Aug 28 10:50:57.932: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Aug 28 10:50:57.932: INFO: ss-0  node-124  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:37 +0800 CST  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:48 +0800 CST ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:37 +0800 CST  }]
Aug 28 10:50:57.932: INFO: 
Aug 28 10:50:57.932: INFO: StatefulSet ss has not reached scale 3, at 1
Aug 28 10:50:58.938: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995611977s
Aug 28 10:50:59.943: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989697321s
Aug 28 10:51:00.949: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984713665s
Aug 28 10:51:01.955: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978760488s
Aug 28 10:51:02.962: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972797873s
Aug 28 10:51:03.967: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.965804495s
Aug 28 10:51:04.972: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.960411483s
Aug 28 10:51:05.977: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.955761761s
Aug 28 10:51:06.983: INFO: Verifying statefulset ss doesn't scale past 3 for another 950.498478ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-j85sj
Aug 28 10:51:07.989: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-j85sj ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 28 10:51:08.705: INFO: stderr: ""
Aug 28 10:51:08.705: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 28 10:51:08.705: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 28 10:51:08.706: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-j85sj ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 28 10:51:09.280: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
Aug 28 10:51:09.280: INFO: stdout: ""
Aug 28 10:51:09.280: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Aug 28 10:51:09.280: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-j85sj ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 28 10:51:09.804: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
Aug 28 10:51:09.804: INFO: stdout: ""
Aug 28 10:51:09.804: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Aug 28 10:51:09.809: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 10:51:09.810: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 10:51:09.810: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 28 10:51:09.814: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-j85sj ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 28 10:51:10.403: INFO: stderr: ""
Aug 28 10:51:10.403: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 28 10:51:10.403: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 28 10:51:10.404: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-j85sj ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 28 10:51:11.030: INFO: stderr: ""
Aug 28 10:51:11.030: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 28 10:51:11.030: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 28 10:51:11.030: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=e2e-tests-statefulset-j85sj ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 28 10:51:11.604: INFO: stderr: ""
Aug 28 10:51:11.604: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 28 10:51:11.604: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 28 10:51:11.604: INFO: Waiting for statefulset status.replicas updated to 0
Aug 28 10:51:11.611: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 28 10:51:21.621: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 28 10:51:21.621: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 28 10:51:21.621: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 28 10:51:21.649: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Aug 28 10:51:21.649: INFO: ss-0  node-124  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:37 +0800 CST  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:51:10 +0800 CST ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:37 +0800 CST  }]
Aug 28 10:51:21.649: INFO: ss-1  node-137  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:58 +0800 CST  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:51:11 +0800 CST ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:58 +0800 CST  }]
Aug 28 10:51:21.649: INFO: ss-2  node-128  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:58 +0800 CST  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:51:11 +0800 CST ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:58 +0800 CST  }]
Aug 28 10:51:21.649: INFO: 
Aug 28 10:51:21.649: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 28 10:51:22.655: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Aug 28 10:51:22.655: INFO: ss-0  node-124  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:37 +0800 CST  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:51:10 +0800 CST ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:37 +0800 CST  }]
Aug 28 10:51:22.655: INFO: ss-1  node-137  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:58 +0800 CST  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:51:11 +0800 CST ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:58 +0800 CST  }]
Aug 28 10:51:22.655: INFO: ss-2  node-128  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:58 +0800 CST  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:51:11 +0800 CST ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:58 +0800 CST  }]
Aug 28 10:51:22.655: INFO: 
Aug 28 10:51:22.655: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 28 10:51:23.661: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Aug 28 10:51:23.661: INFO: ss-0  node-124  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:37 +0800 CST  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:51:10 +0800 CST ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:37 +0800 CST  }]
Aug 28 10:51:23.661: INFO: ss-1  node-137  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:58 +0800 CST  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:51:11 +0800 CST ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:58 +0800 CST  }]
Aug 28 10:51:23.661: INFO: ss-2  node-128  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:58 +0800 CST  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:51:11 +0800 CST ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:58 +0800 CST  }]
Aug 28 10:51:23.661: INFO: 
Aug 28 10:51:23.661: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 28 10:51:24.680: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Aug 28 10:51:24.680: INFO: ss-0  node-124  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:37 +0800 CST  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:51:10 +0800 CST ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:37 +0800 CST  }]
Aug 28 10:51:24.680: INFO: 
Aug 28 10:51:24.680: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 28 10:51:25.688: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Aug 28 10:51:25.688: INFO: ss-0  node-124  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:37 +0800 CST  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:51:10 +0800 CST ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-28 10:50:37 +0800 CST  }]
Aug 28 10:51:25.688: INFO: 
Aug 28 10:51:25.688: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 28 10:51:26.693: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.955843264s
Aug 28 10:51:27.698: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.950925769s
Aug 28 10:51:28.704: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.945927967s
Aug 28 10:51:29.708: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.940543748s
Aug 28 10:51:30.744: INFO: Verifying statefulset ss doesn't scale past 0 for another 935.683535ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-j85sj
Aug 28 10:51:31.750: INFO: Scaling statefulset ss to 0
Aug 28 10:51:31.818: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Aug 28 10:51:31.821: INFO: Deleting all statefulset in ns e2e-tests-statefulset-j85sj
Aug 28 10:51:31.825: INFO: Scaling statefulset ss to 0
Aug 28 10:51:31.836: INFO: Waiting for statefulset status.replicas updated to 0
Aug 28 10:51:31.840: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:51:31.858: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-j85sj" for this suite.
Aug 28 10:51:39.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:51:41.399: INFO: namespace: e2e-tests-statefulset-j85sj, resource: bindings, ignored listing per whitelist
Aug 28 10:51:42.999: INFO: namespace e2e-tests-statefulset-j85sj deletion completed in 11.129800633s

• [SLOW TEST:66.138 seconds]
[sig-apps] StatefulSet
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:51:42.999: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-mwkcr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 28 10:51:43.558: INFO: Waiting up to 5m0s for pod "pod-c4907ae2-c93e-11e9-a0e2-288023b0a458" in namespace "e2e-tests-emptydir-mwkcr" to be "success or failure"
Aug 28 10:51:43.580: INFO: Pod "pod-c4907ae2-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 22.173215ms
Aug 28 10:51:45.600: INFO: Pod "pod-c4907ae2-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042337388s
Aug 28 10:51:47.606: INFO: Pod "pod-c4907ae2-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047999147s
Aug 28 10:51:49.611: INFO: Pod "pod-c4907ae2-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.053073462s
Aug 28 10:51:51.616: INFO: Pod "pod-c4907ae2-c93e-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.057989635s
STEP: Saw pod success
Aug 28 10:51:51.616: INFO: Pod "pod-c4907ae2-c93e-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:51:51.619: INFO: Trying to get logs from node node-124 pod pod-c4907ae2-c93e-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 10:51:51.700: INFO: Waiting for pod pod-c4907ae2-c93e-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:51:51.704: INFO: Pod pod-c4907ae2-c93e-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:51:51.704: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mwkcr" for this suite.
Aug 28 10:51:59.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:51:59.792: INFO: namespace: e2e-tests-emptydir-mwkcr, resource: bindings, ignored listing per whitelist
Aug 28 10:52:02.816: INFO: namespace e2e-tests-emptydir-mwkcr deletion completed in 11.104871002s

• [SLOW TEST:19.817 seconds]
[sig-storage] EmptyDir volumes
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:52:02.816: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mr9cl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl rolling-update
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1276
[It] should support rolling-update to same image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Aug 28 10:52:03.259: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config run e2e-test-nginx-rc --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=run/v1 --namespace=e2e-tests-kubectl-mr9cl'
Aug 28 10:52:03.734: INFO: stderr: ""
Aug 28 10:52:03.734: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Aug 28 10:52:03.740: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Aug 28 10:52:03.767: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug 28 10:52:03.788: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config rolling-update e2e-test-nginx-rc --update-period=1s --image=k8s.gcr.io/nginx-slim-amd64:0.20 --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-mr9cl'
Aug 28 10:52:28.108: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 28 10:52:28.108: INFO: stdout: "Created e2e-test-nginx-rc-ea0e04d6f10a0073b03635625cebaef5\nScaling up e2e-test-nginx-rc-ea0e04d6f10a0073b03635625cebaef5 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-ea0e04d6f10a0073b03635625cebaef5 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-ea0e04d6f10a0073b03635625cebaef5 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug 28 10:52:28.109: INFO: stdout: "Created e2e-test-nginx-rc-ea0e04d6f10a0073b03635625cebaef5\nScaling up e2e-test-nginx-rc-ea0e04d6f10a0073b03635625cebaef5 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-ea0e04d6f10a0073b03635625cebaef5 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-ea0e04d6f10a0073b03635625cebaef5 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug 28 10:52:28.109: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-mr9cl'
Aug 28 10:52:28.581: INFO: stderr: ""
Aug 28 10:52:28.581: INFO: stdout: "e2e-test-nginx-rc-ea0e04d6f10a0073b03635625cebaef5-m6p59 "
Aug 28 10:52:28.581: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods e2e-test-nginx-rc-ea0e04d6f10a0073b03635625cebaef5-m6p59 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mr9cl'
Aug 28 10:52:28.996: INFO: stderr: ""
Aug 28 10:52:28.996: INFO: stdout: "true"
Aug 28 10:52:28.996: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods e2e-test-nginx-rc-ea0e04d6f10a0073b03635625cebaef5-m6p59 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mr9cl'
Aug 28 10:52:29.387: INFO: stderr: ""
Aug 28 10:52:29.387: INFO: stdout: "k8s.gcr.io/nginx-slim-amd64:0.20"
Aug 28 10:52:29.387: INFO: e2e-test-nginx-rc-ea0e04d6f10a0073b03635625cebaef5-m6p59 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1282
Aug 28 10:52:29.387: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-mr9cl'
Aug 28 10:52:29.832: INFO: stderr: ""
Aug 28 10:52:29.832: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:52:29.832: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mr9cl" for this suite.
Aug 28 10:52:53.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:52:54.018: INFO: namespace: e2e-tests-kubectl-mr9cl, resource: bindings, ignored listing per whitelist
Aug 28 10:52:56.938: INFO: namespace e2e-tests-kubectl-mr9cl deletion completed in 27.098192483s

• [SLOW TEST:54.122 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support rolling-update to same image  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:52:56.938: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-nwhxw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Aug 28 10:52:57.480: INFO: Waiting up to 5m0s for pod "downward-api-f0a0b9dd-c93e-11e9-a0e2-288023b0a458" in namespace "e2e-tests-downward-api-nwhxw" to be "success or failure"
Aug 28 10:52:57.484: INFO: Pod "downward-api-f0a0b9dd-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.404323ms
Aug 28 10:52:59.489: INFO: Pod "downward-api-f0a0b9dd-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008598401s
Aug 28 10:53:01.493: INFO: Pod "downward-api-f0a0b9dd-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012837253s
Aug 28 10:53:03.498: INFO: Pod "downward-api-f0a0b9dd-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017592703s
Aug 28 10:53:05.504: INFO: Pod "downward-api-f0a0b9dd-c93e-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.023293497s
STEP: Saw pod success
Aug 28 10:53:05.504: INFO: Pod "downward-api-f0a0b9dd-c93e-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:53:05.590: INFO: Trying to get logs from node node-124 pod downward-api-f0a0b9dd-c93e-11e9-a0e2-288023b0a458 container dapi-container: <nil>
STEP: delete the pod
Aug 28 10:53:05.650: INFO: Waiting for pod downward-api-f0a0b9dd-c93e-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:53:05.653: INFO: Pod downward-api-f0a0b9dd-c93e-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:53:05.653: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nwhxw" for this suite.
Aug 28 10:53:13.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:53:13.889: INFO: namespace: e2e-tests-downward-api-nwhxw, resource: bindings, ignored listing per whitelist
Aug 28 10:53:16.816: INFO: namespace e2e-tests-downward-api-nwhxw deletion completed in 11.156892372s

• [SLOW TEST:19.877 seconds]
[sig-api-machinery] Downward API
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:53:16.816: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5k2m2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 10:53:17.372: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fc79ed72-c93e-11e9-a0e2-288023b0a458" in namespace "e2e-tests-downward-api-5k2m2" to be "success or failure"
Aug 28 10:53:17.419: INFO: Pod "downwardapi-volume-fc79ed72-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 46.187876ms
Aug 28 10:53:19.424: INFO: Pod "downwardapi-volume-fc79ed72-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051539539s
Aug 28 10:53:21.446: INFO: Pod "downwardapi-volume-fc79ed72-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.073810889s
Aug 28 10:53:23.451: INFO: Pod "downwardapi-volume-fc79ed72-c93e-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.078604175s
Aug 28 10:53:25.457: INFO: Pod "downwardapi-volume-fc79ed72-c93e-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.083990605s
STEP: Saw pod success
Aug 28 10:53:25.457: INFO: Pod "downwardapi-volume-fc79ed72-c93e-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:53:25.460: INFO: Trying to get logs from node node-124 pod downwardapi-volume-fc79ed72-c93e-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 10:53:25.669: INFO: Waiting for pod downwardapi-volume-fc79ed72-c93e-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:53:25.674: INFO: Pod downwardapi-volume-fc79ed72-c93e-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:53:25.674: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5k2m2" for this suite.
Aug 28 10:53:33.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:53:35.769: INFO: namespace: e2e-tests-downward-api-5k2m2, resource: bindings, ignored listing per whitelist
Aug 28 10:53:36.766: INFO: namespace e2e-tests-downward-api-5k2m2 deletion completed in 11.085551929s

• [SLOW TEST:19.950 seconds]
[sig-storage] Downward API volume
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:53:36.766: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-258cq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 28 10:53:37.464: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-258cq,SelfLink:/api/v1/namespaces/e2e-tests-watch-258cq/configmaps/e2e-watch-test-label-changed,UID:08774a71-c93f-11e9-bbca-288023b0a1ec,ResourceVersion:15129831,Generation:0,CreationTimestamp:2019-08-28 10:53:37 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 28 10:53:37.464: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-258cq,SelfLink:/api/v1/namespaces/e2e-tests-watch-258cq/configmaps/e2e-watch-test-label-changed,UID:08774a71-c93f-11e9-bbca-288023b0a1ec,ResourceVersion:15129833,Generation:0,CreationTimestamp:2019-08-28 10:53:37 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 28 10:53:37.464: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-258cq,SelfLink:/api/v1/namespaces/e2e-tests-watch-258cq/configmaps/e2e-watch-test-label-changed,UID:08774a71-c93f-11e9-bbca-288023b0a1ec,ResourceVersion:15129835,Generation:0,CreationTimestamp:2019-08-28 10:53:37 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 28 10:53:47.594: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-258cq,SelfLink:/api/v1/namespaces/e2e-tests-watch-258cq/configmaps/e2e-watch-test-label-changed,UID:08774a71-c93f-11e9-bbca-288023b0a1ec,ResourceVersion:15129868,Generation:0,CreationTimestamp:2019-08-28 10:53:37 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 28 10:53:47.594: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-258cq,SelfLink:/api/v1/namespaces/e2e-tests-watch-258cq/configmaps/e2e-watch-test-label-changed,UID:08774a71-c93f-11e9-bbca-288023b0a1ec,ResourceVersion:15129870,Generation:0,CreationTimestamp:2019-08-28 10:53:37 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug 28 10:53:47.594: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-258cq,SelfLink:/api/v1/namespaces/e2e-tests-watch-258cq/configmaps/e2e-watch-test-label-changed,UID:08774a71-c93f-11e9-bbca-288023b0a1ec,ResourceVersion:15129871,Generation:0,CreationTimestamp:2019-08-28 10:53:37 +0800 CST,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:53:47.594: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-258cq" for this suite.
Aug 28 10:53:55.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:53:55.804: INFO: namespace: e2e-tests-watch-258cq, resource: bindings, ignored listing per whitelist
Aug 28 10:53:58.709: INFO: namespace e2e-tests-watch-258cq deletion completed in 11.108472517s

• [SLOW TEST:21.943 seconds]
[sig-api-machinery] Watchers
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:53:58.709: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-jhmpq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl replace
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should update a single-container pod's image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Aug 28 10:53:59.223: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config run e2e-test-nginx-pod --generator=run-pod/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-jhmpq'
Aug 28 10:53:59.743: INFO: stderr: ""
Aug 28 10:53:59.743: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug 28 10:54:09.794: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-jhmpq -o json'
Aug 28 10:54:10.199: INFO: stderr: ""
Aug 28 10:54:10.199: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"openshift.io/scc\": \"anyuid\"\n        },\n        \"creationTimestamp\": \"2019-08-28T02:53:59Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-jhmpq\",\n        \"resourceVersion\": \"15130005\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-jhmpq/pods/e2e-test-nginx-pod\",\n        \"uid\": \"15c72ece-c93f-11e9-bbca-288023b0a1ec\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/nginx-slim-amd64:0.20\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"securityContext\": {\n                    \"capabilities\": {\n                        \"drop\": [\n                            \"MKNOD\"\n                        ]\n                    }\n                },\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-xnxtb\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"imagePullSecrets\": [\n            {\n                \"name\": \"default-dockercfg-69hvq\"\n            }\n        ],\n        \"nodeName\": \"node-124\",\n        \"nodeSelector\": {\n            \"node-role.kubernetes.io/compute\": \"true\"\n        },\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {\n            \"seLinuxOptions\": {\n                \"level\": \"s0:c70,c10\"\n            }\n        },\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"volumes\": [\n            {\n                \"name\": \"default-token-xnxtb\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-xnxtb\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-28T02:54:00Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-28T02:54:07Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": null,\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-28T02:53:59Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://58e1c9d59f6f5c3eabc67e3d0f49f01f47c9fa84592aff10563b32831d05df44\",\n                \"image\": \"k8s.gcr.io/nginx-slim-amd64:0.20\",\n                \"imageID\": \"docker://sha256:69854bafc1214f1a7f88c32f193dd0112e4d89d5bd9da9a85d95d5735acbc397\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-28T02:54:06Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.16.151.81\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.243.1.44\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-28T02:54:00Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 28 10:54:10.200: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config replace -f - --namespace=e2e-tests-kubectl-jhmpq'
Aug 28 10:54:10.852: INFO: stderr: ""
Aug 28 10:54:10.852: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image os-harbor-svc.default.svc.cloudos:443/library/busybox
[AfterEach] [k8s.io] Kubectl replace
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1485
Aug 28 10:54:10.865: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-jhmpq'
Aug 28 10:54:16.259: INFO: stderr: ""
Aug 28 10:54:16.259: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:54:16.260: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jhmpq" for this suite.
Aug 28 10:54:24.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:54:24.435: INFO: namespace: e2e-tests-kubectl-jhmpq, resource: bindings, ignored listing per whitelist
Aug 28 10:54:27.455: INFO: namespace e2e-tests-kubectl-jhmpq deletion completed in 11.188240336s

• [SLOW TEST:28.746 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should update a single-container pod's image  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:54:27.455: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-b65xc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Aug 28 10:54:28.052: INFO: Waiting up to 5m0s for pod "downward-api-269757ac-c93f-11e9-a0e2-288023b0a458" in namespace "e2e-tests-downward-api-b65xc" to be "success or failure"
Aug 28 10:54:28.056: INFO: Pod "downward-api-269757ac-c93f-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.842086ms
Aug 28 10:54:30.063: INFO: Pod "downward-api-269757ac-c93f-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011376048s
Aug 28 10:54:32.068: INFO: Pod "downward-api-269757ac-c93f-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015843958s
Aug 28 10:54:34.072: INFO: Pod "downward-api-269757ac-c93f-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.020157113s
Aug 28 10:54:36.082: INFO: Pod "downward-api-269757ac-c93f-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.030511285s
STEP: Saw pod success
Aug 28 10:54:36.082: INFO: Pod "downward-api-269757ac-c93f-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:54:36.087: INFO: Trying to get logs from node node-124 pod downward-api-269757ac-c93f-11e9-a0e2-288023b0a458 container dapi-container: <nil>
STEP: delete the pod
Aug 28 10:54:36.386: INFO: Waiting for pod downward-api-269757ac-c93f-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:54:36.412: INFO: Pod downward-api-269757ac-c93f-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:54:36.412: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b65xc" for this suite.
Aug 28 10:54:44.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:54:44.540: INFO: namespace: e2e-tests-downward-api-b65xc, resource: bindings, ignored listing per whitelist
Aug 28 10:54:47.534: INFO: namespace e2e-tests-downward-api-b65xc deletion completed in 11.113406499s

• [SLOW TEST:20.079 seconds]
[sig-api-machinery] Downward API
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:54:47.534: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jhp7s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name projected-secret-test-329a0096-c93f-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume secrets
Aug 28 10:54:48.132: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-329c610f-c93f-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-jhp7s" to be "success or failure"
Aug 28 10:54:48.136: INFO: Pod "pod-projected-secrets-329c610f-c93f-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.254029ms
Aug 28 10:54:50.145: INFO: Pod "pod-projected-secrets-329c610f-c93f-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013511856s
Aug 28 10:54:52.150: INFO: Pod "pod-projected-secrets-329c610f-c93f-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018490841s
Aug 28 10:54:54.155: INFO: Pod "pod-projected-secrets-329c610f-c93f-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023073118s
STEP: Saw pod success
Aug 28 10:54:54.155: INFO: Pod "pod-projected-secrets-329c610f-c93f-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:54:54.158: INFO: Trying to get logs from node node-124 pod pod-projected-secrets-329c610f-c93f-11e9-a0e2-288023b0a458 container secret-volume-test: <nil>
STEP: delete the pod
Aug 28 10:54:54.287: INFO: Waiting for pod pod-projected-secrets-329c610f-c93f-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:54:54.290: INFO: Pod pod-projected-secrets-329c610f-c93f-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:54:54.291: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jhp7s" for this suite.
Aug 28 10:55:02.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:55:05.101: INFO: namespace: e2e-tests-projected-jhp7s, resource: bindings, ignored listing per whitelist
Aug 28 10:55:05.403: INFO: namespace e2e-tests-projected-jhp7s deletion completed in 11.105345655s

• [SLOW TEST:17.869 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:55:05.403: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7vrt8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-3d3d8743-c93f-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume secrets
Aug 28 10:55:06.055: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3d3f6b50-c93f-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-7vrt8" to be "success or failure"
Aug 28 10:55:06.070: INFO: Pod "pod-projected-secrets-3d3f6b50-c93f-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 14.658498ms
Aug 28 10:55:08.075: INFO: Pod "pod-projected-secrets-3d3f6b50-c93f-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019934721s
Aug 28 10:55:10.081: INFO: Pod "pod-projected-secrets-3d3f6b50-c93f-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026597965s
Aug 28 10:55:12.086: INFO: Pod "pod-projected-secrets-3d3f6b50-c93f-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.031462679s
Aug 28 10:55:14.091: INFO: Pod "pod-projected-secrets-3d3f6b50-c93f-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.03619362s
STEP: Saw pod success
Aug 28 10:55:14.091: INFO: Pod "pod-projected-secrets-3d3f6b50-c93f-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:55:14.095: INFO: Trying to get logs from node node-124 pod pod-projected-secrets-3d3f6b50-c93f-11e9-a0e2-288023b0a458 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 28 10:55:14.148: INFO: Waiting for pod pod-projected-secrets-3d3f6b50-c93f-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:55:14.151: INFO: Pod pod-projected-secrets-3d3f6b50-c93f-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:55:14.151: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7vrt8" for this suite.
Aug 28 10:55:22.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:55:22.272: INFO: namespace: e2e-tests-projected-7vrt8, resource: bindings, ignored listing per whitelist
Aug 28 10:55:25.309: INFO: namespace e2e-tests-projected-7vrt8 deletion completed in 11.150606908s

• [SLOW TEST:19.906 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:55:25.309: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-dkcjr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should run and stop complex daemon [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 10:55:25.911: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 28 10:55:25.943: INFO: Number of nodes with available pods: 0
Aug 28 10:55:25.943: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug 28 10:55:25.979: INFO: Number of nodes with available pods: 0
Aug 28 10:55:25.979: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:26.990: INFO: Number of nodes with available pods: 0
Aug 28 10:55:26.990: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:27.984: INFO: Number of nodes with available pods: 0
Aug 28 10:55:27.984: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:29.011: INFO: Number of nodes with available pods: 0
Aug 28 10:55:29.011: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:29.984: INFO: Number of nodes with available pods: 0
Aug 28 10:55:29.984: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:30.984: INFO: Number of nodes with available pods: 0
Aug 28 10:55:30.984: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:31.984: INFO: Number of nodes with available pods: 1
Aug 28 10:55:31.984: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 28 10:55:32.048: INFO: Number of nodes with available pods: 1
Aug 28 10:55:32.048: INFO: Number of running nodes: 0, number of available pods: 1
Aug 28 10:55:33.108: INFO: Number of nodes with available pods: 0
Aug 28 10:55:33.108: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 28 10:55:33.154: INFO: Number of nodes with available pods: 0
Aug 28 10:55:33.154: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:34.159: INFO: Number of nodes with available pods: 0
Aug 28 10:55:34.159: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:35.159: INFO: Number of nodes with available pods: 0
Aug 28 10:55:35.159: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:36.159: INFO: Number of nodes with available pods: 0
Aug 28 10:55:36.159: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:37.158: INFO: Number of nodes with available pods: 0
Aug 28 10:55:37.158: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:38.173: INFO: Number of nodes with available pods: 0
Aug 28 10:55:38.173: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:39.158: INFO: Number of nodes with available pods: 0
Aug 28 10:55:39.158: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:40.159: INFO: Number of nodes with available pods: 0
Aug 28 10:55:40.159: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:41.159: INFO: Number of nodes with available pods: 0
Aug 28 10:55:41.159: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:42.159: INFO: Number of nodes with available pods: 0
Aug 28 10:55:42.159: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:43.159: INFO: Number of nodes with available pods: 0
Aug 28 10:55:43.159: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:44.159: INFO: Number of nodes with available pods: 0
Aug 28 10:55:44.159: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:45.158: INFO: Number of nodes with available pods: 0
Aug 28 10:55:45.158: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:46.164: INFO: Number of nodes with available pods: 0
Aug 28 10:55:46.164: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:47.159: INFO: Number of nodes with available pods: 0
Aug 28 10:55:47.159: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:48.159: INFO: Number of nodes with available pods: 0
Aug 28 10:55:48.159: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:49.159: INFO: Number of nodes with available pods: 0
Aug 28 10:55:49.159: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:50.159: INFO: Number of nodes with available pods: 0
Aug 28 10:55:50.159: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:51.158: INFO: Number of nodes with available pods: 0
Aug 28 10:55:51.158: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:55:52.158: INFO: Number of nodes with available pods: 1
Aug 28 10:55:52.158: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-dkcjr, will wait for the garbage collector to delete the pods
Aug 28 10:55:52.286: INFO: Deleting {extensions DaemonSet} daemon-set took: 44.428994ms
Aug 28 10:55:52.386: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.228411ms
Aug 28 10:56:06.290: INFO: Number of nodes with available pods: 0
Aug 28 10:56:06.290: INFO: Number of running nodes: 0, number of available pods: 0
Aug 28 10:56:06.295: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-dkcjr/daemonsets","resourceVersion":"15130736"},"items":null}

Aug 28 10:56:06.298: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-dkcjr/pods","resourceVersion":"15130736"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:56:06.345: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-dkcjr" for this suite.
Aug 28 10:56:14.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:56:15.818: INFO: namespace: e2e-tests-daemonsets-dkcjr, resource: bindings, ignored listing per whitelist
Aug 28 10:56:17.470: INFO: namespace e2e-tests-daemonsets-dkcjr deletion completed in 11.119453023s

• [SLOW TEST:52.161 seconds]
[sig-apps] Daemon set [Serial]
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:56:17.471: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-khz5m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-6829fc42-c93f-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 10:56:18.096: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-682fa2e1-c93f-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-khz5m" to be "success or failure"
Aug 28 10:56:18.132: INFO: Pod "pod-projected-configmaps-682fa2e1-c93f-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 35.743406ms
Aug 28 10:56:20.137: INFO: Pod "pod-projected-configmaps-682fa2e1-c93f-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040874778s
Aug 28 10:56:22.142: INFO: Pod "pod-projected-configmaps-682fa2e1-c93f-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045851758s
Aug 28 10:56:24.147: INFO: Pod "pod-projected-configmaps-682fa2e1-c93f-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.051032777s
Aug 28 10:56:26.152: INFO: Pod "pod-projected-configmaps-682fa2e1-c93f-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.055562279s
STEP: Saw pod success
Aug 28 10:56:26.152: INFO: Pod "pod-projected-configmaps-682fa2e1-c93f-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 10:56:26.155: INFO: Trying to get logs from node node-124 pod pod-projected-configmaps-682fa2e1-c93f-11e9-a0e2-288023b0a458 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 28 10:56:26.206: INFO: Waiting for pod pod-projected-configmaps-682fa2e1-c93f-11e9-a0e2-288023b0a458 to disappear
Aug 28 10:56:26.209: INFO: Pod pod-projected-configmaps-682fa2e1-c93f-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:56:26.209: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-khz5m" for this suite.
Aug 28 10:56:34.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:56:34.285: INFO: namespace: e2e-tests-projected-khz5m, resource: bindings, ignored listing per whitelist
Aug 28 10:56:37.445: INFO: namespace e2e-tests-projected-khz5m deletion completed in 11.228894959s

• [SLOW TEST:19.974 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:56:37.445: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5kxhn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 10:56:37.875: INFO: Couldn't get node TTL annotation (using default value of 0): No TTL annotation found on the node
STEP: Creating projection with configMap that has name projected-configmap-test-upd-740eb80c-c93f-11e9-a0e2-288023b0a458
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-740eb80c-c93f-11e9-a0e2-288023b0a458
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 10:58:24.802: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5kxhn" for this suite.
Aug 28 10:58:48.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 10:58:49.069: INFO: namespace: e2e-tests-projected-5kxhn, resource: bindings, ignored listing per whitelist
Aug 28 10:58:51.928: INFO: namespace e2e-tests-projected-5kxhn deletion completed in 27.119224861s

• [SLOW TEST:134.483 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 10:58:51.928: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-fbxdw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 10:58:52.405: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 28 10:58:52.511: INFO: Number of nodes with available pods: 0
Aug 28 10:58:52.511: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:58:53.524: INFO: Number of nodes with available pods: 0
Aug 28 10:58:53.524: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:58:54.548: INFO: Number of nodes with available pods: 0
Aug 28 10:58:54.548: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:58:55.563: INFO: Number of nodes with available pods: 1
Aug 28 10:58:55.563: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:58:56.531: INFO: Number of nodes with available pods: 1
Aug 28 10:58:56.531: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:58:57.524: INFO: Number of nodes with available pods: 1
Aug 28 10:58:57.524: INFO: Node node-124 is running more than one daemon pod
Aug 28 10:58:58.522: INFO: Number of nodes with available pods: 4
Aug 28 10:58:58.522: INFO: Node node-143 is running more than one daemon pod
Aug 28 10:58:59.534: INFO: Number of nodes with available pods: 6
Aug 28 10:58:59.534: INFO: Number of running nodes: 6, number of available pods: 6
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 28 10:58:59.630: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:58:59.630: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:58:59.630: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:58:59.630: INFO: Wrong image for pod: daemon-set-ml75d. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:58:59.630: INFO: Wrong image for pod: daemon-set-p2mvs. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:58:59.630: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:00.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:00.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:00.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:00.646: INFO: Wrong image for pod: daemon-set-ml75d. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:00.646: INFO: Wrong image for pod: daemon-set-p2mvs. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:00.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:01.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:01.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:01.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:01.646: INFO: Wrong image for pod: daemon-set-ml75d. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:01.646: INFO: Wrong image for pod: daemon-set-p2mvs. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:01.646: INFO: Pod daemon-set-p2mvs is not available
Aug 28 10:59:01.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:02.645: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:02.645: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:02.645: INFO: Pod daemon-set-fbp9m is not available
Aug 28 10:59:02.645: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:02.645: INFO: Wrong image for pod: daemon-set-ml75d. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:02.645: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:03.645: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:03.645: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:03.645: INFO: Pod daemon-set-fbp9m is not available
Aug 28 10:59:03.645: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:03.645: INFO: Wrong image for pod: daemon-set-ml75d. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:03.645: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:04.645: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:04.645: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:04.645: INFO: Pod daemon-set-fbp9m is not available
Aug 28 10:59:04.645: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:04.645: INFO: Wrong image for pod: daemon-set-ml75d. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:04.645: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:05.645: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:05.645: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:05.645: INFO: Pod daemon-set-fbp9m is not available
Aug 28 10:59:05.645: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:05.645: INFO: Wrong image for pod: daemon-set-ml75d. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:05.645: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:06.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:06.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:06.646: INFO: Pod daemon-set-fbp9m is not available
Aug 28 10:59:06.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:06.646: INFO: Wrong image for pod: daemon-set-ml75d. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:06.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:07.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:07.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:07.646: INFO: Pod daemon-set-fbp9m is not available
Aug 28 10:59:07.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:07.646: INFO: Wrong image for pod: daemon-set-ml75d. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:07.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:08.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:08.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:08.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:08.646: INFO: Wrong image for pod: daemon-set-ml75d. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:08.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:09.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:09.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:09.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:09.646: INFO: Wrong image for pod: daemon-set-ml75d. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:09.646: INFO: Pod daemon-set-ml75d is not available
Aug 28 10:59:09.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:10.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:10.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:10.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:10.646: INFO: Pod daemon-set-rp2p7 is not available
Aug 28 10:59:10.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:11.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:11.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:11.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:11.646: INFO: Pod daemon-set-rp2p7 is not available
Aug 28 10:59:11.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:12.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:12.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:12.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:12.646: INFO: Pod daemon-set-rp2p7 is not available
Aug 28 10:59:12.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:13.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:13.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:13.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:13.646: INFO: Pod daemon-set-rp2p7 is not available
Aug 28 10:59:13.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:14.653: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:14.653: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:14.653: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:14.653: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:15.659: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:15.660: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:15.660: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:15.660: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:16.666: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:16.667: INFO: Pod daemon-set-4w6mn is not available
Aug 28 10:59:16.667: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:16.667: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:16.667: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:17.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:17.646: INFO: Pod daemon-set-4w6mn is not available
Aug 28 10:59:17.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:17.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:17.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:18.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:18.646: INFO: Pod daemon-set-4w6mn is not available
Aug 28 10:59:18.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:18.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:18.647: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:19.647: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:19.647: INFO: Pod daemon-set-4w6mn is not available
Aug 28 10:59:19.647: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:19.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:19.647: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:20.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:20.646: INFO: Pod daemon-set-4w6mn is not available
Aug 28 10:59:20.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:20.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:20.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:21.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:21.646: INFO: Pod daemon-set-4w6mn is not available
Aug 28 10:59:21.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:21.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:21.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:22.647: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:22.647: INFO: Pod daemon-set-4w6mn is not available
Aug 28 10:59:22.647: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:22.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:22.647: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:23.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:23.646: INFO: Pod daemon-set-4w6mn is not available
Aug 28 10:59:23.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:23.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:23.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:24.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:24.646: INFO: Pod daemon-set-4w6mn is not available
Aug 28 10:59:24.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:24.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:24.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:25.646: INFO: Wrong image for pod: daemon-set-4w6mn. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:25.646: INFO: Pod daemon-set-4w6mn is not available
Aug 28 10:59:25.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:25.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:25.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:26.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:26.646: INFO: Pod daemon-set-bdcgq is not available
Aug 28 10:59:26.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:26.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:27.645: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:27.645: INFO: Pod daemon-set-bdcgq is not available
Aug 28 10:59:27.645: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:27.645: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:28.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:28.646: INFO: Pod daemon-set-bdcgq is not available
Aug 28 10:59:28.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:28.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:29.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:29.646: INFO: Pod daemon-set-bdcgq is not available
Aug 28 10:59:29.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:29.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:30.647: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:30.647: INFO: Pod daemon-set-bdcgq is not available
Aug 28 10:59:30.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:30.647: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:31.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:31.646: INFO: Pod daemon-set-bdcgq is not available
Aug 28 10:59:31.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:31.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:32.662: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:32.662: INFO: Pod daemon-set-bdcgq is not available
Aug 28 10:59:32.662: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:32.662: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:33.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:33.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:33.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:34.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:34.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:34.646: INFO: Wrong image for pod: daemon-set-vccq6. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:34.646: INFO: Pod daemon-set-vccq6 is not available
Aug 28 10:59:35.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:35.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:35.646: INFO: Pod daemon-set-vpgxn is not available
Aug 28 10:59:36.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:36.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:36.646: INFO: Pod daemon-set-vpgxn is not available
Aug 28 10:59:37.647: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:37.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:37.647: INFO: Pod daemon-set-vpgxn is not available
Aug 28 10:59:38.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:38.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:38.646: INFO: Pod daemon-set-vpgxn is not available
Aug 28 10:59:39.645: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:39.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:40.645: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:40.645: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:41.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:41.647: INFO: Pod daemon-set-87q5w is not available
Aug 28 10:59:41.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:42.647: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:42.647: INFO: Pod daemon-set-87q5w is not available
Aug 28 10:59:42.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:43.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:43.646: INFO: Pod daemon-set-87q5w is not available
Aug 28 10:59:43.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:44.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:44.646: INFO: Pod daemon-set-87q5w is not available
Aug 28 10:59:44.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:45.645: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:45.645: INFO: Pod daemon-set-87q5w is not available
Aug 28 10:59:45.645: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:46.646: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:46.646: INFO: Pod daemon-set-87q5w is not available
Aug 28 10:59:46.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:47.647: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:47.647: INFO: Pod daemon-set-87q5w is not available
Aug 28 10:59:47.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:48.647: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:48.647: INFO: Pod daemon-set-87q5w is not available
Aug 28 10:59:48.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:49.647: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:49.647: INFO: Pod daemon-set-87q5w is not available
Aug 28 10:59:49.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:50.647: INFO: Wrong image for pod: daemon-set-87q5w. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:50.647: INFO: Pod daemon-set-87q5w is not available
Aug 28 10:59:50.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:51.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:51.647: INFO: Pod daemon-set-rwhtc is not available
Aug 28 10:59:52.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:52.647: INFO: Pod daemon-set-rwhtc is not available
Aug 28 10:59:53.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:53.647: INFO: Pod daemon-set-rwhtc is not available
Aug 28 10:59:54.649: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:54.649: INFO: Pod daemon-set-rwhtc is not available
Aug 28 10:59:55.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:55.646: INFO: Pod daemon-set-rwhtc is not available
Aug 28 10:59:56.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:56.646: INFO: Pod daemon-set-rwhtc is not available
Aug 28 10:59:57.655: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:58.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:59.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 10:59:59.646: INFO: Pod daemon-set-fvmll is not available
Aug 28 11:00:00.645: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 11:00:00.645: INFO: Pod daemon-set-fvmll is not available
Aug 28 11:00:01.646: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 11:00:01.646: INFO: Pod daemon-set-fvmll is not available
Aug 28 11:00:02.647: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 11:00:02.647: INFO: Pod daemon-set-fvmll is not available
Aug 28 11:00:03.710: INFO: Wrong image for pod: daemon-set-fvmll. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Aug 28 11:00:03.710: INFO: Pod daemon-set-fvmll is not available
Aug 28 11:00:04.646: INFO: Pod daemon-set-pz7l2 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 28 11:00:04.664: INFO: Number of nodes with available pods: 5
Aug 28 11:00:04.664: INFO: Node node-137 is running more than one daemon pod
Aug 28 11:00:05.677: INFO: Number of nodes with available pods: 5
Aug 28 11:00:05.677: INFO: Node node-137 is running more than one daemon pod
Aug 28 11:00:06.684: INFO: Number of nodes with available pods: 5
Aug 28 11:00:06.684: INFO: Node node-137 is running more than one daemon pod
Aug 28 11:00:07.676: INFO: Number of nodes with available pods: 5
Aug 28 11:00:07.676: INFO: Node node-137 is running more than one daemon pod
Aug 28 11:00:08.677: INFO: Number of nodes with available pods: 5
Aug 28 11:00:08.678: INFO: Node node-137 is running more than one daemon pod
Aug 28 11:00:09.677: INFO: Number of nodes with available pods: 6
Aug 28 11:00:09.677: INFO: Number of running nodes: 6, number of available pods: 6
[AfterEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-fbxdw, will wait for the garbage collector to delete the pods
Aug 28 11:00:09.786: INFO: Deleting {extensions DaemonSet} daemon-set took: 16.653137ms
Aug 28 11:00:09.886: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.226732ms
Aug 28 11:00:22.800: INFO: Number of nodes with available pods: 0
Aug 28 11:00:22.800: INFO: Number of running nodes: 0, number of available pods: 0
Aug 28 11:00:22.804: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fbxdw/daemonsets","resourceVersion":"15131980"},"items":null}

Aug 28 11:00:22.807: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fbxdw/pods","resourceVersion":"15131980"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:00:22.825: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-fbxdw" for this suite.
Aug 28 11:00:30.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:00:30.991: INFO: namespace: e2e-tests-daemonsets-fbxdw, resource: bindings, ignored listing per whitelist
Aug 28 11:00:33.975: INFO: namespace e2e-tests-daemonsets-fbxdw deletion completed in 11.144392608s

• [SLOW TEST:102.046 seconds]
[sig-apps] Daemon set [Serial]
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:00:33.975: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-sbrkj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 28 11:00:34.492: INFO: Waiting up to 5m0s for pod "pod-0104101e-c940-11e9-a0e2-288023b0a458" in namespace "e2e-tests-emptydir-sbrkj" to be "success or failure"
Aug 28 11:00:34.496: INFO: Pod "pod-0104101e-c940-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.846234ms
Aug 28 11:00:36.501: INFO: Pod "pod-0104101e-c940-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008327363s
Aug 28 11:00:38.506: INFO: Pod "pod-0104101e-c940-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013582976s
Aug 28 11:00:40.511: INFO: Pod "pod-0104101e-c940-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.018748156s
Aug 28 11:00:42.516: INFO: Pod "pod-0104101e-c940-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.024039737s
STEP: Saw pod success
Aug 28 11:00:42.516: INFO: Pod "pod-0104101e-c940-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:00:42.520: INFO: Trying to get logs from node node-124 pod pod-0104101e-c940-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 11:00:42.691: INFO: Waiting for pod pod-0104101e-c940-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:00:42.694: INFO: Pod pod-0104101e-c940-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:00:42.694: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sbrkj" for this suite.
Aug 28 11:00:50.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:00:50.862: INFO: namespace: e2e-tests-emptydir-sbrkj, resource: bindings, ignored listing per whitelist
Aug 28 11:00:53.820: INFO: namespace e2e-tests-emptydir-sbrkj deletion completed in 11.119228646s

• [SLOW TEST:19.845 seconds]
[sig-storage] EmptyDir volumes
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:00:53.820: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-b745h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be submitted and removed [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Aug 28 11:01:00.391: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-0ce82c79-c940-11e9-a0e2-288023b0a458", GenerateName:"", Namespace:"e2e-tests-pods-b745h", SelfLink:"/api/v1/namespaces/e2e-tests-pods-b745h/pods/pod-submit-remove-0ce82c79-c940-11e9-a0e2-288023b0a458", UID:"0ceb3694-c940-11e9-bbca-288023b0a1ec", ResourceVersion:"15132306", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63702558054, loc:(*time.Location)(0x640a9a0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"314313657"}, Annotations:map[string]string{"openshift.io/scc":"anyuid"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-hz82v", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc42274b0c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"k8s.gcr.io/nginx-slim-amd64:0.20", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hz82v", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc42274b300), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc42274fa98), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"node-role.kubernetes.io/compute":"true"}, ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"node-124", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421be9320), ImagePullSecrets:[]v1.LocalObjectReference{v1.LocalObjectReference{Name:"default-dockercfg-fmjqw"}}, Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc42274fbc8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702558054, loc:(*time.Location)(0x640a9a0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702558059, loc:(*time.Location)(0x640a9a0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63702558054, loc:(*time.Location)(0x640a9a0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.16.151.81", PodIP:"10.243.1.57", StartTime:(*v1.Time)(0xc422247860), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc422247880), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"k8s.gcr.io/nginx-slim-amd64:0.20", ImageID:"docker://sha256:69854bafc1214f1a7f88c32f193dd0112e4d89d5bd9da9a85d95d5735acbc397", ContainerID:"docker://d0faf6220b39705a8ddb749f9754e534c02b0be251cde22f5b10a468c0ff2c60"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:01:06.243: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-b745h" for this suite.
Aug 28 11:01:14.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:01:14.451: INFO: namespace: e2e-tests-pods-b745h, resource: bindings, ignored listing per whitelist
Aug 28 11:01:17.367: INFO: namespace e2e-tests-pods-b745h deletion completed in 11.117773961s

• [SLOW TEST:23.547 seconds]
[k8s.io] Pods
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be submitted and removed [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:01:17.368: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-wj5xt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-wj5xt
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 28 11:01:17.736: INFO: Waiting up to 10m0s for all (but 3) nodes to be schedulable
STEP: Creating test pods
Aug 28 11:01:46.514: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.245.0.68:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-wj5xt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 11:01:46.514: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 11:01:46.874: INFO: Found all expected endpoints: [netserver-0]
Aug 28 11:01:46.908: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.243.1.58:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-wj5xt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 11:01:46.908: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 11:01:47.058: INFO: Found all expected endpoints: [netserver-1]
Aug 28 11:01:47.062: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.1.37:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-wj5xt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 11:01:47.062: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 11:01:47.272: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:01:47.272: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-wj5xt" for this suite.
Aug 28 11:02:11.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:02:12.867: INFO: namespace: e2e-tests-pod-network-test-wj5xt, resource: bindings, ignored listing per whitelist
Aug 28 11:02:14.370: INFO: namespace e2e-tests-pod-network-test-wj5xt deletion completed in 27.09128466s

• [SLOW TEST:57.003 seconds]
[sig-network] Networking
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed  [Flaky] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:02:14.370: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-7fgt5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:46
[It] should be submitted and removed  [Flaky] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Aug 28 11:02:20.953: INFO: Asynchronously running '/bin/kubectl kubectl --kubeconfig=/root/.kube/config proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug 28 11:02:26.372: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:02:26.393: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7fgt5" for this suite.
Aug 28 11:02:34.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:02:37.081: INFO: namespace: e2e-tests-pods-7fgt5, resource: bindings, ignored listing per whitelist
Aug 28 11:02:37.781: INFO: namespace e2e-tests-pods-7fgt5 deletion completed in 11.381167886s

• [SLOW TEST:23.411 seconds]
[k8s.io] [sig-node] Pods Extended
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  [k8s.io] Delete Grace Period
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should be submitted and removed  [Flaky] [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:02:37.781: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-89xbk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl label
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1012
STEP: creating the pod
Aug 28 11:02:38.272: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-89xbk'
Aug 28 11:02:39.019: INFO: stderr: ""
Aug 28 11:02:39.019: INFO: stdout: "pod/pause created\n"
Aug 28 11:02:39.019: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 28 11:02:39.019: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-89xbk" to be "running and ready"
Aug 28 11:02:39.024: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.820458ms
Aug 28 11:02:41.030: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010460288s
Aug 28 11:02:43.035: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01547063s
Aug 28 11:02:45.039: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 6.020008464s
Aug 28 11:02:45.039: INFO: Pod "pause" satisfied condition "running and ready"
Aug 28 11:02:45.039: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 28 11:02:45.040: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-89xbk'
Aug 28 11:02:45.499: INFO: stderr: ""
Aug 28 11:02:45.499: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 28 11:02:45.499: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pod pause -L testing-label --namespace=e2e-tests-kubectl-89xbk'
Aug 28 11:02:45.975: INFO: stderr: ""
Aug 28 11:02:45.975: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          7s        testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 28 11:02:45.976: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config label pods pause testing-label- --namespace=e2e-tests-kubectl-89xbk'
Aug 28 11:02:46.449: INFO: stderr: ""
Aug 28 11:02:46.449: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 28 11:02:46.449: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pod pause -L testing-label --namespace=e2e-tests-kubectl-89xbk'
Aug 28 11:02:46.877: INFO: stderr: ""
Aug 28 11:02:46.877: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          8s        \n"
[AfterEach] [k8s.io] Kubectl label
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1018
STEP: using delete to clean up resources
Aug 28 11:02:46.878: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-89xbk'
Aug 28 11:02:47.412: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 28 11:02:47.412: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 28 11:02:47.412: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-89xbk'
Aug 28 11:02:47.831: INFO: stderr: "No resources found.\n"
Aug 28 11:02:47.831: INFO: stdout: ""
Aug 28 11:02:47.831: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -l name=pause --namespace=e2e-tests-kubectl-89xbk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 28 11:02:48.233: INFO: stderr: ""
Aug 28 11:02:48.233: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:02:48.233: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-89xbk" for this suite.
Aug 28 11:02:56.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:02:56.455: INFO: namespace: e2e-tests-kubectl-89xbk, resource: bindings, ignored listing per whitelist
Aug 28 11:02:59.347: INFO: namespace e2e-tests-kubectl-89xbk deletion completed in 11.107175148s

• [SLOW TEST:21.566 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should update the label on a resource  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:02:59.348: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jwr6z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 28 11:02:59.861: INFO: Waiting up to 5m0s for pod "pod-57acaa57-c940-11e9-a0e2-288023b0a458" in namespace "e2e-tests-emptydir-jwr6z" to be "success or failure"
Aug 28 11:02:59.887: INFO: Pod "pod-57acaa57-c940-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 25.560737ms
Aug 28 11:03:01.909: INFO: Pod "pod-57acaa57-c940-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048304082s
Aug 28 11:03:03.922: INFO: Pod "pod-57acaa57-c940-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.061541026s
Aug 28 11:03:05.927: INFO: Pod "pod-57acaa57-c940-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.065592822s
Aug 28 11:03:07.931: INFO: Pod "pod-57acaa57-c940-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.069950258s
STEP: Saw pod success
Aug 28 11:03:07.931: INFO: Pod "pod-57acaa57-c940-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:03:07.934: INFO: Trying to get logs from node node-124 pod pod-57acaa57-c940-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 11:03:08.258: INFO: Waiting for pod pod-57acaa57-c940-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:03:08.262: INFO: Pod pod-57acaa57-c940-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:03:08.262: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jwr6z" for this suite.
Aug 28 11:03:16.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:03:18.658: INFO: namespace: e2e-tests-emptydir-jwr6z, resource: bindings, ignored listing per whitelist
Aug 28 11:03:19.355: INFO: namespace e2e-tests-emptydir-jwr6z deletion completed in 11.085652944s

• [SLOW TEST:20.007 seconds]
[sig-storage] EmptyDir volumes
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] PreStop
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:03:19.355: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-96msg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating server pod server in namespace e2e-tests-prestop-96msg
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-96msg
STEP: Deleting pre-stop pod
Aug 28 11:03:37.075: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:03:37.090: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-96msg" for this suite.
Aug 28 11:04:19.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:04:19.191: INFO: namespace: e2e-tests-prestop-96msg, resource: bindings, ignored listing per whitelist
Aug 28 11:04:22.246: INFO: namespace e2e-tests-prestop-96msg deletion completed in 45.148301179s

• [SLOW TEST:62.891 seconds]
[k8s.io] [sig-node] PreStop
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should call prestop when killing a pod  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:04:22.246: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-s55lx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 11:04:22.802: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config version --client'
Aug 28 11:04:23.110: INFO: stderr: ""
Aug 28 11:04:23.110: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11+\", GitVersion:\"v1.11.0+d4cacc0\", GitCommit:\"d4cacc0\", GitTreeState:\"clean\", BuildDate:\"2018-10-15T09:45:30Z\", GoVersion:\"go1.10.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Aug 28 11:04:23.113: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-s55lx'
Aug 28 11:04:23.697: INFO: stderr: ""
Aug 28 11:04:23.697: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug 28 11:04:23.697: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-s55lx'
Aug 28 11:04:24.312: INFO: stderr: ""
Aug 28 11:04:24.312: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 28 11:04:25.318: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:04:25.318: INFO: Found 0 / 1
Aug 28 11:04:26.318: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:04:26.318: INFO: Found 0 / 1
Aug 28 11:04:27.318: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:04:27.318: INFO: Found 0 / 1
Aug 28 11:04:28.317: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:04:28.317: INFO: Found 0 / 1
Aug 28 11:04:29.318: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:04:29.318: INFO: Found 0 / 1
Aug 28 11:04:30.318: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:04:30.318: INFO: Found 1 / 1
Aug 28 11:04:30.318: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 28 11:04:30.321: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:04:30.321: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 28 11:04:30.321: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config describe pod redis-master-w9tzf --namespace=e2e-tests-kubectl-s55lx'
Aug 28 11:04:30.760: INFO: stderr: ""
Aug 28 11:04:30.760: INFO: stdout: "Name:               redis-master-w9tzf\nNamespace:          e2e-tests-kubectl-s55lx\nPriority:           0\nPriorityClassName:  <none>\nNode:               node-124/172.16.151.81\nStart Time:         Wed, 28 Aug 2019 11:04:23 +0800\nLabels:             app=redis\n                    role=master\nAnnotations:        openshift.io/scc=privileged\nStatus:             Running\nIP:                 10.243.1.65\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://69730950e0437f5a1615cff51844993a7e5c0f484e1742455151792d8b74c819\n    Image:          gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\n    Image ID:       docker://sha256:e4423e943a205fe1d81768e60603c8f2c5821576bad0801c1e91b8ba586124a0\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 28 Aug 2019 11:04:29 +0800\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-t2rgn (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-t2rgn:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-t2rgn\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  node-role.kubernetes.io/compute=true\nTolerations:     <none>\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  7s    default-scheduler  Successfully assigned e2e-tests-kubectl-s55lx/redis-master-w9tzf to node-124\n  Normal  Pulled     3s    kubelet, node-124  Container image \"gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\" already present on machine\n  Normal  Created    2s    kubelet, node-124  Created container\n  Normal  Started    1s    kubelet, node-124  Started container\n"
Aug 28 11:04:30.761: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config describe rc redis-master --namespace=e2e-tests-kubectl-s55lx'
Aug 28 11:04:31.204: INFO: stderr: ""
Aug 28 11:04:31.204: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-s55lx\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  8s    replication-controller  Created pod: redis-master-w9tzf\n"
Aug 28 11:04:31.205: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config describe service redis-master --namespace=e2e-tests-kubectl-s55lx'
Aug 28 11:04:31.619: INFO: stderr: ""
Aug 28 11:04:31.619: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-s55lx\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.100.109.172\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.243.1.65:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 28 11:04:31.629: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config describe node node-124'
Aug 28 11:04:32.086: INFO: stderr: ""
Aug 28 11:04:32.087: INFO: stdout: "Name:               node-124\nRoles:              compute\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    clusterIP=172.16.151.81\n                    kubernetes.io/hostname=node-124\n                    node-role.kubernetes.io/compute=true\n                    nodeType=worker\n                    zone-702be40=kubernetes\n                    zone-d2e9fa6=kubernetes\nAnnotations:        node.openshift.io/md5sum=aea1c81582e14baccf60e359b33298d6\nCreationTimestamp:  Thu, 15 Aug 2019 14:03:49 +0800\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Wed, 28 Aug 2019 11:04:31 +0800   Thu, 15 Aug 2019 14:03:49 +0800   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Wed, 28 Aug 2019 11:04:31 +0800   Thu, 15 Aug 2019 14:03:49 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 28 Aug 2019 11:04:31 +0800   Thu, 15 Aug 2019 14:03:49 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 28 Aug 2019 11:04:31 +0800   Thu, 15 Aug 2019 14:03:49 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 28 Aug 2019 11:04:31 +0800   Tue, 27 Aug 2019 17:02:38 +0800   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.16.151.81\n  Hostname:    node-124\nCapacity:\n cpu:            24\n hugepages-1Gi:  0\n hugepages-2Mi:  0\n memory:         263862900Ki\n pods:           250\nAllocatable:\n cpu:            24\n hugepages-1Gi:  0\n hugepages-2Mi:  0\n memory:         261765748Ki\n pods:           250\nSystem Info:\n Machine ID:                 32edd2f6b187453a91f5d51612ca0904\n System UUID:                35333230-3141-4348-5731-35373030394A\n Boot ID:                    a681c676-1c09-4b86-972d-e1c3ba9ea190\n Kernel Version:             4.14.0-115.7.1.el7a.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://1.13.1\n Kubelet Version:            v1.11.0+d4cacc0\n Kube-Proxy Version:         v1.11.0+d4cacc0\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                            CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                            ------------  ----------  ---------------  -------------\n  default                    os-log-daemonset-7rwz8                          200m (0%)     4 (16%)     256Mi (0%)       4Gi (1%)\n  default                    os-weave-scope-agent-grsw6                      200m (0%)     2 (8%)      128Mi (0%)       1Gi (0%)\n  e2e-tests-kubectl-s55lx    redis-master-w9tzf                              0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  openshift-node             sync-b5rks                                      50m (0%)      200m (0%)   20Mi (0%)        200Mi (0%)\n  openshift-sdn              ovs-wbrm7                                       100m (0%)     200m (0%)   256Mi (0%)       512Mi (0%)\n  openshift-sdn              sdn-bptkv                                       100m (0%)     200m (0%)   256Mi (0%)       512Mi (0%)\n  prometheus-monitoring      os-prometheus-prometheus-node-exporter-bhts2    100m (0%)     200m (0%)   30Mi (0%)        50Mi (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       750m (3%)   6800m (28%)\n  memory    946Mi (0%)  6394Mi (2%)\nEvents:     <none>\n"
Aug 28 11:04:32.087: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config describe namespace e2e-tests-kubectl-s55lx'
Aug 28 11:04:32.511: INFO: stderr: ""
Aug 28 11:04:32.511: INFO: stdout: "Name:         e2e-tests-kubectl-s55lx\nLabels:       e2e-framework=kubectl\n              e2e-run=e8c54072-c936-11e9-a0e2-288023b0a458\nAnnotations:  openshift.io/sa.scc.mcs=s0:c71,c15\n              openshift.io/sa.scc.supplemental-groups=1005000000/10000\n              openshift.io/sa.scc.uid-range=1005000000/10000\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:04:32.511: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s55lx" for this suite.
Aug 28 11:04:56.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:04:57.128: INFO: namespace: e2e-tests-kubectl-s55lx, resource: bindings, ignored listing per whitelist
Aug 28 11:04:59.615: INFO: namespace e2e-tests-kubectl-s55lx deletion completed in 27.097371414s

• [SLOW TEST:37.369 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:04:59.615: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-wcbcx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override arguments
Aug 28 11:05:00.254: INFO: Waiting up to 5m0s for pod "client-containers-9f60837b-c940-11e9-a0e2-288023b0a458" in namespace "e2e-tests-containers-wcbcx" to be "success or failure"
Aug 28 11:05:00.303: INFO: Pod "client-containers-9f60837b-c940-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 49.470377ms
Aug 28 11:05:02.309: INFO: Pod "client-containers-9f60837b-c940-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055232432s
Aug 28 11:05:04.314: INFO: Pod "client-containers-9f60837b-c940-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.059520351s
Aug 28 11:05:06.318: INFO: Pod "client-containers-9f60837b-c940-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.063785184s
Aug 28 11:05:08.323: INFO: Pod "client-containers-9f60837b-c940-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.069119757s
STEP: Saw pod success
Aug 28 11:05:08.323: INFO: Pod "client-containers-9f60837b-c940-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:05:08.327: INFO: Trying to get logs from node node-124 pod client-containers-9f60837b-c940-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 11:05:08.367: INFO: Waiting for pod client-containers-9f60837b-c940-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:05:08.370: INFO: Pod client-containers-9f60837b-c940-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:05:08.370: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-wcbcx" for this suite.
Aug 28 11:05:16.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:05:17.741: INFO: namespace: e2e-tests-containers-wcbcx, resource: bindings, ignored listing per whitelist
Aug 28 11:05:19.492: INFO: namespace e2e-tests-containers-wcbcx deletion completed in 11.114648039s

• [SLOW TEST:19.877 seconds]
[k8s.io] Docker Containers
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:05:19.492: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-xr77m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should retry creating failed daemon pods [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 28 11:05:20.016: INFO: Number of nodes with available pods: 0
Aug 28 11:05:20.016: INFO: Node node-124 is running more than one daemon pod
Aug 28 11:05:21.029: INFO: Number of nodes with available pods: 0
Aug 28 11:05:21.029: INFO: Node node-124 is running more than one daemon pod
Aug 28 11:05:22.029: INFO: Number of nodes with available pods: 0
Aug 28 11:05:22.029: INFO: Node node-124 is running more than one daemon pod
Aug 28 11:05:23.028: INFO: Number of nodes with available pods: 1
Aug 28 11:05:23.028: INFO: Node node-124 is running more than one daemon pod
Aug 28 11:05:24.043: INFO: Number of nodes with available pods: 1
Aug 28 11:05:24.043: INFO: Node node-124 is running more than one daemon pod
Aug 28 11:05:25.036: INFO: Number of nodes with available pods: 2
Aug 28 11:05:25.036: INFO: Node node-124 is running more than one daemon pod
Aug 28 11:05:26.076: INFO: Number of nodes with available pods: 3
Aug 28 11:05:26.076: INFO: Node node-124 is running more than one daemon pod
Aug 28 11:05:27.031: INFO: Number of nodes with available pods: 4
Aug 28 11:05:27.031: INFO: Node node-143 is running more than one daemon pod
Aug 28 11:05:28.028: INFO: Number of nodes with available pods: 6
Aug 28 11:05:28.028: INFO: Number of running nodes: 6, number of available pods: 6
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 28 11:05:28.063: INFO: Number of nodes with available pods: 6
Aug 28 11:05:28.063: INFO: Number of running nodes: 6, number of available pods: 6
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-xr77m, will wait for the garbage collector to delete the pods
Aug 28 11:05:29.159: INFO: Deleting {extensions DaemonSet} daemon-set took: 20.563995ms
Aug 28 11:05:29.263: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 103.919079ms
Aug 28 11:05:41.168: INFO: Number of nodes with available pods: 0
Aug 28 11:05:41.168: INFO: Number of running nodes: 0, number of available pods: 0
Aug 28 11:05:41.180: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-xr77m/daemonsets","resourceVersion":"15133987"},"items":null}

Aug 28 11:05:41.183: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-xr77m/pods","resourceVersion":"15133987"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:05:41.201: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-xr77m" for this suite.
Aug 28 11:05:49.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:05:50.747: INFO: namespace: e2e-tests-daemonsets-xr77m, resource: bindings, ignored listing per whitelist
Aug 28 11:05:52.296: INFO: namespace e2e-tests-daemonsets-xr77m deletion completed in 11.08869976s

• [SLOW TEST:32.804 seconds]
[sig-apps] Daemon set [Serial]
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:05:52.297: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-x2hwd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0828 11:05:58.796826   76809 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 28 11:05:58.796: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:05:58.796: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-x2hwd" for this suite.
Aug 28 11:06:06.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:06:06.898: INFO: namespace: e2e-tests-gc-x2hwd, resource: bindings, ignored listing per whitelist
Aug 28 11:06:09.922: INFO: namespace e2e-tests-gc-x2hwd deletion completed in 11.119789949s

• [SLOW TEST:17.626 seconds]
[sig-api-machinery] Garbage collector
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:06:09.923: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-2crdm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-map-c94bf451-c940-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume secrets
Aug 28 11:06:10.525: INFO: Waiting up to 5m0s for pod "pod-secrets-c950aea0-c940-11e9-a0e2-288023b0a458" in namespace "e2e-tests-secrets-2crdm" to be "success or failure"
Aug 28 11:06:10.536: INFO: Pod "pod-secrets-c950aea0-c940-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 11.138419ms
Aug 28 11:06:12.540: INFO: Pod "pod-secrets-c950aea0-c940-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015241564s
Aug 28 11:06:14.545: INFO: Pod "pod-secrets-c950aea0-c940-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020092141s
Aug 28 11:06:16.550: INFO: Pod "pod-secrets-c950aea0-c940-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025002089s
STEP: Saw pod success
Aug 28 11:06:16.550: INFO: Pod "pod-secrets-c950aea0-c940-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:06:16.554: INFO: Trying to get logs from node node-124 pod pod-secrets-c950aea0-c940-11e9-a0e2-288023b0a458 container secret-volume-test: <nil>
STEP: delete the pod
Aug 28 11:06:16.618: INFO: Waiting for pod pod-secrets-c950aea0-c940-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:06:16.622: INFO: Pod pod-secrets-c950aea0-c940-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:06:16.622: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2crdm" for this suite.
Aug 28 11:06:24.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:06:24.713: INFO: namespace: e2e-tests-secrets-2crdm, resource: bindings, ignored listing per whitelist
Aug 28 11:06:27.717: INFO: namespace e2e-tests-secrets-2crdm deletion completed in 11.088643405s

• [SLOW TEST:17.795 seconds]
[sig-storage] Secrets
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:06:27.718: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-nq5xp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-nq5xp
Aug 28 11:06:34.356: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-nq5xp
STEP: checking the pod's current state and verifying that restartCount is present
Aug 28 11:06:34.359: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:10:35.102: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-nq5xp" for this suite.
Aug 28 11:10:43.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:10:45.714: INFO: namespace: e2e-tests-container-probe-nq5xp, resource: bindings, ignored listing per whitelist
Aug 28 11:10:46.215: INFO: namespace e2e-tests-container-probe-nq5xp deletion completed in 11.105748541s

• [SLOW TEST:258.498 seconds]
[k8s.io] Probing container
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:10:46.216: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hkxkm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if v1 is in available api versions  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: validating api versions
Aug 28 11:10:46.628: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config api-versions'
Aug 28 11:10:46.991: INFO: stderr: ""
Aug 28 11:10:46.991: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps.openshift.io/v1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.istio.io/v1alpha1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nauthorization.openshift.io/v1\nautoscaling/v1\nautoscaling/v2beta1\nbatch/v1\nbatch/v1beta1\nbuild.openshift.io/v1\ncertificates.k8s.io/v1beta1\nconfig.istio.io/v1alpha2\nevents.k8s.io/v1beta1\nextensions/v1beta1\nimage.openshift.io/v1\nmetrics.k8s.io/v1beta1\nmonitoring.coreos.com/v1\nnetwork.openshift.io/v1\nnetworking.istio.io/v1alpha3\nnetworking.k8s.io/v1\noauth.openshift.io/v1\npolicy/v1beta1\nproject.openshift.io/v1\nquota.openshift.io/v1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nrbac.istio.io/v1alpha1\nroute.openshift.io/v1\nscheduling.k8s.io/v1beta1\nsecurity.openshift.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nstorage.spotahome.com/v1alpha2\ntemplate.openshift.io/v1\nuser.openshift.io/v1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:10:46.991: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hkxkm" for this suite.
Aug 28 11:10:55.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:10:55.761: INFO: namespace: e2e-tests-kubectl-hkxkm, resource: bindings, ignored listing per whitelist
Aug 28 11:10:58.114: INFO: namespace e2e-tests-kubectl-hkxkm deletion completed in 11.114226234s

• [SLOW TEST:11.898 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if v1 is in available api versions  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:10:58.114: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-2cmc4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-7510bf61-c941-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume secrets
Aug 28 11:10:58.752: INFO: Waiting up to 5m0s for pod "pod-secrets-75135eb8-c941-11e9-a0e2-288023b0a458" in namespace "e2e-tests-secrets-2cmc4" to be "success or failure"
Aug 28 11:10:58.760: INFO: Pod "pod-secrets-75135eb8-c941-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 7.259334ms
Aug 28 11:11:00.764: INFO: Pod "pod-secrets-75135eb8-c941-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011788358s
Aug 28 11:11:02.768: INFO: Pod "pod-secrets-75135eb8-c941-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015839327s
Aug 28 11:11:04.774: INFO: Pod "pod-secrets-75135eb8-c941-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021347097s
STEP: Saw pod success
Aug 28 11:11:04.774: INFO: Pod "pod-secrets-75135eb8-c941-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:11:04.778: INFO: Trying to get logs from node node-124 pod pod-secrets-75135eb8-c941-11e9-a0e2-288023b0a458 container secret-env-test: <nil>
STEP: delete the pod
Aug 28 11:11:04.811: INFO: Waiting for pod pod-secrets-75135eb8-c941-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:11:04.814: INFO: Pod pod-secrets-75135eb8-c941-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:11:04.814: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2cmc4" for this suite.
Aug 28 11:11:12.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:11:13.071: INFO: namespace: e2e-tests-secrets-2cmc4, resource: bindings, ignored listing per whitelist
Aug 28 11:11:15.944: INFO: namespace e2e-tests-secrets-2cmc4 deletion completed in 11.123965197s

• [SLOW TEST:17.830 seconds]
[sig-api-machinery] Secrets
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:11:15.944: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-vsjgn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-7fab61f7-c941-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume secrets
Aug 28 11:11:16.444: INFO: Waiting up to 5m0s for pod "pod-secrets-7fad315b-c941-11e9-a0e2-288023b0a458" in namespace "e2e-tests-secrets-vsjgn" to be "success or failure"
Aug 28 11:11:16.448: INFO: Pod "pod-secrets-7fad315b-c941-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.761293ms
Aug 28 11:11:18.453: INFO: Pod "pod-secrets-7fad315b-c941-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008752766s
Aug 28 11:11:20.716: INFO: Pod "pod-secrets-7fad315b-c941-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.271736101s
Aug 28 11:11:22.721: INFO: Pod "pod-secrets-7fad315b-c941-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.276709389s
STEP: Saw pod success
Aug 28 11:11:22.721: INFO: Pod "pod-secrets-7fad315b-c941-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:11:22.725: INFO: Trying to get logs from node node-124 pod pod-secrets-7fad315b-c941-11e9-a0e2-288023b0a458 container secret-volume-test: <nil>
STEP: delete the pod
Aug 28 11:11:22.761: INFO: Waiting for pod pod-secrets-7fad315b-c941-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:11:22.765: INFO: Pod pod-secrets-7fad315b-c941-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:11:22.765: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vsjgn" for this suite.
Aug 28 11:11:30.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:11:32.674: INFO: namespace: e2e-tests-secrets-vsjgn, resource: bindings, ignored listing per whitelist
Aug 28 11:11:33.874: INFO: namespace e2e-tests-secrets-vsjgn deletion completed in 11.102782052s

• [SLOW TEST:17.930 seconds]
[sig-storage] Secrets
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:11:33.874: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2sc24
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 11:11:34.266: INFO: Couldn't get node TTL annotation (using default value of 0): No TTL annotation found on the node
STEP: Creating configMap with name cm-test-opt-del-8a591942-c941-11e9-a0e2-288023b0a458
STEP: Creating configMap with name cm-test-opt-upd-8a5919dd-c941-11e9-a0e2-288023b0a458
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-8a591942-c941-11e9-a0e2-288023b0a458
STEP: Updating configmap cm-test-opt-upd-8a5919dd-c941-11e9-a0e2-288023b0a458
STEP: Creating configMap with name cm-test-opt-create-8a591a0c-c941-11e9-a0e2-288023b0a458
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:12:49.337: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2sc24" for this suite.
Aug 28 11:13:13.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:13:15.321: INFO: namespace: e2e-tests-configmap-2sc24, resource: bindings, ignored listing per whitelist
Aug 28 11:13:16.470: INFO: namespace e2e-tests-configmap-2sc24 deletion completed in 27.126406217s

• [SLOW TEST:102.596 seconds]
[sig-storage] ConfigMap
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:13:16.470: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-m55nz
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 11:13:16.930: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:13:18.234: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-m55nz" for this suite.
Aug 28 11:13:26.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:13:26.606: INFO: namespace: e2e-tests-custom-resource-definition-m55nz, resource: bindings, ignored listing per whitelist
Aug 28 11:13:29.430: INFO: namespace e2e-tests-custom-resource-definition-m55nz deletion completed in 11.187241576s

• [SLOW TEST:12.960 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:13:29.430: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2s6mj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl logs
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1053
STEP: creating an rc
Aug 28 11:13:29.924: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-2s6mj'
Aug 28 11:13:30.714: INFO: stderr: ""
Aug 28 11:13:30.714: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Waiting for Redis master to start.
Aug 28 11:13:31.721: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:13:31.721: INFO: Found 0 / 1
Aug 28 11:13:32.719: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:13:32.719: INFO: Found 0 / 1
Aug 28 11:13:33.720: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:13:33.720: INFO: Found 0 / 1
Aug 28 11:13:34.719: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:13:34.719: INFO: Found 0 / 1
Aug 28 11:13:35.719: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:13:35.719: INFO: Found 0 / 1
Aug 28 11:13:36.720: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:13:36.720: INFO: Found 1 / 1
Aug 28 11:13:36.720: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 28 11:13:36.724: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:13:36.724: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug 28 11:13:36.724: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config logs redis-master-fqmt8 redis-master --namespace=e2e-tests-kubectl-2s6mj'
Aug 28 11:13:37.158: INFO: stderr: ""
Aug 28 11:13:37.158: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 28 Aug 03:13:36.467 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 28 Aug 03:13:36.475 # Server started, Redis version 3.2.12\n1:M 28 Aug 03:13:36.475 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 28 Aug 03:13:36.475 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug 28 11:13:37.158: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config log redis-master-fqmt8 redis-master --namespace=e2e-tests-kubectl-2s6mj --tail=1'
Aug 28 11:13:37.643: INFO: stderr: ""
Aug 28 11:13:37.643: INFO: stdout: "1:M 28 Aug 03:13:36.475 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug 28 11:13:37.643: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config log redis-master-fqmt8 redis-master --namespace=e2e-tests-kubectl-2s6mj --limit-bytes=1'
Aug 28 11:13:38.123: INFO: stderr: ""
Aug 28 11:13:38.123: INFO: stdout: " "
STEP: exposing timestamps
Aug 28 11:13:38.123: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config log redis-master-fqmt8 redis-master --namespace=e2e-tests-kubectl-2s6mj --tail=1 --timestamps'
Aug 28 11:13:38.538: INFO: stderr: ""
Aug 28 11:13:38.538: INFO: stdout: "2019-08-28T03:13:36.475903375Z 1:M 28 Aug 03:13:36.475 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug 28 11:13:41.038: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config log redis-master-fqmt8 redis-master --namespace=e2e-tests-kubectl-2s6mj --since=1s'
Aug 28 11:13:41.479: INFO: stderr: ""
Aug 28 11:13:41.479: INFO: stdout: ""
Aug 28 11:13:41.479: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config log redis-master-fqmt8 redis-master --namespace=e2e-tests-kubectl-2s6mj --since=24h'
Aug 28 11:13:41.910: INFO: stderr: ""
Aug 28 11:13:41.910: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 28 Aug 03:13:36.467 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 28 Aug 03:13:36.475 # Server started, Redis version 3.2.12\n1:M 28 Aug 03:13:36.475 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 28 Aug 03:13:36.475 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1058
STEP: using delete to clean up resources
Aug 28 11:13:41.911: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2s6mj'
Aug 28 11:13:42.312: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 28 11:13:42.312: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug 28 11:13:42.312: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-2s6mj'
Aug 28 11:13:42.753: INFO: stderr: "No resources found.\n"
Aug 28 11:13:42.753: INFO: stdout: ""
Aug 28 11:13:42.754: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -l name=nginx --namespace=e2e-tests-kubectl-2s6mj -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 28 11:13:43.135: INFO: stderr: ""
Aug 28 11:13:43.135: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:13:43.135: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2s6mj" for this suite.
Aug 28 11:14:07.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:14:07.252: INFO: namespace: e2e-tests-kubectl-2s6mj, resource: bindings, ignored listing per whitelist
Aug 28 11:14:10.265: INFO: namespace e2e-tests-kubectl-2s6mj deletion completed in 27.123377019s

• [SLOW TEST:40.835 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should be able to retrieve and filter logs  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:14:10.266: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-zdnjd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override all
Aug 28 11:14:10.975: INFO: Waiting up to 5m0s for pod "client-containers-e7b28a8b-c941-11e9-a0e2-288023b0a458" in namespace "e2e-tests-containers-zdnjd" to be "success or failure"
Aug 28 11:14:11.005: INFO: Pod "client-containers-e7b28a8b-c941-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 29.749817ms
Aug 28 11:14:13.009: INFO: Pod "client-containers-e7b28a8b-c941-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03436049s
Aug 28 11:14:15.015: INFO: Pod "client-containers-e7b28a8b-c941-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039625603s
Aug 28 11:14:17.019: INFO: Pod "client-containers-e7b28a8b-c941-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044515435s
STEP: Saw pod success
Aug 28 11:14:17.020: INFO: Pod "client-containers-e7b28a8b-c941-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:14:17.023: INFO: Trying to get logs from node node-124 pod client-containers-e7b28a8b-c941-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 11:14:17.072: INFO: Waiting for pod client-containers-e7b28a8b-c941-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:14:17.076: INFO: Pod client-containers-e7b28a8b-c941-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:14:17.076: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-zdnjd" for this suite.
Aug 28 11:14:25.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:14:27.797: INFO: namespace: e2e-tests-containers-zdnjd, resource: bindings, ignored listing per whitelist
Aug 28 11:14:28.248: INFO: namespace e2e-tests-containers-zdnjd deletion completed in 11.164324148s

• [SLOW TEST:17.982 seconds]
[k8s.io] Docker Containers
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:14:28.248: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-5kc48
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test env composition
Aug 28 11:14:28.823: INFO: Waiting up to 5m0s for pod "var-expansion-f24954d6-c941-11e9-a0e2-288023b0a458" in namespace "e2e-tests-var-expansion-5kc48" to be "success or failure"
Aug 28 11:14:28.845: INFO: Pod "var-expansion-f24954d6-c941-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 22.201113ms
Aug 28 11:14:30.850: INFO: Pod "var-expansion-f24954d6-c941-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027071383s
Aug 28 11:14:32.908: INFO: Pod "var-expansion-f24954d6-c941-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.084797017s
Aug 28 11:14:34.912: INFO: Pod "var-expansion-f24954d6-c941-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.089175203s
Aug 28 11:14:36.917: INFO: Pod "var-expansion-f24954d6-c941-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.093979667s
STEP: Saw pod success
Aug 28 11:14:36.917: INFO: Pod "var-expansion-f24954d6-c941-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:14:36.921: INFO: Trying to get logs from node node-124 pod var-expansion-f24954d6-c941-11e9-a0e2-288023b0a458 container dapi-container: <nil>
STEP: delete the pod
Aug 28 11:14:36.952: INFO: Waiting for pod var-expansion-f24954d6-c941-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:14:36.956: INFO: Pod var-expansion-f24954d6-c941-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:14:36.956: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-5kc48" for this suite.
Aug 28 11:14:45.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:14:47.110: INFO: namespace: e2e-tests-var-expansion-5kc48, resource: bindings, ignored listing per whitelist
Aug 28 11:14:48.200: INFO: namespace e2e-tests-var-expansion-5kc48 deletion completed in 11.237108722s

• [SLOW TEST:19.952 seconds]
[k8s.io] Variable Expansion
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:14:48.200: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-bmvwj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be updated [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 28 11:14:55.286: INFO: Successfully updated pod "pod-update-fe32503f-c941-11e9-a0e2-288023b0a458"
STEP: verifying the updated pod is in kubernetes
Aug 28 11:14:55.294: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:14:55.294: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-bmvwj" for this suite.
Aug 28 11:15:19.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:15:19.568: INFO: namespace: e2e-tests-pods-bmvwj, resource: bindings, ignored listing per whitelist
Aug 28 11:15:22.406: INFO: namespace e2e-tests-pods-bmvwj deletion completed in 27.104840042s

• [SLOW TEST:34.206 seconds]
[k8s.io] Pods
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be updated [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:15:22.406: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-c98mc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-c98mc
Aug 28 11:15:28.978: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-c98mc
STEP: checking the pod's current state and verifying that restartCount is present
Aug 28 11:15:28.981: INFO: Initial restart count of pod liveness-http is 0
Aug 28 11:15:53.104: INFO: Restart count of pod e2e-tests-container-probe-c98mc/liveness-http is now 1 (24.12321346s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:15:53.133: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-c98mc" for this suite.
Aug 28 11:16:01.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:16:01.322: INFO: namespace: e2e-tests-container-probe-c98mc, resource: bindings, ignored listing per whitelist
Aug 28 11:16:04.243: INFO: namespace e2e-tests-container-probe-c98mc deletion completed in 11.101469479s

• [SLOW TEST:41.837 seconds]
[k8s.io] Probing container
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:16:04.243: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-clm6g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-2b88c6a6-c942-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 11:16:04.803: INFO: Waiting up to 5m0s for pod "pod-configmaps-2b8f6a62-c942-11e9-a0e2-288023b0a458" in namespace "e2e-tests-configmap-clm6g" to be "success or failure"
Aug 28 11:16:04.824: INFO: Pod "pod-configmaps-2b8f6a62-c942-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 20.776508ms
Aug 28 11:16:06.829: INFO: Pod "pod-configmaps-2b8f6a62-c942-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025650832s
Aug 28 11:16:08.833: INFO: Pod "pod-configmaps-2b8f6a62-c942-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029726669s
Aug 28 11:16:10.837: INFO: Pod "pod-configmaps-2b8f6a62-c942-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034560303s
STEP: Saw pod success
Aug 28 11:16:10.838: INFO: Pod "pod-configmaps-2b8f6a62-c942-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:16:10.841: INFO: Trying to get logs from node node-124 pod pod-configmaps-2b8f6a62-c942-11e9-a0e2-288023b0a458 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 28 11:16:10.884: INFO: Waiting for pod pod-configmaps-2b8f6a62-c942-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:16:10.887: INFO: Pod pod-configmaps-2b8f6a62-c942-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:16:10.887: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-clm6g" for this suite.
Aug 28 11:16:18.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:16:19.686: INFO: namespace: e2e-tests-configmap-clm6g, resource: bindings, ignored listing per whitelist
Aug 28 11:16:22.036: INFO: namespace e2e-tests-configmap-clm6g deletion completed in 11.142123164s

• [SLOW TEST:17.793 seconds]
[sig-storage] ConfigMap
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:16:22.036: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-6zc26
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-3621dfa7-c942-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 11:16:22.622: INFO: Waiting up to 5m0s for pod "pod-configmaps-36247850-c942-11e9-a0e2-288023b0a458" in namespace "e2e-tests-configmap-6zc26" to be "success or failure"
Aug 28 11:16:22.665: INFO: Pod "pod-configmaps-36247850-c942-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 42.514472ms
Aug 28 11:16:24.671: INFO: Pod "pod-configmaps-36247850-c942-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048017804s
Aug 28 11:16:26.675: INFO: Pod "pod-configmaps-36247850-c942-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052833671s
Aug 28 11:16:28.681: INFO: Pod "pod-configmaps-36247850-c942-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.058435374s
Aug 28 11:16:30.686: INFO: Pod "pod-configmaps-36247850-c942-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.063572028s
STEP: Saw pod success
Aug 28 11:16:30.686: INFO: Pod "pod-configmaps-36247850-c942-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:16:30.690: INFO: Trying to get logs from node node-124 pod pod-configmaps-36247850-c942-11e9-a0e2-288023b0a458 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 28 11:16:30.769: INFO: Waiting for pod pod-configmaps-36247850-c942-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:16:30.773: INFO: Pod pod-configmaps-36247850-c942-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:16:30.773: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6zc26" for this suite.
Aug 28 11:16:38.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:16:39.167: INFO: namespace: e2e-tests-configmap-6zc26, resource: bindings, ignored listing per whitelist
Aug 28 11:16:41.901: INFO: namespace e2e-tests-configmap-6zc26 deletion completed in 11.120660633s

• [SLOW TEST:19.865 seconds]
[sig-storage] ConfigMap
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:16:41.901: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-wcjdr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 11:16:42.964: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"424fc837-c942-11e9-bbca-288023b0a1ec", Controller:(*bool)(0xc42163ba3a), BlockOwnerDeletion:(*bool)(0xc42163ba3b)}}
Aug 28 11:16:42.985: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"4242a742-c942-11e9-bbca-288023b0a1ec", Controller:(*bool)(0xc422c1952a), BlockOwnerDeletion:(*bool)(0xc422c1952b)}}
Aug 28 11:16:43.020: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"4249ab4d-c942-11e9-bbca-288023b0a1ec", Controller:(*bool)(0xc421e7ae72), BlockOwnerDeletion:(*bool)(0xc421e7ae73)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:16:48.036: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-wcjdr" for this suite.
Aug 28 11:16:56.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:16:56.178: INFO: namespace: e2e-tests-gc-wcjdr, resource: bindings, ignored listing per whitelist
Aug 28 11:16:59.160: INFO: namespace e2e-tests-gc-wcjdr deletion completed in 11.116591314s

• [SLOW TEST:17.259 seconds]
[sig-api-machinery] Garbage collector
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:16:59.160: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-z7spc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-z7spc
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 28 11:16:59.592: INFO: Waiting up to 10m0s for all (but 3) nodes to be schedulable
STEP: Creating test pods
Aug 28 11:17:30.059: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.1.42 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-z7spc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 11:17:30.059: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 11:17:31.262: INFO: Found all expected endpoints: [netserver-0]
Aug 28 11:17:31.266: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.245.0.74 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-z7spc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 11:17:31.266: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 11:17:32.470: INFO: Found all expected endpoints: [netserver-1]
Aug 28 11:17:32.480: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.243.1.82 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-z7spc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 28 11:17:32.480: INFO: >>> kubeConfig: /root/.kube/config
Aug 28 11:17:33.624: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:17:33.624: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-z7spc" for this suite.
Aug 28 11:17:57.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:17:57.736: INFO: namespace: e2e-tests-pod-network-test-z7spc, resource: bindings, ignored listing per whitelist
Aug 28 11:18:00.722: INFO: namespace e2e-tests-pod-network-test-z7spc deletion completed in 27.090134616s

• [SLOW TEST:61.562 seconds]
[sig-network] Networking
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:18:00.723: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-qwbfb
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 11:18:01.190: INFO: Couldn't get node TTL annotation (using default value of 0): No TTL annotation found on the node
STEP: Creating configMap with name configmap-test-upd-70f8fe3c-c942-11e9-a0e2-288023b0a458
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-70f8fe3c-c942-11e9-a0e2-288023b0a458
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:19:12.209: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qwbfb" for this suite.
Aug 28 11:19:36.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:19:36.271: INFO: namespace: e2e-tests-configmap-qwbfb, resource: bindings, ignored listing per whitelist
Aug 28 11:19:39.339: INFO: namespace e2e-tests-configmap-qwbfb deletion completed in 27.123893786s

• [SLOW TEST:98.616 seconds]
[sig-storage] ConfigMap
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:19:39.339: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-vl8tg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:199
[It] should be submitted and removed  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:19:39.852: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vl8tg" for this suite.
Aug 28 11:21:53.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:21:54.585: INFO: namespace: e2e-tests-pods-vl8tg, resource: bindings, ignored listing per whitelist
Aug 28 11:21:57.037: INFO: namespace e2e-tests-pods-vl8tg deletion completed in 2m17.167592048s

• [SLOW TEST:137.698 seconds]
[k8s.io] [sig-node] Pods Extended
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  [k8s.io] Pods Set QOS Class
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should be submitted and removed  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] ReplicationController
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:21:57.037: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-2lxnm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating replication controller my-hostname-basic-fdd6532d-c942-11e9-a0e2-288023b0a458
Aug 28 11:21:57.546: INFO: Pod name my-hostname-basic-fdd6532d-c942-11e9-a0e2-288023b0a458: Found 0 pods out of 1
Aug 28 11:22:02.551: INFO: Pod name my-hostname-basic-fdd6532d-c942-11e9-a0e2-288023b0a458: Found 1 pods out of 1
Aug 28 11:22:02.551: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-fdd6532d-c942-11e9-a0e2-288023b0a458" are running
Aug 28 11:22:04.559: INFO: Pod "my-hostname-basic-fdd6532d-c942-11e9-a0e2-288023b0a458-hqh5h" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-28 11:21:57 +0800 CST Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-28 11:21:57 +0800 CST Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-fdd6532d-c942-11e9-a0e2-288023b0a458]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-fdd6532d-c942-11e9-a0e2-288023b0a458]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-28 11:21:57 +0800 CST Reason: Message:}])
Aug 28 11:22:04.559: INFO: Trying to dial the pod
Aug 28 11:22:09.605: INFO: Controller my-hostname-basic-fdd6532d-c942-11e9-a0e2-288023b0a458: Got expected result from replica 1 [my-hostname-basic-fdd6532d-c942-11e9-a0e2-288023b0a458-hqh5h]: "my-hostname-basic-fdd6532d-c942-11e9-a0e2-288023b0a458-hqh5h", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:22:09.605: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-2lxnm" for this suite.
Aug 28 11:22:17.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:22:17.812: INFO: namespace: e2e-tests-replication-controller-2lxnm, resource: bindings, ignored listing per whitelist
Aug 28 11:22:20.714: INFO: namespace e2e-tests-replication-controller-2lxnm deletion completed in 11.101420798s

• [SLOW TEST:23.677 seconds]
[sig-apps] ReplicationController
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:22:20.714: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-vl57s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 11:22:21.230: INFO: (0) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.763357ms)
Aug 28 11:22:21.235: INFO: (1) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.577257ms)
Aug 28 11:22:21.242: INFO: (2) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.229318ms)
Aug 28 11:22:21.276: INFO: (3) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 34.295651ms)
Aug 28 11:22:21.293: INFO: (4) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 17.421216ms)
Aug 28 11:22:21.301: INFO: (5) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.076278ms)
Aug 28 11:22:21.306: INFO: (6) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.432022ms)
Aug 28 11:22:21.312: INFO: (7) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.73253ms)
Aug 28 11:22:21.318: INFO: (8) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.722525ms)
Aug 28 11:22:21.324: INFO: (9) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.123105ms)
Aug 28 11:22:21.348: INFO: (10) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 23.922078ms)
Aug 28 11:22:21.353: INFO: (11) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.438937ms)
Aug 28 11:22:21.359: INFO: (12) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.628056ms)
Aug 28 11:22:21.393: INFO: (13) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 34.093251ms)
Aug 28 11:22:21.401: INFO: (14) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.444157ms)
Aug 28 11:22:21.406: INFO: (15) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.475643ms)
Aug 28 11:22:21.412: INFO: (16) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.759481ms)
Aug 28 11:22:21.417: INFO: (17) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.296292ms)
Aug 28 11:22:21.428: INFO: (18) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.725438ms)
Aug 28 11:22:21.433: INFO: (19) /api/v1/nodes/node-124:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.193116ms)
[AfterEach] version v1
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:22:21.433: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-vl57s" for this suite.
Aug 28 11:22:29.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:22:30.443: INFO: namespace: e2e-tests-proxy-vl57s, resource: bindings, ignored listing per whitelist
Aug 28 11:22:30.525: INFO: namespace e2e-tests-proxy-vl57s deletion completed in 9.085718954s

• [SLOW TEST:9.811 seconds]
[sig-network] Proxy
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:22:30.525: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xgfvf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 11:22:31.039: INFO: Waiting up to 5m0s for pod "downwardapi-volume-11bcce51-c943-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-xgfvf" to be "success or failure"
Aug 28 11:22:31.064: INFO: Pod "downwardapi-volume-11bcce51-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 25.006803ms
Aug 28 11:22:33.070: INFO: Pod "downwardapi-volume-11bcce51-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030682384s
Aug 28 11:22:35.075: INFO: Pod "downwardapi-volume-11bcce51-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036098655s
Aug 28 11:22:37.080: INFO: Pod "downwardapi-volume-11bcce51-c943-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040620238s
STEP: Saw pod success
Aug 28 11:22:37.080: INFO: Pod "downwardapi-volume-11bcce51-c943-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:22:37.084: INFO: Trying to get logs from node node-124 pod downwardapi-volume-11bcce51-c943-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 11:22:37.175: INFO: Waiting for pod downwardapi-volume-11bcce51-c943-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:22:37.179: INFO: Pod downwardapi-volume-11bcce51-c943-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:22:37.179: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xgfvf" for this suite.
Aug 28 11:22:45.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:22:47.689: INFO: namespace: e2e-tests-projected-xgfvf, resource: bindings, ignored listing per whitelist
Aug 28 11:22:48.289: INFO: namespace e2e-tests-projected-xgfvf deletion completed in 11.103147351s

• [SLOW TEST:17.763 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:22:48.289: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-zvdbw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-zvdbw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zvdbw to expose endpoints map[]
Aug 28 11:22:48.692: INFO: Get endpoints failed (4.195695ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Aug 28 11:22:49.696: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zvdbw exposes endpoints map[] (1.008509929s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-zvdbw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zvdbw to expose endpoints map[pod1:[100]]
Aug 28 11:22:53.812: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.082314807s elapsed, will retry)
Aug 28 11:22:55.836: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zvdbw exposes endpoints map[pod1:[100]] (6.106334512s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-zvdbw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zvdbw to expose endpoints map[pod1:[100] pod2:[101]]
Aug 28 11:22:59.927: INFO: Unexpected endpoints: found map[1cf28021-c943-11e9-bbca-288023b0a1ec:[100]], expected map[pod2:[101] pod1:[100]] (4.064734542s elapsed, will retry)
Aug 28 11:23:01.991: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zvdbw exposes endpoints map[pod1:[100] pod2:[101]] (6.128199497s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-zvdbw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zvdbw to expose endpoints map[pod2:[101]]
Aug 28 11:23:03.023: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zvdbw exposes endpoints map[pod2:[101]] (1.018193932s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-zvdbw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zvdbw to expose endpoints map[]
Aug 28 11:23:04.043: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zvdbw exposes endpoints map[] (1.00812808s elapsed)
[AfterEach] [sig-network] Services
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:23:04.121: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-zvdbw" for this suite.
Aug 28 11:23:28.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:23:29.563: INFO: namespace: e2e-tests-services-zvdbw, resource: bindings, ignored listing per whitelist
Aug 28 11:23:31.214: INFO: namespace e2e-tests-services-zvdbw deletion completed in 27.085655867s
[AfterEach] [sig-network] Services
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:42.925 seconds]
[sig-network] Services
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:23:31.214: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5kgh7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-35f298be-c943-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume secrets
Aug 28 11:23:31.796: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-35f44f1a-c943-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-5kgh7" to be "success or failure"
Aug 28 11:23:31.849: INFO: Pod "pod-projected-secrets-35f44f1a-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 52.61002ms
Aug 28 11:23:33.853: INFO: Pod "pod-projected-secrets-35f44f1a-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057038261s
Aug 28 11:23:35.858: INFO: Pod "pod-projected-secrets-35f44f1a-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.061966518s
Aug 28 11:23:37.863: INFO: Pod "pod-projected-secrets-35f44f1a-c943-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.066409196s
STEP: Saw pod success
Aug 28 11:23:37.863: INFO: Pod "pod-projected-secrets-35f44f1a-c943-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:23:37.866: INFO: Trying to get logs from node node-124 pod pod-projected-secrets-35f44f1a-c943-11e9-a0e2-288023b0a458 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 28 11:23:37.897: INFO: Waiting for pod pod-projected-secrets-35f44f1a-c943-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:23:37.900: INFO: Pod pod-projected-secrets-35f44f1a-c943-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:23:37.900: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5kgh7" for this suite.
Aug 28 11:23:45.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:23:47.949: INFO: namespace: e2e-tests-projected-5kgh7, resource: bindings, ignored listing per whitelist
Aug 28 11:23:49.027: INFO: namespace e2e-tests-projected-5kgh7 deletion completed in 11.121161132s

• [SLOW TEST:17.813 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:23:49.028: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gfg9g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-4094d659-c943-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 11:23:49.616: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-409dbd05-c943-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-gfg9g" to be "success or failure"
Aug 28 11:23:49.620: INFO: Pod "pod-projected-configmaps-409dbd05-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.097665ms
Aug 28 11:23:51.624: INFO: Pod "pod-projected-configmaps-409dbd05-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008415986s
Aug 28 11:23:53.629: INFO: Pod "pod-projected-configmaps-409dbd05-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013325254s
Aug 28 11:23:55.634: INFO: Pod "pod-projected-configmaps-409dbd05-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017728834s
Aug 28 11:23:57.638: INFO: Pod "pod-projected-configmaps-409dbd05-c943-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.022623121s
STEP: Saw pod success
Aug 28 11:23:57.639: INFO: Pod "pod-projected-configmaps-409dbd05-c943-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:23:57.642: INFO: Trying to get logs from node node-124 pod pod-projected-configmaps-409dbd05-c943-11e9-a0e2-288023b0a458 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 28 11:23:57.704: INFO: Waiting for pod pod-projected-configmaps-409dbd05-c943-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:23:57.708: INFO: Pod pod-projected-configmaps-409dbd05-c943-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:23:57.708: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gfg9g" for this suite.
Aug 28 11:24:05.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:24:05.847: INFO: namespace: e2e-tests-projected-gfg9g, resource: bindings, ignored listing per whitelist
Aug 28 11:24:08.843: INFO: namespace e2e-tests-projected-gfg9g deletion completed in 11.127443114s

• [SLOW TEST:19.815 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:24:08.843: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-28g7k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-4c6120f2-c943-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume secrets
Aug 28 11:24:09.336: INFO: Waiting up to 5m0s for pod "pod-secrets-4c63d42e-c943-11e9-a0e2-288023b0a458" in namespace "e2e-tests-secrets-28g7k" to be "success or failure"
Aug 28 11:24:09.339: INFO: Pod "pod-secrets-4c63d42e-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.601444ms
Aug 28 11:24:11.344: INFO: Pod "pod-secrets-4c63d42e-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008086978s
Aug 28 11:24:13.349: INFO: Pod "pod-secrets-4c63d42e-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01278896s
Aug 28 11:24:15.391: INFO: Pod "pod-secrets-4c63d42e-c943-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.054864314s
STEP: Saw pod success
Aug 28 11:24:15.391: INFO: Pod "pod-secrets-4c63d42e-c943-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:24:15.399: INFO: Trying to get logs from node node-124 pod pod-secrets-4c63d42e-c943-11e9-a0e2-288023b0a458 container secret-volume-test: <nil>
STEP: delete the pod
Aug 28 11:24:15.431: INFO: Waiting for pod pod-secrets-4c63d42e-c943-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:24:15.434: INFO: Pod pod-secrets-4c63d42e-c943-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Secrets
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:24:15.434: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-28g7k" for this suite.
Aug 28 11:24:23.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:24:26.506: INFO: namespace: e2e-tests-secrets-28g7k, resource: bindings, ignored listing per whitelist
Aug 28 11:24:26.555: INFO: namespace e2e-tests-secrets-28g7k deletion completed in 11.114697213s

• [SLOW TEST:17.713 seconds]
[sig-storage] Secrets
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:24:26.556: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-7hxfs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-7hxfs
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a new StaefulSet
Aug 28 11:24:27.138: INFO: Found 0 stateful pods, waiting for 3
Aug 28 11:24:37.148: INFO: Found 2 stateful pods, waiting for 3
Aug 28 11:24:47.146: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 11:24:47.146: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 11:24:47.146: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
Aug 28 11:24:47.185: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 28 11:24:57.269: INFO: Updating stateful set ss2
Aug 28 11:24:57.278: INFO: Waiting for Pod e2e-tests-statefulset-7hxfs/ss2-2 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
STEP: Restoring Pods to the correct revision when they are deleted
Aug 28 11:25:07.412: INFO: Found 1 stateful pods, waiting for 3
Aug 28 11:25:17.426: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 11:25:17.426: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 11:25:17.426: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Aug 28 11:25:27.417: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 11:25:27.417: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 28 11:25:27.417: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 28 11:25:27.452: INFO: Updating stateful set ss2
Aug 28 11:25:27.512: INFO: Waiting for Pod e2e-tests-statefulset-7hxfs/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Aug 28 11:25:37.549: INFO: Updating stateful set ss2
Aug 28 11:25:37.615: INFO: Waiting for StatefulSet e2e-tests-statefulset-7hxfs/ss2 to complete update
Aug 28 11:25:37.615: INFO: Waiting for Pod e2e-tests-statefulset-7hxfs/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Aug 28 11:25:47.624: INFO: Waiting for StatefulSet e2e-tests-statefulset-7hxfs/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Aug 28 11:25:57.828: INFO: Deleting all statefulset in ns e2e-tests-statefulset-7hxfs
Aug 28 11:25:57.916: INFO: Scaling statefulset ss2 to 0
Aug 28 11:26:27.962: INFO: Waiting for statefulset status.replicas updated to 0
Aug 28 11:26:27.966: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:26:27.994: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-7hxfs" for this suite.
Aug 28 11:26:36.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:26:36.214: INFO: namespace: e2e-tests-statefulset-7hxfs, resource: bindings, ignored listing per whitelist
Aug 28 11:26:39.155: INFO: namespace e2e-tests-statefulset-7hxfs deletion completed in 11.14527324s

• [SLOW TEST:132.600 seconds]
[sig-apps] StatefulSet
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:26:39.156: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7d965
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 11:26:39.656: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a5f47665-c943-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-7d965" to be "success or failure"
Aug 28 11:26:39.660: INFO: Pod "downwardapi-volume-a5f47665-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.944611ms
Aug 28 11:26:41.666: INFO: Pod "downwardapi-volume-a5f47665-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009785096s
Aug 28 11:26:43.672: INFO: Pod "downwardapi-volume-a5f47665-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015503925s
Aug 28 11:26:45.676: INFO: Pod "downwardapi-volume-a5f47665-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019826267s
Aug 28 11:26:47.680: INFO: Pod "downwardapi-volume-a5f47665-c943-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.023866406s
STEP: Saw pod success
Aug 28 11:26:47.680: INFO: Pod "downwardapi-volume-a5f47665-c943-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:26:47.684: INFO: Trying to get logs from node node-124 pod downwardapi-volume-a5f47665-c943-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 11:26:47.729: INFO: Waiting for pod downwardapi-volume-a5f47665-c943-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:26:47.733: INFO: Pod downwardapi-volume-a5f47665-c943-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:26:47.733: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7d965" for this suite.
Aug 28 11:26:55.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:26:56.983: INFO: namespace: e2e-tests-projected-7d965, resource: bindings, ignored listing per whitelist
Aug 28 11:26:58.888: INFO: namespace e2e-tests-projected-7d965 deletion completed in 11.148473783s

• [SLOW TEST:19.732 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:26:58.888: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-f8cf8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 28 11:26:59.376: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 28 11:27:59.465: INFO: Waiting for terminating namespaces to be deleted...
Aug 28 11:27:59.473: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 28 11:27:59.485: INFO: 10 / 10 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 28 11:27:59.485: INFO: expected 1 pod replicas in namespace 'kube-system', 1 are Running and Ready.
Aug 28 11:27:59.489: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Aug 28 11:27:59.489: INFO: 
Logging pods the kubelet thinks is on node node-124 before test
Aug 28 11:27:59.501: INFO: os-log-daemonset-7rwz8 from default started at 2019-08-25 20:22:06 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.501: INFO: 	Container oslogmgt ready: true, restart count 0
Aug 28 11:27:59.501: INFO: os-prometheus-prometheus-node-exporter-bhts2 from prometheus-monitoring started at 2019-08-15 14:58:55 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.501: INFO: 	Container node-exporter ready: true, restart count 3
Aug 28 11:27:59.501: INFO: os-weave-scope-agent-grsw6 from default started at 2019-08-15 14:03:49 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.501: INFO: 	Container scope-agent ready: true, restart count 1
Aug 28 11:27:59.501: INFO: sync-b5rks from openshift-node started at 2019-08-15 14:57:23 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.501: INFO: 	Container sync ready: true, restart count 1
Aug 28 11:27:59.501: INFO: ovs-wbrm7 from openshift-sdn started at 2019-08-15 14:03:49 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.501: INFO: 	Container openvswitch ready: true, restart count 1
Aug 28 11:27:59.501: INFO: sdn-bptkv from openshift-sdn started at 2019-08-15 14:03:49 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.501: INFO: 	Container sdn ready: true, restart count 1
Aug 28 11:27:59.501: INFO: 
Logging pods the kubelet thinks is on node node-128 before test
Aug 28 11:27:59.527: INFO: sync-pbcjr from openshift-node started at 2019-08-15 14:57:23 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container sync ready: true, restart count 1
Aug 28 11:27:59.527: INFO: milk-user-server-55c7c9bc48-qx9vh from space2940252d started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container user-server ready: true, restart count 0
Aug 28 11:27:59.527: INFO: database-server-86c6c767b8-dtnf9 from space2940252d started at 2019-08-15 15:49:51 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container database-server ready: true, restart count 1
Aug 28 11:27:59.527: INFO: istio-telemetry-648598656c-rx95s from cloudos-mesh started at 2019-08-27 15:45:55 +0800 CST (2 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 11:27:59.527: INFO: 	Container mixer ready: true, restart count 10
Aug 28 11:27:59.527: INFO: os-weave-scope-agent-dh6qh from default started at 2019-08-15 14:16:07 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container scope-agent ready: true, restart count 1
Aug 28 11:27:59.527: INFO: milk-warehouse-server-667f499dbb-vbptx from space80d22279 started at 2019-08-27 16:49:36 +0800 CST (2 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 11:27:59.527: INFO: 	Container warehouse-server ready: true, restart count 0
Aug 28 11:27:59.527: INFO: front-server-c6d86d655-qknsn from space2940252d started at 2019-08-15 15:49:51 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container front-server ready: true, restart count 2
Aug 28 11:27:59.527: INFO: milk-order-server-6557776f4c-mnb25 from space2940252d started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container order-server ready: true, restart count 0
Aug 28 11:27:59.527: INFO: os-prometheus-prometheus-node-exporter-j5r86 from prometheus-monitoring started at 2019-08-15 14:59:26 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container node-exporter ready: true, restart count 72
Aug 28 11:27:59.527: INFO: milk-order-server-6557776f4c-27rlx from space80d22279 started at 2019-08-15 15:47:24 +0800 CST (2 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container istio-proxy ready: true, restart count 1
Aug 28 11:27:59.527: INFO: 	Container order-server ready: true, restart count 2
Aug 28 11:27:59.527: INFO: milk-warehouse-server-667f499dbb-6jd9h from space2940252d started at 2019-08-15 15:49:51 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container warehouse-server ready: true, restart count 2
Aug 28 11:27:59.527: INFO: ovs-78jnp from openshift-sdn started at 2019-08-15 14:16:07 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container openvswitch ready: true, restart count 1
Aug 28 11:27:59.527: INFO: os-log-daemonset-x56ph from default started at 2019-08-15 14:16:07 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container oslogmgt ready: true, restart count 1
Aug 28 11:27:59.527: INFO: sdn-gszh2 from openshift-sdn started at 2019-08-15 14:16:07 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container sdn ready: true, restart count 1
Aug 28 11:27:59.527: INFO: database-server-86c6c767b8-gc4nr from space80d22279 started at 2019-08-15 15:47:25 +0800 CST (2 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container database-server ready: true, restart count 2
Aug 28 11:27:59.527: INFO: 	Container istio-proxy ready: true, restart count 1
Aug 28 11:27:59.527: INFO: milk-brands-server-569d5bb9fc-f69dc from space2940252d started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container brands-server ready: true, restart count 0
Aug 28 11:27:59.527: INFO: front-server-c6d86d655-wzhpp from space80d22279 started at 2019-08-15 15:47:25 +0800 CST (2 container statuses recorded)
Aug 28 11:27:59.527: INFO: 	Container front-server ready: true, restart count 2
Aug 28 11:27:59.527: INFO: 	Container istio-proxy ready: true, restart count 1
Aug 28 11:27:59.527: INFO: 
Logging pods the kubelet thinks is on node node-137 before test
Aug 28 11:27:59.557: INFO: milk-user-server-55c7c9bc48-2dzp5 from space80d22279 started at 2019-08-27 16:49:36 +0800 CST (2 container statuses recorded)
Aug 28 11:27:59.557: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 11:27:59.557: INFO: 	Container user-server ready: true, restart count 0
Aug 28 11:27:59.557: INFO: os-weave-scope-agent-9h5l2 from default started at 2019-08-15 14:29:56 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.557: INFO: 	Container scope-agent ready: true, restart count 1
Aug 28 11:27:59.557: INFO: os-log-daemonset-wcd7s from default started at 2019-08-15 14:29:56 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.557: INFO: 	Container oslogmgt ready: true, restart count 1
Aug 28 11:27:59.557: INFO: database-server-86c6c767b8-7n4hn from space80d22279 started at 2019-08-27 16:49:36 +0800 CST (2 container statuses recorded)
Aug 28 11:27:59.557: INFO: 	Container database-server ready: true, restart count 0
Aug 28 11:27:59.557: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 11:27:59.557: INFO: sync-4l8lz from openshift-node started at 2019-08-15 14:57:27 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.557: INFO: 	Container sync ready: true, restart count 1
Aug 28 11:27:59.557: INFO: milk-brands-server-569d5bb9fc-d5fg7 from space80d22279 started at 2019-08-26 15:22:38 +0800 CST (2 container statuses recorded)
Aug 28 11:27:59.557: INFO: 	Container brands-server ready: true, restart count 0
Aug 28 11:27:59.557: INFO: 	Container istio-proxy ready: true, restart count 0
Aug 28 11:27:59.557: INFO: redisoperator-d96dc9d-ljrtt from default started at 2019-08-25 20:18:14 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.557: INFO: 	Container operator ready: true, restart count 0
Aug 28 11:27:59.557: INFO: os-prometheus-kube-state-metrics-9d46ff684-gl2g8 from prometheus-monitoring started at 2019-08-25 20:19:09 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.557: INFO: 	Container kube-state-metrics ready: true, restart count 0
Aug 28 11:27:59.557: INFO: istio-policy-68879ddc88-rv7wl from cloudos-mesh started at 2019-08-15 14:36:43 +0800 CST (2 container statuses recorded)
Aug 28 11:27:59.557: INFO: 	Container istio-proxy ready: true, restart count 1
Aug 28 11:27:59.557: INFO: 	Container mixer ready: true, restart count 287
Aug 28 11:27:59.557: INFO: os-prometheus-prometheus-node-exporter-mvf5c from prometheus-monitoring started at 2019-08-15 15:00:11 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.557: INFO: 	Container node-exporter ready: true, restart count 4
Aug 28 11:27:59.557: INFO: metrics-server-57ff6c6465-dccxw from openshift-metrics-server started at 2019-08-25 20:18:15 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.557: INFO: 	Container metrics-server ready: true, restart count 0
Aug 28 11:27:59.557: INFO: database-server-86c6c767b8-k8d4s from space2940252d started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.557: INFO: 	Container database-server ready: true, restart count 0
Aug 28 11:27:59.557: INFO: sdn-fzp9m from openshift-sdn started at 2019-08-15 14:29:56 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.557: INFO: 	Container sdn ready: true, restart count 1
Aug 28 11:27:59.557: INFO: fortiotest-7f4b6c6dbc-wtnxn from space58e14a82 started at 2019-08-27 16:49:36 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.558: INFO: 	Container fortiotest ready: true, restart count 0
Aug 28 11:27:59.558: INFO: os-weave-scope-app-67464966f6-xqkp8 from default started at 2019-08-25 20:20:27 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.558: INFO: 	Container app ready: true, restart count 0
Aug 28 11:27:59.558: INFO: ovs-t6trh from openshift-sdn started at 2019-08-15 14:29:55 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.558: INFO: 	Container openvswitch ready: true, restart count 1
Aug 28 11:27:59.558: INFO: heapster-s76t8 from openshift-infra started at 2019-08-25 20:20:30 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.558: INFO: 	Container heapster ready: true, restart count 0
Aug 28 11:27:59.558: INFO: redis-proxy-76ff84c585-d2wwt from default started at 2019-08-25 20:18:14 +0800 CST (1 container statuses recorded)
Aug 28 11:27:59.558: INFO: 	Container haproxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-d940cbe5-c943-11e9-a0e2-288023b0a458 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-d940cbe5-c943-11e9-a0e2-288023b0a458 off the node node-124
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d940cbe5-c943-11e9-a0e2-288023b0a458
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:28:11.777: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-f8cf8" for this suite.
Aug 28 11:28:35.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:28:38.727: INFO: namespace: e2e-tests-sched-pred-f8cf8, resource: bindings, ignored listing per whitelist
Aug 28 11:28:38.872: INFO: namespace e2e-tests-sched-pred-f8cf8 deletion completed in 27.089173283s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:99.984 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:28:38.873: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-tvrvs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test substitution in container's command
Aug 28 11:28:39.530: INFO: Waiting up to 5m0s for pod "var-expansion-ed48c583-c943-11e9-a0e2-288023b0a458" in namespace "e2e-tests-var-expansion-tvrvs" to be "success or failure"
Aug 28 11:28:39.534: INFO: Pod "var-expansion-ed48c583-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.253118ms
Aug 28 11:28:41.538: INFO: Pod "var-expansion-ed48c583-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008684296s
Aug 28 11:28:43.543: INFO: Pod "var-expansion-ed48c583-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013385006s
Aug 28 11:28:45.547: INFO: Pod "var-expansion-ed48c583-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017797539s
Aug 28 11:28:47.614: INFO: Pod "var-expansion-ed48c583-c943-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.08431263s
STEP: Saw pod success
Aug 28 11:28:47.614: INFO: Pod "var-expansion-ed48c583-c943-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:28:47.618: INFO: Trying to get logs from node node-124 pod var-expansion-ed48c583-c943-11e9-a0e2-288023b0a458 container dapi-container: <nil>
STEP: delete the pod
Aug 28 11:28:47.654: INFO: Waiting for pod var-expansion-ed48c583-c943-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:28:47.658: INFO: Pod var-expansion-ed48c583-c943-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:28:47.658: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-tvrvs" for this suite.
Aug 28 11:28:55.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:28:56.001: INFO: namespace: e2e-tests-var-expansion-tvrvs, resource: bindings, ignored listing per whitelist
Aug 28 11:28:58.753: INFO: namespace e2e-tests-var-expansion-tvrvs deletion completed in 11.08838616s

• [SLOW TEST:19.880 seconds]
[k8s.io] Variable Expansion
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:28:58.753: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-vw976
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test substitution in container's args
Aug 28 11:28:59.444: INFO: Waiting up to 5m0s for pod "var-expansion-f93162ed-c943-11e9-a0e2-288023b0a458" in namespace "e2e-tests-var-expansion-vw976" to be "success or failure"
Aug 28 11:28:59.447: INFO: Pod "var-expansion-f93162ed-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.568441ms
Aug 28 11:29:01.452: INFO: Pod "var-expansion-f93162ed-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008148053s
Aug 28 11:29:03.457: INFO: Pod "var-expansion-f93162ed-c943-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013012292s
Aug 28 11:29:05.508: INFO: Pod "var-expansion-f93162ed-c943-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.064936877s
STEP: Saw pod success
Aug 28 11:29:05.509: INFO: Pod "var-expansion-f93162ed-c943-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:29:05.512: INFO: Trying to get logs from node node-124 pod var-expansion-f93162ed-c943-11e9-a0e2-288023b0a458 container dapi-container: <nil>
STEP: delete the pod
Aug 28 11:29:05.560: INFO: Waiting for pod var-expansion-f93162ed-c943-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:29:05.564: INFO: Pod var-expansion-f93162ed-c943-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:29:05.564: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-vw976" for this suite.
Aug 28 11:29:13.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:29:14.963: INFO: namespace: e2e-tests-var-expansion-vw976, resource: bindings, ignored listing per whitelist
Aug 28 11:29:16.713: INFO: namespace e2e-tests-var-expansion-vw976 deletion completed in 11.143707207s

• [SLOW TEST:17.961 seconds]
[k8s.io] Variable Expansion
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:29:16.714: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wmh8c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should scale a replication controller  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a replication controller
Aug 28 11:29:17.119: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:17.803: INFO: stderr: ""
Aug 28 11:29:17.803: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 28 11:29:17.803: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:18.244: INFO: stderr: ""
Aug 28 11:29:18.244: INFO: stdout: "update-demo-nautilus-8c967 update-demo-nautilus-z8qfc "
Aug 28 11:29:18.244: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-8c967 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:18.643: INFO: stderr: ""
Aug 28 11:29:18.643: INFO: stdout: ""
Aug 28 11:29:18.643: INFO: update-demo-nautilus-8c967 is created but not running
Aug 28 11:29:23.643: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:24.046: INFO: stderr: ""
Aug 28 11:29:24.046: INFO: stdout: "update-demo-nautilus-8c967 update-demo-nautilus-z8qfc "
Aug 28 11:29:24.047: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-8c967 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:24.464: INFO: stderr: ""
Aug 28 11:29:24.464: INFO: stdout: "true"
Aug 28 11:29:24.464: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-8c967 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:24.869: INFO: stderr: ""
Aug 28 11:29:24.869: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Aug 28 11:29:24.869: INFO: validating pod update-demo-nautilus-8c967
Aug 28 11:29:24.881: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 28 11:29:24.881: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 28 11:29:24.881: INFO: update-demo-nautilus-8c967 is verified up and running
Aug 28 11:29:24.881: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-z8qfc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:25.283: INFO: stderr: ""
Aug 28 11:29:25.283: INFO: stdout: "true"
Aug 28 11:29:25.283: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-z8qfc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:25.706: INFO: stderr: ""
Aug 28 11:29:25.706: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Aug 28 11:29:25.706: INFO: validating pod update-demo-nautilus-z8qfc
Aug 28 11:29:25.718: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 28 11:29:25.718: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 28 11:29:25.718: INFO: update-demo-nautilus-z8qfc is verified up and running
STEP: scaling down the replication controller
Aug 28 11:29:25.718: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:27.374: INFO: stderr: ""
Aug 28 11:29:27.374: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 28 11:29:27.374: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:27.825: INFO: stderr: ""
Aug 28 11:29:27.825: INFO: stdout: "update-demo-nautilus-8c967 update-demo-nautilus-z8qfc "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 28 11:29:32.825: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:33.257: INFO: stderr: ""
Aug 28 11:29:33.257: INFO: stdout: "update-demo-nautilus-z8qfc "
Aug 28 11:29:33.257: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-z8qfc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:33.680: INFO: stderr: ""
Aug 28 11:29:33.680: INFO: stdout: "true"
Aug 28 11:29:33.680: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-z8qfc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:34.092: INFO: stderr: ""
Aug 28 11:29:34.092: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Aug 28 11:29:34.092: INFO: validating pod update-demo-nautilus-z8qfc
Aug 28 11:29:34.098: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 28 11:29:34.098: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 28 11:29:34.098: INFO: update-demo-nautilus-z8qfc is verified up and running
STEP: scaling up the replication controller
Aug 28 11:29:34.098: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:35.617: INFO: stderr: ""
Aug 28 11:29:35.617: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 28 11:29:35.617: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:36.021: INFO: stderr: ""
Aug 28 11:29:36.022: INFO: stdout: "update-demo-nautilus-58fq8 update-demo-nautilus-z8qfc "
Aug 28 11:29:36.022: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-58fq8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:36.417: INFO: stderr: ""
Aug 28 11:29:36.417: INFO: stdout: ""
Aug 28 11:29:36.417: INFO: update-demo-nautilus-58fq8 is created but not running
Aug 28 11:29:41.418: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:41.840: INFO: stderr: ""
Aug 28 11:29:41.840: INFO: stdout: "update-demo-nautilus-58fq8 update-demo-nautilus-z8qfc "
Aug 28 11:29:41.840: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-58fq8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:42.236: INFO: stderr: ""
Aug 28 11:29:42.236: INFO: stdout: "true"
Aug 28 11:29:42.236: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-58fq8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:42.647: INFO: stderr: ""
Aug 28 11:29:42.648: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Aug 28 11:29:42.648: INFO: validating pod update-demo-nautilus-58fq8
Aug 28 11:29:42.678: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 28 11:29:42.678: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 28 11:29:42.678: INFO: update-demo-nautilus-58fq8 is verified up and running
Aug 28 11:29:42.678: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-z8qfc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:43.073: INFO: stderr: ""
Aug 28 11:29:43.073: INFO: stdout: "true"
Aug 28 11:29:43.074: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-z8qfc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:43.478: INFO: stderr: ""
Aug 28 11:29:43.478: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Aug 28 11:29:43.478: INFO: validating pod update-demo-nautilus-z8qfc
Aug 28 11:29:43.484: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 28 11:29:43.484: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 28 11:29:43.484: INFO: update-demo-nautilus-z8qfc is verified up and running
STEP: using delete to clean up resources
Aug 28 11:29:43.484: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:43.932: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 28 11:29:43.932: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 28 11:29:43.932: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-wmh8c'
Aug 28 11:29:44.376: INFO: stderr: "No resources found.\n"
Aug 28 11:29:44.376: INFO: stdout: ""
Aug 28 11:29:44.377: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config get pods -l name=update-demo --namespace=e2e-tests-kubectl-wmh8c -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 28 11:29:44.820: INFO: stderr: ""
Aug 28 11:29:44.820: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:29:44.820: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wmh8c" for this suite.
Aug 28 11:30:02.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:30:03.057: INFO: namespace: e2e-tests-kubectl-wmh8c, resource: bindings, ignored listing per whitelist
Aug 28 11:30:06.009: INFO: namespace e2e-tests-kubectl-wmh8c deletion completed in 21.182907715s

• [SLOW TEST:49.296 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should scale a replication controller  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:30:06.010: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-hjvrc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0828 11:30:17.109731   76809 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 28 11:30:17.109: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:30:17.109: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hjvrc" for this suite.
Aug 28 11:30:25.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:30:25.996: INFO: namespace: e2e-tests-gc-hjvrc, resource: bindings, ignored listing per whitelist
Aug 28 11:30:28.247: INFO: namespace e2e-tests-gc-hjvrc deletion completed in 11.131645591s

• [SLOW TEST:22.238 seconds]
[sig-api-machinery] Garbage collector
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:30:28.247: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vckxl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should add annotations for pods in rc  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating Redis RC
Aug 28 11:30:28.681: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-vckxl'
Aug 28 11:30:29.262: INFO: stderr: ""
Aug 28 11:30:29.263: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 28 11:30:30.279: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:30:30.279: INFO: Found 0 / 1
Aug 28 11:30:31.268: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:30:31.268: INFO: Found 0 / 1
Aug 28 11:30:32.268: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:30:32.268: INFO: Found 0 / 1
Aug 28 11:30:33.268: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:30:33.268: INFO: Found 0 / 1
Aug 28 11:30:34.268: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:30:34.268: INFO: Found 1 / 1
Aug 28 11:30:34.268: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 28 11:30:34.272: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:30:34.272: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 28 11:30:34.273: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config patch pod redis-master-tmpdp --namespace=e2e-tests-kubectl-vckxl -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 28 11:30:34.721: INFO: stderr: ""
Aug 28 11:30:34.721: INFO: stdout: "pod/redis-master-tmpdp patched\n"
STEP: checking annotations
Aug 28 11:30:34.726: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:30:34.726: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:30:34.726: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vckxl" for this suite.
Aug 28 11:30:58.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:30:59.647: INFO: namespace: e2e-tests-kubectl-vckxl, resource: bindings, ignored listing per whitelist
Aug 28 11:31:01.846: INFO: namespace e2e-tests-kubectl-vckxl deletion completed in 27.113258854s

• [SLOW TEST:33.598 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should add annotations for pods in rc  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:31:01.846: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2jsvr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-4286062a-c944-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 11:31:02.429: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-428dd74b-c944-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-2jsvr" to be "success or failure"
Aug 28 11:31:02.443: INFO: Pod "pod-projected-configmaps-428dd74b-c944-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 14.095007ms
Aug 28 11:31:04.447: INFO: Pod "pod-projected-configmaps-428dd74b-c944-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018466856s
Aug 28 11:31:06.453: INFO: Pod "pod-projected-configmaps-428dd74b-c944-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023518616s
Aug 28 11:31:08.457: INFO: Pod "pod-projected-configmaps-428dd74b-c944-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.028016648s
Aug 28 11:31:10.472: INFO: Pod "pod-projected-configmaps-428dd74b-c944-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.042626444s
STEP: Saw pod success
Aug 28 11:31:10.472: INFO: Pod "pod-projected-configmaps-428dd74b-c944-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:31:10.475: INFO: Trying to get logs from node node-124 pod pod-projected-configmaps-428dd74b-c944-11e9-a0e2-288023b0a458 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 28 11:31:10.516: INFO: Waiting for pod pod-projected-configmaps-428dd74b-c944-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:31:10.519: INFO: Pod pod-projected-configmaps-428dd74b-c944-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:31:10.519: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2jsvr" for this suite.
Aug 28 11:31:18.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:31:21.655: INFO: namespace: e2e-tests-projected-2jsvr, resource: bindings, ignored listing per whitelist
Aug 28 11:31:21.655: INFO: namespace e2e-tests-projected-2jsvr deletion completed in 11.129491621s

• [SLOW TEST:19.809 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:31:21.656: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2wdb5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create services for rc  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating Redis RC
Aug 28 11:31:22.399: INFO: namespace e2e-tests-kubectl-2wdb5
Aug 28 11:31:22.399: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-2wdb5'
Aug 28 11:31:22.997: INFO: stderr: ""
Aug 28 11:31:22.997: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 28 11:31:24.003: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:31:24.003: INFO: Found 0 / 1
Aug 28 11:31:25.003: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:31:25.003: INFO: Found 0 / 1
Aug 28 11:31:26.002: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:31:26.003: INFO: Found 0 / 1
Aug 28 11:31:27.003: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:31:27.003: INFO: Found 0 / 1
Aug 28 11:31:28.003: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:31:28.003: INFO: Found 0 / 1
Aug 28 11:31:29.002: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:31:29.002: INFO: Found 1 / 1
Aug 28 11:31:29.002: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 28 11:31:29.005: INFO: Selector matched 1 pods for map[app:redis]
Aug 28 11:31:29.005: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 28 11:31:29.005: INFO: wait on redis-master startup in e2e-tests-kubectl-2wdb5 
Aug 28 11:31:29.005: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config logs redis-master-247kx redis-master --namespace=e2e-tests-kubectl-2wdb5'
Aug 28 11:31:29.423: INFO: stderr: ""
Aug 28 11:31:29.423: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 28 Aug 03:31:28.033 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 28 Aug 03:31:28.033 # Server started, Redis version 3.2.12\n1:M 28 Aug 03:31:28.034 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 28 Aug 03:31:28.034 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug 28 11:31:29.423: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-2wdb5'
Aug 28 11:31:29.873: INFO: stderr: ""
Aug 28 11:31:29.873: INFO: stdout: "service/rm2 exposed\n"
Aug 28 11:31:29.877: INFO: Service rm2 in namespace e2e-tests-kubectl-2wdb5 found.
STEP: exposing service
Aug 28 11:31:31.885: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-2wdb5'
Aug 28 11:31:32.357: INFO: stderr: ""
Aug 28 11:31:32.357: INFO: stdout: "service/rm3 exposed\n"
Aug 28 11:31:32.361: INFO: Service rm3 in namespace e2e-tests-kubectl-2wdb5 found.
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:31:34.369: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2wdb5" for this suite.
Aug 28 11:31:58.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:31:58.596: INFO: namespace: e2e-tests-kubectl-2wdb5, resource: bindings, ignored listing per whitelist
Aug 28 11:32:01.474: INFO: namespace e2e-tests-kubectl-2wdb5 deletion completed in 27.098271655s

• [SLOW TEST:39.819 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create services for rc  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:32:01.475: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-k2vt9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should rollback without unnecessary restarts [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Aug 28 11:32:01.978: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
Aug 28 11:32:01.988: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-k2vt9/daemonsets","resourceVersion":"15142284"},"items":null}

Aug 28 11:32:01.991: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-k2vt9/pods","resourceVersion":"15142284"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:32:02.041: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-k2vt9" for this suite.
Aug 28 11:32:10.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:32:10.168: INFO: namespace: e2e-tests-daemonsets-k2vt9, resource: bindings, ignored listing per whitelist
Aug 28 11:32:13.152: INFO: namespace e2e-tests-daemonsets-k2vt9 deletion completed in 11.105470195s

S [SKIPPING] [11.678 seconds]
[sig-apps] Daemon set [Serial]
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684

  Aug 28 11:32:01.978: Requires at least 2 nodes (not -1)

  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:305
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:32:13.153: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-ql2cf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test use defaults
Aug 28 11:32:13.657: INFO: Waiting up to 5m0s for pod "client-containers-6d0b334f-c944-11e9-a0e2-288023b0a458" in namespace "e2e-tests-containers-ql2cf" to be "success or failure"
Aug 28 11:32:13.685: INFO: Pod "client-containers-6d0b334f-c944-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 28.817782ms
Aug 28 11:32:15.689: INFO: Pod "client-containers-6d0b334f-c944-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032776474s
Aug 28 11:32:17.695: INFO: Pod "client-containers-6d0b334f-c944-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037938778s
Aug 28 11:32:19.707: INFO: Pod "client-containers-6d0b334f-c944-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.050576296s
Aug 28 11:32:21.713: INFO: Pod "client-containers-6d0b334f-c944-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.05663487s
STEP: Saw pod success
Aug 28 11:32:21.714: INFO: Pod "client-containers-6d0b334f-c944-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:32:21.718: INFO: Trying to get logs from node node-124 pod client-containers-6d0b334f-c944-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 11:32:21.779: INFO: Waiting for pod client-containers-6d0b334f-c944-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:32:21.783: INFO: Pod client-containers-6d0b334f-c944-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:32:21.783: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-ql2cf" for this suite.
Aug 28 11:32:29.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:32:29.936: INFO: namespace: e2e-tests-containers-ql2cf, resource: bindings, ignored listing per whitelist
Aug 28 11:32:32.920: INFO: namespace e2e-tests-containers-ql2cf deletion completed in 11.129802525s

• [SLOW TEST:19.768 seconds]
[k8s.io] Docker Containers
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-auth] ServiceAccounts
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:32:32.920: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-pjl6b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Aug 28 11:32:33.994: INFO: Waiting up to 5m0s for pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-mx49n" in namespace "e2e-tests-svcaccounts-pjl6b" to be "success or failure"
Aug 28 11:32:34.022: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-mx49n": Phase="Pending", Reason="", readiness=false. Elapsed: 27.668036ms
Aug 28 11:32:36.027: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-mx49n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032527479s
Aug 28 11:32:38.032: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-mx49n": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037625783s
Aug 28 11:32:40.037: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-mx49n": Phase="Pending", Reason="", readiness=false. Elapsed: 6.042356681s
Aug 28 11:32:42.042: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-mx49n": Phase="Pending", Reason="", readiness=false. Elapsed: 8.047471047s
Aug 28 11:32:44.060: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-mx49n": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.065204824s
STEP: Saw pod success
Aug 28 11:32:44.060: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-mx49n" satisfied condition "success or failure"
Aug 28 11:32:44.064: INFO: Trying to get logs from node node-124 pod pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-mx49n container token-test: <nil>
STEP: delete the pod
Aug 28 11:32:44.134: INFO: Waiting for pod pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-mx49n to disappear
Aug 28 11:32:44.137: INFO: Pod pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-mx49n no longer exists
STEP: Creating a pod to test consume service account root CA
Aug 28 11:32:44.239: INFO: Waiting up to 5m0s for pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-jnx72" in namespace "e2e-tests-svcaccounts-pjl6b" to be "success or failure"
Aug 28 11:32:44.254: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-jnx72": Phase="Pending", Reason="", readiness=false. Elapsed: 14.839251ms
Aug 28 11:32:46.259: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-jnx72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01971218s
Aug 28 11:32:48.264: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-jnx72": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024846211s
Aug 28 11:32:50.270: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-jnx72": Phase="Pending", Reason="", readiness=false. Elapsed: 6.030441844s
Aug 28 11:32:52.275: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-jnx72": Phase="Pending", Reason="", readiness=false. Elapsed: 8.035175148s
Aug 28 11:32:54.280: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-jnx72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.040492712s
STEP: Saw pod success
Aug 28 11:32:54.280: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-jnx72" satisfied condition "success or failure"
Aug 28 11:32:54.284: INFO: Trying to get logs from node node-124 pod pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-jnx72 container root-ca-test: <nil>
STEP: delete the pod
Aug 28 11:32:54.339: INFO: Waiting for pod pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-jnx72 to disappear
Aug 28 11:32:54.342: INFO: Pod pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-jnx72 no longer exists
STEP: Creating a pod to test consume service account namespace
Aug 28 11:32:54.410: INFO: Waiting up to 5m0s for pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-qxkv6" in namespace "e2e-tests-svcaccounts-pjl6b" to be "success or failure"
Aug 28 11:32:54.437: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-qxkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 26.969761ms
Aug 28 11:32:56.442: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-qxkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032041714s
Aug 28 11:32:58.451: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-qxkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040794857s
Aug 28 11:33:00.456: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-qxkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.045174165s
Aug 28 11:33:02.460: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-qxkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.049777843s
Aug 28 11:33:04.465: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-qxkv6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.054727801s
STEP: Saw pod success
Aug 28 11:33:04.465: INFO: Pod "pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-qxkv6" satisfied condition "success or failure"
Aug 28 11:33:04.469: INFO: Trying to get logs from node node-124 pod pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-qxkv6 container namespace-test: <nil>
STEP: delete the pod
Aug 28 11:33:04.508: INFO: Waiting for pod pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-qxkv6 to disappear
Aug 28 11:33:04.514: INFO: Pod pod-service-account-792cda9e-c944-11e9-a0e2-288023b0a458-qxkv6 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:33:04.514: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-pjl6b" for this suite.
Aug 28 11:33:12.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:33:14.673: INFO: namespace: e2e-tests-svcaccounts-pjl6b, resource: bindings, ignored listing per whitelist
Aug 28 11:33:15.625: INFO: namespace e2e-tests-svcaccounts-pjl6b deletion completed in 11.103228645s

• [SLOW TEST:42.704 seconds]
[sig-auth] ServiceAccounts
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:33:15.625: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9bjxd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Aug 28 11:33:16.252: INFO: Waiting up to 5m0s for pod "downwardapi-volume-925603c5-c944-11e9-a0e2-288023b0a458" in namespace "e2e-tests-downward-api-9bjxd" to be "success or failure"
Aug 28 11:33:16.271: INFO: Pod "downwardapi-volume-925603c5-c944-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 19.550132ms
Aug 28 11:33:18.277: INFO: Pod "downwardapi-volume-925603c5-c944-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024891143s
Aug 28 11:33:20.281: INFO: Pod "downwardapi-volume-925603c5-c944-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029292881s
Aug 28 11:33:22.286: INFO: Pod "downwardapi-volume-925603c5-c944-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.033873779s
Aug 28 11:33:24.291: INFO: Pod "downwardapi-volume-925603c5-c944-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.039263196s
STEP: Saw pod success
Aug 28 11:33:24.291: INFO: Pod "downwardapi-volume-925603c5-c944-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:33:24.295: INFO: Trying to get logs from node node-124 pod downwardapi-volume-925603c5-c944-11e9-a0e2-288023b0a458 container client-container: <nil>
STEP: delete the pod
Aug 28 11:33:24.358: INFO: Waiting for pod downwardapi-volume-925603c5-c944-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:33:24.366: INFO: Pod downwardapi-volume-925603c5-c944-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:33:24.366: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9bjxd" for this suite.
Aug 28 11:33:32.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:33:32.574: INFO: namespace: e2e-tests-downward-api-9bjxd, resource: bindings, ignored listing per whitelist
Aug 28 11:33:35.538: INFO: namespace e2e-tests-downward-api-9bjxd deletion completed in 11.164873613s

• [SLOW TEST:19.913 seconds]
[sig-storage] Downward API volume
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:33:35.538: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-b2trv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 28 11:33:36.057: INFO: Waiting up to 5m0s for pod "pod-9e223176-c944-11e9-a0e2-288023b0a458" in namespace "e2e-tests-emptydir-b2trv" to be "success or failure"
Aug 28 11:33:36.099: INFO: Pod "pod-9e223176-c944-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 41.62571ms
Aug 28 11:33:38.103: INFO: Pod "pod-9e223176-c944-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046184029s
Aug 28 11:33:40.109: INFO: Pod "pod-9e223176-c944-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051360556s
Aug 28 11:33:42.113: INFO: Pod "pod-9e223176-c944-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.056143929s
STEP: Saw pod success
Aug 28 11:33:42.113: INFO: Pod "pod-9e223176-c944-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:33:42.117: INFO: Trying to get logs from node node-124 pod pod-9e223176-c944-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 11:33:42.170: INFO: Waiting for pod pod-9e223176-c944-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:33:42.173: INFO: Pod pod-9e223176-c944-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:33:42.174: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b2trv" for this suite.
Aug 28 11:33:50.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:33:53.056: INFO: namespace: e2e-tests-emptydir-b2trv, resource: bindings, ignored listing per whitelist
Aug 28 11:33:53.356: INFO: namespace e2e-tests-emptydir-b2trv deletion completed in 11.175771674s

• [SLOW TEST:17.818 seconds]
[sig-storage] EmptyDir volumes
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:33:53.357: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-jtnk9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-jtnk9
Aug 28 11:33:59.994: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-jtnk9
STEP: checking the pod's current state and verifying that restartCount is present
Aug 28 11:33:59.998: INFO: Initial restart count of pod liveness-http is 0
Aug 28 11:34:14.094: INFO: Restart count of pod e2e-tests-container-probe-jtnk9/liveness-http is now 1 (14.095297708s elapsed)
Aug 28 11:34:34.230: INFO: Restart count of pod e2e-tests-container-probe-jtnk9/liveness-http is now 2 (34.231475451s elapsed)
Aug 28 11:34:54.306: INFO: Restart count of pod e2e-tests-container-probe-jtnk9/liveness-http is now 3 (54.307239831s elapsed)
Aug 28 11:35:14.360: INFO: Restart count of pod e2e-tests-container-probe-jtnk9/liveness-http is now 4 (1m14.361302279s elapsed)
Aug 28 11:36:20.564: INFO: Restart count of pod e2e-tests-container-probe-jtnk9/liveness-http is now 5 (2m20.565887816s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:36:20.589: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jtnk9" for this suite.
Aug 28 11:36:28.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:36:31.545: INFO: namespace: e2e-tests-container-probe-jtnk9, resource: bindings, ignored listing per whitelist
Aug 28 11:36:31.695: INFO: namespace e2e-tests-container-probe-jtnk9 deletion completed in 11.098113022s

• [SLOW TEST:158.338 seconds]
[k8s.io] Probing container
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:36:31.695: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-s5mnl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-s5mnl
Aug 28 11:36:38.299: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-s5mnl
STEP: checking the pod's current state and verifying that restartCount is present
Aug 28 11:36:38.303: INFO: Initial restart count of pod liveness-exec is 0
Aug 28 11:37:30.431: INFO: Restart count of pod e2e-tests-container-probe-s5mnl/liveness-exec is now 1 (52.128091625s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:37:30.455: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-s5mnl" for this suite.
Aug 28 11:37:38.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:37:40.801: INFO: namespace: e2e-tests-container-probe-s5mnl, resource: bindings, ignored listing per whitelist
Aug 28 11:37:41.602: INFO: namespace e2e-tests-container-probe-s5mnl deletion completed in 11.139914179s

• [SLOW TEST:69.907 seconds]
[k8s.io] Probing container
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:37:41.602: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-sdkwc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-30d02ded-c945-11e9-a0e2-288023b0a458
STEP: Creating a pod to test consume configMaps
Aug 28 11:37:42.185: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-30d643be-c945-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-sdkwc" to be "success or failure"
Aug 28 11:37:42.189: INFO: Pod "pod-projected-configmaps-30d643be-c945-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 3.782967ms
Aug 28 11:37:44.196: INFO: Pod "pod-projected-configmaps-30d643be-c945-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010253515s
Aug 28 11:37:46.201: INFO: Pod "pod-projected-configmaps-30d643be-c945-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015265552s
Aug 28 11:37:48.206: INFO: Pod "pod-projected-configmaps-30d643be-c945-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020652803s
STEP: Saw pod success
Aug 28 11:37:48.206: INFO: Pod "pod-projected-configmaps-30d643be-c945-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:37:48.211: INFO: Trying to get logs from node node-124 pod pod-projected-configmaps-30d643be-c945-11e9-a0e2-288023b0a458 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 28 11:37:48.258: INFO: Waiting for pod pod-projected-configmaps-30d643be-c945-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:37:48.261: INFO: Pod pod-projected-configmaps-30d643be-c945-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:37:48.261: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sdkwc" for this suite.
Aug 28 11:37:56.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:37:56.601: INFO: namespace: e2e-tests-projected-sdkwc, resource: bindings, ignored listing per whitelist
Aug 28 11:37:59.378: INFO: namespace e2e-tests-projected-sdkwc deletion completed in 11.111029195s

• [SLOW TEST:17.776 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:37:59.379: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8m78m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support proxy with --port 0  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: starting the proxy server
Aug 28 11:37:59.818: INFO: Asynchronously running '/bin/kubectl kubectl --kubeconfig=/root/.kube/config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:38:00.198: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8m78m" for this suite.
Aug 28 11:38:06.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:38:07.192: INFO: namespace: e2e-tests-kubectl-8m78m, resource: bindings, ignored listing per whitelist
Aug 28 11:38:09.292: INFO: namespace e2e-tests-kubectl-8m78m deletion completed in 9.086018136s

• [SLOW TEST:9.914 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support proxy with --port 0  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:38:09.293: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zrttz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create and stop a working application  [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating all guestbook components
Aug 28 11:38:09.731: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug 28 11:38:09.731: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-zrttz'
Aug 28 11:38:10.346: INFO: stderr: ""
Aug 28 11:38:10.347: INFO: stdout: "service/redis-slave created\n"
Aug 28 11:38:10.347: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug 28 11:38:10.347: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-zrttz'
Aug 28 11:38:11.045: INFO: stderr: ""
Aug 28 11:38:11.046: INFO: stdout: "service/redis-master created\n"
Aug 28 11:38:11.046: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 28 11:38:11.046: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-zrttz'
Aug 28 11:38:11.767: INFO: stderr: ""
Aug 28 11:38:11.767: INFO: stdout: "service/frontend created\n"
Aug 28 11:38:11.767: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend-amd64:v5
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug 28 11:38:11.767: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-zrttz'
Aug 28 11:38:12.460: INFO: stderr: ""
Aug 28 11:38:12.460: INFO: stdout: "deployment.extensions/frontend created\n"
Aug 28 11:38:12.460: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 28 11:38:12.460: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-zrttz'
Aug 28 11:38:13.065: INFO: stderr: ""
Aug 28 11:38:13.065: INFO: stdout: "deployment.extensions/redis-master created\n"
Aug 28 11:38:13.065: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave-amd64:v2
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug 28 11:38:13.065: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=e2e-tests-kubectl-zrttz'
Aug 28 11:38:13.663: INFO: stderr: ""
Aug 28 11:38:13.663: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Aug 28 11:38:13.663: INFO: Waiting for all frontend pods to be Running.
Aug 28 11:38:23.714: INFO: Waiting for frontend to serve content.
Aug 28 11:38:23.891: INFO: Trying to add a new entry to the guestbook.
Aug 28 11:38:24.041: INFO: Verifying that added entry can be retrieved.
Aug 28 11:38:24.064: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Aug 28 11:38:29.087: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zrttz'
Aug 28 11:38:29.601: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 28 11:38:29.601: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug 28 11:38:29.602: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zrttz'
Aug 28 11:38:30.225: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 28 11:38:30.225: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 28 11:38:30.226: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zrttz'
Aug 28 11:38:30.679: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 28 11:38:30.679: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 28 11:38:30.679: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zrttz'
Aug 28 11:38:31.201: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 28 11:38:31.201: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 28 11:38:31.202: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zrttz'
Aug 28 11:38:31.678: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 28 11:38:31.678: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 28 11:38:31.678: INFO: Running '/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zrttz'
Aug 28 11:38:32.118: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 28 11:38:32.118: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:38:32.118: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zrttz" for this suite.
Aug 28 11:39:14.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:39:16.111: INFO: namespace: e2e-tests-kubectl-zrttz, resource: bindings, ignored listing per whitelist
Aug 28 11:39:17.343: INFO: namespace e2e-tests-kubectl-zrttz deletion completed in 45.216790661s

• [SLOW TEST:68.050 seconds]
[sig-cli] Kubectl client
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create and stop a working application  [Conformance]
    /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:39:17.343: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bxnqs
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 28 11:39:17.829: INFO: Waiting up to 5m0s for pod "pod-69d8fd81-c945-11e9-a0e2-288023b0a458" in namespace "e2e-tests-emptydir-bxnqs" to be "success or failure"
Aug 28 11:39:17.854: INFO: Pod "pod-69d8fd81-c945-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 25.181645ms
Aug 28 11:39:19.858: INFO: Pod "pod-69d8fd81-c945-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029027666s
Aug 28 11:39:21.862: INFO: Pod "pod-69d8fd81-c945-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033466193s
Aug 28 11:39:23.908: INFO: Pod "pod-69d8fd81-c945-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.079618448s
STEP: Saw pod success
Aug 28 11:39:23.909: INFO: Pod "pod-69d8fd81-c945-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:39:23.913: INFO: Trying to get logs from node node-124 pod pod-69d8fd81-c945-11e9-a0e2-288023b0a458 container test-container: <nil>
STEP: delete the pod
Aug 28 11:39:23.956: INFO: Waiting for pod pod-69d8fd81-c945-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:39:23.959: INFO: Pod pod-69d8fd81-c945-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:39:23.959: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bxnqs" for this suite.
Aug 28 11:39:31.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:39:32.915: INFO: namespace: e2e-tests-emptydir-bxnqs, resource: bindings, ignored listing per whitelist
Aug 28 11:39:35.065: INFO: namespace e2e-tests-emptydir-bxnqs deletion completed in 11.099031919s

• [SLOW TEST:17.722 seconds]
[sig-storage] EmptyDir volumes
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:39:35.065: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-2f7mp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0828 11:40:15.626256   76809 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 28 11:40:15.626: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:40:15.626: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2f7mp" for this suite.
Aug 28 11:40:23.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:40:25.735: INFO: namespace: e2e-tests-gc-2f7mp, resource: bindings, ignored listing per whitelist
Aug 28 11:40:26.735: INFO: namespace e2e-tests-gc-2f7mp deletion completed in 11.103518922s

• [SLOW TEST:51.670 seconds]
[sig-api-machinery] Garbage collector
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:40:26.735: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7cz26
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-projected-all-test-volume-933d61f9-c945-11e9-a0e2-288023b0a458
STEP: Creating secret with name secret-projected-all-test-volume-933d61aa-c945-11e9-a0e2-288023b0a458
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 28 11:40:27.374: INFO: Waiting up to 5m0s for pod "projected-volume-933d612f-c945-11e9-a0e2-288023b0a458" in namespace "e2e-tests-projected-7cz26" to be "success or failure"
Aug 28 11:40:27.378: INFO: Pod "projected-volume-933d612f-c945-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.19751ms
Aug 28 11:40:29.383: INFO: Pod "projected-volume-933d612f-c945-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009050256s
Aug 28 11:40:31.388: INFO: Pod "projected-volume-933d612f-c945-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014051067s
Aug 28 11:40:33.393: INFO: Pod "projected-volume-933d612f-c945-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018957528s
STEP: Saw pod success
Aug 28 11:40:33.393: INFO: Pod "projected-volume-933d612f-c945-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:40:33.396: INFO: Trying to get logs from node node-124 pod projected-volume-933d612f-c945-11e9-a0e2-288023b0a458 container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 28 11:40:33.447: INFO: Waiting for pod projected-volume-933d612f-c945-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:40:33.454: INFO: Pod projected-volume-933d612f-c945-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-storage] Projected
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:40:33.454: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7cz26" for this suite.
Aug 28 11:40:41.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:40:41.744: INFO: namespace: e2e-tests-projected-7cz26, resource: bindings, ignored listing per whitelist
Aug 28 11:40:44.589: INFO: namespace e2e-tests-projected-7cz26 deletion completed in 11.12919341s

• [SLOW TEST:17.854 seconds]
[sig-storage] Projected
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Aug 28 11:40:44.590: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-qbpz9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Aug 28 11:40:45.093: INFO: Waiting up to 5m0s for pod "downward-api-9de2b2f6-c945-11e9-a0e2-288023b0a458" in namespace "e2e-tests-downward-api-qbpz9" to be "success or failure"
Aug 28 11:40:45.098: INFO: Pod "downward-api-9de2b2f6-c945-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.725505ms
Aug 28 11:40:47.104: INFO: Pod "downward-api-9de2b2f6-c945-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010676645s
Aug 28 11:40:49.109: INFO: Pod "downward-api-9de2b2f6-c945-11e9-a0e2-288023b0a458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016199817s
Aug 28 11:40:51.114: INFO: Pod "downward-api-9de2b2f6-c945-11e9-a0e2-288023b0a458": Phase="Running", Reason="", readiness=true. Elapsed: 6.021290545s
Aug 28 11:40:53.119: INFO: Pod "downward-api-9de2b2f6-c945-11e9-a0e2-288023b0a458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.026074364s
STEP: Saw pod success
Aug 28 11:40:53.119: INFO: Pod "downward-api-9de2b2f6-c945-11e9-a0e2-288023b0a458" satisfied condition "success or failure"
Aug 28 11:40:53.123: INFO: Trying to get logs from node node-124 pod downward-api-9de2b2f6-c945-11e9-a0e2-288023b0a458 container dapi-container: <nil>
STEP: delete the pod
Aug 28 11:40:53.166: INFO: Waiting for pod downward-api-9de2b2f6-c945-11e9-a0e2-288023b0a458 to disappear
Aug 28 11:40:53.171: INFO: Pod downward-api-9de2b2f6-c945-11e9-a0e2-288023b0a458 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Aug 28 11:40:53.171: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qbpz9" for this suite.
Aug 28 11:41:01.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 28 11:41:02.600: INFO: namespace: e2e-tests-downward-api-qbpz9, resource: bindings, ignored listing per whitelist
Aug 28 11:41:04.488: INFO: namespace e2e-tests-downward-api-qbpz9 deletion completed in 11.27931402s

• [SLOW TEST:19.898 seconds]
[sig-api-machinery] Downward API
/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSAug 28 11:41:04.488: INFO: Running AfterSuite actions on all node
Aug 28 11:41:04.488: INFO: Running AfterSuite actions on node 1
Aug 28 11:41:04.488: INFO: Dumping logs locally to: /home/conformance
Aug 28 11:41:04.488: INFO: Error running cluster/log-dump/log-dump.sh: fork/exec ../../cluster/log-dump/log-dump.sh: no such file or directory

Ran 166 of 998 Specs in 6335.907 seconds
SUCCESS! -- 166 Passed | 0 Failed | 0 Pending | 832 Skipped PASS

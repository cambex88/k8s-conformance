I0822 03:50:52.658386      19 e2e.go:116] Starting e2e run "446d56d2-2673-4aa3-a77e-727529e19729" on Ginkgo node 1
Aug 22 03:50:52.668: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1692676252 - will randomize all specs

Will run 360 of 7066 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Aug 22 03:50:52.804: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
E0822 03:50:52.805906      19 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
Aug 22 03:50:52.805: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
E0822 03:50:52.805906      19 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
Aug 22 03:50:52.832: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 22 03:50:52.857: INFO: 29 / 29 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 22 03:50:52.857: INFO: expected 7 pod replicas in namespace 'kube-system', 7 are Running and Ready.
Aug 22 03:50:52.857: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 22 03:50:52.862: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'csi-cinder-nodeplugin' (0 seconds elapsed)
Aug 22 03:50:52.862: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'k8s-keystone-auth' (0 seconds elapsed)
Aug 22 03:50:52.862: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Aug 22 03:50:52.862: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'npd' (0 seconds elapsed)
Aug 22 03:50:52.862: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'openstack-cloud-controller-manager' (0 seconds elapsed)
Aug 22 03:50:52.862: INFO: e2e test version: v1.25.9
Aug 22 03:50:52.864: INFO: kube-apiserver version: v1.25.9
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Aug 22 03:50:52.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 03:50:52.867: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.063 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Aug 22 03:50:52.804: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 03:50:52.805: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    E0822 03:50:52.805906      19 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
    Aug 22 03:50:52.832: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Aug 22 03:50:52.857: INFO: 29 / 29 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Aug 22 03:50:52.857: INFO: expected 7 pod replicas in namespace 'kube-system', 7 are Running and Ready.
    Aug 22 03:50:52.857: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Aug 22 03:50:52.862: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'csi-cinder-nodeplugin' (0 seconds elapsed)
    Aug 22 03:50:52.862: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'k8s-keystone-auth' (0 seconds elapsed)
    Aug 22 03:50:52.862: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
    Aug 22 03:50:52.862: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'npd' (0 seconds elapsed)
    Aug 22 03:50:52.862: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'openstack-cloud-controller-manager' (0 seconds elapsed)
    Aug 22 03:50:52.862: INFO: e2e test version: v1.25.9
    Aug 22 03:50:52.864: INFO: kube-apiserver version: v1.25.9
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Aug 22 03:50:52.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 03:50:52.867: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:50:52.897
Aug 22 03:50:52.897: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename job 08/22/23 03:50:52.897
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:50:52.929
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:50:52.933
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 08/22/23 03:50:52.937
STEP: Ensuring job reaches completions 08/22/23 03:50:52.946
STEP: Ensuring pods with index for job exist 08/22/23 03:51:10.951
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 22 03:51:10.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6240" for this suite. 08/22/23 03:51:10.958
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":1,"skipped":6,"failed":0}
------------------------------
â€¢ [SLOW TEST] [18.068 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:50:52.897
    Aug 22 03:50:52.897: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename job 08/22/23 03:50:52.897
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:50:52.929
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:50:52.933
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 08/22/23 03:50:52.937
    STEP: Ensuring job reaches completions 08/22/23 03:50:52.946
    STEP: Ensuring pods with index for job exist 08/22/23 03:51:10.951
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 22 03:51:10.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-6240" for this suite. 08/22/23 03:51:10.958
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:51:10.966
Aug 22 03:51:10.966: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 03:51:10.967
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:51:10.98
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:51:10.984
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 08/22/23 03:51:10.987
Aug 22 03:51:11.003: INFO: Waiting up to 5m0s for pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e" in namespace "downward-api-6091" to be "running and ready"
Aug 22 03:51:11.006: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.981883ms
Aug 22 03:51:11.006: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:51:13.010: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007254836s
Aug 22 03:51:13.010: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:51:15.010: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007730476s
Aug 22 03:51:15.011: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:51:17.011: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008140526s
Aug 22 03:51:17.011: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:51:19.010: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.006774053s
Aug 22 03:51:19.010: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:51:21.010: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007097146s
Aug 22 03:51:21.010: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:51:23.010: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.007102266s
Aug 22 03:51:23.010: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:51:25.012: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.009478211s
Aug 22 03:51:25.012: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:51:27.010: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.006909835s
Aug 22 03:51:27.010: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:51:29.011: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Running", Reason="", readiness=true. Elapsed: 18.008246972s
Aug 22 03:51:29.011: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Running (Ready = true)
Aug 22 03:51:29.011: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e" satisfied condition "running and ready"
Aug 22 03:51:29.583: INFO: Successfully updated pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 22 03:51:31.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6091" for this suite. 08/22/23 03:51:31.868
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":2,"skipped":27,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.928 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:51:10.966
    Aug 22 03:51:10.966: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 03:51:10.967
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:51:10.98
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:51:10.984
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 08/22/23 03:51:10.987
    Aug 22 03:51:11.003: INFO: Waiting up to 5m0s for pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e" in namespace "downward-api-6091" to be "running and ready"
    Aug 22 03:51:11.006: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.981883ms
    Aug 22 03:51:11.006: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:51:13.010: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007254836s
    Aug 22 03:51:13.010: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:51:15.010: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007730476s
    Aug 22 03:51:15.011: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:51:17.011: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008140526s
    Aug 22 03:51:17.011: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:51:19.010: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.006774053s
    Aug 22 03:51:19.010: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:51:21.010: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007097146s
    Aug 22 03:51:21.010: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:51:23.010: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.007102266s
    Aug 22 03:51:23.010: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:51:25.012: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.009478211s
    Aug 22 03:51:25.012: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:51:27.010: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.006909835s
    Aug 22 03:51:27.010: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:51:29.011: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e": Phase="Running", Reason="", readiness=true. Elapsed: 18.008246972s
    Aug 22 03:51:29.011: INFO: The phase of Pod labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e is Running (Ready = true)
    Aug 22 03:51:29.011: INFO: Pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e" satisfied condition "running and ready"
    Aug 22 03:51:29.583: INFO: Successfully updated pod "labelsupdate58062b94-9a36-4452-80a6-b54ac6b6f91e"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 22 03:51:31.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6091" for this suite. 08/22/23 03:51:31.868
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:51:31.897
Aug 22 03:51:31.897: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 03:51:31.898
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:51:31.913
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:51:31.916
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 08/22/23 03:51:31.92
Aug 22 03:51:31.929: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812" in namespace "projected-6947" to be "Succeeded or Failed"
Aug 22 03:51:31.935: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 6.192394ms
Aug 22 03:51:33.953: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023838916s
Aug 22 03:51:35.941: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011743222s
Aug 22 03:51:37.940: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010995954s
Aug 22 03:51:39.939: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010342183s
Aug 22 03:51:41.939: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 10.010226971s
Aug 22 03:51:43.940: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 12.010815486s
Aug 22 03:51:45.940: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 14.010786445s
Aug 22 03:51:47.966: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.036692678s
STEP: Saw pod success 08/22/23 03:51:47.966
Aug 22 03:51:47.966: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812" satisfied condition "Succeeded or Failed"
Aug 22 03:51:47.970: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812 container client-container: <nil>
STEP: delete the pod 08/22/23 03:51:48.01
Aug 22 03:51:48.032: INFO: Waiting for pod downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812 to disappear
Aug 22 03:51:48.035: INFO: Pod downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 22 03:51:48.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6947" for this suite. 08/22/23 03:51:48.038
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":3,"skipped":47,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.149 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:51:31.897
    Aug 22 03:51:31.897: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 03:51:31.898
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:51:31.913
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:51:31.916
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 08/22/23 03:51:31.92
    Aug 22 03:51:31.929: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812" in namespace "projected-6947" to be "Succeeded or Failed"
    Aug 22 03:51:31.935: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 6.192394ms
    Aug 22 03:51:33.953: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023838916s
    Aug 22 03:51:35.941: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011743222s
    Aug 22 03:51:37.940: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010995954s
    Aug 22 03:51:39.939: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010342183s
    Aug 22 03:51:41.939: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 10.010226971s
    Aug 22 03:51:43.940: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 12.010815486s
    Aug 22 03:51:45.940: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Pending", Reason="", readiness=false. Elapsed: 14.010786445s
    Aug 22 03:51:47.966: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.036692678s
    STEP: Saw pod success 08/22/23 03:51:47.966
    Aug 22 03:51:47.966: INFO: Pod "downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812" satisfied condition "Succeeded or Failed"
    Aug 22 03:51:47.970: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812 container client-container: <nil>
    STEP: delete the pod 08/22/23 03:51:48.01
    Aug 22 03:51:48.032: INFO: Waiting for pod downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812 to disappear
    Aug 22 03:51:48.035: INFO: Pod downwardapi-volume-4ddfc62d-41de-410c-bd0d-3005cf2da812 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 22 03:51:48.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6947" for this suite. 08/22/23 03:51:48.038
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:51:48.047
Aug 22 03:51:48.047: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename secrets 08/22/23 03:51:48.048
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:51:48.061
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:51:48.065
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-e490bf60-7ece-4703-af5c-a99e10fd4c02 08/22/23 03:51:48.166
STEP: Creating a pod to test consume secrets 08/22/23 03:51:48.17
Aug 22 03:51:48.177: INFO: Waiting up to 5m0s for pod "pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832" in namespace "secrets-6350" to be "Succeeded or Failed"
Aug 22 03:51:48.181: INFO: Pod "pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832": Phase="Pending", Reason="", readiness=false. Elapsed: 3.425727ms
Aug 22 03:51:50.185: INFO: Pod "pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00745157s
Aug 22 03:51:52.185: INFO: Pod "pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007299869s
Aug 22 03:51:54.185: INFO: Pod "pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007564146s
STEP: Saw pod success 08/22/23 03:51:54.185
Aug 22 03:51:54.185: INFO: Pod "pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832" satisfied condition "Succeeded or Failed"
Aug 22 03:51:54.189: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832 container secret-volume-test: <nil>
STEP: delete the pod 08/22/23 03:51:54.194
Aug 22 03:51:54.205: INFO: Waiting for pod pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832 to disappear
Aug 22 03:51:54.208: INFO: Pod pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 22 03:51:54.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6350" for this suite. 08/22/23 03:51:54.212
STEP: Destroying namespace "secret-namespace-704" for this suite. 08/22/23 03:51:54.217
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":4,"skipped":58,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.179 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:51:48.047
    Aug 22 03:51:48.047: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename secrets 08/22/23 03:51:48.048
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:51:48.061
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:51:48.065
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-e490bf60-7ece-4703-af5c-a99e10fd4c02 08/22/23 03:51:48.166
    STEP: Creating a pod to test consume secrets 08/22/23 03:51:48.17
    Aug 22 03:51:48.177: INFO: Waiting up to 5m0s for pod "pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832" in namespace "secrets-6350" to be "Succeeded or Failed"
    Aug 22 03:51:48.181: INFO: Pod "pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832": Phase="Pending", Reason="", readiness=false. Elapsed: 3.425727ms
    Aug 22 03:51:50.185: INFO: Pod "pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00745157s
    Aug 22 03:51:52.185: INFO: Pod "pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007299869s
    Aug 22 03:51:54.185: INFO: Pod "pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007564146s
    STEP: Saw pod success 08/22/23 03:51:54.185
    Aug 22 03:51:54.185: INFO: Pod "pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832" satisfied condition "Succeeded or Failed"
    Aug 22 03:51:54.189: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832 container secret-volume-test: <nil>
    STEP: delete the pod 08/22/23 03:51:54.194
    Aug 22 03:51:54.205: INFO: Waiting for pod pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832 to disappear
    Aug 22 03:51:54.208: INFO: Pod pod-secrets-b83a6728-dadc-46a5-b56d-016a099b4832 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 22 03:51:54.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6350" for this suite. 08/22/23 03:51:54.212
    STEP: Destroying namespace "secret-namespace-704" for this suite. 08/22/23 03:51:54.217
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:51:54.226
Aug 22 03:51:54.226: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename deployment 08/22/23 03:51:54.227
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:51:54.24
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:51:54.244
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Aug 22 03:51:54.248: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 22 03:51:54.259: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 22 03:51:59.262: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/22/23 03:51:59.262
Aug 22 03:51:59.262: INFO: Waiting up to 5m0s for pod "test-rolling-update-controller-656dj" in namespace "deployment-3662" to be "running"
Aug 22 03:51:59.266: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 3.71564ms
Aug 22 03:52:01.386: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123876776s
Aug 22 03:52:03.271: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00863931s
Aug 22 03:52:05.272: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009487379s
Aug 22 03:52:07.272: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009183252s
Aug 22 03:52:09.271: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 10.008725959s
Aug 22 03:52:11.270: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 12.0078919s
Aug 22 03:52:13.271: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 14.008510402s
Aug 22 03:52:15.271: INFO: Pod "test-rolling-update-controller-656dj": Phase="Running", Reason="", readiness=true. Elapsed: 16.008463868s
Aug 22 03:52:15.271: INFO: Pod "test-rolling-update-controller-656dj" satisfied condition "running"
Aug 22 03:52:15.271: INFO: Creating deployment "test-rolling-update-deployment"
Aug 22 03:52:15.279: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 22 03:52:15.289: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 22 03:52:17.296: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 22 03:52:17.298: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 52, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 52, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 52, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 52, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:52:19.303: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 22 03:52:19.311: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3662  01e2e076-9ef3-41a5-99aa-dd28a76d28c8 1247327 1 2023-08-22 03:52:15 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-08-22 03:52:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 03:52:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00250b048 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-08-22 03:52:15 +0000 UTC,LastTransitionTime:2023-08-22 03:52:15 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-08-22 03:52:18 +0000 UTC,LastTransitionTime:2023-08-22 03:52:15 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 22 03:52:19.314: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-3662  55905dda-b2f5-4977-ba3e-f3e39dc19ec8 1247317 1 2023-08-22 03:52:15 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 01e2e076-9ef3-41a5-99aa-dd28a76d28c8 0xc00241b9c7 0xc00241b9c8}] [] [{kube-controller-manager Update apps/v1 2023-08-22 03:52:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"01e2e076-9ef3-41a5-99aa-dd28a76d28c8\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 03:52:18 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00241ba78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 22 03:52:19.314: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 22 03:52:19.314: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3662  3b244148-a77b-46c0-b558-f8a4dce1a158 1247326 2 2023-08-22 03:51:54 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 01e2e076-9ef3-41a5-99aa-dd28a76d28c8 0xc00241b897 0xc00241b898}] [] [{e2e.test Update apps/v1 2023-08-22 03:51:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 03:52:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"01e2e076-9ef3-41a5-99aa-dd28a76d28c8\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-08-22 03:52:18 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00241b958 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 22 03:52:19.317: INFO: Pod "test-rolling-update-deployment-78f575d8ff-wmbzq" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-wmbzq test-rolling-update-deployment-78f575d8ff- deployment-3662  fe14ee8d-5b6c-4284-9123-fb8e077722fc 1247316 0 2023-08-22 03:52:15 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 55905dda-b2f5-4977-ba3e-f3e39dc19ec8 0xc00241bed7 0xc00241bed8}] [] [{kube-controller-manager Update v1 2023-08-22 03:52:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"55905dda-b2f5-4977-ba3e-f3e39dc19ec8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 03:52:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.3.8\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s9q49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s9q49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:10.100.3.8,StartTime:2023-08-22 03:52:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 03:52:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://5d0083b32909473970a53948ceaeba283a03d6118a499f76867cce134479d9d2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.3.8,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 22 03:52:19.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3662" for this suite. 08/22/23 03:52:19.322
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":5,"skipped":61,"failed":0}
------------------------------
â€¢ [SLOW TEST] [25.101 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:51:54.226
    Aug 22 03:51:54.226: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename deployment 08/22/23 03:51:54.227
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:51:54.24
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:51:54.244
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Aug 22 03:51:54.248: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Aug 22 03:51:54.259: INFO: Pod name sample-pod: Found 0 pods out of 1
    Aug 22 03:51:59.262: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/22/23 03:51:59.262
    Aug 22 03:51:59.262: INFO: Waiting up to 5m0s for pod "test-rolling-update-controller-656dj" in namespace "deployment-3662" to be "running"
    Aug 22 03:51:59.266: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 3.71564ms
    Aug 22 03:52:01.386: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123876776s
    Aug 22 03:52:03.271: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00863931s
    Aug 22 03:52:05.272: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009487379s
    Aug 22 03:52:07.272: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009183252s
    Aug 22 03:52:09.271: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 10.008725959s
    Aug 22 03:52:11.270: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 12.0078919s
    Aug 22 03:52:13.271: INFO: Pod "test-rolling-update-controller-656dj": Phase="Pending", Reason="", readiness=false. Elapsed: 14.008510402s
    Aug 22 03:52:15.271: INFO: Pod "test-rolling-update-controller-656dj": Phase="Running", Reason="", readiness=true. Elapsed: 16.008463868s
    Aug 22 03:52:15.271: INFO: Pod "test-rolling-update-controller-656dj" satisfied condition "running"
    Aug 22 03:52:15.271: INFO: Creating deployment "test-rolling-update-deployment"
    Aug 22 03:52:15.279: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Aug 22 03:52:15.289: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Aug 22 03:52:17.296: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Aug 22 03:52:17.298: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 52, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 52, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 52, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 52, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:52:19.303: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 22 03:52:19.311: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3662  01e2e076-9ef3-41a5-99aa-dd28a76d28c8 1247327 1 2023-08-22 03:52:15 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-08-22 03:52:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 03:52:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00250b048 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-08-22 03:52:15 +0000 UTC,LastTransitionTime:2023-08-22 03:52:15 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-08-22 03:52:18 +0000 UTC,LastTransitionTime:2023-08-22 03:52:15 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Aug 22 03:52:19.314: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-3662  55905dda-b2f5-4977-ba3e-f3e39dc19ec8 1247317 1 2023-08-22 03:52:15 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 01e2e076-9ef3-41a5-99aa-dd28a76d28c8 0xc00241b9c7 0xc00241b9c8}] [] [{kube-controller-manager Update apps/v1 2023-08-22 03:52:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"01e2e076-9ef3-41a5-99aa-dd28a76d28c8\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 03:52:18 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00241ba78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Aug 22 03:52:19.314: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Aug 22 03:52:19.314: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3662  3b244148-a77b-46c0-b558-f8a4dce1a158 1247326 2 2023-08-22 03:51:54 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 01e2e076-9ef3-41a5-99aa-dd28a76d28c8 0xc00241b897 0xc00241b898}] [] [{e2e.test Update apps/v1 2023-08-22 03:51:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 03:52:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"01e2e076-9ef3-41a5-99aa-dd28a76d28c8\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-08-22 03:52:18 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00241b958 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 22 03:52:19.317: INFO: Pod "test-rolling-update-deployment-78f575d8ff-wmbzq" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-wmbzq test-rolling-update-deployment-78f575d8ff- deployment-3662  fe14ee8d-5b6c-4284-9123-fb8e077722fc 1247316 0 2023-08-22 03:52:15 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 55905dda-b2f5-4977-ba3e-f3e39dc19ec8 0xc00241bed7 0xc00241bed8}] [] [{kube-controller-manager Update v1 2023-08-22 03:52:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"55905dda-b2f5-4977-ba3e-f3e39dc19ec8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 03:52:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.3.8\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s9q49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s9q49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:10.100.3.8,StartTime:2023-08-22 03:52:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 03:52:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://5d0083b32909473970a53948ceaeba283a03d6118a499f76867cce134479d9d2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.3.8,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 22 03:52:19.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3662" for this suite. 08/22/23 03:52:19.322
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:52:19.331
Aug 22 03:52:19.331: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename containers 08/22/23 03:52:19.332
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:52:19.348
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:52:19.351
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 08/22/23 03:52:19.355
Aug 22 03:52:19.363: INFO: Waiting up to 5m0s for pod "client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c" in namespace "containers-6352" to be "Succeeded or Failed"
Aug 22 03:52:19.368: INFO: Pod "client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.024381ms
Aug 22 03:52:21.372: INFO: Pod "client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009012454s
Aug 22 03:52:23.373: INFO: Pod "client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009646342s
Aug 22 03:52:25.372: INFO: Pod "client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008910448s
STEP: Saw pod success 08/22/23 03:52:25.372
Aug 22 03:52:25.372: INFO: Pod "client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c" satisfied condition "Succeeded or Failed"
Aug 22 03:52:25.375: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c container agnhost-container: <nil>
STEP: delete the pod 08/22/23 03:52:25.38
Aug 22 03:52:25.762: INFO: Waiting for pod client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c to disappear
Aug 22 03:52:25.766: INFO: Pod client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Aug 22 03:52:25.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6352" for this suite. 08/22/23 03:52:25.771
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":6,"skipped":91,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.545 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:52:19.331
    Aug 22 03:52:19.331: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename containers 08/22/23 03:52:19.332
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:52:19.348
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:52:19.351
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 08/22/23 03:52:19.355
    Aug 22 03:52:19.363: INFO: Waiting up to 5m0s for pod "client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c" in namespace "containers-6352" to be "Succeeded or Failed"
    Aug 22 03:52:19.368: INFO: Pod "client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.024381ms
    Aug 22 03:52:21.372: INFO: Pod "client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009012454s
    Aug 22 03:52:23.373: INFO: Pod "client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009646342s
    Aug 22 03:52:25.372: INFO: Pod "client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008910448s
    STEP: Saw pod success 08/22/23 03:52:25.372
    Aug 22 03:52:25.372: INFO: Pod "client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c" satisfied condition "Succeeded or Failed"
    Aug 22 03:52:25.375: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 03:52:25.38
    Aug 22 03:52:25.762: INFO: Waiting for pod client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c to disappear
    Aug 22 03:52:25.766: INFO: Pod client-containers-5c8f02c6-8aca-4a0f-a6ae-e62854f0f65c no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Aug 22 03:52:25.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-6352" for this suite. 08/22/23 03:52:25.771
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:52:25.877
Aug 22 03:52:25.877: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename svcaccounts 08/22/23 03:52:25.878
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:52:25.916
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:52:25.919
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  08/22/23 03:52:25.923
Aug 22 03:52:25.932: INFO: Waiting up to 5m0s for pod "test-pod-316b3cea-be98-46db-9a81-44caf231186d" in namespace "svcaccounts-8363" to be "Succeeded or Failed"
Aug 22 03:52:25.936: INFO: Pod "test-pod-316b3cea-be98-46db-9a81-44caf231186d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.522848ms
Aug 22 03:52:27.941: INFO: Pod "test-pod-316b3cea-be98-46db-9a81-44caf231186d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00886718s
Aug 22 03:52:29.941: INFO: Pod "test-pod-316b3cea-be98-46db-9a81-44caf231186d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009371258s
Aug 22 03:52:32.085: INFO: Pod "test-pod-316b3cea-be98-46db-9a81-44caf231186d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.153098641s
STEP: Saw pod success 08/22/23 03:52:32.086
Aug 22 03:52:32.086: INFO: Pod "test-pod-316b3cea-be98-46db-9a81-44caf231186d" satisfied condition "Succeeded or Failed"
Aug 22 03:52:32.089: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod test-pod-316b3cea-be98-46db-9a81-44caf231186d container agnhost-container: <nil>
STEP: delete the pod 08/22/23 03:52:32.093
Aug 22 03:52:32.112: INFO: Waiting for pod test-pod-316b3cea-be98-46db-9a81-44caf231186d to disappear
Aug 22 03:52:32.115: INFO: Pod test-pod-316b3cea-be98-46db-9a81-44caf231186d no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 22 03:52:32.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8363" for this suite. 08/22/23 03:52:32.119
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":7,"skipped":94,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.249 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:52:25.877
    Aug 22 03:52:25.877: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename svcaccounts 08/22/23 03:52:25.878
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:52:25.916
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:52:25.919
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  08/22/23 03:52:25.923
    Aug 22 03:52:25.932: INFO: Waiting up to 5m0s for pod "test-pod-316b3cea-be98-46db-9a81-44caf231186d" in namespace "svcaccounts-8363" to be "Succeeded or Failed"
    Aug 22 03:52:25.936: INFO: Pod "test-pod-316b3cea-be98-46db-9a81-44caf231186d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.522848ms
    Aug 22 03:52:27.941: INFO: Pod "test-pod-316b3cea-be98-46db-9a81-44caf231186d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00886718s
    Aug 22 03:52:29.941: INFO: Pod "test-pod-316b3cea-be98-46db-9a81-44caf231186d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009371258s
    Aug 22 03:52:32.085: INFO: Pod "test-pod-316b3cea-be98-46db-9a81-44caf231186d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.153098641s
    STEP: Saw pod success 08/22/23 03:52:32.086
    Aug 22 03:52:32.086: INFO: Pod "test-pod-316b3cea-be98-46db-9a81-44caf231186d" satisfied condition "Succeeded or Failed"
    Aug 22 03:52:32.089: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod test-pod-316b3cea-be98-46db-9a81-44caf231186d container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 03:52:32.093
    Aug 22 03:52:32.112: INFO: Waiting for pod test-pod-316b3cea-be98-46db-9a81-44caf231186d to disappear
    Aug 22 03:52:32.115: INFO: Pod test-pod-316b3cea-be98-46db-9a81-44caf231186d no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 22 03:52:32.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8363" for this suite. 08/22/23 03:52:32.119
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:52:32.127
Aug 22 03:52:32.127: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 03:52:32.128
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:52:32.172
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:52:32.176
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 08/22/23 03:52:32.179
Aug 22 03:52:32.189: INFO: Waiting up to 5m0s for pod "pod-972e7956-31bc-420c-99a9-58e12ff41dec" in namespace "emptydir-6534" to be "Succeeded or Failed"
Aug 22 03:52:32.195: INFO: Pod "pod-972e7956-31bc-420c-99a9-58e12ff41dec": Phase="Pending", Reason="", readiness=false. Elapsed: 5.450479ms
Aug 22 03:52:34.211: INFO: Pod "pod-972e7956-31bc-420c-99a9-58e12ff41dec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021422928s
Aug 22 03:52:36.200: INFO: Pod "pod-972e7956-31bc-420c-99a9-58e12ff41dec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011353455s
Aug 22 03:52:38.199: INFO: Pod "pod-972e7956-31bc-420c-99a9-58e12ff41dec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010235301s
STEP: Saw pod success 08/22/23 03:52:38.199
Aug 22 03:52:38.200: INFO: Pod "pod-972e7956-31bc-420c-99a9-58e12ff41dec" satisfied condition "Succeeded or Failed"
Aug 22 03:52:38.203: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-972e7956-31bc-420c-99a9-58e12ff41dec container test-container: <nil>
STEP: delete the pod 08/22/23 03:52:38.21
Aug 22 03:52:38.409: INFO: Waiting for pod pod-972e7956-31bc-420c-99a9-58e12ff41dec to disappear
Aug 22 03:52:38.413: INFO: Pod pod-972e7956-31bc-420c-99a9-58e12ff41dec no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 03:52:38.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6534" for this suite. 08/22/23 03:52:38.417
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":8,"skipped":103,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.299 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:52:32.127
    Aug 22 03:52:32.127: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 03:52:32.128
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:52:32.172
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:52:32.176
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 08/22/23 03:52:32.179
    Aug 22 03:52:32.189: INFO: Waiting up to 5m0s for pod "pod-972e7956-31bc-420c-99a9-58e12ff41dec" in namespace "emptydir-6534" to be "Succeeded or Failed"
    Aug 22 03:52:32.195: INFO: Pod "pod-972e7956-31bc-420c-99a9-58e12ff41dec": Phase="Pending", Reason="", readiness=false. Elapsed: 5.450479ms
    Aug 22 03:52:34.211: INFO: Pod "pod-972e7956-31bc-420c-99a9-58e12ff41dec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021422928s
    Aug 22 03:52:36.200: INFO: Pod "pod-972e7956-31bc-420c-99a9-58e12ff41dec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011353455s
    Aug 22 03:52:38.199: INFO: Pod "pod-972e7956-31bc-420c-99a9-58e12ff41dec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010235301s
    STEP: Saw pod success 08/22/23 03:52:38.199
    Aug 22 03:52:38.200: INFO: Pod "pod-972e7956-31bc-420c-99a9-58e12ff41dec" satisfied condition "Succeeded or Failed"
    Aug 22 03:52:38.203: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-972e7956-31bc-420c-99a9-58e12ff41dec container test-container: <nil>
    STEP: delete the pod 08/22/23 03:52:38.21
    Aug 22 03:52:38.409: INFO: Waiting for pod pod-972e7956-31bc-420c-99a9-58e12ff41dec to disappear
    Aug 22 03:52:38.413: INFO: Pod pod-972e7956-31bc-420c-99a9-58e12ff41dec no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 03:52:38.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6534" for this suite. 08/22/23 03:52:38.417
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:52:38.427
Aug 22 03:52:38.427: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename deployment 08/22/23 03:52:38.427
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:52:38.444
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:52:38.448
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 08/22/23 03:52:38.455
Aug 22 03:52:38.456: INFO: Creating simple deployment test-deployment-wbgmr
Aug 22 03:52:38.470: INFO: new replicaset for deployment "test-deployment-wbgmr" is yet to be created
Aug 22 03:52:40.481: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 52, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 52, 38, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 52, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 52, 38, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-wbgmr-777898ffcc\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Getting /status 08/22/23 03:52:42.655
Aug 22 03:52:42.774: INFO: Deployment test-deployment-wbgmr has Conditions: [{Available True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wbgmr-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 08/22/23 03:52:42.774
Aug 22 03:52:42.978: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 52, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 52, 41, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 52, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 52, 38, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-wbgmr-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 08/22/23 03:52:42.978
Aug 22 03:52:42.981: INFO: Observed &Deployment event: ADDED
Aug 22 03:52:42.981: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wbgmr-777898ffcc"}
Aug 22 03:52:42.982: INFO: Observed &Deployment event: MODIFIED
Aug 22 03:52:42.982: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wbgmr-777898ffcc"}
Aug 22 03:52:42.982: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 22 03:52:42.982: INFO: Observed &Deployment event: MODIFIED
Aug 22 03:52:42.982: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 22 03:52:42.982: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-wbgmr-777898ffcc" is progressing.}
Aug 22 03:52:42.982: INFO: Observed &Deployment event: MODIFIED
Aug 22 03:52:42.982: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 22 03:52:42.982: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wbgmr-777898ffcc" has successfully progressed.}
Aug 22 03:52:42.983: INFO: Observed &Deployment event: MODIFIED
Aug 22 03:52:42.983: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 22 03:52:42.983: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wbgmr-777898ffcc" has successfully progressed.}
Aug 22 03:52:42.983: INFO: Found Deployment test-deployment-wbgmr in namespace deployment-3656 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 22 03:52:42.983: INFO: Deployment test-deployment-wbgmr has an updated status
STEP: patching the Statefulset Status 08/22/23 03:52:42.983
Aug 22 03:52:42.983: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug 22 03:52:43.024: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 08/22/23 03:52:43.025
Aug 22 03:52:43.027: INFO: Observed &Deployment event: ADDED
Aug 22 03:52:43.027: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wbgmr-777898ffcc"}
Aug 22 03:52:43.027: INFO: Observed &Deployment event: MODIFIED
Aug 22 03:52:43.027: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wbgmr-777898ffcc"}
Aug 22 03:52:43.027: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 22 03:52:43.027: INFO: Observed &Deployment event: MODIFIED
Aug 22 03:52:43.027: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 22 03:52:43.027: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-wbgmr-777898ffcc" is progressing.}
Aug 22 03:52:43.027: INFO: Observed &Deployment event: MODIFIED
Aug 22 03:52:43.028: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 22 03:52:43.028: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wbgmr-777898ffcc" has successfully progressed.}
Aug 22 03:52:43.028: INFO: Observed &Deployment event: MODIFIED
Aug 22 03:52:43.028: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 22 03:52:43.028: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wbgmr-777898ffcc" has successfully progressed.}
Aug 22 03:52:43.028: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 22 03:52:43.028: INFO: Observed &Deployment event: MODIFIED
Aug 22 03:52:43.028: INFO: Found deployment test-deployment-wbgmr in namespace deployment-3656 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Aug 22 03:52:43.028: INFO: Deployment test-deployment-wbgmr has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 22 03:52:43.035: INFO: Deployment "test-deployment-wbgmr":
&Deployment{ObjectMeta:{test-deployment-wbgmr  deployment-3656  29f9ae73-e866-4ed7-8c4b-f38019ec1292 1247519 1 2023-08-22 03:52:38 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-08-22 03:52:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-08-22 03:52:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-08-22 03:52:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032dab88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-wbgmr-777898ffcc",LastUpdateTime:2023-08-22 03:52:43 +0000 UTC,LastTransitionTime:2023-08-22 03:52:43 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 22 03:52:43.038: INFO: New ReplicaSet "test-deployment-wbgmr-777898ffcc" of Deployment "test-deployment-wbgmr":
&ReplicaSet{ObjectMeta:{test-deployment-wbgmr-777898ffcc  deployment-3656  020a3657-48c7-4b15-9ed9-4803e0f3077b 1247510 1 2023-08-22 03:52:38 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-wbgmr 29f9ae73-e866-4ed7-8c4b-f38019ec1292 0xc003397dd7 0xc003397dd8}] [] [{kube-controller-manager Update apps/v1 2023-08-22 03:52:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"29f9ae73-e866-4ed7-8c4b-f38019ec1292\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 03:52:41 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003397e88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 22 03:52:43.042: INFO: Pod "test-deployment-wbgmr-777898ffcc-vps5p" is available:
&Pod{ObjectMeta:{test-deployment-wbgmr-777898ffcc-vps5p test-deployment-wbgmr-777898ffcc- deployment-3656  1ea04eb9-f52e-4d0e-a38b-61f265536e02 1247509 0 2023-08-22 03:52:38 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-wbgmr-777898ffcc 020a3657-48c7-4b15-9ed9-4803e0f3077b 0xc0032daf67 0xc0032daf68}] [] [{kube-controller-manager Update v1 2023-08-22 03:52:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"020a3657-48c7-4b15-9ed9-4803e0f3077b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 03:52:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.12\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-84l28,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-84l28,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:10.100.4.12,StartTime:2023-08-22 03:52:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 03:52:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b90f3c676c6af8ad4520a07bff356d727e1169bf036bea40d6c833d07cd28b43,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.4.12,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 22 03:52:43.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3656" for this suite. 08/22/23 03:52:43.046
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":9,"skipped":115,"failed":0}
------------------------------
â€¢ [4.625 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:52:38.427
    Aug 22 03:52:38.427: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename deployment 08/22/23 03:52:38.427
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:52:38.444
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:52:38.448
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 08/22/23 03:52:38.455
    Aug 22 03:52:38.456: INFO: Creating simple deployment test-deployment-wbgmr
    Aug 22 03:52:38.470: INFO: new replicaset for deployment "test-deployment-wbgmr" is yet to be created
    Aug 22 03:52:40.481: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 52, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 52, 38, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 52, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 52, 38, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-wbgmr-777898ffcc\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Getting /status 08/22/23 03:52:42.655
    Aug 22 03:52:42.774: INFO: Deployment test-deployment-wbgmr has Conditions: [{Available True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wbgmr-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 08/22/23 03:52:42.774
    Aug 22 03:52:42.978: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 52, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 52, 41, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 52, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 52, 38, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-wbgmr-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 08/22/23 03:52:42.978
    Aug 22 03:52:42.981: INFO: Observed &Deployment event: ADDED
    Aug 22 03:52:42.981: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wbgmr-777898ffcc"}
    Aug 22 03:52:42.982: INFO: Observed &Deployment event: MODIFIED
    Aug 22 03:52:42.982: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wbgmr-777898ffcc"}
    Aug 22 03:52:42.982: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Aug 22 03:52:42.982: INFO: Observed &Deployment event: MODIFIED
    Aug 22 03:52:42.982: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Aug 22 03:52:42.982: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-wbgmr-777898ffcc" is progressing.}
    Aug 22 03:52:42.982: INFO: Observed &Deployment event: MODIFIED
    Aug 22 03:52:42.982: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Aug 22 03:52:42.982: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wbgmr-777898ffcc" has successfully progressed.}
    Aug 22 03:52:42.983: INFO: Observed &Deployment event: MODIFIED
    Aug 22 03:52:42.983: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Aug 22 03:52:42.983: INFO: Observed Deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wbgmr-777898ffcc" has successfully progressed.}
    Aug 22 03:52:42.983: INFO: Found Deployment test-deployment-wbgmr in namespace deployment-3656 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Aug 22 03:52:42.983: INFO: Deployment test-deployment-wbgmr has an updated status
    STEP: patching the Statefulset Status 08/22/23 03:52:42.983
    Aug 22 03:52:42.983: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Aug 22 03:52:43.024: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 08/22/23 03:52:43.025
    Aug 22 03:52:43.027: INFO: Observed &Deployment event: ADDED
    Aug 22 03:52:43.027: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wbgmr-777898ffcc"}
    Aug 22 03:52:43.027: INFO: Observed &Deployment event: MODIFIED
    Aug 22 03:52:43.027: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wbgmr-777898ffcc"}
    Aug 22 03:52:43.027: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Aug 22 03:52:43.027: INFO: Observed &Deployment event: MODIFIED
    Aug 22 03:52:43.027: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Aug 22 03:52:43.027: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:38 +0000 UTC 2023-08-22 03:52:38 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-wbgmr-777898ffcc" is progressing.}
    Aug 22 03:52:43.027: INFO: Observed &Deployment event: MODIFIED
    Aug 22 03:52:43.028: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Aug 22 03:52:43.028: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wbgmr-777898ffcc" has successfully progressed.}
    Aug 22 03:52:43.028: INFO: Observed &Deployment event: MODIFIED
    Aug 22 03:52:43.028: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:41 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Aug 22 03:52:43.028: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-08-22 03:52:41 +0000 UTC 2023-08-22 03:52:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wbgmr-777898ffcc" has successfully progressed.}
    Aug 22 03:52:43.028: INFO: Observed deployment test-deployment-wbgmr in namespace deployment-3656 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Aug 22 03:52:43.028: INFO: Observed &Deployment event: MODIFIED
    Aug 22 03:52:43.028: INFO: Found deployment test-deployment-wbgmr in namespace deployment-3656 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Aug 22 03:52:43.028: INFO: Deployment test-deployment-wbgmr has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 22 03:52:43.035: INFO: Deployment "test-deployment-wbgmr":
    &Deployment{ObjectMeta:{test-deployment-wbgmr  deployment-3656  29f9ae73-e866-4ed7-8c4b-f38019ec1292 1247519 1 2023-08-22 03:52:38 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-08-22 03:52:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-08-22 03:52:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-08-22 03:52:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032dab88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-wbgmr-777898ffcc",LastUpdateTime:2023-08-22 03:52:43 +0000 UTC,LastTransitionTime:2023-08-22 03:52:43 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Aug 22 03:52:43.038: INFO: New ReplicaSet "test-deployment-wbgmr-777898ffcc" of Deployment "test-deployment-wbgmr":
    &ReplicaSet{ObjectMeta:{test-deployment-wbgmr-777898ffcc  deployment-3656  020a3657-48c7-4b15-9ed9-4803e0f3077b 1247510 1 2023-08-22 03:52:38 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-wbgmr 29f9ae73-e866-4ed7-8c4b-f38019ec1292 0xc003397dd7 0xc003397dd8}] [] [{kube-controller-manager Update apps/v1 2023-08-22 03:52:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"29f9ae73-e866-4ed7-8c4b-f38019ec1292\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 03:52:41 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003397e88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Aug 22 03:52:43.042: INFO: Pod "test-deployment-wbgmr-777898ffcc-vps5p" is available:
    &Pod{ObjectMeta:{test-deployment-wbgmr-777898ffcc-vps5p test-deployment-wbgmr-777898ffcc- deployment-3656  1ea04eb9-f52e-4d0e-a38b-61f265536e02 1247509 0 2023-08-22 03:52:38 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-wbgmr-777898ffcc 020a3657-48c7-4b15-9ed9-4803e0f3077b 0xc0032daf67 0xc0032daf68}] [] [{kube-controller-manager Update v1 2023-08-22 03:52:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"020a3657-48c7-4b15-9ed9-4803e0f3077b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 03:52:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.12\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-84l28,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-84l28,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 03:52:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:10.100.4.12,StartTime:2023-08-22 03:52:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 03:52:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b90f3c676c6af8ad4520a07bff356d727e1169bf036bea40d6c833d07cd28b43,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.4.12,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 22 03:52:43.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3656" for this suite. 08/22/23 03:52:43.046
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:52:43.056
Aug 22 03:52:43.056: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pod-network-test 08/22/23 03:52:43.057
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:52:43.07
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:52:43.073
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-1275 08/22/23 03:52:43.077
STEP: creating a selector 08/22/23 03:52:43.078
STEP: Creating the service pods in kubernetes 08/22/23 03:52:43.078
Aug 22 03:52:43.078: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 22 03:52:43.102: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1275" to be "running and ready"
Aug 22 03:52:43.106: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.803805ms
Aug 22 03:52:43.106: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:52:45.111: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009165507s
Aug 22 03:52:45.111: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:52:47.179: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.076217941s
Aug 22 03:52:47.179: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 03:52:49.110: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.007907706s
Aug 22 03:52:49.110: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 03:52:51.112: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.009851886s
Aug 22 03:52:51.112: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 03:52:53.360: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.258000159s
Aug 22 03:52:53.360: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 03:52:55.116: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.013932117s
Aug 22 03:52:55.116: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 03:52:57.111: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.008919008s
Aug 22 03:52:57.111: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 03:52:59.110: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.007806925s
Aug 22 03:52:59.110: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 03:53:01.112: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.009238684s
Aug 22 03:53:01.112: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 03:53:03.110: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.007336519s
Aug 22 03:53:03.110: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 03:53:05.111: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.008335577s
Aug 22 03:53:05.111: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Aug 22 03:53:05.111: INFO: Pod "netserver-0" satisfied condition "running and ready"
Aug 22 03:53:05.113: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1275" to be "running and ready"
Aug 22 03:53:05.116: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.565528ms
Aug 22 03:53:05.116: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Aug 22 03:53:05.116: INFO: Pod "netserver-1" satisfied condition "running and ready"
Aug 22 03:53:05.119: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-1275" to be "running and ready"
Aug 22 03:53:05.121: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.634582ms
Aug 22 03:53:05.121: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Aug 22 03:53:05.121: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 08/22/23 03:53:05.123
Aug 22 03:53:05.137: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1275" to be "running"
Aug 22 03:53:05.141: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.702375ms
Aug 22 03:53:07.146: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008549152s
Aug 22 03:53:09.145: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.007591801s
Aug 22 03:53:09.145: INFO: Pod "test-container-pod" satisfied condition "running"
Aug 22 03:53:09.147: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1275" to be "running"
Aug 22 03:53:09.151: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.126154ms
Aug 22 03:53:09.151: INFO: Pod "host-test-container-pod" satisfied condition "running"
Aug 22 03:53:09.153: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Aug 22 03:53:09.153: INFO: Going to poll 10.100.3.9 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Aug 22 03:53:09.154: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.100.3.9 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1275 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 03:53:09.154: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 03:53:09.155: INFO: ExecWithOptions: Clientset creation
Aug 22 03:53:09.155: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-1275/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.100.3.9+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 22 03:53:10.261: INFO: Found all 1 expected endpoints: [netserver-0]
Aug 22 03:53:10.261: INFO: Going to poll 10.100.5.4 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Aug 22 03:53:10.266: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.100.5.4 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1275 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 03:53:10.266: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 03:53:10.266: INFO: ExecWithOptions: Clientset creation
Aug 22 03:53:10.266: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-1275/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.100.5.4+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 22 03:53:11.343: INFO: Found all 1 expected endpoints: [netserver-1]
Aug 22 03:53:11.343: INFO: Going to poll 10.100.4.13 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Aug 22 03:53:11.346: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.100.4.13 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1275 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 03:53:11.346: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 03:53:11.347: INFO: ExecWithOptions: Clientset creation
Aug 22 03:53:11.347: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-1275/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.100.4.13+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 22 03:53:12.423: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Aug 22 03:53:12.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1275" for this suite. 08/22/23 03:53:12.43
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":10,"skipped":144,"failed":0}
------------------------------
â€¢ [SLOW TEST] [29.381 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:52:43.056
    Aug 22 03:52:43.056: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pod-network-test 08/22/23 03:52:43.057
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:52:43.07
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:52:43.073
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-1275 08/22/23 03:52:43.077
    STEP: creating a selector 08/22/23 03:52:43.078
    STEP: Creating the service pods in kubernetes 08/22/23 03:52:43.078
    Aug 22 03:52:43.078: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Aug 22 03:52:43.102: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1275" to be "running and ready"
    Aug 22 03:52:43.106: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.803805ms
    Aug 22 03:52:43.106: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:52:45.111: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009165507s
    Aug 22 03:52:45.111: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:52:47.179: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.076217941s
    Aug 22 03:52:47.179: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 03:52:49.110: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.007907706s
    Aug 22 03:52:49.110: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 03:52:51.112: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.009851886s
    Aug 22 03:52:51.112: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 03:52:53.360: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.258000159s
    Aug 22 03:52:53.360: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 03:52:55.116: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.013932117s
    Aug 22 03:52:55.116: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 03:52:57.111: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.008919008s
    Aug 22 03:52:57.111: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 03:52:59.110: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.007806925s
    Aug 22 03:52:59.110: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 03:53:01.112: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.009238684s
    Aug 22 03:53:01.112: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 03:53:03.110: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.007336519s
    Aug 22 03:53:03.110: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 03:53:05.111: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.008335577s
    Aug 22 03:53:05.111: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Aug 22 03:53:05.111: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Aug 22 03:53:05.113: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1275" to be "running and ready"
    Aug 22 03:53:05.116: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.565528ms
    Aug 22 03:53:05.116: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Aug 22 03:53:05.116: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Aug 22 03:53:05.119: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-1275" to be "running and ready"
    Aug 22 03:53:05.121: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.634582ms
    Aug 22 03:53:05.121: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Aug 22 03:53:05.121: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 08/22/23 03:53:05.123
    Aug 22 03:53:05.137: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1275" to be "running"
    Aug 22 03:53:05.141: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.702375ms
    Aug 22 03:53:07.146: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008549152s
    Aug 22 03:53:09.145: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.007591801s
    Aug 22 03:53:09.145: INFO: Pod "test-container-pod" satisfied condition "running"
    Aug 22 03:53:09.147: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1275" to be "running"
    Aug 22 03:53:09.151: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.126154ms
    Aug 22 03:53:09.151: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Aug 22 03:53:09.153: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Aug 22 03:53:09.153: INFO: Going to poll 10.100.3.9 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Aug 22 03:53:09.154: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.100.3.9 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1275 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 03:53:09.154: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 03:53:09.155: INFO: ExecWithOptions: Clientset creation
    Aug 22 03:53:09.155: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-1275/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.100.3.9+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 22 03:53:10.261: INFO: Found all 1 expected endpoints: [netserver-0]
    Aug 22 03:53:10.261: INFO: Going to poll 10.100.5.4 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Aug 22 03:53:10.266: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.100.5.4 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1275 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 03:53:10.266: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 03:53:10.266: INFO: ExecWithOptions: Clientset creation
    Aug 22 03:53:10.266: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-1275/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.100.5.4+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 22 03:53:11.343: INFO: Found all 1 expected endpoints: [netserver-1]
    Aug 22 03:53:11.343: INFO: Going to poll 10.100.4.13 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Aug 22 03:53:11.346: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.100.4.13 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1275 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 03:53:11.346: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 03:53:11.347: INFO: ExecWithOptions: Clientset creation
    Aug 22 03:53:11.347: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-1275/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.100.4.13+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 22 03:53:12.423: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Aug 22 03:53:12.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-1275" for this suite. 08/22/23 03:53:12.43
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:53:12.439
Aug 22 03:53:12.439: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 03:53:12.44
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:53:12.493
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:53:12.496
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 08/22/23 03:53:12.5
Aug 22 03:53:12.501: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 08/22/23 03:53:22.637
Aug 22 03:53:22.639: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 03:53:24.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 03:53:35.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6735" for this suite. 08/22/23 03:53:35.841
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":11,"skipped":170,"failed":0}
------------------------------
â€¢ [SLOW TEST] [23.601 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:53:12.439
    Aug 22 03:53:12.439: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 03:53:12.44
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:53:12.493
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:53:12.496
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 08/22/23 03:53:12.5
    Aug 22 03:53:12.501: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 08/22/23 03:53:22.637
    Aug 22 03:53:22.639: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 03:53:24.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 03:53:35.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6735" for this suite. 08/22/23 03:53:35.841
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:53:36.041
Aug 22 03:53:36.041: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename hostport 08/22/23 03:53:36.042
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:53:36.07
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:53:36.073
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 08/22/23 03:53:36.079
Aug 22 03:53:36.109: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-416" to be "running and ready"
Aug 22 03:53:36.113: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.959628ms
Aug 22 03:53:36.113: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:53:38.256: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.146137055s
Aug 22 03:53:38.256: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:53:40.117: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.007770644s
Aug 22 03:53:40.117: INFO: The phase of Pod pod1 is Running (Ready = true)
Aug 22 03:53:40.117: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.0.0.130 on the node which pod1 resides and expect scheduled 08/22/23 03:53:40.117
Aug 22 03:53:40.122: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-416" to be "running and ready"
Aug 22 03:53:40.127: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.863732ms
Aug 22 03:53:40.127: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:53:42.131: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00900847s
Aug 22 03:53:42.131: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:53:44.416: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.294306269s
Aug 22 03:53:44.417: INFO: The phase of Pod pod2 is Running (Ready = true)
Aug 22 03:53:44.417: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.0.0.130 but use UDP protocol on the node which pod2 resides 08/22/23 03:53:44.417
Aug 22 03:53:44.461: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-416" to be "running and ready"
Aug 22 03:53:44.464: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.894109ms
Aug 22 03:53:44.464: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:53:46.468: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006415037s
Aug 22 03:53:46.468: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:53:48.469: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.007611585s
Aug 22 03:53:48.469: INFO: The phase of Pod pod3 is Running (Ready = true)
Aug 22 03:53:48.469: INFO: Pod "pod3" satisfied condition "running and ready"
Aug 22 03:53:48.477: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-416" to be "running and ready"
Aug 22 03:53:48.484: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.735161ms
Aug 22 03:53:48.484: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:53:50.490: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.013167122s
Aug 22 03:53:50.490: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Aug 22 03:53:50.490: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 08/22/23 03:53:50.492
Aug 22 03:53:50.492: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.0.0.130 http://127.0.0.1:54323/hostname] Namespace:hostport-416 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 03:53:50.493: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 03:53:50.493: INFO: ExecWithOptions: Clientset creation
Aug 22 03:53:50.493: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/hostport-416/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.0.0.130+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.0.0.130, port: 54323 08/22/23 03:53:50.581
Aug 22 03:53:50.581: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.0.0.130:54323/hostname] Namespace:hostport-416 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 03:53:50.581: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 03:53:50.581: INFO: ExecWithOptions: Clientset creation
Aug 22 03:53:50.581: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/hostport-416/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.0.0.130%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.0.0.130, port: 54323 UDP 08/22/23 03:53:50.848
Aug 22 03:53:50.849: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.0.0.130 54323] Namespace:hostport-416 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 03:53:50.849: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 03:53:50.849: INFO: ExecWithOptions: Clientset creation
Aug 22 03:53:50.849: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/hostport-416/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.0.0.130+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Aug 22 03:53:55.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-416" for this suite. 08/22/23 03:53:55.93
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":12,"skipped":189,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.092 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:53:36.041
    Aug 22 03:53:36.041: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename hostport 08/22/23 03:53:36.042
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:53:36.07
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:53:36.073
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 08/22/23 03:53:36.079
    Aug 22 03:53:36.109: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-416" to be "running and ready"
    Aug 22 03:53:36.113: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.959628ms
    Aug 22 03:53:36.113: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:53:38.256: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.146137055s
    Aug 22 03:53:38.256: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:53:40.117: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.007770644s
    Aug 22 03:53:40.117: INFO: The phase of Pod pod1 is Running (Ready = true)
    Aug 22 03:53:40.117: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.0.0.130 on the node which pod1 resides and expect scheduled 08/22/23 03:53:40.117
    Aug 22 03:53:40.122: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-416" to be "running and ready"
    Aug 22 03:53:40.127: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.863732ms
    Aug 22 03:53:40.127: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:53:42.131: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00900847s
    Aug 22 03:53:42.131: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:53:44.416: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.294306269s
    Aug 22 03:53:44.417: INFO: The phase of Pod pod2 is Running (Ready = true)
    Aug 22 03:53:44.417: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.0.0.130 but use UDP protocol on the node which pod2 resides 08/22/23 03:53:44.417
    Aug 22 03:53:44.461: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-416" to be "running and ready"
    Aug 22 03:53:44.464: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.894109ms
    Aug 22 03:53:44.464: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:53:46.468: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006415037s
    Aug 22 03:53:46.468: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:53:48.469: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.007611585s
    Aug 22 03:53:48.469: INFO: The phase of Pod pod3 is Running (Ready = true)
    Aug 22 03:53:48.469: INFO: Pod "pod3" satisfied condition "running and ready"
    Aug 22 03:53:48.477: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-416" to be "running and ready"
    Aug 22 03:53:48.484: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.735161ms
    Aug 22 03:53:48.484: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:53:50.490: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.013167122s
    Aug 22 03:53:50.490: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Aug 22 03:53:50.490: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 08/22/23 03:53:50.492
    Aug 22 03:53:50.492: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.0.0.130 http://127.0.0.1:54323/hostname] Namespace:hostport-416 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 03:53:50.493: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 03:53:50.493: INFO: ExecWithOptions: Clientset creation
    Aug 22 03:53:50.493: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/hostport-416/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.0.0.130+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.0.0.130, port: 54323 08/22/23 03:53:50.581
    Aug 22 03:53:50.581: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.0.0.130:54323/hostname] Namespace:hostport-416 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 03:53:50.581: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 03:53:50.581: INFO: ExecWithOptions: Clientset creation
    Aug 22 03:53:50.581: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/hostport-416/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.0.0.130%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.0.0.130, port: 54323 UDP 08/22/23 03:53:50.848
    Aug 22 03:53:50.849: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.0.0.130 54323] Namespace:hostport-416 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 03:53:50.849: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 03:53:50.849: INFO: ExecWithOptions: Clientset creation
    Aug 22 03:53:50.849: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/hostport-416/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.0.0.130+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Aug 22 03:53:55.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-416" for this suite. 08/22/23 03:53:55.93
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:53:56.134
Aug 22 03:53:56.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 03:53:56.134
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:53:56.158
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:53:56.161
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-880f1e77-fe8c-423b-aa80-9c56582e6ad5 08/22/23 03:53:56.165
STEP: Creating secret with name secret-projected-all-test-volume-1ab2a3f6-05f4-4d09-80e1-482d17262a9b 08/22/23 03:53:56.17
STEP: Creating a pod to test Check all projections for projected volume plugin 08/22/23 03:53:56.177
Aug 22 03:53:56.187: INFO: Waiting up to 5m0s for pod "projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971" in namespace "projected-4142" to be "Succeeded or Failed"
Aug 22 03:53:56.199: INFO: Pod "projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971": Phase="Pending", Reason="", readiness=false. Elapsed: 12.110842ms
Aug 22 03:53:58.202: INFO: Pod "projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015725822s
Aug 22 03:54:00.204: INFO: Pod "projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017342472s
Aug 22 03:54:02.203: INFO: Pod "projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016010381s
STEP: Saw pod success 08/22/23 03:54:02.203
Aug 22 03:54:02.203: INFO: Pod "projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971" satisfied condition "Succeeded or Failed"
Aug 22 03:54:02.205: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971 container projected-all-volume-test: <nil>
STEP: delete the pod 08/22/23 03:54:02.232
Aug 22 03:54:02.519: INFO: Waiting for pod projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971 to disappear
Aug 22 03:54:02.522: INFO: Pod projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Aug 22 03:54:02.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4142" for this suite. 08/22/23 03:54:02.526
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":13,"skipped":197,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.452 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:53:56.134
    Aug 22 03:53:56.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 03:53:56.134
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:53:56.158
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:53:56.161
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-880f1e77-fe8c-423b-aa80-9c56582e6ad5 08/22/23 03:53:56.165
    STEP: Creating secret with name secret-projected-all-test-volume-1ab2a3f6-05f4-4d09-80e1-482d17262a9b 08/22/23 03:53:56.17
    STEP: Creating a pod to test Check all projections for projected volume plugin 08/22/23 03:53:56.177
    Aug 22 03:53:56.187: INFO: Waiting up to 5m0s for pod "projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971" in namespace "projected-4142" to be "Succeeded or Failed"
    Aug 22 03:53:56.199: INFO: Pod "projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971": Phase="Pending", Reason="", readiness=false. Elapsed: 12.110842ms
    Aug 22 03:53:58.202: INFO: Pod "projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015725822s
    Aug 22 03:54:00.204: INFO: Pod "projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017342472s
    Aug 22 03:54:02.203: INFO: Pod "projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016010381s
    STEP: Saw pod success 08/22/23 03:54:02.203
    Aug 22 03:54:02.203: INFO: Pod "projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971" satisfied condition "Succeeded or Failed"
    Aug 22 03:54:02.205: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971 container projected-all-volume-test: <nil>
    STEP: delete the pod 08/22/23 03:54:02.232
    Aug 22 03:54:02.519: INFO: Waiting for pod projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971 to disappear
    Aug 22 03:54:02.522: INFO: Pod projected-volume-7cd316f0-0592-4e9c-bc7d-f61f027d4971 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Aug 22 03:54:02.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4142" for this suite. 08/22/23 03:54:02.526
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:54:02.587
Aug 22 03:54:02.587: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 03:54:02.587
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:54:02.712
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:54:02.715
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194
STEP: creating service in namespace services-4431 08/22/23 03:54:02.72
STEP: creating service affinity-nodeport in namespace services-4431 08/22/23 03:54:02.72
STEP: creating replication controller affinity-nodeport in namespace services-4431 08/22/23 03:54:02.951
I0822 03:54:02.987584      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-4431, replica count: 3
I0822 03:54:06.038146      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 03:54:09.038469      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 22 03:54:09.109: INFO: Creating new exec pod
Aug 22 03:54:09.121: INFO: Waiting up to 5m0s for pod "execpod-affinityhfr89" in namespace "services-4431" to be "running"
Aug 22 03:54:09.128: INFO: Pod "execpod-affinityhfr89": Phase="Pending", Reason="", readiness=false. Elapsed: 7.114262ms
Aug 22 03:54:11.134: INFO: Pod "execpod-affinityhfr89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01319319s
Aug 22 03:54:13.132: INFO: Pod "execpod-affinityhfr89": Phase="Running", Reason="", readiness=true. Elapsed: 4.011088643s
Aug 22 03:54:13.132: INFO: Pod "execpod-affinityhfr89" satisfied condition "running"
Aug 22 03:54:14.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-4431 exec execpod-affinityhfr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Aug 22 03:54:14.293: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport 80\n+ echo hostName\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Aug 22 03:54:14.293: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 03:54:14.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-4431 exec execpod-affinityhfr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.21.17 80'
Aug 22 03:54:14.421: INFO: stderr: "+ nc -v -t -w 2 10.254.21.17 80\n+ echo hostName\nConnection to 10.254.21.17 80 port [tcp/http] succeeded!\n"
Aug 22 03:54:14.422: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 03:54:14.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-4431 exec execpod-affinityhfr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.97 30321'
Aug 22 03:54:14.558: INFO: stderr: "+ + echo hostName\nnc -v -t -w 2 10.0.0.97 30321\nConnection to 10.0.0.97 30321 port [tcp/*] succeeded!\n"
Aug 22 03:54:14.558: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 03:54:14.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-4431 exec execpod-affinityhfr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.130 30321'
Aug 22 03:54:14.687: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.0.130 30321\nConnection to 10.0.0.130 30321 port [tcp/*] succeeded!\n"
Aug 22 03:54:14.687: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 03:54:14.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-4431 exec execpod-affinityhfr89 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.0.97:30321/ ; done'
Aug 22 03:54:14.883: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n"
Aug 22 03:54:14.883: INFO: stdout: "\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94"
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
Aug 22 03:54:14.883: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-4431, will wait for the garbage collector to delete the pods 08/22/23 03:54:15.114
Aug 22 03:54:15.177: INFO: Deleting ReplicationController affinity-nodeport took: 7.730248ms
Aug 22 03:54:15.378: INFO: Terminating ReplicationController affinity-nodeport pods took: 200.773559ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 03:54:17.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4431" for this suite. 08/22/23 03:54:17.526
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":14,"skipped":206,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.944 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:54:02.587
    Aug 22 03:54:02.587: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 03:54:02.587
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:54:02.712
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:54:02.715
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2194
    STEP: creating service in namespace services-4431 08/22/23 03:54:02.72
    STEP: creating service affinity-nodeport in namespace services-4431 08/22/23 03:54:02.72
    STEP: creating replication controller affinity-nodeport in namespace services-4431 08/22/23 03:54:02.951
    I0822 03:54:02.987584      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-4431, replica count: 3
    I0822 03:54:06.038146      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0822 03:54:09.038469      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 22 03:54:09.109: INFO: Creating new exec pod
    Aug 22 03:54:09.121: INFO: Waiting up to 5m0s for pod "execpod-affinityhfr89" in namespace "services-4431" to be "running"
    Aug 22 03:54:09.128: INFO: Pod "execpod-affinityhfr89": Phase="Pending", Reason="", readiness=false. Elapsed: 7.114262ms
    Aug 22 03:54:11.134: INFO: Pod "execpod-affinityhfr89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01319319s
    Aug 22 03:54:13.132: INFO: Pod "execpod-affinityhfr89": Phase="Running", Reason="", readiness=true. Elapsed: 4.011088643s
    Aug 22 03:54:13.132: INFO: Pod "execpod-affinityhfr89" satisfied condition "running"
    Aug 22 03:54:14.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-4431 exec execpod-affinityhfr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Aug 22 03:54:14.293: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport 80\n+ echo hostName\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Aug 22 03:54:14.293: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 03:54:14.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-4431 exec execpod-affinityhfr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.21.17 80'
    Aug 22 03:54:14.421: INFO: stderr: "+ nc -v -t -w 2 10.254.21.17 80\n+ echo hostName\nConnection to 10.254.21.17 80 port [tcp/http] succeeded!\n"
    Aug 22 03:54:14.422: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 03:54:14.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-4431 exec execpod-affinityhfr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.97 30321'
    Aug 22 03:54:14.558: INFO: stderr: "+ + echo hostName\nnc -v -t -w 2 10.0.0.97 30321\nConnection to 10.0.0.97 30321 port [tcp/*] succeeded!\n"
    Aug 22 03:54:14.558: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 03:54:14.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-4431 exec execpod-affinityhfr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.130 30321'
    Aug 22 03:54:14.687: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.0.130 30321\nConnection to 10.0.0.130 30321 port [tcp/*] succeeded!\n"
    Aug 22 03:54:14.687: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 03:54:14.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-4431 exec execpod-affinityhfr89 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.0.97:30321/ ; done'
    Aug 22 03:54:14.883: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30321/\n"
    Aug 22 03:54:14.883: INFO: stdout: "\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94\naffinity-nodeport-4sc94"
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Received response from host: affinity-nodeport-4sc94
    Aug 22 03:54:14.883: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-4431, will wait for the garbage collector to delete the pods 08/22/23 03:54:15.114
    Aug 22 03:54:15.177: INFO: Deleting ReplicationController affinity-nodeport took: 7.730248ms
    Aug 22 03:54:15.378: INFO: Terminating ReplicationController affinity-nodeport pods took: 200.773559ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 03:54:17.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4431" for this suite. 08/22/23 03:54:17.526
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:54:17.531
Aug 22 03:54:17.531: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pods 08/22/23 03:54:17.532
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:54:17.549
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:54:17.552
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 08/22/23 03:54:17.555
Aug 22 03:54:17.566: INFO: Waiting up to 5m0s for pod "pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a" in namespace "pods-8454" to be "running and ready"
Aug 22 03:54:17.574: INFO: Pod "pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.947043ms
Aug 22 03:54:17.574: INFO: The phase of Pod pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:54:19.578: INFO: Pod "pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011845143s
Aug 22 03:54:19.578: INFO: The phase of Pod pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:54:21.578: INFO: Pod "pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012437763s
Aug 22 03:54:21.578: INFO: The phase of Pod pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:54:23.648: INFO: Pod "pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.082336863s
Aug 22 03:54:23.648: INFO: The phase of Pod pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:54:25.579: INFO: Pod "pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a": Phase="Running", Reason="", readiness=true. Elapsed: 8.01362229s
Aug 22 03:54:25.580: INFO: The phase of Pod pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a is Running (Ready = true)
Aug 22 03:54:25.580: INFO: Pod "pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a" satisfied condition "running and ready"
Aug 22 03:54:25.584: INFO: Pod pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a has hostIP: 10.0.0.130
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 22 03:54:25.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8454" for this suite. 08/22/23 03:54:25.587
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":15,"skipped":208,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.070 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:54:17.531
    Aug 22 03:54:17.531: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pods 08/22/23 03:54:17.532
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:54:17.549
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:54:17.552
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 08/22/23 03:54:17.555
    Aug 22 03:54:17.566: INFO: Waiting up to 5m0s for pod "pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a" in namespace "pods-8454" to be "running and ready"
    Aug 22 03:54:17.574: INFO: Pod "pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.947043ms
    Aug 22 03:54:17.574: INFO: The phase of Pod pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:54:19.578: INFO: Pod "pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011845143s
    Aug 22 03:54:19.578: INFO: The phase of Pod pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:54:21.578: INFO: Pod "pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012437763s
    Aug 22 03:54:21.578: INFO: The phase of Pod pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:54:23.648: INFO: Pod "pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.082336863s
    Aug 22 03:54:23.648: INFO: The phase of Pod pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:54:25.579: INFO: Pod "pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a": Phase="Running", Reason="", readiness=true. Elapsed: 8.01362229s
    Aug 22 03:54:25.580: INFO: The phase of Pod pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a is Running (Ready = true)
    Aug 22 03:54:25.580: INFO: Pod "pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a" satisfied condition "running and ready"
    Aug 22 03:54:25.584: INFO: Pod pod-hostip-576a4c92-7aec-45c2-965a-f7808f66c43a has hostIP: 10.0.0.130
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 22 03:54:25.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8454" for this suite. 08/22/23 03:54:25.587
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:54:25.602
Aug 22 03:54:25.602: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 03:54:25.602
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:54:25.618
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:54:25.621
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 03:54:26.303
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 03:54:26.699
STEP: Deploying the webhook pod 08/22/23 03:54:26.71
STEP: Wait for the deployment to be ready 08/22/23 03:54:26.75
Aug 22 03:54:26.788: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 54, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 54, 26, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-5d85dd8cdb\""}}, CollisionCount:(*int32)(nil)}
Aug 22 03:54:28.792: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 54, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 54, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 54, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 54, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 03:54:30.912
STEP: Verifying the service has paired with the endpoint 08/22/23 03:54:30.948
Aug 22 03:54:31.948: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 08/22/23 03:54:31.958
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 08/22/23 03:54:31.959
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 08/22/23 03:54:31.959
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 08/22/23 03:54:31.959
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 08/22/23 03:54:31.961
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 08/22/23 03:54:31.961
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 08/22/23 03:54:31.962
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 03:54:31.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2574" for this suite. 08/22/23 03:54:31.968
STEP: Destroying namespace "webhook-2574-markers" for this suite. 08/22/23 03:54:31.975
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":16,"skipped":208,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.542 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:54:25.602
    Aug 22 03:54:25.602: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 03:54:25.602
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:54:25.618
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:54:25.621
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 03:54:26.303
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 03:54:26.699
    STEP: Deploying the webhook pod 08/22/23 03:54:26.71
    STEP: Wait for the deployment to be ready 08/22/23 03:54:26.75
    Aug 22 03:54:26.788: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 54, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 54, 26, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-5d85dd8cdb\""}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:54:28.792: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 54, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 54, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 54, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 54, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 03:54:30.912
    STEP: Verifying the service has paired with the endpoint 08/22/23 03:54:30.948
    Aug 22 03:54:31.948: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 08/22/23 03:54:31.958
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 08/22/23 03:54:31.959
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 08/22/23 03:54:31.959
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 08/22/23 03:54:31.959
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 08/22/23 03:54:31.961
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 08/22/23 03:54:31.961
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 08/22/23 03:54:31.962
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 03:54:31.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2574" for this suite. 08/22/23 03:54:31.968
    STEP: Destroying namespace "webhook-2574-markers" for this suite. 08/22/23 03:54:31.975
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:54:32.145
Aug 22 03:54:32.145: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename proxy 08/22/23 03:54:32.146
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:54:32.166
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:54:32.169
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Aug 22 03:54:32.172: INFO: Creating pod...
Aug 22 03:54:32.198: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-5551" to be "running"
Aug 22 03:54:32.272: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 74.1061ms
Aug 22 03:54:34.341: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.143222504s
Aug 22 03:54:36.276: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.078759866s
Aug 22 03:54:36.276: INFO: Pod "agnhost" satisfied condition "running"
Aug 22 03:54:36.277: INFO: Creating service...
Aug 22 03:54:36.287: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/pods/agnhost/proxy?method=DELETE
Aug 22 03:54:36.295: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug 22 03:54:36.295: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/pods/agnhost/proxy?method=OPTIONS
Aug 22 03:54:36.303: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug 22 03:54:36.303: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/pods/agnhost/proxy?method=PATCH
Aug 22 03:54:36.307: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug 22 03:54:36.307: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/pods/agnhost/proxy?method=POST
Aug 22 03:54:36.315: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug 22 03:54:36.315: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/pods/agnhost/proxy?method=PUT
Aug 22 03:54:36.320: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Aug 22 03:54:36.320: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/services/e2e-proxy-test-service/proxy?method=DELETE
Aug 22 03:54:36.326: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug 22 03:54:36.326: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/services/e2e-proxy-test-service/proxy?method=OPTIONS
Aug 22 03:54:36.333: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug 22 03:54:36.333: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/services/e2e-proxy-test-service/proxy?method=PATCH
Aug 22 03:54:36.340: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug 22 03:54:36.340: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/services/e2e-proxy-test-service/proxy?method=POST
Aug 22 03:54:36.352: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug 22 03:54:36.352: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/services/e2e-proxy-test-service/proxy?method=PUT
Aug 22 03:54:36.364: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Aug 22 03:54:36.365: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/pods/agnhost/proxy?method=GET
Aug 22 03:54:36.368: INFO: http.Client request:GET StatusCode:301
Aug 22 03:54:36.368: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/services/e2e-proxy-test-service/proxy?method=GET
Aug 22 03:54:36.375: INFO: http.Client request:GET StatusCode:301
Aug 22 03:54:36.375: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/pods/agnhost/proxy?method=HEAD
Aug 22 03:54:36.379: INFO: http.Client request:HEAD StatusCode:301
Aug 22 03:54:36.379: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/services/e2e-proxy-test-service/proxy?method=HEAD
Aug 22 03:54:36.386: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Aug 22 03:54:36.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5551" for this suite. 08/22/23 03:54:36.391
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":17,"skipped":214,"failed":0}
------------------------------
â€¢ [4.254 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:54:32.145
    Aug 22 03:54:32.145: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename proxy 08/22/23 03:54:32.146
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:54:32.166
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:54:32.169
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Aug 22 03:54:32.172: INFO: Creating pod...
    Aug 22 03:54:32.198: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-5551" to be "running"
    Aug 22 03:54:32.272: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 74.1061ms
    Aug 22 03:54:34.341: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.143222504s
    Aug 22 03:54:36.276: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.078759866s
    Aug 22 03:54:36.276: INFO: Pod "agnhost" satisfied condition "running"
    Aug 22 03:54:36.277: INFO: Creating service...
    Aug 22 03:54:36.287: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/pods/agnhost/proxy?method=DELETE
    Aug 22 03:54:36.295: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Aug 22 03:54:36.295: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/pods/agnhost/proxy?method=OPTIONS
    Aug 22 03:54:36.303: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Aug 22 03:54:36.303: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/pods/agnhost/proxy?method=PATCH
    Aug 22 03:54:36.307: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Aug 22 03:54:36.307: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/pods/agnhost/proxy?method=POST
    Aug 22 03:54:36.315: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Aug 22 03:54:36.315: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/pods/agnhost/proxy?method=PUT
    Aug 22 03:54:36.320: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Aug 22 03:54:36.320: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/services/e2e-proxy-test-service/proxy?method=DELETE
    Aug 22 03:54:36.326: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Aug 22 03:54:36.326: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Aug 22 03:54:36.333: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Aug 22 03:54:36.333: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/services/e2e-proxy-test-service/proxy?method=PATCH
    Aug 22 03:54:36.340: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Aug 22 03:54:36.340: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/services/e2e-proxy-test-service/proxy?method=POST
    Aug 22 03:54:36.352: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Aug 22 03:54:36.352: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/services/e2e-proxy-test-service/proxy?method=PUT
    Aug 22 03:54:36.364: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Aug 22 03:54:36.365: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/pods/agnhost/proxy?method=GET
    Aug 22 03:54:36.368: INFO: http.Client request:GET StatusCode:301
    Aug 22 03:54:36.368: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/services/e2e-proxy-test-service/proxy?method=GET
    Aug 22 03:54:36.375: INFO: http.Client request:GET StatusCode:301
    Aug 22 03:54:36.375: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/pods/agnhost/proxy?method=HEAD
    Aug 22 03:54:36.379: INFO: http.Client request:HEAD StatusCode:301
    Aug 22 03:54:36.379: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-5551/services/e2e-proxy-test-service/proxy?method=HEAD
    Aug 22 03:54:36.386: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Aug 22 03:54:36.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-5551" for this suite. 08/22/23 03:54:36.391
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:54:36.4
Aug 22 03:54:36.400: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename subpath 08/22/23 03:54:36.4
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:54:36.419
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:54:36.423
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/22/23 03:54:36.427
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-f7zv 08/22/23 03:54:36.445
STEP: Creating a pod to test atomic-volume-subpath 08/22/23 03:54:36.446
Aug 22 03:54:36.458: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-f7zv" in namespace "subpath-7537" to be "Succeeded or Failed"
Aug 22 03:54:36.467: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.118344ms
Aug 22 03:54:38.471: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012815274s
Aug 22 03:54:40.471: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 4.012512633s
Aug 22 03:54:42.470: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 6.01198927s
Aug 22 03:54:44.501: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 8.042078719s
Aug 22 03:54:46.560: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 10.101888167s
Aug 22 03:54:48.471: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 12.012268358s
Aug 22 03:54:50.514: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 14.055133216s
Aug 22 03:54:52.472: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 16.013656446s
Aug 22 03:54:54.473: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 18.0145242s
Aug 22 03:54:56.471: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 20.012210407s
Aug 22 03:54:58.470: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 22.011260021s
Aug 22 03:55:00.669: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=false. Elapsed: 24.21071006s
Aug 22 03:55:02.471: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.012066926s
STEP: Saw pod success 08/22/23 03:55:02.471
Aug 22 03:55:02.471: INFO: Pod "pod-subpath-test-downwardapi-f7zv" satisfied condition "Succeeded or Failed"
Aug 22 03:55:02.473: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod pod-subpath-test-downwardapi-f7zv container test-container-subpath-downwardapi-f7zv: <nil>
STEP: delete the pod 08/22/23 03:55:02.479
Aug 22 03:55:02.944: INFO: Waiting for pod pod-subpath-test-downwardapi-f7zv to disappear
Aug 22 03:55:03.286: INFO: Pod pod-subpath-test-downwardapi-f7zv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-f7zv 08/22/23 03:55:03.286
Aug 22 03:55:03.286: INFO: Deleting pod "pod-subpath-test-downwardapi-f7zv" in namespace "subpath-7537"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 22 03:55:03.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7537" for this suite. 08/22/23 03:55:03.294
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":18,"skipped":221,"failed":0}
------------------------------
â€¢ [SLOW TEST] [26.904 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:54:36.4
    Aug 22 03:54:36.400: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename subpath 08/22/23 03:54:36.4
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:54:36.419
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:54:36.423
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/22/23 03:54:36.427
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-f7zv 08/22/23 03:54:36.445
    STEP: Creating a pod to test atomic-volume-subpath 08/22/23 03:54:36.446
    Aug 22 03:54:36.458: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-f7zv" in namespace "subpath-7537" to be "Succeeded or Failed"
    Aug 22 03:54:36.467: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.118344ms
    Aug 22 03:54:38.471: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012815274s
    Aug 22 03:54:40.471: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 4.012512633s
    Aug 22 03:54:42.470: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 6.01198927s
    Aug 22 03:54:44.501: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 8.042078719s
    Aug 22 03:54:46.560: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 10.101888167s
    Aug 22 03:54:48.471: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 12.012268358s
    Aug 22 03:54:50.514: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 14.055133216s
    Aug 22 03:54:52.472: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 16.013656446s
    Aug 22 03:54:54.473: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 18.0145242s
    Aug 22 03:54:56.471: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 20.012210407s
    Aug 22 03:54:58.470: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=true. Elapsed: 22.011260021s
    Aug 22 03:55:00.669: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Running", Reason="", readiness=false. Elapsed: 24.21071006s
    Aug 22 03:55:02.471: INFO: Pod "pod-subpath-test-downwardapi-f7zv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.012066926s
    STEP: Saw pod success 08/22/23 03:55:02.471
    Aug 22 03:55:02.471: INFO: Pod "pod-subpath-test-downwardapi-f7zv" satisfied condition "Succeeded or Failed"
    Aug 22 03:55:02.473: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod pod-subpath-test-downwardapi-f7zv container test-container-subpath-downwardapi-f7zv: <nil>
    STEP: delete the pod 08/22/23 03:55:02.479
    Aug 22 03:55:02.944: INFO: Waiting for pod pod-subpath-test-downwardapi-f7zv to disappear
    Aug 22 03:55:03.286: INFO: Pod pod-subpath-test-downwardapi-f7zv no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-f7zv 08/22/23 03:55:03.286
    Aug 22 03:55:03.286: INFO: Deleting pod "pod-subpath-test-downwardapi-f7zv" in namespace "subpath-7537"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 22 03:55:03.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-7537" for this suite. 08/22/23 03:55:03.294
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:55:03.306
Aug 22 03:55:03.306: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 03:55:03.306
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:55:03.325
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:55:03.327
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-9aa0d2bf-e20d-452e-be7e-c3a2ab2981db 08/22/23 03:55:03.331
STEP: Creating a pod to test consume secrets 08/22/23 03:55:03.336
Aug 22 03:55:03.351: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d" in namespace "projected-8707" to be "Succeeded or Failed"
Aug 22 03:55:03.356: INFO: Pod "pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.933171ms
Aug 22 03:55:05.592: INFO: Pod "pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.241291924s
Aug 22 03:55:07.360: INFO: Pod "pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008913066s
Aug 22 03:55:09.360: INFO: Pod "pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009151198s
STEP: Saw pod success 08/22/23 03:55:09.36
Aug 22 03:55:09.360: INFO: Pod "pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d" satisfied condition "Succeeded or Failed"
Aug 22 03:55:09.362: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d container projected-secret-volume-test: <nil>
STEP: delete the pod 08/22/23 03:55:09.393
Aug 22 03:55:09.473: INFO: Waiting for pod pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d to disappear
Aug 22 03:55:09.476: INFO: Pod pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 22 03:55:09.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8707" for this suite. 08/22/23 03:55:09.48
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":19,"skipped":262,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.472 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:55:03.306
    Aug 22 03:55:03.306: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 03:55:03.306
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:55:03.325
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:55:03.327
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-9aa0d2bf-e20d-452e-be7e-c3a2ab2981db 08/22/23 03:55:03.331
    STEP: Creating a pod to test consume secrets 08/22/23 03:55:03.336
    Aug 22 03:55:03.351: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d" in namespace "projected-8707" to be "Succeeded or Failed"
    Aug 22 03:55:03.356: INFO: Pod "pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.933171ms
    Aug 22 03:55:05.592: INFO: Pod "pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.241291924s
    Aug 22 03:55:07.360: INFO: Pod "pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008913066s
    Aug 22 03:55:09.360: INFO: Pod "pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009151198s
    STEP: Saw pod success 08/22/23 03:55:09.36
    Aug 22 03:55:09.360: INFO: Pod "pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d" satisfied condition "Succeeded or Failed"
    Aug 22 03:55:09.362: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/22/23 03:55:09.393
    Aug 22 03:55:09.473: INFO: Waiting for pod pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d to disappear
    Aug 22 03:55:09.476: INFO: Pod pod-projected-secrets-ac0fc5c6-1ead-4adf-94f3-b2624ef8922d no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 22 03:55:09.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8707" for this suite. 08/22/23 03:55:09.48
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:55:09.779
Aug 22 03:55:09.779: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 03:55:09.78
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:55:10.127
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:55:10.13
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 08/22/23 03:55:10.134
Aug 22 03:55:10.143: INFO: Waiting up to 5m0s for pod "annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17" in namespace "downward-api-1513" to be "running and ready"
Aug 22 03:55:10.152: INFO: Pod "annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17": Phase="Pending", Reason="", readiness=false. Elapsed: 8.622851ms
Aug 22 03:55:10.152: INFO: The phase of Pod annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:55:12.155: INFO: Pod "annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012259355s
Aug 22 03:55:12.156: INFO: The phase of Pod annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 03:55:14.155: INFO: Pod "annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17": Phase="Running", Reason="", readiness=true. Elapsed: 4.012233182s
Aug 22 03:55:14.155: INFO: The phase of Pod annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17 is Running (Ready = true)
Aug 22 03:55:14.155: INFO: Pod "annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17" satisfied condition "running and ready"
Aug 22 03:55:14.830: INFO: Successfully updated pod "annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 22 03:55:16.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1513" for this suite. 08/22/23 03:55:16.857
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":20,"skipped":270,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.210 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:55:09.779
    Aug 22 03:55:09.779: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 03:55:09.78
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:55:10.127
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:55:10.13
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 08/22/23 03:55:10.134
    Aug 22 03:55:10.143: INFO: Waiting up to 5m0s for pod "annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17" in namespace "downward-api-1513" to be "running and ready"
    Aug 22 03:55:10.152: INFO: Pod "annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17": Phase="Pending", Reason="", readiness=false. Elapsed: 8.622851ms
    Aug 22 03:55:10.152: INFO: The phase of Pod annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:55:12.155: INFO: Pod "annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012259355s
    Aug 22 03:55:12.156: INFO: The phase of Pod annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 03:55:14.155: INFO: Pod "annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17": Phase="Running", Reason="", readiness=true. Elapsed: 4.012233182s
    Aug 22 03:55:14.155: INFO: The phase of Pod annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17 is Running (Ready = true)
    Aug 22 03:55:14.155: INFO: Pod "annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17" satisfied condition "running and ready"
    Aug 22 03:55:14.830: INFO: Successfully updated pod "annotationupdate3ea0a55f-7c59-4cb1-9f64-8984b6007b17"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 22 03:55:16.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1513" for this suite. 08/22/23 03:55:16.857
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:55:16.992
Aug 22 03:55:16.992: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 03:55:16.992
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:55:17.011
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:55:17.014
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 08/22/23 03:55:17.019
Aug 22 03:55:17.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 create -f -'
Aug 22 03:55:17.794: INFO: stderr: ""
Aug 22 03:55:17.794: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 08/22/23 03:55:17.794
Aug 22 03:55:17.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 22 03:55:17.852: INFO: stderr: ""
Aug 22 03:55:17.852: INFO: stdout: "update-demo-nautilus-cg75j update-demo-nautilus-vpz2l "
Aug 22 03:55:17.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods update-demo-nautilus-cg75j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 22 03:55:17.903: INFO: stderr: ""
Aug 22 03:55:17.903: INFO: stdout: ""
Aug 22 03:55:17.903: INFO: update-demo-nautilus-cg75j is created but not running
Aug 22 03:55:22.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 22 03:55:22.959: INFO: stderr: ""
Aug 22 03:55:22.959: INFO: stdout: "update-demo-nautilus-cg75j update-demo-nautilus-vpz2l "
Aug 22 03:55:22.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods update-demo-nautilus-cg75j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 22 03:55:23.010: INFO: stderr: ""
Aug 22 03:55:23.010: INFO: stdout: ""
Aug 22 03:55:23.010: INFO: update-demo-nautilus-cg75j is created but not running
Aug 22 03:55:28.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 22 03:55:28.067: INFO: stderr: ""
Aug 22 03:55:28.067: INFO: stdout: "update-demo-nautilus-cg75j update-demo-nautilus-vpz2l "
Aug 22 03:55:28.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods update-demo-nautilus-cg75j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 22 03:55:28.117: INFO: stderr: ""
Aug 22 03:55:28.117: INFO: stdout: "true"
Aug 22 03:55:28.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods update-demo-nautilus-cg75j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 22 03:55:28.170: INFO: stderr: ""
Aug 22 03:55:28.170: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 22 03:55:28.170: INFO: validating pod update-demo-nautilus-cg75j
Aug 22 03:55:28.175: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 03:55:28.176: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 03:55:28.176: INFO: update-demo-nautilus-cg75j is verified up and running
Aug 22 03:55:28.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods update-demo-nautilus-vpz2l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 22 03:55:28.228: INFO: stderr: ""
Aug 22 03:55:28.228: INFO: stdout: "true"
Aug 22 03:55:28.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods update-demo-nautilus-vpz2l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 22 03:55:28.283: INFO: stderr: ""
Aug 22 03:55:28.283: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 22 03:55:28.283: INFO: validating pod update-demo-nautilus-vpz2l
Aug 22 03:55:28.289: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 03:55:28.289: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 03:55:28.289: INFO: update-demo-nautilus-vpz2l is verified up and running
STEP: using delete to clean up resources 08/22/23 03:55:28.289
Aug 22 03:55:28.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 delete --grace-period=0 --force -f -'
Aug 22 03:55:28.355: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 03:55:28.355: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 22 03:55:28.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get rc,svc -l name=update-demo --no-headers'
Aug 22 03:55:28.502: INFO: stderr: "No resources found in kubectl-9594 namespace.\n"
Aug 22 03:55:28.502: INFO: stdout: ""
Aug 22 03:55:28.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 22 03:55:28.561: INFO: stderr: ""
Aug 22 03:55:28.561: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 03:55:28.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9594" for this suite. 08/22/23 03:55:28.566
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":21,"skipped":284,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.582 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:55:16.992
    Aug 22 03:55:16.992: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 03:55:16.992
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:55:17.011
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:55:17.014
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 08/22/23 03:55:17.019
    Aug 22 03:55:17.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 create -f -'
    Aug 22 03:55:17.794: INFO: stderr: ""
    Aug 22 03:55:17.794: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 08/22/23 03:55:17.794
    Aug 22 03:55:17.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 22 03:55:17.852: INFO: stderr: ""
    Aug 22 03:55:17.852: INFO: stdout: "update-demo-nautilus-cg75j update-demo-nautilus-vpz2l "
    Aug 22 03:55:17.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods update-demo-nautilus-cg75j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 22 03:55:17.903: INFO: stderr: ""
    Aug 22 03:55:17.903: INFO: stdout: ""
    Aug 22 03:55:17.903: INFO: update-demo-nautilus-cg75j is created but not running
    Aug 22 03:55:22.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 22 03:55:22.959: INFO: stderr: ""
    Aug 22 03:55:22.959: INFO: stdout: "update-demo-nautilus-cg75j update-demo-nautilus-vpz2l "
    Aug 22 03:55:22.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods update-demo-nautilus-cg75j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 22 03:55:23.010: INFO: stderr: ""
    Aug 22 03:55:23.010: INFO: stdout: ""
    Aug 22 03:55:23.010: INFO: update-demo-nautilus-cg75j is created but not running
    Aug 22 03:55:28.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 22 03:55:28.067: INFO: stderr: ""
    Aug 22 03:55:28.067: INFO: stdout: "update-demo-nautilus-cg75j update-demo-nautilus-vpz2l "
    Aug 22 03:55:28.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods update-demo-nautilus-cg75j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 22 03:55:28.117: INFO: stderr: ""
    Aug 22 03:55:28.117: INFO: stdout: "true"
    Aug 22 03:55:28.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods update-demo-nautilus-cg75j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 22 03:55:28.170: INFO: stderr: ""
    Aug 22 03:55:28.170: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 22 03:55:28.170: INFO: validating pod update-demo-nautilus-cg75j
    Aug 22 03:55:28.175: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 22 03:55:28.176: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 22 03:55:28.176: INFO: update-demo-nautilus-cg75j is verified up and running
    Aug 22 03:55:28.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods update-demo-nautilus-vpz2l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 22 03:55:28.228: INFO: stderr: ""
    Aug 22 03:55:28.228: INFO: stdout: "true"
    Aug 22 03:55:28.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods update-demo-nautilus-vpz2l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 22 03:55:28.283: INFO: stderr: ""
    Aug 22 03:55:28.283: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 22 03:55:28.283: INFO: validating pod update-demo-nautilus-vpz2l
    Aug 22 03:55:28.289: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 22 03:55:28.289: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 22 03:55:28.289: INFO: update-demo-nautilus-vpz2l is verified up and running
    STEP: using delete to clean up resources 08/22/23 03:55:28.289
    Aug 22 03:55:28.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 delete --grace-period=0 --force -f -'
    Aug 22 03:55:28.355: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 22 03:55:28.355: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Aug 22 03:55:28.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get rc,svc -l name=update-demo --no-headers'
    Aug 22 03:55:28.502: INFO: stderr: "No resources found in kubectl-9594 namespace.\n"
    Aug 22 03:55:28.502: INFO: stdout: ""
    Aug 22 03:55:28.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9594 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Aug 22 03:55:28.561: INFO: stderr: ""
    Aug 22 03:55:28.561: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 03:55:28.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9594" for this suite. 08/22/23 03:55:28.566
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:55:28.575
Aug 22 03:55:28.575: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename aggregator 08/22/23 03:55:28.575
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:55:28.592
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:55:28.595
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Aug 22 03:55:28.598: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 08/22/23 03:55:28.598
Aug 22 03:55:29.522: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Aug 22 03:55:31.705: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:55:33.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:55:35.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:55:37.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:55:39.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:55:41.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:55:43.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:55:45.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:55:47.803: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:55:49.711: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:55:51.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:55:53.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:55:55.712: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:55:57.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:55:59.711: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:02.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:03.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:05.711: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:07.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:09.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:11.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:13.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:15.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:17.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:19.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:21.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:23.722: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:25.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:27.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:29.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:31.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:33.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:35.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:37.764: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:39.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:41.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:43.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:45.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:47.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:49.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:51.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:53.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:55.711: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:57.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 03:56:59.861: INFO: Waited 129.208069ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 08/22/23 03:56:59.924
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 08/22/23 03:56:59.928
STEP: List APIServices 08/22/23 03:56:59.937
Aug 22 03:56:59.943: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Aug 22 03:57:00.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-8458" for this suite. 08/22/23 03:57:00.773
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":22,"skipped":359,"failed":0}
------------------------------
â€¢ [SLOW TEST] [92.204 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:55:28.575
    Aug 22 03:55:28.575: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename aggregator 08/22/23 03:55:28.575
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:55:28.592
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:55:28.595
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Aug 22 03:55:28.598: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 08/22/23 03:55:28.598
    Aug 22 03:55:29.522: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Aug 22 03:55:31.705: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:55:33.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:55:35.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:55:37.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:55:39.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:55:41.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:55:43.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:55:45.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:55:47.803: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:55:49.711: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:55:51.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:55:53.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:55:55.712: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:55:57.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:55:59.711: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:02.039: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:03.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:05.711: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:07.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:09.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:11.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:13.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:15.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:17.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:19.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:21.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:23.722: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:25.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:27.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:29.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:31.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:33.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:35.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:37.764: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:39.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:41.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:43.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:45.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:47.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:49.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:51.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:53.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:55.711: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:57.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 3, 55, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 03:56:59.861: INFO: Waited 129.208069ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 08/22/23 03:56:59.924
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 08/22/23 03:56:59.928
    STEP: List APIServices 08/22/23 03:56:59.937
    Aug 22 03:56:59.943: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Aug 22 03:57:00.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-8458" for this suite. 08/22/23 03:57:00.773
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:57:00.78
Aug 22 03:57:00.780: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 03:57:00.78
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:57:00.937
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:57:00.941
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 08/22/23 03:57:00.944
Aug 22 03:57:00.952: INFO: Waiting up to 5m0s for pod "pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4" in namespace "emptydir-2906" to be "Succeeded or Failed"
Aug 22 03:57:00.955: INFO: Pod "pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.675094ms
Aug 22 03:57:02.959: INFO: Pod "pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007325957s
Aug 22 03:57:04.961: INFO: Pod "pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009640486s
Aug 22 03:57:07.089: INFO: Pod "pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.137170914s
STEP: Saw pod success 08/22/23 03:57:07.089
Aug 22 03:57:07.089: INFO: Pod "pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4" satisfied condition "Succeeded or Failed"
Aug 22 03:57:07.094: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4 container test-container: <nil>
STEP: delete the pod 08/22/23 03:57:07.131
Aug 22 03:57:07.142: INFO: Waiting for pod pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4 to disappear
Aug 22 03:57:07.146: INFO: Pod pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 03:57:07.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2906" for this suite. 08/22/23 03:57:07.149
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":23,"skipped":407,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.376 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:57:00.78
    Aug 22 03:57:00.780: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 03:57:00.78
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:57:00.937
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:57:00.941
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 08/22/23 03:57:00.944
    Aug 22 03:57:00.952: INFO: Waiting up to 5m0s for pod "pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4" in namespace "emptydir-2906" to be "Succeeded or Failed"
    Aug 22 03:57:00.955: INFO: Pod "pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.675094ms
    Aug 22 03:57:02.959: INFO: Pod "pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007325957s
    Aug 22 03:57:04.961: INFO: Pod "pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009640486s
    Aug 22 03:57:07.089: INFO: Pod "pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.137170914s
    STEP: Saw pod success 08/22/23 03:57:07.089
    Aug 22 03:57:07.089: INFO: Pod "pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4" satisfied condition "Succeeded or Failed"
    Aug 22 03:57:07.094: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4 container test-container: <nil>
    STEP: delete the pod 08/22/23 03:57:07.131
    Aug 22 03:57:07.142: INFO: Waiting for pod pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4 to disappear
    Aug 22 03:57:07.146: INFO: Pod pod-70eb5f7a-f3b1-423e-bb19-5ec47b54f4b4 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 03:57:07.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2906" for this suite. 08/22/23 03:57:07.149
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:57:07.157
Aug 22 03:57:07.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename cronjob 08/22/23 03:57:07.157
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:57:07.173
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:57:07.176
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 08/22/23 03:57:07.18
STEP: Ensuring more than one job is running at a time 08/22/23 03:57:07.186
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 08/22/23 03:59:01.204
STEP: Removing cronjob 08/22/23 03:59:01.209
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 22 03:59:01.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5608" for this suite. 08/22/23 03:59:01.22
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":24,"skipped":444,"failed":0}
------------------------------
â€¢ [SLOW TEST] [114.071 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:57:07.157
    Aug 22 03:57:07.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename cronjob 08/22/23 03:57:07.157
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:57:07.173
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:57:07.176
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 08/22/23 03:57:07.18
    STEP: Ensuring more than one job is running at a time 08/22/23 03:57:07.186
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 08/22/23 03:59:01.204
    STEP: Removing cronjob 08/22/23 03:59:01.209
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 22 03:59:01.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5608" for this suite. 08/22/23 03:59:01.22
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:59:01.228
Aug 22 03:59:01.229: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename containers 08/22/23 03:59:01.229
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:59:01.273
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:59:01.276
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 08/22/23 03:59:01.28
Aug 22 03:59:01.291: INFO: Waiting up to 5m0s for pod "client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8" in namespace "containers-1715" to be "Succeeded or Failed"
Aug 22 03:59:01.300: INFO: Pod "client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.653333ms
Aug 22 03:59:03.308: INFO: Pod "client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016789968s
Aug 22 03:59:05.306: INFO: Pod "client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015002127s
Aug 22 03:59:07.304: INFO: Pod "client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012861775s
STEP: Saw pod success 08/22/23 03:59:07.304
Aug 22 03:59:07.304: INFO: Pod "client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8" satisfied condition "Succeeded or Failed"
Aug 22 03:59:07.307: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8 container agnhost-container: <nil>
STEP: delete the pod 08/22/23 03:59:07.34
Aug 22 03:59:07.526: INFO: Waiting for pod client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8 to disappear
Aug 22 03:59:07.529: INFO: Pod client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Aug 22 03:59:07.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1715" for this suite. 08/22/23 03:59:07.533
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":25,"skipped":452,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.311 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:59:01.228
    Aug 22 03:59:01.229: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename containers 08/22/23 03:59:01.229
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:59:01.273
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:59:01.276
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 08/22/23 03:59:01.28
    Aug 22 03:59:01.291: INFO: Waiting up to 5m0s for pod "client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8" in namespace "containers-1715" to be "Succeeded or Failed"
    Aug 22 03:59:01.300: INFO: Pod "client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.653333ms
    Aug 22 03:59:03.308: INFO: Pod "client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016789968s
    Aug 22 03:59:05.306: INFO: Pod "client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015002127s
    Aug 22 03:59:07.304: INFO: Pod "client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012861775s
    STEP: Saw pod success 08/22/23 03:59:07.304
    Aug 22 03:59:07.304: INFO: Pod "client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8" satisfied condition "Succeeded or Failed"
    Aug 22 03:59:07.307: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8 container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 03:59:07.34
    Aug 22 03:59:07.526: INFO: Waiting for pod client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8 to disappear
    Aug 22 03:59:07.529: INFO: Pod client-containers-5fca39a9-4788-4153-8c9f-11d5e8ef22e8 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Aug 22 03:59:07.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-1715" for this suite. 08/22/23 03:59:07.533
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:59:07.539
Aug 22 03:59:07.540: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename init-container 08/22/23 03:59:07.54
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:59:07.555
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:59:07.558
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 08/22/23 03:59:07.562
Aug 22 03:59:07.562: INFO: PodSpec: initContainers in spec.initContainers
Aug 22 03:59:53.754: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-23807576-a961-4ad0-b40a-db23650760dd", GenerateName:"", Namespace:"init-container-2683", SelfLink:"", UID:"70fa875e-d80d-4dc7-afc8-030413fc0a47", ResourceVersion:"1249761", Generation:0, CreationTimestamp:time.Date(2023, time.August, 22, 3, 59, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"562151688"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.August, 22, 3, 59, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ca6138), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.August, 22, 3, 59, 53, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ca6168), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-kh6ch", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc000b82220), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kh6ch", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kh6ch", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kh6ch", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0034b0718), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"jake-melb-gmyyva4zrlsz-node-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00022a380), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0034b0790)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0034b07b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0034b07b8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0034b07bc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000f80080), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.August, 22, 3, 59, 7, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.August, 22, 3, 59, 7, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.August, 22, 3, 59, 7, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.August, 22, 3, 59, 7, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.130", PodIP:"10.100.4.28", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.100.4.28"}}, StartTime:time.Date(2023, time.August, 22, 3, 59, 7, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00022a690)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00022a700)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://1389b5d66c71e703e41526004131a660a313f77ebebb915ea97d2fe9ccfe72c2", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000b822a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000b82280), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc0034b083f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 22 03:59:53.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2683" for this suite. 08/22/23 03:59:53.76
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":26,"skipped":457,"failed":0}
------------------------------
â€¢ [SLOW TEST] [46.227 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:59:07.539
    Aug 22 03:59:07.540: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename init-container 08/22/23 03:59:07.54
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:59:07.555
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:59:07.558
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 08/22/23 03:59:07.562
    Aug 22 03:59:07.562: INFO: PodSpec: initContainers in spec.initContainers
    Aug 22 03:59:53.754: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-23807576-a961-4ad0-b40a-db23650760dd", GenerateName:"", Namespace:"init-container-2683", SelfLink:"", UID:"70fa875e-d80d-4dc7-afc8-030413fc0a47", ResourceVersion:"1249761", Generation:0, CreationTimestamp:time.Date(2023, time.August, 22, 3, 59, 7, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"562151688"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.August, 22, 3, 59, 7, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ca6138), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.August, 22, 3, 59, 53, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ca6168), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-kh6ch", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc000b82220), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kh6ch", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kh6ch", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kh6ch", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0034b0718), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"jake-melb-gmyyva4zrlsz-node-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00022a380), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0034b0790)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0034b07b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0034b07b8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0034b07bc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000f80080), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.August, 22, 3, 59, 7, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.August, 22, 3, 59, 7, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.August, 22, 3, 59, 7, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.August, 22, 3, 59, 7, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.130", PodIP:"10.100.4.28", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.100.4.28"}}, StartTime:time.Date(2023, time.August, 22, 3, 59, 7, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00022a690)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00022a700)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://1389b5d66c71e703e41526004131a660a313f77ebebb915ea97d2fe9ccfe72c2", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000b822a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000b82280), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc0034b083f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 22 03:59:53.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-2683" for this suite. 08/22/23 03:59:53.76
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 03:59:53.767
Aug 22 03:59:53.767: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-probe 08/22/23 03:59:53.768
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:59:54.048
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:59:54.051
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc in namespace container-probe-5802 08/22/23 03:59:54.055
Aug 22 03:59:54.140: INFO: Waiting up to 5m0s for pod "liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc" in namespace "container-probe-5802" to be "not pending"
Aug 22 03:59:54.226: INFO: Pod "liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc": Phase="Pending", Reason="", readiness=false. Elapsed: 85.992892ms
Aug 22 03:59:56.230: INFO: Pod "liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090625565s
Aug 22 03:59:58.230: INFO: Pod "liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc": Phase="Running", Reason="", readiness=true. Elapsed: 4.090374968s
Aug 22 03:59:58.230: INFO: Pod "liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc" satisfied condition "not pending"
Aug 22 03:59:58.230: INFO: Started pod liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc in namespace container-probe-5802
STEP: checking the pod's current state and verifying that restartCount is present 08/22/23 03:59:58.23
Aug 22 03:59:58.232: INFO: Initial restart count of pod liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc is 0
Aug 22 04:00:16.356: INFO: Restart count of pod container-probe-5802/liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc is now 1 (18.123447458s elapsed)
Aug 22 04:00:36.721: INFO: Restart count of pod container-probe-5802/liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc is now 2 (38.488667563s elapsed)
Aug 22 04:00:56.918: INFO: Restart count of pod container-probe-5802/liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc is now 3 (58.685929519s elapsed)
Aug 22 04:01:15.046: INFO: Restart count of pod container-probe-5802/liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc is now 4 (1m16.814375617s elapsed)
Aug 22 04:02:19.489: INFO: Restart count of pod container-probe-5802/liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc is now 5 (2m21.256777551s elapsed)
STEP: deleting the pod 08/22/23 04:02:19.489
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 22 04:02:19.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5802" for this suite. 08/22/23 04:02:19.642
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":27,"skipped":469,"failed":0}
------------------------------
â€¢ [SLOW TEST] [145.885 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 03:59:53.767
    Aug 22 03:59:53.767: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-probe 08/22/23 03:59:53.768
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 03:59:54.048
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 03:59:54.051
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc in namespace container-probe-5802 08/22/23 03:59:54.055
    Aug 22 03:59:54.140: INFO: Waiting up to 5m0s for pod "liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc" in namespace "container-probe-5802" to be "not pending"
    Aug 22 03:59:54.226: INFO: Pod "liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc": Phase="Pending", Reason="", readiness=false. Elapsed: 85.992892ms
    Aug 22 03:59:56.230: INFO: Pod "liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090625565s
    Aug 22 03:59:58.230: INFO: Pod "liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc": Phase="Running", Reason="", readiness=true. Elapsed: 4.090374968s
    Aug 22 03:59:58.230: INFO: Pod "liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc" satisfied condition "not pending"
    Aug 22 03:59:58.230: INFO: Started pod liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc in namespace container-probe-5802
    STEP: checking the pod's current state and verifying that restartCount is present 08/22/23 03:59:58.23
    Aug 22 03:59:58.232: INFO: Initial restart count of pod liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc is 0
    Aug 22 04:00:16.356: INFO: Restart count of pod container-probe-5802/liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc is now 1 (18.123447458s elapsed)
    Aug 22 04:00:36.721: INFO: Restart count of pod container-probe-5802/liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc is now 2 (38.488667563s elapsed)
    Aug 22 04:00:56.918: INFO: Restart count of pod container-probe-5802/liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc is now 3 (58.685929519s elapsed)
    Aug 22 04:01:15.046: INFO: Restart count of pod container-probe-5802/liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc is now 4 (1m16.814375617s elapsed)
    Aug 22 04:02:19.489: INFO: Restart count of pod container-probe-5802/liveness-ebf4e0d3-7d57-4a92-98d5-98f391d995dc is now 5 (2m21.256777551s elapsed)
    STEP: deleting the pod 08/22/23 04:02:19.489
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 22 04:02:19.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5802" for this suite. 08/22/23 04:02:19.642
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:02:19.653
Aug 22 04:02:19.653: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename secrets 08/22/23 04:02:19.654
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:02:19.669
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:02:19.672
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 08/22/23 04:02:19.675
STEP: listing secrets in all namespaces to ensure that there are more than zero 08/22/23 04:02:19.681
STEP: patching the secret 08/22/23 04:02:19.686
STEP: deleting the secret using a LabelSelector 08/22/23 04:02:19.699
STEP: listing secrets in all namespaces, searching for label name and value in patch 08/22/23 04:02:19.705
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Aug 22 04:02:19.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8308" for this suite. 08/22/23 04:02:19.714
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":28,"skipped":481,"failed":0}
------------------------------
â€¢ [0.068 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:02:19.653
    Aug 22 04:02:19.653: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename secrets 08/22/23 04:02:19.654
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:02:19.669
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:02:19.672
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 08/22/23 04:02:19.675
    STEP: listing secrets in all namespaces to ensure that there are more than zero 08/22/23 04:02:19.681
    STEP: patching the secret 08/22/23 04:02:19.686
    STEP: deleting the secret using a LabelSelector 08/22/23 04:02:19.699
    STEP: listing secrets in all namespaces, searching for label name and value in patch 08/22/23 04:02:19.705
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Aug 22 04:02:19.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8308" for this suite. 08/22/23 04:02:19.714
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:02:19.722
Aug 22 04:02:19.722: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename job 08/22/23 04:02:19.722
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:02:19.738
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:02:19.74
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 08/22/23 04:02:19.748
STEP: Patching the Job 08/22/23 04:02:19.757
STEP: Watching for Job to be patched 08/22/23 04:02:19.779
Aug 22 04:02:19.782: INFO: Event ADDED observed for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking:]
Aug 22 04:02:19.782: INFO: Event MODIFIED observed for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking:]
Aug 22 04:02:19.782: INFO: Event MODIFIED found for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 08/22/23 04:02:19.782
STEP: Watching for Job to be updated 08/22/23 04:02:19.793
Aug 22 04:02:19.795: INFO: Event MODIFIED found for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 22 04:02:19.795: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 08/22/23 04:02:19.795
Aug 22 04:02:19.807: INFO: Job: e2e-d9v2g as labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g]
STEP: Waiting for job to complete 08/22/23 04:02:19.807
STEP: Delete a job collection with a labelselector 08/22/23 04:02:33.812
STEP: Watching for Job to be deleted 08/22/23 04:02:33.824
Aug 22 04:02:33.826: INFO: Event MODIFIED observed for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 22 04:02:33.826: INFO: Event MODIFIED observed for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 22 04:02:33.826: INFO: Event MODIFIED observed for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 22 04:02:33.826: INFO: Event MODIFIED observed for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 22 04:02:33.827: INFO: Event MODIFIED observed for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 22 04:02:33.827: INFO: Event DELETED found for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 08/22/23 04:02:33.827
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 22 04:02:33.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7763" for this suite. 08/22/23 04:02:33.839
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":29,"skipped":488,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.268 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:02:19.722
    Aug 22 04:02:19.722: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename job 08/22/23 04:02:19.722
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:02:19.738
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:02:19.74
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 08/22/23 04:02:19.748
    STEP: Patching the Job 08/22/23 04:02:19.757
    STEP: Watching for Job to be patched 08/22/23 04:02:19.779
    Aug 22 04:02:19.782: INFO: Event ADDED observed for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking:]
    Aug 22 04:02:19.782: INFO: Event MODIFIED observed for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking:]
    Aug 22 04:02:19.782: INFO: Event MODIFIED found for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 08/22/23 04:02:19.782
    STEP: Watching for Job to be updated 08/22/23 04:02:19.793
    Aug 22 04:02:19.795: INFO: Event MODIFIED found for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 22 04:02:19.795: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 08/22/23 04:02:19.795
    Aug 22 04:02:19.807: INFO: Job: e2e-d9v2g as labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g]
    STEP: Waiting for job to complete 08/22/23 04:02:19.807
    STEP: Delete a job collection with a labelselector 08/22/23 04:02:33.812
    STEP: Watching for Job to be deleted 08/22/23 04:02:33.824
    Aug 22 04:02:33.826: INFO: Event MODIFIED observed for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 22 04:02:33.826: INFO: Event MODIFIED observed for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 22 04:02:33.826: INFO: Event MODIFIED observed for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 22 04:02:33.826: INFO: Event MODIFIED observed for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 22 04:02:33.827: INFO: Event MODIFIED observed for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 22 04:02:33.827: INFO: Event DELETED found for Job e2e-d9v2g in namespace job-7763 with labels: map[e2e-d9v2g:patched e2e-job-label:e2e-d9v2g] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 08/22/23 04:02:33.827
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 22 04:02:33.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-7763" for this suite. 08/22/23 04:02:33.839
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:02:33.991
Aug 22 04:02:33.991: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename controllerrevisions 08/22/23 04:02:33.992
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:02:34.164
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:02:34.167
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-qqbvv-daemon-set" 08/22/23 04:02:34.195
STEP: Check that daemon pods launch on every node of the cluster. 08/22/23 04:02:34.203
Aug 22 04:02:34.210: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:34.210: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:34.210: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:34.219: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 0
Aug 22 04:02:34.219: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:02:35.385: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:35.385: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:35.385: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:35.391: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 0
Aug 22 04:02:35.391: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:02:36.252: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:36.252: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:36.252: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:36.255: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 0
Aug 22 04:02:36.255: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:02:37.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:37.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:37.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:37.228: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
Aug 22 04:02:37.229: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:02:38.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:38.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:38.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:38.227: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
Aug 22 04:02:38.227: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:02:39.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:39.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:39.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:39.228: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
Aug 22 04:02:39.228: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:02:40.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:40.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:40.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:40.227: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
Aug 22 04:02:40.227: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:02:41.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:41.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:41.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:41.231: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
Aug 22 04:02:41.231: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:02:42.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:42.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:42.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:42.230: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
Aug 22 04:02:42.231: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:02:43.231: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:43.231: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:43.231: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:43.235: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
Aug 22 04:02:43.235: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:02:44.229: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:44.229: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:44.229: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:44.235: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
Aug 22 04:02:44.235: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:02:45.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:45.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:45.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:45.227: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 2
Aug 22 04:02:45.227: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
Aug 22 04:02:46.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:46.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:46.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:46.229: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 2
Aug 22 04:02:46.229: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
Aug 22 04:02:47.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:47.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:47.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:47.227: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 2
Aug 22 04:02:47.227: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
Aug 22 04:02:48.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:48.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:48.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:48.230: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 2
Aug 22 04:02:48.230: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
Aug 22 04:02:49.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:49.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:49.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:49.227: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 2
Aug 22 04:02:49.227: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
Aug 22 04:02:50.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:50.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:50.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:50.228: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 2
Aug 22 04:02:50.228: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
Aug 22 04:02:51.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:51.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:51.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:02:51.227: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 3
Aug 22 04:02:51.227: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-qqbvv-daemon-set
STEP: Confirm DaemonSet "e2e-qqbvv-daemon-set" successfully created with "daemonset-name=e2e-qqbvv-daemon-set" label 08/22/23 04:02:51.23
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-qqbvv-daemon-set" 08/22/23 04:02:51.237
Aug 22 04:02:51.240: INFO: Located ControllerRevision: "e2e-qqbvv-daemon-set-75b6b49675"
STEP: Patching ControllerRevision "e2e-qqbvv-daemon-set-75b6b49675" 08/22/23 04:02:51.248
Aug 22 04:02:51.391: INFO: e2e-qqbvv-daemon-set-75b6b49675 has been patched
STEP: Create a new ControllerRevision 08/22/23 04:02:51.391
Aug 22 04:02:51.398: INFO: Created ControllerRevision: e2e-qqbvv-daemon-set-748568c955
STEP: Confirm that there are two ControllerRevisions 08/22/23 04:02:51.398
Aug 22 04:02:51.398: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 22 04:02:51.402: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-qqbvv-daemon-set-75b6b49675" 08/22/23 04:02:51.402
STEP: Confirm that there is only one ControllerRevision 08/22/23 04:02:51.409
Aug 22 04:02:51.409: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 22 04:02:51.411: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-qqbvv-daemon-set-748568c955" 08/22/23 04:02:51.413
Aug 22 04:02:51.422: INFO: e2e-qqbvv-daemon-set-748568c955 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 08/22/23 04:02:51.422
W0822 04:02:51.435398      19 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 08/22/23 04:02:51.435
Aug 22 04:02:51.435: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 22 04:02:52.438: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 22 04:02:52.442: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-qqbvv-daemon-set-748568c955=updated" 08/22/23 04:02:52.442
STEP: Confirm that there is only one ControllerRevision 08/22/23 04:02:52.449
Aug 22 04:02:52.449: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 22 04:02:52.452: INFO: Found 1 ControllerRevisions
Aug 22 04:02:52.454: INFO: ControllerRevision "e2e-qqbvv-daemon-set-5c8894b76b" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-qqbvv-daemon-set" 08/22/23 04:02:52.457
STEP: deleting DaemonSet.extensions e2e-qqbvv-daemon-set in namespace controllerrevisions-6156, will wait for the garbage collector to delete the pods 08/22/23 04:02:52.457
Aug 22 04:02:52.552: INFO: Deleting DaemonSet.extensions e2e-qqbvv-daemon-set took: 41.930527ms
Aug 22 04:02:52.753: INFO: Terminating DaemonSet.extensions e2e-qqbvv-daemon-set pods took: 201.034616ms
Aug 22 04:02:54.359: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 0
Aug 22 04:02:54.359: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-qqbvv-daemon-set
Aug 22 04:02:54.363: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1250589"},"items":null}

Aug 22 04:02:54.365: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1250589"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Aug 22 04:02:54.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-6156" for this suite. 08/22/23 04:02:54.38
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":30,"skipped":497,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.399 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:02:33.991
    Aug 22 04:02:33.991: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename controllerrevisions 08/22/23 04:02:33.992
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:02:34.164
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:02:34.167
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-qqbvv-daemon-set" 08/22/23 04:02:34.195
    STEP: Check that daemon pods launch on every node of the cluster. 08/22/23 04:02:34.203
    Aug 22 04:02:34.210: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:34.210: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:34.210: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:34.219: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 0
    Aug 22 04:02:34.219: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:02:35.385: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:35.385: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:35.385: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:35.391: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 0
    Aug 22 04:02:35.391: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:02:36.252: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:36.252: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:36.252: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:36.255: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 0
    Aug 22 04:02:36.255: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:02:37.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:37.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:37.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:37.228: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
    Aug 22 04:02:37.229: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:02:38.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:38.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:38.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:38.227: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
    Aug 22 04:02:38.227: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:02:39.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:39.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:39.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:39.228: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
    Aug 22 04:02:39.228: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:02:40.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:40.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:40.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:40.227: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
    Aug 22 04:02:40.227: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:02:41.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:41.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:41.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:41.231: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
    Aug 22 04:02:41.231: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:02:42.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:42.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:42.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:42.230: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
    Aug 22 04:02:42.231: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:02:43.231: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:43.231: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:43.231: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:43.235: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
    Aug 22 04:02:43.235: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:02:44.229: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:44.229: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:44.229: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:44.235: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 1
    Aug 22 04:02:44.235: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:02:45.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:45.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:45.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:45.227: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 2
    Aug 22 04:02:45.227: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
    Aug 22 04:02:46.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:46.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:46.225: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:46.229: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 2
    Aug 22 04:02:46.229: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
    Aug 22 04:02:47.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:47.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:47.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:47.227: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 2
    Aug 22 04:02:47.227: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
    Aug 22 04:02:48.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:48.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:48.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:48.230: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 2
    Aug 22 04:02:48.230: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
    Aug 22 04:02:49.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:49.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:49.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:49.227: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 2
    Aug 22 04:02:49.227: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
    Aug 22 04:02:50.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:50.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:50.226: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:50.228: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 2
    Aug 22 04:02:50.228: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
    Aug 22 04:02:51.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:51.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:51.224: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:02:51.227: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 3
    Aug 22 04:02:51.227: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-qqbvv-daemon-set
    STEP: Confirm DaemonSet "e2e-qqbvv-daemon-set" successfully created with "daemonset-name=e2e-qqbvv-daemon-set" label 08/22/23 04:02:51.23
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-qqbvv-daemon-set" 08/22/23 04:02:51.237
    Aug 22 04:02:51.240: INFO: Located ControllerRevision: "e2e-qqbvv-daemon-set-75b6b49675"
    STEP: Patching ControllerRevision "e2e-qqbvv-daemon-set-75b6b49675" 08/22/23 04:02:51.248
    Aug 22 04:02:51.391: INFO: e2e-qqbvv-daemon-set-75b6b49675 has been patched
    STEP: Create a new ControllerRevision 08/22/23 04:02:51.391
    Aug 22 04:02:51.398: INFO: Created ControllerRevision: e2e-qqbvv-daemon-set-748568c955
    STEP: Confirm that there are two ControllerRevisions 08/22/23 04:02:51.398
    Aug 22 04:02:51.398: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 22 04:02:51.402: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-qqbvv-daemon-set-75b6b49675" 08/22/23 04:02:51.402
    STEP: Confirm that there is only one ControllerRevision 08/22/23 04:02:51.409
    Aug 22 04:02:51.409: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 22 04:02:51.411: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-qqbvv-daemon-set-748568c955" 08/22/23 04:02:51.413
    Aug 22 04:02:51.422: INFO: e2e-qqbvv-daemon-set-748568c955 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 08/22/23 04:02:51.422
    W0822 04:02:51.435398      19 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 08/22/23 04:02:51.435
    Aug 22 04:02:51.435: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 22 04:02:52.438: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 22 04:02:52.442: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-qqbvv-daemon-set-748568c955=updated" 08/22/23 04:02:52.442
    STEP: Confirm that there is only one ControllerRevision 08/22/23 04:02:52.449
    Aug 22 04:02:52.449: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 22 04:02:52.452: INFO: Found 1 ControllerRevisions
    Aug 22 04:02:52.454: INFO: ControllerRevision "e2e-qqbvv-daemon-set-5c8894b76b" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-qqbvv-daemon-set" 08/22/23 04:02:52.457
    STEP: deleting DaemonSet.extensions e2e-qqbvv-daemon-set in namespace controllerrevisions-6156, will wait for the garbage collector to delete the pods 08/22/23 04:02:52.457
    Aug 22 04:02:52.552: INFO: Deleting DaemonSet.extensions e2e-qqbvv-daemon-set took: 41.930527ms
    Aug 22 04:02:52.753: INFO: Terminating DaemonSet.extensions e2e-qqbvv-daemon-set pods took: 201.034616ms
    Aug 22 04:02:54.359: INFO: Number of nodes with available pods controlled by daemonset e2e-qqbvv-daemon-set: 0
    Aug 22 04:02:54.359: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-qqbvv-daemon-set
    Aug 22 04:02:54.363: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1250589"},"items":null}

    Aug 22 04:02:54.365: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1250589"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 04:02:54.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-6156" for this suite. 08/22/23 04:02:54.38
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:02:54.39
Aug 22 04:02:54.390: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 04:02:54.391
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:02:54.411
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:02:54.414
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 08/22/23 04:02:54.418
Aug 22 04:02:54.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 create -f -'
Aug 22 04:02:55.308: INFO: stderr: ""
Aug 22 04:02:55.308: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 08/22/23 04:02:55.309
Aug 22 04:02:55.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 22 04:02:55.776: INFO: stderr: ""
Aug 22 04:02:55.776: INFO: stdout: "update-demo-nautilus-qpvbl "
STEP: Replicas for name=update-demo: expected=2 actual=1 08/22/23 04:02:55.776
Aug 22 04:03:00.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 22 04:03:00.834: INFO: stderr: ""
Aug 22 04:03:00.834: INFO: stdout: "update-demo-nautilus-qpvbl update-demo-nautilus-z7lds "
Aug 22 04:03:00.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 22 04:03:00.892: INFO: stderr: ""
Aug 22 04:03:00.892: INFO: stdout: "true"
Aug 22 04:03:00.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 22 04:03:00.949: INFO: stderr: ""
Aug 22 04:03:00.949: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 22 04:03:00.949: INFO: validating pod update-demo-nautilus-qpvbl
Aug 22 04:03:00.956: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 04:03:00.956: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 04:03:00.956: INFO: update-demo-nautilus-qpvbl is verified up and running
Aug 22 04:03:00.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-z7lds -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 22 04:03:01.007: INFO: stderr: ""
Aug 22 04:03:01.007: INFO: stdout: "true"
Aug 22 04:03:01.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-z7lds -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 22 04:03:01.055: INFO: stderr: ""
Aug 22 04:03:01.055: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 22 04:03:01.055: INFO: validating pod update-demo-nautilus-z7lds
Aug 22 04:03:01.061: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 04:03:01.061: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 04:03:01.061: INFO: update-demo-nautilus-z7lds is verified up and running
STEP: scaling down the replication controller 08/22/23 04:03:01.061
Aug 22 04:03:01.062: INFO: scanned /root for discovery docs: <nil>
Aug 22 04:03:01.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Aug 22 04:03:02.470: INFO: stderr: ""
Aug 22 04:03:02.470: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 08/22/23 04:03:02.47
Aug 22 04:03:02.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 22 04:03:02.526: INFO: stderr: ""
Aug 22 04:03:02.526: INFO: stdout: "update-demo-nautilus-qpvbl "
Aug 22 04:03:02.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 22 04:03:02.686: INFO: stderr: ""
Aug 22 04:03:02.686: INFO: stdout: "true"
Aug 22 04:03:02.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 22 04:03:02.739: INFO: stderr: ""
Aug 22 04:03:02.739: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 22 04:03:02.739: INFO: validating pod update-demo-nautilus-qpvbl
Aug 22 04:03:02.742: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 04:03:02.742: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 04:03:02.742: INFO: update-demo-nautilus-qpvbl is verified up and running
STEP: scaling up the replication controller 08/22/23 04:03:02.742
Aug 22 04:03:02.743: INFO: scanned /root for discovery docs: <nil>
Aug 22 04:03:02.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Aug 22 04:03:03.119: INFO: stderr: ""
Aug 22 04:03:03.119: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 08/22/23 04:03:03.119
Aug 22 04:03:03.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 22 04:03:03.173: INFO: stderr: ""
Aug 22 04:03:03.173: INFO: stdout: "update-demo-nautilus-qpvbl update-demo-nautilus-z977r "
Aug 22 04:03:03.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 22 04:03:03.229: INFO: stderr: ""
Aug 22 04:03:03.229: INFO: stdout: "true"
Aug 22 04:03:03.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 22 04:03:03.281: INFO: stderr: ""
Aug 22 04:03:03.281: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 22 04:03:03.281: INFO: validating pod update-demo-nautilus-qpvbl
Aug 22 04:03:03.286: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 04:03:03.286: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 04:03:03.286: INFO: update-demo-nautilus-qpvbl is verified up and running
Aug 22 04:03:03.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-z977r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 22 04:03:03.345: INFO: stderr: ""
Aug 22 04:03:03.345: INFO: stdout: ""
Aug 22 04:03:03.345: INFO: update-demo-nautilus-z977r is created but not running
Aug 22 04:03:08.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 22 04:03:08.402: INFO: stderr: ""
Aug 22 04:03:08.402: INFO: stdout: "update-demo-nautilus-qpvbl update-demo-nautilus-z977r "
Aug 22 04:03:08.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 22 04:03:08.454: INFO: stderr: ""
Aug 22 04:03:08.454: INFO: stdout: "true"
Aug 22 04:03:08.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 22 04:03:08.503: INFO: stderr: ""
Aug 22 04:03:08.503: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 22 04:03:08.503: INFO: validating pod update-demo-nautilus-qpvbl
Aug 22 04:03:08.508: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 04:03:08.508: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 04:03:08.508: INFO: update-demo-nautilus-qpvbl is verified up and running
Aug 22 04:03:08.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-z977r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 22 04:03:08.561: INFO: stderr: ""
Aug 22 04:03:08.561: INFO: stdout: "true"
Aug 22 04:03:08.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-z977r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 22 04:03:08.610: INFO: stderr: ""
Aug 22 04:03:08.610: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 22 04:03:08.610: INFO: validating pod update-demo-nautilus-z977r
Aug 22 04:03:08.616: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 22 04:03:08.616: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 22 04:03:08.616: INFO: update-demo-nautilus-z977r is verified up and running
STEP: using delete to clean up resources 08/22/23 04:03:08.616
Aug 22 04:03:08.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 delete --grace-period=0 --force -f -'
Aug 22 04:03:08.676: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 04:03:08.676: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 22 04:03:08.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get rc,svc -l name=update-demo --no-headers'
Aug 22 04:03:09.103: INFO: stderr: "No resources found in kubectl-7207 namespace.\n"
Aug 22 04:03:09.103: INFO: stdout: ""
Aug 22 04:03:09.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 22 04:03:09.346: INFO: stderr: ""
Aug 22 04:03:09.346: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 04:03:09.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7207" for this suite. 08/22/23 04:03:09.353
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":31,"skipped":500,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.970 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:02:54.39
    Aug 22 04:02:54.390: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 04:02:54.391
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:02:54.411
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:02:54.414
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 08/22/23 04:02:54.418
    Aug 22 04:02:54.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 create -f -'
    Aug 22 04:02:55.308: INFO: stderr: ""
    Aug 22 04:02:55.308: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 08/22/23 04:02:55.309
    Aug 22 04:02:55.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 22 04:02:55.776: INFO: stderr: ""
    Aug 22 04:02:55.776: INFO: stdout: "update-demo-nautilus-qpvbl "
    STEP: Replicas for name=update-demo: expected=2 actual=1 08/22/23 04:02:55.776
    Aug 22 04:03:00.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 22 04:03:00.834: INFO: stderr: ""
    Aug 22 04:03:00.834: INFO: stdout: "update-demo-nautilus-qpvbl update-demo-nautilus-z7lds "
    Aug 22 04:03:00.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 22 04:03:00.892: INFO: stderr: ""
    Aug 22 04:03:00.892: INFO: stdout: "true"
    Aug 22 04:03:00.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 22 04:03:00.949: INFO: stderr: ""
    Aug 22 04:03:00.949: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 22 04:03:00.949: INFO: validating pod update-demo-nautilus-qpvbl
    Aug 22 04:03:00.956: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 22 04:03:00.956: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 22 04:03:00.956: INFO: update-demo-nautilus-qpvbl is verified up and running
    Aug 22 04:03:00.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-z7lds -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 22 04:03:01.007: INFO: stderr: ""
    Aug 22 04:03:01.007: INFO: stdout: "true"
    Aug 22 04:03:01.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-z7lds -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 22 04:03:01.055: INFO: stderr: ""
    Aug 22 04:03:01.055: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 22 04:03:01.055: INFO: validating pod update-demo-nautilus-z7lds
    Aug 22 04:03:01.061: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 22 04:03:01.061: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 22 04:03:01.061: INFO: update-demo-nautilus-z7lds is verified up and running
    STEP: scaling down the replication controller 08/22/23 04:03:01.061
    Aug 22 04:03:01.062: INFO: scanned /root for discovery docs: <nil>
    Aug 22 04:03:01.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Aug 22 04:03:02.470: INFO: stderr: ""
    Aug 22 04:03:02.470: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 08/22/23 04:03:02.47
    Aug 22 04:03:02.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 22 04:03:02.526: INFO: stderr: ""
    Aug 22 04:03:02.526: INFO: stdout: "update-demo-nautilus-qpvbl "
    Aug 22 04:03:02.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 22 04:03:02.686: INFO: stderr: ""
    Aug 22 04:03:02.686: INFO: stdout: "true"
    Aug 22 04:03:02.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 22 04:03:02.739: INFO: stderr: ""
    Aug 22 04:03:02.739: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 22 04:03:02.739: INFO: validating pod update-demo-nautilus-qpvbl
    Aug 22 04:03:02.742: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 22 04:03:02.742: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 22 04:03:02.742: INFO: update-demo-nautilus-qpvbl is verified up and running
    STEP: scaling up the replication controller 08/22/23 04:03:02.742
    Aug 22 04:03:02.743: INFO: scanned /root for discovery docs: <nil>
    Aug 22 04:03:02.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Aug 22 04:03:03.119: INFO: stderr: ""
    Aug 22 04:03:03.119: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 08/22/23 04:03:03.119
    Aug 22 04:03:03.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 22 04:03:03.173: INFO: stderr: ""
    Aug 22 04:03:03.173: INFO: stdout: "update-demo-nautilus-qpvbl update-demo-nautilus-z977r "
    Aug 22 04:03:03.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 22 04:03:03.229: INFO: stderr: ""
    Aug 22 04:03:03.229: INFO: stdout: "true"
    Aug 22 04:03:03.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 22 04:03:03.281: INFO: stderr: ""
    Aug 22 04:03:03.281: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 22 04:03:03.281: INFO: validating pod update-demo-nautilus-qpvbl
    Aug 22 04:03:03.286: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 22 04:03:03.286: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 22 04:03:03.286: INFO: update-demo-nautilus-qpvbl is verified up and running
    Aug 22 04:03:03.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-z977r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 22 04:03:03.345: INFO: stderr: ""
    Aug 22 04:03:03.345: INFO: stdout: ""
    Aug 22 04:03:03.345: INFO: update-demo-nautilus-z977r is created but not running
    Aug 22 04:03:08.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 22 04:03:08.402: INFO: stderr: ""
    Aug 22 04:03:08.402: INFO: stdout: "update-demo-nautilus-qpvbl update-demo-nautilus-z977r "
    Aug 22 04:03:08.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 22 04:03:08.454: INFO: stderr: ""
    Aug 22 04:03:08.454: INFO: stdout: "true"
    Aug 22 04:03:08.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-qpvbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 22 04:03:08.503: INFO: stderr: ""
    Aug 22 04:03:08.503: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 22 04:03:08.503: INFO: validating pod update-demo-nautilus-qpvbl
    Aug 22 04:03:08.508: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 22 04:03:08.508: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 22 04:03:08.508: INFO: update-demo-nautilus-qpvbl is verified up and running
    Aug 22 04:03:08.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-z977r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 22 04:03:08.561: INFO: stderr: ""
    Aug 22 04:03:08.561: INFO: stdout: "true"
    Aug 22 04:03:08.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods update-demo-nautilus-z977r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 22 04:03:08.610: INFO: stderr: ""
    Aug 22 04:03:08.610: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 22 04:03:08.610: INFO: validating pod update-demo-nautilus-z977r
    Aug 22 04:03:08.616: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 22 04:03:08.616: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 22 04:03:08.616: INFO: update-demo-nautilus-z977r is verified up and running
    STEP: using delete to clean up resources 08/22/23 04:03:08.616
    Aug 22 04:03:08.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 delete --grace-period=0 --force -f -'
    Aug 22 04:03:08.676: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 22 04:03:08.676: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Aug 22 04:03:08.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get rc,svc -l name=update-demo --no-headers'
    Aug 22 04:03:09.103: INFO: stderr: "No resources found in kubectl-7207 namespace.\n"
    Aug 22 04:03:09.103: INFO: stdout: ""
    Aug 22 04:03:09.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7207 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Aug 22 04:03:09.346: INFO: stderr: ""
    Aug 22 04:03:09.346: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 04:03:09.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7207" for this suite. 08/22/23 04:03:09.353
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:03:09.361
Aug 22 04:03:09.361: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename disruption 08/22/23 04:03:09.361
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:09.459
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:09.461
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:03:09.465
Aug 22 04:03:09.465: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename disruption-2 08/22/23 04:03:09.466
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:09.482
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:09.486
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 08/22/23 04:03:09.499
STEP: Waiting for the pdb to be processed 08/22/23 04:03:09.516
STEP: Waiting for the pdb to be processed 08/22/23 04:03:09.528
STEP: listing a collection of PDBs across all namespaces 08/22/23 04:03:09.533
STEP: listing a collection of PDBs in namespace disruption-6117 08/22/23 04:03:09.538
STEP: deleting a collection of PDBs 08/22/23 04:03:09.542
STEP: Waiting for the PDB collection to be deleted 08/22/23 04:03:09.567
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Aug 22 04:03:09.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-133" for this suite. 08/22/23 04:03:09.574
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 22 04:03:09.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6117" for this suite. 08/22/23 04:03:09.584
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":32,"skipped":508,"failed":0}
------------------------------
â€¢ [0.233 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:03:09.361
    Aug 22 04:03:09.361: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename disruption 08/22/23 04:03:09.361
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:09.459
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:09.461
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:03:09.465
    Aug 22 04:03:09.465: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename disruption-2 08/22/23 04:03:09.466
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:09.482
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:09.486
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 08/22/23 04:03:09.499
    STEP: Waiting for the pdb to be processed 08/22/23 04:03:09.516
    STEP: Waiting for the pdb to be processed 08/22/23 04:03:09.528
    STEP: listing a collection of PDBs across all namespaces 08/22/23 04:03:09.533
    STEP: listing a collection of PDBs in namespace disruption-6117 08/22/23 04:03:09.538
    STEP: deleting a collection of PDBs 08/22/23 04:03:09.542
    STEP: Waiting for the PDB collection to be deleted 08/22/23 04:03:09.567
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Aug 22 04:03:09.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-133" for this suite. 08/22/23 04:03:09.574
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 22 04:03:09.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-6117" for this suite. 08/22/23 04:03:09.584
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:03:09.594
Aug 22 04:03:09.595: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:03:09.595
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:09.611
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:09.614
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-d4e21dd6-9c23-45e9-8089-5d50644422f9 08/22/23 04:03:09.618
STEP: Creating a pod to test consume configMaps 08/22/23 04:03:09.626
Aug 22 04:03:09.637: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a" in namespace "projected-8173" to be "Succeeded or Failed"
Aug 22 04:03:09.651: INFO: Pod "pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a": Phase="Pending", Reason="", readiness=false. Elapsed: 13.317907ms
Aug 22 04:03:11.656: INFO: Pod "pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01844718s
Aug 22 04:03:13.658: INFO: Pod "pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020843396s
Aug 22 04:03:15.654: INFO: Pod "pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01699783s
STEP: Saw pod success 08/22/23 04:03:15.654
Aug 22 04:03:15.655: INFO: Pod "pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a" satisfied condition "Succeeded or Failed"
Aug 22 04:03:15.657: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a container agnhost-container: <nil>
STEP: delete the pod 08/22/23 04:03:15.781
Aug 22 04:03:15.799: INFO: Waiting for pod pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a to disappear
Aug 22 04:03:15.801: INFO: Pod pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 22 04:03:15.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8173" for this suite. 08/22/23 04:03:15.806
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":33,"skipped":513,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.220 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:03:09.594
    Aug 22 04:03:09.595: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:03:09.595
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:09.611
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:09.614
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-d4e21dd6-9c23-45e9-8089-5d50644422f9 08/22/23 04:03:09.618
    STEP: Creating a pod to test consume configMaps 08/22/23 04:03:09.626
    Aug 22 04:03:09.637: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a" in namespace "projected-8173" to be "Succeeded or Failed"
    Aug 22 04:03:09.651: INFO: Pod "pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a": Phase="Pending", Reason="", readiness=false. Elapsed: 13.317907ms
    Aug 22 04:03:11.656: INFO: Pod "pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01844718s
    Aug 22 04:03:13.658: INFO: Pod "pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020843396s
    Aug 22 04:03:15.654: INFO: Pod "pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01699783s
    STEP: Saw pod success 08/22/23 04:03:15.654
    Aug 22 04:03:15.655: INFO: Pod "pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a" satisfied condition "Succeeded or Failed"
    Aug 22 04:03:15.657: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 04:03:15.781
    Aug 22 04:03:15.799: INFO: Waiting for pod pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a to disappear
    Aug 22 04:03:15.801: INFO: Pod pod-projected-configmaps-200971fa-9ec1-41d2-a8f4-848e94776d0a no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 22 04:03:15.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8173" for this suite. 08/22/23 04:03:15.806
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:03:15.817
Aug 22 04:03:15.817: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:03:15.818
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:15.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:15.842
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-d783444a-f07d-4d0e-b4b3-ed25e0fc4d5f 08/22/23 04:03:15.845
STEP: Creating a pod to test consume configMaps 08/22/23 04:03:15.851
Aug 22 04:03:15.861: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69" in namespace "projected-7317" to be "Succeeded or Failed"
Aug 22 04:03:15.865: INFO: Pod "pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69": Phase="Pending", Reason="", readiness=false. Elapsed: 4.784346ms
Aug 22 04:03:17.870: INFO: Pod "pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00941878s
Aug 22 04:03:19.870: INFO: Pod "pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69": Phase="Running", Reason="", readiness=false. Elapsed: 4.009687646s
Aug 22 04:03:21.871: INFO: Pod "pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01021212s
STEP: Saw pod success 08/22/23 04:03:21.871
Aug 22 04:03:21.871: INFO: Pod "pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69" satisfied condition "Succeeded or Failed"
Aug 22 04:03:21.873: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69 container projected-configmap-volume-test: <nil>
STEP: delete the pod 08/22/23 04:03:21.914
Aug 22 04:03:21.975: INFO: Waiting for pod pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69 to disappear
Aug 22 04:03:21.979: INFO: Pod pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 22 04:03:21.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7317" for this suite. 08/22/23 04:03:21.985
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":34,"skipped":525,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.179 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:03:15.817
    Aug 22 04:03:15.817: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:03:15.818
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:15.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:15.842
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-d783444a-f07d-4d0e-b4b3-ed25e0fc4d5f 08/22/23 04:03:15.845
    STEP: Creating a pod to test consume configMaps 08/22/23 04:03:15.851
    Aug 22 04:03:15.861: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69" in namespace "projected-7317" to be "Succeeded or Failed"
    Aug 22 04:03:15.865: INFO: Pod "pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69": Phase="Pending", Reason="", readiness=false. Elapsed: 4.784346ms
    Aug 22 04:03:17.870: INFO: Pod "pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00941878s
    Aug 22 04:03:19.870: INFO: Pod "pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69": Phase="Running", Reason="", readiness=false. Elapsed: 4.009687646s
    Aug 22 04:03:21.871: INFO: Pod "pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01021212s
    STEP: Saw pod success 08/22/23 04:03:21.871
    Aug 22 04:03:21.871: INFO: Pod "pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69" satisfied condition "Succeeded or Failed"
    Aug 22 04:03:21.873: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 08/22/23 04:03:21.914
    Aug 22 04:03:21.975: INFO: Waiting for pod pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69 to disappear
    Aug 22 04:03:21.979: INFO: Pod pod-projected-configmaps-9efdef3c-b6b5-4fa0-afe0-a6eea014ef69 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 22 04:03:21.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7317" for this suite. 08/22/23 04:03:21.985
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:03:21.996
Aug 22 04:03:21.996: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 04:03:21.997
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:22.021
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:22.024
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-906289c4-387c-471c-bb66-3f93d7c302bb 08/22/23 04:03:22.03
STEP: Creating a pod to test consume configMaps 08/22/23 04:03:22.039
Aug 22 04:03:22.286: INFO: Waiting up to 5m0s for pod "pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658" in namespace "configmap-5471" to be "Succeeded or Failed"
Aug 22 04:03:22.477: INFO: Pod "pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658": Phase="Pending", Reason="", readiness=false. Elapsed: 190.543203ms
Aug 22 04:03:24.481: INFO: Pod "pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658": Phase="Pending", Reason="", readiness=false. Elapsed: 2.194491331s
Aug 22 04:03:26.481: INFO: Pod "pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658": Phase="Pending", Reason="", readiness=false. Elapsed: 4.194896189s
Aug 22 04:03:28.481: INFO: Pod "pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.194942478s
STEP: Saw pod success 08/22/23 04:03:28.481
Aug 22 04:03:28.482: INFO: Pod "pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658" satisfied condition "Succeeded or Failed"
Aug 22 04:03:28.484: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658 container agnhost-container: <nil>
STEP: delete the pod 08/22/23 04:03:28.49
Aug 22 04:03:28.542: INFO: Waiting for pod pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658 to disappear
Aug 22 04:03:28.549: INFO: Pod pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 04:03:28.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5471" for this suite. 08/22/23 04:03:28.554
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":35,"skipped":532,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.565 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:03:21.996
    Aug 22 04:03:21.996: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 04:03:21.997
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:22.021
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:22.024
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-906289c4-387c-471c-bb66-3f93d7c302bb 08/22/23 04:03:22.03
    STEP: Creating a pod to test consume configMaps 08/22/23 04:03:22.039
    Aug 22 04:03:22.286: INFO: Waiting up to 5m0s for pod "pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658" in namespace "configmap-5471" to be "Succeeded or Failed"
    Aug 22 04:03:22.477: INFO: Pod "pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658": Phase="Pending", Reason="", readiness=false. Elapsed: 190.543203ms
    Aug 22 04:03:24.481: INFO: Pod "pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658": Phase="Pending", Reason="", readiness=false. Elapsed: 2.194491331s
    Aug 22 04:03:26.481: INFO: Pod "pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658": Phase="Pending", Reason="", readiness=false. Elapsed: 4.194896189s
    Aug 22 04:03:28.481: INFO: Pod "pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.194942478s
    STEP: Saw pod success 08/22/23 04:03:28.481
    Aug 22 04:03:28.482: INFO: Pod "pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658" satisfied condition "Succeeded or Failed"
    Aug 22 04:03:28.484: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658 container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 04:03:28.49
    Aug 22 04:03:28.542: INFO: Waiting for pod pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658 to disappear
    Aug 22 04:03:28.549: INFO: Pod pod-configmaps-7f403499-2504-4979-9682-72baf4fa8658 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 04:03:28.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5471" for this suite. 08/22/23 04:03:28.554
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:03:28.564
Aug 22 04:03:28.564: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pods 08/22/23 04:03:28.564
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:28.584
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:28.587
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 08/22/23 04:03:28.59
Aug 22 04:03:28.604: INFO: Waiting up to 5m0s for pod "pod-p7klm" in namespace "pods-9471" to be "running"
Aug 22 04:03:28.611: INFO: Pod "pod-p7klm": Phase="Pending", Reason="", readiness=false. Elapsed: 6.570006ms
Aug 22 04:03:30.617: INFO: Pod "pod-p7klm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012871027s
Aug 22 04:03:32.615: INFO: Pod "pod-p7klm": Phase="Running", Reason="", readiness=true. Elapsed: 4.010734519s
Aug 22 04:03:32.615: INFO: Pod "pod-p7klm" satisfied condition "running"
STEP: patching /status 08/22/23 04:03:32.615
Aug 22 04:03:32.664: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 22 04:03:32.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9471" for this suite. 08/22/23 04:03:32.667
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":36,"skipped":552,"failed":0}
------------------------------
â€¢ [4.109 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:03:28.564
    Aug 22 04:03:28.564: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pods 08/22/23 04:03:28.564
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:28.584
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:28.587
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 08/22/23 04:03:28.59
    Aug 22 04:03:28.604: INFO: Waiting up to 5m0s for pod "pod-p7klm" in namespace "pods-9471" to be "running"
    Aug 22 04:03:28.611: INFO: Pod "pod-p7klm": Phase="Pending", Reason="", readiness=false. Elapsed: 6.570006ms
    Aug 22 04:03:30.617: INFO: Pod "pod-p7klm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012871027s
    Aug 22 04:03:32.615: INFO: Pod "pod-p7klm": Phase="Running", Reason="", readiness=true. Elapsed: 4.010734519s
    Aug 22 04:03:32.615: INFO: Pod "pod-p7klm" satisfied condition "running"
    STEP: patching /status 08/22/23 04:03:32.615
    Aug 22 04:03:32.664: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 22 04:03:32.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9471" for this suite. 08/22/23 04:03:32.667
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:03:32.675
Aug 22 04:03:32.675: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pods 08/22/23 04:03:32.675
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:33.024
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:33.027
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Aug 22 04:03:33.031: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: creating the pod 08/22/23 04:03:33.031
STEP: submitting the pod to kubernetes 08/22/23 04:03:33.031
Aug 22 04:03:33.126: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9" in namespace "pods-8808" to be "running and ready"
Aug 22 04:03:33.138: INFO: Pod "pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.070725ms
Aug 22 04:03:33.138: INFO: The phase of Pod pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:03:35.286: INFO: Pod "pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.160112982s
Aug 22 04:03:35.286: INFO: The phase of Pod pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:03:37.142: INFO: Pod "pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9": Phase="Running", Reason="", readiness=true. Elapsed: 4.015501471s
Aug 22 04:03:37.142: INFO: The phase of Pod pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9 is Running (Ready = true)
Aug 22 04:03:37.142: INFO: Pod "pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 22 04:03:37.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8808" for this suite. 08/22/23 04:03:37.303
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":37,"skipped":582,"failed":0}
------------------------------
â€¢ [4.800 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:03:32.675
    Aug 22 04:03:32.675: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pods 08/22/23 04:03:32.675
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:33.024
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:33.027
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Aug 22 04:03:33.031: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: creating the pod 08/22/23 04:03:33.031
    STEP: submitting the pod to kubernetes 08/22/23 04:03:33.031
    Aug 22 04:03:33.126: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9" in namespace "pods-8808" to be "running and ready"
    Aug 22 04:03:33.138: INFO: Pod "pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.070725ms
    Aug 22 04:03:33.138: INFO: The phase of Pod pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:03:35.286: INFO: Pod "pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.160112982s
    Aug 22 04:03:35.286: INFO: The phase of Pod pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:03:37.142: INFO: Pod "pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9": Phase="Running", Reason="", readiness=true. Elapsed: 4.015501471s
    Aug 22 04:03:37.142: INFO: The phase of Pod pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9 is Running (Ready = true)
    Aug 22 04:03:37.142: INFO: Pod "pod-exec-websocket-1a7d356d-ccd3-453a-bad2-80048d9962f9" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 22 04:03:37.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8808" for this suite. 08/22/23 04:03:37.303
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:03:37.477
Aug 22 04:03:37.477: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 04:03:37.478
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:37.907
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:37.91
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 08/22/23 04:03:37.914
Aug 22 04:03:37.957: INFO: Waiting up to 5m0s for pod "pod-65a9ea9b-4b95-450e-928b-8497b3e15922" in namespace "emptydir-2334" to be "Succeeded or Failed"
Aug 22 04:03:37.975: INFO: Pod "pod-65a9ea9b-4b95-450e-928b-8497b3e15922": Phase="Pending", Reason="", readiness=false. Elapsed: 17.608085ms
Aug 22 04:03:39.979: INFO: Pod "pod-65a9ea9b-4b95-450e-928b-8497b3e15922": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021849422s
Aug 22 04:03:41.980: INFO: Pod "pod-65a9ea9b-4b95-450e-928b-8497b3e15922": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0226212s
Aug 22 04:03:43.981: INFO: Pod "pod-65a9ea9b-4b95-450e-928b-8497b3e15922": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023525016s
STEP: Saw pod success 08/22/23 04:03:43.981
Aug 22 04:03:43.981: INFO: Pod "pod-65a9ea9b-4b95-450e-928b-8497b3e15922" satisfied condition "Succeeded or Failed"
Aug 22 04:03:43.984: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-65a9ea9b-4b95-450e-928b-8497b3e15922 container test-container: <nil>
STEP: delete the pod 08/22/23 04:03:43.991
Aug 22 04:03:44.161: INFO: Waiting for pod pod-65a9ea9b-4b95-450e-928b-8497b3e15922 to disappear
Aug 22 04:03:44.165: INFO: Pod pod-65a9ea9b-4b95-450e-928b-8497b3e15922 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 04:03:44.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2334" for this suite. 08/22/23 04:03:44.168
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":38,"skipped":621,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.698 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:03:37.477
    Aug 22 04:03:37.477: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 04:03:37.478
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:37.907
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:37.91
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 08/22/23 04:03:37.914
    Aug 22 04:03:37.957: INFO: Waiting up to 5m0s for pod "pod-65a9ea9b-4b95-450e-928b-8497b3e15922" in namespace "emptydir-2334" to be "Succeeded or Failed"
    Aug 22 04:03:37.975: INFO: Pod "pod-65a9ea9b-4b95-450e-928b-8497b3e15922": Phase="Pending", Reason="", readiness=false. Elapsed: 17.608085ms
    Aug 22 04:03:39.979: INFO: Pod "pod-65a9ea9b-4b95-450e-928b-8497b3e15922": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021849422s
    Aug 22 04:03:41.980: INFO: Pod "pod-65a9ea9b-4b95-450e-928b-8497b3e15922": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0226212s
    Aug 22 04:03:43.981: INFO: Pod "pod-65a9ea9b-4b95-450e-928b-8497b3e15922": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023525016s
    STEP: Saw pod success 08/22/23 04:03:43.981
    Aug 22 04:03:43.981: INFO: Pod "pod-65a9ea9b-4b95-450e-928b-8497b3e15922" satisfied condition "Succeeded or Failed"
    Aug 22 04:03:43.984: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-65a9ea9b-4b95-450e-928b-8497b3e15922 container test-container: <nil>
    STEP: delete the pod 08/22/23 04:03:43.991
    Aug 22 04:03:44.161: INFO: Waiting for pod pod-65a9ea9b-4b95-450e-928b-8497b3e15922 to disappear
    Aug 22 04:03:44.165: INFO: Pod pod-65a9ea9b-4b95-450e-928b-8497b3e15922 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 04:03:44.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2334" for this suite. 08/22/23 04:03:44.168
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:03:44.176
Aug 22 04:03:44.176: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename daemonsets 08/22/23 04:03:44.177
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:44.192
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:44.194
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Aug 22 04:03:44.221: INFO: Create a RollingUpdate DaemonSet
Aug 22 04:03:44.227: INFO: Check that daemon pods launch on every node of the cluster
Aug 22 04:03:44.232: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:44.232: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:44.232: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:44.235: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:03:44.235: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:03:45.241: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:45.241: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:45.241: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:45.244: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:03:45.244: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:03:46.240: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:46.240: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:46.240: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:46.243: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:03:46.243: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:03:47.242: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:47.242: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:47.242: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:47.245: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 04:03:47.245: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
Aug 22 04:03:48.383: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:48.383: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:48.383: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:48.386: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 22 04:03:48.386: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Aug 22 04:03:48.386: INFO: Update the DaemonSet to trigger a rollout
Aug 22 04:03:48.459: INFO: Updating DaemonSet daemon-set
Aug 22 04:03:50.487: INFO: Roll back the DaemonSet before rollout is complete
Aug 22 04:03:50.498: INFO: Updating DaemonSet daemon-set
Aug 22 04:03:50.498: INFO: Make sure DaemonSet rollback is complete
Aug 22 04:03:50.504: INFO: Wrong image for pod: daemon-set-sknj2. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Aug 22 04:03:50.504: INFO: Pod daemon-set-sknj2 is not available
Aug 22 04:03:50.509: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:50.509: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:50.509: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:51.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:51.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:51.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:52.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:52.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:52.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:53.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:53.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:53.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:54.518: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:54.518: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:54.518: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:55.603: INFO: Pod daemon-set-5bznl is not available
Aug 22 04:03:55.610: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:55.610: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:55.610: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:56.559: INFO: Pod daemon-set-5bznl is not available
Aug 22 04:03:56.563: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:56.564: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:03:56.564: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/22/23 04:03:56.572
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8761, will wait for the garbage collector to delete the pods 08/22/23 04:03:56.572
Aug 22 04:03:56.635: INFO: Deleting DaemonSet.extensions daemon-set took: 8.471604ms
Aug 22 04:03:56.835: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.443997ms
Aug 22 04:03:59.809: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:03:59.809: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 22 04:03:59.812: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1251186"},"items":null}

Aug 22 04:03:59.815: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1251187"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 22 04:03:59.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8761" for this suite. 08/22/23 04:03:59.828
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":39,"skipped":636,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.660 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:03:44.176
    Aug 22 04:03:44.176: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename daemonsets 08/22/23 04:03:44.177
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:44.192
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:44.194
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Aug 22 04:03:44.221: INFO: Create a RollingUpdate DaemonSet
    Aug 22 04:03:44.227: INFO: Check that daemon pods launch on every node of the cluster
    Aug 22 04:03:44.232: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:44.232: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:44.232: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:44.235: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:03:44.235: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:03:45.241: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:45.241: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:45.241: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:45.244: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:03:45.244: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:03:46.240: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:46.240: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:46.240: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:46.243: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:03:46.243: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:03:47.242: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:47.242: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:47.242: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:47.245: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 04:03:47.245: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
    Aug 22 04:03:48.383: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:48.383: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:48.383: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:48.386: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 22 04:03:48.386: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Aug 22 04:03:48.386: INFO: Update the DaemonSet to trigger a rollout
    Aug 22 04:03:48.459: INFO: Updating DaemonSet daemon-set
    Aug 22 04:03:50.487: INFO: Roll back the DaemonSet before rollout is complete
    Aug 22 04:03:50.498: INFO: Updating DaemonSet daemon-set
    Aug 22 04:03:50.498: INFO: Make sure DaemonSet rollback is complete
    Aug 22 04:03:50.504: INFO: Wrong image for pod: daemon-set-sknj2. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Aug 22 04:03:50.504: INFO: Pod daemon-set-sknj2 is not available
    Aug 22 04:03:50.509: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:50.509: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:50.509: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:51.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:51.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:51.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:52.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:52.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:52.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:53.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:53.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:53.517: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:54.518: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:54.518: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:54.518: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:55.603: INFO: Pod daemon-set-5bznl is not available
    Aug 22 04:03:55.610: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:55.610: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:55.610: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:56.559: INFO: Pod daemon-set-5bznl is not available
    Aug 22 04:03:56.563: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:56.564: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:03:56.564: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/22/23 04:03:56.572
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8761, will wait for the garbage collector to delete the pods 08/22/23 04:03:56.572
    Aug 22 04:03:56.635: INFO: Deleting DaemonSet.extensions daemon-set took: 8.471604ms
    Aug 22 04:03:56.835: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.443997ms
    Aug 22 04:03:59.809: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:03:59.809: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 22 04:03:59.812: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1251186"},"items":null}

    Aug 22 04:03:59.815: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1251187"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 04:03:59.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8761" for this suite. 08/22/23 04:03:59.828
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:03:59.837
Aug 22 04:03:59.837: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename sched-preemption 08/22/23 04:03:59.838
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:59.856
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:59.859
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug 22 04:03:59.881: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 22 04:05:00.266: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 08/22/23 04:05:00.27
Aug 22 04:05:00.810: INFO: Created pod: pod0-0-sched-preemption-low-priority
Aug 22 04:05:00.822: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Aug 22 04:05:01.418: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Aug 22 04:05:01.652: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Aug 22 04:05:01.771: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Aug 22 04:05:01.780: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 08/22/23 04:05:01.78
Aug 22 04:05:01.780: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8174" to be "running"
Aug 22 04:05:01.786: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.197637ms
Aug 22 04:05:03.925: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.144841412s
Aug 22 04:05:05.789: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009411512s
Aug 22 04:05:07.791: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010489462s
Aug 22 04:05:09.865: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.085224754s
Aug 22 04:05:11.792: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.011944596s
Aug 22 04:05:11.792: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Aug 22 04:05:11.792: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8174" to be "running"
Aug 22 04:05:11.796: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.733675ms
Aug 22 04:05:11.796: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Aug 22 04:05:11.796: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8174" to be "running"
Aug 22 04:05:11.800: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.822932ms
Aug 22 04:05:13.804: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008153894s
Aug 22 04:05:15.804: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008682433s
Aug 22 04:05:17.804: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008296766s
Aug 22 04:05:19.803: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.007680757s
Aug 22 04:05:19.803: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Aug 22 04:05:19.803: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8174" to be "running"
Aug 22 04:05:19.807: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.719468ms
Aug 22 04:05:19.807: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Aug 22 04:05:19.807: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8174" to be "running"
Aug 22 04:05:19.810: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.998194ms
Aug 22 04:05:19.810: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Aug 22 04:05:19.810: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8174" to be "running"
Aug 22 04:05:19.814: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.40087ms
Aug 22 04:05:19.814: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 08/22/23 04:05:19.814
Aug 22 04:05:19.990: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-8174" to be "running"
Aug 22 04:05:19.996: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.970513ms
Aug 22 04:05:22.035: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044743893s
Aug 22 04:05:24.001: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0103114s
Aug 22 04:05:26.000: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.009968254s
Aug 22 04:05:26.000: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Aug 22 04:05:26.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8174" for this suite. 08/22/23 04:05:26.02
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":40,"skipped":653,"failed":0}
------------------------------
â€¢ [SLOW TEST] [86.231 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:03:59.837
    Aug 22 04:03:59.837: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename sched-preemption 08/22/23 04:03:59.838
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:03:59.856
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:03:59.859
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Aug 22 04:03:59.881: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 22 04:05:00.266: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 08/22/23 04:05:00.27
    Aug 22 04:05:00.810: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Aug 22 04:05:00.822: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Aug 22 04:05:01.418: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Aug 22 04:05:01.652: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Aug 22 04:05:01.771: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Aug 22 04:05:01.780: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 08/22/23 04:05:01.78
    Aug 22 04:05:01.780: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8174" to be "running"
    Aug 22 04:05:01.786: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.197637ms
    Aug 22 04:05:03.925: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.144841412s
    Aug 22 04:05:05.789: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009411512s
    Aug 22 04:05:07.791: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010489462s
    Aug 22 04:05:09.865: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.085224754s
    Aug 22 04:05:11.792: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.011944596s
    Aug 22 04:05:11.792: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Aug 22 04:05:11.792: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8174" to be "running"
    Aug 22 04:05:11.796: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.733675ms
    Aug 22 04:05:11.796: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Aug 22 04:05:11.796: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8174" to be "running"
    Aug 22 04:05:11.800: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.822932ms
    Aug 22 04:05:13.804: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008153894s
    Aug 22 04:05:15.804: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008682433s
    Aug 22 04:05:17.804: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008296766s
    Aug 22 04:05:19.803: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.007680757s
    Aug 22 04:05:19.803: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Aug 22 04:05:19.803: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8174" to be "running"
    Aug 22 04:05:19.807: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.719468ms
    Aug 22 04:05:19.807: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Aug 22 04:05:19.807: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8174" to be "running"
    Aug 22 04:05:19.810: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.998194ms
    Aug 22 04:05:19.810: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Aug 22 04:05:19.810: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8174" to be "running"
    Aug 22 04:05:19.814: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.40087ms
    Aug 22 04:05:19.814: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 08/22/23 04:05:19.814
    Aug 22 04:05:19.990: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-8174" to be "running"
    Aug 22 04:05:19.996: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.970513ms
    Aug 22 04:05:22.035: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044743893s
    Aug 22 04:05:24.001: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0103114s
    Aug 22 04:05:26.000: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.009968254s
    Aug 22 04:05:26.000: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 04:05:26.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8174" for this suite. 08/22/23 04:05:26.02
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:05:26.069
Aug 22 04:05:26.069: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 04:05:26.07
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:05:26.12
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:05:26.123
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 04:05:26.148
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 04:05:26.552
STEP: Deploying the webhook pod 08/22/23 04:05:26.566
STEP: Wait for the deployment to be ready 08/22/23 04:05:26.588
Aug 22 04:05:26.646: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 04:05:28.656: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 5, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 5, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 5, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 5, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 04:05:30.661
STEP: Verifying the service has paired with the endpoint 08/22/23 04:05:30.677
Aug 22 04:05:31.678: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 08/22/23 04:05:31.683
STEP: create a namespace for the webhook 08/22/23 04:05:31.703
STEP: create a configmap should be unconditionally rejected by the webhook 08/22/23 04:05:31.711
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:05:31.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2991" for this suite. 08/22/23 04:05:31.91
STEP: Destroying namespace "webhook-2991-markers" for this suite. 08/22/23 04:05:31.919
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":41,"skipped":668,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.031 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:05:26.069
    Aug 22 04:05:26.069: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 04:05:26.07
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:05:26.12
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:05:26.123
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 04:05:26.148
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 04:05:26.552
    STEP: Deploying the webhook pod 08/22/23 04:05:26.566
    STEP: Wait for the deployment to be ready 08/22/23 04:05:26.588
    Aug 22 04:05:26.646: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 04:05:28.656: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 5, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 5, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 5, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 5, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 04:05:30.661
    STEP: Verifying the service has paired with the endpoint 08/22/23 04:05:30.677
    Aug 22 04:05:31.678: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 08/22/23 04:05:31.683
    STEP: create a namespace for the webhook 08/22/23 04:05:31.703
    STEP: create a configmap should be unconditionally rejected by the webhook 08/22/23 04:05:31.711
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:05:31.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2991" for this suite. 08/22/23 04:05:31.91
    STEP: Destroying namespace "webhook-2991-markers" for this suite. 08/22/23 04:05:31.919
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:05:32.1
Aug 22 04:05:32.100: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename namespaces 08/22/23 04:05:32.101
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:05:32.399
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:05:32.401
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 08/22/23 04:05:32.406
Aug 22 04:05:32.410: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 08/22/23 04:05:32.41
Aug 22 04:05:32.417: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 08/22/23 04:05:32.417
Aug 22 04:05:32.429: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Aug 22 04:05:32.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2314" for this suite. 08/22/23 04:05:32.432
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":42,"skipped":670,"failed":0}
------------------------------
â€¢ [0.338 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:05:32.1
    Aug 22 04:05:32.100: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename namespaces 08/22/23 04:05:32.101
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:05:32.399
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:05:32.401
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 08/22/23 04:05:32.406
    Aug 22 04:05:32.410: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 08/22/23 04:05:32.41
    Aug 22 04:05:32.417: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 08/22/23 04:05:32.417
    Aug 22 04:05:32.429: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 04:05:32.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-2314" for this suite. 08/22/23 04:05:32.432
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:05:32.439
Aug 22 04:05:32.439: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename daemonsets 08/22/23 04:05:32.44
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:05:32.508
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:05:32.512
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Aug 22 04:05:32.554: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 08/22/23 04:05:32.561
Aug 22 04:05:32.566: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:05:32.566: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 08/22/23 04:05:32.566
Aug 22 04:05:32.593: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:05:32.593: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:05:33.598: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:05:33.598: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:05:34.599: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:05:34.599: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:05:35.642: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:05:35.642: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:05:36.686: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 22 04:05:36.686: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 08/22/23 04:05:36.689
Aug 22 04:05:36.706: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 22 04:05:36.706: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Aug 22 04:05:37.710: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:05:37.710: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 08/22/23 04:05:37.71
Aug 22 04:05:37.827: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:05:37.827: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:05:38.930: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:05:38.930: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:05:39.832: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:05:39.832: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:05:40.844: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:05:40.844: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:05:41.832: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:05:41.832: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:05:42.833: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 22 04:05:42.833: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/22/23 04:05:42.841
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4302, will wait for the garbage collector to delete the pods 08/22/23 04:05:42.841
Aug 22 04:05:42.907: INFO: Deleting DaemonSet.extensions daemon-set took: 12.452543ms
Aug 22 04:05:43.008: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.539729ms
Aug 22 04:05:45.513: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:05:45.514: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 22 04:05:45.516: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1251868"},"items":null}

Aug 22 04:05:45.519: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1251868"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 22 04:05:45.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4302" for this suite. 08/22/23 04:05:45.703
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":43,"skipped":685,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.270 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:05:32.439
    Aug 22 04:05:32.439: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename daemonsets 08/22/23 04:05:32.44
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:05:32.508
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:05:32.512
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Aug 22 04:05:32.554: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 08/22/23 04:05:32.561
    Aug 22 04:05:32.566: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:05:32.566: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 08/22/23 04:05:32.566
    Aug 22 04:05:32.593: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:05:32.593: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:05:33.598: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:05:33.598: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:05:34.599: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:05:34.599: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:05:35.642: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:05:35.642: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:05:36.686: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 22 04:05:36.686: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 08/22/23 04:05:36.689
    Aug 22 04:05:36.706: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 22 04:05:36.706: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Aug 22 04:05:37.710: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:05:37.710: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 08/22/23 04:05:37.71
    Aug 22 04:05:37.827: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:05:37.827: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:05:38.930: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:05:38.930: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:05:39.832: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:05:39.832: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:05:40.844: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:05:40.844: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:05:41.832: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:05:41.832: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:05:42.833: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 22 04:05:42.833: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/22/23 04:05:42.841
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4302, will wait for the garbage collector to delete the pods 08/22/23 04:05:42.841
    Aug 22 04:05:42.907: INFO: Deleting DaemonSet.extensions daemon-set took: 12.452543ms
    Aug 22 04:05:43.008: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.539729ms
    Aug 22 04:05:45.513: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:05:45.514: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 22 04:05:45.516: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1251868"},"items":null}

    Aug 22 04:05:45.519: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1251868"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 04:05:45.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4302" for this suite. 08/22/23 04:05:45.703
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:05:45.711
Aug 22 04:05:45.711: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename namespaces 08/22/23 04:05:45.711
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:05:45.743
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:05:45.747
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 08/22/23 04:05:45.752
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:05:45.767
STEP: Creating a service in the namespace 08/22/23 04:05:45.77
STEP: Deleting the namespace 08/22/23 04:05:45.793
STEP: Waiting for the namespace to be removed. 08/22/23 04:05:45.808
STEP: Recreating the namespace 08/22/23 04:05:52.815
STEP: Verifying there is no service in the namespace 08/22/23 04:05:52.86
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Aug 22 04:05:52.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9735" for this suite. 08/22/23 04:05:52.868
STEP: Destroying namespace "nsdeletetest-5557" for this suite. 08/22/23 04:05:52.876
Aug 22 04:05:52.879: INFO: Namespace nsdeletetest-5557 was already deleted
STEP: Destroying namespace "nsdeletetest-5172" for this suite. 08/22/23 04:05:52.879
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":44,"skipped":713,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.174 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:05:45.711
    Aug 22 04:05:45.711: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename namespaces 08/22/23 04:05:45.711
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:05:45.743
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:05:45.747
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 08/22/23 04:05:45.752
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:05:45.767
    STEP: Creating a service in the namespace 08/22/23 04:05:45.77
    STEP: Deleting the namespace 08/22/23 04:05:45.793
    STEP: Waiting for the namespace to be removed. 08/22/23 04:05:45.808
    STEP: Recreating the namespace 08/22/23 04:05:52.815
    STEP: Verifying there is no service in the namespace 08/22/23 04:05:52.86
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 04:05:52.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-9735" for this suite. 08/22/23 04:05:52.868
    STEP: Destroying namespace "nsdeletetest-5557" for this suite. 08/22/23 04:05:52.876
    Aug 22 04:05:52.879: INFO: Namespace nsdeletetest-5557 was already deleted
    STEP: Destroying namespace "nsdeletetest-5172" for this suite. 08/22/23 04:05:52.879
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:05:52.89
Aug 22 04:05:52.890: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename discovery 08/22/23 04:05:52.89
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:05:52.906
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:05:52.91
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 08/22/23 04:05:52.92
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Aug 22 04:05:53.182: INFO: Checking APIGroup: apiregistration.k8s.io
Aug 22 04:05:53.184: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Aug 22 04:05:53.184: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Aug 22 04:05:53.184: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Aug 22 04:05:53.184: INFO: Checking APIGroup: apps
Aug 22 04:05:53.186: INFO: PreferredVersion.GroupVersion: apps/v1
Aug 22 04:05:53.186: INFO: Versions found [{apps/v1 v1}]
Aug 22 04:05:53.186: INFO: apps/v1 matches apps/v1
Aug 22 04:05:53.186: INFO: Checking APIGroup: events.k8s.io
Aug 22 04:05:53.187: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Aug 22 04:05:53.187: INFO: Versions found [{events.k8s.io/v1 v1}]
Aug 22 04:05:53.187: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Aug 22 04:05:53.187: INFO: Checking APIGroup: authentication.k8s.io
Aug 22 04:05:53.189: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Aug 22 04:05:53.189: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Aug 22 04:05:53.189: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Aug 22 04:05:53.189: INFO: Checking APIGroup: authorization.k8s.io
Aug 22 04:05:53.191: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Aug 22 04:05:53.191: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Aug 22 04:05:53.191: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Aug 22 04:05:53.191: INFO: Checking APIGroup: autoscaling
Aug 22 04:05:53.200: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Aug 22 04:05:53.200: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Aug 22 04:05:53.200: INFO: autoscaling/v2 matches autoscaling/v2
Aug 22 04:05:53.200: INFO: Checking APIGroup: batch
Aug 22 04:05:53.201: INFO: PreferredVersion.GroupVersion: batch/v1
Aug 22 04:05:53.201: INFO: Versions found [{batch/v1 v1}]
Aug 22 04:05:53.201: INFO: batch/v1 matches batch/v1
Aug 22 04:05:53.201: INFO: Checking APIGroup: certificates.k8s.io
Aug 22 04:05:53.203: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Aug 22 04:05:53.203: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Aug 22 04:05:53.203: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Aug 22 04:05:53.203: INFO: Checking APIGroup: networking.k8s.io
Aug 22 04:05:53.204: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Aug 22 04:05:53.204: INFO: Versions found [{networking.k8s.io/v1 v1} {networking.k8s.io/v1alpha1 v1alpha1}]
Aug 22 04:05:53.204: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Aug 22 04:05:53.204: INFO: Checking APIGroup: policy
Aug 22 04:05:53.205: INFO: PreferredVersion.GroupVersion: policy/v1
Aug 22 04:05:53.205: INFO: Versions found [{policy/v1 v1}]
Aug 22 04:05:53.205: INFO: policy/v1 matches policy/v1
Aug 22 04:05:53.205: INFO: Checking APIGroup: rbac.authorization.k8s.io
Aug 22 04:05:53.207: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Aug 22 04:05:53.207: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Aug 22 04:05:53.207: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Aug 22 04:05:53.207: INFO: Checking APIGroup: storage.k8s.io
Aug 22 04:05:53.208: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Aug 22 04:05:53.208: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Aug 22 04:05:53.208: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Aug 22 04:05:53.208: INFO: Checking APIGroup: admissionregistration.k8s.io
Aug 22 04:05:53.209: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Aug 22 04:05:53.209: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Aug 22 04:05:53.209: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Aug 22 04:05:53.209: INFO: Checking APIGroup: apiextensions.k8s.io
Aug 22 04:05:53.211: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Aug 22 04:05:53.211: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Aug 22 04:05:53.211: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Aug 22 04:05:53.211: INFO: Checking APIGroup: scheduling.k8s.io
Aug 22 04:05:53.212: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Aug 22 04:05:53.212: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Aug 22 04:05:53.212: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Aug 22 04:05:53.212: INFO: Checking APIGroup: coordination.k8s.io
Aug 22 04:05:53.213: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Aug 22 04:05:53.213: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Aug 22 04:05:53.213: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Aug 22 04:05:53.213: INFO: Checking APIGroup: node.k8s.io
Aug 22 04:05:53.215: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Aug 22 04:05:53.215: INFO: Versions found [{node.k8s.io/v1 v1}]
Aug 22 04:05:53.215: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Aug 22 04:05:53.215: INFO: Checking APIGroup: discovery.k8s.io
Aug 22 04:05:53.216: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Aug 22 04:05:53.216: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Aug 22 04:05:53.216: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Aug 22 04:05:53.216: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Aug 22 04:05:53.217: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Aug 22 04:05:53.217: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Aug 22 04:05:53.217: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Aug 22 04:05:53.217: INFO: Checking APIGroup: internal.apiserver.k8s.io
Aug 22 04:05:53.219: INFO: PreferredVersion.GroupVersion: internal.apiserver.k8s.io/v1alpha1
Aug 22 04:05:53.219: INFO: Versions found [{internal.apiserver.k8s.io/v1alpha1 v1alpha1}]
Aug 22 04:05:53.219: INFO: internal.apiserver.k8s.io/v1alpha1 matches internal.apiserver.k8s.io/v1alpha1
Aug 22 04:05:53.219: INFO: Checking APIGroup: metrics.k8s.io
Aug 22 04:05:53.220: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Aug 22 04:05:53.220: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Aug 22 04:05:53.220: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Aug 22 04:05:53.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-3234" for this suite. 08/22/23 04:05:53.225
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":45,"skipped":748,"failed":0}
------------------------------
â€¢ [0.344 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:05:52.89
    Aug 22 04:05:52.890: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename discovery 08/22/23 04:05:52.89
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:05:52.906
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:05:52.91
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 08/22/23 04:05:52.92
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Aug 22 04:05:53.182: INFO: Checking APIGroup: apiregistration.k8s.io
    Aug 22 04:05:53.184: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Aug 22 04:05:53.184: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Aug 22 04:05:53.184: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Aug 22 04:05:53.184: INFO: Checking APIGroup: apps
    Aug 22 04:05:53.186: INFO: PreferredVersion.GroupVersion: apps/v1
    Aug 22 04:05:53.186: INFO: Versions found [{apps/v1 v1}]
    Aug 22 04:05:53.186: INFO: apps/v1 matches apps/v1
    Aug 22 04:05:53.186: INFO: Checking APIGroup: events.k8s.io
    Aug 22 04:05:53.187: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Aug 22 04:05:53.187: INFO: Versions found [{events.k8s.io/v1 v1}]
    Aug 22 04:05:53.187: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Aug 22 04:05:53.187: INFO: Checking APIGroup: authentication.k8s.io
    Aug 22 04:05:53.189: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Aug 22 04:05:53.189: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Aug 22 04:05:53.189: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Aug 22 04:05:53.189: INFO: Checking APIGroup: authorization.k8s.io
    Aug 22 04:05:53.191: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Aug 22 04:05:53.191: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Aug 22 04:05:53.191: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Aug 22 04:05:53.191: INFO: Checking APIGroup: autoscaling
    Aug 22 04:05:53.200: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Aug 22 04:05:53.200: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Aug 22 04:05:53.200: INFO: autoscaling/v2 matches autoscaling/v2
    Aug 22 04:05:53.200: INFO: Checking APIGroup: batch
    Aug 22 04:05:53.201: INFO: PreferredVersion.GroupVersion: batch/v1
    Aug 22 04:05:53.201: INFO: Versions found [{batch/v1 v1}]
    Aug 22 04:05:53.201: INFO: batch/v1 matches batch/v1
    Aug 22 04:05:53.201: INFO: Checking APIGroup: certificates.k8s.io
    Aug 22 04:05:53.203: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Aug 22 04:05:53.203: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Aug 22 04:05:53.203: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Aug 22 04:05:53.203: INFO: Checking APIGroup: networking.k8s.io
    Aug 22 04:05:53.204: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Aug 22 04:05:53.204: INFO: Versions found [{networking.k8s.io/v1 v1} {networking.k8s.io/v1alpha1 v1alpha1}]
    Aug 22 04:05:53.204: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Aug 22 04:05:53.204: INFO: Checking APIGroup: policy
    Aug 22 04:05:53.205: INFO: PreferredVersion.GroupVersion: policy/v1
    Aug 22 04:05:53.205: INFO: Versions found [{policy/v1 v1}]
    Aug 22 04:05:53.205: INFO: policy/v1 matches policy/v1
    Aug 22 04:05:53.205: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Aug 22 04:05:53.207: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Aug 22 04:05:53.207: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Aug 22 04:05:53.207: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Aug 22 04:05:53.207: INFO: Checking APIGroup: storage.k8s.io
    Aug 22 04:05:53.208: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Aug 22 04:05:53.208: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Aug 22 04:05:53.208: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Aug 22 04:05:53.208: INFO: Checking APIGroup: admissionregistration.k8s.io
    Aug 22 04:05:53.209: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Aug 22 04:05:53.209: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Aug 22 04:05:53.209: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Aug 22 04:05:53.209: INFO: Checking APIGroup: apiextensions.k8s.io
    Aug 22 04:05:53.211: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Aug 22 04:05:53.211: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Aug 22 04:05:53.211: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Aug 22 04:05:53.211: INFO: Checking APIGroup: scheduling.k8s.io
    Aug 22 04:05:53.212: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Aug 22 04:05:53.212: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Aug 22 04:05:53.212: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Aug 22 04:05:53.212: INFO: Checking APIGroup: coordination.k8s.io
    Aug 22 04:05:53.213: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Aug 22 04:05:53.213: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Aug 22 04:05:53.213: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Aug 22 04:05:53.213: INFO: Checking APIGroup: node.k8s.io
    Aug 22 04:05:53.215: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Aug 22 04:05:53.215: INFO: Versions found [{node.k8s.io/v1 v1}]
    Aug 22 04:05:53.215: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Aug 22 04:05:53.215: INFO: Checking APIGroup: discovery.k8s.io
    Aug 22 04:05:53.216: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Aug 22 04:05:53.216: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Aug 22 04:05:53.216: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Aug 22 04:05:53.216: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Aug 22 04:05:53.217: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Aug 22 04:05:53.217: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Aug 22 04:05:53.217: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Aug 22 04:05:53.217: INFO: Checking APIGroup: internal.apiserver.k8s.io
    Aug 22 04:05:53.219: INFO: PreferredVersion.GroupVersion: internal.apiserver.k8s.io/v1alpha1
    Aug 22 04:05:53.219: INFO: Versions found [{internal.apiserver.k8s.io/v1alpha1 v1alpha1}]
    Aug 22 04:05:53.219: INFO: internal.apiserver.k8s.io/v1alpha1 matches internal.apiserver.k8s.io/v1alpha1
    Aug 22 04:05:53.219: INFO: Checking APIGroup: metrics.k8s.io
    Aug 22 04:05:53.220: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Aug 22 04:05:53.220: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Aug 22 04:05:53.220: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Aug 22 04:05:53.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-3234" for this suite. 08/22/23 04:05:53.225
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:05:53.236
Aug 22 04:05:53.236: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 04:05:53.237
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:05:53.289
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:05:53.292
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-1112 08/22/23 04:05:53.296
STEP: creating service affinity-clusterip in namespace services-1112 08/22/23 04:05:53.296
STEP: creating replication controller affinity-clusterip in namespace services-1112 08/22/23 04:05:53.493
I0822 04:05:53.505788      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-1112, replica count: 3
I0822 04:05:56.557140      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 04:05:59.557395      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 22 04:05:59.565: INFO: Creating new exec pod
Aug 22 04:05:59.575: INFO: Waiting up to 5m0s for pod "execpod-affinity6ltsw" in namespace "services-1112" to be "running"
Aug 22 04:05:59.708: INFO: Pod "execpod-affinity6ltsw": Phase="Pending", Reason="", readiness=false. Elapsed: 132.811895ms
Aug 22 04:06:01.714: INFO: Pod "execpod-affinity6ltsw": Phase="Running", Reason="", readiness=true. Elapsed: 2.138640025s
Aug 22 04:06:01.714: INFO: Pod "execpod-affinity6ltsw" satisfied condition "running"
Aug 22 04:06:02.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1112 exec execpod-affinity6ltsw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Aug 22 04:06:02.859: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Aug 22 04:06:02.859: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 04:06:02.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1112 exec execpod-affinity6ltsw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.222.42 80'
Aug 22 04:06:02.989: INFO: stderr: "+ nc -v -t -w 2 10.254.222.42 80\n+ echo hostName\nConnection to 10.254.222.42 80 port [tcp/http] succeeded!\n"
Aug 22 04:06:02.989: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 04:06:02.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1112 exec execpod-affinity6ltsw -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.254.222.42:80/ ; done'
Aug 22 04:06:03.168: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n"
Aug 22 04:06:03.168: INFO: stdout: "\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x"
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
Aug 22 04:06:03.168: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-1112, will wait for the garbage collector to delete the pods 08/22/23 04:06:03.379
Aug 22 04:06:03.440: INFO: Deleting ReplicationController affinity-clusterip took: 7.140568ms
Aug 22 04:06:03.541: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.982027ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 04:06:07.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1112" for this suite. 08/22/23 04:06:07.168
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":46,"skipped":779,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.943 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:05:53.236
    Aug 22 04:05:53.236: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 04:05:53.237
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:05:53.289
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:05:53.292
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-1112 08/22/23 04:05:53.296
    STEP: creating service affinity-clusterip in namespace services-1112 08/22/23 04:05:53.296
    STEP: creating replication controller affinity-clusterip in namespace services-1112 08/22/23 04:05:53.493
    I0822 04:05:53.505788      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-1112, replica count: 3
    I0822 04:05:56.557140      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0822 04:05:59.557395      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 22 04:05:59.565: INFO: Creating new exec pod
    Aug 22 04:05:59.575: INFO: Waiting up to 5m0s for pod "execpod-affinity6ltsw" in namespace "services-1112" to be "running"
    Aug 22 04:05:59.708: INFO: Pod "execpod-affinity6ltsw": Phase="Pending", Reason="", readiness=false. Elapsed: 132.811895ms
    Aug 22 04:06:01.714: INFO: Pod "execpod-affinity6ltsw": Phase="Running", Reason="", readiness=true. Elapsed: 2.138640025s
    Aug 22 04:06:01.714: INFO: Pod "execpod-affinity6ltsw" satisfied condition "running"
    Aug 22 04:06:02.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1112 exec execpod-affinity6ltsw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Aug 22 04:06:02.859: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Aug 22 04:06:02.859: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 04:06:02.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1112 exec execpod-affinity6ltsw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.222.42 80'
    Aug 22 04:06:02.989: INFO: stderr: "+ nc -v -t -w 2 10.254.222.42 80\n+ echo hostName\nConnection to 10.254.222.42 80 port [tcp/http] succeeded!\n"
    Aug 22 04:06:02.989: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 04:06:02.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1112 exec execpod-affinity6ltsw -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.254.222.42:80/ ; done'
    Aug 22 04:06:03.168: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.222.42:80/\n"
    Aug 22 04:06:03.168: INFO: stdout: "\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x\naffinity-clusterip-p4j5x"
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Received response from host: affinity-clusterip-p4j5x
    Aug 22 04:06:03.168: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-1112, will wait for the garbage collector to delete the pods 08/22/23 04:06:03.379
    Aug 22 04:06:03.440: INFO: Deleting ReplicationController affinity-clusterip took: 7.140568ms
    Aug 22 04:06:03.541: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.982027ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 04:06:07.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1112" for this suite. 08/22/23 04:06:07.168
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:06:07.18
Aug 22 04:06:07.180: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename statefulset 08/22/23 04:06:07.18
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:06:07.389
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:06:07.391
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2364 08/22/23 04:06:07.395
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 08/22/23 04:06:07.4
Aug 22 04:06:07.416: INFO: Found 0 stateful pods, waiting for 3
Aug 22 04:06:17.421: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 04:06:17.421: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 04:06:17.421: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 08/22/23 04:06:17.43
Aug 22 04:06:17.714: INFO: Updating stateful set ss2
STEP: Creating a new revision 08/22/23 04:06:17.714
STEP: Not applying an update when the partition is greater than the number of replicas 08/22/23 04:06:27.734
STEP: Performing a canary update 08/22/23 04:06:27.734
Aug 22 04:06:28.166: INFO: Updating stateful set ss2
Aug 22 04:06:28.171: INFO: Waiting for Pod statefulset-2364/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 08/22/23 04:06:38.18
Aug 22 04:06:38.425: INFO: Found 1 stateful pods, waiting for 3
Aug 22 04:06:48.429: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 04:06:48.429: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 04:06:48.429: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Aug 22 04:06:58.431: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 04:06:58.431: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 04:06:58.431: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 08/22/23 04:06:58.438
Aug 22 04:06:58.529: INFO: Updating stateful set ss2
Aug 22 04:06:58.546: INFO: Waiting for Pod statefulset-2364/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Aug 22 04:07:08.724: INFO: Updating stateful set ss2
Aug 22 04:07:08.904: INFO: Waiting for StatefulSet statefulset-2364/ss2 to complete update
Aug 22 04:07:08.904: INFO: Waiting for Pod statefulset-2364/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Aug 22 04:07:18.911: INFO: Waiting for StatefulSet statefulset-2364/ss2 to complete update
Aug 22 04:07:29.054: INFO: Waiting for StatefulSet statefulset-2364/ss2 to complete update
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 22 04:07:38.912: INFO: Deleting all statefulset in ns statefulset-2364
Aug 22 04:07:38.915: INFO: Scaling statefulset ss2 to 0
Aug 22 04:07:49.042: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 04:07:49.045: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 22 04:07:49.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2364" for this suite. 08/22/23 04:07:49.175
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":47,"skipped":784,"failed":0}
------------------------------
â€¢ [SLOW TEST] [102.011 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:06:07.18
    Aug 22 04:06:07.180: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename statefulset 08/22/23 04:06:07.18
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:06:07.389
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:06:07.391
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2364 08/22/23 04:06:07.395
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 08/22/23 04:06:07.4
    Aug 22 04:06:07.416: INFO: Found 0 stateful pods, waiting for 3
    Aug 22 04:06:17.421: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 22 04:06:17.421: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 22 04:06:17.421: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 08/22/23 04:06:17.43
    Aug 22 04:06:17.714: INFO: Updating stateful set ss2
    STEP: Creating a new revision 08/22/23 04:06:17.714
    STEP: Not applying an update when the partition is greater than the number of replicas 08/22/23 04:06:27.734
    STEP: Performing a canary update 08/22/23 04:06:27.734
    Aug 22 04:06:28.166: INFO: Updating stateful set ss2
    Aug 22 04:06:28.171: INFO: Waiting for Pod statefulset-2364/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 08/22/23 04:06:38.18
    Aug 22 04:06:38.425: INFO: Found 1 stateful pods, waiting for 3
    Aug 22 04:06:48.429: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 22 04:06:48.429: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 22 04:06:48.429: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
    Aug 22 04:06:58.431: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 22 04:06:58.431: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 22 04:06:58.431: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 08/22/23 04:06:58.438
    Aug 22 04:06:58.529: INFO: Updating stateful set ss2
    Aug 22 04:06:58.546: INFO: Waiting for Pod statefulset-2364/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Aug 22 04:07:08.724: INFO: Updating stateful set ss2
    Aug 22 04:07:08.904: INFO: Waiting for StatefulSet statefulset-2364/ss2 to complete update
    Aug 22 04:07:08.904: INFO: Waiting for Pod statefulset-2364/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Aug 22 04:07:18.911: INFO: Waiting for StatefulSet statefulset-2364/ss2 to complete update
    Aug 22 04:07:29.054: INFO: Waiting for StatefulSet statefulset-2364/ss2 to complete update
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 22 04:07:38.912: INFO: Deleting all statefulset in ns statefulset-2364
    Aug 22 04:07:38.915: INFO: Scaling statefulset ss2 to 0
    Aug 22 04:07:49.042: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 22 04:07:49.045: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 22 04:07:49.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2364" for this suite. 08/22/23 04:07:49.175
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:07:49.192
Aug 22 04:07:49.192: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename secrets 08/22/23 04:07:49.193
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:07:49.248
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:07:49.251
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 22 04:07:49.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7141" for this suite. 08/22/23 04:07:49.293
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":48,"skipped":788,"failed":0}
------------------------------
â€¢ [0.110 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:07:49.192
    Aug 22 04:07:49.192: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename secrets 08/22/23 04:07:49.193
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:07:49.248
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:07:49.251
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 22 04:07:49.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7141" for this suite. 08/22/23 04:07:49.293
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:07:49.304
Aug 22 04:07:49.304: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename ephemeral-containers-test 08/22/23 04:07:49.305
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:07:49.326
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:07:49.329
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 08/22/23 04:07:49.333
Aug 22 04:07:49.341: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-9262" to be "running and ready"
Aug 22 04:07:49.345: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.433031ms
Aug 22 04:07:49.345: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:07:51.533: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.191712929s
Aug 22 04:07:51.533: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:07:53.350: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.008277561s
Aug 22 04:07:53.350: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Aug 22 04:07:53.350: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 08/22/23 04:07:53.353
Aug 22 04:07:53.599: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-9262" to be "container debugger running"
Aug 22 04:07:53.603: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.636794ms
Aug 22 04:07:55.936: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.336771577s
Aug 22 04:07:55.936: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 08/22/23 04:07:55.936
Aug 22 04:07:55.936: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-9262 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 04:07:55.936: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 04:07:55.937: INFO: ExecWithOptions: Clientset creation
Aug 22 04:07:55.937: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/ephemeral-containers-test-9262/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Aug 22 04:07:56.018: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 22 04:07:56.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-9262" for this suite. 08/22/23 04:07:56.056
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":49,"skipped":801,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.759 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:07:49.304
    Aug 22 04:07:49.304: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename ephemeral-containers-test 08/22/23 04:07:49.305
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:07:49.326
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:07:49.329
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 08/22/23 04:07:49.333
    Aug 22 04:07:49.341: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-9262" to be "running and ready"
    Aug 22 04:07:49.345: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.433031ms
    Aug 22 04:07:49.345: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:07:51.533: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.191712929s
    Aug 22 04:07:51.533: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:07:53.350: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.008277561s
    Aug 22 04:07:53.350: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Aug 22 04:07:53.350: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 08/22/23 04:07:53.353
    Aug 22 04:07:53.599: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-9262" to be "container debugger running"
    Aug 22 04:07:53.603: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.636794ms
    Aug 22 04:07:55.936: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.336771577s
    Aug 22 04:07:55.936: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 08/22/23 04:07:55.936
    Aug 22 04:07:55.936: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-9262 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 04:07:55.936: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 04:07:55.937: INFO: ExecWithOptions: Clientset creation
    Aug 22 04:07:55.937: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/ephemeral-containers-test-9262/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Aug 22 04:07:56.018: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 22 04:07:56.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-9262" for this suite. 08/22/23 04:07:56.056
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:07:56.064
Aug 22 04:07:56.064: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-lifecycle-hook 08/22/23 04:07:56.065
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:07:56.383
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:07:56.386
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 08/22/23 04:07:56.396
Aug 22 04:07:56.597: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9811" to be "running and ready"
Aug 22 04:07:56.605: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 7.503107ms
Aug 22 04:07:56.605: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:07:58.610: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012138133s
Aug 22 04:07:58.610: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:08:00.823: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.22524392s
Aug 22 04:08:00.823: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Aug 22 04:08:00.823: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 08/22/23 04:08:00.826
Aug 22 04:08:00.834: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-9811" to be "running and ready"
Aug 22 04:08:00.838: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.37041ms
Aug 22 04:08:00.838: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:08:02.843: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009351656s
Aug 22 04:08:02.843: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:08:04.843: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.009125191s
Aug 22 04:08:04.843: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Aug 22 04:08:04.843: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 08/22/23 04:08:04.845
Aug 22 04:08:04.859: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 22 04:08:04.862: INFO: Pod pod-with-prestop-http-hook still exists
Aug 22 04:08:06.863: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 22 04:08:06.869: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 08/22/23 04:08:06.869
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Aug 22 04:08:06.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9811" for this suite. 08/22/23 04:08:06.908
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":50,"skipped":802,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.016 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:07:56.064
    Aug 22 04:07:56.064: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-lifecycle-hook 08/22/23 04:07:56.065
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:07:56.383
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:07:56.386
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 08/22/23 04:07:56.396
    Aug 22 04:07:56.597: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9811" to be "running and ready"
    Aug 22 04:07:56.605: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 7.503107ms
    Aug 22 04:07:56.605: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:07:58.610: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012138133s
    Aug 22 04:07:58.610: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:08:00.823: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.22524392s
    Aug 22 04:08:00.823: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Aug 22 04:08:00.823: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 08/22/23 04:08:00.826
    Aug 22 04:08:00.834: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-9811" to be "running and ready"
    Aug 22 04:08:00.838: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.37041ms
    Aug 22 04:08:00.838: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:08:02.843: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009351656s
    Aug 22 04:08:02.843: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:08:04.843: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.009125191s
    Aug 22 04:08:04.843: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Aug 22 04:08:04.843: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 08/22/23 04:08:04.845
    Aug 22 04:08:04.859: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Aug 22 04:08:04.862: INFO: Pod pod-with-prestop-http-hook still exists
    Aug 22 04:08:06.863: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Aug 22 04:08:06.869: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 08/22/23 04:08:06.869
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Aug 22 04:08:06.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-9811" for this suite. 08/22/23 04:08:06.908
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:08:07.08
Aug 22 04:08:07.080: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename job 08/22/23 04:08:07.081
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:08:07.455
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:08:07.461
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 08/22/23 04:08:07.464
STEP: Ensure pods equal to paralellism count is attached to the job 08/22/23 04:08:07.476
STEP: patching /status 08/22/23 04:08:11.482
STEP: updating /status 08/22/23 04:08:11.68
STEP: get /status 08/22/23 04:08:11.701
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 22 04:08:11.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2199" for this suite. 08/22/23 04:08:11.71
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":51,"skipped":807,"failed":0}
------------------------------
â€¢ [4.637 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:08:07.08
    Aug 22 04:08:07.080: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename job 08/22/23 04:08:07.081
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:08:07.455
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:08:07.461
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 08/22/23 04:08:07.464
    STEP: Ensure pods equal to paralellism count is attached to the job 08/22/23 04:08:07.476
    STEP: patching /status 08/22/23 04:08:11.482
    STEP: updating /status 08/22/23 04:08:11.68
    STEP: get /status 08/22/23 04:08:11.701
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 22 04:08:11.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-2199" for this suite. 08/22/23 04:08:11.71
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:08:11.717
Aug 22 04:08:11.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename statefulset 08/22/23 04:08:11.719
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:08:11.746
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:08:11.749
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1926 08/22/23 04:08:11.753
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 08/22/23 04:08:11.773
STEP: Creating pod with conflicting port in namespace statefulset-1926 08/22/23 04:08:11.792
STEP: Waiting until pod test-pod will start running in namespace statefulset-1926 08/22/23 04:08:11.802
Aug 22 04:08:11.802: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-1926" to be "running"
Aug 22 04:08:11.806: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.15194ms
Aug 22 04:08:13.812: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01010002s
Aug 22 04:08:15.854: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.052343627s
Aug 22 04:08:15.854: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-1926 08/22/23 04:08:15.854
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1926 08/22/23 04:08:15.986
Aug 22 04:08:16.406: INFO: Observed stateful pod in namespace: statefulset-1926, name: ss-0, uid: 5e814a38-5036-49f0-b0c8-98cf0ff00407, status phase: Pending. Waiting for statefulset controller to delete.
Aug 22 04:08:16.586: INFO: Observed stateful pod in namespace: statefulset-1926, name: ss-0, uid: 5e814a38-5036-49f0-b0c8-98cf0ff00407, status phase: Failed. Waiting for statefulset controller to delete.
Aug 22 04:08:16.622: INFO: Observed stateful pod in namespace: statefulset-1926, name: ss-0, uid: 5e814a38-5036-49f0-b0c8-98cf0ff00407, status phase: Failed. Waiting for statefulset controller to delete.
Aug 22 04:08:16.625: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1926
STEP: Removing pod with conflicting port in namespace statefulset-1926 08/22/23 04:08:16.625
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1926 and will be in running state 08/22/23 04:08:16.662
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 22 04:08:18.673: INFO: Deleting all statefulset in ns statefulset-1926
Aug 22 04:08:18.676: INFO: Scaling statefulset ss to 0
Aug 22 04:08:28.780: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 04:08:28.783: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 22 04:08:28.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1926" for this suite. 08/22/23 04:08:28.815
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":52,"skipped":815,"failed":0}
------------------------------
â€¢ [SLOW TEST] [17.310 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:08:11.717
    Aug 22 04:08:11.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename statefulset 08/22/23 04:08:11.719
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:08:11.746
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:08:11.749
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1926 08/22/23 04:08:11.753
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 08/22/23 04:08:11.773
    STEP: Creating pod with conflicting port in namespace statefulset-1926 08/22/23 04:08:11.792
    STEP: Waiting until pod test-pod will start running in namespace statefulset-1926 08/22/23 04:08:11.802
    Aug 22 04:08:11.802: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-1926" to be "running"
    Aug 22 04:08:11.806: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.15194ms
    Aug 22 04:08:13.812: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01010002s
    Aug 22 04:08:15.854: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.052343627s
    Aug 22 04:08:15.854: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-1926 08/22/23 04:08:15.854
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1926 08/22/23 04:08:15.986
    Aug 22 04:08:16.406: INFO: Observed stateful pod in namespace: statefulset-1926, name: ss-0, uid: 5e814a38-5036-49f0-b0c8-98cf0ff00407, status phase: Pending. Waiting for statefulset controller to delete.
    Aug 22 04:08:16.586: INFO: Observed stateful pod in namespace: statefulset-1926, name: ss-0, uid: 5e814a38-5036-49f0-b0c8-98cf0ff00407, status phase: Failed. Waiting for statefulset controller to delete.
    Aug 22 04:08:16.622: INFO: Observed stateful pod in namespace: statefulset-1926, name: ss-0, uid: 5e814a38-5036-49f0-b0c8-98cf0ff00407, status phase: Failed. Waiting for statefulset controller to delete.
    Aug 22 04:08:16.625: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1926
    STEP: Removing pod with conflicting port in namespace statefulset-1926 08/22/23 04:08:16.625
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1926 and will be in running state 08/22/23 04:08:16.662
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 22 04:08:18.673: INFO: Deleting all statefulset in ns statefulset-1926
    Aug 22 04:08:18.676: INFO: Scaling statefulset ss to 0
    Aug 22 04:08:28.780: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 22 04:08:28.783: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 22 04:08:28.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1926" for this suite. 08/22/23 04:08:28.815
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:08:29.03
Aug 22 04:08:29.030: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename secrets 08/22/23 04:08:29.031
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:08:29.045
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:08:29.047
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-f3277df3-b4f6-467d-b125-d1894b9d97b8 08/22/23 04:08:29.051
STEP: Creating a pod to test consume secrets 08/22/23 04:08:29.056
Aug 22 04:08:29.064: INFO: Waiting up to 5m0s for pod "pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0" in namespace "secrets-4649" to be "Succeeded or Failed"
Aug 22 04:08:29.071: INFO: Pod "pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.413579ms
Aug 22 04:08:31.076: INFO: Pod "pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012293636s
Aug 22 04:08:33.077: INFO: Pod "pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013315603s
Aug 22 04:08:35.076: INFO: Pod "pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012431234s
STEP: Saw pod success 08/22/23 04:08:35.076
Aug 22 04:08:35.077: INFO: Pod "pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0" satisfied condition "Succeeded or Failed"
Aug 22 04:08:35.080: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0 container secret-volume-test: <nil>
STEP: delete the pod 08/22/23 04:08:35.089
Aug 22 04:08:35.106: INFO: Waiting for pod pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0 to disappear
Aug 22 04:08:35.110: INFO: Pod pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 22 04:08:35.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4649" for this suite. 08/22/23 04:08:35.121
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":53,"skipped":819,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.231 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:08:29.03
    Aug 22 04:08:29.030: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename secrets 08/22/23 04:08:29.031
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:08:29.045
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:08:29.047
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-f3277df3-b4f6-467d-b125-d1894b9d97b8 08/22/23 04:08:29.051
    STEP: Creating a pod to test consume secrets 08/22/23 04:08:29.056
    Aug 22 04:08:29.064: INFO: Waiting up to 5m0s for pod "pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0" in namespace "secrets-4649" to be "Succeeded or Failed"
    Aug 22 04:08:29.071: INFO: Pod "pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.413579ms
    Aug 22 04:08:31.076: INFO: Pod "pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012293636s
    Aug 22 04:08:33.077: INFO: Pod "pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013315603s
    Aug 22 04:08:35.076: INFO: Pod "pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012431234s
    STEP: Saw pod success 08/22/23 04:08:35.076
    Aug 22 04:08:35.077: INFO: Pod "pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0" satisfied condition "Succeeded or Failed"
    Aug 22 04:08:35.080: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0 container secret-volume-test: <nil>
    STEP: delete the pod 08/22/23 04:08:35.089
    Aug 22 04:08:35.106: INFO: Waiting for pod pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0 to disappear
    Aug 22 04:08:35.110: INFO: Pod pod-secrets-337b24a4-5452-4fbf-b76d-22d09bcd73b0 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 22 04:08:35.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4649" for this suite. 08/22/23 04:08:35.121
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:08:35.263
Aug 22 04:08:35.263: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubelet-test 08/22/23 04:08:35.264
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:08:35.285
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:08:35.289
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 22 04:08:35.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3647" for this suite. 08/22/23 04:08:35.353
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":54,"skipped":821,"failed":0}
------------------------------
â€¢ [0.100 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:08:35.263
    Aug 22 04:08:35.263: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubelet-test 08/22/23 04:08:35.264
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:08:35.285
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:08:35.289
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 22 04:08:35.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-3647" for this suite. 08/22/23 04:08:35.353
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:08:35.365
Aug 22 04:08:35.365: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 04:08:35.366
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:08:35.389
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:08:35.395
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-7648/configmap-test-c035c230-2359-4eeb-b156-e00264b6b533 08/22/23 04:08:35.402
STEP: Creating a pod to test consume configMaps 08/22/23 04:08:35.418
Aug 22 04:08:35.433: INFO: Waiting up to 5m0s for pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e" in namespace "configmap-7648" to be "Succeeded or Failed"
Aug 22 04:08:35.443: INFO: Pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.279396ms
Aug 22 04:08:37.448: INFO: Pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015288792s
Aug 22 04:08:39.448: INFO: Pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015480332s
Aug 22 04:08:41.647: INFO: Pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.214049586s
Aug 22 04:08:43.447: INFO: Pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014521374s
Aug 22 04:08:45.448: INFO: Pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.015607602s
STEP: Saw pod success 08/22/23 04:08:45.449
Aug 22 04:08:45.449: INFO: Pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e" satisfied condition "Succeeded or Failed"
Aug 22 04:08:45.451: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e container env-test: <nil>
STEP: delete the pod 08/22/23 04:08:45.46
Aug 22 04:08:45.654: INFO: Waiting for pod pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e to disappear
Aug 22 04:08:45.658: INFO: Pod pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 04:08:45.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7648" for this suite. 08/22/23 04:08:45.664
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":55,"skipped":828,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.508 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:08:35.365
    Aug 22 04:08:35.365: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 04:08:35.366
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:08:35.389
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:08:35.395
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-7648/configmap-test-c035c230-2359-4eeb-b156-e00264b6b533 08/22/23 04:08:35.402
    STEP: Creating a pod to test consume configMaps 08/22/23 04:08:35.418
    Aug 22 04:08:35.433: INFO: Waiting up to 5m0s for pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e" in namespace "configmap-7648" to be "Succeeded or Failed"
    Aug 22 04:08:35.443: INFO: Pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.279396ms
    Aug 22 04:08:37.448: INFO: Pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015288792s
    Aug 22 04:08:39.448: INFO: Pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015480332s
    Aug 22 04:08:41.647: INFO: Pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.214049586s
    Aug 22 04:08:43.447: INFO: Pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014521374s
    Aug 22 04:08:45.448: INFO: Pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.015607602s
    STEP: Saw pod success 08/22/23 04:08:45.449
    Aug 22 04:08:45.449: INFO: Pod "pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e" satisfied condition "Succeeded or Failed"
    Aug 22 04:08:45.451: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e container env-test: <nil>
    STEP: delete the pod 08/22/23 04:08:45.46
    Aug 22 04:08:45.654: INFO: Waiting for pod pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e to disappear
    Aug 22 04:08:45.658: INFO: Pod pod-configmaps-bb956f85-2b02-42c9-a0eb-769fa7d4473e no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 04:08:45.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7648" for this suite. 08/22/23 04:08:45.664
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:08:45.877
Aug 22 04:08:45.877: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 04:08:45.878
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:08:45.911
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:08:45.915
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-3184 08/22/23 04:08:45.921
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3184 to expose endpoints map[] 08/22/23 04:08:45.937
Aug 22 04:08:45.958: INFO: successfully validated that service endpoint-test2 in namespace services-3184 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-3184 08/22/23 04:08:45.958
Aug 22 04:08:45.972: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-3184" to be "running and ready"
Aug 22 04:08:45.982: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.479681ms
Aug 22 04:08:45.982: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:08:47.987: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015088228s
Aug 22 04:08:47.987: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:08:49.986: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.014606013s
Aug 22 04:08:49.986: INFO: The phase of Pod pod1 is Running (Ready = true)
Aug 22 04:08:49.986: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3184 to expose endpoints map[pod1:[80]] 08/22/23 04:08:49.988
Aug 22 04:08:49.995: INFO: successfully validated that service endpoint-test2 in namespace services-3184 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 08/22/23 04:08:49.995
Aug 22 04:08:49.995: INFO: Creating new exec pod
Aug 22 04:08:50.165: INFO: Waiting up to 5m0s for pod "execpodzzdjx" in namespace "services-3184" to be "running"
Aug 22 04:08:50.184: INFO: Pod "execpodzzdjx": Phase="Pending", Reason="", readiness=false. Elapsed: 18.054713ms
Aug 22 04:08:52.188: INFO: Pod "execpodzzdjx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022962688s
Aug 22 04:08:54.187: INFO: Pod "execpodzzdjx": Phase="Running", Reason="", readiness=true. Elapsed: 4.021749352s
Aug 22 04:08:54.187: INFO: Pod "execpodzzdjx" satisfied condition "running"
Aug 22 04:08:55.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-3184 exec execpodzzdjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug 22 04:08:55.882: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug 22 04:08:55.882: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 04:08:55.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-3184 exec execpodzzdjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.184.213 80'
Aug 22 04:08:56.247: INFO: stderr: "+ nc -v -t -w 2 10.254.184.213 80\n+ echo hostName\nConnection to 10.254.184.213 80 port [tcp/http] succeeded!\n"
Aug 22 04:08:56.247: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-3184 08/22/23 04:08:56.247
Aug 22 04:08:56.255: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-3184" to be "running and ready"
Aug 22 04:08:56.260: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.698165ms
Aug 22 04:08:56.260: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:08:58.266: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010077207s
Aug 22 04:08:58.266: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:09:00.265: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.00913507s
Aug 22 04:09:00.265: INFO: The phase of Pod pod2 is Running (Ready = true)
Aug 22 04:09:00.265: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3184 to expose endpoints map[pod1:[80] pod2:[80]] 08/22/23 04:09:00.267
Aug 22 04:09:00.277: INFO: successfully validated that service endpoint-test2 in namespace services-3184 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 08/22/23 04:09:00.277
Aug 22 04:09:01.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-3184 exec execpodzzdjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug 22 04:09:01.423: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug 22 04:09:01.423: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 04:09:01.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-3184 exec execpodzzdjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.184.213 80'
Aug 22 04:09:01.569: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.184.213 80\nConnection to 10.254.184.213 80 port [tcp/http] succeeded!\n"
Aug 22 04:09:01.569: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-3184 08/22/23 04:09:01.569
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3184 to expose endpoints map[pod2:[80]] 08/22/23 04:09:01.589
Aug 22 04:09:01.602: INFO: successfully validated that service endpoint-test2 in namespace services-3184 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 08/22/23 04:09:01.602
Aug 22 04:09:02.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-3184 exec execpodzzdjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug 22 04:09:02.744: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug 22 04:09:02.744: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 04:09:02.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-3184 exec execpodzzdjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.184.213 80'
Aug 22 04:09:02.893: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.184.213 80\nConnection to 10.254.184.213 80 port [tcp/http] succeeded!\n"
Aug 22 04:09:02.893: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-3184 08/22/23 04:09:02.893
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3184 to expose endpoints map[] 08/22/23 04:09:02.927
Aug 22 04:09:02.942: INFO: successfully validated that service endpoint-test2 in namespace services-3184 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 04:09:02.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3184" for this suite. 08/22/23 04:09:02.972
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":56,"skipped":869,"failed":0}
------------------------------
â€¢ [SLOW TEST] [17.102 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:08:45.877
    Aug 22 04:08:45.877: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 04:08:45.878
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:08:45.911
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:08:45.915
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-3184 08/22/23 04:08:45.921
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3184 to expose endpoints map[] 08/22/23 04:08:45.937
    Aug 22 04:08:45.958: INFO: successfully validated that service endpoint-test2 in namespace services-3184 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-3184 08/22/23 04:08:45.958
    Aug 22 04:08:45.972: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-3184" to be "running and ready"
    Aug 22 04:08:45.982: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.479681ms
    Aug 22 04:08:45.982: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:08:47.987: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015088228s
    Aug 22 04:08:47.987: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:08:49.986: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.014606013s
    Aug 22 04:08:49.986: INFO: The phase of Pod pod1 is Running (Ready = true)
    Aug 22 04:08:49.986: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3184 to expose endpoints map[pod1:[80]] 08/22/23 04:08:49.988
    Aug 22 04:08:49.995: INFO: successfully validated that service endpoint-test2 in namespace services-3184 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 08/22/23 04:08:49.995
    Aug 22 04:08:49.995: INFO: Creating new exec pod
    Aug 22 04:08:50.165: INFO: Waiting up to 5m0s for pod "execpodzzdjx" in namespace "services-3184" to be "running"
    Aug 22 04:08:50.184: INFO: Pod "execpodzzdjx": Phase="Pending", Reason="", readiness=false. Elapsed: 18.054713ms
    Aug 22 04:08:52.188: INFO: Pod "execpodzzdjx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022962688s
    Aug 22 04:08:54.187: INFO: Pod "execpodzzdjx": Phase="Running", Reason="", readiness=true. Elapsed: 4.021749352s
    Aug 22 04:08:54.187: INFO: Pod "execpodzzdjx" satisfied condition "running"
    Aug 22 04:08:55.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-3184 exec execpodzzdjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Aug 22 04:08:55.882: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Aug 22 04:08:55.882: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 04:08:55.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-3184 exec execpodzzdjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.184.213 80'
    Aug 22 04:08:56.247: INFO: stderr: "+ nc -v -t -w 2 10.254.184.213 80\n+ echo hostName\nConnection to 10.254.184.213 80 port [tcp/http] succeeded!\n"
    Aug 22 04:08:56.247: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-3184 08/22/23 04:08:56.247
    Aug 22 04:08:56.255: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-3184" to be "running and ready"
    Aug 22 04:08:56.260: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.698165ms
    Aug 22 04:08:56.260: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:08:58.266: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010077207s
    Aug 22 04:08:58.266: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:09:00.265: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.00913507s
    Aug 22 04:09:00.265: INFO: The phase of Pod pod2 is Running (Ready = true)
    Aug 22 04:09:00.265: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3184 to expose endpoints map[pod1:[80] pod2:[80]] 08/22/23 04:09:00.267
    Aug 22 04:09:00.277: INFO: successfully validated that service endpoint-test2 in namespace services-3184 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 08/22/23 04:09:00.277
    Aug 22 04:09:01.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-3184 exec execpodzzdjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Aug 22 04:09:01.423: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Aug 22 04:09:01.423: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 04:09:01.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-3184 exec execpodzzdjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.184.213 80'
    Aug 22 04:09:01.569: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.184.213 80\nConnection to 10.254.184.213 80 port [tcp/http] succeeded!\n"
    Aug 22 04:09:01.569: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-3184 08/22/23 04:09:01.569
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3184 to expose endpoints map[pod2:[80]] 08/22/23 04:09:01.589
    Aug 22 04:09:01.602: INFO: successfully validated that service endpoint-test2 in namespace services-3184 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 08/22/23 04:09:01.602
    Aug 22 04:09:02.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-3184 exec execpodzzdjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Aug 22 04:09:02.744: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Aug 22 04:09:02.744: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 04:09:02.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-3184 exec execpodzzdjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.184.213 80'
    Aug 22 04:09:02.893: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.184.213 80\nConnection to 10.254.184.213 80 port [tcp/http] succeeded!\n"
    Aug 22 04:09:02.893: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-3184 08/22/23 04:09:02.893
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3184 to expose endpoints map[] 08/22/23 04:09:02.927
    Aug 22 04:09:02.942: INFO: successfully validated that service endpoint-test2 in namespace services-3184 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 04:09:02.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3184" for this suite. 08/22/23 04:09:02.972
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:09:02.98
Aug 22 04:09:02.980: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubelet-test 08/22/23 04:09:02.981
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:09:03.021
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:09:03.024
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Aug 22 04:09:03.039: INFO: Waiting up to 5m0s for pod "busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f" in namespace "kubelet-test-797" to be "running and ready"
Aug 22 04:09:03.043: INFO: Pod "busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.14655ms
Aug 22 04:09:03.043: INFO: The phase of Pod busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:09:05.050: INFO: Pod "busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010460416s
Aug 22 04:09:05.050: INFO: The phase of Pod busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:09:07.050: INFO: Pod "busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f": Phase="Running", Reason="", readiness=true. Elapsed: 4.0105052s
Aug 22 04:09:07.050: INFO: The phase of Pod busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f is Running (Ready = true)
Aug 22 04:09:07.050: INFO: Pod "busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 22 04:09:07.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-797" for this suite. 08/22/23 04:09:07.093
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":57,"skipped":887,"failed":0}
------------------------------
â€¢ [4.121 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:09:02.98
    Aug 22 04:09:02.980: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubelet-test 08/22/23 04:09:02.981
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:09:03.021
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:09:03.024
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Aug 22 04:09:03.039: INFO: Waiting up to 5m0s for pod "busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f" in namespace "kubelet-test-797" to be "running and ready"
    Aug 22 04:09:03.043: INFO: Pod "busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.14655ms
    Aug 22 04:09:03.043: INFO: The phase of Pod busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:09:05.050: INFO: Pod "busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010460416s
    Aug 22 04:09:05.050: INFO: The phase of Pod busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:09:07.050: INFO: Pod "busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f": Phase="Running", Reason="", readiness=true. Elapsed: 4.0105052s
    Aug 22 04:09:07.050: INFO: The phase of Pod busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f is Running (Ready = true)
    Aug 22 04:09:07.050: INFO: Pod "busybox-scheduling-a6f9a6ef-e9dd-4d93-be64-6cb19067fc8f" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 22 04:09:07.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-797" for this suite. 08/22/23 04:09:07.093
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:09:07.101
Aug 22 04:09:07.101: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 04:09:07.102
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:09:07.122
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:09:07.128
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 08/22/23 04:09:07.133
Aug 22 04:09:07.144: INFO: Waiting up to 5m0s for pod "downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6" in namespace "downward-api-2632" to be "Succeeded or Failed"
Aug 22 04:09:07.149: INFO: Pod "downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.673157ms
Aug 22 04:09:09.153: INFO: Pod "downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009527885s
Aug 22 04:09:11.157: INFO: Pod "downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012688165s
Aug 22 04:09:13.164: INFO: Pod "downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020156165s
STEP: Saw pod success 08/22/23 04:09:13.164
Aug 22 04:09:13.164: INFO: Pod "downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6" satisfied condition "Succeeded or Failed"
Aug 22 04:09:13.175: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6 container dapi-container: <nil>
STEP: delete the pod 08/22/23 04:09:13.185
Aug 22 04:09:13.437: INFO: Waiting for pod downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6 to disappear
Aug 22 04:09:13.442: INFO: Pod downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 22 04:09:13.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2632" for this suite. 08/22/23 04:09:13.447
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":58,"skipped":887,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.555 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:09:07.101
    Aug 22 04:09:07.101: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 04:09:07.102
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:09:07.122
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:09:07.128
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 08/22/23 04:09:07.133
    Aug 22 04:09:07.144: INFO: Waiting up to 5m0s for pod "downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6" in namespace "downward-api-2632" to be "Succeeded or Failed"
    Aug 22 04:09:07.149: INFO: Pod "downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.673157ms
    Aug 22 04:09:09.153: INFO: Pod "downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009527885s
    Aug 22 04:09:11.157: INFO: Pod "downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012688165s
    Aug 22 04:09:13.164: INFO: Pod "downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020156165s
    STEP: Saw pod success 08/22/23 04:09:13.164
    Aug 22 04:09:13.164: INFO: Pod "downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6" satisfied condition "Succeeded or Failed"
    Aug 22 04:09:13.175: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6 container dapi-container: <nil>
    STEP: delete the pod 08/22/23 04:09:13.185
    Aug 22 04:09:13.437: INFO: Waiting for pod downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6 to disappear
    Aug 22 04:09:13.442: INFO: Pod downward-api-e57a6f5c-f388-409c-9d6a-b778d10e49b6 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 22 04:09:13.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2632" for this suite. 08/22/23 04:09:13.447
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:09:13.656
Aug 22 04:09:13.657: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 04:09:13.657
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:09:13.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:09:13.693
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 08/22/23 04:09:13.697
Aug 22 04:09:13.708: INFO: Waiting up to 5m0s for pod "downward-api-f488e108-e055-4c8a-830c-bffd44366290" in namespace "downward-api-3754" to be "Succeeded or Failed"
Aug 22 04:09:13.713: INFO: Pod "downward-api-f488e108-e055-4c8a-830c-bffd44366290": Phase="Pending", Reason="", readiness=false. Elapsed: 5.482465ms
Aug 22 04:09:15.719: INFO: Pod "downward-api-f488e108-e055-4c8a-830c-bffd44366290": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010877899s
Aug 22 04:09:18.417: INFO: Pod "downward-api-f488e108-e055-4c8a-830c-bffd44366290": Phase="Pending", Reason="", readiness=false. Elapsed: 4.709345242s
Aug 22 04:09:19.717: INFO: Pod "downward-api-f488e108-e055-4c8a-830c-bffd44366290": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009338791s
STEP: Saw pod success 08/22/23 04:09:19.717
Aug 22 04:09:19.718: INFO: Pod "downward-api-f488e108-e055-4c8a-830c-bffd44366290" satisfied condition "Succeeded or Failed"
Aug 22 04:09:19.720: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downward-api-f488e108-e055-4c8a-830c-bffd44366290 container dapi-container: <nil>
STEP: delete the pod 08/22/23 04:09:19.731
Aug 22 04:09:19.858: INFO: Waiting for pod downward-api-f488e108-e055-4c8a-830c-bffd44366290 to disappear
Aug 22 04:09:19.861: INFO: Pod downward-api-f488e108-e055-4c8a-830c-bffd44366290 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 22 04:09:19.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3754" for this suite. 08/22/23 04:09:19.864
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":59,"skipped":897,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.214 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:09:13.656
    Aug 22 04:09:13.657: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 04:09:13.657
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:09:13.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:09:13.693
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 08/22/23 04:09:13.697
    Aug 22 04:09:13.708: INFO: Waiting up to 5m0s for pod "downward-api-f488e108-e055-4c8a-830c-bffd44366290" in namespace "downward-api-3754" to be "Succeeded or Failed"
    Aug 22 04:09:13.713: INFO: Pod "downward-api-f488e108-e055-4c8a-830c-bffd44366290": Phase="Pending", Reason="", readiness=false. Elapsed: 5.482465ms
    Aug 22 04:09:15.719: INFO: Pod "downward-api-f488e108-e055-4c8a-830c-bffd44366290": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010877899s
    Aug 22 04:09:18.417: INFO: Pod "downward-api-f488e108-e055-4c8a-830c-bffd44366290": Phase="Pending", Reason="", readiness=false. Elapsed: 4.709345242s
    Aug 22 04:09:19.717: INFO: Pod "downward-api-f488e108-e055-4c8a-830c-bffd44366290": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009338791s
    STEP: Saw pod success 08/22/23 04:09:19.717
    Aug 22 04:09:19.718: INFO: Pod "downward-api-f488e108-e055-4c8a-830c-bffd44366290" satisfied condition "Succeeded or Failed"
    Aug 22 04:09:19.720: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downward-api-f488e108-e055-4c8a-830c-bffd44366290 container dapi-container: <nil>
    STEP: delete the pod 08/22/23 04:09:19.731
    Aug 22 04:09:19.858: INFO: Waiting for pod downward-api-f488e108-e055-4c8a-830c-bffd44366290 to disappear
    Aug 22 04:09:19.861: INFO: Pod downward-api-f488e108-e055-4c8a-830c-bffd44366290 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 22 04:09:19.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3754" for this suite. 08/22/23 04:09:19.864
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:09:19.871
Aug 22 04:09:19.871: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename dns 08/22/23 04:09:19.872
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:09:19.888
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:09:19.89
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 08/22/23 04:09:19.895
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7629 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7629;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7629 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7629;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7629.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7629.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7629.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7629.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7629.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7629.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7629.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7629.svc;check="$$(dig +notcp +noall +answer +search 90.173.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.173.90_udp@PTR;check="$$(dig +tcp +noall +answer +search 90.173.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.173.90_tcp@PTR;sleep 1; done
 08/22/23 04:09:19.921
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7629 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7629;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7629 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7629;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7629.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7629.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7629.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7629.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7629.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7629.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7629.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7629.svc;check="$$(dig +notcp +noall +answer +search 90.173.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.173.90_udp@PTR;check="$$(dig +tcp +noall +answer +search 90.173.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.173.90_tcp@PTR;sleep 1; done
 08/22/23 04:09:19.921
STEP: creating a pod to probe DNS 08/22/23 04:09:19.921
STEP: submitting the pod to kubernetes 08/22/23 04:09:19.921
Aug 22 04:09:19.940: INFO: Waiting up to 15m0s for pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159" in namespace "dns-7629" to be "running"
Aug 22 04:09:19.954: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 13.826672ms
Aug 22 04:09:21.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01796182s
Aug 22 04:09:24.106: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 4.166136062s
Aug 22 04:09:25.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018369086s
Aug 22 04:09:27.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017708388s
Aug 22 04:09:29.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 10.019291177s
Aug 22 04:09:31.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 12.019296687s
Aug 22 04:09:33.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 14.018230609s
Aug 22 04:09:35.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 16.0188179s
Aug 22 04:09:37.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 18.01828433s
Aug 22 04:09:39.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 20.019008519s
Aug 22 04:09:41.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 22.017779213s
Aug 22 04:09:43.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 24.018430076s
Aug 22 04:09:45.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 26.019285261s
Aug 22 04:09:47.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 28.019085516s
Aug 22 04:09:49.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 30.018981231s
Aug 22 04:09:51.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 32.018195387s
Aug 22 04:09:53.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 34.018663456s
Aug 22 04:09:55.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 36.018029887s
Aug 22 04:09:57.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 38.01873397s
Aug 22 04:09:59.960: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 40.02056289s
Aug 22 04:10:01.966: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 42.026535646s
Aug 22 04:10:03.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 44.017989003s
Aug 22 04:10:05.961: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 46.020714716s
Aug 22 04:10:07.961: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 48.020955798s
Aug 22 04:10:09.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Running", Reason="", readiness=true. Elapsed: 50.01940001s
Aug 22 04:10:09.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159" satisfied condition "running"
STEP: retrieving the pod 08/22/23 04:10:09.959
STEP: looking for the results for each expected name from probers 08/22/23 04:10:09.966
Aug 22 04:10:09.973: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
Aug 22 04:10:09.978: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
Aug 22 04:10:09.982: INFO: Unable to read wheezy_udp@dns-test-service.dns-7629 from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
Aug 22 04:10:09.997: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7629 from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
Aug 22 04:10:10.001: INFO: Unable to read wheezy_udp@dns-test-service.dns-7629.svc from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
Aug 22 04:10:10.009: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7629.svc from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
Aug 22 04:10:10.013: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7629.svc from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
Aug 22 04:10:10.061: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
Aug 22 04:10:10.066: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
Aug 22 04:10:10.074: INFO: Unable to read jessie_tcp@dns-test-service.dns-7629 from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
Aug 22 04:10:10.079: INFO: Unable to read jessie_udp@dns-test-service.dns-7629.svc from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
Aug 22 04:10:10.083: INFO: Unable to read jessie_tcp@dns-test-service.dns-7629.svc from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
Aug 22 04:10:10.088: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7629.svc from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
Aug 22 04:10:10.092: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7629.svc from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
Aug 22 04:10:10.111: INFO: Lookups using dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7629 wheezy_tcp@dns-test-service.dns-7629 wheezy_udp@dns-test-service.dns-7629.svc wheezy_udp@_http._tcp.dns-test-service.dns-7629.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7629.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_tcp@dns-test-service.dns-7629 jessie_udp@dns-test-service.dns-7629.svc jessie_tcp@dns-test-service.dns-7629.svc jessie_udp@_http._tcp.dns-test-service.dns-7629.svc jessie_tcp@_http._tcp.dns-test-service.dns-7629.svc]

Aug 22 04:10:15.196: INFO: DNS probes using dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159 succeeded

STEP: deleting the pod 08/22/23 04:10:15.196
STEP: deleting the test service 08/22/23 04:10:15.293
STEP: deleting the test headless service 08/22/23 04:10:15.324
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 22 04:10:15.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7629" for this suite. 08/22/23 04:10:15.363
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":60,"skipped":907,"failed":0}
------------------------------
â€¢ [SLOW TEST] [55.501 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:09:19.871
    Aug 22 04:09:19.871: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename dns 08/22/23 04:09:19.872
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:09:19.888
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:09:19.89
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 08/22/23 04:09:19.895
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7629 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7629;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7629 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7629;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7629.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7629.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7629.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7629.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7629.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7629.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7629.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7629.svc;check="$$(dig +notcp +noall +answer +search 90.173.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.173.90_udp@PTR;check="$$(dig +tcp +noall +answer +search 90.173.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.173.90_tcp@PTR;sleep 1; done
     08/22/23 04:09:19.921
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7629 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7629;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7629 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7629;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7629.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7629.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7629.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7629.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7629.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7629.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7629.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7629.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7629.svc;check="$$(dig +notcp +noall +answer +search 90.173.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.173.90_udp@PTR;check="$$(dig +tcp +noall +answer +search 90.173.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.173.90_tcp@PTR;sleep 1; done
     08/22/23 04:09:19.921
    STEP: creating a pod to probe DNS 08/22/23 04:09:19.921
    STEP: submitting the pod to kubernetes 08/22/23 04:09:19.921
    Aug 22 04:09:19.940: INFO: Waiting up to 15m0s for pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159" in namespace "dns-7629" to be "running"
    Aug 22 04:09:19.954: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 13.826672ms
    Aug 22 04:09:21.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01796182s
    Aug 22 04:09:24.106: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 4.166136062s
    Aug 22 04:09:25.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018369086s
    Aug 22 04:09:27.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017708388s
    Aug 22 04:09:29.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 10.019291177s
    Aug 22 04:09:31.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 12.019296687s
    Aug 22 04:09:33.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 14.018230609s
    Aug 22 04:09:35.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 16.0188179s
    Aug 22 04:09:37.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 18.01828433s
    Aug 22 04:09:39.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 20.019008519s
    Aug 22 04:09:41.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 22.017779213s
    Aug 22 04:09:43.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 24.018430076s
    Aug 22 04:09:45.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 26.019285261s
    Aug 22 04:09:47.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 28.019085516s
    Aug 22 04:09:49.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 30.018981231s
    Aug 22 04:09:51.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 32.018195387s
    Aug 22 04:09:53.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 34.018663456s
    Aug 22 04:09:55.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 36.018029887s
    Aug 22 04:09:57.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 38.01873397s
    Aug 22 04:09:59.960: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 40.02056289s
    Aug 22 04:10:01.966: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 42.026535646s
    Aug 22 04:10:03.958: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 44.017989003s
    Aug 22 04:10:05.961: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 46.020714716s
    Aug 22 04:10:07.961: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Pending", Reason="", readiness=false. Elapsed: 48.020955798s
    Aug 22 04:10:09.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159": Phase="Running", Reason="", readiness=true. Elapsed: 50.01940001s
    Aug 22 04:10:09.959: INFO: Pod "dns-test-3949ab5f-d905-4323-9a9d-106ade249159" satisfied condition "running"
    STEP: retrieving the pod 08/22/23 04:10:09.959
    STEP: looking for the results for each expected name from probers 08/22/23 04:10:09.966
    Aug 22 04:10:09.973: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
    Aug 22 04:10:09.978: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
    Aug 22 04:10:09.982: INFO: Unable to read wheezy_udp@dns-test-service.dns-7629 from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
    Aug 22 04:10:09.997: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7629 from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
    Aug 22 04:10:10.001: INFO: Unable to read wheezy_udp@dns-test-service.dns-7629.svc from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
    Aug 22 04:10:10.009: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7629.svc from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
    Aug 22 04:10:10.013: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7629.svc from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
    Aug 22 04:10:10.061: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
    Aug 22 04:10:10.066: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
    Aug 22 04:10:10.074: INFO: Unable to read jessie_tcp@dns-test-service.dns-7629 from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
    Aug 22 04:10:10.079: INFO: Unable to read jessie_udp@dns-test-service.dns-7629.svc from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
    Aug 22 04:10:10.083: INFO: Unable to read jessie_tcp@dns-test-service.dns-7629.svc from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
    Aug 22 04:10:10.088: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7629.svc from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
    Aug 22 04:10:10.092: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7629.svc from pod dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159: the server could not find the requested resource (get pods dns-test-3949ab5f-d905-4323-9a9d-106ade249159)
    Aug 22 04:10:10.111: INFO: Lookups using dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7629 wheezy_tcp@dns-test-service.dns-7629 wheezy_udp@dns-test-service.dns-7629.svc wheezy_udp@_http._tcp.dns-test-service.dns-7629.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7629.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_tcp@dns-test-service.dns-7629 jessie_udp@dns-test-service.dns-7629.svc jessie_tcp@dns-test-service.dns-7629.svc jessie_udp@_http._tcp.dns-test-service.dns-7629.svc jessie_tcp@_http._tcp.dns-test-service.dns-7629.svc]

    Aug 22 04:10:15.196: INFO: DNS probes using dns-7629/dns-test-3949ab5f-d905-4323-9a9d-106ade249159 succeeded

    STEP: deleting the pod 08/22/23 04:10:15.196
    STEP: deleting the test service 08/22/23 04:10:15.293
    STEP: deleting the test headless service 08/22/23 04:10:15.324
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 22 04:10:15.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7629" for this suite. 08/22/23 04:10:15.363
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:10:15.374
Aug 22 04:10:15.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename crd-watch 08/22/23 04:10:15.375
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:10:15.402
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:10:15.409
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Aug 22 04:10:15.416: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Creating first CR  08/22/23 04:10:17.972
Aug 22 04:10:17.977: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-08-22T04:10:17Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-08-22T04:10:17Z]] name:name1 resourceVersion:1253706 uid:c5f6344f-d5a5-4be5-85e3-bd30fbb1f8cd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 08/22/23 04:10:27.977
Aug 22 04:10:27.986: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-08-22T04:10:27Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-08-22T04:10:27Z]] name:name2 resourceVersion:1253758 uid:6108f1e7-317f-4da4-864b-7264333a86f0] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 08/22/23 04:10:37.986
Aug 22 04:10:37.996: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-08-22T04:10:17Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-08-22T04:10:37Z]] name:name1 resourceVersion:1253791 uid:c5f6344f-d5a5-4be5-85e3-bd30fbb1f8cd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 08/22/23 04:10:47.997
Aug 22 04:10:48.007: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-08-22T04:10:27Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-08-22T04:10:48Z]] name:name2 resourceVersion:1253825 uid:6108f1e7-317f-4da4-864b-7264333a86f0] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 08/22/23 04:10:58.007
Aug 22 04:10:58.016: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-08-22T04:10:17Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-08-22T04:10:37Z]] name:name1 resourceVersion:1253859 uid:c5f6344f-d5a5-4be5-85e3-bd30fbb1f8cd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 08/22/23 04:11:08.017
Aug 22 04:11:08.025: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-08-22T04:10:27Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-08-22T04:10:48Z]] name:name2 resourceVersion:1253893 uid:6108f1e7-317f-4da4-864b-7264333a86f0] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:11:18.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-7564" for this suite. 08/22/23 04:11:18.547
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":61,"skipped":919,"failed":0}
------------------------------
â€¢ [SLOW TEST] [63.339 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:10:15.374
    Aug 22 04:10:15.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename crd-watch 08/22/23 04:10:15.375
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:10:15.402
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:10:15.409
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Aug 22 04:10:15.416: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Creating first CR  08/22/23 04:10:17.972
    Aug 22 04:10:17.977: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-08-22T04:10:17Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-08-22T04:10:17Z]] name:name1 resourceVersion:1253706 uid:c5f6344f-d5a5-4be5-85e3-bd30fbb1f8cd] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 08/22/23 04:10:27.977
    Aug 22 04:10:27.986: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-08-22T04:10:27Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-08-22T04:10:27Z]] name:name2 resourceVersion:1253758 uid:6108f1e7-317f-4da4-864b-7264333a86f0] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 08/22/23 04:10:37.986
    Aug 22 04:10:37.996: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-08-22T04:10:17Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-08-22T04:10:37Z]] name:name1 resourceVersion:1253791 uid:c5f6344f-d5a5-4be5-85e3-bd30fbb1f8cd] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 08/22/23 04:10:47.997
    Aug 22 04:10:48.007: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-08-22T04:10:27Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-08-22T04:10:48Z]] name:name2 resourceVersion:1253825 uid:6108f1e7-317f-4da4-864b-7264333a86f0] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 08/22/23 04:10:58.007
    Aug 22 04:10:58.016: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-08-22T04:10:17Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-08-22T04:10:37Z]] name:name1 resourceVersion:1253859 uid:c5f6344f-d5a5-4be5-85e3-bd30fbb1f8cd] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 08/22/23 04:11:08.017
    Aug 22 04:11:08.025: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-08-22T04:10:27Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-08-22T04:10:48Z]] name:name2 resourceVersion:1253893 uid:6108f1e7-317f-4da4-864b-7264333a86f0] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:11:18.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-7564" for this suite. 08/22/23 04:11:18.547
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:11:18.713
Aug 22 04:11:18.713: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename runtimeclass 08/22/23 04:11:18.713
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:11:18.732
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:11:18.735
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 22 04:11:18.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-6220" for this suite. 08/22/23 04:11:18.748
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":62,"skipped":930,"failed":0}
------------------------------
â€¢ [0.042 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:11:18.713
    Aug 22 04:11:18.713: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename runtimeclass 08/22/23 04:11:18.713
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:11:18.732
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:11:18.735
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 22 04:11:18.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-6220" for this suite. 08/22/23 04:11:18.748
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:11:18.758
Aug 22 04:11:18.758: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 04:11:18.759
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:11:18.775
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:11:18.778
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 08/22/23 04:11:18.781
Aug 22 04:11:18.789: INFO: Waiting up to 5m0s for pod "pod-7076e8fd-31ca-4454-b020-61db62ad5e39" in namespace "emptydir-4412" to be "Succeeded or Failed"
Aug 22 04:11:18.793: INFO: Pod "pod-7076e8fd-31ca-4454-b020-61db62ad5e39": Phase="Pending", Reason="", readiness=false. Elapsed: 3.351106ms
Aug 22 04:11:20.798: INFO: Pod "pod-7076e8fd-31ca-4454-b020-61db62ad5e39": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00833648s
Aug 22 04:11:22.846: INFO: Pod "pod-7076e8fd-31ca-4454-b020-61db62ad5e39": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056372466s
Aug 22 04:11:24.798: INFO: Pod "pod-7076e8fd-31ca-4454-b020-61db62ad5e39": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008292498s
STEP: Saw pod success 08/22/23 04:11:24.798
Aug 22 04:11:24.798: INFO: Pod "pod-7076e8fd-31ca-4454-b020-61db62ad5e39" satisfied condition "Succeeded or Failed"
Aug 22 04:11:24.801: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-7076e8fd-31ca-4454-b020-61db62ad5e39 container test-container: <nil>
STEP: delete the pod 08/22/23 04:11:24.829
Aug 22 04:11:25.215: INFO: Waiting for pod pod-7076e8fd-31ca-4454-b020-61db62ad5e39 to disappear
Aug 22 04:11:25.220: INFO: Pod pod-7076e8fd-31ca-4454-b020-61db62ad5e39 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 04:11:25.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4412" for this suite. 08/22/23 04:11:25.227
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":63,"skipped":990,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.479 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:11:18.758
    Aug 22 04:11:18.758: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 04:11:18.759
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:11:18.775
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:11:18.778
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 08/22/23 04:11:18.781
    Aug 22 04:11:18.789: INFO: Waiting up to 5m0s for pod "pod-7076e8fd-31ca-4454-b020-61db62ad5e39" in namespace "emptydir-4412" to be "Succeeded or Failed"
    Aug 22 04:11:18.793: INFO: Pod "pod-7076e8fd-31ca-4454-b020-61db62ad5e39": Phase="Pending", Reason="", readiness=false. Elapsed: 3.351106ms
    Aug 22 04:11:20.798: INFO: Pod "pod-7076e8fd-31ca-4454-b020-61db62ad5e39": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00833648s
    Aug 22 04:11:22.846: INFO: Pod "pod-7076e8fd-31ca-4454-b020-61db62ad5e39": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056372466s
    Aug 22 04:11:24.798: INFO: Pod "pod-7076e8fd-31ca-4454-b020-61db62ad5e39": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008292498s
    STEP: Saw pod success 08/22/23 04:11:24.798
    Aug 22 04:11:24.798: INFO: Pod "pod-7076e8fd-31ca-4454-b020-61db62ad5e39" satisfied condition "Succeeded or Failed"
    Aug 22 04:11:24.801: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-7076e8fd-31ca-4454-b020-61db62ad5e39 container test-container: <nil>
    STEP: delete the pod 08/22/23 04:11:24.829
    Aug 22 04:11:25.215: INFO: Waiting for pod pod-7076e8fd-31ca-4454-b020-61db62ad5e39 to disappear
    Aug 22 04:11:25.220: INFO: Pod pod-7076e8fd-31ca-4454-b020-61db62ad5e39 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 04:11:25.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4412" for this suite. 08/22/23 04:11:25.227
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:11:25.238
Aug 22 04:11:25.238: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubelet-test 08/22/23 04:11:25.239
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:11:25.651
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:11:25.656
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 22 04:11:29.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3057" for this suite. 08/22/23 04:11:29.865
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":64,"skipped":1004,"failed":0}
------------------------------
â€¢ [4.753 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:11:25.238
    Aug 22 04:11:25.238: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubelet-test 08/22/23 04:11:25.239
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:11:25.651
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:11:25.656
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 22 04:11:29.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-3057" for this suite. 08/22/23 04:11:29.865
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:11:29.992
Aug 22 04:11:29.992: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename svcaccounts 08/22/23 04:11:29.993
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:11:30.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:11:30.011
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Aug 22 04:11:30.031: INFO: created pod
Aug 22 04:11:30.031: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-4221" to be "Succeeded or Failed"
Aug 22 04:11:30.037: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.426419ms
Aug 22 04:11:32.107: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075077667s
Aug 22 04:11:34.043: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011631532s
Aug 22 04:11:36.161: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.130052812s
STEP: Saw pod success 08/22/23 04:11:36.162
Aug 22 04:11:36.162: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Aug 22 04:12:06.162: INFO: polling logs
Aug 22 04:12:06.241: INFO: Pod logs: 
I0822 04:11:32.602585       1 log.go:195] OK: Got token
I0822 04:11:32.602610       1 log.go:195] validating with in-cluster discovery
I0822 04:11:32.603298       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
I0822 04:11:32.603381       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-4221:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1692678090, NotBefore:1692677490, IssuedAt:1692677490, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4221", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"96e5087e-05ae-4e3e-a8f4-49932eb62357"}}}
I0822 04:11:32.621700       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
I0822 04:11:32.634764       1 log.go:195] OK: Validated signature on JWT
I0822 04:11:32.634855       1 log.go:195] OK: Got valid claims from token!
I0822 04:11:32.634943       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-4221:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1692678090, NotBefore:1692677490, IssuedAt:1692677490, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4221", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"96e5087e-05ae-4e3e-a8f4-49932eb62357"}}}

Aug 22 04:12:06.241: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 22 04:12:06.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4221" for this suite. 08/22/23 04:12:06.258
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":65,"skipped":1028,"failed":0}
------------------------------
â€¢ [SLOW TEST] [36.273 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:11:29.992
    Aug 22 04:11:29.992: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename svcaccounts 08/22/23 04:11:29.993
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:11:30.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:11:30.011
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Aug 22 04:11:30.031: INFO: created pod
    Aug 22 04:11:30.031: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-4221" to be "Succeeded or Failed"
    Aug 22 04:11:30.037: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.426419ms
    Aug 22 04:11:32.107: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075077667s
    Aug 22 04:11:34.043: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011631532s
    Aug 22 04:11:36.161: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.130052812s
    STEP: Saw pod success 08/22/23 04:11:36.162
    Aug 22 04:11:36.162: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Aug 22 04:12:06.162: INFO: polling logs
    Aug 22 04:12:06.241: INFO: Pod logs: 
    I0822 04:11:32.602585       1 log.go:195] OK: Got token
    I0822 04:11:32.602610       1 log.go:195] validating with in-cluster discovery
    I0822 04:11:32.603298       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
    I0822 04:11:32.603381       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-4221:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1692678090, NotBefore:1692677490, IssuedAt:1692677490, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4221", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"96e5087e-05ae-4e3e-a8f4-49932eb62357"}}}
    I0822 04:11:32.621700       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
    I0822 04:11:32.634764       1 log.go:195] OK: Validated signature on JWT
    I0822 04:11:32.634855       1 log.go:195] OK: Got valid claims from token!
    I0822 04:11:32.634943       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-4221:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1692678090, NotBefore:1692677490, IssuedAt:1692677490, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4221", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"96e5087e-05ae-4e3e-a8f4-49932eb62357"}}}

    Aug 22 04:12:06.241: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 22 04:12:06.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4221" for this suite. 08/22/23 04:12:06.258
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:12:06.266
Aug 22 04:12:06.266: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 04:12:06.267
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:12:06.284
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:12:06.287
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 08/22/23 04:12:06.291
Aug 22 04:12:06.301: INFO: Waiting up to 5m0s for pod "pod-3a90b213-a8b4-40f7-8711-632d0891cdd9" in namespace "emptydir-8277" to be "Succeeded or Failed"
Aug 22 04:12:06.306: INFO: Pod "pod-3a90b213-a8b4-40f7-8711-632d0891cdd9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.341041ms
Aug 22 04:12:08.373: INFO: Pod "pod-3a90b213-a8b4-40f7-8711-632d0891cdd9": Phase="Running", Reason="", readiness=true. Elapsed: 2.072340734s
Aug 22 04:12:10.312: INFO: Pod "pod-3a90b213-a8b4-40f7-8711-632d0891cdd9": Phase="Running", Reason="", readiness=false. Elapsed: 4.011322944s
Aug 22 04:12:12.336: INFO: Pod "pod-3a90b213-a8b4-40f7-8711-632d0891cdd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035191292s
STEP: Saw pod success 08/22/23 04:12:12.336
Aug 22 04:12:12.337: INFO: Pod "pod-3a90b213-a8b4-40f7-8711-632d0891cdd9" satisfied condition "Succeeded or Failed"
Aug 22 04:12:12.340: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-3a90b213-a8b4-40f7-8711-632d0891cdd9 container test-container: <nil>
STEP: delete the pod 08/22/23 04:12:12.346
Aug 22 04:12:12.369: INFO: Waiting for pod pod-3a90b213-a8b4-40f7-8711-632d0891cdd9 to disappear
Aug 22 04:12:12.372: INFO: Pod pod-3a90b213-a8b4-40f7-8711-632d0891cdd9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 04:12:12.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8277" for this suite. 08/22/23 04:12:12.376
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":66,"skipped":1028,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.115 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:12:06.266
    Aug 22 04:12:06.266: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 04:12:06.267
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:12:06.284
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:12:06.287
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 08/22/23 04:12:06.291
    Aug 22 04:12:06.301: INFO: Waiting up to 5m0s for pod "pod-3a90b213-a8b4-40f7-8711-632d0891cdd9" in namespace "emptydir-8277" to be "Succeeded or Failed"
    Aug 22 04:12:06.306: INFO: Pod "pod-3a90b213-a8b4-40f7-8711-632d0891cdd9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.341041ms
    Aug 22 04:12:08.373: INFO: Pod "pod-3a90b213-a8b4-40f7-8711-632d0891cdd9": Phase="Running", Reason="", readiness=true. Elapsed: 2.072340734s
    Aug 22 04:12:10.312: INFO: Pod "pod-3a90b213-a8b4-40f7-8711-632d0891cdd9": Phase="Running", Reason="", readiness=false. Elapsed: 4.011322944s
    Aug 22 04:12:12.336: INFO: Pod "pod-3a90b213-a8b4-40f7-8711-632d0891cdd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035191292s
    STEP: Saw pod success 08/22/23 04:12:12.336
    Aug 22 04:12:12.337: INFO: Pod "pod-3a90b213-a8b4-40f7-8711-632d0891cdd9" satisfied condition "Succeeded or Failed"
    Aug 22 04:12:12.340: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-3a90b213-a8b4-40f7-8711-632d0891cdd9 container test-container: <nil>
    STEP: delete the pod 08/22/23 04:12:12.346
    Aug 22 04:12:12.369: INFO: Waiting for pod pod-3a90b213-a8b4-40f7-8711-632d0891cdd9 to disappear
    Aug 22 04:12:12.372: INFO: Pod pod-3a90b213-a8b4-40f7-8711-632d0891cdd9 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 04:12:12.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8277" for this suite. 08/22/23 04:12:12.376
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:12:12.383
Aug 22 04:12:12.383: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename deployment 08/22/23 04:12:12.384
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:12:12.399
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:12:12.401
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Aug 22 04:12:12.405: INFO: Creating simple deployment test-new-deployment
Aug 22 04:12:12.446: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"test-new-deployment-845c8977d9\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Aug 22 04:12:14.452: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: getting scale subresource 08/22/23 04:12:16.453
STEP: updating a scale subresource 08/22/23 04:12:16.456
STEP: verifying the deployment Spec.Replicas was modified 08/22/23 04:12:16.557
STEP: Patch a scale subresource 08/22/23 04:12:16.6
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 22 04:12:16.745: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-8900  6c3ba4d8-4c77-41a3-a567-001869554957 1254256 3 2023-08-22 04:12:12 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-08-22 04:12:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003329408 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-08-22 04:12:16 +0000 UTC,LastTransitionTime:2023-08-22 04:12:12 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-08-22 04:12:16 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 22 04:12:16.755: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-8900  5ac682ff-8024-4278-959d-90ce328e8078 1254258 3 2023-08-22 04:12:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 6c3ba4d8-4c77-41a3-a567-001869554957 0xc003329857 0xc003329858}] [] [{kube-controller-manager Update apps/v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6c3ba4d8-4c77-41a3-a567-001869554957\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0033298e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 22 04:12:16.762: INFO: Pod "test-new-deployment-845c8977d9-cc4lr" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-cc4lr test-new-deployment-845c8977d9- deployment-8900  96caa714-5dce-498e-af07-76ca6a512f83 1254267 0 2023-08-22 04:12:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 5ac682ff-8024-4278-959d-90ce328e8078 0xc0039c4fc7 0xc0039c4fc8}] [] [{kube-controller-manager Update v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ac682ff-8024-4278-959d-90ce328e8078\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mqrl7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mqrl7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:12:16.763: INFO: Pod "test-new-deployment-845c8977d9-n69m8" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-n69m8 test-new-deployment-845c8977d9- deployment-8900  058d35ad-0236-4a70-957d-f603024ecdbe 1254266 0 2023-08-22 04:12:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 5ac682ff-8024-4278-959d-90ce328e8078 0xc0039c5157 0xc0039c5158}] [] [{kube-controller-manager Update v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ac682ff-8024-4278-959d-90ce328e8078\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vvpxz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vvpxz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:12:16.763: INFO: Pod "test-new-deployment-845c8977d9-rmbnz" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-rmbnz test-new-deployment-845c8977d9- deployment-8900  6de4fc94-d5ce-4575-bbfb-3b90e52d4ef1 1254241 0 2023-08-22 04:12:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 5ac682ff-8024-4278-959d-90ce328e8078 0xc0039c52b7 0xc0039c52b8}] [] [{kube-controller-manager Update v1 2023-08-22 04:12:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ac682ff-8024-4278-959d-90ce328e8078\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.54\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wtmx4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wtmx4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:10.100.4.54,StartTime:2023-08-22 04:12:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:12:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f28b94121c9f95ceaf0e96d7ee2bf003719d6c202acdd5623594f29c390dea1e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.4.54,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:12:16.763: INFO: Pod "test-new-deployment-845c8977d9-xrm4g" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-xrm4g test-new-deployment-845c8977d9- deployment-8900  40c09982-a16d-4ad0-aa47-9de005dbd33f 1254261 0 2023-08-22 04:12:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 5ac682ff-8024-4278-959d-90ce328e8078 0xc0039c54a7 0xc0039c54a8}] [] [{kube-controller-manager Update v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ac682ff-8024-4278-959d-90ce328e8078\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nf87n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nf87n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:12:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 22 04:12:16.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8900" for this suite. 08/22/23 04:12:16.77
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":67,"skipped":1068,"failed":0}
------------------------------
â€¢ [4.418 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:12:12.383
    Aug 22 04:12:12.383: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename deployment 08/22/23 04:12:12.384
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:12:12.399
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:12:12.401
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Aug 22 04:12:12.405: INFO: Creating simple deployment test-new-deployment
    Aug 22 04:12:12.446: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"test-new-deployment-845c8977d9\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
    Aug 22 04:12:14.452: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 12, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: getting scale subresource 08/22/23 04:12:16.453
    STEP: updating a scale subresource 08/22/23 04:12:16.456
    STEP: verifying the deployment Spec.Replicas was modified 08/22/23 04:12:16.557
    STEP: Patch a scale subresource 08/22/23 04:12:16.6
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 22 04:12:16.745: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-8900  6c3ba4d8-4c77-41a3-a567-001869554957 1254256 3 2023-08-22 04:12:12 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-08-22 04:12:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003329408 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-08-22 04:12:16 +0000 UTC,LastTransitionTime:2023-08-22 04:12:12 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-08-22 04:12:16 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Aug 22 04:12:16.755: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-8900  5ac682ff-8024-4278-959d-90ce328e8078 1254258 3 2023-08-22 04:12:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 6c3ba4d8-4c77-41a3-a567-001869554957 0xc003329857 0xc003329858}] [] [{kube-controller-manager Update apps/v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6c3ba4d8-4c77-41a3-a567-001869554957\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0033298e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Aug 22 04:12:16.762: INFO: Pod "test-new-deployment-845c8977d9-cc4lr" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-cc4lr test-new-deployment-845c8977d9- deployment-8900  96caa714-5dce-498e-af07-76ca6a512f83 1254267 0 2023-08-22 04:12:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 5ac682ff-8024-4278-959d-90ce328e8078 0xc0039c4fc7 0xc0039c4fc8}] [] [{kube-controller-manager Update v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ac682ff-8024-4278-959d-90ce328e8078\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mqrl7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mqrl7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:12:16.763: INFO: Pod "test-new-deployment-845c8977d9-n69m8" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-n69m8 test-new-deployment-845c8977d9- deployment-8900  058d35ad-0236-4a70-957d-f603024ecdbe 1254266 0 2023-08-22 04:12:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 5ac682ff-8024-4278-959d-90ce328e8078 0xc0039c5157 0xc0039c5158}] [] [{kube-controller-manager Update v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ac682ff-8024-4278-959d-90ce328e8078\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vvpxz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vvpxz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:12:16.763: INFO: Pod "test-new-deployment-845c8977d9-rmbnz" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-rmbnz test-new-deployment-845c8977d9- deployment-8900  6de4fc94-d5ce-4575-bbfb-3b90e52d4ef1 1254241 0 2023-08-22 04:12:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 5ac682ff-8024-4278-959d-90ce328e8078 0xc0039c52b7 0xc0039c52b8}] [] [{kube-controller-manager Update v1 2023-08-22 04:12:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ac682ff-8024-4278-959d-90ce328e8078\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.54\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wtmx4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wtmx4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:10.100.4.54,StartTime:2023-08-22 04:12:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:12:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f28b94121c9f95ceaf0e96d7ee2bf003719d6c202acdd5623594f29c390dea1e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.4.54,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:12:16.763: INFO: Pod "test-new-deployment-845c8977d9-xrm4g" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-xrm4g test-new-deployment-845c8977d9- deployment-8900  40c09982-a16d-4ad0-aa47-9de005dbd33f 1254261 0 2023-08-22 04:12:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 5ac682ff-8024-4278-959d-90ce328e8078 0xc0039c54a7 0xc0039c54a8}] [] [{kube-controller-manager Update v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ac682ff-8024-4278-959d-90ce328e8078\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:12:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nf87n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nf87n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:12:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:12:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 22 04:12:16.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8900" for this suite. 08/22/23 04:12:16.77
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:12:16.803
Aug 22 04:12:16.803: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pods 08/22/23 04:12:16.804
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:12:16.824
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:12:16.826
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 08/22/23 04:12:16.836
STEP: watching for Pod to be ready 08/22/23 04:12:16.924
Aug 22 04:12:16.927: INFO: observed Pod pod-test in namespace pods-8877 in phase Pending with labels: map[test-pod-static:true] & conditions []
Aug 22 04:12:16.929: INFO: observed Pod pod-test in namespace pods-8877 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:16 +0000 UTC  }]
Aug 22 04:12:16.944: INFO: observed Pod pod-test in namespace pods-8877 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:16 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:16 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:16 +0000 UTC  }]
Aug 22 04:12:20.245: INFO: Found Pod pod-test in namespace pods-8877 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:16 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 08/22/23 04:12:20.346
STEP: getting the Pod and ensuring that it's patched 08/22/23 04:12:20.357
STEP: replacing the Pod's status Ready condition to False 08/22/23 04:12:20.36
STEP: check the Pod again to ensure its Ready conditions are False 08/22/23 04:12:20.377
STEP: deleting the Pod via a Collection with a LabelSelector 08/22/23 04:12:20.377
STEP: watching for the Pod to be deleted 08/22/23 04:12:20.389
Aug 22 04:12:20.391: INFO: observed event type MODIFIED
Aug 22 04:12:22.124: INFO: observed event type MODIFIED
Aug 22 04:12:23.228: INFO: observed event type MODIFIED
Aug 22 04:12:23.259: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 22 04:12:23.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8877" for this suite. 08/22/23 04:12:23.272
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":68,"skipped":1088,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.474 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:12:16.803
    Aug 22 04:12:16.803: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pods 08/22/23 04:12:16.804
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:12:16.824
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:12:16.826
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 08/22/23 04:12:16.836
    STEP: watching for Pod to be ready 08/22/23 04:12:16.924
    Aug 22 04:12:16.927: INFO: observed Pod pod-test in namespace pods-8877 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Aug 22 04:12:16.929: INFO: observed Pod pod-test in namespace pods-8877 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:16 +0000 UTC  }]
    Aug 22 04:12:16.944: INFO: observed Pod pod-test in namespace pods-8877 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:16 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:16 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:16 +0000 UTC  }]
    Aug 22 04:12:20.245: INFO: Found Pod pod-test in namespace pods-8877 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 04:12:16 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 08/22/23 04:12:20.346
    STEP: getting the Pod and ensuring that it's patched 08/22/23 04:12:20.357
    STEP: replacing the Pod's status Ready condition to False 08/22/23 04:12:20.36
    STEP: check the Pod again to ensure its Ready conditions are False 08/22/23 04:12:20.377
    STEP: deleting the Pod via a Collection with a LabelSelector 08/22/23 04:12:20.377
    STEP: watching for the Pod to be deleted 08/22/23 04:12:20.389
    Aug 22 04:12:20.391: INFO: observed event type MODIFIED
    Aug 22 04:12:22.124: INFO: observed event type MODIFIED
    Aug 22 04:12:23.228: INFO: observed event type MODIFIED
    Aug 22 04:12:23.259: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 22 04:12:23.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8877" for this suite. 08/22/23 04:12:23.272
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:12:23.279
Aug 22 04:12:23.279: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubelet-test 08/22/23 04:12:23.28
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:12:23.297
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:12:23.3
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Aug 22 04:12:23.312: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b" in namespace "kubelet-test-602" to be "running and ready"
Aug 22 04:12:23.317: INFO: Pod "busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.984992ms
Aug 22 04:12:23.317: INFO: The phase of Pod busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:12:25.508: INFO: Pod "busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.196524296s
Aug 22 04:12:25.508: INFO: The phase of Pod busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:12:27.321: INFO: Pod "busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b": Phase="Running", Reason="", readiness=true. Elapsed: 4.009755943s
Aug 22 04:12:27.321: INFO: The phase of Pod busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b is Running (Ready = true)
Aug 22 04:12:27.321: INFO: Pod "busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 22 04:12:27.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-602" for this suite. 08/22/23 04:12:27.336
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":69,"skipped":1109,"failed":0}
------------------------------
â€¢ [4.064 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:12:23.279
    Aug 22 04:12:23.279: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubelet-test 08/22/23 04:12:23.28
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:12:23.297
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:12:23.3
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Aug 22 04:12:23.312: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b" in namespace "kubelet-test-602" to be "running and ready"
    Aug 22 04:12:23.317: INFO: Pod "busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.984992ms
    Aug 22 04:12:23.317: INFO: The phase of Pod busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:12:25.508: INFO: Pod "busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.196524296s
    Aug 22 04:12:25.508: INFO: The phase of Pod busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:12:27.321: INFO: Pod "busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b": Phase="Running", Reason="", readiness=true. Elapsed: 4.009755943s
    Aug 22 04:12:27.321: INFO: The phase of Pod busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b is Running (Ready = true)
    Aug 22 04:12:27.321: INFO: Pod "busybox-readonly-fs3fb92bc6-9a82-475d-ae15-262cade2997b" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 22 04:12:27.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-602" for this suite. 08/22/23 04:12:27.336
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:12:27.343
Aug 22 04:12:27.343: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename custom-resource-definition 08/22/23 04:12:27.343
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:12:27.362
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:12:27.366
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Aug 22 04:12:27.369: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:12:35.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8890" for this suite. 08/22/23 04:12:35.009
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":70,"skipped":1111,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.673 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:12:27.343
    Aug 22 04:12:27.343: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename custom-resource-definition 08/22/23 04:12:27.343
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:12:27.362
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:12:27.366
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Aug 22 04:12:27.369: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:12:35.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-8890" for this suite. 08/22/23 04:12:35.009
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:12:35.017
Aug 22 04:12:35.017: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-probe 08/22/23 04:12:35.017
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:12:35.162
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:12:35.164
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-c71a35e1-f858-40d6-b722-7c9169b07132 in namespace container-probe-3211 08/22/23 04:12:35.169
Aug 22 04:12:35.355: INFO: Waiting up to 5m0s for pod "liveness-c71a35e1-f858-40d6-b722-7c9169b07132" in namespace "container-probe-3211" to be "not pending"
Aug 22 04:12:35.361: INFO: Pod "liveness-c71a35e1-f858-40d6-b722-7c9169b07132": Phase="Pending", Reason="", readiness=false. Elapsed: 6.068614ms
Aug 22 04:12:37.366: INFO: Pod "liveness-c71a35e1-f858-40d6-b722-7c9169b07132": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010773411s
Aug 22 04:12:39.366: INFO: Pod "liveness-c71a35e1-f858-40d6-b722-7c9169b07132": Phase="Running", Reason="", readiness=true. Elapsed: 4.010604724s
Aug 22 04:12:39.366: INFO: Pod "liveness-c71a35e1-f858-40d6-b722-7c9169b07132" satisfied condition "not pending"
Aug 22 04:12:39.366: INFO: Started pod liveness-c71a35e1-f858-40d6-b722-7c9169b07132 in namespace container-probe-3211
STEP: checking the pod's current state and verifying that restartCount is present 08/22/23 04:12:39.366
Aug 22 04:12:39.368: INFO: Initial restart count of pod liveness-c71a35e1-f858-40d6-b722-7c9169b07132 is 0
Aug 22 04:12:57.442: INFO: Restart count of pod container-probe-3211/liveness-c71a35e1-f858-40d6-b722-7c9169b07132 is now 1 (18.073287944s elapsed)
STEP: deleting the pod 08/22/23 04:12:57.442
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 22 04:12:57.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3211" for this suite. 08/22/23 04:12:57.463
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":71,"skipped":1113,"failed":0}
------------------------------
â€¢ [SLOW TEST] [22.453 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:12:35.017
    Aug 22 04:12:35.017: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-probe 08/22/23 04:12:35.017
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:12:35.162
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:12:35.164
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-c71a35e1-f858-40d6-b722-7c9169b07132 in namespace container-probe-3211 08/22/23 04:12:35.169
    Aug 22 04:12:35.355: INFO: Waiting up to 5m0s for pod "liveness-c71a35e1-f858-40d6-b722-7c9169b07132" in namespace "container-probe-3211" to be "not pending"
    Aug 22 04:12:35.361: INFO: Pod "liveness-c71a35e1-f858-40d6-b722-7c9169b07132": Phase="Pending", Reason="", readiness=false. Elapsed: 6.068614ms
    Aug 22 04:12:37.366: INFO: Pod "liveness-c71a35e1-f858-40d6-b722-7c9169b07132": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010773411s
    Aug 22 04:12:39.366: INFO: Pod "liveness-c71a35e1-f858-40d6-b722-7c9169b07132": Phase="Running", Reason="", readiness=true. Elapsed: 4.010604724s
    Aug 22 04:12:39.366: INFO: Pod "liveness-c71a35e1-f858-40d6-b722-7c9169b07132" satisfied condition "not pending"
    Aug 22 04:12:39.366: INFO: Started pod liveness-c71a35e1-f858-40d6-b722-7c9169b07132 in namespace container-probe-3211
    STEP: checking the pod's current state and verifying that restartCount is present 08/22/23 04:12:39.366
    Aug 22 04:12:39.368: INFO: Initial restart count of pod liveness-c71a35e1-f858-40d6-b722-7c9169b07132 is 0
    Aug 22 04:12:57.442: INFO: Restart count of pod container-probe-3211/liveness-c71a35e1-f858-40d6-b722-7c9169b07132 is now 1 (18.073287944s elapsed)
    STEP: deleting the pod 08/22/23 04:12:57.442
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 22 04:12:57.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3211" for this suite. 08/22/23 04:12:57.463
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:12:57.47
Aug 22 04:12:57.470: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 04:12:57.471
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:12:57.487
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:12:57.489
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 04:12:57.504
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 04:12:57.716
STEP: Deploying the webhook pod 08/22/23 04:12:57.727
STEP: Wait for the deployment to be ready 08/22/23 04:12:57.891
Aug 22 04:12:57.904: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 04:12:59.914: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 12, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 12, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 12, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 12, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 04:13:01.919
STEP: Verifying the service has paired with the endpoint 08/22/23 04:13:02.113
Aug 22 04:13:03.113: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 08/22/23 04:13:03.47
STEP: Creating a configMap that should be mutated 08/22/23 04:13:03.483
STEP: Deleting the collection of validation webhooks 08/22/23 04:13:03.51
STEP: Creating a configMap that should not be mutated 08/22/23 04:13:03.556
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:13:03.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-445" for this suite. 08/22/23 04:13:03.571
STEP: Destroying namespace "webhook-445-markers" for this suite. 08/22/23 04:13:03.943
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":72,"skipped":1118,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.758 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:12:57.47
    Aug 22 04:12:57.470: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 04:12:57.471
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:12:57.487
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:12:57.489
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 04:12:57.504
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 04:12:57.716
    STEP: Deploying the webhook pod 08/22/23 04:12:57.727
    STEP: Wait for the deployment to be ready 08/22/23 04:12:57.891
    Aug 22 04:12:57.904: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 04:12:59.914: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 12, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 12, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 12, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 12, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 04:13:01.919
    STEP: Verifying the service has paired with the endpoint 08/22/23 04:13:02.113
    Aug 22 04:13:03.113: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 08/22/23 04:13:03.47
    STEP: Creating a configMap that should be mutated 08/22/23 04:13:03.483
    STEP: Deleting the collection of validation webhooks 08/22/23 04:13:03.51
    STEP: Creating a configMap that should not be mutated 08/22/23 04:13:03.556
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:13:03.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-445" for this suite. 08/22/23 04:13:03.571
    STEP: Destroying namespace "webhook-445-markers" for this suite. 08/22/23 04:13:03.943
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:13:04.231
Aug 22 04:13:04.232: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 04:13:04.232
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:13:04.255
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:13:04.257
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-b44ee0d5-3271-4a0b-8521-e09f2610d3f6 08/22/23 04:13:04.264
STEP: Creating the pod 08/22/23 04:13:04.269
Aug 22 04:13:04.313: INFO: Waiting up to 5m0s for pod "pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0" in namespace "configmap-2309" to be "running and ready"
Aug 22 04:13:04.318: INFO: Pod "pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.571866ms
Aug 22 04:13:04.318: INFO: The phase of Pod pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:13:06.321: INFO: Pod "pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008494216s
Aug 22 04:13:06.321: INFO: The phase of Pod pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:13:08.322: INFO: Pod "pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0": Phase="Running", Reason="", readiness=true. Elapsed: 4.009258761s
Aug 22 04:13:08.322: INFO: The phase of Pod pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0 is Running (Ready = true)
Aug 22 04:13:08.322: INFO: Pod "pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-b44ee0d5-3271-4a0b-8521-e09f2610d3f6 08/22/23 04:13:08.332
STEP: waiting to observe update in volume 08/22/23 04:13:08.34
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 04:13:10.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2309" for this suite. 08/22/23 04:13:10.362
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":73,"skipped":1206,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.140 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:13:04.231
    Aug 22 04:13:04.232: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 04:13:04.232
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:13:04.255
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:13:04.257
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-b44ee0d5-3271-4a0b-8521-e09f2610d3f6 08/22/23 04:13:04.264
    STEP: Creating the pod 08/22/23 04:13:04.269
    Aug 22 04:13:04.313: INFO: Waiting up to 5m0s for pod "pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0" in namespace "configmap-2309" to be "running and ready"
    Aug 22 04:13:04.318: INFO: Pod "pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.571866ms
    Aug 22 04:13:04.318: INFO: The phase of Pod pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:13:06.321: INFO: Pod "pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008494216s
    Aug 22 04:13:06.321: INFO: The phase of Pod pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:13:08.322: INFO: Pod "pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0": Phase="Running", Reason="", readiness=true. Elapsed: 4.009258761s
    Aug 22 04:13:08.322: INFO: The phase of Pod pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0 is Running (Ready = true)
    Aug 22 04:13:08.322: INFO: Pod "pod-configmaps-fd3f76b7-580e-4cc7-963d-0cd1ff67abc0" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-b44ee0d5-3271-4a0b-8521-e09f2610d3f6 08/22/23 04:13:08.332
    STEP: waiting to observe update in volume 08/22/23 04:13:08.34
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 04:13:10.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2309" for this suite. 08/22/23 04:13:10.362
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:13:10.376
Aug 22 04:13:10.376: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 04:13:10.377
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:13:10.394
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:13:10.397
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/22/23 04:13:10.403
Aug 22 04:13:10.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-552 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Aug 22 04:13:10.553: INFO: stderr: ""
Aug 22 04:13:10.553: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 08/22/23 04:13:10.553
Aug 22 04:13:10.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-552 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Aug 22 04:13:11.253: INFO: stderr: ""
Aug 22 04:13:11.253: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/22/23 04:13:11.253
Aug 22 04:13:11.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-552 delete pods e2e-test-httpd-pod'
Aug 22 04:13:14.353: INFO: stderr: ""
Aug 22 04:13:14.353: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 04:13:14.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-552" for this suite. 08/22/23 04:13:14.359
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":74,"skipped":1295,"failed":0}
------------------------------
â€¢ [4.002 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:13:10.376
    Aug 22 04:13:10.376: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 04:13:10.377
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:13:10.394
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:13:10.397
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/22/23 04:13:10.403
    Aug 22 04:13:10.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-552 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Aug 22 04:13:10.553: INFO: stderr: ""
    Aug 22 04:13:10.553: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 08/22/23 04:13:10.553
    Aug 22 04:13:10.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-552 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Aug 22 04:13:11.253: INFO: stderr: ""
    Aug 22 04:13:11.253: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/22/23 04:13:11.253
    Aug 22 04:13:11.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-552 delete pods e2e-test-httpd-pod'
    Aug 22 04:13:14.353: INFO: stderr: ""
    Aug 22 04:13:14.353: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 04:13:14.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-552" for this suite. 08/22/23 04:13:14.359
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:13:14.379
Aug 22 04:13:14.379: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 04:13:14.379
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:13:14.615
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:13:14.618
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 08/22/23 04:13:14.623
Aug 22 04:13:14.623: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Aug 22 04:13:14.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 create -f -'
Aug 22 04:13:14.950: INFO: stderr: ""
Aug 22 04:13:14.951: INFO: stdout: "service/agnhost-replica created\n"
Aug 22 04:13:14.951: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Aug 22 04:13:14.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 create -f -'
Aug 22 04:13:15.385: INFO: stderr: ""
Aug 22 04:13:15.385: INFO: stdout: "service/agnhost-primary created\n"
Aug 22 04:13:15.385: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 22 04:13:15.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 create -f -'
Aug 22 04:13:15.570: INFO: stderr: ""
Aug 22 04:13:15.570: INFO: stdout: "service/frontend created\n"
Aug 22 04:13:15.570: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Aug 22 04:13:15.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 create -f -'
Aug 22 04:13:16.271: INFO: stderr: ""
Aug 22 04:13:16.271: INFO: stdout: "deployment.apps/frontend created\n"
Aug 22 04:13:16.271: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 22 04:13:16.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 create -f -'
Aug 22 04:13:16.411: INFO: stderr: ""
Aug 22 04:13:16.411: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Aug 22 04:13:16.411: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 22 04:13:16.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 create -f -'
Aug 22 04:13:17.134: INFO: stderr: ""
Aug 22 04:13:17.134: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 08/22/23 04:13:17.134
Aug 22 04:13:17.135: INFO: Waiting for all frontend pods to be Running.
Aug 22 04:13:22.186: INFO: Waiting for frontend to serve content.
Aug 22 04:13:22.198: INFO: Trying to add a new entry to the guestbook.
Aug 22 04:13:22.209: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 08/22/23 04:13:22.224
Aug 22 04:13:22.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 delete --grace-period=0 --force -f -'
Aug 22 04:13:22.439: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 04:13:22.439: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 08/22/23 04:13:22.439
Aug 22 04:13:22.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 delete --grace-period=0 --force -f -'
Aug 22 04:13:22.549: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 04:13:22.549: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 08/22/23 04:13:22.549
Aug 22 04:13:22.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 delete --grace-period=0 --force -f -'
Aug 22 04:13:22.889: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 04:13:22.889: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 08/22/23 04:13:22.889
Aug 22 04:13:22.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 delete --grace-period=0 --force -f -'
Aug 22 04:13:22.946: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 04:13:22.946: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 08/22/23 04:13:22.947
Aug 22 04:13:22.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 delete --grace-period=0 --force -f -'
Aug 22 04:13:23.009: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 04:13:23.009: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 08/22/23 04:13:23.009
Aug 22 04:13:23.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 delete --grace-period=0 --force -f -'
Aug 22 04:13:23.072: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 04:13:23.072: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 04:13:23.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2452" for this suite. 08/22/23 04:13:23.078
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":75,"skipped":1306,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.709 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:13:14.379
    Aug 22 04:13:14.379: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 04:13:14.379
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:13:14.615
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:13:14.618
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 08/22/23 04:13:14.623
    Aug 22 04:13:14.623: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Aug 22 04:13:14.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 create -f -'
    Aug 22 04:13:14.950: INFO: stderr: ""
    Aug 22 04:13:14.951: INFO: stdout: "service/agnhost-replica created\n"
    Aug 22 04:13:14.951: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Aug 22 04:13:14.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 create -f -'
    Aug 22 04:13:15.385: INFO: stderr: ""
    Aug 22 04:13:15.385: INFO: stdout: "service/agnhost-primary created\n"
    Aug 22 04:13:15.385: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Aug 22 04:13:15.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 create -f -'
    Aug 22 04:13:15.570: INFO: stderr: ""
    Aug 22 04:13:15.570: INFO: stdout: "service/frontend created\n"
    Aug 22 04:13:15.570: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Aug 22 04:13:15.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 create -f -'
    Aug 22 04:13:16.271: INFO: stderr: ""
    Aug 22 04:13:16.271: INFO: stdout: "deployment.apps/frontend created\n"
    Aug 22 04:13:16.271: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Aug 22 04:13:16.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 create -f -'
    Aug 22 04:13:16.411: INFO: stderr: ""
    Aug 22 04:13:16.411: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Aug 22 04:13:16.411: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Aug 22 04:13:16.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 create -f -'
    Aug 22 04:13:17.134: INFO: stderr: ""
    Aug 22 04:13:17.134: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 08/22/23 04:13:17.134
    Aug 22 04:13:17.135: INFO: Waiting for all frontend pods to be Running.
    Aug 22 04:13:22.186: INFO: Waiting for frontend to serve content.
    Aug 22 04:13:22.198: INFO: Trying to add a new entry to the guestbook.
    Aug 22 04:13:22.209: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 08/22/23 04:13:22.224
    Aug 22 04:13:22.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 delete --grace-period=0 --force -f -'
    Aug 22 04:13:22.439: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 22 04:13:22.439: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 08/22/23 04:13:22.439
    Aug 22 04:13:22.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 delete --grace-period=0 --force -f -'
    Aug 22 04:13:22.549: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 22 04:13:22.549: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 08/22/23 04:13:22.549
    Aug 22 04:13:22.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 delete --grace-period=0 --force -f -'
    Aug 22 04:13:22.889: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 22 04:13:22.889: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 08/22/23 04:13:22.889
    Aug 22 04:13:22.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 delete --grace-period=0 --force -f -'
    Aug 22 04:13:22.946: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 22 04:13:22.946: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 08/22/23 04:13:22.947
    Aug 22 04:13:22.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 delete --grace-period=0 --force -f -'
    Aug 22 04:13:23.009: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 22 04:13:23.009: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 08/22/23 04:13:23.009
    Aug 22 04:13:23.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2452 delete --grace-period=0 --force -f -'
    Aug 22 04:13:23.072: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 22 04:13:23.072: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 04:13:23.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2452" for this suite. 08/22/23 04:13:23.078
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:13:23.09
Aug 22 04:13:23.090: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 04:13:23.092
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:13:23.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:13:23.122
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 08/22/23 04:13:23.126
Aug 22 04:13:23.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-8551 create -f -'
Aug 22 04:13:23.374: INFO: stderr: ""
Aug 22 04:13:23.374: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 08/22/23 04:13:23.374
Aug 22 04:13:23.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-8551 diff -f -'
Aug 22 04:13:27.732: INFO: rc: 1
Aug 22 04:13:27.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-8551 delete -f -'
Aug 22 04:13:27.800: INFO: stderr: ""
Aug 22 04:13:27.800: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 04:13:27.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8551" for this suite. 08/22/23 04:13:27.819
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":76,"skipped":1372,"failed":0}
------------------------------
â€¢ [4.738 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:13:23.09
    Aug 22 04:13:23.090: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 04:13:23.092
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:13:23.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:13:23.122
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 08/22/23 04:13:23.126
    Aug 22 04:13:23.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-8551 create -f -'
    Aug 22 04:13:23.374: INFO: stderr: ""
    Aug 22 04:13:23.374: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 08/22/23 04:13:23.374
    Aug 22 04:13:23.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-8551 diff -f -'
    Aug 22 04:13:27.732: INFO: rc: 1
    Aug 22 04:13:27.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-8551 delete -f -'
    Aug 22 04:13:27.800: INFO: stderr: ""
    Aug 22 04:13:27.800: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 04:13:27.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8551" for this suite. 08/22/23 04:13:27.819
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:13:27.83
Aug 22 04:13:27.830: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-probe 08/22/23 04:13:27.831
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:13:27.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:13:27.979
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76 in namespace container-probe-7207 08/22/23 04:13:27.983
Aug 22 04:13:27.996: INFO: Waiting up to 5m0s for pod "test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76" in namespace "container-probe-7207" to be "not pending"
Aug 22 04:13:28.000: INFO: Pod "test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76": Phase="Pending", Reason="", readiness=false. Elapsed: 4.164783ms
Aug 22 04:13:30.004: INFO: Pod "test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008434714s
Aug 22 04:13:32.005: INFO: Pod "test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76": Phase="Running", Reason="", readiness=true. Elapsed: 4.009635798s
Aug 22 04:13:32.005: INFO: Pod "test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76" satisfied condition "not pending"
Aug 22 04:13:32.005: INFO: Started pod test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76 in namespace container-probe-7207
STEP: checking the pod's current state and verifying that restartCount is present 08/22/23 04:13:32.005
Aug 22 04:13:32.008: INFO: Initial restart count of pod test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76 is 0
STEP: deleting the pod 08/22/23 04:17:33.838
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 22 04:17:34.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7207" for this suite. 08/22/23 04:17:34.064
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":77,"skipped":1423,"failed":0}
------------------------------
â€¢ [SLOW TEST] [246.468 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:13:27.83
    Aug 22 04:13:27.830: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-probe 08/22/23 04:13:27.831
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:13:27.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:13:27.979
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76 in namespace container-probe-7207 08/22/23 04:13:27.983
    Aug 22 04:13:27.996: INFO: Waiting up to 5m0s for pod "test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76" in namespace "container-probe-7207" to be "not pending"
    Aug 22 04:13:28.000: INFO: Pod "test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76": Phase="Pending", Reason="", readiness=false. Elapsed: 4.164783ms
    Aug 22 04:13:30.004: INFO: Pod "test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008434714s
    Aug 22 04:13:32.005: INFO: Pod "test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76": Phase="Running", Reason="", readiness=true. Elapsed: 4.009635798s
    Aug 22 04:13:32.005: INFO: Pod "test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76" satisfied condition "not pending"
    Aug 22 04:13:32.005: INFO: Started pod test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76 in namespace container-probe-7207
    STEP: checking the pod's current state and verifying that restartCount is present 08/22/23 04:13:32.005
    Aug 22 04:13:32.008: INFO: Initial restart count of pod test-webserver-c14ed17a-0086-4deb-a4d6-e2952950cc76 is 0
    STEP: deleting the pod 08/22/23 04:17:33.838
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 22 04:17:34.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7207" for this suite. 08/22/23 04:17:34.064
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:17:34.299
Aug 22 04:17:34.299: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename taint-single-pod 08/22/23 04:17:34.3
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:17:34.478
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:17:34.482
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Aug 22 04:17:34.486: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 22 04:18:34.521: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Aug 22 04:18:34.526: INFO: Starting informer...
STEP: Starting pod... 08/22/23 04:18:34.526
Aug 22 04:18:34.743: INFO: Pod is running on jake-melb-gmyyva4zrlsz-node-2. Tainting Node
STEP: Trying to apply a taint on the Node 08/22/23 04:18:34.743
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/22/23 04:18:34.755
STEP: Waiting short time to make sure Pod is queued for deletion 08/22/23 04:18:34.761
Aug 22 04:18:34.761: INFO: Pod wasn't evicted. Proceeding
Aug 22 04:18:34.761: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/22/23 04:18:34.785
STEP: Waiting some time to make sure that toleration time passed. 08/22/23 04:18:34.792
Aug 22 04:19:49.792: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Aug 22 04:19:49.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-5720" for this suite. 08/22/23 04:19:49.798
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":78,"skipped":1431,"failed":0}
------------------------------
â€¢ [SLOW TEST] [135.507 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:17:34.299
    Aug 22 04:17:34.299: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename taint-single-pod 08/22/23 04:17:34.3
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:17:34.478
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:17:34.482
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Aug 22 04:17:34.486: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 22 04:18:34.521: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Aug 22 04:18:34.526: INFO: Starting informer...
    STEP: Starting pod... 08/22/23 04:18:34.526
    Aug 22 04:18:34.743: INFO: Pod is running on jake-melb-gmyyva4zrlsz-node-2. Tainting Node
    STEP: Trying to apply a taint on the Node 08/22/23 04:18:34.743
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/22/23 04:18:34.755
    STEP: Waiting short time to make sure Pod is queued for deletion 08/22/23 04:18:34.761
    Aug 22 04:18:34.761: INFO: Pod wasn't evicted. Proceeding
    Aug 22 04:18:34.761: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/22/23 04:18:34.785
    STEP: Waiting some time to make sure that toleration time passed. 08/22/23 04:18:34.792
    Aug 22 04:19:49.792: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 04:19:49.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-5720" for this suite. 08/22/23 04:19:49.798
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:19:49.806
Aug 22 04:19:49.807: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 04:19:49.807
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:19:50.09
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:19:50.093
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620
STEP: creating a collection of services 08/22/23 04:19:50.098
Aug 22 04:19:50.098: INFO: Creating e2e-svc-a-cdm7v
Aug 22 04:19:50.486: INFO: Creating e2e-svc-b-nxrl9
Aug 22 04:19:50.502: INFO: Creating e2e-svc-c-thj28
STEP: deleting service collection 08/22/23 04:19:50.53
Aug 22 04:19:50.581: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 04:19:50.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3225" for this suite. 08/22/23 04:19:50.586
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":79,"skipped":1444,"failed":0}
------------------------------
â€¢ [0.788 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:19:49.806
    Aug 22 04:19:49.807: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 04:19:49.807
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:19:50.09
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:19:50.093
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3620
    STEP: creating a collection of services 08/22/23 04:19:50.098
    Aug 22 04:19:50.098: INFO: Creating e2e-svc-a-cdm7v
    Aug 22 04:19:50.486: INFO: Creating e2e-svc-b-nxrl9
    Aug 22 04:19:50.502: INFO: Creating e2e-svc-c-thj28
    STEP: deleting service collection 08/22/23 04:19:50.53
    Aug 22 04:19:50.581: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 04:19:50.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3225" for this suite. 08/22/23 04:19:50.586
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:19:50.596
Aug 22 04:19:50.596: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 04:19:50.597
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:19:50.617
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:19:50.621
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-ef897f36-f984-4cb7-b6ee-c32b54fab268 08/22/23 04:19:50.625
STEP: Creating a pod to test consume configMaps 08/22/23 04:19:50.632
Aug 22 04:19:50.642: INFO: Waiting up to 5m0s for pod "pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615" in namespace "configmap-696" to be "Succeeded or Failed"
Aug 22 04:19:50.649: INFO: Pod "pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615": Phase="Pending", Reason="", readiness=false. Elapsed: 7.292349ms
Aug 22 04:19:52.654: INFO: Pod "pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012144275s
Aug 22 04:19:54.654: INFO: Pod "pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011836181s
Aug 22 04:19:56.653: INFO: Pod "pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011125324s
STEP: Saw pod success 08/22/23 04:19:56.653
Aug 22 04:19:56.653: INFO: Pod "pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615" satisfied condition "Succeeded or Failed"
Aug 22 04:19:56.656: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615 container agnhost-container: <nil>
STEP: delete the pod 08/22/23 04:19:56.685
Aug 22 04:19:57.008: INFO: Waiting for pod pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615 to disappear
Aug 22 04:19:57.012: INFO: Pod pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 04:19:57.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-696" for this suite. 08/22/23 04:19:57.017
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":80,"skipped":1460,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.428 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:19:50.596
    Aug 22 04:19:50.596: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 04:19:50.597
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:19:50.617
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:19:50.621
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-ef897f36-f984-4cb7-b6ee-c32b54fab268 08/22/23 04:19:50.625
    STEP: Creating a pod to test consume configMaps 08/22/23 04:19:50.632
    Aug 22 04:19:50.642: INFO: Waiting up to 5m0s for pod "pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615" in namespace "configmap-696" to be "Succeeded or Failed"
    Aug 22 04:19:50.649: INFO: Pod "pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615": Phase="Pending", Reason="", readiness=false. Elapsed: 7.292349ms
    Aug 22 04:19:52.654: INFO: Pod "pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012144275s
    Aug 22 04:19:54.654: INFO: Pod "pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011836181s
    Aug 22 04:19:56.653: INFO: Pod "pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011125324s
    STEP: Saw pod success 08/22/23 04:19:56.653
    Aug 22 04:19:56.653: INFO: Pod "pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615" satisfied condition "Succeeded or Failed"
    Aug 22 04:19:56.656: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615 container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 04:19:56.685
    Aug 22 04:19:57.008: INFO: Waiting for pod pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615 to disappear
    Aug 22 04:19:57.012: INFO: Pod pod-configmaps-9f53b4b0-3e6d-4759-b1de-e6b6f9f71615 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 04:19:57.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-696" for this suite. 08/22/23 04:19:57.017
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:19:57.025
Aug 22 04:19:57.025: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 04:19:57.025
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:19:57.277
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:19:57.279
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 04:19:57.573
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 04:19:57.713
STEP: Deploying the webhook pod 08/22/23 04:19:57.745
STEP: Wait for the deployment to be ready 08/22/23 04:19:57.764
Aug 22 04:19:57.788: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 04:19:59.826: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 19, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 19, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 19, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 19, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 04:20:01.831
STEP: Verifying the service has paired with the endpoint 08/22/23 04:20:02.023
Aug 22 04:20:03.023: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 08/22/23 04:20:03.028
STEP: Updating a mutating webhook configuration's rules to not include the create operation 08/22/23 04:20:03.341
STEP: Creating a configMap that should not be mutated 08/22/23 04:20:03.349
STEP: Patching a mutating webhook configuration's rules to include the create operation 08/22/23 04:20:03.372
STEP: Creating a configMap that should be mutated 08/22/23 04:20:03.384
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:20:03.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3374" for this suite. 08/22/23 04:20:03.408
STEP: Destroying namespace "webhook-3374-markers" for this suite. 08/22/23 04:20:03.414
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":81,"skipped":1467,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.455 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:19:57.025
    Aug 22 04:19:57.025: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 04:19:57.025
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:19:57.277
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:19:57.279
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 04:19:57.573
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 04:19:57.713
    STEP: Deploying the webhook pod 08/22/23 04:19:57.745
    STEP: Wait for the deployment to be ready 08/22/23 04:19:57.764
    Aug 22 04:19:57.788: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 04:19:59.826: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 19, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 19, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 19, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 19, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 04:20:01.831
    STEP: Verifying the service has paired with the endpoint 08/22/23 04:20:02.023
    Aug 22 04:20:03.023: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 08/22/23 04:20:03.028
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 08/22/23 04:20:03.341
    STEP: Creating a configMap that should not be mutated 08/22/23 04:20:03.349
    STEP: Patching a mutating webhook configuration's rules to include the create operation 08/22/23 04:20:03.372
    STEP: Creating a configMap that should be mutated 08/22/23 04:20:03.384
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:20:03.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3374" for this suite. 08/22/23 04:20:03.408
    STEP: Destroying namespace "webhook-3374-markers" for this suite. 08/22/23 04:20:03.414
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:20:03.481
Aug 22 04:20:03.481: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename endpointslice 08/22/23 04:20:03.482
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:20:03.565
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:20:03.569
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Aug 22 04:20:05.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7275" for this suite. 08/22/23 04:20:05.677
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":82,"skipped":1517,"failed":0}
------------------------------
â€¢ [2.204 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:20:03.481
    Aug 22 04:20:03.481: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename endpointslice 08/22/23 04:20:03.482
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:20:03.565
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:20:03.569
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Aug 22 04:20:05.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-7275" for this suite. 08/22/23 04:20:05.677
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:20:05.686
Aug 22 04:20:05.686: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename var-expansion 08/22/23 04:20:05.687
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:20:05.704
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:20:05.707
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Aug 22 04:20:05.729: INFO: Waiting up to 2m0s for pod "var-expansion-b0677c4b-af84-4e5b-a1fe-b5482e2558eb" in namespace "var-expansion-4105" to be "container 0 failed with reason CreateContainerConfigError"
Aug 22 04:20:05.739: INFO: Pod "var-expansion-b0677c4b-af84-4e5b-a1fe-b5482e2558eb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.277423ms
Aug 22 04:20:07.742: INFO: Pod "var-expansion-b0677c4b-af84-4e5b-a1fe-b5482e2558eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012982217s
Aug 22 04:20:09.742: INFO: Pod "var-expansion-b0677c4b-af84-4e5b-a1fe-b5482e2558eb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01258575s
Aug 22 04:20:09.742: INFO: Pod "var-expansion-b0677c4b-af84-4e5b-a1fe-b5482e2558eb" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Aug 22 04:20:09.742: INFO: Deleting pod "var-expansion-b0677c4b-af84-4e5b-a1fe-b5482e2558eb" in namespace "var-expansion-4105"
Aug 22 04:20:09.971: INFO: Wait up to 5m0s for pod "var-expansion-b0677c4b-af84-4e5b-a1fe-b5482e2558eb" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 22 04:20:11.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4105" for this suite. 08/22/23 04:20:11.983
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":83,"skipped":1545,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.304 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:20:05.686
    Aug 22 04:20:05.686: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename var-expansion 08/22/23 04:20:05.687
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:20:05.704
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:20:05.707
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Aug 22 04:20:05.729: INFO: Waiting up to 2m0s for pod "var-expansion-b0677c4b-af84-4e5b-a1fe-b5482e2558eb" in namespace "var-expansion-4105" to be "container 0 failed with reason CreateContainerConfigError"
    Aug 22 04:20:05.739: INFO: Pod "var-expansion-b0677c4b-af84-4e5b-a1fe-b5482e2558eb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.277423ms
    Aug 22 04:20:07.742: INFO: Pod "var-expansion-b0677c4b-af84-4e5b-a1fe-b5482e2558eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012982217s
    Aug 22 04:20:09.742: INFO: Pod "var-expansion-b0677c4b-af84-4e5b-a1fe-b5482e2558eb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01258575s
    Aug 22 04:20:09.742: INFO: Pod "var-expansion-b0677c4b-af84-4e5b-a1fe-b5482e2558eb" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Aug 22 04:20:09.742: INFO: Deleting pod "var-expansion-b0677c4b-af84-4e5b-a1fe-b5482e2558eb" in namespace "var-expansion-4105"
    Aug 22 04:20:09.971: INFO: Wait up to 5m0s for pod "var-expansion-b0677c4b-af84-4e5b-a1fe-b5482e2558eb" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 22 04:20:11.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4105" for this suite. 08/22/23 04:20:11.983
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:20:11.991
Aug 22 04:20:11.991: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename statefulset 08/22/23 04:20:11.991
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:20:12.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:20:12.122
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6894 08/22/23 04:20:12.125
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-6894 08/22/23 04:20:12.132
Aug 22 04:20:12.144: INFO: Found 0 stateful pods, waiting for 1
Aug 22 04:20:22.283: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 08/22/23 04:20:22.303
STEP: updating a scale subresource 08/22/23 04:20:22.307
STEP: verifying the statefulset Spec.Replicas was modified 08/22/23 04:20:22.318
STEP: Patch a scale subresource 08/22/23 04:20:22.324
STEP: verifying the statefulset Spec.Replicas was modified 08/22/23 04:20:22.356
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 22 04:20:22.362: INFO: Deleting all statefulset in ns statefulset-6894
Aug 22 04:20:22.374: INFO: Scaling statefulset ss to 0
Aug 22 04:20:32.395: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 04:20:32.398: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 22 04:20:32.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6894" for this suite. 08/22/23 04:20:32.649
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":84,"skipped":1560,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.688 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:20:11.991
    Aug 22 04:20:11.991: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename statefulset 08/22/23 04:20:11.991
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:20:12.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:20:12.122
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6894 08/22/23 04:20:12.125
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-6894 08/22/23 04:20:12.132
    Aug 22 04:20:12.144: INFO: Found 0 stateful pods, waiting for 1
    Aug 22 04:20:22.283: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 08/22/23 04:20:22.303
    STEP: updating a scale subresource 08/22/23 04:20:22.307
    STEP: verifying the statefulset Spec.Replicas was modified 08/22/23 04:20:22.318
    STEP: Patch a scale subresource 08/22/23 04:20:22.324
    STEP: verifying the statefulset Spec.Replicas was modified 08/22/23 04:20:22.356
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 22 04:20:22.362: INFO: Deleting all statefulset in ns statefulset-6894
    Aug 22 04:20:22.374: INFO: Scaling statefulset ss to 0
    Aug 22 04:20:32.395: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 22 04:20:32.398: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 22 04:20:32.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6894" for this suite. 08/22/23 04:20:32.649
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:20:32.679
Aug 22 04:20:32.679: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:20:32.679
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:20:32.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:20:32.989
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-bc547bc3-5525-42bc-9637-ca45563d3d3b 08/22/23 04:20:32.993
STEP: Creating a pod to test consume secrets 08/22/23 04:20:33.066
Aug 22 04:20:33.246: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913" in namespace "projected-5483" to be "Succeeded or Failed"
Aug 22 04:20:33.296: INFO: Pod "pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913": Phase="Pending", Reason="", readiness=false. Elapsed: 50.221502ms
Aug 22 04:20:35.305: INFO: Pod "pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058512269s
Aug 22 04:20:37.301: INFO: Pod "pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055153754s
Aug 22 04:20:39.303: INFO: Pod "pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05662561s
STEP: Saw pod success 08/22/23 04:20:39.303
Aug 22 04:20:39.303: INFO: Pod "pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913" satisfied condition "Succeeded or Failed"
Aug 22 04:20:39.306: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913 container projected-secret-volume-test: <nil>
STEP: delete the pod 08/22/23 04:20:39.338
Aug 22 04:20:39.574: INFO: Waiting for pod pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913 to disappear
Aug 22 04:20:39.579: INFO: Pod pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 22 04:20:39.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5483" for this suite. 08/22/23 04:20:39.582
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":85,"skipped":1585,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.910 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:20:32.679
    Aug 22 04:20:32.679: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:20:32.679
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:20:32.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:20:32.989
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-bc547bc3-5525-42bc-9637-ca45563d3d3b 08/22/23 04:20:32.993
    STEP: Creating a pod to test consume secrets 08/22/23 04:20:33.066
    Aug 22 04:20:33.246: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913" in namespace "projected-5483" to be "Succeeded or Failed"
    Aug 22 04:20:33.296: INFO: Pod "pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913": Phase="Pending", Reason="", readiness=false. Elapsed: 50.221502ms
    Aug 22 04:20:35.305: INFO: Pod "pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058512269s
    Aug 22 04:20:37.301: INFO: Pod "pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055153754s
    Aug 22 04:20:39.303: INFO: Pod "pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05662561s
    STEP: Saw pod success 08/22/23 04:20:39.303
    Aug 22 04:20:39.303: INFO: Pod "pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913" satisfied condition "Succeeded or Failed"
    Aug 22 04:20:39.306: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913 container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/22/23 04:20:39.338
    Aug 22 04:20:39.574: INFO: Waiting for pod pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913 to disappear
    Aug 22 04:20:39.579: INFO: Pod pod-projected-secrets-e0f61382-4017-41e5-a406-013f6c10e913 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 22 04:20:39.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5483" for this suite. 08/22/23 04:20:39.582
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:20:39.59
Aug 22 04:20:39.590: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 04:20:39.59
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:20:39.611
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:20:39.614
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 08/22/23 04:20:39.618
Aug 22 04:20:39.618: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: mark a version not serverd 08/22/23 04:20:45.887
STEP: check the unserved version gets removed 08/22/23 04:20:46.07
STEP: check the other version is not changed 08/22/23 04:20:48.892
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:20:53.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4823" for this suite. 08/22/23 04:20:53.706
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":86,"skipped":1633,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.127 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:20:39.59
    Aug 22 04:20:39.590: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 04:20:39.59
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:20:39.611
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:20:39.614
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 08/22/23 04:20:39.618
    Aug 22 04:20:39.618: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: mark a version not serverd 08/22/23 04:20:45.887
    STEP: check the unserved version gets removed 08/22/23 04:20:46.07
    STEP: check the other version is not changed 08/22/23 04:20:48.892
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:20:53.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4823" for this suite. 08/22/23 04:20:53.706
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:20:53.717
Aug 22 04:20:53.717: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename svcaccounts 08/22/23 04:20:53.717
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:20:53.875
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:20:53.878
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Aug 22 04:20:53.895: INFO: Waiting up to 5m0s for pod "pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe" in namespace "svcaccounts-6294" to be "running"
Aug 22 04:20:53.899: INFO: Pod "pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.797142ms
Aug 22 04:20:55.904: INFO: Pod "pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009233113s
Aug 22 04:20:57.903: INFO: Pod "pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe": Phase="Running", Reason="", readiness=true. Elapsed: 4.007787185s
Aug 22 04:20:57.903: INFO: Pod "pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe" satisfied condition "running"
STEP: reading a file in the container 08/22/23 04:20:57.903
Aug 22 04:20:57.903: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6294 pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 08/22/23 04:20:58.04
Aug 22 04:20:58.040: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6294 pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 08/22/23 04:20:58.176
Aug 22 04:20:58.176: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6294 pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Aug 22 04:20:58.313: INFO: Got root ca configmap in namespace "svcaccounts-6294"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 22 04:20:58.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6294" for this suite. 08/22/23 04:20:58.318
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":87,"skipped":1638,"failed":0}
------------------------------
â€¢ [4.609 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:20:53.717
    Aug 22 04:20:53.717: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename svcaccounts 08/22/23 04:20:53.717
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:20:53.875
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:20:53.878
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Aug 22 04:20:53.895: INFO: Waiting up to 5m0s for pod "pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe" in namespace "svcaccounts-6294" to be "running"
    Aug 22 04:20:53.899: INFO: Pod "pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.797142ms
    Aug 22 04:20:55.904: INFO: Pod "pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009233113s
    Aug 22 04:20:57.903: INFO: Pod "pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe": Phase="Running", Reason="", readiness=true. Elapsed: 4.007787185s
    Aug 22 04:20:57.903: INFO: Pod "pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe" satisfied condition "running"
    STEP: reading a file in the container 08/22/23 04:20:57.903
    Aug 22 04:20:57.903: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6294 pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 08/22/23 04:20:58.04
    Aug 22 04:20:58.040: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6294 pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 08/22/23 04:20:58.176
    Aug 22 04:20:58.176: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6294 pod-service-account-b9b3e3cd-726d-4813-a4af-588f13d49ffe -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Aug 22 04:20:58.313: INFO: Got root ca configmap in namespace "svcaccounts-6294"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 22 04:20:58.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-6294" for this suite. 08/22/23 04:20:58.318
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:20:58.326
Aug 22 04:20:58.326: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename dns 08/22/23 04:20:58.327
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:20:58.343
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:20:58.346
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 08/22/23 04:20:58.349
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9594.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9594.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 08/22/23 04:20:58.384
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9594.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9594.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 08/22/23 04:20:58.384
STEP: creating a pod to probe DNS 08/22/23 04:20:58.384
STEP: submitting the pod to kubernetes 08/22/23 04:20:58.384
Aug 22 04:20:58.394: INFO: Waiting up to 15m0s for pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9" in namespace "dns-9594" to be "running"
Aug 22 04:20:58.407: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.667391ms
Aug 22 04:21:00.411: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017214175s
Aug 22 04:21:02.411: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016844856s
Aug 22 04:21:04.411: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017024939s
Aug 22 04:21:06.410: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016077467s
Aug 22 04:21:08.411: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.017547701s
Aug 22 04:21:10.410: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016269277s
Aug 22 04:21:12.411: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.01734464s
Aug 22 04:21:14.411: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.017417611s
Aug 22 04:21:16.410: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.016213178s
Aug 22 04:21:18.410: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.016336133s
Aug 22 04:21:20.411: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 22.016800719s
Aug 22 04:21:22.412: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 24.018436692s
Aug 22 04:21:24.410: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Running", Reason="", readiness=true. Elapsed: 26.015943111s
Aug 22 04:21:24.410: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9" satisfied condition "running"
STEP: retrieving the pod 08/22/23 04:21:24.41
STEP: looking for the results for each expected name from probers 08/22/23 04:21:24.412
Aug 22 04:21:24.423: INFO: DNS probes using dns-9594/dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9 succeeded

STEP: deleting the pod 08/22/23 04:21:24.423
STEP: deleting the test headless service 08/22/23 04:21:24.522
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 22 04:21:24.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9594" for this suite. 08/22/23 04:21:24.604
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":88,"skipped":1650,"failed":0}
------------------------------
â€¢ [SLOW TEST] [26.284 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:20:58.326
    Aug 22 04:20:58.326: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename dns 08/22/23 04:20:58.327
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:20:58.343
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:20:58.346
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 08/22/23 04:20:58.349
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9594.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9594.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     08/22/23 04:20:58.384
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9594.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9594.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     08/22/23 04:20:58.384
    STEP: creating a pod to probe DNS 08/22/23 04:20:58.384
    STEP: submitting the pod to kubernetes 08/22/23 04:20:58.384
    Aug 22 04:20:58.394: INFO: Waiting up to 15m0s for pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9" in namespace "dns-9594" to be "running"
    Aug 22 04:20:58.407: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.667391ms
    Aug 22 04:21:00.411: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017214175s
    Aug 22 04:21:02.411: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016844856s
    Aug 22 04:21:04.411: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017024939s
    Aug 22 04:21:06.410: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016077467s
    Aug 22 04:21:08.411: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.017547701s
    Aug 22 04:21:10.410: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016269277s
    Aug 22 04:21:12.411: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.01734464s
    Aug 22 04:21:14.411: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.017417611s
    Aug 22 04:21:16.410: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.016213178s
    Aug 22 04:21:18.410: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.016336133s
    Aug 22 04:21:20.411: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 22.016800719s
    Aug 22 04:21:22.412: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Pending", Reason="", readiness=false. Elapsed: 24.018436692s
    Aug 22 04:21:24.410: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9": Phase="Running", Reason="", readiness=true. Elapsed: 26.015943111s
    Aug 22 04:21:24.410: INFO: Pod "dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9" satisfied condition "running"
    STEP: retrieving the pod 08/22/23 04:21:24.41
    STEP: looking for the results for each expected name from probers 08/22/23 04:21:24.412
    Aug 22 04:21:24.423: INFO: DNS probes using dns-9594/dns-test-6922136d-3f0a-43f3-8450-4e5820e1afb9 succeeded

    STEP: deleting the pod 08/22/23 04:21:24.423
    STEP: deleting the test headless service 08/22/23 04:21:24.522
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 22 04:21:24.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9594" for this suite. 08/22/23 04:21:24.604
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:21:24.61
Aug 22 04:21:24.611: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename deployment 08/22/23 04:21:24.611
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:21:24.624
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:21:24.627
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 08/22/23 04:21:24.634
STEP: waiting for Deployment to be created 08/22/23 04:21:24.641
STEP: waiting for all Replicas to be Ready 08/22/23 04:21:24.644
Aug 22 04:21:24.647: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 22 04:21:24.647: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 22 04:21:24.654: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 22 04:21:24.654: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 22 04:21:24.746: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 22 04:21:24.746: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 22 04:21:24.774: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 22 04:21:24.774: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 22 04:21:27.248: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Aug 22 04:21:27.248: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Aug 22 04:21:31.083: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 08/22/23 04:21:31.083
W0822 04:21:31.091474      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Aug 22 04:21:31.093: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 08/22/23 04:21:31.093
Aug 22 04:21:31.095: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
Aug 22 04:21:31.095: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
Aug 22 04:21:31.095: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
Aug 22 04:21:31.095: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
Aug 22 04:21:31.095: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
Aug 22 04:21:31.095: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
Aug 22 04:21:31.106: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
Aug 22 04:21:31.106: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
Aug 22 04:21:31.134: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
Aug 22 04:21:31.135: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
Aug 22 04:21:31.149: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
Aug 22 04:21:31.149: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
Aug 22 04:21:31.186: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
Aug 22 04:21:31.186: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
Aug 22 04:21:34.718: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
Aug 22 04:21:34.718: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
Aug 22 04:21:34.751: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
STEP: listing Deployments 08/22/23 04:21:34.751
Aug 22 04:21:34.754: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 08/22/23 04:21:34.754
Aug 22 04:21:34.765: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 08/22/23 04:21:34.765
Aug 22 04:21:34.773: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 22 04:21:34.775: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 22 04:21:34.810: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 22 04:21:34.850: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 22 04:21:34.860: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 22 04:21:34.868: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 22 04:21:37.560: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug 22 04:21:37.588: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug 22 04:21:37.614: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug 22 04:21:37.633: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug 22 04:21:41.436: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 08/22/23 04:21:41.649
STEP: fetching the DeploymentStatus 08/22/23 04:21:41.657
Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 3
STEP: deleting the Deployment 08/22/23 04:21:41.662
Aug 22 04:21:41.670: INFO: observed event type MODIFIED
Aug 22 04:21:41.670: INFO: observed event type MODIFIED
Aug 22 04:21:41.670: INFO: observed event type MODIFIED
Aug 22 04:21:41.670: INFO: observed event type MODIFIED
Aug 22 04:21:41.670: INFO: observed event type MODIFIED
Aug 22 04:21:41.670: INFO: observed event type MODIFIED
Aug 22 04:21:41.670: INFO: observed event type MODIFIED
Aug 22 04:21:41.671: INFO: observed event type MODIFIED
Aug 22 04:21:41.671: INFO: observed event type MODIFIED
Aug 22 04:21:41.671: INFO: observed event type MODIFIED
Aug 22 04:21:41.671: INFO: observed event type MODIFIED
Aug 22 04:21:41.671: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 22 04:21:41.683: INFO: Log out all the ReplicaSets if there is no deployment created
Aug 22 04:21:41.687: INFO: ReplicaSet "test-deployment-54cc775c4b":
&ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-6703  a1ff9dcd-1631-4a51-9d75-0ae04760bad4 1257258 4 2023-08-22 04:21:31 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 7b3ed4be-35ef-4bbd-8823-da9e0c2fff96 0xc0049a2c37 0xc0049a2c38}] [] [{kube-controller-manager Update apps/v1 2023-08-22 04:21:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7b3ed4be-35ef-4bbd-8823-da9e0c2fff96\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:21:41 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049a2cf0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Aug 22 04:21:41.695: INFO: pod: "test-deployment-54cc775c4b-tx4wq":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-tx4wq test-deployment-54cc775c4b- deployment-6703  2139d475-5b2c-4927-8e62-2062dd5b36d8 1257254 0 2023-08-22 04:21:31 +0000 UTC 2023-08-22 04:21:42 +0000 UTC 0xc004a80cd8 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-54cc775c4b a1ff9dcd-1631-4a51-9d75-0ae04760bad4 0xc004a80d17 0xc004a80d18}] [] [{kube-controller-manager Update v1 2023-08-22 04:21:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a1ff9dcd-1631-4a51-9d75-0ae04760bad4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:21:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.67\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-55twd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-55twd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:10.100.4.67,StartTime:2023-08-22 04:21:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:21:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://907130a60b2b532470bc0dba361e7c6b4cda5a48f4f6d4bc3bdd77d4cd46e09e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.4.67,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Aug 22 04:21:41.695: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
&ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-6703  4028ab58-3c11-4548-b93c-ef57d3ad8663 1257250 2 2023-08-22 04:21:34 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 7b3ed4be-35ef-4bbd-8823-da9e0c2fff96 0xc0049a2d77 0xc0049a2d78}] [] [{kube-controller-manager Update apps/v1 2023-08-22 04:21:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7b3ed4be-35ef-4bbd-8823-da9e0c2fff96\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:21:41 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049a2e20 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Aug 22 04:21:41.701: INFO: pod: "test-deployment-7c7d8d58c8-mfxmk":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-mfxmk test-deployment-7c7d8d58c8- deployment-6703  6f0a1d0c-5e15-49a2-9313-8400d9a93984 1257249 0 2023-08-22 04:21:37 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 4028ab58-3c11-4548-b93c-ef57d3ad8663 0xc0049a32d7 0xc0049a32d8}] [] [{kube-controller-manager Update v1 2023-08-22 04:21:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4028ab58-3c11-4548-b93c-ef57d3ad8663\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:21:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.68\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qb8dv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qb8dv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:10.100.4.68,StartTime:2023-08-22 04:21:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:21:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://a471b3703745ba421e3deac78c8b5263dfd68052e55bb0af1a95670042247ecd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.4.68,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Aug 22 04:21:41.701: INFO: pod: "test-deployment-7c7d8d58c8-ph6s6":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-ph6s6 test-deployment-7c7d8d58c8- deployment-6703  7fc6144e-95ea-4df8-b7d6-91fd9db96054 1257209 0 2023-08-22 04:21:34 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 4028ab58-3c11-4548-b93c-ef57d3ad8663 0xc0049a35b7 0xc0049a35b8}] [] [{kube-controller-manager Update v1 2023-08-22 04:21:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4028ab58-3c11-4548-b93c-ef57d3ad8663\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:21:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.5.24\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6968b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6968b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:10.100.5.24,StartTime:2023-08-22 04:21:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:21:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c9d50e15fbc94329255cbe27c5d771ac143a1d402848ffe749ca97eec4be5bb1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.5.24,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Aug 22 04:21:41.701: INFO: ReplicaSet "test-deployment-8594bb6fdd":
&ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-6703  c8df2371-f42e-48dc-b256-8e076b3cb84e 1257166 3 2023-08-22 04:21:24 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 7b3ed4be-35ef-4bbd-8823-da9e0c2fff96 0xc0049a2ea7 0xc0049a2ea8}] [] [{kube-controller-manager Update apps/v1 2023-08-22 04:21:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7b3ed4be-35ef-4bbd-8823-da9e0c2fff96\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:21:34 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049a2f40 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 22 04:21:41.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6703" for this suite. 08/22/23 04:21:41.891
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":89,"skipped":1656,"failed":0}
------------------------------
â€¢ [SLOW TEST] [17.311 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:21:24.61
    Aug 22 04:21:24.611: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename deployment 08/22/23 04:21:24.611
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:21:24.624
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:21:24.627
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 08/22/23 04:21:24.634
    STEP: waiting for Deployment to be created 08/22/23 04:21:24.641
    STEP: waiting for all Replicas to be Ready 08/22/23 04:21:24.644
    Aug 22 04:21:24.647: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 22 04:21:24.647: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 22 04:21:24.654: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 22 04:21:24.654: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 22 04:21:24.746: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 22 04:21:24.746: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 22 04:21:24.774: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 22 04:21:24.774: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 22 04:21:27.248: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Aug 22 04:21:27.248: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Aug 22 04:21:31.083: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 08/22/23 04:21:31.083
    W0822 04:21:31.091474      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Aug 22 04:21:31.093: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 08/22/23 04:21:31.093
    Aug 22 04:21:31.095: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
    Aug 22 04:21:31.095: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
    Aug 22 04:21:31.095: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
    Aug 22 04:21:31.095: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
    Aug 22 04:21:31.095: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
    Aug 22 04:21:31.095: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
    Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
    Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 0
    Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
    Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
    Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
    Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
    Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
    Aug 22 04:21:31.096: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
    Aug 22 04:21:31.106: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
    Aug 22 04:21:31.106: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
    Aug 22 04:21:31.134: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
    Aug 22 04:21:31.135: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
    Aug 22 04:21:31.149: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
    Aug 22 04:21:31.149: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
    Aug 22 04:21:31.186: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
    Aug 22 04:21:31.186: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
    Aug 22 04:21:34.718: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
    Aug 22 04:21:34.718: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
    Aug 22 04:21:34.751: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
    STEP: listing Deployments 08/22/23 04:21:34.751
    Aug 22 04:21:34.754: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 08/22/23 04:21:34.754
    Aug 22 04:21:34.765: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 08/22/23 04:21:34.765
    Aug 22 04:21:34.773: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 22 04:21:34.775: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 22 04:21:34.810: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 22 04:21:34.850: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 22 04:21:34.860: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 22 04:21:34.868: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 22 04:21:37.560: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 22 04:21:37.588: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 22 04:21:37.614: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 22 04:21:37.633: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 22 04:21:41.436: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 08/22/23 04:21:41.649
    STEP: fetching the DeploymentStatus 08/22/23 04:21:41.657
    Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
    Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
    Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
    Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
    Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
    Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 1
    Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
    Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
    Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
    Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 2
    Aug 22 04:21:41.661: INFO: observed Deployment test-deployment in namespace deployment-6703 with ReadyReplicas 3
    STEP: deleting the Deployment 08/22/23 04:21:41.662
    Aug 22 04:21:41.670: INFO: observed event type MODIFIED
    Aug 22 04:21:41.670: INFO: observed event type MODIFIED
    Aug 22 04:21:41.670: INFO: observed event type MODIFIED
    Aug 22 04:21:41.670: INFO: observed event type MODIFIED
    Aug 22 04:21:41.670: INFO: observed event type MODIFIED
    Aug 22 04:21:41.670: INFO: observed event type MODIFIED
    Aug 22 04:21:41.670: INFO: observed event type MODIFIED
    Aug 22 04:21:41.671: INFO: observed event type MODIFIED
    Aug 22 04:21:41.671: INFO: observed event type MODIFIED
    Aug 22 04:21:41.671: INFO: observed event type MODIFIED
    Aug 22 04:21:41.671: INFO: observed event type MODIFIED
    Aug 22 04:21:41.671: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 22 04:21:41.683: INFO: Log out all the ReplicaSets if there is no deployment created
    Aug 22 04:21:41.687: INFO: ReplicaSet "test-deployment-54cc775c4b":
    &ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-6703  a1ff9dcd-1631-4a51-9d75-0ae04760bad4 1257258 4 2023-08-22 04:21:31 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 7b3ed4be-35ef-4bbd-8823-da9e0c2fff96 0xc0049a2c37 0xc0049a2c38}] [] [{kube-controller-manager Update apps/v1 2023-08-22 04:21:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7b3ed4be-35ef-4bbd-8823-da9e0c2fff96\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:21:41 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049a2cf0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Aug 22 04:21:41.695: INFO: pod: "test-deployment-54cc775c4b-tx4wq":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-tx4wq test-deployment-54cc775c4b- deployment-6703  2139d475-5b2c-4927-8e62-2062dd5b36d8 1257254 0 2023-08-22 04:21:31 +0000 UTC 2023-08-22 04:21:42 +0000 UTC 0xc004a80cd8 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-54cc775c4b a1ff9dcd-1631-4a51-9d75-0ae04760bad4 0xc004a80d17 0xc004a80d18}] [] [{kube-controller-manager Update v1 2023-08-22 04:21:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a1ff9dcd-1631-4a51-9d75-0ae04760bad4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:21:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.67\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-55twd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-55twd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:10.100.4.67,StartTime:2023-08-22 04:21:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:21:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://907130a60b2b532470bc0dba361e7c6b4cda5a48f4f6d4bc3bdd77d4cd46e09e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.4.67,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Aug 22 04:21:41.695: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
    &ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-6703  4028ab58-3c11-4548-b93c-ef57d3ad8663 1257250 2 2023-08-22 04:21:34 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 7b3ed4be-35ef-4bbd-8823-da9e0c2fff96 0xc0049a2d77 0xc0049a2d78}] [] [{kube-controller-manager Update apps/v1 2023-08-22 04:21:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7b3ed4be-35ef-4bbd-8823-da9e0c2fff96\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:21:41 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049a2e20 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Aug 22 04:21:41.701: INFO: pod: "test-deployment-7c7d8d58c8-mfxmk":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-mfxmk test-deployment-7c7d8d58c8- deployment-6703  6f0a1d0c-5e15-49a2-9313-8400d9a93984 1257249 0 2023-08-22 04:21:37 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 4028ab58-3c11-4548-b93c-ef57d3ad8663 0xc0049a32d7 0xc0049a32d8}] [] [{kube-controller-manager Update v1 2023-08-22 04:21:37 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4028ab58-3c11-4548-b93c-ef57d3ad8663\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:21:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.68\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qb8dv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qb8dv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:10.100.4.68,StartTime:2023-08-22 04:21:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:21:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://a471b3703745ba421e3deac78c8b5263dfd68052e55bb0af1a95670042247ecd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.4.68,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Aug 22 04:21:41.701: INFO: pod: "test-deployment-7c7d8d58c8-ph6s6":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-ph6s6 test-deployment-7c7d8d58c8- deployment-6703  7fc6144e-95ea-4df8-b7d6-91fd9db96054 1257209 0 2023-08-22 04:21:34 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 4028ab58-3c11-4548-b93c-ef57d3ad8663 0xc0049a35b7 0xc0049a35b8}] [] [{kube-controller-manager Update v1 2023-08-22 04:21:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4028ab58-3c11-4548-b93c-ef57d3ad8663\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:21:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.5.24\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6968b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6968b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:21:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:10.100.5.24,StartTime:2023-08-22 04:21:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:21:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c9d50e15fbc94329255cbe27c5d771ac143a1d402848ffe749ca97eec4be5bb1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.5.24,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Aug 22 04:21:41.701: INFO: ReplicaSet "test-deployment-8594bb6fdd":
    &ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-6703  c8df2371-f42e-48dc-b256-8e076b3cb84e 1257166 3 2023-08-22 04:21:24 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 7b3ed4be-35ef-4bbd-8823-da9e0c2fff96 0xc0049a2ea7 0xc0049a2ea8}] [] [{kube-controller-manager Update apps/v1 2023-08-22 04:21:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7b3ed4be-35ef-4bbd-8823-da9e0c2fff96\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:21:34 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049a2f40 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 22 04:21:41.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-6703" for this suite. 08/22/23 04:21:41.891
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:21:41.924
Aug 22 04:21:41.924: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename security-context-test 08/22/23 04:21:41.924
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:21:41.941
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:21:41.943
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Aug 22 04:21:41.955: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1" in namespace "security-context-test-893" to be "Succeeded or Failed"
Aug 22 04:21:41.960: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.854314ms
Aug 22 04:21:43.963: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008169648s
Aug 22 04:21:45.964: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008644935s
Aug 22 04:21:47.964: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009350923s
Aug 22 04:21:49.964: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008602805s
Aug 22 04:21:52.338: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.383273036s
Aug 22 04:21:53.964: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.008556188s
Aug 22 04:21:53.964: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 22 04:21:53.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-893" for this suite. 08/22/23 04:21:53.996
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":90,"skipped":1702,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.081 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:21:41.924
    Aug 22 04:21:41.924: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename security-context-test 08/22/23 04:21:41.924
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:21:41.941
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:21:41.943
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Aug 22 04:21:41.955: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1" in namespace "security-context-test-893" to be "Succeeded or Failed"
    Aug 22 04:21:41.960: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.854314ms
    Aug 22 04:21:43.963: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008169648s
    Aug 22 04:21:45.964: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008644935s
    Aug 22 04:21:47.964: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009350923s
    Aug 22 04:21:49.964: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008602805s
    Aug 22 04:21:52.338: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.383273036s
    Aug 22 04:21:53.964: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.008556188s
    Aug 22 04:21:53.964: INFO: Pod "alpine-nnp-false-0933b355-57b9-4610-9144-4f63062c6ca1" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 22 04:21:53.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-893" for this suite. 08/22/23 04:21:53.996
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:21:54.007
Aug 22 04:21:54.007: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename resourcequota 08/22/23 04:21:54.008
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:21:54.026
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:21:54.03
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 08/22/23 04:21:54.034
STEP: Ensuring ResourceQuota status is calculated 08/22/23 04:21:54.04
STEP: Creating a ResourceQuota with not terminating scope 08/22/23 04:21:56.044
STEP: Ensuring ResourceQuota status is calculated 08/22/23 04:21:56.048
STEP: Creating a long running pod 08/22/23 04:21:58.054
STEP: Ensuring resource quota with not terminating scope captures the pod usage 08/22/23 04:21:58.075
STEP: Ensuring resource quota with terminating scope ignored the pod usage 08/22/23 04:22:00.079
STEP: Deleting the pod 08/22/23 04:22:02.083
STEP: Ensuring resource quota status released the pod usage 08/22/23 04:22:02.113
STEP: Creating a terminating pod 08/22/23 04:22:04.118
STEP: Ensuring resource quota with terminating scope captures the pod usage 08/22/23 04:22:04.204
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 08/22/23 04:22:06.208
STEP: Deleting the pod 08/22/23 04:22:08.212
STEP: Ensuring resource quota status released the pod usage 08/22/23 04:22:08.227
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 22 04:22:10.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6676" for this suite. 08/22/23 04:22:10.235
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":91,"skipped":1717,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.235 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:21:54.007
    Aug 22 04:21:54.007: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename resourcequota 08/22/23 04:21:54.008
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:21:54.026
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:21:54.03
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 08/22/23 04:21:54.034
    STEP: Ensuring ResourceQuota status is calculated 08/22/23 04:21:54.04
    STEP: Creating a ResourceQuota with not terminating scope 08/22/23 04:21:56.044
    STEP: Ensuring ResourceQuota status is calculated 08/22/23 04:21:56.048
    STEP: Creating a long running pod 08/22/23 04:21:58.054
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 08/22/23 04:21:58.075
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 08/22/23 04:22:00.079
    STEP: Deleting the pod 08/22/23 04:22:02.083
    STEP: Ensuring resource quota status released the pod usage 08/22/23 04:22:02.113
    STEP: Creating a terminating pod 08/22/23 04:22:04.118
    STEP: Ensuring resource quota with terminating scope captures the pod usage 08/22/23 04:22:04.204
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 08/22/23 04:22:06.208
    STEP: Deleting the pod 08/22/23 04:22:08.212
    STEP: Ensuring resource quota status released the pod usage 08/22/23 04:22:08.227
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 22 04:22:10.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6676" for this suite. 08/22/23 04:22:10.235
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:22:10.244
Aug 22 04:22:10.244: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename resourcequota 08/22/23 04:22:10.245
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:22:10.287
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:22:10.29
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 08/22/23 04:22:10.293
STEP: Getting a ResourceQuota 08/22/23 04:22:10.297
STEP: Listing all ResourceQuotas with LabelSelector 08/22/23 04:22:10.301
STEP: Patching the ResourceQuota 08/22/23 04:22:10.303
STEP: Deleting a Collection of ResourceQuotas 08/22/23 04:22:10.31
STEP: Verifying the deleted ResourceQuota 08/22/23 04:22:10.318
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 22 04:22:10.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-482" for this suite. 08/22/23 04:22:10.322
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":92,"skipped":1720,"failed":0}
------------------------------
â€¢ [0.083 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:22:10.244
    Aug 22 04:22:10.244: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename resourcequota 08/22/23 04:22:10.245
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:22:10.287
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:22:10.29
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 08/22/23 04:22:10.293
    STEP: Getting a ResourceQuota 08/22/23 04:22:10.297
    STEP: Listing all ResourceQuotas with LabelSelector 08/22/23 04:22:10.301
    STEP: Patching the ResourceQuota 08/22/23 04:22:10.303
    STEP: Deleting a Collection of ResourceQuotas 08/22/23 04:22:10.31
    STEP: Verifying the deleted ResourceQuota 08/22/23 04:22:10.318
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 22 04:22:10.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-482" for this suite. 08/22/23 04:22:10.322
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:22:10.329
Aug 22 04:22:10.329: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename sched-preemption 08/22/23 04:22:10.33
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:22:10.544
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:22:10.546
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug 22 04:22:10.562: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 22 04:23:10.602: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:23:10.607
Aug 22 04:23:10.607: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename sched-preemption-path 08/22/23 04:23:10.607
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:23:10.725
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:23:10.728
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 08/22/23 04:23:10.732
STEP: Trying to launch a pod without a label to get a node which can launch it. 08/22/23 04:23:10.732
Aug 22 04:23:10.740: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-9414" to be "running"
Aug 22 04:23:10.744: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.813794ms
Aug 22 04:23:12.748: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008241495s
Aug 22 04:23:14.749: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.009514467s
Aug 22 04:23:14.749: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 08/22/23 04:23:14.751
Aug 22 04:23:14.762: INFO: found a healthy node: jake-melb-gmyyva4zrlsz-node-2
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Aug 22 04:23:34.872: INFO: pods created so far: [1 1 1]
Aug 22 04:23:34.872: INFO: length of pods created so far: 3
Aug 22 04:23:38.882: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Aug 22 04:23:45.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-9414" for this suite. 08/22/23 04:23:45.889
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Aug 22 04:23:45.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7783" for this suite. 08/22/23 04:23:45.951
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":93,"skipped":1728,"failed":0}
------------------------------
â€¢ [SLOW TEST] [95.742 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:22:10.329
    Aug 22 04:22:10.329: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename sched-preemption 08/22/23 04:22:10.33
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:22:10.544
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:22:10.546
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Aug 22 04:22:10.562: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 22 04:23:10.602: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:23:10.607
    Aug 22 04:23:10.607: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename sched-preemption-path 08/22/23 04:23:10.607
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:23:10.725
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:23:10.728
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 08/22/23 04:23:10.732
    STEP: Trying to launch a pod without a label to get a node which can launch it. 08/22/23 04:23:10.732
    Aug 22 04:23:10.740: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-9414" to be "running"
    Aug 22 04:23:10.744: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.813794ms
    Aug 22 04:23:12.748: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008241495s
    Aug 22 04:23:14.749: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.009514467s
    Aug 22 04:23:14.749: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 08/22/23 04:23:14.751
    Aug 22 04:23:14.762: INFO: found a healthy node: jake-melb-gmyyva4zrlsz-node-2
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Aug 22 04:23:34.872: INFO: pods created so far: [1 1 1]
    Aug 22 04:23:34.872: INFO: length of pods created so far: 3
    Aug 22 04:23:38.882: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Aug 22 04:23:45.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-9414" for this suite. 08/22/23 04:23:45.889
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 04:23:45.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-7783" for this suite. 08/22/23 04:23:45.951
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:23:46.073
Aug 22 04:23:46.073: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename sched-pred 08/22/23 04:23:46.074
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:23:46.094
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:23:46.097
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug 22 04:23:46.101: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 22 04:23:46.108: INFO: Waiting for terminating namespaces to be deleted...
Aug 22 04:23:46.111: INFO: 
Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-0 before test
Aug 22 04:23:46.120: INFO: csi-cinder-nodeplugin-zmsc8 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (3 container statuses recorded)
Aug 22 04:23:46.120: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Aug 22 04:23:46.120: INFO: 	Container liveness-probe ready: true, restart count 0
Aug 22 04:23:46.120: INFO: 	Container node-driver-registrar ready: true, restart count 0
Aug 22 04:23:46.120: INFO: kube-dns-autoscaler-96fb49f55-c54df from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
Aug 22 04:23:46.120: INFO: 	Container autoscaler ready: true, restart count 0
Aug 22 04:23:46.120: INFO: kube-flannel-ds-m6hb5 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (1 container statuses recorded)
Aug 22 04:23:46.120: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 22 04:23:46.120: INFO: magnum-metrics-server-758ff97b5-qfdbj from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
Aug 22 04:23:46.120: INFO: 	Container metrics-server ready: true, restart count 0
Aug 22 04:23:46.120: INFO: npd-z88sb from kube-system started at 2023-08-17 07:08:01 +0000 UTC (1 container statuses recorded)
Aug 22 04:23:46.120: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug 22 04:23:46.120: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-gklhn from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 04:23:46.120: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 04:23:46.120: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 04:23:46.120: INFO: 
Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-1 before test
Aug 22 04:23:46.127: INFO: csi-cinder-nodeplugin-jmnz5 from kube-system started at 2023-08-22 03:43:22 +0000 UTC (3 container statuses recorded)
Aug 22 04:23:46.127: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Aug 22 04:23:46.127: INFO: 	Container liveness-probe ready: true, restart count 0
Aug 22 04:23:46.127: INFO: 	Container node-driver-registrar ready: true, restart count 0
Aug 22 04:23:46.127: INFO: kube-flannel-ds-pc26k from kube-system started at 2023-08-22 03:43:22 +0000 UTC (1 container statuses recorded)
Aug 22 04:23:46.127: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 22 04:23:46.127: INFO: npd-jxn7d from kube-system started at 2023-08-22 03:43:42 +0000 UTC (1 container statuses recorded)
Aug 22 04:23:46.127: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug 22 04:23:46.127: INFO: sonobuoy-e2e-job-95e99bb4c3804681 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 04:23:46.127: INFO: 	Container e2e ready: true, restart count 0
Aug 22 04:23:46.127: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 04:23:46.127: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-mmzwp from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 04:23:46.127: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 04:23:46.127: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 04:23:46.127: INFO: 
Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-2 before test
Aug 22 04:23:46.134: INFO: csi-cinder-nodeplugin-6xsh5 from kube-system started at 2023-08-22 03:43:15 +0000 UTC (3 container statuses recorded)
Aug 22 04:23:46.134: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Aug 22 04:23:46.134: INFO: 	Container liveness-probe ready: true, restart count 0
Aug 22 04:23:46.134: INFO: 	Container node-driver-registrar ready: true, restart count 0
Aug 22 04:23:46.134: INFO: kube-flannel-ds-g6mwx from kube-system started at 2023-08-22 04:19:06 +0000 UTC (1 container statuses recorded)
Aug 22 04:23:46.134: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 22 04:23:46.134: INFO: npd-cwq76 from kube-system started at 2023-08-22 03:43:35 +0000 UTC (1 container statuses recorded)
Aug 22 04:23:46.134: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug 22 04:23:46.134: INFO: pod4 from sched-preemption-path-9414 started at 2023-08-22 04:23:37 +0000 UTC (1 container statuses recorded)
Aug 22 04:23:46.134: INFO: 	Container pod4 ready: true, restart count 0
Aug 22 04:23:46.134: INFO: rs-pod3-krx9h from sched-preemption-path-9414 started at 2023-08-22 04:23:30 +0000 UTC (1 container statuses recorded)
Aug 22 04:23:46.134: INFO: 	Container pod3 ready: true, restart count 0
Aug 22 04:23:46.134: INFO: sonobuoy from sonobuoy started at 2023-08-22 03:50:01 +0000 UTC (1 container statuses recorded)
Aug 22 04:23:46.134: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 22 04:23:46.134: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-6dms5 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 04:23:46.134: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 04:23:46.134: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 08/22/23 04:23:46.134
Aug 22 04:23:46.250: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-8467" to be "running"
Aug 22 04:23:46.262: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 12.253695ms
Aug 22 04:23:48.267: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016926676s
Aug 22 04:23:50.267: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.017458019s
Aug 22 04:23:50.267: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 08/22/23 04:23:50.27
STEP: Trying to apply a random label on the found node. 08/22/23 04:23:50.298
STEP: verifying the node has the label kubernetes.io/e2e-1edd353c-4154-40b9-85b8-4e566dbc5e6a 95 08/22/23 04:23:50.322
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 08/22/23 04:23:50.328
Aug 22 04:23:50.340: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-8467" to be "not pending"
Aug 22 04:23:50.344: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.251098ms
Aug 22 04:23:52.349: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008225723s
Aug 22 04:23:54.347: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 4.00680847s
Aug 22 04:23:54.347: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.0.0.97 on the node which pod4 resides and expect not scheduled 08/22/23 04:23:54.347
Aug 22 04:23:54.354: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-8467" to be "not pending"
Aug 22 04:23:54.357: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.109172ms
Aug 22 04:23:56.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007944827s
Aug 22 04:23:58.465: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.111274202s
Aug 22 04:24:00.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006701515s
Aug 22 04:24:02.372: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017973298s
Aug 22 04:24:04.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007789338s
Aug 22 04:24:06.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.006802213s
Aug 22 04:24:08.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.007520707s
Aug 22 04:24:10.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.006437532s
Aug 22 04:24:12.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.007257618s
Aug 22 04:24:14.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.006524427s
Aug 22 04:24:16.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.006810088s
Aug 22 04:24:18.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.007028264s
Aug 22 04:24:20.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.007085106s
Aug 22 04:24:22.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.008927439s
Aug 22 04:24:24.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.0088811s
Aug 22 04:24:26.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.007227612s
Aug 22 04:24:28.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.007340158s
Aug 22 04:24:30.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.009298117s
Aug 22 04:24:32.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.006949677s
Aug 22 04:24:34.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.007044811s
Aug 22 04:24:36.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.009890688s
Aug 22 04:24:38.373: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.01862066s
Aug 22 04:24:40.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.006718097s
Aug 22 04:24:42.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.007228219s
Aug 22 04:24:44.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.007870811s
Aug 22 04:24:46.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.007238042s
Aug 22 04:24:48.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.006406999s
Aug 22 04:24:50.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.009451105s
Aug 22 04:24:52.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.007777641s
Aug 22 04:24:54.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.007141454s
Aug 22 04:24:56.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.00820273s
Aug 22 04:24:58.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.007718929s
Aug 22 04:25:00.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.006762912s
Aug 22 04:25:02.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.007343166s
Aug 22 04:25:04.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.007121555s
Aug 22 04:25:06.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.007081176s
Aug 22 04:25:08.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.007590767s
Aug 22 04:25:10.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.008178997s
Aug 22 04:25:12.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.007804891s
Aug 22 04:25:14.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.00820661s
Aug 22 04:25:16.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.007559675s
Aug 22 04:25:18.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.006870147s
Aug 22 04:25:20.360: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.006342792s
Aug 22 04:25:22.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.006813412s
Aug 22 04:25:24.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.007008153s
Aug 22 04:25:26.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.010235183s
Aug 22 04:25:28.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.008963443s
Aug 22 04:25:30.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.00784357s
Aug 22 04:25:32.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.009292893s
Aug 22 04:25:34.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.007179134s
Aug 22 04:25:36.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.006871743s
Aug 22 04:25:38.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.007590227s
Aug 22 04:25:40.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.008912333s
Aug 22 04:25:42.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.007102134s
Aug 22 04:25:44.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.007508031s
Aug 22 04:25:46.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.006980367s
Aug 22 04:25:48.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.008171046s
Aug 22 04:25:50.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.007103409s
Aug 22 04:25:52.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.006838059s
Aug 22 04:25:54.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.006617492s
Aug 22 04:25:56.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.007659061s
Aug 22 04:25:58.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.006949183s
Aug 22 04:26:00.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.008690397s
Aug 22 04:26:02.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.006438027s
Aug 22 04:26:04.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.008556588s
Aug 22 04:26:06.547: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.192714369s
Aug 22 04:26:08.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.008236038s
Aug 22 04:26:10.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.007065229s
Aug 22 04:26:12.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.009588206s
Aug 22 04:26:14.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.006543572s
Aug 22 04:26:16.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.007900152s
Aug 22 04:26:18.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.006689207s
Aug 22 04:26:20.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.007081691s
Aug 22 04:26:22.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.00883697s
Aug 22 04:26:24.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.007594373s
Aug 22 04:26:26.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.007833588s
Aug 22 04:26:28.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.008116343s
Aug 22 04:26:30.360: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.006299691s
Aug 22 04:26:32.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.006852245s
Aug 22 04:26:34.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.006849375s
Aug 22 04:26:36.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.007426725s
Aug 22 04:26:38.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.006964222s
Aug 22 04:26:40.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.008526679s
Aug 22 04:26:42.360: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.006212985s
Aug 22 04:26:44.360: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.006088006s
Aug 22 04:26:46.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.008772899s
Aug 22 04:26:48.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.006582226s
Aug 22 04:26:50.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.00860175s
Aug 22 04:26:52.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.007811453s
Aug 22 04:26:54.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.006652004s
Aug 22 04:26:56.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.008382056s
Aug 22 04:26:58.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.007954961s
Aug 22 04:27:00.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.010015754s
Aug 22 04:27:02.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.007303692s
Aug 22 04:27:04.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.007528899s
Aug 22 04:27:06.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.006865812s
Aug 22 04:27:08.653: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.299370333s
Aug 22 04:27:10.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.006906258s
Aug 22 04:27:12.580: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.22571768s
Aug 22 04:27:14.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.007851446s
Aug 22 04:27:16.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.008543759s
Aug 22 04:27:18.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.006575233s
Aug 22 04:27:20.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.00799393s
Aug 22 04:27:22.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.008783316s
Aug 22 04:27:24.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.007359452s
Aug 22 04:27:26.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.107531171s
Aug 22 04:27:28.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.006698943s
Aug 22 04:27:30.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.007867883s
Aug 22 04:27:32.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.007012975s
Aug 22 04:27:34.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.008324063s
Aug 22 04:27:36.360: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.006052115s
Aug 22 04:27:38.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.006602293s
Aug 22 04:27:40.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.007563311s
Aug 22 04:27:42.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.009884313s
Aug 22 04:27:44.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.009592871s
Aug 22 04:27:46.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.007970282s
Aug 22 04:27:48.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.007321824s
Aug 22 04:27:50.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.006820669s
Aug 22 04:27:52.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.008129229s
Aug 22 04:27:54.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.008053593s
Aug 22 04:27:56.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.007644882s
Aug 22 04:27:58.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.006922593s
Aug 22 04:28:00.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.006641423s
Aug 22 04:28:02.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.00856138s
Aug 22 04:28:04.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.007273078s
Aug 22 04:28:06.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.008111898s
Aug 22 04:28:08.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.007416088s
Aug 22 04:28:10.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.006913051s
Aug 22 04:28:12.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.007013988s
Aug 22 04:28:14.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.006958099s
Aug 22 04:28:16.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.007105765s
Aug 22 04:28:18.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.007335064s
Aug 22 04:28:20.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.007507325s
Aug 22 04:28:22.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.007193595s
Aug 22 04:28:24.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.006965235s
Aug 22 04:28:26.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.008669049s
Aug 22 04:28:28.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.006789784s
Aug 22 04:28:30.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.006610606s
Aug 22 04:28:32.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.007506676s
Aug 22 04:28:34.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.009606084s
Aug 22 04:28:36.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.0088633s
Aug 22 04:28:38.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.007026963s
Aug 22 04:28:40.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.007065876s
Aug 22 04:28:42.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.007788721s
Aug 22 04:28:44.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.007603752s
Aug 22 04:28:46.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.007615182s
Aug 22 04:28:48.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.007429823s
Aug 22 04:28:50.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.006567464s
Aug 22 04:28:52.380: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.026146956s
Aug 22 04:28:54.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.007843956s
Aug 22 04:28:54.365: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.010373813s
STEP: removing the label kubernetes.io/e2e-1edd353c-4154-40b9-85b8-4e566dbc5e6a off the node jake-melb-gmyyva4zrlsz-node-0 08/22/23 04:28:54.365
STEP: verifying the node doesn't have the label kubernetes.io/e2e-1edd353c-4154-40b9-85b8-4e566dbc5e6a 08/22/23 04:28:54.383
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Aug 22 04:28:54.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8467" for this suite. 08/22/23 04:28:54.39
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":94,"skipped":1749,"failed":0}
------------------------------
â€¢ [SLOW TEST] [308.324 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:23:46.073
    Aug 22 04:23:46.073: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename sched-pred 08/22/23 04:23:46.074
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:23:46.094
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:23:46.097
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Aug 22 04:23:46.101: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Aug 22 04:23:46.108: INFO: Waiting for terminating namespaces to be deleted...
    Aug 22 04:23:46.111: INFO: 
    Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-0 before test
    Aug 22 04:23:46.120: INFO: csi-cinder-nodeplugin-zmsc8 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (3 container statuses recorded)
    Aug 22 04:23:46.120: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
    Aug 22 04:23:46.120: INFO: 	Container liveness-probe ready: true, restart count 0
    Aug 22 04:23:46.120: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Aug 22 04:23:46.120: INFO: kube-dns-autoscaler-96fb49f55-c54df from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
    Aug 22 04:23:46.120: INFO: 	Container autoscaler ready: true, restart count 0
    Aug 22 04:23:46.120: INFO: kube-flannel-ds-m6hb5 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (1 container statuses recorded)
    Aug 22 04:23:46.120: INFO: 	Container kube-flannel ready: true, restart count 0
    Aug 22 04:23:46.120: INFO: magnum-metrics-server-758ff97b5-qfdbj from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
    Aug 22 04:23:46.120: INFO: 	Container metrics-server ready: true, restart count 0
    Aug 22 04:23:46.120: INFO: npd-z88sb from kube-system started at 2023-08-17 07:08:01 +0000 UTC (1 container statuses recorded)
    Aug 22 04:23:46.120: INFO: 	Container node-problem-detector ready: true, restart count 0
    Aug 22 04:23:46.120: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-gklhn from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 04:23:46.120: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 04:23:46.120: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 22 04:23:46.120: INFO: 
    Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-1 before test
    Aug 22 04:23:46.127: INFO: csi-cinder-nodeplugin-jmnz5 from kube-system started at 2023-08-22 03:43:22 +0000 UTC (3 container statuses recorded)
    Aug 22 04:23:46.127: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
    Aug 22 04:23:46.127: INFO: 	Container liveness-probe ready: true, restart count 0
    Aug 22 04:23:46.127: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Aug 22 04:23:46.127: INFO: kube-flannel-ds-pc26k from kube-system started at 2023-08-22 03:43:22 +0000 UTC (1 container statuses recorded)
    Aug 22 04:23:46.127: INFO: 	Container kube-flannel ready: true, restart count 0
    Aug 22 04:23:46.127: INFO: npd-jxn7d from kube-system started at 2023-08-22 03:43:42 +0000 UTC (1 container statuses recorded)
    Aug 22 04:23:46.127: INFO: 	Container node-problem-detector ready: true, restart count 0
    Aug 22 04:23:46.127: INFO: sonobuoy-e2e-job-95e99bb4c3804681 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 04:23:46.127: INFO: 	Container e2e ready: true, restart count 0
    Aug 22 04:23:46.127: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 04:23:46.127: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-mmzwp from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 04:23:46.127: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 04:23:46.127: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 22 04:23:46.127: INFO: 
    Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-2 before test
    Aug 22 04:23:46.134: INFO: csi-cinder-nodeplugin-6xsh5 from kube-system started at 2023-08-22 03:43:15 +0000 UTC (3 container statuses recorded)
    Aug 22 04:23:46.134: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
    Aug 22 04:23:46.134: INFO: 	Container liveness-probe ready: true, restart count 0
    Aug 22 04:23:46.134: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Aug 22 04:23:46.134: INFO: kube-flannel-ds-g6mwx from kube-system started at 2023-08-22 04:19:06 +0000 UTC (1 container statuses recorded)
    Aug 22 04:23:46.134: INFO: 	Container kube-flannel ready: true, restart count 0
    Aug 22 04:23:46.134: INFO: npd-cwq76 from kube-system started at 2023-08-22 03:43:35 +0000 UTC (1 container statuses recorded)
    Aug 22 04:23:46.134: INFO: 	Container node-problem-detector ready: true, restart count 0
    Aug 22 04:23:46.134: INFO: pod4 from sched-preemption-path-9414 started at 2023-08-22 04:23:37 +0000 UTC (1 container statuses recorded)
    Aug 22 04:23:46.134: INFO: 	Container pod4 ready: true, restart count 0
    Aug 22 04:23:46.134: INFO: rs-pod3-krx9h from sched-preemption-path-9414 started at 2023-08-22 04:23:30 +0000 UTC (1 container statuses recorded)
    Aug 22 04:23:46.134: INFO: 	Container pod3 ready: true, restart count 0
    Aug 22 04:23:46.134: INFO: sonobuoy from sonobuoy started at 2023-08-22 03:50:01 +0000 UTC (1 container statuses recorded)
    Aug 22 04:23:46.134: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Aug 22 04:23:46.134: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-6dms5 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 04:23:46.134: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 04:23:46.134: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 08/22/23 04:23:46.134
    Aug 22 04:23:46.250: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-8467" to be "running"
    Aug 22 04:23:46.262: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 12.253695ms
    Aug 22 04:23:48.267: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016926676s
    Aug 22 04:23:50.267: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.017458019s
    Aug 22 04:23:50.267: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 08/22/23 04:23:50.27
    STEP: Trying to apply a random label on the found node. 08/22/23 04:23:50.298
    STEP: verifying the node has the label kubernetes.io/e2e-1edd353c-4154-40b9-85b8-4e566dbc5e6a 95 08/22/23 04:23:50.322
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 08/22/23 04:23:50.328
    Aug 22 04:23:50.340: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-8467" to be "not pending"
    Aug 22 04:23:50.344: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.251098ms
    Aug 22 04:23:52.349: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008225723s
    Aug 22 04:23:54.347: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 4.00680847s
    Aug 22 04:23:54.347: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.0.0.97 on the node which pod4 resides and expect not scheduled 08/22/23 04:23:54.347
    Aug 22 04:23:54.354: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-8467" to be "not pending"
    Aug 22 04:23:54.357: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.109172ms
    Aug 22 04:23:56.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007944827s
    Aug 22 04:23:58.465: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.111274202s
    Aug 22 04:24:00.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006701515s
    Aug 22 04:24:02.372: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017973298s
    Aug 22 04:24:04.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007789338s
    Aug 22 04:24:06.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.006802213s
    Aug 22 04:24:08.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.007520707s
    Aug 22 04:24:10.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.006437532s
    Aug 22 04:24:12.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.007257618s
    Aug 22 04:24:14.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.006524427s
    Aug 22 04:24:16.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.006810088s
    Aug 22 04:24:18.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.007028264s
    Aug 22 04:24:20.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.007085106s
    Aug 22 04:24:22.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.008927439s
    Aug 22 04:24:24.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.0088811s
    Aug 22 04:24:26.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.007227612s
    Aug 22 04:24:28.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.007340158s
    Aug 22 04:24:30.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.009298117s
    Aug 22 04:24:32.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.006949677s
    Aug 22 04:24:34.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.007044811s
    Aug 22 04:24:36.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.009890688s
    Aug 22 04:24:38.373: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.01862066s
    Aug 22 04:24:40.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.006718097s
    Aug 22 04:24:42.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.007228219s
    Aug 22 04:24:44.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.007870811s
    Aug 22 04:24:46.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.007238042s
    Aug 22 04:24:48.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.006406999s
    Aug 22 04:24:50.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.009451105s
    Aug 22 04:24:52.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.007777641s
    Aug 22 04:24:54.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.007141454s
    Aug 22 04:24:56.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.00820273s
    Aug 22 04:24:58.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.007718929s
    Aug 22 04:25:00.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.006762912s
    Aug 22 04:25:02.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.007343166s
    Aug 22 04:25:04.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.007121555s
    Aug 22 04:25:06.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.007081176s
    Aug 22 04:25:08.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.007590767s
    Aug 22 04:25:10.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.008178997s
    Aug 22 04:25:12.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.007804891s
    Aug 22 04:25:14.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.00820661s
    Aug 22 04:25:16.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.007559675s
    Aug 22 04:25:18.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.006870147s
    Aug 22 04:25:20.360: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.006342792s
    Aug 22 04:25:22.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.006813412s
    Aug 22 04:25:24.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.007008153s
    Aug 22 04:25:26.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.010235183s
    Aug 22 04:25:28.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.008963443s
    Aug 22 04:25:30.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.00784357s
    Aug 22 04:25:32.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.009292893s
    Aug 22 04:25:34.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.007179134s
    Aug 22 04:25:36.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.006871743s
    Aug 22 04:25:38.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.007590227s
    Aug 22 04:25:40.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.008912333s
    Aug 22 04:25:42.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.007102134s
    Aug 22 04:25:44.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.007508031s
    Aug 22 04:25:46.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.006980367s
    Aug 22 04:25:48.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.008171046s
    Aug 22 04:25:50.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.007103409s
    Aug 22 04:25:52.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.006838059s
    Aug 22 04:25:54.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.006617492s
    Aug 22 04:25:56.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.007659061s
    Aug 22 04:25:58.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.006949183s
    Aug 22 04:26:00.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.008690397s
    Aug 22 04:26:02.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.006438027s
    Aug 22 04:26:04.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.008556588s
    Aug 22 04:26:06.547: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.192714369s
    Aug 22 04:26:08.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.008236038s
    Aug 22 04:26:10.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.007065229s
    Aug 22 04:26:12.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.009588206s
    Aug 22 04:26:14.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.006543572s
    Aug 22 04:26:16.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.007900152s
    Aug 22 04:26:18.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.006689207s
    Aug 22 04:26:20.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.007081691s
    Aug 22 04:26:22.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.00883697s
    Aug 22 04:26:24.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.007594373s
    Aug 22 04:26:26.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.007833588s
    Aug 22 04:26:28.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.008116343s
    Aug 22 04:26:30.360: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.006299691s
    Aug 22 04:26:32.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.006852245s
    Aug 22 04:26:34.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.006849375s
    Aug 22 04:26:36.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.007426725s
    Aug 22 04:26:38.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.006964222s
    Aug 22 04:26:40.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.008526679s
    Aug 22 04:26:42.360: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.006212985s
    Aug 22 04:26:44.360: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.006088006s
    Aug 22 04:26:46.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.008772899s
    Aug 22 04:26:48.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.006582226s
    Aug 22 04:26:50.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.00860175s
    Aug 22 04:26:52.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.007811453s
    Aug 22 04:26:54.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.006652004s
    Aug 22 04:26:56.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.008382056s
    Aug 22 04:26:58.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.007954961s
    Aug 22 04:27:00.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.010015754s
    Aug 22 04:27:02.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.007303692s
    Aug 22 04:27:04.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.007528899s
    Aug 22 04:27:06.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.006865812s
    Aug 22 04:27:08.653: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.299370333s
    Aug 22 04:27:10.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.006906258s
    Aug 22 04:27:12.580: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.22571768s
    Aug 22 04:27:14.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.007851446s
    Aug 22 04:27:16.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.008543759s
    Aug 22 04:27:18.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.006575233s
    Aug 22 04:27:20.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.00799393s
    Aug 22 04:27:22.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.008783316s
    Aug 22 04:27:24.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.007359452s
    Aug 22 04:27:26.462: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.107531171s
    Aug 22 04:27:28.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.006698943s
    Aug 22 04:27:30.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.007867883s
    Aug 22 04:27:32.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.007012975s
    Aug 22 04:27:34.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.008324063s
    Aug 22 04:27:36.360: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.006052115s
    Aug 22 04:27:38.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.006602293s
    Aug 22 04:27:40.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.007563311s
    Aug 22 04:27:42.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.009884313s
    Aug 22 04:27:44.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.009592871s
    Aug 22 04:27:46.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.007970282s
    Aug 22 04:27:48.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.007321824s
    Aug 22 04:27:50.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.006820669s
    Aug 22 04:27:52.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.008129229s
    Aug 22 04:27:54.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.008053593s
    Aug 22 04:27:56.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.007644882s
    Aug 22 04:27:58.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.006922593s
    Aug 22 04:28:00.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.006641423s
    Aug 22 04:28:02.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.00856138s
    Aug 22 04:28:04.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.007273078s
    Aug 22 04:28:06.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.008111898s
    Aug 22 04:28:08.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.007416088s
    Aug 22 04:28:10.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.006913051s
    Aug 22 04:28:12.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.007013988s
    Aug 22 04:28:14.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.006958099s
    Aug 22 04:28:16.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.007105765s
    Aug 22 04:28:18.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.007335064s
    Aug 22 04:28:20.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.007507325s
    Aug 22 04:28:22.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.007193595s
    Aug 22 04:28:24.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.006965235s
    Aug 22 04:28:26.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.008669049s
    Aug 22 04:28:28.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.006789784s
    Aug 22 04:28:30.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.006610606s
    Aug 22 04:28:32.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.007506676s
    Aug 22 04:28:34.364: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.009606084s
    Aug 22 04:28:36.363: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.0088633s
    Aug 22 04:28:38.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.007026963s
    Aug 22 04:28:40.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.007065876s
    Aug 22 04:28:42.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.007788721s
    Aug 22 04:28:44.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.007603752s
    Aug 22 04:28:46.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.007615182s
    Aug 22 04:28:48.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.007429823s
    Aug 22 04:28:50.361: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.006567464s
    Aug 22 04:28:52.380: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.026146956s
    Aug 22 04:28:54.362: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.007843956s
    Aug 22 04:28:54.365: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.010373813s
    STEP: removing the label kubernetes.io/e2e-1edd353c-4154-40b9-85b8-4e566dbc5e6a off the node jake-melb-gmyyva4zrlsz-node-0 08/22/23 04:28:54.365
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-1edd353c-4154-40b9-85b8-4e566dbc5e6a 08/22/23 04:28:54.383
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 04:28:54.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8467" for this suite. 08/22/23 04:28:54.39
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:28:54.398
Aug 22 04:28:54.398: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir-wrapper 08/22/23 04:28:54.399
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:28:54.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:28:54.419
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Aug 22 04:28:54.493: INFO: Waiting up to 5m0s for pod "pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141" in namespace "emptydir-wrapper-698" to be "running and ready"
Aug 22 04:28:54.498: INFO: Pod "pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141": Phase="Pending", Reason="", readiness=false. Elapsed: 4.766213ms
Aug 22 04:28:54.498: INFO: The phase of Pod pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:28:56.501: INFO: Pod "pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008511629s
Aug 22 04:28:56.502: INFO: The phase of Pod pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:28:58.502: INFO: Pod "pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141": Phase="Running", Reason="", readiness=true. Elapsed: 4.009054776s
Aug 22 04:28:58.502: INFO: The phase of Pod pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141 is Running (Ready = true)
Aug 22 04:28:58.502: INFO: Pod "pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141" satisfied condition "running and ready"
STEP: Cleaning up the secret 08/22/23 04:28:58.505
STEP: Cleaning up the configmap 08/22/23 04:28:58.511
STEP: Cleaning up the pod 08/22/23 04:28:58.554
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Aug 22 04:28:58.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-698" for this suite. 08/22/23 04:28:58.575
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":95,"skipped":1756,"failed":0}
------------------------------
â€¢ [4.186 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:28:54.398
    Aug 22 04:28:54.398: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir-wrapper 08/22/23 04:28:54.399
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:28:54.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:28:54.419
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Aug 22 04:28:54.493: INFO: Waiting up to 5m0s for pod "pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141" in namespace "emptydir-wrapper-698" to be "running and ready"
    Aug 22 04:28:54.498: INFO: Pod "pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141": Phase="Pending", Reason="", readiness=false. Elapsed: 4.766213ms
    Aug 22 04:28:54.498: INFO: The phase of Pod pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:28:56.501: INFO: Pod "pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008511629s
    Aug 22 04:28:56.502: INFO: The phase of Pod pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:28:58.502: INFO: Pod "pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141": Phase="Running", Reason="", readiness=true. Elapsed: 4.009054776s
    Aug 22 04:28:58.502: INFO: The phase of Pod pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141 is Running (Ready = true)
    Aug 22 04:28:58.502: INFO: Pod "pod-secrets-0176656d-0eab-45bf-85b0-7b7f1abf0141" satisfied condition "running and ready"
    STEP: Cleaning up the secret 08/22/23 04:28:58.505
    STEP: Cleaning up the configmap 08/22/23 04:28:58.511
    STEP: Cleaning up the pod 08/22/23 04:28:58.554
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Aug 22 04:28:58.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-698" for this suite. 08/22/23 04:28:58.575
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:28:58.587
Aug 22 04:28:58.587: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-runtime 08/22/23 04:28:58.587
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:28:58.614
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:28:58.617
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 08/22/23 04:28:58.62
STEP: wait for the container to reach Succeeded 08/22/23 04:28:58.627
STEP: get the container status 08/22/23 04:29:03.809
STEP: the container should be terminated 08/22/23 04:29:03.812
STEP: the termination message should be set 08/22/23 04:29:03.812
Aug 22 04:29:03.812: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 08/22/23 04:29:03.812
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 22 04:29:03.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1735" for this suite. 08/22/23 04:29:03.833
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":96,"skipped":1808,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.252 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:28:58.587
    Aug 22 04:28:58.587: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-runtime 08/22/23 04:28:58.587
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:28:58.614
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:28:58.617
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 08/22/23 04:28:58.62
    STEP: wait for the container to reach Succeeded 08/22/23 04:28:58.627
    STEP: get the container status 08/22/23 04:29:03.809
    STEP: the container should be terminated 08/22/23 04:29:03.812
    STEP: the termination message should be set 08/22/23 04:29:03.812
    Aug 22 04:29:03.812: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 08/22/23 04:29:03.812
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 22 04:29:03.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-1735" for this suite. 08/22/23 04:29:03.833
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:29:03.84
Aug 22 04:29:03.840: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 04:29:03.84
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:03.869
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:03.872
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210
STEP: creating an Endpoint 08/22/23 04:29:03.976
STEP: waiting for available Endpoint 08/22/23 04:29:03.981
STEP: listing all Endpoints 08/22/23 04:29:03.983
STEP: updating the Endpoint 08/22/23 04:29:03.986
STEP: fetching the Endpoint 08/22/23 04:29:03.993
STEP: patching the Endpoint 08/22/23 04:29:03.996
STEP: fetching the Endpoint 08/22/23 04:29:04.005
STEP: deleting the Endpoint by Collection 08/22/23 04:29:04.007
STEP: waiting for Endpoint deletion 08/22/23 04:29:04.013
STEP: fetching the Endpoint 08/22/23 04:29:04.015
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 04:29:04.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3459" for this suite. 08/22/23 04:29:04.02
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":97,"skipped":1814,"failed":0}
------------------------------
â€¢ [0.186 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:29:03.84
    Aug 22 04:29:03.840: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 04:29:03.84
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:03.869
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:03.872
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3210
    STEP: creating an Endpoint 08/22/23 04:29:03.976
    STEP: waiting for available Endpoint 08/22/23 04:29:03.981
    STEP: listing all Endpoints 08/22/23 04:29:03.983
    STEP: updating the Endpoint 08/22/23 04:29:03.986
    STEP: fetching the Endpoint 08/22/23 04:29:03.993
    STEP: patching the Endpoint 08/22/23 04:29:03.996
    STEP: fetching the Endpoint 08/22/23 04:29:04.005
    STEP: deleting the Endpoint by Collection 08/22/23 04:29:04.007
    STEP: waiting for Endpoint deletion 08/22/23 04:29:04.013
    STEP: fetching the Endpoint 08/22/23 04:29:04.015
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 04:29:04.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3459" for this suite. 08/22/23 04:29:04.02
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:29:04.028
Aug 22 04:29:04.028: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:29:04.028
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:04.248
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:04.253
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 08/22/23 04:29:04.26
Aug 22 04:29:04.270: INFO: Waiting up to 5m0s for pod "labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919" in namespace "projected-1860" to be "running and ready"
Aug 22 04:29:04.279: INFO: Pod "labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919": Phase="Pending", Reason="", readiness=false. Elapsed: 9.34322ms
Aug 22 04:29:04.279: INFO: The phase of Pod labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:29:06.283: INFO: Pod "labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013418483s
Aug 22 04:29:06.283: INFO: The phase of Pod labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:29:08.283: INFO: Pod "labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919": Phase="Running", Reason="", readiness=true. Elapsed: 4.013385701s
Aug 22 04:29:08.283: INFO: The phase of Pod labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919 is Running (Ready = true)
Aug 22 04:29:08.283: INFO: Pod "labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919" satisfied condition "running and ready"
Aug 22 04:29:08.885: INFO: Successfully updated pod "labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 22 04:29:10.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1860" for this suite. 08/22/23 04:29:10.915
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":98,"skipped":1843,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.950 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:29:04.028
    Aug 22 04:29:04.028: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:29:04.028
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:04.248
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:04.253
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 08/22/23 04:29:04.26
    Aug 22 04:29:04.270: INFO: Waiting up to 5m0s for pod "labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919" in namespace "projected-1860" to be "running and ready"
    Aug 22 04:29:04.279: INFO: Pod "labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919": Phase="Pending", Reason="", readiness=false. Elapsed: 9.34322ms
    Aug 22 04:29:04.279: INFO: The phase of Pod labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:29:06.283: INFO: Pod "labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013418483s
    Aug 22 04:29:06.283: INFO: The phase of Pod labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:29:08.283: INFO: Pod "labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919": Phase="Running", Reason="", readiness=true. Elapsed: 4.013385701s
    Aug 22 04:29:08.283: INFO: The phase of Pod labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919 is Running (Ready = true)
    Aug 22 04:29:08.283: INFO: Pod "labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919" satisfied condition "running and ready"
    Aug 22 04:29:08.885: INFO: Successfully updated pod "labelsupdate90deb39f-75ff-4d1f-bc28-3bb9ce4be919"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 22 04:29:10.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1860" for this suite. 08/22/23 04:29:10.915
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:29:10.977
Aug 22 04:29:10.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 04:29:10.978
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:11.172
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:11.177
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 08/22/23 04:29:11.183
Aug 22 04:29:11.192: INFO: Waiting up to 5m0s for pod "downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614" in namespace "downward-api-6077" to be "Succeeded or Failed"
Aug 22 04:29:11.197: INFO: Pod "downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614": Phase="Pending", Reason="", readiness=false. Elapsed: 5.110638ms
Aug 22 04:29:13.201: INFO: Pod "downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009585683s
Aug 22 04:29:15.201: INFO: Pod "downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009774405s
Aug 22 04:29:17.303: INFO: Pod "downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.111155513s
STEP: Saw pod success 08/22/23 04:29:17.303
Aug 22 04:29:17.303: INFO: Pod "downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614" satisfied condition "Succeeded or Failed"
Aug 22 04:29:17.307: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614 container client-container: <nil>
STEP: delete the pod 08/22/23 04:29:17.381
Aug 22 04:29:17.393: INFO: Waiting for pod downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614 to disappear
Aug 22 04:29:17.396: INFO: Pod downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 22 04:29:17.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6077" for this suite. 08/22/23 04:29:17.4
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":99,"skipped":1847,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.430 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:29:10.977
    Aug 22 04:29:10.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 04:29:10.978
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:11.172
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:11.177
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 08/22/23 04:29:11.183
    Aug 22 04:29:11.192: INFO: Waiting up to 5m0s for pod "downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614" in namespace "downward-api-6077" to be "Succeeded or Failed"
    Aug 22 04:29:11.197: INFO: Pod "downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614": Phase="Pending", Reason="", readiness=false. Elapsed: 5.110638ms
    Aug 22 04:29:13.201: INFO: Pod "downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009585683s
    Aug 22 04:29:15.201: INFO: Pod "downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009774405s
    Aug 22 04:29:17.303: INFO: Pod "downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.111155513s
    STEP: Saw pod success 08/22/23 04:29:17.303
    Aug 22 04:29:17.303: INFO: Pod "downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614" satisfied condition "Succeeded or Failed"
    Aug 22 04:29:17.307: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614 container client-container: <nil>
    STEP: delete the pod 08/22/23 04:29:17.381
    Aug 22 04:29:17.393: INFO: Waiting for pod downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614 to disappear
    Aug 22 04:29:17.396: INFO: Pod downwardapi-volume-70df865c-7e66-459f-9f0b-e62b068e0614 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 22 04:29:17.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6077" for this suite. 08/22/23 04:29:17.4
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:29:17.409
Aug 22 04:29:17.409: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 04:29:17.41
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:17.424
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:17.427
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-2e820c05-3748-408a-a628-66c55564213b 08/22/23 04:29:17.436
STEP: Creating the pod 08/22/23 04:29:17.441
Aug 22 04:29:17.450: INFO: Waiting up to 5m0s for pod "pod-configmaps-6605f945-5eab-4c8a-880a-029760c4cf96" in namespace "configmap-7129" to be "running"
Aug 22 04:29:17.454: INFO: Pod "pod-configmaps-6605f945-5eab-4c8a-880a-029760c4cf96": Phase="Pending", Reason="", readiness=false. Elapsed: 3.084737ms
Aug 22 04:29:19.459: INFO: Pod "pod-configmaps-6605f945-5eab-4c8a-880a-029760c4cf96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00776632s
Aug 22 04:29:21.458: INFO: Pod "pod-configmaps-6605f945-5eab-4c8a-880a-029760c4cf96": Phase="Running", Reason="", readiness=false. Elapsed: 4.007489067s
Aug 22 04:29:21.458: INFO: Pod "pod-configmaps-6605f945-5eab-4c8a-880a-029760c4cf96" satisfied condition "running"
STEP: Waiting for pod with text data 08/22/23 04:29:21.458
STEP: Waiting for pod with binary data 08/22/23 04:29:21.466
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 04:29:21.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7129" for this suite. 08/22/23 04:29:21.474
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":100,"skipped":1848,"failed":0}
------------------------------
â€¢ [4.071 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:29:17.409
    Aug 22 04:29:17.409: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 04:29:17.41
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:17.424
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:17.427
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-2e820c05-3748-408a-a628-66c55564213b 08/22/23 04:29:17.436
    STEP: Creating the pod 08/22/23 04:29:17.441
    Aug 22 04:29:17.450: INFO: Waiting up to 5m0s for pod "pod-configmaps-6605f945-5eab-4c8a-880a-029760c4cf96" in namespace "configmap-7129" to be "running"
    Aug 22 04:29:17.454: INFO: Pod "pod-configmaps-6605f945-5eab-4c8a-880a-029760c4cf96": Phase="Pending", Reason="", readiness=false. Elapsed: 3.084737ms
    Aug 22 04:29:19.459: INFO: Pod "pod-configmaps-6605f945-5eab-4c8a-880a-029760c4cf96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00776632s
    Aug 22 04:29:21.458: INFO: Pod "pod-configmaps-6605f945-5eab-4c8a-880a-029760c4cf96": Phase="Running", Reason="", readiness=false. Elapsed: 4.007489067s
    Aug 22 04:29:21.458: INFO: Pod "pod-configmaps-6605f945-5eab-4c8a-880a-029760c4cf96" satisfied condition "running"
    STEP: Waiting for pod with text data 08/22/23 04:29:21.458
    STEP: Waiting for pod with binary data 08/22/23 04:29:21.466
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 04:29:21.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7129" for this suite. 08/22/23 04:29:21.474
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:29:21.482
Aug 22 04:29:21.482: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:29:21.483
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:21.74
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:21.745
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-fa66b0e6-c25f-49c0-888d-deb98a066f75 08/22/23 04:29:21.748
STEP: Creating a pod to test consume configMaps 08/22/23 04:29:21.752
Aug 22 04:29:21.760: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d" in namespace "projected-7035" to be "Succeeded or Failed"
Aug 22 04:29:21.763: INFO: Pod "pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.719933ms
Aug 22 04:29:23.766: INFO: Pod "pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006220017s
Aug 22 04:29:25.768: INFO: Pod "pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008041254s
Aug 22 04:29:27.766: INFO: Pod "pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00572679s
STEP: Saw pod success 08/22/23 04:29:27.766
Aug 22 04:29:27.766: INFO: Pod "pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d" satisfied condition "Succeeded or Failed"
Aug 22 04:29:27.768: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d container agnhost-container: <nil>
STEP: delete the pod 08/22/23 04:29:27.775
Aug 22 04:29:27.903: INFO: Waiting for pod pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d to disappear
Aug 22 04:29:27.906: INFO: Pod pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 22 04:29:27.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7035" for this suite. 08/22/23 04:29:27.91
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":101,"skipped":1863,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.442 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:29:21.482
    Aug 22 04:29:21.482: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:29:21.483
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:21.74
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:21.745
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-fa66b0e6-c25f-49c0-888d-deb98a066f75 08/22/23 04:29:21.748
    STEP: Creating a pod to test consume configMaps 08/22/23 04:29:21.752
    Aug 22 04:29:21.760: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d" in namespace "projected-7035" to be "Succeeded or Failed"
    Aug 22 04:29:21.763: INFO: Pod "pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.719933ms
    Aug 22 04:29:23.766: INFO: Pod "pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006220017s
    Aug 22 04:29:25.768: INFO: Pod "pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008041254s
    Aug 22 04:29:27.766: INFO: Pod "pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00572679s
    STEP: Saw pod success 08/22/23 04:29:27.766
    Aug 22 04:29:27.766: INFO: Pod "pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d" satisfied condition "Succeeded or Failed"
    Aug 22 04:29:27.768: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 04:29:27.775
    Aug 22 04:29:27.903: INFO: Waiting for pod pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d to disappear
    Aug 22 04:29:27.906: INFO: Pod pod-projected-configmaps-8a1ac930-c610-4081-8570-0a664861651d no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 22 04:29:27.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7035" for this suite. 08/22/23 04:29:27.91
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:29:27.924
Aug 22 04:29:27.924: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename dns 08/22/23 04:29:27.925
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:27.939
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:27.942
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 08/22/23 04:29:27.946
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7487.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7487.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7487.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7487.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 144.145.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.145.144_udp@PTR;check="$$(dig +tcp +noall +answer +search 144.145.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.145.144_tcp@PTR;sleep 1; done
 08/22/23 04:29:27.969
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7487.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7487.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7487.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7487.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 144.145.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.145.144_udp@PTR;check="$$(dig +tcp +noall +answer +search 144.145.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.145.144_tcp@PTR;sleep 1; done
 08/22/23 04:29:27.969
STEP: creating a pod to probe DNS 08/22/23 04:29:27.97
STEP: submitting the pod to kubernetes 08/22/23 04:29:27.97
Aug 22 04:29:27.991: INFO: Waiting up to 15m0s for pod "dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b" in namespace "dns-7487" to be "running"
Aug 22 04:29:27.995: INFO: Pod "dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.423459ms
Aug 22 04:29:30.081: INFO: Pod "dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090458156s
Aug 22 04:29:32.053: INFO: Pod "dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b": Phase="Running", Reason="", readiness=true. Elapsed: 4.062015785s
Aug 22 04:29:32.053: INFO: Pod "dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b" satisfied condition "running"
STEP: retrieving the pod 08/22/23 04:29:32.053
STEP: looking for the results for each expected name from probers 08/22/23 04:29:32.057
Aug 22 04:29:32.065: INFO: Unable to read wheezy_udp@dns-test-service.dns-7487.svc.cluster.local from pod dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b: the server could not find the requested resource (get pods dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b)
Aug 22 04:29:32.067: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7487.svc.cluster.local from pod dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b: the server could not find the requested resource (get pods dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b)
Aug 22 04:29:32.069: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local from pod dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b: the server could not find the requested resource (get pods dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b)
Aug 22 04:29:32.071: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local from pod dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b: the server could not find the requested resource (get pods dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b)
Aug 22 04:29:32.094: INFO: Unable to read jessie_udp@dns-test-service.dns-7487.svc.cluster.local from pod dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b: the server could not find the requested resource (get pods dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b)
Aug 22 04:29:32.096: INFO: Unable to read jessie_tcp@dns-test-service.dns-7487.svc.cluster.local from pod dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b: the server could not find the requested resource (get pods dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b)
Aug 22 04:29:32.109: INFO: Lookups using dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b failed for: [wheezy_udp@dns-test-service.dns-7487.svc.cluster.local wheezy_tcp@dns-test-service.dns-7487.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local jessie_udp@dns-test-service.dns-7487.svc.cluster.local jessie_tcp@dns-test-service.dns-7487.svc.cluster.local]

Aug 22 04:29:37.144: INFO: DNS probes using dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b succeeded

STEP: deleting the pod 08/22/23 04:29:37.144
STEP: deleting the test service 08/22/23 04:29:37.437
STEP: deleting the test headless service 08/22/23 04:29:37.682
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 22 04:29:37.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7487" for this suite. 08/22/23 04:29:37.706
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":102,"skipped":1876,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.790 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:29:27.924
    Aug 22 04:29:27.924: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename dns 08/22/23 04:29:27.925
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:27.939
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:27.942
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 08/22/23 04:29:27.946
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7487.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7487.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7487.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7487.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 144.145.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.145.144_udp@PTR;check="$$(dig +tcp +noall +answer +search 144.145.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.145.144_tcp@PTR;sleep 1; done
     08/22/23 04:29:27.969
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7487.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7487.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7487.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7487.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7487.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 144.145.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.145.144_udp@PTR;check="$$(dig +tcp +noall +answer +search 144.145.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.145.144_tcp@PTR;sleep 1; done
     08/22/23 04:29:27.969
    STEP: creating a pod to probe DNS 08/22/23 04:29:27.97
    STEP: submitting the pod to kubernetes 08/22/23 04:29:27.97
    Aug 22 04:29:27.991: INFO: Waiting up to 15m0s for pod "dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b" in namespace "dns-7487" to be "running"
    Aug 22 04:29:27.995: INFO: Pod "dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.423459ms
    Aug 22 04:29:30.081: INFO: Pod "dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090458156s
    Aug 22 04:29:32.053: INFO: Pod "dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b": Phase="Running", Reason="", readiness=true. Elapsed: 4.062015785s
    Aug 22 04:29:32.053: INFO: Pod "dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b" satisfied condition "running"
    STEP: retrieving the pod 08/22/23 04:29:32.053
    STEP: looking for the results for each expected name from probers 08/22/23 04:29:32.057
    Aug 22 04:29:32.065: INFO: Unable to read wheezy_udp@dns-test-service.dns-7487.svc.cluster.local from pod dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b: the server could not find the requested resource (get pods dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b)
    Aug 22 04:29:32.067: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7487.svc.cluster.local from pod dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b: the server could not find the requested resource (get pods dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b)
    Aug 22 04:29:32.069: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local from pod dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b: the server could not find the requested resource (get pods dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b)
    Aug 22 04:29:32.071: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local from pod dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b: the server could not find the requested resource (get pods dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b)
    Aug 22 04:29:32.094: INFO: Unable to read jessie_udp@dns-test-service.dns-7487.svc.cluster.local from pod dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b: the server could not find the requested resource (get pods dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b)
    Aug 22 04:29:32.096: INFO: Unable to read jessie_tcp@dns-test-service.dns-7487.svc.cluster.local from pod dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b: the server could not find the requested resource (get pods dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b)
    Aug 22 04:29:32.109: INFO: Lookups using dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b failed for: [wheezy_udp@dns-test-service.dns-7487.svc.cluster.local wheezy_tcp@dns-test-service.dns-7487.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7487.svc.cluster.local jessie_udp@dns-test-service.dns-7487.svc.cluster.local jessie_tcp@dns-test-service.dns-7487.svc.cluster.local]

    Aug 22 04:29:37.144: INFO: DNS probes using dns-7487/dns-test-49d19427-6a83-4687-91f8-eaefb3e6895b succeeded

    STEP: deleting the pod 08/22/23 04:29:37.144
    STEP: deleting the test service 08/22/23 04:29:37.437
    STEP: deleting the test headless service 08/22/23 04:29:37.682
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 22 04:29:37.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7487" for this suite. 08/22/23 04:29:37.706
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:29:37.715
Aug 22 04:29:37.716: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename secrets 08/22/23 04:29:37.716
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:37.734
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:37.736
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-8e760106-ff34-4b97-b8ca-4b0c18eddac2 08/22/23 04:29:37.741
STEP: Creating a pod to test consume secrets 08/22/23 04:29:37.747
Aug 22 04:29:37.758: INFO: Waiting up to 5m0s for pod "pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff" in namespace "secrets-5723" to be "Succeeded or Failed"
Aug 22 04:29:37.765: INFO: Pod "pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff": Phase="Pending", Reason="", readiness=false. Elapsed: 6.896729ms
Aug 22 04:29:39.768: INFO: Pod "pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009853095s
Aug 22 04:29:41.769: INFO: Pod "pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011112906s
Aug 22 04:29:43.770: INFO: Pod "pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011624244s
STEP: Saw pod success 08/22/23 04:29:43.77
Aug 22 04:29:43.770: INFO: Pod "pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff" satisfied condition "Succeeded or Failed"
Aug 22 04:29:43.772: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff container secret-volume-test: <nil>
STEP: delete the pod 08/22/23 04:29:43.781
Aug 22 04:29:43.805: INFO: Waiting for pod pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff to disappear
Aug 22 04:29:43.811: INFO: Pod pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 22 04:29:43.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5723" for this suite. 08/22/23 04:29:43.816
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":103,"skipped":1891,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.108 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:29:37.715
    Aug 22 04:29:37.716: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename secrets 08/22/23 04:29:37.716
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:37.734
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:37.736
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-8e760106-ff34-4b97-b8ca-4b0c18eddac2 08/22/23 04:29:37.741
    STEP: Creating a pod to test consume secrets 08/22/23 04:29:37.747
    Aug 22 04:29:37.758: INFO: Waiting up to 5m0s for pod "pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff" in namespace "secrets-5723" to be "Succeeded or Failed"
    Aug 22 04:29:37.765: INFO: Pod "pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff": Phase="Pending", Reason="", readiness=false. Elapsed: 6.896729ms
    Aug 22 04:29:39.768: INFO: Pod "pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009853095s
    Aug 22 04:29:41.769: INFO: Pod "pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011112906s
    Aug 22 04:29:43.770: INFO: Pod "pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011624244s
    STEP: Saw pod success 08/22/23 04:29:43.77
    Aug 22 04:29:43.770: INFO: Pod "pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff" satisfied condition "Succeeded or Failed"
    Aug 22 04:29:43.772: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff container secret-volume-test: <nil>
    STEP: delete the pod 08/22/23 04:29:43.781
    Aug 22 04:29:43.805: INFO: Waiting for pod pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff to disappear
    Aug 22 04:29:43.811: INFO: Pod pod-secrets-a1366d37-d7bf-42cc-88ed-26b376f918ff no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 22 04:29:43.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5723" for this suite. 08/22/23 04:29:43.816
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:29:43.824
Aug 22 04:29:43.824: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:29:43.825
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:43.859
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:43.861
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 08/22/23 04:29:43.867
Aug 22 04:29:43.887: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57" in namespace "projected-5057" to be "Succeeded or Failed"
Aug 22 04:29:43.895: INFO: Pod "downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57": Phase="Pending", Reason="", readiness=false. Elapsed: 7.822415ms
Aug 22 04:29:45.900: INFO: Pod "downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012504679s
Aug 22 04:29:47.901: INFO: Pod "downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013523228s
Aug 22 04:29:49.900: INFO: Pod "downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012483777s
STEP: Saw pod success 08/22/23 04:29:49.9
Aug 22 04:29:49.900: INFO: Pod "downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57" satisfied condition "Succeeded or Failed"
Aug 22 04:29:49.903: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57 container client-container: <nil>
STEP: delete the pod 08/22/23 04:29:49.908
Aug 22 04:29:49.960: INFO: Waiting for pod downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57 to disappear
Aug 22 04:29:49.963: INFO: Pod downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 22 04:29:49.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5057" for this suite. 08/22/23 04:29:49.967
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":104,"skipped":1895,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.149 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:29:43.824
    Aug 22 04:29:43.824: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:29:43.825
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:43.859
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:43.861
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 08/22/23 04:29:43.867
    Aug 22 04:29:43.887: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57" in namespace "projected-5057" to be "Succeeded or Failed"
    Aug 22 04:29:43.895: INFO: Pod "downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57": Phase="Pending", Reason="", readiness=false. Elapsed: 7.822415ms
    Aug 22 04:29:45.900: INFO: Pod "downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012504679s
    Aug 22 04:29:47.901: INFO: Pod "downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013523228s
    Aug 22 04:29:49.900: INFO: Pod "downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012483777s
    STEP: Saw pod success 08/22/23 04:29:49.9
    Aug 22 04:29:49.900: INFO: Pod "downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57" satisfied condition "Succeeded or Failed"
    Aug 22 04:29:49.903: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57 container client-container: <nil>
    STEP: delete the pod 08/22/23 04:29:49.908
    Aug 22 04:29:49.960: INFO: Waiting for pod downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57 to disappear
    Aug 22 04:29:49.963: INFO: Pod downwardapi-volume-e8afa514-015d-4328-9816-15f0153dec57 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 22 04:29:49.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5057" for this suite. 08/22/23 04:29:49.967
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:29:49.975
Aug 22 04:29:49.975: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename replication-controller 08/22/23 04:29:49.975
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:50.107
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:50.11
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 08/22/23 04:29:50.117
STEP: waiting for RC to be added 08/22/23 04:29:50.122
STEP: waiting for available Replicas 08/22/23 04:29:50.123
STEP: patching ReplicationController 08/22/23 04:29:59.241
STEP: waiting for RC to be modified 08/22/23 04:29:59.25
STEP: patching ReplicationController status 08/22/23 04:29:59.25
STEP: waiting for RC to be modified 08/22/23 04:29:59.255
STEP: waiting for available Replicas 08/22/23 04:29:59.255
STEP: fetching ReplicationController status 08/22/23 04:29:59.261
STEP: patching ReplicationController scale 08/22/23 04:29:59.264
STEP: waiting for RC to be modified 08/22/23 04:29:59.273
STEP: waiting for ReplicationController's scale to be the max amount 08/22/23 04:29:59.273
STEP: fetching ReplicationController; ensuring that it's patched 08/22/23 04:30:06.921
STEP: updating ReplicationController status 08/22/23 04:30:06.924
STEP: waiting for RC to be modified 08/22/23 04:30:06.929
STEP: listing all ReplicationControllers 08/22/23 04:30:06.929
STEP: checking that ReplicationController has expected values 08/22/23 04:30:06.943
STEP: deleting ReplicationControllers by collection 08/22/23 04:30:06.943
STEP: waiting for ReplicationController to have a DELETED watchEvent 08/22/23 04:30:06.95
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 22 04:30:07.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1210" for this suite. 08/22/23 04:30:07.022
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":105,"skipped":1913,"failed":0}
------------------------------
â€¢ [SLOW TEST] [17.052 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:29:49.975
    Aug 22 04:29:49.975: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename replication-controller 08/22/23 04:29:49.975
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:29:50.107
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:29:50.11
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 08/22/23 04:29:50.117
    STEP: waiting for RC to be added 08/22/23 04:29:50.122
    STEP: waiting for available Replicas 08/22/23 04:29:50.123
    STEP: patching ReplicationController 08/22/23 04:29:59.241
    STEP: waiting for RC to be modified 08/22/23 04:29:59.25
    STEP: patching ReplicationController status 08/22/23 04:29:59.25
    STEP: waiting for RC to be modified 08/22/23 04:29:59.255
    STEP: waiting for available Replicas 08/22/23 04:29:59.255
    STEP: fetching ReplicationController status 08/22/23 04:29:59.261
    STEP: patching ReplicationController scale 08/22/23 04:29:59.264
    STEP: waiting for RC to be modified 08/22/23 04:29:59.273
    STEP: waiting for ReplicationController's scale to be the max amount 08/22/23 04:29:59.273
    STEP: fetching ReplicationController; ensuring that it's patched 08/22/23 04:30:06.921
    STEP: updating ReplicationController status 08/22/23 04:30:06.924
    STEP: waiting for RC to be modified 08/22/23 04:30:06.929
    STEP: listing all ReplicationControllers 08/22/23 04:30:06.929
    STEP: checking that ReplicationController has expected values 08/22/23 04:30:06.943
    STEP: deleting ReplicationControllers by collection 08/22/23 04:30:06.943
    STEP: waiting for ReplicationController to have a DELETED watchEvent 08/22/23 04:30:06.95
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 22 04:30:07.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1210" for this suite. 08/22/23 04:30:07.022
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:30:07.027
Aug 22 04:30:07.027: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename replicaset 08/22/23 04:30:07.028
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:30:07.043
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:30:07.046
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 08/22/23 04:30:07.048
Aug 22 04:30:07.064: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 22 04:30:12.071: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/22/23 04:30:12.071
STEP: getting scale subresource 08/22/23 04:30:12.071
STEP: updating a scale subresource 08/22/23 04:30:12.075
STEP: verifying the replicaset Spec.Replicas was modified 08/22/23 04:30:12.084
STEP: Patch a scale subresource 08/22/23 04:30:12.091
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 22 04:30:12.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5435" for this suite. 08/22/23 04:30:12.138
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":106,"skipped":1915,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.121 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:30:07.027
    Aug 22 04:30:07.027: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename replicaset 08/22/23 04:30:07.028
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:30:07.043
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:30:07.046
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 08/22/23 04:30:07.048
    Aug 22 04:30:07.064: INFO: Pod name sample-pod: Found 0 pods out of 1
    Aug 22 04:30:12.071: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/22/23 04:30:12.071
    STEP: getting scale subresource 08/22/23 04:30:12.071
    STEP: updating a scale subresource 08/22/23 04:30:12.075
    STEP: verifying the replicaset Spec.Replicas was modified 08/22/23 04:30:12.084
    STEP: Patch a scale subresource 08/22/23 04:30:12.091
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 22 04:30:12.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-5435" for this suite. 08/22/23 04:30:12.138
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:30:12.149
Aug 22 04:30:12.149: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename dns 08/22/23 04:30:12.15
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:30:12.34
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:30:12.347
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 08/22/23 04:30:12.35
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-722.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-722.svc.cluster.local;sleep 1; done
 08/22/23 04:30:12.374
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-722.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-722.svc.cluster.local;sleep 1; done
 08/22/23 04:30:12.374
STEP: creating a pod to probe DNS 08/22/23 04:30:12.375
STEP: submitting the pod to kubernetes 08/22/23 04:30:12.375
Aug 22 04:30:12.501: INFO: Waiting up to 15m0s for pod "dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324" in namespace "dns-722" to be "running"
Aug 22 04:30:12.507: INFO: Pod "dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324": Phase="Pending", Reason="", readiness=false. Elapsed: 6.474196ms
Aug 22 04:30:14.512: INFO: Pod "dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011570326s
Aug 22 04:30:16.772: INFO: Pod "dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324": Phase="Running", Reason="", readiness=true. Elapsed: 4.271459536s
Aug 22 04:30:16.772: INFO: Pod "dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324" satisfied condition "running"
STEP: retrieving the pod 08/22/23 04:30:16.772
STEP: looking for the results for each expected name from probers 08/22/23 04:30:16.776
Aug 22 04:30:16.782: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
Aug 22 04:30:16.786: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
Aug 22 04:30:16.789: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
Aug 22 04:30:16.791: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
Aug 22 04:30:16.794: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
Aug 22 04:30:16.796: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
Aug 22 04:30:16.798: INFO: Unable to read jessie_udp@dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
Aug 22 04:30:16.801: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
Aug 22 04:30:16.801: INFO: Lookups using dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local wheezy_udp@dns-test-service-2.dns-722.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-722.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local jessie_udp@dns-test-service-2.dns-722.svc.cluster.local jessie_tcp@dns-test-service-2.dns-722.svc.cluster.local]

Aug 22 04:30:21.820: INFO: DNS probes using dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324 succeeded

STEP: deleting the pod 08/22/23 04:30:21.82
STEP: deleting the test headless service 08/22/23 04:30:21.856
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 22 04:30:21.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-722" for this suite. 08/22/23 04:30:21.878
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":107,"skipped":1922,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.734 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:30:12.149
    Aug 22 04:30:12.149: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename dns 08/22/23 04:30:12.15
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:30:12.34
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:30:12.347
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 08/22/23 04:30:12.35
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-722.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-722.svc.cluster.local;sleep 1; done
     08/22/23 04:30:12.374
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-722.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-722.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-722.svc.cluster.local;sleep 1; done
     08/22/23 04:30:12.374
    STEP: creating a pod to probe DNS 08/22/23 04:30:12.375
    STEP: submitting the pod to kubernetes 08/22/23 04:30:12.375
    Aug 22 04:30:12.501: INFO: Waiting up to 15m0s for pod "dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324" in namespace "dns-722" to be "running"
    Aug 22 04:30:12.507: INFO: Pod "dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324": Phase="Pending", Reason="", readiness=false. Elapsed: 6.474196ms
    Aug 22 04:30:14.512: INFO: Pod "dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011570326s
    Aug 22 04:30:16.772: INFO: Pod "dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324": Phase="Running", Reason="", readiness=true. Elapsed: 4.271459536s
    Aug 22 04:30:16.772: INFO: Pod "dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324" satisfied condition "running"
    STEP: retrieving the pod 08/22/23 04:30:16.772
    STEP: looking for the results for each expected name from probers 08/22/23 04:30:16.776
    Aug 22 04:30:16.782: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
    Aug 22 04:30:16.786: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
    Aug 22 04:30:16.789: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
    Aug 22 04:30:16.791: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
    Aug 22 04:30:16.794: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
    Aug 22 04:30:16.796: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
    Aug 22 04:30:16.798: INFO: Unable to read jessie_udp@dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
    Aug 22 04:30:16.801: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-722.svc.cluster.local from pod dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324: the server could not find the requested resource (get pods dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324)
    Aug 22 04:30:16.801: INFO: Lookups using dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local wheezy_udp@dns-test-service-2.dns-722.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-722.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-722.svc.cluster.local jessie_udp@dns-test-service-2.dns-722.svc.cluster.local jessie_tcp@dns-test-service-2.dns-722.svc.cluster.local]

    Aug 22 04:30:21.820: INFO: DNS probes using dns-722/dns-test-a2b642ba-5d1b-40e5-b764-9a8eff958324 succeeded

    STEP: deleting the pod 08/22/23 04:30:21.82
    STEP: deleting the test headless service 08/22/23 04:30:21.856
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 22 04:30:21.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-722" for this suite. 08/22/23 04:30:21.878
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:30:21.884
Aug 22 04:30:21.885: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename replicaset 08/22/23 04:30:21.885
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:30:21.896
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:30:21.899
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Aug 22 04:30:21.959: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 22 04:30:26.971: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/22/23 04:30:26.971
STEP: Scaling up "test-rs" replicaset  08/22/23 04:30:26.971
Aug 22 04:30:26.991: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 08/22/23 04:30:26.991
W0822 04:30:27.021051      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Aug 22 04:30:27.025: INFO: observed ReplicaSet test-rs in namespace replicaset-2608 with ReadyReplicas 1, AvailableReplicas 1
Aug 22 04:30:27.035: INFO: observed ReplicaSet test-rs in namespace replicaset-2608 with ReadyReplicas 1, AvailableReplicas 1
Aug 22 04:30:27.082: INFO: observed ReplicaSet test-rs in namespace replicaset-2608 with ReadyReplicas 1, AvailableReplicas 1
Aug 22 04:30:27.090: INFO: observed ReplicaSet test-rs in namespace replicaset-2608 with ReadyReplicas 1, AvailableReplicas 1
Aug 22 04:30:29.986: INFO: observed ReplicaSet test-rs in namespace replicaset-2608 with ReadyReplicas 2, AvailableReplicas 2
Aug 22 04:30:30.324: INFO: observed Replicaset test-rs in namespace replicaset-2608 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 22 04:30:30.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2608" for this suite. 08/22/23 04:30:30.328
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":108,"skipped":1923,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.449 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:30:21.884
    Aug 22 04:30:21.885: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename replicaset 08/22/23 04:30:21.885
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:30:21.896
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:30:21.899
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Aug 22 04:30:21.959: INFO: Pod name sample-pod: Found 0 pods out of 1
    Aug 22 04:30:26.971: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/22/23 04:30:26.971
    STEP: Scaling up "test-rs" replicaset  08/22/23 04:30:26.971
    Aug 22 04:30:26.991: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 08/22/23 04:30:26.991
    W0822 04:30:27.021051      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Aug 22 04:30:27.025: INFO: observed ReplicaSet test-rs in namespace replicaset-2608 with ReadyReplicas 1, AvailableReplicas 1
    Aug 22 04:30:27.035: INFO: observed ReplicaSet test-rs in namespace replicaset-2608 with ReadyReplicas 1, AvailableReplicas 1
    Aug 22 04:30:27.082: INFO: observed ReplicaSet test-rs in namespace replicaset-2608 with ReadyReplicas 1, AvailableReplicas 1
    Aug 22 04:30:27.090: INFO: observed ReplicaSet test-rs in namespace replicaset-2608 with ReadyReplicas 1, AvailableReplicas 1
    Aug 22 04:30:29.986: INFO: observed ReplicaSet test-rs in namespace replicaset-2608 with ReadyReplicas 2, AvailableReplicas 2
    Aug 22 04:30:30.324: INFO: observed Replicaset test-rs in namespace replicaset-2608 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 22 04:30:30.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2608" for this suite. 08/22/23 04:30:30.328
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:30:30.336
Aug 22 04:30:30.336: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename cronjob 08/22/23 04:30:30.337
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:30:30.354
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:30:30.356
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 08/22/23 04:30:30.359
STEP: Ensuring a job is scheduled 08/22/23 04:30:30.366
STEP: Ensuring exactly one is scheduled 08/22/23 04:31:00.371
STEP: Ensuring exactly one running job exists by listing jobs explicitly 08/22/23 04:31:00.373
STEP: Ensuring the job is replaced with a new one 08/22/23 04:31:00.376
STEP: Removing cronjob 08/22/23 04:32:00.379
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 22 04:32:00.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2012" for this suite. 08/22/23 04:32:00.394
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":109,"skipped":1943,"failed":0}
------------------------------
â€¢ [SLOW TEST] [90.072 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:30:30.336
    Aug 22 04:30:30.336: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename cronjob 08/22/23 04:30:30.337
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:30:30.354
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:30:30.356
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 08/22/23 04:30:30.359
    STEP: Ensuring a job is scheduled 08/22/23 04:30:30.366
    STEP: Ensuring exactly one is scheduled 08/22/23 04:31:00.371
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 08/22/23 04:31:00.373
    STEP: Ensuring the job is replaced with a new one 08/22/23 04:31:00.376
    STEP: Removing cronjob 08/22/23 04:32:00.379
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 22 04:32:00.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2012" for this suite. 08/22/23 04:32:00.394
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:32:00.408
Aug 22 04:32:00.408: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 04:32:00.409
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:32:00.424
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:32:00.428
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5241 08/22/23 04:32:00.431
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 08/22/23 04:32:00.442
STEP: creating service externalsvc in namespace services-5241 08/22/23 04:32:00.442
STEP: creating replication controller externalsvc in namespace services-5241 08/22/23 04:32:00.462
I0822 04:32:00.472543      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-5241, replica count: 2
I0822 04:32:03.523277      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 04:32:06.524145      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 08/22/23 04:32:06.528
Aug 22 04:32:06.718: INFO: Creating new exec pod
Aug 22 04:32:06.860: INFO: Waiting up to 5m0s for pod "execpodgcmcc" in namespace "services-5241" to be "running"
Aug 22 04:32:06.867: INFO: Pod "execpodgcmcc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.559457ms
Aug 22 04:32:08.870: INFO: Pod "execpodgcmcc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010330291s
Aug 22 04:32:10.871: INFO: Pod "execpodgcmcc": Phase="Running", Reason="", readiness=true. Elapsed: 4.011171769s
Aug 22 04:32:10.871: INFO: Pod "execpodgcmcc" satisfied condition "running"
Aug 22 04:32:10.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-5241 exec execpodgcmcc -- /bin/sh -x -c nslookup clusterip-service.services-5241.svc.cluster.local'
Aug 22 04:32:11.050: INFO: stderr: "+ nslookup clusterip-service.services-5241.svc.cluster.local\n"
Aug 22 04:32:11.050: INFO: stdout: "Server:\t\t10.254.0.10\nAddress:\t10.254.0.10#53\n\nclusterip-service.services-5241.svc.cluster.local\tcanonical name = externalsvc.services-5241.svc.cluster.local.\nName:\texternalsvc.services-5241.svc.cluster.local\nAddress: 10.254.38.128\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5241, will wait for the garbage collector to delete the pods 08/22/23 04:32:11.05
Aug 22 04:32:11.113: INFO: Deleting ReplicationController externalsvc took: 8.16021ms
Aug 22 04:32:11.614: INFO: Terminating ReplicationController externalsvc pods took: 500.264345ms
Aug 22 04:32:14.634: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 04:32:14.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5241" for this suite. 08/22/23 04:32:14.657
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":110,"skipped":1957,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.258 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:32:00.408
    Aug 22 04:32:00.408: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 04:32:00.409
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:32:00.424
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:32:00.428
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5241 08/22/23 04:32:00.431
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 08/22/23 04:32:00.442
    STEP: creating service externalsvc in namespace services-5241 08/22/23 04:32:00.442
    STEP: creating replication controller externalsvc in namespace services-5241 08/22/23 04:32:00.462
    I0822 04:32:00.472543      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-5241, replica count: 2
    I0822 04:32:03.523277      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0822 04:32:06.524145      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 08/22/23 04:32:06.528
    Aug 22 04:32:06.718: INFO: Creating new exec pod
    Aug 22 04:32:06.860: INFO: Waiting up to 5m0s for pod "execpodgcmcc" in namespace "services-5241" to be "running"
    Aug 22 04:32:06.867: INFO: Pod "execpodgcmcc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.559457ms
    Aug 22 04:32:08.870: INFO: Pod "execpodgcmcc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010330291s
    Aug 22 04:32:10.871: INFO: Pod "execpodgcmcc": Phase="Running", Reason="", readiness=true. Elapsed: 4.011171769s
    Aug 22 04:32:10.871: INFO: Pod "execpodgcmcc" satisfied condition "running"
    Aug 22 04:32:10.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-5241 exec execpodgcmcc -- /bin/sh -x -c nslookup clusterip-service.services-5241.svc.cluster.local'
    Aug 22 04:32:11.050: INFO: stderr: "+ nslookup clusterip-service.services-5241.svc.cluster.local\n"
    Aug 22 04:32:11.050: INFO: stdout: "Server:\t\t10.254.0.10\nAddress:\t10.254.0.10#53\n\nclusterip-service.services-5241.svc.cluster.local\tcanonical name = externalsvc.services-5241.svc.cluster.local.\nName:\texternalsvc.services-5241.svc.cluster.local\nAddress: 10.254.38.128\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-5241, will wait for the garbage collector to delete the pods 08/22/23 04:32:11.05
    Aug 22 04:32:11.113: INFO: Deleting ReplicationController externalsvc took: 8.16021ms
    Aug 22 04:32:11.614: INFO: Terminating ReplicationController externalsvc pods took: 500.264345ms
    Aug 22 04:32:14.634: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 04:32:14.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5241" for this suite. 08/22/23 04:32:14.657
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:32:14.666
Aug 22 04:32:14.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename gc 08/22/23 04:32:14.666
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:32:14.686
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:32:14.689
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 08/22/23 04:32:14.693
STEP: Wait for the Deployment to create new ReplicaSet 08/22/23 04:32:14.699
STEP: delete the deployment 08/22/23 04:32:15.208
STEP: wait for all rs to be garbage collected 08/22/23 04:32:15.215
STEP: expected 0 rs, got 1 rs 08/22/23 04:32:15.225
STEP: expected 0 pods, got 2 pods 08/22/23 04:32:15.231
STEP: Gathering metrics 08/22/23 04:32:15.741
W0822 04:32:15.752729      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Aug 22 04:32:15.752: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 22 04:32:15.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8775" for this suite. 08/22/23 04:32:15.756
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":111,"skipped":1957,"failed":0}
------------------------------
â€¢ [1.098 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:32:14.666
    Aug 22 04:32:14.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename gc 08/22/23 04:32:14.666
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:32:14.686
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:32:14.689
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 08/22/23 04:32:14.693
    STEP: Wait for the Deployment to create new ReplicaSet 08/22/23 04:32:14.699
    STEP: delete the deployment 08/22/23 04:32:15.208
    STEP: wait for all rs to be garbage collected 08/22/23 04:32:15.215
    STEP: expected 0 rs, got 1 rs 08/22/23 04:32:15.225
    STEP: expected 0 pods, got 2 pods 08/22/23 04:32:15.231
    STEP: Gathering metrics 08/22/23 04:32:15.741
    W0822 04:32:15.752729      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Aug 22 04:32:15.752: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 22 04:32:15.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-8775" for this suite. 08/22/23 04:32:15.756
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:32:15.766
Aug 22 04:32:15.766: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 04:32:15.767
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:32:15.783
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:32:15.786
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 08/22/23 04:32:15.791
Aug 22 04:32:15.801: INFO: Waiting up to 5m0s for pod "pod-4a638916-e2a7-455d-85c8-60fe47f898f2" in namespace "emptydir-8328" to be "Succeeded or Failed"
Aug 22 04:32:15.807: INFO: Pod "pod-4a638916-e2a7-455d-85c8-60fe47f898f2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.381606ms
Aug 22 04:32:17.814: INFO: Pod "pod-4a638916-e2a7-455d-85c8-60fe47f898f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01281495s
Aug 22 04:32:19.833: INFO: Pod "pod-4a638916-e2a7-455d-85c8-60fe47f898f2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031782884s
Aug 22 04:32:21.810: INFO: Pod "pod-4a638916-e2a7-455d-85c8-60fe47f898f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009012435s
STEP: Saw pod success 08/22/23 04:32:21.81
Aug 22 04:32:21.810: INFO: Pod "pod-4a638916-e2a7-455d-85c8-60fe47f898f2" satisfied condition "Succeeded or Failed"
Aug 22 04:32:21.812: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod pod-4a638916-e2a7-455d-85c8-60fe47f898f2 container test-container: <nil>
STEP: delete the pod 08/22/23 04:32:21.846
Aug 22 04:32:21.855: INFO: Waiting for pod pod-4a638916-e2a7-455d-85c8-60fe47f898f2 to disappear
Aug 22 04:32:21.858: INFO: Pod pod-4a638916-e2a7-455d-85c8-60fe47f898f2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 04:32:21.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8328" for this suite. 08/22/23 04:32:21.861
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":112,"skipped":1993,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.100 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:32:15.766
    Aug 22 04:32:15.766: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 04:32:15.767
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:32:15.783
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:32:15.786
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 08/22/23 04:32:15.791
    Aug 22 04:32:15.801: INFO: Waiting up to 5m0s for pod "pod-4a638916-e2a7-455d-85c8-60fe47f898f2" in namespace "emptydir-8328" to be "Succeeded or Failed"
    Aug 22 04:32:15.807: INFO: Pod "pod-4a638916-e2a7-455d-85c8-60fe47f898f2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.381606ms
    Aug 22 04:32:17.814: INFO: Pod "pod-4a638916-e2a7-455d-85c8-60fe47f898f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01281495s
    Aug 22 04:32:19.833: INFO: Pod "pod-4a638916-e2a7-455d-85c8-60fe47f898f2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031782884s
    Aug 22 04:32:21.810: INFO: Pod "pod-4a638916-e2a7-455d-85c8-60fe47f898f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009012435s
    STEP: Saw pod success 08/22/23 04:32:21.81
    Aug 22 04:32:21.810: INFO: Pod "pod-4a638916-e2a7-455d-85c8-60fe47f898f2" satisfied condition "Succeeded or Failed"
    Aug 22 04:32:21.812: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod pod-4a638916-e2a7-455d-85c8-60fe47f898f2 container test-container: <nil>
    STEP: delete the pod 08/22/23 04:32:21.846
    Aug 22 04:32:21.855: INFO: Waiting for pod pod-4a638916-e2a7-455d-85c8-60fe47f898f2 to disappear
    Aug 22 04:32:21.858: INFO: Pod pod-4a638916-e2a7-455d-85c8-60fe47f898f2 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 04:32:21.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8328" for this suite. 08/22/23 04:32:21.861
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:32:21.868
Aug 22 04:32:21.868: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:32:21.869
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:32:21.88
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:32:21.883
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-92987745-ac2c-4ddc-8f55-df0ee079ff55 08/22/23 04:32:21.887
STEP: Creating a pod to test consume configMaps 08/22/23 04:32:21.892
Aug 22 04:32:21.900: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed" in namespace "projected-3211" to be "Succeeded or Failed"
Aug 22 04:32:21.902: INFO: Pod "pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.390044ms
Aug 22 04:32:23.906: INFO: Pod "pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00589082s
Aug 22 04:32:25.907: INFO: Pod "pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed": Phase="Running", Reason="", readiness=true. Elapsed: 4.00658905s
Aug 22 04:32:27.907: INFO: Pod "pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed": Phase="Running", Reason="", readiness=false. Elapsed: 6.007121096s
Aug 22 04:32:29.907: INFO: Pod "pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.006720543s
STEP: Saw pod success 08/22/23 04:32:29.907
Aug 22 04:32:29.907: INFO: Pod "pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed" satisfied condition "Succeeded or Failed"
Aug 22 04:32:29.909: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed container agnhost-container: <nil>
STEP: delete the pod 08/22/23 04:32:29.914
Aug 22 04:32:29.942: INFO: Waiting for pod pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed to disappear
Aug 22 04:32:29.945: INFO: Pod pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 22 04:32:29.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3211" for this suite. 08/22/23 04:32:29.948
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":113,"skipped":2017,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.088 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:32:21.868
    Aug 22 04:32:21.868: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:32:21.869
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:32:21.88
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:32:21.883
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-92987745-ac2c-4ddc-8f55-df0ee079ff55 08/22/23 04:32:21.887
    STEP: Creating a pod to test consume configMaps 08/22/23 04:32:21.892
    Aug 22 04:32:21.900: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed" in namespace "projected-3211" to be "Succeeded or Failed"
    Aug 22 04:32:21.902: INFO: Pod "pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.390044ms
    Aug 22 04:32:23.906: INFO: Pod "pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00589082s
    Aug 22 04:32:25.907: INFO: Pod "pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed": Phase="Running", Reason="", readiness=true. Elapsed: 4.00658905s
    Aug 22 04:32:27.907: INFO: Pod "pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed": Phase="Running", Reason="", readiness=false. Elapsed: 6.007121096s
    Aug 22 04:32:29.907: INFO: Pod "pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.006720543s
    STEP: Saw pod success 08/22/23 04:32:29.907
    Aug 22 04:32:29.907: INFO: Pod "pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed" satisfied condition "Succeeded or Failed"
    Aug 22 04:32:29.909: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 04:32:29.914
    Aug 22 04:32:29.942: INFO: Waiting for pod pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed to disappear
    Aug 22 04:32:29.945: INFO: Pod pod-projected-configmaps-22b77758-f38f-4af6-ae25-bae4b803c2ed no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 22 04:32:29.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3211" for this suite. 08/22/23 04:32:29.948
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:32:29.957
Aug 22 04:32:29.957: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename endpointslice 08/22/23 04:32:29.957
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:32:29.971
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:32:29.974
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 08/22/23 04:32:29.977
STEP: getting /apis/discovery.k8s.io 08/22/23 04:32:29.98
STEP: getting /apis/discovery.k8s.iov1 08/22/23 04:32:29.981
STEP: creating 08/22/23 04:32:29.989
STEP: getting 08/22/23 04:32:30.018
STEP: listing 08/22/23 04:32:30.021
STEP: watching 08/22/23 04:32:30.024
Aug 22 04:32:30.024: INFO: starting watch
STEP: cluster-wide listing 08/22/23 04:32:30.025
STEP: cluster-wide watching 08/22/23 04:32:30.028
Aug 22 04:32:30.028: INFO: starting watch
STEP: patching 08/22/23 04:32:30.029
STEP: updating 08/22/23 04:32:30.039
Aug 22 04:32:30.047: INFO: waiting for watch events with expected annotations
Aug 22 04:32:30.047: INFO: saw patched and updated annotations
STEP: deleting 08/22/23 04:32:30.047
STEP: deleting a collection 08/22/23 04:32:30.058
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Aug 22 04:32:30.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-3282" for this suite. 08/22/23 04:32:30.074
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":114,"skipped":2019,"failed":0}
------------------------------
â€¢ [0.123 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:32:29.957
    Aug 22 04:32:29.957: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename endpointslice 08/22/23 04:32:29.957
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:32:29.971
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:32:29.974
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 08/22/23 04:32:29.977
    STEP: getting /apis/discovery.k8s.io 08/22/23 04:32:29.98
    STEP: getting /apis/discovery.k8s.iov1 08/22/23 04:32:29.981
    STEP: creating 08/22/23 04:32:29.989
    STEP: getting 08/22/23 04:32:30.018
    STEP: listing 08/22/23 04:32:30.021
    STEP: watching 08/22/23 04:32:30.024
    Aug 22 04:32:30.024: INFO: starting watch
    STEP: cluster-wide listing 08/22/23 04:32:30.025
    STEP: cluster-wide watching 08/22/23 04:32:30.028
    Aug 22 04:32:30.028: INFO: starting watch
    STEP: patching 08/22/23 04:32:30.029
    STEP: updating 08/22/23 04:32:30.039
    Aug 22 04:32:30.047: INFO: waiting for watch events with expected annotations
    Aug 22 04:32:30.047: INFO: saw patched and updated annotations
    STEP: deleting 08/22/23 04:32:30.047
    STEP: deleting a collection 08/22/23 04:32:30.058
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Aug 22 04:32:30.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-3282" for this suite. 08/22/23 04:32:30.074
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:32:30.08
Aug 22 04:32:30.080: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename gc 08/22/23 04:32:30.081
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:32:30.093
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:32:30.096
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 08/22/23 04:32:30.102
STEP: delete the rc 08/22/23 04:32:35.237
STEP: wait for the rc to be deleted 08/22/23 04:32:35.481
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 08/22/23 04:32:40.555
STEP: Gathering metrics 08/22/23 04:33:10.569
W0822 04:33:10.578148      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Aug 22 04:33:10.578: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Aug 22 04:33:10.578: INFO: Deleting pod "simpletest.rc-25fw4" in namespace "gc-1434"
Aug 22 04:33:10.591: INFO: Deleting pod "simpletest.rc-42fxp" in namespace "gc-1434"
Aug 22 04:33:10.711: INFO: Deleting pod "simpletest.rc-455rk" in namespace "gc-1434"
Aug 22 04:33:11.195: INFO: Deleting pod "simpletest.rc-4kgpz" in namespace "gc-1434"
Aug 22 04:33:11.207: INFO: Deleting pod "simpletest.rc-4ngmv" in namespace "gc-1434"
Aug 22 04:33:11.228: INFO: Deleting pod "simpletest.rc-4rdp9" in namespace "gc-1434"
Aug 22 04:33:11.254: INFO: Deleting pod "simpletest.rc-4v4rb" in namespace "gc-1434"
Aug 22 04:33:11.314: INFO: Deleting pod "simpletest.rc-4xhhm" in namespace "gc-1434"
Aug 22 04:33:11.377: INFO: Deleting pod "simpletest.rc-52gdt" in namespace "gc-1434"
Aug 22 04:33:11.398: INFO: Deleting pod "simpletest.rc-5c88m" in namespace "gc-1434"
Aug 22 04:33:11.409: INFO: Deleting pod "simpletest.rc-5nqt5" in namespace "gc-1434"
Aug 22 04:33:11.425: INFO: Deleting pod "simpletest.rc-5nvvr" in namespace "gc-1434"
Aug 22 04:33:11.591: INFO: Deleting pod "simpletest.rc-62tnp" in namespace "gc-1434"
Aug 22 04:33:11.626: INFO: Deleting pod "simpletest.rc-6fm7d" in namespace "gc-1434"
Aug 22 04:33:11.638: INFO: Deleting pod "simpletest.rc-6pfjn" in namespace "gc-1434"
Aug 22 04:33:11.672: INFO: Deleting pod "simpletest.rc-6pj7w" in namespace "gc-1434"
Aug 22 04:33:11.685: INFO: Deleting pod "simpletest.rc-7gb82" in namespace "gc-1434"
Aug 22 04:33:11.698: INFO: Deleting pod "simpletest.rc-7khsf" in namespace "gc-1434"
Aug 22 04:33:11.714: INFO: Deleting pod "simpletest.rc-7vvsk" in namespace "gc-1434"
Aug 22 04:33:11.728: INFO: Deleting pod "simpletest.rc-852ws" in namespace "gc-1434"
Aug 22 04:33:11.741: INFO: Deleting pod "simpletest.rc-8ngcx" in namespace "gc-1434"
Aug 22 04:33:11.756: INFO: Deleting pod "simpletest.rc-949jm" in namespace "gc-1434"
Aug 22 04:33:11.776: INFO: Deleting pod "simpletest.rc-955sp" in namespace "gc-1434"
Aug 22 04:33:11.796: INFO: Deleting pod "simpletest.rc-9lnmw" in namespace "gc-1434"
Aug 22 04:33:11.809: INFO: Deleting pod "simpletest.rc-9sflg" in namespace "gc-1434"
Aug 22 04:33:11.821: INFO: Deleting pod "simpletest.rc-b6j77" in namespace "gc-1434"
Aug 22 04:33:11.844: INFO: Deleting pod "simpletest.rc-bbc9d" in namespace "gc-1434"
Aug 22 04:33:11.864: INFO: Deleting pod "simpletest.rc-blnwc" in namespace "gc-1434"
Aug 22 04:33:11.879: INFO: Deleting pod "simpletest.rc-bs5bk" in namespace "gc-1434"
Aug 22 04:33:11.895: INFO: Deleting pod "simpletest.rc-cfmb6" in namespace "gc-1434"
Aug 22 04:33:11.906: INFO: Deleting pod "simpletest.rc-cr8x6" in namespace "gc-1434"
Aug 22 04:33:11.917: INFO: Deleting pod "simpletest.rc-cw6rd" in namespace "gc-1434"
Aug 22 04:33:12.122: INFO: Deleting pod "simpletest.rc-d5ncn" in namespace "gc-1434"
Aug 22 04:33:12.151: INFO: Deleting pod "simpletest.rc-df8k4" in namespace "gc-1434"
Aug 22 04:33:12.242: INFO: Deleting pod "simpletest.rc-djb9b" in namespace "gc-1434"
Aug 22 04:33:12.257: INFO: Deleting pod "simpletest.rc-dp86m" in namespace "gc-1434"
Aug 22 04:33:12.269: INFO: Deleting pod "simpletest.rc-fcjxq" in namespace "gc-1434"
Aug 22 04:33:12.287: INFO: Deleting pod "simpletest.rc-ff5gb" in namespace "gc-1434"
Aug 22 04:33:12.301: INFO: Deleting pod "simpletest.rc-gf4t4" in namespace "gc-1434"
Aug 22 04:33:12.333: INFO: Deleting pod "simpletest.rc-gnm7x" in namespace "gc-1434"
Aug 22 04:33:12.354: INFO: Deleting pod "simpletest.rc-h9hph" in namespace "gc-1434"
Aug 22 04:33:12.396: INFO: Deleting pod "simpletest.rc-hcpkz" in namespace "gc-1434"
Aug 22 04:33:12.413: INFO: Deleting pod "simpletest.rc-hpb7f" in namespace "gc-1434"
Aug 22 04:33:12.432: INFO: Deleting pod "simpletest.rc-htwhb" in namespace "gc-1434"
Aug 22 04:33:12.460: INFO: Deleting pod "simpletest.rc-j2jtb" in namespace "gc-1434"
Aug 22 04:33:12.479: INFO: Deleting pod "simpletest.rc-j8bng" in namespace "gc-1434"
Aug 22 04:33:12.488: INFO: Deleting pod "simpletest.rc-j9d5t" in namespace "gc-1434"
Aug 22 04:33:12.500: INFO: Deleting pod "simpletest.rc-jbsm4" in namespace "gc-1434"
Aug 22 04:33:12.510: INFO: Deleting pod "simpletest.rc-jkl7s" in namespace "gc-1434"
Aug 22 04:33:12.522: INFO: Deleting pod "simpletest.rc-jq6rb" in namespace "gc-1434"
Aug 22 04:33:12.533: INFO: Deleting pod "simpletest.rc-jqgcs" in namespace "gc-1434"
Aug 22 04:33:12.542: INFO: Deleting pod "simpletest.rc-jwm4w" in namespace "gc-1434"
Aug 22 04:33:12.553: INFO: Deleting pod "simpletest.rc-k7bbr" in namespace "gc-1434"
Aug 22 04:33:12.564: INFO: Deleting pod "simpletest.rc-kb2pd" in namespace "gc-1434"
Aug 22 04:33:12.577: INFO: Deleting pod "simpletest.rc-kc8mm" in namespace "gc-1434"
Aug 22 04:33:12.592: INFO: Deleting pod "simpletest.rc-kfn4z" in namespace "gc-1434"
Aug 22 04:33:12.603: INFO: Deleting pod "simpletest.rc-krq4p" in namespace "gc-1434"
Aug 22 04:33:12.672: INFO: Deleting pod "simpletest.rc-kzbmj" in namespace "gc-1434"
Aug 22 04:33:12.794: INFO: Deleting pod "simpletest.rc-l2qfr" in namespace "gc-1434"
Aug 22 04:33:12.938: INFO: Deleting pod "simpletest.rc-lcwnj" in namespace "gc-1434"
Aug 22 04:33:12.954: INFO: Deleting pod "simpletest.rc-lh6lf" in namespace "gc-1434"
Aug 22 04:33:12.971: INFO: Deleting pod "simpletest.rc-lls8k" in namespace "gc-1434"
Aug 22 04:33:13.013: INFO: Deleting pod "simpletest.rc-lxbk2" in namespace "gc-1434"
Aug 22 04:33:13.328: INFO: Deleting pod "simpletest.rc-mbcjk" in namespace "gc-1434"
Aug 22 04:33:13.340: INFO: Deleting pod "simpletest.rc-mlt4s" in namespace "gc-1434"
Aug 22 04:33:13.351: INFO: Deleting pod "simpletest.rc-mqn64" in namespace "gc-1434"
Aug 22 04:33:13.360: INFO: Deleting pod "simpletest.rc-n5p5z" in namespace "gc-1434"
Aug 22 04:33:13.375: INFO: Deleting pod "simpletest.rc-n5spc" in namespace "gc-1434"
Aug 22 04:33:13.385: INFO: Deleting pod "simpletest.rc-nczxq" in namespace "gc-1434"
Aug 22 04:33:13.395: INFO: Deleting pod "simpletest.rc-ntgkg" in namespace "gc-1434"
Aug 22 04:33:13.406: INFO: Deleting pod "simpletest.rc-pc62h" in namespace "gc-1434"
Aug 22 04:33:13.419: INFO: Deleting pod "simpletest.rc-pghdw" in namespace "gc-1434"
Aug 22 04:33:13.679: INFO: Deleting pod "simpletest.rc-phkx4" in namespace "gc-1434"
Aug 22 04:33:13.707: INFO: Deleting pod "simpletest.rc-pl8kz" in namespace "gc-1434"
Aug 22 04:33:13.739: INFO: Deleting pod "simpletest.rc-pp9wd" in namespace "gc-1434"
Aug 22 04:33:13.748: INFO: Deleting pod "simpletest.rc-qhndv" in namespace "gc-1434"
Aug 22 04:33:13.920: INFO: Deleting pod "simpletest.rc-qldrm" in namespace "gc-1434"
Aug 22 04:33:13.934: INFO: Deleting pod "simpletest.rc-qqcrm" in namespace "gc-1434"
Aug 22 04:33:13.945: INFO: Deleting pod "simpletest.rc-qszfl" in namespace "gc-1434"
Aug 22 04:33:14.141: INFO: Deleting pod "simpletest.rc-r24mv" in namespace "gc-1434"
Aug 22 04:33:14.687: INFO: Deleting pod "simpletest.rc-r2vsr" in namespace "gc-1434"
Aug 22 04:33:14.698: INFO: Deleting pod "simpletest.rc-r8s9f" in namespace "gc-1434"
Aug 22 04:33:14.712: INFO: Deleting pod "simpletest.rc-rnk72" in namespace "gc-1434"
Aug 22 04:33:14.741: INFO: Deleting pod "simpletest.rc-sp9mc" in namespace "gc-1434"
Aug 22 04:33:14.757: INFO: Deleting pod "simpletest.rc-sscqq" in namespace "gc-1434"
Aug 22 04:33:14.768: INFO: Deleting pod "simpletest.rc-sxpwc" in namespace "gc-1434"
Aug 22 04:33:14.778: INFO: Deleting pod "simpletest.rc-tgcsn" in namespace "gc-1434"
Aug 22 04:33:14.849: INFO: Deleting pod "simpletest.rc-thwtl" in namespace "gc-1434"
Aug 22 04:33:14.858: INFO: Deleting pod "simpletest.rc-trz6q" in namespace "gc-1434"
Aug 22 04:33:14.869: INFO: Deleting pod "simpletest.rc-vgl8l" in namespace "gc-1434"
Aug 22 04:33:14.881: INFO: Deleting pod "simpletest.rc-vv6p2" in namespace "gc-1434"
Aug 22 04:33:14.892: INFO: Deleting pod "simpletest.rc-w22cl" in namespace "gc-1434"
Aug 22 04:33:14.903: INFO: Deleting pod "simpletest.rc-w6j5l" in namespace "gc-1434"
Aug 22 04:33:14.923: INFO: Deleting pod "simpletest.rc-whbqc" in namespace "gc-1434"
Aug 22 04:33:14.931: INFO: Deleting pod "simpletest.rc-wnd4x" in namespace "gc-1434"
Aug 22 04:33:14.940: INFO: Deleting pod "simpletest.rc-wrmrw" in namespace "gc-1434"
Aug 22 04:33:15.024: INFO: Deleting pod "simpletest.rc-x7lh7" in namespace "gc-1434"
Aug 22 04:33:15.035: INFO: Deleting pod "simpletest.rc-xgb6x" in namespace "gc-1434"
Aug 22 04:33:15.043: INFO: Deleting pod "simpletest.rc-z2d48" in namespace "gc-1434"
Aug 22 04:33:15.249: INFO: Deleting pod "simpletest.rc-ztf24" in namespace "gc-1434"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 22 04:33:15.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1434" for this suite. 08/22/23 04:33:15.369
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":115,"skipped":2032,"failed":0}
------------------------------
â€¢ [SLOW TEST] [45.294 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:32:30.08
    Aug 22 04:32:30.080: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename gc 08/22/23 04:32:30.081
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:32:30.093
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:32:30.096
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 08/22/23 04:32:30.102
    STEP: delete the rc 08/22/23 04:32:35.237
    STEP: wait for the rc to be deleted 08/22/23 04:32:35.481
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 08/22/23 04:32:40.555
    STEP: Gathering metrics 08/22/23 04:33:10.569
    W0822 04:33:10.578148      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Aug 22 04:33:10.578: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Aug 22 04:33:10.578: INFO: Deleting pod "simpletest.rc-25fw4" in namespace "gc-1434"
    Aug 22 04:33:10.591: INFO: Deleting pod "simpletest.rc-42fxp" in namespace "gc-1434"
    Aug 22 04:33:10.711: INFO: Deleting pod "simpletest.rc-455rk" in namespace "gc-1434"
    Aug 22 04:33:11.195: INFO: Deleting pod "simpletest.rc-4kgpz" in namespace "gc-1434"
    Aug 22 04:33:11.207: INFO: Deleting pod "simpletest.rc-4ngmv" in namespace "gc-1434"
    Aug 22 04:33:11.228: INFO: Deleting pod "simpletest.rc-4rdp9" in namespace "gc-1434"
    Aug 22 04:33:11.254: INFO: Deleting pod "simpletest.rc-4v4rb" in namespace "gc-1434"
    Aug 22 04:33:11.314: INFO: Deleting pod "simpletest.rc-4xhhm" in namespace "gc-1434"
    Aug 22 04:33:11.377: INFO: Deleting pod "simpletest.rc-52gdt" in namespace "gc-1434"
    Aug 22 04:33:11.398: INFO: Deleting pod "simpletest.rc-5c88m" in namespace "gc-1434"
    Aug 22 04:33:11.409: INFO: Deleting pod "simpletest.rc-5nqt5" in namespace "gc-1434"
    Aug 22 04:33:11.425: INFO: Deleting pod "simpletest.rc-5nvvr" in namespace "gc-1434"
    Aug 22 04:33:11.591: INFO: Deleting pod "simpletest.rc-62tnp" in namespace "gc-1434"
    Aug 22 04:33:11.626: INFO: Deleting pod "simpletest.rc-6fm7d" in namespace "gc-1434"
    Aug 22 04:33:11.638: INFO: Deleting pod "simpletest.rc-6pfjn" in namespace "gc-1434"
    Aug 22 04:33:11.672: INFO: Deleting pod "simpletest.rc-6pj7w" in namespace "gc-1434"
    Aug 22 04:33:11.685: INFO: Deleting pod "simpletest.rc-7gb82" in namespace "gc-1434"
    Aug 22 04:33:11.698: INFO: Deleting pod "simpletest.rc-7khsf" in namespace "gc-1434"
    Aug 22 04:33:11.714: INFO: Deleting pod "simpletest.rc-7vvsk" in namespace "gc-1434"
    Aug 22 04:33:11.728: INFO: Deleting pod "simpletest.rc-852ws" in namespace "gc-1434"
    Aug 22 04:33:11.741: INFO: Deleting pod "simpletest.rc-8ngcx" in namespace "gc-1434"
    Aug 22 04:33:11.756: INFO: Deleting pod "simpletest.rc-949jm" in namespace "gc-1434"
    Aug 22 04:33:11.776: INFO: Deleting pod "simpletest.rc-955sp" in namespace "gc-1434"
    Aug 22 04:33:11.796: INFO: Deleting pod "simpletest.rc-9lnmw" in namespace "gc-1434"
    Aug 22 04:33:11.809: INFO: Deleting pod "simpletest.rc-9sflg" in namespace "gc-1434"
    Aug 22 04:33:11.821: INFO: Deleting pod "simpletest.rc-b6j77" in namespace "gc-1434"
    Aug 22 04:33:11.844: INFO: Deleting pod "simpletest.rc-bbc9d" in namespace "gc-1434"
    Aug 22 04:33:11.864: INFO: Deleting pod "simpletest.rc-blnwc" in namespace "gc-1434"
    Aug 22 04:33:11.879: INFO: Deleting pod "simpletest.rc-bs5bk" in namespace "gc-1434"
    Aug 22 04:33:11.895: INFO: Deleting pod "simpletest.rc-cfmb6" in namespace "gc-1434"
    Aug 22 04:33:11.906: INFO: Deleting pod "simpletest.rc-cr8x6" in namespace "gc-1434"
    Aug 22 04:33:11.917: INFO: Deleting pod "simpletest.rc-cw6rd" in namespace "gc-1434"
    Aug 22 04:33:12.122: INFO: Deleting pod "simpletest.rc-d5ncn" in namespace "gc-1434"
    Aug 22 04:33:12.151: INFO: Deleting pod "simpletest.rc-df8k4" in namespace "gc-1434"
    Aug 22 04:33:12.242: INFO: Deleting pod "simpletest.rc-djb9b" in namespace "gc-1434"
    Aug 22 04:33:12.257: INFO: Deleting pod "simpletest.rc-dp86m" in namespace "gc-1434"
    Aug 22 04:33:12.269: INFO: Deleting pod "simpletest.rc-fcjxq" in namespace "gc-1434"
    Aug 22 04:33:12.287: INFO: Deleting pod "simpletest.rc-ff5gb" in namespace "gc-1434"
    Aug 22 04:33:12.301: INFO: Deleting pod "simpletest.rc-gf4t4" in namespace "gc-1434"
    Aug 22 04:33:12.333: INFO: Deleting pod "simpletest.rc-gnm7x" in namespace "gc-1434"
    Aug 22 04:33:12.354: INFO: Deleting pod "simpletest.rc-h9hph" in namespace "gc-1434"
    Aug 22 04:33:12.396: INFO: Deleting pod "simpletest.rc-hcpkz" in namespace "gc-1434"
    Aug 22 04:33:12.413: INFO: Deleting pod "simpletest.rc-hpb7f" in namespace "gc-1434"
    Aug 22 04:33:12.432: INFO: Deleting pod "simpletest.rc-htwhb" in namespace "gc-1434"
    Aug 22 04:33:12.460: INFO: Deleting pod "simpletest.rc-j2jtb" in namespace "gc-1434"
    Aug 22 04:33:12.479: INFO: Deleting pod "simpletest.rc-j8bng" in namespace "gc-1434"
    Aug 22 04:33:12.488: INFO: Deleting pod "simpletest.rc-j9d5t" in namespace "gc-1434"
    Aug 22 04:33:12.500: INFO: Deleting pod "simpletest.rc-jbsm4" in namespace "gc-1434"
    Aug 22 04:33:12.510: INFO: Deleting pod "simpletest.rc-jkl7s" in namespace "gc-1434"
    Aug 22 04:33:12.522: INFO: Deleting pod "simpletest.rc-jq6rb" in namespace "gc-1434"
    Aug 22 04:33:12.533: INFO: Deleting pod "simpletest.rc-jqgcs" in namespace "gc-1434"
    Aug 22 04:33:12.542: INFO: Deleting pod "simpletest.rc-jwm4w" in namespace "gc-1434"
    Aug 22 04:33:12.553: INFO: Deleting pod "simpletest.rc-k7bbr" in namespace "gc-1434"
    Aug 22 04:33:12.564: INFO: Deleting pod "simpletest.rc-kb2pd" in namespace "gc-1434"
    Aug 22 04:33:12.577: INFO: Deleting pod "simpletest.rc-kc8mm" in namespace "gc-1434"
    Aug 22 04:33:12.592: INFO: Deleting pod "simpletest.rc-kfn4z" in namespace "gc-1434"
    Aug 22 04:33:12.603: INFO: Deleting pod "simpletest.rc-krq4p" in namespace "gc-1434"
    Aug 22 04:33:12.672: INFO: Deleting pod "simpletest.rc-kzbmj" in namespace "gc-1434"
    Aug 22 04:33:12.794: INFO: Deleting pod "simpletest.rc-l2qfr" in namespace "gc-1434"
    Aug 22 04:33:12.938: INFO: Deleting pod "simpletest.rc-lcwnj" in namespace "gc-1434"
    Aug 22 04:33:12.954: INFO: Deleting pod "simpletest.rc-lh6lf" in namespace "gc-1434"
    Aug 22 04:33:12.971: INFO: Deleting pod "simpletest.rc-lls8k" in namespace "gc-1434"
    Aug 22 04:33:13.013: INFO: Deleting pod "simpletest.rc-lxbk2" in namespace "gc-1434"
    Aug 22 04:33:13.328: INFO: Deleting pod "simpletest.rc-mbcjk" in namespace "gc-1434"
    Aug 22 04:33:13.340: INFO: Deleting pod "simpletest.rc-mlt4s" in namespace "gc-1434"
    Aug 22 04:33:13.351: INFO: Deleting pod "simpletest.rc-mqn64" in namespace "gc-1434"
    Aug 22 04:33:13.360: INFO: Deleting pod "simpletest.rc-n5p5z" in namespace "gc-1434"
    Aug 22 04:33:13.375: INFO: Deleting pod "simpletest.rc-n5spc" in namespace "gc-1434"
    Aug 22 04:33:13.385: INFO: Deleting pod "simpletest.rc-nczxq" in namespace "gc-1434"
    Aug 22 04:33:13.395: INFO: Deleting pod "simpletest.rc-ntgkg" in namespace "gc-1434"
    Aug 22 04:33:13.406: INFO: Deleting pod "simpletest.rc-pc62h" in namespace "gc-1434"
    Aug 22 04:33:13.419: INFO: Deleting pod "simpletest.rc-pghdw" in namespace "gc-1434"
    Aug 22 04:33:13.679: INFO: Deleting pod "simpletest.rc-phkx4" in namespace "gc-1434"
    Aug 22 04:33:13.707: INFO: Deleting pod "simpletest.rc-pl8kz" in namespace "gc-1434"
    Aug 22 04:33:13.739: INFO: Deleting pod "simpletest.rc-pp9wd" in namespace "gc-1434"
    Aug 22 04:33:13.748: INFO: Deleting pod "simpletest.rc-qhndv" in namespace "gc-1434"
    Aug 22 04:33:13.920: INFO: Deleting pod "simpletest.rc-qldrm" in namespace "gc-1434"
    Aug 22 04:33:13.934: INFO: Deleting pod "simpletest.rc-qqcrm" in namespace "gc-1434"
    Aug 22 04:33:13.945: INFO: Deleting pod "simpletest.rc-qszfl" in namespace "gc-1434"
    Aug 22 04:33:14.141: INFO: Deleting pod "simpletest.rc-r24mv" in namespace "gc-1434"
    Aug 22 04:33:14.687: INFO: Deleting pod "simpletest.rc-r2vsr" in namespace "gc-1434"
    Aug 22 04:33:14.698: INFO: Deleting pod "simpletest.rc-r8s9f" in namespace "gc-1434"
    Aug 22 04:33:14.712: INFO: Deleting pod "simpletest.rc-rnk72" in namespace "gc-1434"
    Aug 22 04:33:14.741: INFO: Deleting pod "simpletest.rc-sp9mc" in namespace "gc-1434"
    Aug 22 04:33:14.757: INFO: Deleting pod "simpletest.rc-sscqq" in namespace "gc-1434"
    Aug 22 04:33:14.768: INFO: Deleting pod "simpletest.rc-sxpwc" in namespace "gc-1434"
    Aug 22 04:33:14.778: INFO: Deleting pod "simpletest.rc-tgcsn" in namespace "gc-1434"
    Aug 22 04:33:14.849: INFO: Deleting pod "simpletest.rc-thwtl" in namespace "gc-1434"
    Aug 22 04:33:14.858: INFO: Deleting pod "simpletest.rc-trz6q" in namespace "gc-1434"
    Aug 22 04:33:14.869: INFO: Deleting pod "simpletest.rc-vgl8l" in namespace "gc-1434"
    Aug 22 04:33:14.881: INFO: Deleting pod "simpletest.rc-vv6p2" in namespace "gc-1434"
    Aug 22 04:33:14.892: INFO: Deleting pod "simpletest.rc-w22cl" in namespace "gc-1434"
    Aug 22 04:33:14.903: INFO: Deleting pod "simpletest.rc-w6j5l" in namespace "gc-1434"
    Aug 22 04:33:14.923: INFO: Deleting pod "simpletest.rc-whbqc" in namespace "gc-1434"
    Aug 22 04:33:14.931: INFO: Deleting pod "simpletest.rc-wnd4x" in namespace "gc-1434"
    Aug 22 04:33:14.940: INFO: Deleting pod "simpletest.rc-wrmrw" in namespace "gc-1434"
    Aug 22 04:33:15.024: INFO: Deleting pod "simpletest.rc-x7lh7" in namespace "gc-1434"
    Aug 22 04:33:15.035: INFO: Deleting pod "simpletest.rc-xgb6x" in namespace "gc-1434"
    Aug 22 04:33:15.043: INFO: Deleting pod "simpletest.rc-z2d48" in namespace "gc-1434"
    Aug 22 04:33:15.249: INFO: Deleting pod "simpletest.rc-ztf24" in namespace "gc-1434"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 22 04:33:15.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1434" for this suite. 08/22/23 04:33:15.369
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:33:15.374
Aug 22 04:33:15.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename custom-resource-definition 08/22/23 04:33:15.375
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:33:15.401
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:33:15.404
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Aug 22 04:33:15.408: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:33:16.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5863" for this suite. 08/22/23 04:33:16.012
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":116,"skipped":2045,"failed":0}
------------------------------
â€¢ [0.647 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:33:15.374
    Aug 22 04:33:15.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename custom-resource-definition 08/22/23 04:33:15.375
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:33:15.401
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:33:15.404
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Aug 22 04:33:15.408: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:33:16.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-5863" for this suite. 08/22/23 04:33:16.012
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:33:16.023
Aug 22 04:33:16.023: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename subpath 08/22/23 04:33:16.023
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:33:16.044
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:33:16.049
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/22/23 04:33:16.056
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-76rj 08/22/23 04:33:16.07
STEP: Creating a pod to test atomic-volume-subpath 08/22/23 04:33:16.07
Aug 22 04:33:16.084: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-76rj" in namespace "subpath-6783" to be "Succeeded or Failed"
Aug 22 04:33:16.090: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.165828ms
Aug 22 04:33:18.094: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010215485s
Aug 22 04:33:20.097: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012684444s
Aug 22 04:33:22.341: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.256842666s
Aug 22 04:33:24.196: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Pending", Reason="", readiness=false. Elapsed: 8.111779643s
Aug 22 04:33:26.093: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 10.009596439s
Aug 22 04:33:28.094: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 12.009768409s
Aug 22 04:33:30.095: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 14.010790166s
Aug 22 04:33:32.096: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 16.011771305s
Aug 22 04:33:34.097: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 18.012731295s
Aug 22 04:33:36.095: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 20.01093815s
Aug 22 04:33:38.094: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 22.009892829s
Aug 22 04:33:40.094: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 24.00971853s
Aug 22 04:33:42.154: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=false. Elapsed: 26.070259998s
Aug 22 04:33:44.093: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.009369042s
STEP: Saw pod success 08/22/23 04:33:44.093
Aug 22 04:33:44.093: INFO: Pod "pod-subpath-test-configmap-76rj" satisfied condition "Succeeded or Failed"
Aug 22 04:33:44.095: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-subpath-test-configmap-76rj container test-container-subpath-configmap-76rj: <nil>
STEP: delete the pod 08/22/23 04:33:44.127
Aug 22 04:33:44.301: INFO: Waiting for pod pod-subpath-test-configmap-76rj to disappear
Aug 22 04:33:44.304: INFO: Pod pod-subpath-test-configmap-76rj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-76rj 08/22/23 04:33:44.304
Aug 22 04:33:44.304: INFO: Deleting pod "pod-subpath-test-configmap-76rj" in namespace "subpath-6783"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 22 04:33:44.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6783" for this suite. 08/22/23 04:33:44.308
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":117,"skipped":2082,"failed":0}
------------------------------
â€¢ [SLOW TEST] [28.291 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:33:16.023
    Aug 22 04:33:16.023: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename subpath 08/22/23 04:33:16.023
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:33:16.044
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:33:16.049
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/22/23 04:33:16.056
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-76rj 08/22/23 04:33:16.07
    STEP: Creating a pod to test atomic-volume-subpath 08/22/23 04:33:16.07
    Aug 22 04:33:16.084: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-76rj" in namespace "subpath-6783" to be "Succeeded or Failed"
    Aug 22 04:33:16.090: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.165828ms
    Aug 22 04:33:18.094: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010215485s
    Aug 22 04:33:20.097: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012684444s
    Aug 22 04:33:22.341: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.256842666s
    Aug 22 04:33:24.196: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Pending", Reason="", readiness=false. Elapsed: 8.111779643s
    Aug 22 04:33:26.093: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 10.009596439s
    Aug 22 04:33:28.094: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 12.009768409s
    Aug 22 04:33:30.095: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 14.010790166s
    Aug 22 04:33:32.096: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 16.011771305s
    Aug 22 04:33:34.097: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 18.012731295s
    Aug 22 04:33:36.095: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 20.01093815s
    Aug 22 04:33:38.094: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 22.009892829s
    Aug 22 04:33:40.094: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=true. Elapsed: 24.00971853s
    Aug 22 04:33:42.154: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Running", Reason="", readiness=false. Elapsed: 26.070259998s
    Aug 22 04:33:44.093: INFO: Pod "pod-subpath-test-configmap-76rj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.009369042s
    STEP: Saw pod success 08/22/23 04:33:44.093
    Aug 22 04:33:44.093: INFO: Pod "pod-subpath-test-configmap-76rj" satisfied condition "Succeeded or Failed"
    Aug 22 04:33:44.095: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-subpath-test-configmap-76rj container test-container-subpath-configmap-76rj: <nil>
    STEP: delete the pod 08/22/23 04:33:44.127
    Aug 22 04:33:44.301: INFO: Waiting for pod pod-subpath-test-configmap-76rj to disappear
    Aug 22 04:33:44.304: INFO: Pod pod-subpath-test-configmap-76rj no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-76rj 08/22/23 04:33:44.304
    Aug 22 04:33:44.304: INFO: Deleting pod "pod-subpath-test-configmap-76rj" in namespace "subpath-6783"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 22 04:33:44.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-6783" for this suite. 08/22/23 04:33:44.308
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:33:44.314
Aug 22 04:33:44.314: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename secrets 08/22/23 04:33:44.314
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:33:44.653
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:33:44.657
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-0932fa0a-d7bd-4f69-a616-8f0731617d94 08/22/23 04:33:44.661
STEP: Creating a pod to test consume secrets 08/22/23 04:33:44.678
Aug 22 04:33:44.686: INFO: Waiting up to 5m0s for pod "pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8" in namespace "secrets-3366" to be "Succeeded or Failed"
Aug 22 04:33:44.690: INFO: Pod "pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.517689ms
Aug 22 04:33:46.693: INFO: Pod "pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00691916s
Aug 22 04:33:48.693: INFO: Pod "pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007080049s
Aug 22 04:33:50.693: INFO: Pod "pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007359635s
STEP: Saw pod success 08/22/23 04:33:50.693
Aug 22 04:33:50.694: INFO: Pod "pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8" satisfied condition "Succeeded or Failed"
Aug 22 04:33:50.696: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8 container secret-volume-test: <nil>
STEP: delete the pod 08/22/23 04:33:50.701
Aug 22 04:33:50.712: INFO: Waiting for pod pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8 to disappear
Aug 22 04:33:50.715: INFO: Pod pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 22 04:33:50.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3366" for this suite. 08/22/23 04:33:50.719
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":118,"skipped":2102,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.410 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:33:44.314
    Aug 22 04:33:44.314: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename secrets 08/22/23 04:33:44.314
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:33:44.653
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:33:44.657
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-0932fa0a-d7bd-4f69-a616-8f0731617d94 08/22/23 04:33:44.661
    STEP: Creating a pod to test consume secrets 08/22/23 04:33:44.678
    Aug 22 04:33:44.686: INFO: Waiting up to 5m0s for pod "pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8" in namespace "secrets-3366" to be "Succeeded or Failed"
    Aug 22 04:33:44.690: INFO: Pod "pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.517689ms
    Aug 22 04:33:46.693: INFO: Pod "pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00691916s
    Aug 22 04:33:48.693: INFO: Pod "pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007080049s
    Aug 22 04:33:50.693: INFO: Pod "pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007359635s
    STEP: Saw pod success 08/22/23 04:33:50.693
    Aug 22 04:33:50.694: INFO: Pod "pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8" satisfied condition "Succeeded or Failed"
    Aug 22 04:33:50.696: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8 container secret-volume-test: <nil>
    STEP: delete the pod 08/22/23 04:33:50.701
    Aug 22 04:33:50.712: INFO: Waiting for pod pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8 to disappear
    Aug 22 04:33:50.715: INFO: Pod pod-secrets-f8ee8ef7-05e9-4e0f-8dee-f355cc80fff8 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 22 04:33:50.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3366" for this suite. 08/22/23 04:33:50.719
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:33:50.725
Aug 22 04:33:50.725: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 04:33:50.726
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:33:50.741
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:33:50.745
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 08/22/23 04:33:50.748
Aug 22 04:33:50.749: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 04:33:53.100: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:34:03.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5568" for this suite. 08/22/23 04:34:03.459
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":119,"skipped":2109,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.740 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:33:50.725
    Aug 22 04:33:50.725: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 04:33:50.726
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:33:50.741
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:33:50.745
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 08/22/23 04:33:50.748
    Aug 22 04:33:50.749: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 04:33:53.100: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:34:03.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5568" for this suite. 08/22/23 04:34:03.459
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:34:03.466
Aug 22 04:34:03.466: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:34:03.467
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:03.579
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:03.583
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-63ec3c9d-d73c-47a8-b8e3-82a8466bd6d9 08/22/23 04:34:03.587
STEP: Creating a pod to test consume configMaps 08/22/23 04:34:03.664
Aug 22 04:34:03.675: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d" in namespace "projected-7880" to be "Succeeded or Failed"
Aug 22 04:34:03.681: INFO: Pod "pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.003925ms
Aug 22 04:34:06.239: INFO: Pod "pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.564235079s
Aug 22 04:34:07.686: INFO: Pod "pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010936435s
Aug 22 04:34:09.686: INFO: Pod "pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011017167s
STEP: Saw pod success 08/22/23 04:34:09.686
Aug 22 04:34:09.686: INFO: Pod "pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d" satisfied condition "Succeeded or Failed"
Aug 22 04:34:09.689: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d container agnhost-container: <nil>
STEP: delete the pod 08/22/23 04:34:09.722
Aug 22 04:34:09.838: INFO: Waiting for pod pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d to disappear
Aug 22 04:34:09.842: INFO: Pod pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 22 04:34:09.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7880" for this suite. 08/22/23 04:34:09.846
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":120,"skipped":2109,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.386 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:34:03.466
    Aug 22 04:34:03.466: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:34:03.467
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:03.579
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:03.583
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-63ec3c9d-d73c-47a8-b8e3-82a8466bd6d9 08/22/23 04:34:03.587
    STEP: Creating a pod to test consume configMaps 08/22/23 04:34:03.664
    Aug 22 04:34:03.675: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d" in namespace "projected-7880" to be "Succeeded or Failed"
    Aug 22 04:34:03.681: INFO: Pod "pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.003925ms
    Aug 22 04:34:06.239: INFO: Pod "pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.564235079s
    Aug 22 04:34:07.686: INFO: Pod "pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010936435s
    Aug 22 04:34:09.686: INFO: Pod "pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011017167s
    STEP: Saw pod success 08/22/23 04:34:09.686
    Aug 22 04:34:09.686: INFO: Pod "pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d" satisfied condition "Succeeded or Failed"
    Aug 22 04:34:09.689: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 04:34:09.722
    Aug 22 04:34:09.838: INFO: Waiting for pod pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d to disappear
    Aug 22 04:34:09.842: INFO: Pod pod-projected-configmaps-9ecd68bb-0d2b-450d-b6c7-85842565614d no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 22 04:34:09.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7880" for this suite. 08/22/23 04:34:09.846
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:34:09.853
Aug 22 04:34:09.853: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename daemonsets 08/22/23 04:34:09.853
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:09.87
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:09.872
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 08/22/23 04:34:09.89
STEP: Check that daemon pods launch on every node of the cluster. 08/22/23 04:34:09.915
Aug 22 04:34:09.918: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:09.918: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:09.918: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:09.922: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:34:09.922: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:34:10.933: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:10.933: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:10.933: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:10.937: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:34:10.937: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:34:11.941: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:11.941: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:11.941: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:11.944: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:34:11.944: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:34:12.927: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:12.927: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:12.927: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:12.930: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 04:34:12.930: INFO: Node jake-melb-gmyyva4zrlsz-node-2 is running 0 daemon pod, expected 1
Aug 22 04:34:13.927: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:13.927: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:13.927: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:13.929: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 04:34:13.929: INFO: Node jake-melb-gmyyva4zrlsz-node-2 is running 0 daemon pod, expected 1
Aug 22 04:34:14.926: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:14.926: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:14.926: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:14.928: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 22 04:34:14.928: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 08/22/23 04:34:14.93
Aug 22 04:34:15.098: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:15.098: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:15.098: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:15.101: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 04:34:15.102: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:34:16.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:16.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:16.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:16.110: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 04:34:16.110: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:34:17.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:17.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:17.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:17.110: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 04:34:17.110: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:34:18.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:18.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:18.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:18.109: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 04:34:18.109: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:34:19.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:19.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:19.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:19.109: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 04:34:19.109: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:34:20.109: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:20.109: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:20.109: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:20.112: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 04:34:20.112: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:34:21.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:21.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:21.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:34:21.110: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 22 04:34:21.110: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/22/23 04:34:21.113
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7931, will wait for the garbage collector to delete the pods 08/22/23 04:34:21.113
Aug 22 04:34:21.174: INFO: Deleting DaemonSet.extensions daemon-set took: 6.714295ms
Aug 22 04:34:21.274: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.259224ms
Aug 22 04:34:23.278: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:34:23.278: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 22 04:34:23.280: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1262830"},"items":null}

Aug 22 04:34:23.282: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1262830"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 22 04:34:23.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7931" for this suite. 08/22/23 04:34:23.294
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":121,"skipped":2117,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.462 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:34:09.853
    Aug 22 04:34:09.853: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename daemonsets 08/22/23 04:34:09.853
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:09.87
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:09.872
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 08/22/23 04:34:09.89
    STEP: Check that daemon pods launch on every node of the cluster. 08/22/23 04:34:09.915
    Aug 22 04:34:09.918: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:09.918: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:09.918: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:09.922: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:34:09.922: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:34:10.933: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:10.933: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:10.933: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:10.937: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:34:10.937: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:34:11.941: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:11.941: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:11.941: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:11.944: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:34:11.944: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:34:12.927: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:12.927: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:12.927: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:12.930: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 04:34:12.930: INFO: Node jake-melb-gmyyva4zrlsz-node-2 is running 0 daemon pod, expected 1
    Aug 22 04:34:13.927: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:13.927: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:13.927: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:13.929: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 04:34:13.929: INFO: Node jake-melb-gmyyva4zrlsz-node-2 is running 0 daemon pod, expected 1
    Aug 22 04:34:14.926: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:14.926: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:14.926: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:14.928: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 22 04:34:14.928: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 08/22/23 04:34:14.93
    Aug 22 04:34:15.098: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:15.098: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:15.098: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:15.101: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 04:34:15.102: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:34:16.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:16.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:16.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:16.110: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 04:34:16.110: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:34:17.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:17.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:17.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:17.110: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 04:34:17.110: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:34:18.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:18.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:18.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:18.109: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 04:34:18.109: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:34:19.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:19.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:19.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:19.109: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 04:34:19.109: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:34:20.109: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:20.109: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:20.109: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:20.112: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 04:34:20.112: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:34:21.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:21.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:21.107: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:34:21.110: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 22 04:34:21.110: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/22/23 04:34:21.113
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7931, will wait for the garbage collector to delete the pods 08/22/23 04:34:21.113
    Aug 22 04:34:21.174: INFO: Deleting DaemonSet.extensions daemon-set took: 6.714295ms
    Aug 22 04:34:21.274: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.259224ms
    Aug 22 04:34:23.278: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:34:23.278: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 22 04:34:23.280: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1262830"},"items":null}

    Aug 22 04:34:23.282: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1262830"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 04:34:23.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7931" for this suite. 08/22/23 04:34:23.294
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:34:23.315
Aug 22 04:34:23.315: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename resourcequota 08/22/23 04:34:23.315
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:23.339
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:23.342
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 08/22/23 04:34:23.345
STEP: Counting existing ResourceQuota 08/22/23 04:34:28.348
STEP: Creating a ResourceQuota 08/22/23 04:34:33.352
STEP: Ensuring resource quota status is calculated 08/22/23 04:34:33.368
STEP: Creating a Secret 08/22/23 04:34:35.373
STEP: Ensuring resource quota status captures secret creation 08/22/23 04:34:35.46
STEP: Deleting a secret 08/22/23 04:34:37.465
STEP: Ensuring resource quota status released usage 08/22/23 04:34:37.473
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 22 04:34:39.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4074" for this suite. 08/22/23 04:34:39.482
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":122,"skipped":2118,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.302 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:34:23.315
    Aug 22 04:34:23.315: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename resourcequota 08/22/23 04:34:23.315
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:23.339
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:23.342
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 08/22/23 04:34:23.345
    STEP: Counting existing ResourceQuota 08/22/23 04:34:28.348
    STEP: Creating a ResourceQuota 08/22/23 04:34:33.352
    STEP: Ensuring resource quota status is calculated 08/22/23 04:34:33.368
    STEP: Creating a Secret 08/22/23 04:34:35.373
    STEP: Ensuring resource quota status captures secret creation 08/22/23 04:34:35.46
    STEP: Deleting a secret 08/22/23 04:34:37.465
    STEP: Ensuring resource quota status released usage 08/22/23 04:34:37.473
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 22 04:34:39.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4074" for this suite. 08/22/23 04:34:39.482
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:34:39.618
Aug 22 04:34:39.618: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename events 08/22/23 04:34:39.619
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:39.77
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:39.772
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 08/22/23 04:34:39.777
STEP: get a list of Events with a label in the current namespace 08/22/23 04:34:39.926
STEP: delete a list of events 08/22/23 04:34:39.93
Aug 22 04:34:39.930: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 08/22/23 04:34:39.952
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Aug 22 04:34:39.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7943" for this suite. 08/22/23 04:34:39.959
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":123,"skipped":2123,"failed":0}
------------------------------
â€¢ [0.350 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:34:39.618
    Aug 22 04:34:39.618: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename events 08/22/23 04:34:39.619
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:39.77
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:39.772
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 08/22/23 04:34:39.777
    STEP: get a list of Events with a label in the current namespace 08/22/23 04:34:39.926
    STEP: delete a list of events 08/22/23 04:34:39.93
    Aug 22 04:34:39.930: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 08/22/23 04:34:39.952
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Aug 22 04:34:39.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-7943" for this suite. 08/22/23 04:34:39.959
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:34:39.969
Aug 22 04:34:39.969: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 04:34:39.969
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:39.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:39.989
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 08/22/23 04:34:39.993
Aug 22 04:34:39.993: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-5743 proxy --unix-socket=/tmp/kubectl-proxy-unix1287212414/test'
STEP: retrieving proxy /api/ output 08/22/23 04:34:40.026
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 04:34:40.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5743" for this suite. 08/22/23 04:34:40.038
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":124,"skipped":2156,"failed":0}
------------------------------
â€¢ [0.078 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:34:39.969
    Aug 22 04:34:39.969: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 04:34:39.969
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:39.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:39.989
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 08/22/23 04:34:39.993
    Aug 22 04:34:39.993: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-5743 proxy --unix-socket=/tmp/kubectl-proxy-unix1287212414/test'
    STEP: retrieving proxy /api/ output 08/22/23 04:34:40.026
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 04:34:40.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5743" for this suite. 08/22/23 04:34:40.038
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:34:40.047
Aug 22 04:34:40.047: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:34:40.048
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:40.068
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:40.07
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-98da0609-1dae-488f-abb2-f87e83d57464 08/22/23 04:34:40.078
STEP: Creating the pod 08/22/23 04:34:40.083
Aug 22 04:34:40.092: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055" in namespace "projected-3007" to be "running and ready"
Aug 22 04:34:40.100: INFO: Pod "pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055": Phase="Pending", Reason="", readiness=false. Elapsed: 7.881857ms
Aug 22 04:34:40.100: INFO: The phase of Pod pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:34:42.106: INFO: Pod "pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013708028s
Aug 22 04:34:42.106: INFO: The phase of Pod pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:34:44.104: INFO: Pod "pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055": Phase="Running", Reason="", readiness=true. Elapsed: 4.011977107s
Aug 22 04:34:44.104: INFO: The phase of Pod pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055 is Running (Ready = true)
Aug 22 04:34:44.104: INFO: Pod "pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-98da0609-1dae-488f-abb2-f87e83d57464 08/22/23 04:34:44.112
STEP: waiting to observe update in volume 08/22/23 04:34:44.118
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 22 04:34:46.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3007" for this suite. 08/22/23 04:34:46.136
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":125,"skipped":2171,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.250 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:34:40.047
    Aug 22 04:34:40.047: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:34:40.048
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:40.068
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:40.07
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-98da0609-1dae-488f-abb2-f87e83d57464 08/22/23 04:34:40.078
    STEP: Creating the pod 08/22/23 04:34:40.083
    Aug 22 04:34:40.092: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055" in namespace "projected-3007" to be "running and ready"
    Aug 22 04:34:40.100: INFO: Pod "pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055": Phase="Pending", Reason="", readiness=false. Elapsed: 7.881857ms
    Aug 22 04:34:40.100: INFO: The phase of Pod pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:34:42.106: INFO: Pod "pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013708028s
    Aug 22 04:34:42.106: INFO: The phase of Pod pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:34:44.104: INFO: Pod "pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055": Phase="Running", Reason="", readiness=true. Elapsed: 4.011977107s
    Aug 22 04:34:44.104: INFO: The phase of Pod pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055 is Running (Ready = true)
    Aug 22 04:34:44.104: INFO: Pod "pod-projected-configmaps-c5634eb2-3b8f-4223-831c-aa91d3040055" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-98da0609-1dae-488f-abb2-f87e83d57464 08/22/23 04:34:44.112
    STEP: waiting to observe update in volume 08/22/23 04:34:44.118
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 22 04:34:46.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3007" for this suite. 08/22/23 04:34:46.136
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:34:46.298
Aug 22 04:34:46.298: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-lifecycle-hook 08/22/23 04:34:46.299
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:46.315
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:46.318
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 08/22/23 04:34:46.326
Aug 22 04:34:46.362: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7225" to be "running and ready"
Aug 22 04:34:46.366: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.925204ms
Aug 22 04:34:46.366: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:34:48.370: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00806074s
Aug 22 04:34:48.370: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:34:50.371: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.008976287s
Aug 22 04:34:50.371: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Aug 22 04:34:50.371: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 08/22/23 04:34:50.373
Aug 22 04:34:50.380: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-7225" to be "running and ready"
Aug 22 04:34:50.386: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.34317ms
Aug 22 04:34:50.386: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:34:52.390: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010470532s
Aug 22 04:34:52.390: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:34:54.391: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.011349481s
Aug 22 04:34:54.391: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Aug 22 04:34:54.391: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 08/22/23 04:34:54.393
Aug 22 04:34:54.584: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 04:34:54.588: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 22 04:34:56.589: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 22 04:34:56.604: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 08/22/23 04:34:56.604
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Aug 22 04:34:56.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7225" for this suite. 08/22/23 04:34:56.615
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":126,"skipped":2178,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.324 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:34:46.298
    Aug 22 04:34:46.298: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-lifecycle-hook 08/22/23 04:34:46.299
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:46.315
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:46.318
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 08/22/23 04:34:46.326
    Aug 22 04:34:46.362: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7225" to be "running and ready"
    Aug 22 04:34:46.366: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.925204ms
    Aug 22 04:34:46.366: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:34:48.370: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00806074s
    Aug 22 04:34:48.370: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:34:50.371: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.008976287s
    Aug 22 04:34:50.371: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Aug 22 04:34:50.371: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 08/22/23 04:34:50.373
    Aug 22 04:34:50.380: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-7225" to be "running and ready"
    Aug 22 04:34:50.386: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.34317ms
    Aug 22 04:34:50.386: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:34:52.390: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010470532s
    Aug 22 04:34:52.390: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:34:54.391: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.011349481s
    Aug 22 04:34:54.391: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Aug 22 04:34:54.391: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 08/22/23 04:34:54.393
    Aug 22 04:34:54.584: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Aug 22 04:34:54.588: INFO: Pod pod-with-prestop-exec-hook still exists
    Aug 22 04:34:56.589: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Aug 22 04:34:56.604: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 08/22/23 04:34:56.604
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Aug 22 04:34:56.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-7225" for this suite. 08/22/23 04:34:56.615
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:34:56.623
Aug 22 04:34:56.623: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename gc 08/22/23 04:34:56.624
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:56.642
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:56.644
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 08/22/23 04:34:56.647
STEP: Wait for the Deployment to create new ReplicaSet 08/22/23 04:34:56.654
STEP: delete the deployment 08/22/23 04:34:57.086
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 08/22/23 04:34:58.056
STEP: Gathering metrics 08/22/23 04:34:58.15
W0822 04:34:58.158460      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Aug 22 04:34:58.158: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 22 04:34:58.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7137" for this suite. 08/22/23 04:34:58.161
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":127,"skipped":2179,"failed":0}
------------------------------
â€¢ [1.545 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:34:56.623
    Aug 22 04:34:56.623: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename gc 08/22/23 04:34:56.624
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:56.642
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:56.644
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 08/22/23 04:34:56.647
    STEP: Wait for the Deployment to create new ReplicaSet 08/22/23 04:34:56.654
    STEP: delete the deployment 08/22/23 04:34:57.086
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 08/22/23 04:34:58.056
    STEP: Gathering metrics 08/22/23 04:34:58.15
    W0822 04:34:58.158460      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Aug 22 04:34:58.158: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 22 04:34:58.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7137" for this suite. 08/22/23 04:34:58.161
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:34:58.169
Aug 22 04:34:58.169: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-runtime 08/22/23 04:34:58.17
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:58.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:58.186
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 08/22/23 04:34:58.189
STEP: wait for the container to reach Succeeded 08/22/23 04:34:58.211
STEP: get the container status 08/22/23 04:35:04.336
STEP: the container should be terminated 08/22/23 04:35:04.34
STEP: the termination message should be set 08/22/23 04:35:04.34
Aug 22 04:35:04.340: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 08/22/23 04:35:04.34
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 22 04:35:04.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6783" for this suite. 08/22/23 04:35:04.361
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":128,"skipped":2198,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.422 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:34:58.169
    Aug 22 04:34:58.169: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-runtime 08/22/23 04:34:58.17
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:34:58.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:34:58.186
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 08/22/23 04:34:58.189
    STEP: wait for the container to reach Succeeded 08/22/23 04:34:58.211
    STEP: get the container status 08/22/23 04:35:04.336
    STEP: the container should be terminated 08/22/23 04:35:04.34
    STEP: the termination message should be set 08/22/23 04:35:04.34
    Aug 22 04:35:04.340: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 08/22/23 04:35:04.34
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 22 04:35:04.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-6783" for this suite. 08/22/23 04:35:04.361
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:35:04.592
Aug 22 04:35:04.592: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename svcaccounts 08/22/23 04:35:04.592
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:35:04.61
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:35:04.614
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Aug 22 04:35:04.623: INFO: Got root ca configmap in namespace "svcaccounts-910"
Aug 22 04:35:04.631: INFO: Deleted root ca configmap in namespace "svcaccounts-910"
STEP: waiting for a new root ca configmap created 08/22/23 04:35:05.132
Aug 22 04:35:05.136: INFO: Recreated root ca configmap in namespace "svcaccounts-910"
Aug 22 04:35:05.142: INFO: Updated root ca configmap in namespace "svcaccounts-910"
STEP: waiting for the root ca configmap reconciled 08/22/23 04:35:05.642
Aug 22 04:35:06.121: INFO: Reconciled root ca configmap in namespace "svcaccounts-910"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 22 04:35:06.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-910" for this suite. 08/22/23 04:35:06.127
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":129,"skipped":2216,"failed":0}
------------------------------
â€¢ [1.544 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:35:04.592
    Aug 22 04:35:04.592: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename svcaccounts 08/22/23 04:35:04.592
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:35:04.61
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:35:04.614
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Aug 22 04:35:04.623: INFO: Got root ca configmap in namespace "svcaccounts-910"
    Aug 22 04:35:04.631: INFO: Deleted root ca configmap in namespace "svcaccounts-910"
    STEP: waiting for a new root ca configmap created 08/22/23 04:35:05.132
    Aug 22 04:35:05.136: INFO: Recreated root ca configmap in namespace "svcaccounts-910"
    Aug 22 04:35:05.142: INFO: Updated root ca configmap in namespace "svcaccounts-910"
    STEP: waiting for the root ca configmap reconciled 08/22/23 04:35:05.642
    Aug 22 04:35:06.121: INFO: Reconciled root ca configmap in namespace "svcaccounts-910"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 22 04:35:06.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-910" for this suite. 08/22/23 04:35:06.127
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:35:06.137
Aug 22 04:35:06.137: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename var-expansion 08/22/23 04:35:06.137
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:35:06.515
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:35:06.518
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 08/22/23 04:35:06.527
Aug 22 04:35:06.543: INFO: Waiting up to 2m0s for pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098" in namespace "var-expansion-5832" to be "running"
Aug 22 04:35:06.555: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 11.94011ms
Aug 22 04:35:08.946: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 2.402860446s
Aug 22 04:35:10.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016032334s
Aug 22 04:35:12.558: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015369389s
Aug 22 04:35:14.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016162575s
Aug 22 04:35:16.887: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 10.343651689s
Aug 22 04:35:18.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016759093s
Aug 22 04:35:20.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 14.015946317s
Aug 22 04:35:22.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 16.016140861s
Aug 22 04:35:24.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 18.016451351s
Aug 22 04:35:26.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 20.016973189s
Aug 22 04:35:29.121: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 22.577800495s
Aug 22 04:35:30.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 24.0159783s
Aug 22 04:35:32.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 26.016071905s
Aug 22 04:35:34.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 28.016988754s
Aug 22 04:35:36.678: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 30.135054323s
Aug 22 04:35:38.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 32.017049205s
Aug 22 04:35:40.562: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 34.018619901s
Aug 22 04:35:42.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 36.016334573s
Aug 22 04:35:44.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 38.017217869s
Aug 22 04:35:46.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 40.018393122s
Aug 22 04:35:48.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 42.01675142s
Aug 22 04:35:50.773: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 44.229740944s
Aug 22 04:35:52.562: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 46.018937038s
Aug 22 04:35:54.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 48.017984871s
Aug 22 04:35:56.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 50.018258593s
Aug 22 04:35:58.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 52.016030994s
Aug 22 04:36:00.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 54.01640815s
Aug 22 04:36:02.697: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 56.154072037s
Aug 22 04:36:04.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 58.017461314s
Aug 22 04:36:06.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.016594246s
Aug 22 04:36:08.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.017169294s
Aug 22 04:36:10.562: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.018608481s
Aug 22 04:36:12.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.016650738s
Aug 22 04:36:14.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.017644071s
Aug 22 04:36:16.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.016692494s
Aug 22 04:36:18.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.015540121s
Aug 22 04:36:20.828: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.285434793s
Aug 22 04:36:22.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.016181852s
Aug 22 04:36:24.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.018444136s
Aug 22 04:36:26.590: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.047001071s
Aug 22 04:36:28.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.015804291s
Aug 22 04:36:30.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.018031618s
Aug 22 04:36:32.588: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.044537583s
Aug 22 04:36:34.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.017334779s
Aug 22 04:36:36.724: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.180665879s
Aug 22 04:36:38.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.017002061s
Aug 22 04:36:40.562: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.018636286s
Aug 22 04:36:42.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.017611614s
Aug 22 04:36:44.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.018402325s
Aug 22 04:36:46.741: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.198274479s
Aug 22 04:36:48.619: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.076092263s
Aug 22 04:36:50.563: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.019764065s
Aug 22 04:36:52.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.016586772s
Aug 22 04:36:54.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.017113737s
Aug 22 04:36:56.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.016031352s
Aug 22 04:36:58.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.016915814s
Aug 22 04:37:00.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.017766103s
Aug 22 04:37:02.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.018040861s
Aug 22 04:37:04.585: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.041885462s
Aug 22 04:37:06.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.017038061s
Aug 22 04:37:06.563: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.019800153s
STEP: updating the pod 08/22/23 04:37:06.563
Aug 22 04:37:07.077: INFO: Successfully updated pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098"
STEP: waiting for pod running 08/22/23 04:37:07.077
Aug 22 04:37:07.077: INFO: Waiting up to 2m0s for pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098" in namespace "var-expansion-5832" to be "running"
Aug 22 04:37:07.081: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 3.324376ms
Aug 22 04:37:09.086: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Running", Reason="", readiness=true. Elapsed: 2.008665099s
Aug 22 04:37:09.086: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098" satisfied condition "running"
STEP: deleting the pod gracefully 08/22/23 04:37:09.086
Aug 22 04:37:09.086: INFO: Deleting pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098" in namespace "var-expansion-5832"
Aug 22 04:37:09.288: INFO: Wait up to 5m0s for pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 22 04:37:41.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5832" for this suite. 08/22/23 04:37:41.304
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":130,"skipped":2223,"failed":0}
------------------------------
â€¢ [SLOW TEST] [155.379 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:35:06.137
    Aug 22 04:35:06.137: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename var-expansion 08/22/23 04:35:06.137
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:35:06.515
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:35:06.518
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 08/22/23 04:35:06.527
    Aug 22 04:35:06.543: INFO: Waiting up to 2m0s for pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098" in namespace "var-expansion-5832" to be "running"
    Aug 22 04:35:06.555: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 11.94011ms
    Aug 22 04:35:08.946: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 2.402860446s
    Aug 22 04:35:10.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016032334s
    Aug 22 04:35:12.558: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015369389s
    Aug 22 04:35:14.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016162575s
    Aug 22 04:35:16.887: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 10.343651689s
    Aug 22 04:35:18.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016759093s
    Aug 22 04:35:20.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 14.015946317s
    Aug 22 04:35:22.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 16.016140861s
    Aug 22 04:35:24.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 18.016451351s
    Aug 22 04:35:26.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 20.016973189s
    Aug 22 04:35:29.121: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 22.577800495s
    Aug 22 04:35:30.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 24.0159783s
    Aug 22 04:35:32.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 26.016071905s
    Aug 22 04:35:34.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 28.016988754s
    Aug 22 04:35:36.678: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 30.135054323s
    Aug 22 04:35:38.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 32.017049205s
    Aug 22 04:35:40.562: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 34.018619901s
    Aug 22 04:35:42.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 36.016334573s
    Aug 22 04:35:44.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 38.017217869s
    Aug 22 04:35:46.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 40.018393122s
    Aug 22 04:35:48.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 42.01675142s
    Aug 22 04:35:50.773: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 44.229740944s
    Aug 22 04:35:52.562: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 46.018937038s
    Aug 22 04:35:54.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 48.017984871s
    Aug 22 04:35:56.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 50.018258593s
    Aug 22 04:35:58.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 52.016030994s
    Aug 22 04:36:00.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 54.01640815s
    Aug 22 04:36:02.697: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 56.154072037s
    Aug 22 04:36:04.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 58.017461314s
    Aug 22 04:36:06.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.016594246s
    Aug 22 04:36:08.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.017169294s
    Aug 22 04:36:10.562: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.018608481s
    Aug 22 04:36:12.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.016650738s
    Aug 22 04:36:14.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.017644071s
    Aug 22 04:36:16.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.016692494s
    Aug 22 04:36:18.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.015540121s
    Aug 22 04:36:20.828: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.285434793s
    Aug 22 04:36:22.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.016181852s
    Aug 22 04:36:24.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.018444136s
    Aug 22 04:36:26.590: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.047001071s
    Aug 22 04:36:28.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.015804291s
    Aug 22 04:36:30.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.018031618s
    Aug 22 04:36:32.588: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.044537583s
    Aug 22 04:36:34.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.017334779s
    Aug 22 04:36:36.724: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.180665879s
    Aug 22 04:36:38.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.017002061s
    Aug 22 04:36:40.562: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.018636286s
    Aug 22 04:36:42.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.017611614s
    Aug 22 04:36:44.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.018402325s
    Aug 22 04:36:46.741: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.198274479s
    Aug 22 04:36:48.619: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.076092263s
    Aug 22 04:36:50.563: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.019764065s
    Aug 22 04:36:52.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.016586772s
    Aug 22 04:36:54.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.017113737s
    Aug 22 04:36:56.559: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.016031352s
    Aug 22 04:36:58.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.016915814s
    Aug 22 04:37:00.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.017766103s
    Aug 22 04:37:02.561: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.018040861s
    Aug 22 04:37:04.585: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.041885462s
    Aug 22 04:37:06.560: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.017038061s
    Aug 22 04:37:06.563: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.019800153s
    STEP: updating the pod 08/22/23 04:37:06.563
    Aug 22 04:37:07.077: INFO: Successfully updated pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098"
    STEP: waiting for pod running 08/22/23 04:37:07.077
    Aug 22 04:37:07.077: INFO: Waiting up to 2m0s for pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098" in namespace "var-expansion-5832" to be "running"
    Aug 22 04:37:07.081: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Pending", Reason="", readiness=false. Elapsed: 3.324376ms
    Aug 22 04:37:09.086: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098": Phase="Running", Reason="", readiness=true. Elapsed: 2.008665099s
    Aug 22 04:37:09.086: INFO: Pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098" satisfied condition "running"
    STEP: deleting the pod gracefully 08/22/23 04:37:09.086
    Aug 22 04:37:09.086: INFO: Deleting pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098" in namespace "var-expansion-5832"
    Aug 22 04:37:09.288: INFO: Wait up to 5m0s for pod "var-expansion-f4773d64-b481-4c49-8866-8945047dc098" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 22 04:37:41.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-5832" for this suite. 08/22/23 04:37:41.304
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:37:41.516
Aug 22 04:37:41.516: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename security-context-test 08/22/23 04:37:41.517
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:37:41.651
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:37:41.654
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Aug 22 04:37:41.706: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-3cf241c7-bc2f-4bb3-973f-b1dacdec152b" in namespace "security-context-test-9616" to be "Succeeded or Failed"
Aug 22 04:37:41.830: INFO: Pod "busybox-privileged-false-3cf241c7-bc2f-4bb3-973f-b1dacdec152b": Phase="Pending", Reason="", readiness=false. Elapsed: 124.140441ms
Aug 22 04:37:43.835: INFO: Pod "busybox-privileged-false-3cf241c7-bc2f-4bb3-973f-b1dacdec152b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.128886858s
Aug 22 04:37:45.834: INFO: Pod "busybox-privileged-false-3cf241c7-bc2f-4bb3-973f-b1dacdec152b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.128297177s
Aug 22 04:37:47.835: INFO: Pod "busybox-privileged-false-3cf241c7-bc2f-4bb3-973f-b1dacdec152b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.128876849s
Aug 22 04:37:47.835: INFO: Pod "busybox-privileged-false-3cf241c7-bc2f-4bb3-973f-b1dacdec152b" satisfied condition "Succeeded or Failed"
Aug 22 04:37:47.866: INFO: Got logs for pod "busybox-privileged-false-3cf241c7-bc2f-4bb3-973f-b1dacdec152b": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 22 04:37:47.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9616" for this suite. 08/22/23 04:37:47.872
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":131,"skipped":2232,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.397 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:37:41.516
    Aug 22 04:37:41.516: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename security-context-test 08/22/23 04:37:41.517
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:37:41.651
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:37:41.654
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Aug 22 04:37:41.706: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-3cf241c7-bc2f-4bb3-973f-b1dacdec152b" in namespace "security-context-test-9616" to be "Succeeded or Failed"
    Aug 22 04:37:41.830: INFO: Pod "busybox-privileged-false-3cf241c7-bc2f-4bb3-973f-b1dacdec152b": Phase="Pending", Reason="", readiness=false. Elapsed: 124.140441ms
    Aug 22 04:37:43.835: INFO: Pod "busybox-privileged-false-3cf241c7-bc2f-4bb3-973f-b1dacdec152b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.128886858s
    Aug 22 04:37:45.834: INFO: Pod "busybox-privileged-false-3cf241c7-bc2f-4bb3-973f-b1dacdec152b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.128297177s
    Aug 22 04:37:47.835: INFO: Pod "busybox-privileged-false-3cf241c7-bc2f-4bb3-973f-b1dacdec152b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.128876849s
    Aug 22 04:37:47.835: INFO: Pod "busybox-privileged-false-3cf241c7-bc2f-4bb3-973f-b1dacdec152b" satisfied condition "Succeeded or Failed"
    Aug 22 04:37:47.866: INFO: Got logs for pod "busybox-privileged-false-3cf241c7-bc2f-4bb3-973f-b1dacdec152b": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 22 04:37:47.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-9616" for this suite. 08/22/23 04:37:47.872
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:37:47.915
Aug 22 04:37:47.915: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 04:37:47.916
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:37:47.932
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:37:47.938
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 08/22/23 04:37:47.941
Aug 22 04:37:47.962: INFO: Waiting up to 5m0s for pod "downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d" in namespace "downward-api-1501" to be "Succeeded or Failed"
Aug 22 04:37:47.971: INFO: Pod "downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.453209ms
Aug 22 04:37:49.978: INFO: Pod "downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015270724s
Aug 22 04:37:51.975: INFO: Pod "downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013067864s
Aug 22 04:37:53.974: INFO: Pod "downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011854252s
STEP: Saw pod success 08/22/23 04:37:53.974
Aug 22 04:37:53.974: INFO: Pod "downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d" satisfied condition "Succeeded or Failed"
Aug 22 04:37:53.976: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d container client-container: <nil>
STEP: delete the pod 08/22/23 04:37:53.982
Aug 22 04:37:54.020: INFO: Waiting for pod downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d to disappear
Aug 22 04:37:54.023: INFO: Pod downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 22 04:37:54.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1501" for this suite. 08/22/23 04:37:54.027
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":132,"skipped":2232,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.118 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:37:47.915
    Aug 22 04:37:47.915: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 04:37:47.916
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:37:47.932
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:37:47.938
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 08/22/23 04:37:47.941
    Aug 22 04:37:47.962: INFO: Waiting up to 5m0s for pod "downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d" in namespace "downward-api-1501" to be "Succeeded or Failed"
    Aug 22 04:37:47.971: INFO: Pod "downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.453209ms
    Aug 22 04:37:49.978: INFO: Pod "downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015270724s
    Aug 22 04:37:51.975: INFO: Pod "downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013067864s
    Aug 22 04:37:53.974: INFO: Pod "downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011854252s
    STEP: Saw pod success 08/22/23 04:37:53.974
    Aug 22 04:37:53.974: INFO: Pod "downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d" satisfied condition "Succeeded or Failed"
    Aug 22 04:37:53.976: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d container client-container: <nil>
    STEP: delete the pod 08/22/23 04:37:53.982
    Aug 22 04:37:54.020: INFO: Waiting for pod downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d to disappear
    Aug 22 04:37:54.023: INFO: Pod downwardapi-volume-35e185f5-5763-47c2-931e-066f5dd8c54d no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 22 04:37:54.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1501" for this suite. 08/22/23 04:37:54.027
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:37:54.033
Aug 22 04:37:54.033: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename subpath 08/22/23 04:37:54.034
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:37:54.049
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:37:54.051
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/22/23 04:37:54.054
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-sr5r 08/22/23 04:37:54.064
STEP: Creating a pod to test atomic-volume-subpath 08/22/23 04:37:54.064
Aug 22 04:37:54.072: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-sr5r" in namespace "subpath-5724" to be "Succeeded or Failed"
Aug 22 04:37:54.079: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Pending", Reason="", readiness=false. Elapsed: 6.593579ms
Aug 22 04:37:56.187: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114603521s
Aug 22 04:37:58.101: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 4.028870653s
Aug 22 04:38:00.102: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 6.030164874s
Aug 22 04:38:02.084: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 8.011906753s
Aug 22 04:38:04.084: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 10.011605502s
Aug 22 04:38:06.083: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 12.011133319s
Aug 22 04:38:08.083: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 14.010999463s
Aug 22 04:38:10.084: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 16.011493734s
Aug 22 04:38:12.084: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 18.011533682s
Aug 22 04:38:14.083: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 20.011353468s
Aug 22 04:38:16.083: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 22.010688685s
Aug 22 04:38:18.083: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=false. Elapsed: 24.010563923s
Aug 22 04:38:20.084: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.011724475s
STEP: Saw pod success 08/22/23 04:38:20.084
Aug 22 04:38:20.084: INFO: Pod "pod-subpath-test-projected-sr5r" satisfied condition "Succeeded or Failed"
Aug 22 04:38:20.087: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-subpath-test-projected-sr5r container test-container-subpath-projected-sr5r: <nil>
STEP: delete the pod 08/22/23 04:38:20.095
Aug 22 04:38:20.629: INFO: Waiting for pod pod-subpath-test-projected-sr5r to disappear
Aug 22 04:38:20.640: INFO: Pod pod-subpath-test-projected-sr5r no longer exists
STEP: Deleting pod pod-subpath-test-projected-sr5r 08/22/23 04:38:20.64
Aug 22 04:38:20.640: INFO: Deleting pod "pod-subpath-test-projected-sr5r" in namespace "subpath-5724"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 22 04:38:20.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5724" for this suite. 08/22/23 04:38:20.649
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":133,"skipped":2241,"failed":0}
------------------------------
â€¢ [SLOW TEST] [26.623 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:37:54.033
    Aug 22 04:37:54.033: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename subpath 08/22/23 04:37:54.034
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:37:54.049
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:37:54.051
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/22/23 04:37:54.054
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-sr5r 08/22/23 04:37:54.064
    STEP: Creating a pod to test atomic-volume-subpath 08/22/23 04:37:54.064
    Aug 22 04:37:54.072: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-sr5r" in namespace "subpath-5724" to be "Succeeded or Failed"
    Aug 22 04:37:54.079: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Pending", Reason="", readiness=false. Elapsed: 6.593579ms
    Aug 22 04:37:56.187: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114603521s
    Aug 22 04:37:58.101: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 4.028870653s
    Aug 22 04:38:00.102: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 6.030164874s
    Aug 22 04:38:02.084: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 8.011906753s
    Aug 22 04:38:04.084: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 10.011605502s
    Aug 22 04:38:06.083: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 12.011133319s
    Aug 22 04:38:08.083: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 14.010999463s
    Aug 22 04:38:10.084: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 16.011493734s
    Aug 22 04:38:12.084: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 18.011533682s
    Aug 22 04:38:14.083: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 20.011353468s
    Aug 22 04:38:16.083: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=true. Elapsed: 22.010688685s
    Aug 22 04:38:18.083: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Running", Reason="", readiness=false. Elapsed: 24.010563923s
    Aug 22 04:38:20.084: INFO: Pod "pod-subpath-test-projected-sr5r": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.011724475s
    STEP: Saw pod success 08/22/23 04:38:20.084
    Aug 22 04:38:20.084: INFO: Pod "pod-subpath-test-projected-sr5r" satisfied condition "Succeeded or Failed"
    Aug 22 04:38:20.087: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-subpath-test-projected-sr5r container test-container-subpath-projected-sr5r: <nil>
    STEP: delete the pod 08/22/23 04:38:20.095
    Aug 22 04:38:20.629: INFO: Waiting for pod pod-subpath-test-projected-sr5r to disappear
    Aug 22 04:38:20.640: INFO: Pod pod-subpath-test-projected-sr5r no longer exists
    STEP: Deleting pod pod-subpath-test-projected-sr5r 08/22/23 04:38:20.64
    Aug 22 04:38:20.640: INFO: Deleting pod "pod-subpath-test-projected-sr5r" in namespace "subpath-5724"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 22 04:38:20.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-5724" for this suite. 08/22/23 04:38:20.649
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:38:20.659
Aug 22 04:38:20.659: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename dns 08/22/23 04:38:20.66
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:38:20.688
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:38:20.691
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 08/22/23 04:38:20.695
Aug 22 04:38:20.707: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7756  5ee75da7-57cb-497e-9e60-cbb2502cac08 1263928 0 2023-08-22 04:38:20 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-08-22 04:38:20 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2rfd2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2rfd2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:38:20.707: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-7756" to be "running and ready"
Aug 22 04:38:20.732: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 25.030529ms
Aug 22 04:38:20.732: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:38:22.812: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.10425656s
Aug 22 04:38:22.812: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:38:24.737: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029886187s
Aug 22 04:38:24.737: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:38:26.739: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 6.031369754s
Aug 22 04:38:26.739: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Aug 22 04:38:26.739: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 08/22/23 04:38:26.739
Aug 22 04:38:26.739: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7756 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 04:38:26.739: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 04:38:26.740: INFO: ExecWithOptions: Clientset creation
Aug 22 04:38:26.740: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/dns-7756/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 08/22/23 04:38:26.855
Aug 22 04:38:26.855: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7756 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 04:38:26.855: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 04:38:26.856: INFO: ExecWithOptions: Clientset creation
Aug 22 04:38:26.856: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/dns-7756/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 22 04:38:26.977: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 22 04:38:27.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7756" for this suite. 08/22/23 04:38:27.029
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":134,"skipped":2254,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.378 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:38:20.659
    Aug 22 04:38:20.659: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename dns 08/22/23 04:38:20.66
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:38:20.688
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:38:20.691
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 08/22/23 04:38:20.695
    Aug 22 04:38:20.707: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7756  5ee75da7-57cb-497e-9e60-cbb2502cac08 1263928 0 2023-08-22 04:38:20 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-08-22 04:38:20 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2rfd2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2rfd2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:38:20.707: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-7756" to be "running and ready"
    Aug 22 04:38:20.732: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 25.030529ms
    Aug 22 04:38:20.732: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:38:22.812: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.10425656s
    Aug 22 04:38:22.812: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:38:24.737: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029886187s
    Aug 22 04:38:24.737: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:38:26.739: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 6.031369754s
    Aug 22 04:38:26.739: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Aug 22 04:38:26.739: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 08/22/23 04:38:26.739
    Aug 22 04:38:26.739: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7756 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 04:38:26.739: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 04:38:26.740: INFO: ExecWithOptions: Clientset creation
    Aug 22 04:38:26.740: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/dns-7756/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 08/22/23 04:38:26.855
    Aug 22 04:38:26.855: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7756 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 04:38:26.855: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 04:38:26.856: INFO: ExecWithOptions: Clientset creation
    Aug 22 04:38:26.856: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/dns-7756/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 22 04:38:26.977: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 22 04:38:27.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7756" for this suite. 08/22/23 04:38:27.029
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:38:27.037
Aug 22 04:38:27.037: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename daemonsets 08/22/23 04:38:27.038
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:38:27.157
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:38:27.161
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 08/22/23 04:38:27.183
STEP: Check that daemon pods launch on every node of the cluster. 08/22/23 04:38:27.202
Aug 22 04:38:27.206: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:27.207: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:27.207: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:27.210: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:38:27.210: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:38:28.217: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:28.217: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:28.217: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:28.220: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:38:28.220: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:38:29.282: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:29.282: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:29.282: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:29.286: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 04:38:29.286: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 04:38:30.218: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:30.218: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:30.218: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:30.236: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 04:38:30.236: INFO: Node jake-melb-gmyyva4zrlsz-node-2 is running 0 daemon pod, expected 1
Aug 22 04:38:31.218: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:31.218: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:31.218: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:31.221: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 04:38:31.221: INFO: Node jake-melb-gmyyva4zrlsz-node-2 is running 0 daemon pod, expected 1
Aug 22 04:38:32.215: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:32.215: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:32.215: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 04:38:32.218: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 22 04:38:32.218: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 08/22/23 04:38:32.224
STEP: DeleteCollection of the DaemonSets 08/22/23 04:38:32.229
STEP: Verify that ReplicaSets have been deleted 08/22/23 04:38:32.237
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Aug 22 04:38:32.245: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1264034"},"items":null}

Aug 22 04:38:32.248: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1264034"},"items":[{"metadata":{"name":"daemon-set-gvctb","generateName":"daemon-set-","namespace":"daemonsets-6349","uid":"fc7a741f-c0fc-48ff-b3e0-a78ac5c90e3b","resourceVersion":"1264003","creationTimestamp":"2023-08-22T04:38:27Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"76f1bba9-fce2-4cdc-9c0d-5ff4d3b02246","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-08-22T04:38:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"76f1bba9-fce2-4cdc-9c0d-5ff4d3b02246\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-08-22T04:38:29Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.3.98\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-bqwng","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-bqwng","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"jake-melb-gmyyva4zrlsz-node-0","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["jake-melb-gmyyva4zrlsz-node-0"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:27Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:29Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:29Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:27Z"}],"hostIP":"10.0.0.97","podIP":"10.100.3.98","podIPs":[{"ip":"10.100.3.98"}],"startTime":"2023-08-22T04:38:27Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-08-22T04:38:29Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://19642549a8c37ce0c49e0da0b6bdb54f4afb4f34d3e26d91f13d97887376bde6","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-nqlwl","generateName":"daemon-set-","namespace":"daemonsets-6349","uid":"b7b0e357-b00e-4eae-9e44-e0ba3ae21444","resourceVersion":"1264007","creationTimestamp":"2023-08-22T04:38:27Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"76f1bba9-fce2-4cdc-9c0d-5ff4d3b02246","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-08-22T04:38:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"76f1bba9-fce2-4cdc-9c0d-5ff4d3b02246\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-08-22T04:38:30Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.5.65\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-z7s2q","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-z7s2q","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"jake-melb-gmyyva4zrlsz-node-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["jake-melb-gmyyva4zrlsz-node-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:27Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:29Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:29Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:27Z"}],"hostIP":"10.0.0.232","podIP":"10.100.5.65","podIPs":[{"ip":"10.100.5.65"}],"startTime":"2023-08-22T04:38:27Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-08-22T04:38:29Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://12eadb5bd8d5995a23e3a99a4b82a7cf78934765c31597cb149a3ed140c33099","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-thxtw","generateName":"daemon-set-","namespace":"daemonsets-6349","uid":"0a0bb295-936f-4ca9-ab10-614fbbd814d2","resourceVersion":"1264021","creationTimestamp":"2023-08-22T04:38:27Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"76f1bba9-fce2-4cdc-9c0d-5ff4d3b02246","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-08-22T04:38:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"76f1bba9-fce2-4cdc-9c0d-5ff4d3b02246\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-08-22T04:38:31Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.133\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-crxhz","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-crxhz","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"jake-melb-gmyyva4zrlsz-node-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["jake-melb-gmyyva4zrlsz-node-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:27Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:31Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:31Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:27Z"}],"hostIP":"10.0.0.130","podIP":"10.100.4.133","podIPs":[{"ip":"10.100.4.133"}],"startTime":"2023-08-22T04:38:27Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-08-22T04:38:30Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://d4ab55275a680c77025bc017c9372ac46b42a6def91f4b56ceae862e05626696","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 22 04:38:32.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6349" for this suite. 08/22/23 04:38:32.267
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":135,"skipped":2264,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.240 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:38:27.037
    Aug 22 04:38:27.037: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename daemonsets 08/22/23 04:38:27.038
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:38:27.157
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:38:27.161
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 08/22/23 04:38:27.183
    STEP: Check that daemon pods launch on every node of the cluster. 08/22/23 04:38:27.202
    Aug 22 04:38:27.206: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:27.207: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:27.207: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:27.210: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:38:27.210: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:38:28.217: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:28.217: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:28.217: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:28.220: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:38:28.220: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:38:29.282: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:29.282: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:29.282: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:29.286: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 04:38:29.286: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 04:38:30.218: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:30.218: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:30.218: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:30.236: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 04:38:30.236: INFO: Node jake-melb-gmyyva4zrlsz-node-2 is running 0 daemon pod, expected 1
    Aug 22 04:38:31.218: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:31.218: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:31.218: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:31.221: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 04:38:31.221: INFO: Node jake-melb-gmyyva4zrlsz-node-2 is running 0 daemon pod, expected 1
    Aug 22 04:38:32.215: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:32.215: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:32.215: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 04:38:32.218: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 22 04:38:32.218: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 08/22/23 04:38:32.224
    STEP: DeleteCollection of the DaemonSets 08/22/23 04:38:32.229
    STEP: Verify that ReplicaSets have been deleted 08/22/23 04:38:32.237
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Aug 22 04:38:32.245: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1264034"},"items":null}

    Aug 22 04:38:32.248: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1264034"},"items":[{"metadata":{"name":"daemon-set-gvctb","generateName":"daemon-set-","namespace":"daemonsets-6349","uid":"fc7a741f-c0fc-48ff-b3e0-a78ac5c90e3b","resourceVersion":"1264003","creationTimestamp":"2023-08-22T04:38:27Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"76f1bba9-fce2-4cdc-9c0d-5ff4d3b02246","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-08-22T04:38:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"76f1bba9-fce2-4cdc-9c0d-5ff4d3b02246\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-08-22T04:38:29Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.3.98\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-bqwng","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-bqwng","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"jake-melb-gmyyva4zrlsz-node-0","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["jake-melb-gmyyva4zrlsz-node-0"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:27Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:29Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:29Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:27Z"}],"hostIP":"10.0.0.97","podIP":"10.100.3.98","podIPs":[{"ip":"10.100.3.98"}],"startTime":"2023-08-22T04:38:27Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-08-22T04:38:29Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://19642549a8c37ce0c49e0da0b6bdb54f4afb4f34d3e26d91f13d97887376bde6","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-nqlwl","generateName":"daemon-set-","namespace":"daemonsets-6349","uid":"b7b0e357-b00e-4eae-9e44-e0ba3ae21444","resourceVersion":"1264007","creationTimestamp":"2023-08-22T04:38:27Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"76f1bba9-fce2-4cdc-9c0d-5ff4d3b02246","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-08-22T04:38:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"76f1bba9-fce2-4cdc-9c0d-5ff4d3b02246\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-08-22T04:38:30Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.5.65\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-z7s2q","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-z7s2q","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"jake-melb-gmyyva4zrlsz-node-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["jake-melb-gmyyva4zrlsz-node-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:27Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:29Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:29Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:27Z"}],"hostIP":"10.0.0.232","podIP":"10.100.5.65","podIPs":[{"ip":"10.100.5.65"}],"startTime":"2023-08-22T04:38:27Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-08-22T04:38:29Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://12eadb5bd8d5995a23e3a99a4b82a7cf78934765c31597cb149a3ed140c33099","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-thxtw","generateName":"daemon-set-","namespace":"daemonsets-6349","uid":"0a0bb295-936f-4ca9-ab10-614fbbd814d2","resourceVersion":"1264021","creationTimestamp":"2023-08-22T04:38:27Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"76f1bba9-fce2-4cdc-9c0d-5ff4d3b02246","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-08-22T04:38:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"76f1bba9-fce2-4cdc-9c0d-5ff4d3b02246\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-08-22T04:38:31Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.133\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-crxhz","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-crxhz","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"jake-melb-gmyyva4zrlsz-node-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["jake-melb-gmyyva4zrlsz-node-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:27Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:31Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:31Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-08-22T04:38:27Z"}],"hostIP":"10.0.0.130","podIP":"10.100.4.133","podIPs":[{"ip":"10.100.4.133"}],"startTime":"2023-08-22T04:38:27Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-08-22T04:38:30Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://d4ab55275a680c77025bc017c9372ac46b42a6def91f4b56ceae862e05626696","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 04:38:32.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-6349" for this suite. 08/22/23 04:38:32.267
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:38:32.279
Aug 22 04:38:32.279: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename security-context 08/22/23 04:38:32.279
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:38:32.301
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:38:32.304
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 08/22/23 04:38:32.308
Aug 22 04:38:32.317: INFO: Waiting up to 5m0s for pod "security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062" in namespace "security-context-1074" to be "Succeeded or Failed"
Aug 22 04:38:32.321: INFO: Pod "security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062": Phase="Pending", Reason="", readiness=false. Elapsed: 3.841607ms
Aug 22 04:38:34.327: INFO: Pod "security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009921987s
Aug 22 04:38:36.325: INFO: Pod "security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007851187s
Aug 22 04:38:38.333: INFO: Pod "security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01610219s
STEP: Saw pod success 08/22/23 04:38:38.334
Aug 22 04:38:38.334: INFO: Pod "security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062" satisfied condition "Succeeded or Failed"
Aug 22 04:38:38.339: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062 container test-container: <nil>
STEP: delete the pod 08/22/23 04:38:38.344
Aug 22 04:38:38.649: INFO: Waiting for pod security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062 to disappear
Aug 22 04:38:38.653: INFO: Pod security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 22 04:38:38.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-1074" for this suite. 08/22/23 04:38:38.658
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":136,"skipped":2315,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.391 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:38:32.279
    Aug 22 04:38:32.279: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename security-context 08/22/23 04:38:32.279
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:38:32.301
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:38:32.304
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 08/22/23 04:38:32.308
    Aug 22 04:38:32.317: INFO: Waiting up to 5m0s for pod "security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062" in namespace "security-context-1074" to be "Succeeded or Failed"
    Aug 22 04:38:32.321: INFO: Pod "security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062": Phase="Pending", Reason="", readiness=false. Elapsed: 3.841607ms
    Aug 22 04:38:34.327: INFO: Pod "security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009921987s
    Aug 22 04:38:36.325: INFO: Pod "security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007851187s
    Aug 22 04:38:38.333: INFO: Pod "security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01610219s
    STEP: Saw pod success 08/22/23 04:38:38.334
    Aug 22 04:38:38.334: INFO: Pod "security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062" satisfied condition "Succeeded or Failed"
    Aug 22 04:38:38.339: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062 container test-container: <nil>
    STEP: delete the pod 08/22/23 04:38:38.344
    Aug 22 04:38:38.649: INFO: Waiting for pod security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062 to disappear
    Aug 22 04:38:38.653: INFO: Pod security-context-b9fe1a61-4b4b-4e7c-a3ee-2d733b625062 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 22 04:38:38.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-1074" for this suite. 08/22/23 04:38:38.658
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:38:38.675
Aug 22 04:38:38.675: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:38:38.676
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:38:38.698
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:38:38.7
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-8fa94a5c-f304-4059-8c6c-44bae088ee6d 08/22/23 04:38:38.708
STEP: Creating secret with name s-test-opt-upd-8fce1ba6-2348-4e2a-9960-d8b99363d49e 08/22/23 04:38:38.713
STEP: Creating the pod 08/22/23 04:38:38.719
Aug 22 04:38:38.736: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe" in namespace "projected-8012" to be "running and ready"
Aug 22 04:38:38.741: INFO: Pod "pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.471506ms
Aug 22 04:38:38.741: INFO: The phase of Pod pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:38:40.745: INFO: Pod "pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009700062s
Aug 22 04:38:40.746: INFO: The phase of Pod pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:38:42.746: INFO: Pod "pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010406129s
Aug 22 04:38:42.746: INFO: The phase of Pod pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:38:44.747: INFO: Pod "pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe": Phase="Running", Reason="", readiness=true. Elapsed: 6.010966525s
Aug 22 04:38:44.747: INFO: The phase of Pod pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe is Running (Ready = true)
Aug 22 04:38:44.747: INFO: Pod "pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-8fa94a5c-f304-4059-8c6c-44bae088ee6d 08/22/23 04:38:44.763
STEP: Updating secret s-test-opt-upd-8fce1ba6-2348-4e2a-9960-d8b99363d49e 08/22/23 04:38:44.77
STEP: Creating secret with name s-test-opt-create-4b24ea38-c0f8-434b-9087-c398ed1dfb65 08/22/23 04:38:44.776
STEP: waiting to observe update in volume 08/22/23 04:38:44.78
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 22 04:39:58.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8012" for this suite. 08/22/23 04:39:58.215
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":137,"skipped":2332,"failed":0}
------------------------------
â€¢ [SLOW TEST] [79.549 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:38:38.675
    Aug 22 04:38:38.675: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:38:38.676
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:38:38.698
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:38:38.7
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-8fa94a5c-f304-4059-8c6c-44bae088ee6d 08/22/23 04:38:38.708
    STEP: Creating secret with name s-test-opt-upd-8fce1ba6-2348-4e2a-9960-d8b99363d49e 08/22/23 04:38:38.713
    STEP: Creating the pod 08/22/23 04:38:38.719
    Aug 22 04:38:38.736: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe" in namespace "projected-8012" to be "running and ready"
    Aug 22 04:38:38.741: INFO: Pod "pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.471506ms
    Aug 22 04:38:38.741: INFO: The phase of Pod pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:38:40.745: INFO: Pod "pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009700062s
    Aug 22 04:38:40.746: INFO: The phase of Pod pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:38:42.746: INFO: Pod "pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010406129s
    Aug 22 04:38:42.746: INFO: The phase of Pod pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:38:44.747: INFO: Pod "pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe": Phase="Running", Reason="", readiness=true. Elapsed: 6.010966525s
    Aug 22 04:38:44.747: INFO: The phase of Pod pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe is Running (Ready = true)
    Aug 22 04:38:44.747: INFO: Pod "pod-projected-secrets-fc4e3fe6-fda4-411f-b7d4-352f9c5d1cbe" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-8fa94a5c-f304-4059-8c6c-44bae088ee6d 08/22/23 04:38:44.763
    STEP: Updating secret s-test-opt-upd-8fce1ba6-2348-4e2a-9960-d8b99363d49e 08/22/23 04:38:44.77
    STEP: Creating secret with name s-test-opt-create-4b24ea38-c0f8-434b-9087-c398ed1dfb65 08/22/23 04:38:44.776
    STEP: waiting to observe update in volume 08/22/23 04:38:44.78
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 22 04:39:58.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8012" for this suite. 08/22/23 04:39:58.215
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:39:58.226
Aug 22 04:39:58.226: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename security-context 08/22/23 04:39:58.226
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:39:58.295
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:39:58.299
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 08/22/23 04:39:58.305
Aug 22 04:39:58.350: INFO: Waiting up to 5m0s for pod "security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2" in namespace "security-context-7454" to be "Succeeded or Failed"
Aug 22 04:39:58.360: INFO: Pod "security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.257505ms
Aug 22 04:40:00.423: INFO: Pod "security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073789521s
Aug 22 04:40:02.365: INFO: Pod "security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015655029s
Aug 22 04:40:04.485: INFO: Pod "security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.134986639s
STEP: Saw pod success 08/22/23 04:40:04.485
Aug 22 04:40:04.485: INFO: Pod "security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2" satisfied condition "Succeeded or Failed"
Aug 22 04:40:04.491: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2 container test-container: <nil>
STEP: delete the pod 08/22/23 04:40:04.529
Aug 22 04:40:04.852: INFO: Waiting for pod security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2 to disappear
Aug 22 04:40:04.856: INFO: Pod security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 22 04:40:04.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-7454" for this suite. 08/22/23 04:40:04.86
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":138,"skipped":2385,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.740 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:39:58.226
    Aug 22 04:39:58.226: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename security-context 08/22/23 04:39:58.226
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:39:58.295
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:39:58.299
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 08/22/23 04:39:58.305
    Aug 22 04:39:58.350: INFO: Waiting up to 5m0s for pod "security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2" in namespace "security-context-7454" to be "Succeeded or Failed"
    Aug 22 04:39:58.360: INFO: Pod "security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.257505ms
    Aug 22 04:40:00.423: INFO: Pod "security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073789521s
    Aug 22 04:40:02.365: INFO: Pod "security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015655029s
    Aug 22 04:40:04.485: INFO: Pod "security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.134986639s
    STEP: Saw pod success 08/22/23 04:40:04.485
    Aug 22 04:40:04.485: INFO: Pod "security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2" satisfied condition "Succeeded or Failed"
    Aug 22 04:40:04.491: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2 container test-container: <nil>
    STEP: delete the pod 08/22/23 04:40:04.529
    Aug 22 04:40:04.852: INFO: Waiting for pod security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2 to disappear
    Aug 22 04:40:04.856: INFO: Pod security-context-fdf3f5ea-796a-4145-9a71-826b2c9910b2 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 22 04:40:04.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-7454" for this suite. 08/22/23 04:40:04.86
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:40:04.966
Aug 22 04:40:04.966: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 04:40:04.967
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:05.088
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:05.092
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 08/22/23 04:40:05.095
Aug 22 04:40:05.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Aug 22 04:40:05.681: INFO: stderr: ""
Aug 22 04:40:05.681: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 08/22/23 04:40:05.681
Aug 22 04:40:05.681: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Aug 22 04:40:05.681: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-6691" to be "running and ready, or succeeded"
Aug 22 04:40:06.206: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 524.998593ms
Aug 22 04:40:06.206: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'jake-melb-gmyyva4zrlsz-node-0' to be 'Running' but was 'Pending'
Aug 22 04:40:08.211: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.529657757s
Aug 22 04:40:08.211: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'jake-melb-gmyyva4zrlsz-node-0' to be 'Running' but was 'Pending'
Aug 22 04:40:10.210: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.52866557s
Aug 22 04:40:10.210: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Aug 22 04:40:10.210: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 08/22/23 04:40:10.21
Aug 22 04:40:10.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 logs logs-generator logs-generator'
Aug 22 04:40:10.276: INFO: stderr: ""
Aug 22 04:40:10.276: INFO: stdout: "I0822 04:40:08.589466       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/dr8 512\nI0822 04:40:08.789543       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/bdv 242\nI0822 04:40:08.990168       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/lnf 528\nI0822 04:40:09.190307       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/2lsr 544\nI0822 04:40:09.389523       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/5j9 285\nI0822 04:40:09.590014       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/k7c7 366\nI0822 04:40:09.790140       1 logs_generator.go:76] 6 POST /api/v1/namespaces/default/pods/bl97 368\nI0822 04:40:09.990399       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/d99 555\nI0822 04:40:10.189722       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/qcs 462\n"
STEP: limiting log lines 08/22/23 04:40:10.276
Aug 22 04:40:10.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 logs logs-generator logs-generator --tail=1'
Aug 22 04:40:10.336: INFO: stderr: ""
Aug 22 04:40:10.336: INFO: stdout: "I0822 04:40:10.189722       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/qcs 462\n"
Aug 22 04:40:10.336: INFO: got output "I0822 04:40:10.189722       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/qcs 462\n"
STEP: limiting log bytes 08/22/23 04:40:10.336
Aug 22 04:40:10.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 logs logs-generator logs-generator --limit-bytes=1'
Aug 22 04:40:10.420: INFO: stderr: ""
Aug 22 04:40:10.420: INFO: stdout: "I"
Aug 22 04:40:10.420: INFO: got output "I"
STEP: exposing timestamps 08/22/23 04:40:10.42
Aug 22 04:40:10.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 logs logs-generator logs-generator --tail=1 --timestamps'
Aug 22 04:40:10.523: INFO: stderr: ""
Aug 22 04:40:10.523: INFO: stdout: "2023-08-22T04:40:10.390171358Z I0822 04:40:10.390031       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/46zk 590\n"
Aug 22 04:40:10.523: INFO: got output "2023-08-22T04:40:10.390171358Z I0822 04:40:10.390031       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/46zk 590\n"
STEP: restricting to a time range 08/22/23 04:40:10.523
Aug 22 04:40:13.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 logs logs-generator logs-generator --since=1s'
Aug 22 04:40:13.089: INFO: stderr: ""
Aug 22 04:40:13.089: INFO: stdout: "I0822 04:40:12.190007       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/zfnm 531\nI0822 04:40:12.390397       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/px7l 324\nI0822 04:40:12.589922       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/vfv 275\nI0822 04:40:12.790233       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/spvw 254\nI0822 04:40:12.989478       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/ns/pods/fkm 389\n"
Aug 22 04:40:13.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 logs logs-generator logs-generator --since=24h'
Aug 22 04:40:13.147: INFO: stderr: ""
Aug 22 04:40:13.147: INFO: stdout: "I0822 04:40:08.589466       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/dr8 512\nI0822 04:40:08.789543       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/bdv 242\nI0822 04:40:08.990168       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/lnf 528\nI0822 04:40:09.190307       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/2lsr 544\nI0822 04:40:09.389523       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/5j9 285\nI0822 04:40:09.590014       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/k7c7 366\nI0822 04:40:09.790140       1 logs_generator.go:76] 6 POST /api/v1/namespaces/default/pods/bl97 368\nI0822 04:40:09.990399       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/d99 555\nI0822 04:40:10.189722       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/qcs 462\nI0822 04:40:10.390031       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/46zk 590\nI0822 04:40:10.590334       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/nq6 437\nI0822 04:40:10.789592       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/zsd 230\nI0822 04:40:10.989859       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/85c 309\nI0822 04:40:11.190311       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/h4b 247\nI0822 04:40:11.389572       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/6bf 371\nI0822 04:40:11.589852       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/nz79 441\nI0822 04:40:11.790381       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/mlr 480\nI0822 04:40:11.989711       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/rgxs 522\nI0822 04:40:12.190007       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/zfnm 531\nI0822 04:40:12.390397       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/px7l 324\nI0822 04:40:12.589922       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/vfv 275\nI0822 04:40:12.790233       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/spvw 254\nI0822 04:40:12.989478       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/ns/pods/fkm 389\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Aug 22 04:40:13.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 delete pod logs-generator'
Aug 22 04:40:14.783: INFO: stderr: ""
Aug 22 04:40:14.783: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 04:40:14.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6691" for this suite. 08/22/23 04:40:14.787
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":139,"skipped":2388,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.829 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:40:04.966
    Aug 22 04:40:04.966: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 04:40:04.967
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:05.088
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:05.092
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 08/22/23 04:40:05.095
    Aug 22 04:40:05.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Aug 22 04:40:05.681: INFO: stderr: ""
    Aug 22 04:40:05.681: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 08/22/23 04:40:05.681
    Aug 22 04:40:05.681: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Aug 22 04:40:05.681: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-6691" to be "running and ready, or succeeded"
    Aug 22 04:40:06.206: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 524.998593ms
    Aug 22 04:40:06.206: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'jake-melb-gmyyva4zrlsz-node-0' to be 'Running' but was 'Pending'
    Aug 22 04:40:08.211: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.529657757s
    Aug 22 04:40:08.211: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'jake-melb-gmyyva4zrlsz-node-0' to be 'Running' but was 'Pending'
    Aug 22 04:40:10.210: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.52866557s
    Aug 22 04:40:10.210: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Aug 22 04:40:10.210: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 08/22/23 04:40:10.21
    Aug 22 04:40:10.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 logs logs-generator logs-generator'
    Aug 22 04:40:10.276: INFO: stderr: ""
    Aug 22 04:40:10.276: INFO: stdout: "I0822 04:40:08.589466       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/dr8 512\nI0822 04:40:08.789543       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/bdv 242\nI0822 04:40:08.990168       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/lnf 528\nI0822 04:40:09.190307       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/2lsr 544\nI0822 04:40:09.389523       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/5j9 285\nI0822 04:40:09.590014       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/k7c7 366\nI0822 04:40:09.790140       1 logs_generator.go:76] 6 POST /api/v1/namespaces/default/pods/bl97 368\nI0822 04:40:09.990399       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/d99 555\nI0822 04:40:10.189722       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/qcs 462\n"
    STEP: limiting log lines 08/22/23 04:40:10.276
    Aug 22 04:40:10.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 logs logs-generator logs-generator --tail=1'
    Aug 22 04:40:10.336: INFO: stderr: ""
    Aug 22 04:40:10.336: INFO: stdout: "I0822 04:40:10.189722       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/qcs 462\n"
    Aug 22 04:40:10.336: INFO: got output "I0822 04:40:10.189722       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/qcs 462\n"
    STEP: limiting log bytes 08/22/23 04:40:10.336
    Aug 22 04:40:10.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 logs logs-generator logs-generator --limit-bytes=1'
    Aug 22 04:40:10.420: INFO: stderr: ""
    Aug 22 04:40:10.420: INFO: stdout: "I"
    Aug 22 04:40:10.420: INFO: got output "I"
    STEP: exposing timestamps 08/22/23 04:40:10.42
    Aug 22 04:40:10.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 logs logs-generator logs-generator --tail=1 --timestamps'
    Aug 22 04:40:10.523: INFO: stderr: ""
    Aug 22 04:40:10.523: INFO: stdout: "2023-08-22T04:40:10.390171358Z I0822 04:40:10.390031       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/46zk 590\n"
    Aug 22 04:40:10.523: INFO: got output "2023-08-22T04:40:10.390171358Z I0822 04:40:10.390031       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/46zk 590\n"
    STEP: restricting to a time range 08/22/23 04:40:10.523
    Aug 22 04:40:13.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 logs logs-generator logs-generator --since=1s'
    Aug 22 04:40:13.089: INFO: stderr: ""
    Aug 22 04:40:13.089: INFO: stdout: "I0822 04:40:12.190007       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/zfnm 531\nI0822 04:40:12.390397       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/px7l 324\nI0822 04:40:12.589922       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/vfv 275\nI0822 04:40:12.790233       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/spvw 254\nI0822 04:40:12.989478       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/ns/pods/fkm 389\n"
    Aug 22 04:40:13.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 logs logs-generator logs-generator --since=24h'
    Aug 22 04:40:13.147: INFO: stderr: ""
    Aug 22 04:40:13.147: INFO: stdout: "I0822 04:40:08.589466       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/dr8 512\nI0822 04:40:08.789543       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/bdv 242\nI0822 04:40:08.990168       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/lnf 528\nI0822 04:40:09.190307       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/2lsr 544\nI0822 04:40:09.389523       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/5j9 285\nI0822 04:40:09.590014       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/k7c7 366\nI0822 04:40:09.790140       1 logs_generator.go:76] 6 POST /api/v1/namespaces/default/pods/bl97 368\nI0822 04:40:09.990399       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/d99 555\nI0822 04:40:10.189722       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/qcs 462\nI0822 04:40:10.390031       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/46zk 590\nI0822 04:40:10.590334       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/nq6 437\nI0822 04:40:10.789592       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/zsd 230\nI0822 04:40:10.989859       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/85c 309\nI0822 04:40:11.190311       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/h4b 247\nI0822 04:40:11.389572       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/6bf 371\nI0822 04:40:11.589852       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/nz79 441\nI0822 04:40:11.790381       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/mlr 480\nI0822 04:40:11.989711       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/rgxs 522\nI0822 04:40:12.190007       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/zfnm 531\nI0822 04:40:12.390397       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/px7l 324\nI0822 04:40:12.589922       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/vfv 275\nI0822 04:40:12.790233       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/spvw 254\nI0822 04:40:12.989478       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/ns/pods/fkm 389\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Aug 22 04:40:13.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6691 delete pod logs-generator'
    Aug 22 04:40:14.783: INFO: stderr: ""
    Aug 22 04:40:14.783: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 04:40:14.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6691" for this suite. 08/22/23 04:40:14.787
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:40:14.795
Aug 22 04:40:14.795: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 04:40:14.796
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:14.811
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:14.814
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 08/22/23 04:40:14.818
Aug 22 04:40:14.826: INFO: Waiting up to 5m0s for pod "pod-1da86bce-6c3b-45b3-9282-164fe08c262d" in namespace "emptydir-5912" to be "Succeeded or Failed"
Aug 22 04:40:14.835: INFO: Pod "pod-1da86bce-6c3b-45b3-9282-164fe08c262d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.597756ms
Aug 22 04:40:16.841: INFO: Pod "pod-1da86bce-6c3b-45b3-9282-164fe08c262d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015598828s
Aug 22 04:40:18.840: INFO: Pod "pod-1da86bce-6c3b-45b3-9282-164fe08c262d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014336603s
Aug 22 04:40:20.841: INFO: Pod "pod-1da86bce-6c3b-45b3-9282-164fe08c262d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014792313s
STEP: Saw pod success 08/22/23 04:40:20.841
Aug 22 04:40:20.841: INFO: Pod "pod-1da86bce-6c3b-45b3-9282-164fe08c262d" satisfied condition "Succeeded or Failed"
Aug 22 04:40:20.843: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-1da86bce-6c3b-45b3-9282-164fe08c262d container test-container: <nil>
STEP: delete the pod 08/22/23 04:40:20.849
Aug 22 04:40:21.052: INFO: Waiting for pod pod-1da86bce-6c3b-45b3-9282-164fe08c262d to disappear
Aug 22 04:40:21.055: INFO: Pod pod-1da86bce-6c3b-45b3-9282-164fe08c262d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 04:40:21.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5912" for this suite. 08/22/23 04:40:21.059
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":140,"skipped":2406,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.272 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:40:14.795
    Aug 22 04:40:14.795: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 04:40:14.796
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:14.811
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:14.814
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 08/22/23 04:40:14.818
    Aug 22 04:40:14.826: INFO: Waiting up to 5m0s for pod "pod-1da86bce-6c3b-45b3-9282-164fe08c262d" in namespace "emptydir-5912" to be "Succeeded or Failed"
    Aug 22 04:40:14.835: INFO: Pod "pod-1da86bce-6c3b-45b3-9282-164fe08c262d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.597756ms
    Aug 22 04:40:16.841: INFO: Pod "pod-1da86bce-6c3b-45b3-9282-164fe08c262d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015598828s
    Aug 22 04:40:18.840: INFO: Pod "pod-1da86bce-6c3b-45b3-9282-164fe08c262d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014336603s
    Aug 22 04:40:20.841: INFO: Pod "pod-1da86bce-6c3b-45b3-9282-164fe08c262d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014792313s
    STEP: Saw pod success 08/22/23 04:40:20.841
    Aug 22 04:40:20.841: INFO: Pod "pod-1da86bce-6c3b-45b3-9282-164fe08c262d" satisfied condition "Succeeded or Failed"
    Aug 22 04:40:20.843: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-1da86bce-6c3b-45b3-9282-164fe08c262d container test-container: <nil>
    STEP: delete the pod 08/22/23 04:40:20.849
    Aug 22 04:40:21.052: INFO: Waiting for pod pod-1da86bce-6c3b-45b3-9282-164fe08c262d to disappear
    Aug 22 04:40:21.055: INFO: Pod pod-1da86bce-6c3b-45b3-9282-164fe08c262d no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 04:40:21.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5912" for this suite. 08/22/23 04:40:21.059
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:40:21.07
Aug 22 04:40:21.070: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename resourcequota 08/22/23 04:40:21.071
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:21.088
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:21.091
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 08/22/23 04:40:21.095
STEP: Creating a ResourceQuota 08/22/23 04:40:26.1
STEP: Ensuring resource quota status is calculated 08/22/23 04:40:26.335
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 22 04:40:28.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7575" for this suite. 08/22/23 04:40:28.346
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":141,"skipped":2441,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.282 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:40:21.07
    Aug 22 04:40:21.070: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename resourcequota 08/22/23 04:40:21.071
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:21.088
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:21.091
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 08/22/23 04:40:21.095
    STEP: Creating a ResourceQuota 08/22/23 04:40:26.1
    STEP: Ensuring resource quota status is calculated 08/22/23 04:40:26.335
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 22 04:40:28.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7575" for this suite. 08/22/23 04:40:28.346
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:40:28.353
Aug 22 04:40:28.353: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename secrets 08/22/23 04:40:28.354
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:28.689
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:28.692
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-548dd48b-e0ff-470e-9b6d-f22a6d479e23 08/22/23 04:40:28.696
STEP: Creating a pod to test consume secrets 08/22/23 04:40:28.808
Aug 22 04:40:28.816: INFO: Waiting up to 5m0s for pod "pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc" in namespace "secrets-2002" to be "Succeeded or Failed"
Aug 22 04:40:28.820: INFO: Pod "pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.482964ms
Aug 22 04:40:30.825: INFO: Pod "pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008757903s
Aug 22 04:40:32.840: INFO: Pod "pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023334343s
Aug 22 04:40:34.923: INFO: Pod "pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.106796742s
STEP: Saw pod success 08/22/23 04:40:34.923
Aug 22 04:40:34.923: INFO: Pod "pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc" satisfied condition "Succeeded or Failed"
Aug 22 04:40:34.926: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc container secret-volume-test: <nil>
STEP: delete the pod 08/22/23 04:40:34.934
Aug 22 04:40:35.606: INFO: Waiting for pod pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc to disappear
Aug 22 04:40:35.610: INFO: Pod pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 22 04:40:35.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2002" for this suite. 08/22/23 04:40:35.614
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":142,"skipped":2457,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.394 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:40:28.353
    Aug 22 04:40:28.353: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename secrets 08/22/23 04:40:28.354
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:28.689
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:28.692
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-548dd48b-e0ff-470e-9b6d-f22a6d479e23 08/22/23 04:40:28.696
    STEP: Creating a pod to test consume secrets 08/22/23 04:40:28.808
    Aug 22 04:40:28.816: INFO: Waiting up to 5m0s for pod "pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc" in namespace "secrets-2002" to be "Succeeded or Failed"
    Aug 22 04:40:28.820: INFO: Pod "pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.482964ms
    Aug 22 04:40:30.825: INFO: Pod "pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008757903s
    Aug 22 04:40:32.840: INFO: Pod "pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023334343s
    Aug 22 04:40:34.923: INFO: Pod "pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.106796742s
    STEP: Saw pod success 08/22/23 04:40:34.923
    Aug 22 04:40:34.923: INFO: Pod "pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc" satisfied condition "Succeeded or Failed"
    Aug 22 04:40:34.926: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc container secret-volume-test: <nil>
    STEP: delete the pod 08/22/23 04:40:34.934
    Aug 22 04:40:35.606: INFO: Waiting for pod pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc to disappear
    Aug 22 04:40:35.610: INFO: Pod pod-secrets-46d43108-f5b7-4887-9596-9bbae82203cc no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 22 04:40:35.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2002" for this suite. 08/22/23 04:40:35.614
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:40:35.749
Aug 22 04:40:35.749: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:40:35.749
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:35.892
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:35.895
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-0598116a-aa4a-46d5-a4b7-a87238721ccb 08/22/23 04:40:35.898
STEP: Creating a pod to test consume secrets 08/22/23 04:40:35.902
Aug 22 04:40:35.960: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755" in namespace "projected-3418" to be "Succeeded or Failed"
Aug 22 04:40:35.967: INFO: Pod "pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755": Phase="Pending", Reason="", readiness=false. Elapsed: 6.397693ms
Aug 22 04:40:37.971: INFO: Pod "pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01026351s
Aug 22 04:40:39.971: INFO: Pod "pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755": Phase="Running", Reason="", readiness=true. Elapsed: 4.010564077s
Aug 22 04:40:41.972: INFO: Pod "pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755": Phase="Running", Reason="", readiness=false. Elapsed: 6.011292488s
Aug 22 04:40:43.971: INFO: Pod "pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.011171794s
STEP: Saw pod success 08/22/23 04:40:43.971
Aug 22 04:40:43.972: INFO: Pod "pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755" satisfied condition "Succeeded or Failed"
Aug 22 04:40:43.974: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755 container projected-secret-volume-test: <nil>
STEP: delete the pod 08/22/23 04:40:43.981
Aug 22 04:40:44.012: INFO: Waiting for pod pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755 to disappear
Aug 22 04:40:44.015: INFO: Pod pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 22 04:40:44.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3418" for this suite. 08/22/23 04:40:44.019
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":143,"skipped":2481,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.279 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:40:35.749
    Aug 22 04:40:35.749: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:40:35.749
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:35.892
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:35.895
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-0598116a-aa4a-46d5-a4b7-a87238721ccb 08/22/23 04:40:35.898
    STEP: Creating a pod to test consume secrets 08/22/23 04:40:35.902
    Aug 22 04:40:35.960: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755" in namespace "projected-3418" to be "Succeeded or Failed"
    Aug 22 04:40:35.967: INFO: Pod "pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755": Phase="Pending", Reason="", readiness=false. Elapsed: 6.397693ms
    Aug 22 04:40:37.971: INFO: Pod "pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01026351s
    Aug 22 04:40:39.971: INFO: Pod "pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755": Phase="Running", Reason="", readiness=true. Elapsed: 4.010564077s
    Aug 22 04:40:41.972: INFO: Pod "pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755": Phase="Running", Reason="", readiness=false. Elapsed: 6.011292488s
    Aug 22 04:40:43.971: INFO: Pod "pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.011171794s
    STEP: Saw pod success 08/22/23 04:40:43.971
    Aug 22 04:40:43.972: INFO: Pod "pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755" satisfied condition "Succeeded or Failed"
    Aug 22 04:40:43.974: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755 container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/22/23 04:40:43.981
    Aug 22 04:40:44.012: INFO: Waiting for pod pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755 to disappear
    Aug 22 04:40:44.015: INFO: Pod pod-projected-secrets-d3214d8f-b9c9-416a-9d74-f8166e62d755 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 22 04:40:44.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3418" for this suite. 08/22/23 04:40:44.019
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:40:44.029
Aug 22 04:40:44.029: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:40:44.029
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:44.051
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:44.053
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-c7ff5703-9638-42eb-a3e0-b75934238ba3 08/22/23 04:40:44.058
STEP: Creating a pod to test consume secrets 08/22/23 04:40:44.065
Aug 22 04:40:44.074: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9" in namespace "projected-3038" to be "Succeeded or Failed"
Aug 22 04:40:44.078: INFO: Pod "pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.53909ms
Aug 22 04:40:46.082: INFO: Pod "pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007835454s
Aug 22 04:40:48.082: INFO: Pod "pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007526568s
Aug 22 04:40:50.084: INFO: Pod "pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009674612s
STEP: Saw pod success 08/22/23 04:40:50.084
Aug 22 04:40:50.084: INFO: Pod "pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9" satisfied condition "Succeeded or Failed"
Aug 22 04:40:50.087: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9 container projected-secret-volume-test: <nil>
STEP: delete the pod 08/22/23 04:40:50.094
Aug 22 04:40:50.132: INFO: Waiting for pod pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9 to disappear
Aug 22 04:40:50.136: INFO: Pod pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 22 04:40:50.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3038" for this suite. 08/22/23 04:40:50.14
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":144,"skipped":2494,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.119 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:40:44.029
    Aug 22 04:40:44.029: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:40:44.029
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:44.051
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:44.053
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-c7ff5703-9638-42eb-a3e0-b75934238ba3 08/22/23 04:40:44.058
    STEP: Creating a pod to test consume secrets 08/22/23 04:40:44.065
    Aug 22 04:40:44.074: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9" in namespace "projected-3038" to be "Succeeded or Failed"
    Aug 22 04:40:44.078: INFO: Pod "pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.53909ms
    Aug 22 04:40:46.082: INFO: Pod "pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007835454s
    Aug 22 04:40:48.082: INFO: Pod "pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007526568s
    Aug 22 04:40:50.084: INFO: Pod "pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009674612s
    STEP: Saw pod success 08/22/23 04:40:50.084
    Aug 22 04:40:50.084: INFO: Pod "pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9" satisfied condition "Succeeded or Failed"
    Aug 22 04:40:50.087: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9 container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/22/23 04:40:50.094
    Aug 22 04:40:50.132: INFO: Waiting for pod pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9 to disappear
    Aug 22 04:40:50.136: INFO: Pod pod-projected-secrets-2dd28ca2-62be-4534-b782-3338e4a1bfa9 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 22 04:40:50.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3038" for this suite. 08/22/23 04:40:50.14
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:40:50.148
Aug 22 04:40:50.148: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename endpointslice 08/22/23 04:40:50.149
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:50.167
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:50.17
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Aug 22 04:40:50.185: INFO: Endpoints addresses: [10.0.0.171 10.0.0.207 10.0.0.98] , ports: [6443]
Aug 22 04:40:50.185: INFO: EndpointSlices addresses: [10.0.0.171 10.0.0.207 10.0.0.98] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Aug 22 04:40:50.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-1415" for this suite. 08/22/23 04:40:50.189
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":145,"skipped":2506,"failed":0}
------------------------------
â€¢ [0.047 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:40:50.148
    Aug 22 04:40:50.148: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename endpointslice 08/22/23 04:40:50.149
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:50.167
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:50.17
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Aug 22 04:40:50.185: INFO: Endpoints addresses: [10.0.0.171 10.0.0.207 10.0.0.98] , ports: [6443]
    Aug 22 04:40:50.185: INFO: EndpointSlices addresses: [10.0.0.171 10.0.0.207 10.0.0.98] , ports: [6443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Aug 22 04:40:50.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-1415" for this suite. 08/22/23 04:40:50.189
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:40:50.195
Aug 22 04:40:50.195: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename sysctl 08/22/23 04:40:50.196
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:50.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:50.249
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 08/22/23 04:40:50.253
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 22 04:40:50.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-5454" for this suite. 08/22/23 04:40:50.262
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":146,"skipped":2512,"failed":0}
------------------------------
â€¢ [0.074 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:40:50.195
    Aug 22 04:40:50.195: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename sysctl 08/22/23 04:40:50.196
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:50.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:50.249
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 08/22/23 04:40:50.253
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 22 04:40:50.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-5454" for this suite. 08/22/23 04:40:50.262
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:40:50.272
Aug 22 04:40:50.272: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 04:40:50.272
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:50.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:50.293
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 08/22/23 04:40:50.297
Aug 22 04:40:50.306: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-7b503e98-96c2-44b1-94b4-9f32a29f6292" in namespace "emptydir-3741" to be "running"
Aug 22 04:40:50.310: INFO: Pod "pod-sharedvolume-7b503e98-96c2-44b1-94b4-9f32a29f6292": Phase="Pending", Reason="", readiness=false. Elapsed: 3.933068ms
Aug 22 04:40:52.326: INFO: Pod "pod-sharedvolume-7b503e98-96c2-44b1-94b4-9f32a29f6292": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019814427s
Aug 22 04:40:54.404: INFO: Pod "pod-sharedvolume-7b503e98-96c2-44b1-94b4-9f32a29f6292": Phase="Running", Reason="", readiness=false. Elapsed: 4.098127956s
Aug 22 04:40:54.404: INFO: Pod "pod-sharedvolume-7b503e98-96c2-44b1-94b4-9f32a29f6292" satisfied condition "running"
STEP: Reading file content from the nginx-container 08/22/23 04:40:54.404
Aug 22 04:40:54.404: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3741 PodName:pod-sharedvolume-7b503e98-96c2-44b1-94b4-9f32a29f6292 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 04:40:54.404: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 04:40:54.405: INFO: ExecWithOptions: Clientset creation
Aug 22 04:40:54.405: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/emptydir-3741/pods/pod-sharedvolume-7b503e98-96c2-44b1-94b4-9f32a29f6292/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Aug 22 04:40:54.560: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 04:40:54.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3741" for this suite. 08/22/23 04:40:54.633
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":147,"skipped":2559,"failed":0}
------------------------------
â€¢ [4.368 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:40:50.272
    Aug 22 04:40:50.272: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 04:40:50.272
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:50.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:50.293
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 08/22/23 04:40:50.297
    Aug 22 04:40:50.306: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-7b503e98-96c2-44b1-94b4-9f32a29f6292" in namespace "emptydir-3741" to be "running"
    Aug 22 04:40:50.310: INFO: Pod "pod-sharedvolume-7b503e98-96c2-44b1-94b4-9f32a29f6292": Phase="Pending", Reason="", readiness=false. Elapsed: 3.933068ms
    Aug 22 04:40:52.326: INFO: Pod "pod-sharedvolume-7b503e98-96c2-44b1-94b4-9f32a29f6292": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019814427s
    Aug 22 04:40:54.404: INFO: Pod "pod-sharedvolume-7b503e98-96c2-44b1-94b4-9f32a29f6292": Phase="Running", Reason="", readiness=false. Elapsed: 4.098127956s
    Aug 22 04:40:54.404: INFO: Pod "pod-sharedvolume-7b503e98-96c2-44b1-94b4-9f32a29f6292" satisfied condition "running"
    STEP: Reading file content from the nginx-container 08/22/23 04:40:54.404
    Aug 22 04:40:54.404: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3741 PodName:pod-sharedvolume-7b503e98-96c2-44b1-94b4-9f32a29f6292 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 04:40:54.404: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 04:40:54.405: INFO: ExecWithOptions: Clientset creation
    Aug 22 04:40:54.405: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/emptydir-3741/pods/pod-sharedvolume-7b503e98-96c2-44b1-94b4-9f32a29f6292/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Aug 22 04:40:54.560: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 04:40:54.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3741" for this suite. 08/22/23 04:40:54.633
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:40:54.64
Aug 22 04:40:54.640: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename runtimeclass 08/22/23 04:40:54.641
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:54.925
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:54.928
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-6784-delete-me 08/22/23 04:40:54.938
STEP: Waiting for the RuntimeClass to disappear 08/22/23 04:40:54.944
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 22 04:40:54.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-6784" for this suite. 08/22/23 04:40:54.955
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":148,"skipped":2573,"failed":0}
------------------------------
â€¢ [0.321 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:40:54.64
    Aug 22 04:40:54.640: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename runtimeclass 08/22/23 04:40:54.641
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:54.925
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:54.928
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-6784-delete-me 08/22/23 04:40:54.938
    STEP: Waiting for the RuntimeClass to disappear 08/22/23 04:40:54.944
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 22 04:40:54.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-6784" for this suite. 08/22/23 04:40:54.955
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:40:54.962
Aug 22 04:40:54.962: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:40:54.963
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:54.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:54.983
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 08/22/23 04:40:54.987
Aug 22 04:40:55.086: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b" in namespace "projected-5174" to be "Succeeded or Failed"
Aug 22 04:40:55.094: INFO: Pod "downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.585029ms
Aug 22 04:40:57.098: INFO: Pod "downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011799189s
Aug 22 04:40:59.348: INFO: Pod "downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.262181285s
Aug 22 04:41:01.098: INFO: Pod "downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01149652s
STEP: Saw pod success 08/22/23 04:41:01.098
Aug 22 04:41:01.098: INFO: Pod "downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b" satisfied condition "Succeeded or Failed"
Aug 22 04:41:01.100: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b container client-container: <nil>
STEP: delete the pod 08/22/23 04:41:01.107
Aug 22 04:41:01.121: INFO: Waiting for pod downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b to disappear
Aug 22 04:41:01.126: INFO: Pod downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 22 04:41:01.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5174" for this suite. 08/22/23 04:41:01.132
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":149,"skipped":2595,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.177 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:40:54.962
    Aug 22 04:40:54.962: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:40:54.963
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:40:54.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:40:54.983
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 08/22/23 04:40:54.987
    Aug 22 04:40:55.086: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b" in namespace "projected-5174" to be "Succeeded or Failed"
    Aug 22 04:40:55.094: INFO: Pod "downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.585029ms
    Aug 22 04:40:57.098: INFO: Pod "downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011799189s
    Aug 22 04:40:59.348: INFO: Pod "downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.262181285s
    Aug 22 04:41:01.098: INFO: Pod "downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01149652s
    STEP: Saw pod success 08/22/23 04:41:01.098
    Aug 22 04:41:01.098: INFO: Pod "downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b" satisfied condition "Succeeded or Failed"
    Aug 22 04:41:01.100: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b container client-container: <nil>
    STEP: delete the pod 08/22/23 04:41:01.107
    Aug 22 04:41:01.121: INFO: Waiting for pod downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b to disappear
    Aug 22 04:41:01.126: INFO: Pod downwardapi-volume-8f67617a-2c86-4875-9983-86d1d73c993b no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 22 04:41:01.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5174" for this suite. 08/22/23 04:41:01.132
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:41:01.14
Aug 22 04:41:01.140: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 04:41:01.141
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:41:01.21
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:41:01.213
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-9057/configmap-test-f37615b4-b1c2-49fb-b213-0003a608f4f2 08/22/23 04:41:01.217
STEP: Creating a pod to test consume configMaps 08/22/23 04:41:01.361
Aug 22 04:41:01.371: INFO: Waiting up to 5m0s for pod "pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa" in namespace "configmap-9057" to be "Succeeded or Failed"
Aug 22 04:41:01.401: INFO: Pod "pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa": Phase="Pending", Reason="", readiness=false. Elapsed: 30.739951ms
Aug 22 04:41:03.405: INFO: Pod "pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034566825s
Aug 22 04:41:05.449: INFO: Pod "pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa": Phase="Running", Reason="", readiness=false. Elapsed: 4.078244613s
Aug 22 04:41:07.430: INFO: Pod "pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.059453243s
STEP: Saw pod success 08/22/23 04:41:07.43
Aug 22 04:41:07.430: INFO: Pod "pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa" satisfied condition "Succeeded or Failed"
Aug 22 04:41:07.433: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa container env-test: <nil>
STEP: delete the pod 08/22/23 04:41:07.441
Aug 22 04:41:07.508: INFO: Waiting for pod pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa to disappear
Aug 22 04:41:07.512: INFO: Pod pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 04:41:07.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9057" for this suite. 08/22/23 04:41:07.516
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":150,"skipped":2631,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.393 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:41:01.14
    Aug 22 04:41:01.140: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 04:41:01.141
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:41:01.21
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:41:01.213
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-9057/configmap-test-f37615b4-b1c2-49fb-b213-0003a608f4f2 08/22/23 04:41:01.217
    STEP: Creating a pod to test consume configMaps 08/22/23 04:41:01.361
    Aug 22 04:41:01.371: INFO: Waiting up to 5m0s for pod "pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa" in namespace "configmap-9057" to be "Succeeded or Failed"
    Aug 22 04:41:01.401: INFO: Pod "pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa": Phase="Pending", Reason="", readiness=false. Elapsed: 30.739951ms
    Aug 22 04:41:03.405: INFO: Pod "pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034566825s
    Aug 22 04:41:05.449: INFO: Pod "pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa": Phase="Running", Reason="", readiness=false. Elapsed: 4.078244613s
    Aug 22 04:41:07.430: INFO: Pod "pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.059453243s
    STEP: Saw pod success 08/22/23 04:41:07.43
    Aug 22 04:41:07.430: INFO: Pod "pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa" satisfied condition "Succeeded or Failed"
    Aug 22 04:41:07.433: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa container env-test: <nil>
    STEP: delete the pod 08/22/23 04:41:07.441
    Aug 22 04:41:07.508: INFO: Waiting for pod pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa to disappear
    Aug 22 04:41:07.512: INFO: Pod pod-configmaps-d543b3ab-c3eb-4030-b203-91b3816e08fa no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 04:41:07.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9057" for this suite. 08/22/23 04:41:07.516
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:41:07.534
Aug 22 04:41:07.534: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename var-expansion 08/22/23 04:41:07.535
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:41:07.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:41:07.553
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 08/22/23 04:41:07.557
Aug 22 04:41:07.573: INFO: Waiting up to 5m0s for pod "var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69" in namespace "var-expansion-2432" to be "Succeeded or Failed"
Aug 22 04:41:07.578: INFO: Pod "var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69": Phase="Pending", Reason="", readiness=false. Elapsed: 5.172112ms
Aug 22 04:41:09.582: INFO: Pod "var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009608622s
Aug 22 04:41:11.583: INFO: Pod "var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01023458s
Aug 22 04:41:13.581: INFO: Pod "var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008642868s
STEP: Saw pod success 08/22/23 04:41:13.581
Aug 22 04:41:13.581: INFO: Pod "var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69" satisfied condition "Succeeded or Failed"
Aug 22 04:41:13.584: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69 container dapi-container: <nil>
STEP: delete the pod 08/22/23 04:41:13.59
Aug 22 04:41:13.604: INFO: Waiting for pod var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69 to disappear
Aug 22 04:41:13.608: INFO: Pod var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 22 04:41:13.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2432" for this suite. 08/22/23 04:41:13.612
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":151,"skipped":2655,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.085 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:41:07.534
    Aug 22 04:41:07.534: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename var-expansion 08/22/23 04:41:07.535
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:41:07.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:41:07.553
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 08/22/23 04:41:07.557
    Aug 22 04:41:07.573: INFO: Waiting up to 5m0s for pod "var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69" in namespace "var-expansion-2432" to be "Succeeded or Failed"
    Aug 22 04:41:07.578: INFO: Pod "var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69": Phase="Pending", Reason="", readiness=false. Elapsed: 5.172112ms
    Aug 22 04:41:09.582: INFO: Pod "var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009608622s
    Aug 22 04:41:11.583: INFO: Pod "var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01023458s
    Aug 22 04:41:13.581: INFO: Pod "var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008642868s
    STEP: Saw pod success 08/22/23 04:41:13.581
    Aug 22 04:41:13.581: INFO: Pod "var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69" satisfied condition "Succeeded or Failed"
    Aug 22 04:41:13.584: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69 container dapi-container: <nil>
    STEP: delete the pod 08/22/23 04:41:13.59
    Aug 22 04:41:13.604: INFO: Waiting for pod var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69 to disappear
    Aug 22 04:41:13.608: INFO: Pod var-expansion-22070862-6db7-46fe-85d8-dc8aa8878e69 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 22 04:41:13.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2432" for this suite. 08/22/23 04:41:13.612
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:41:13.621
Aug 22 04:41:13.621: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename deployment 08/22/23 04:41:13.621
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:41:13.647
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:41:13.651
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Aug 22 04:41:13.654: INFO: Creating deployment "webserver-deployment"
Aug 22 04:41:13.661: INFO: Waiting for observed generation 1
Aug 22 04:41:15.717: INFO: Waiting for all required pods to come up
Aug 22 04:41:15.723: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 08/22/23 04:41:15.723
Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-w69fz" in namespace "deployment-8506" to be "running"
Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-ghqvj" in namespace "deployment-8506" to be "running"
Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-gz7jl" in namespace "deployment-8506" to be "running"
Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-hw4zf" in namespace "deployment-8506" to be "running"
Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-rvd84" in namespace "deployment-8506" to be "running"
Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-vppn7" in namespace "deployment-8506" to be "running"
Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-bhnk5" in namespace "deployment-8506" to be "running"
Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-9k57b" in namespace "deployment-8506" to be "running"
Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-czr6k" in namespace "deployment-8506" to be "running"
Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-fcjvm" in namespace "deployment-8506" to be "running"
Aug 22 04:41:15.728: INFO: Pod "webserver-deployment-845c8977d9-ghqvj": Phase="Pending", Reason="", readiness=false. Elapsed: 5.489879ms
Aug 22 04:41:15.729: INFO: Pod "webserver-deployment-845c8977d9-fcjvm": Phase="Pending", Reason="", readiness=false. Elapsed: 5.62902ms
Aug 22 04:41:15.731: INFO: Pod "webserver-deployment-845c8977d9-hw4zf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012091ms
Aug 22 04:41:15.731: INFO: Pod "webserver-deployment-845c8977d9-vppn7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.039023ms
Aug 22 04:41:15.731: INFO: Pod "webserver-deployment-845c8977d9-gz7jl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.284713ms
Aug 22 04:41:15.731: INFO: Pod "webserver-deployment-845c8977d9-9k57b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.914608ms
Aug 22 04:41:15.731: INFO: Pod "webserver-deployment-845c8977d9-bhnk5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.239278ms
Aug 22 04:41:15.732: INFO: Pod "webserver-deployment-845c8977d9-w69fz": Phase="Pending", Reason="", readiness=false. Elapsed: 8.864251ms
Aug 22 04:41:15.732: INFO: Pod "webserver-deployment-845c8977d9-czr6k": Phase="Pending", Reason="", readiness=false. Elapsed: 8.37381ms
Aug 22 04:41:15.732: INFO: Pod "webserver-deployment-845c8977d9-rvd84": Phase="Pending", Reason="", readiness=false. Elapsed: 8.75248ms
Aug 22 04:41:17.732: INFO: Pod "webserver-deployment-845c8977d9-ghqvj": Phase="Running", Reason="", readiness=true. Elapsed: 2.009333775s
Aug 22 04:41:17.732: INFO: Pod "webserver-deployment-845c8977d9-ghqvj" satisfied condition "running"
Aug 22 04:41:17.734: INFO: Pod "webserver-deployment-845c8977d9-fcjvm": Phase="Running", Reason="", readiness=true. Elapsed: 2.010781421s
Aug 22 04:41:17.734: INFO: Pod "webserver-deployment-845c8977d9-fcjvm" satisfied condition "running"
Aug 22 04:41:17.736: INFO: Pod "webserver-deployment-845c8977d9-czr6k": Phase="Running", Reason="", readiness=true. Elapsed: 2.012349713s
Aug 22 04:41:17.736: INFO: Pod "webserver-deployment-845c8977d9-czr6k" satisfied condition "running"
Aug 22 04:41:17.736: INFO: Pod "webserver-deployment-845c8977d9-gz7jl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013400846s
Aug 22 04:41:17.737: INFO: Pod "webserver-deployment-845c8977d9-w69fz": Phase="Running", Reason="", readiness=true. Elapsed: 2.014134903s
Aug 22 04:41:17.737: INFO: Pod "webserver-deployment-845c8977d9-w69fz" satisfied condition "running"
Aug 22 04:41:17.737: INFO: Pod "webserver-deployment-845c8977d9-hw4zf": Phase="Running", Reason="", readiness=true. Elapsed: 2.01387242s
Aug 22 04:41:17.737: INFO: Pod "webserver-deployment-845c8977d9-hw4zf" satisfied condition "running"
Aug 22 04:41:17.738: INFO: Pod "webserver-deployment-845c8977d9-rvd84": Phase="Running", Reason="", readiness=true. Elapsed: 2.014383629s
Aug 22 04:41:17.738: INFO: Pod "webserver-deployment-845c8977d9-rvd84" satisfied condition "running"
Aug 22 04:41:17.738: INFO: Pod "webserver-deployment-845c8977d9-bhnk5": Phase="Running", Reason="", readiness=true. Elapsed: 2.014514566s
Aug 22 04:41:17.738: INFO: Pod "webserver-deployment-845c8977d9-bhnk5" satisfied condition "running"
Aug 22 04:41:17.738: INFO: Pod "webserver-deployment-845c8977d9-9k57b": Phase="Running", Reason="", readiness=true. Elapsed: 2.0146299s
Aug 22 04:41:17.738: INFO: Pod "webserver-deployment-845c8977d9-9k57b" satisfied condition "running"
Aug 22 04:41:17.739: INFO: Pod "webserver-deployment-845c8977d9-vppn7": Phase="Running", Reason="", readiness=true. Elapsed: 2.015644936s
Aug 22 04:41:17.739: INFO: Pod "webserver-deployment-845c8977d9-vppn7" satisfied condition "running"
Aug 22 04:41:19.735: INFO: Pod "webserver-deployment-845c8977d9-gz7jl": Phase="Running", Reason="", readiness=true. Elapsed: 4.012092074s
Aug 22 04:41:19.735: INFO: Pod "webserver-deployment-845c8977d9-gz7jl" satisfied condition "running"
Aug 22 04:41:19.735: INFO: Waiting for deployment "webserver-deployment" to complete
Aug 22 04:41:19.741: INFO: Updating deployment "webserver-deployment" with a non-existent image
Aug 22 04:41:20.147: INFO: Updating deployment webserver-deployment
Aug 22 04:41:20.147: INFO: Waiting for observed generation 2
Aug 22 04:41:22.156: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 22 04:41:22.159: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 22 04:41:22.162: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Aug 22 04:41:22.169: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 22 04:41:22.169: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 22 04:41:22.173: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Aug 22 04:41:22.177: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Aug 22 04:41:22.177: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Aug 22 04:41:22.448: INFO: Updating deployment webserver-deployment
Aug 22 04:41:22.448: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Aug 22 04:41:22.461: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 22 04:41:24.528: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 22 04:41:24.551: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-8506  2c3ce498-a57c-4106-b1f5-7c1c67bec240 1265198 3 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034f2f08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-08-22 04:41:22 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-08-22 04:41:22 +0000 UTC,LastTransitionTime:2023-08-22 04:41:13 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Aug 22 04:41:24.554: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-8506  7828c764-5e94-4115-b09d-9a5b580cf2be 1265193 3 2023-08-22 04:41:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 2c3ce498-a57c-4106-b1f5-7c1c67bec240 0xc003a1e397 0xc003a1e398}] [] [{kube-controller-manager Update apps/v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2c3ce498-a57c-4106-b1f5-7c1c67bec240\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a1e438 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 22 04:41:24.554: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Aug 22 04:41:24.554: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-8506  460513dd-7894-48a6-90fa-7f2f381a9687 1265190 3 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 2c3ce498-a57c-4106-b1f5-7c1c67bec240 0xc003a1e497 0xc003a1e498}] [] [{kube-controller-manager Update apps/v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2c3ce498-a57c-4106-b1f5-7c1c67bec240\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a1e528 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Aug 22 04:41:24.561: INFO: Pod "webserver-deployment-69b7448995-42hdz" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-42hdz webserver-deployment-69b7448995- deployment-8506  a821febc-3f40-4672-9be4-72f4930af952 1265217 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0034f3307 0xc0034f3308}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2r4t5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2r4t5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.561: INFO: Pod "webserver-deployment-69b7448995-7mn6t" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-7mn6t webserver-deployment-69b7448995- deployment-8506  ea10cf7a-08e9-4be4-b69f-fc2468437d32 1265119 0 2023-08-22 04:41:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0034f3497 0xc0034f3498}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9tg8t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9tg8t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.561: INFO: Pod "webserver-deployment-69b7448995-b2vpr" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-b2vpr webserver-deployment-69b7448995- deployment-8506  e1c2b012-7f20-4308-9eb9-a364b9929be4 1265140 0 2023-08-22 04:41:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0034f3677 0xc0034f3678}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ff7ng,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ff7ng,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.562: INFO: Pod "webserver-deployment-69b7448995-bfqf7" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-bfqf7 webserver-deployment-69b7448995- deployment-8506  1c7b9759-5f10-44a6-ace5-c507ec8baf28 1265125 0 2023-08-22 04:41:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0034f3ae7 0xc0034f3ae8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mfgnp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mfgnp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:,StartTime:2023-08-22 04:41:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.562: INFO: Pod "webserver-deployment-69b7448995-lbttf" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-lbttf webserver-deployment-69b7448995- deployment-8506  dcc90c93-2893-4455-9542-64071a5db1f8 1265127 0 2023-08-22 04:41:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0034f3d17 0xc0034f3d18}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jqsvk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jqsvk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:,StartTime:2023-08-22 04:41:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.562: INFO: Pod "webserver-deployment-69b7448995-llhlk" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-llhlk webserver-deployment-69b7448995- deployment-8506  cd80a801-5bc3-4a0f-b6f4-cabd1b6fd6a1 1265135 0 2023-08-22 04:41:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0034f3f07 0xc0034f3f08}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-569fj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-569fj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:,StartTime:2023-08-22 04:41:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.562: INFO: Pod "webserver-deployment-69b7448995-mkdj7" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-mkdj7 webserver-deployment-69b7448995- deployment-8506  7cba9a67-cdb4-470c-ac24-68b2b69e3cd2 1265184 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0037680e7 0xc0037680e8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qfdh8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qfdh8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.562: INFO: Pod "webserver-deployment-69b7448995-n82zv" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-n82zv webserver-deployment-69b7448995- deployment-8506  d9df6f2d-98bb-49c4-accf-63eb64310330 1265258 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0037682c7 0xc0037682c8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zcccz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zcccz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.563: INFO: Pod "webserver-deployment-69b7448995-sm6tr" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-sm6tr webserver-deployment-69b7448995- deployment-8506  21de2aff-a3f3-4d91-8321-533dd739e5aa 1265222 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0037684a7 0xc0037684a8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vf4gd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vf4gd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.563: INFO: Pod "webserver-deployment-69b7448995-wm9rr" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-wm9rr webserver-deployment-69b7448995- deployment-8506  757ad270-0d43-483f-b7ff-07c8a0a4c022 1265264 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc003768687 0xc003768688}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-49wbc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-49wbc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.563: INFO: Pod "webserver-deployment-69b7448995-wrsdv" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-wrsdv webserver-deployment-69b7448995- deployment-8506  c3f48795-0ce9-4830-868e-74846fa66745 1265278 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc003768877 0xc003768878}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8zd6f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8zd6f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.563: INFO: Pod "webserver-deployment-69b7448995-xf24v" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-xf24v webserver-deployment-69b7448995- deployment-8506  645c9ee1-c8c0-4424-81fd-79c342a7b48b 1265241 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc003768a67 0xc003768a68}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7ptg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7ptg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.563: INFO: Pod "webserver-deployment-69b7448995-xj8hw" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-xj8hw webserver-deployment-69b7448995- deployment-8506  f5c10750-4f93-478e-9aa2-aaa983d98afa 1265226 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc003768c57 0xc003768c58}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t5vf8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t5vf8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.563: INFO: Pod "webserver-deployment-845c8977d9-2fb7d" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2fb7d webserver-deployment-845c8977d9- deployment-8506  bf1126c9-fe75-4582-bc38-22eefb620c71 1265221 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003768dd7 0xc003768dd8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sqpxq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sqpxq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.563: INFO: Pod "webserver-deployment-845c8977d9-2rzzb" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2rzzb webserver-deployment-845c8977d9- deployment-8506  91928f55-ddcc-4a97-936a-6e8ff07ee487 1265211 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003768fa7 0xc003768fa8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8j5hv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8j5hv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.564: INFO: Pod "webserver-deployment-845c8977d9-9k57b" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-9k57b webserver-deployment-845c8977d9- deployment-8506  ad638b5f-0ee6-4c3b-8cad-4102c2d987e1 1265034 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769167 0xc003769168}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.5.68\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mpmz2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mpmz2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:10.100.5.68,StartTime:2023-08-22 04:41:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ec364e7611f969eacf34277d0a09288a20dbbd99751db44cfa1d1d7ca8a20820,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.5.68,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.564: INFO: Pod "webserver-deployment-845c8977d9-9lkzx" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-9lkzx webserver-deployment-845c8977d9- deployment-8506  4af455be-f6b6-4f71-b685-5faddb709890 1265269 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769347 0xc003769348}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qccwb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qccwb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.564: INFO: Pod "webserver-deployment-845c8977d9-b8dbr" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-b8dbr webserver-deployment-845c8977d9- deployment-8506  b2b8a566-1cf7-40e4-8471-7e00979f6ceb 1265225 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769507 0xc003769508}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qjtng,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qjtng,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.564: INFO: Pod "webserver-deployment-845c8977d9-bhnk5" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bhnk5 webserver-deployment-845c8977d9- deployment-8506  d74cc5d3-cd1e-45c2-9350-09b163e1e938 1265047 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769667 0xc003769668}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.3.104\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lx6cc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lx6cc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:10.100.3.104,StartTime:2023-08-22 04:41:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://66ca4ad0437f0da078d8064f02a79dd489bc2f2e21975e1888372a3c44b1f397,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.3.104,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.564: INFO: Pod "webserver-deployment-845c8977d9-bjn6m" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bjn6m webserver-deployment-845c8977d9- deployment-8506  773532ec-644e-4a83-ad48-9c8a9487ea80 1265227 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769847 0xc003769848}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-glg7z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-glg7z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.565: INFO: Pod "webserver-deployment-845c8977d9-czr6k" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-czr6k webserver-deployment-845c8977d9- deployment-8506  aa6ec349-d49c-41b9-8317-141b34d09033 1265061 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769a17 0xc003769a18}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.5.66\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qmxt7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qmxt7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:10.100.5.66,StartTime:2023-08-22 04:41:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://edb8ca63b688e385d70050018a4331b01d13213f9edcb629e733e9c9c37c9ef9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.5.66,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.565: INFO: Pod "webserver-deployment-845c8977d9-fcjvm" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-fcjvm webserver-deployment-845c8977d9- deployment-8506  d406f411-3b98-49cd-bcfd-0f08de1f07c3 1265039 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769bf7 0xc003769bf8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.3.103\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5g79l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5g79l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:10.100.3.103,StartTime:2023-08-22 04:41:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://582a94c8aee41cc8ef20ef394c92a2838a9f2590eae56aa102c279c4a4e91ac4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.3.103,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.565: INFO: Pod "webserver-deployment-845c8977d9-gbq96" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gbq96 webserver-deployment-845c8977d9- deployment-8506  cb27833f-6d0d-4225-812d-291abd5a5cb8 1265272 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769dd7 0xc003769dd8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hd7ml,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hd7ml,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.565: INFO: Pod "webserver-deployment-845c8977d9-ghqvj" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ghqvj webserver-deployment-845c8977d9- deployment-8506  e882f308-bd74-4f4f-9a9f-dc92fc1c326f 1265050 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769f97 0xc003769f98}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.3.102\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x555z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x555z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:10.100.3.102,StartTime:2023-08-22 04:41:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f5c9482a3baa82c82d00f25a3429e3175af4d7bbb1f2935b103b72445be93f7f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.3.102,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.565: INFO: Pod "webserver-deployment-845c8977d9-hw4zf" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-hw4zf webserver-deployment-845c8977d9- deployment-8506  29de359c-a7de-43e3-be46-9349fbd9dd4c 1265056 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bfe177 0xc003bfe178}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.5.67\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pjclm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pjclm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:10.100.5.67,StartTime:2023-08-22 04:41:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f96b385b935cd33ecb361341105cad245a3edcc35b04f8dfece56115d2eac3a9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.5.67,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.565: INFO: Pod "webserver-deployment-845c8977d9-j2946" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-j2946 webserver-deployment-845c8977d9- deployment-8506  2be97468-d6a4-4a5e-a276-69db274f1d5c 1265195 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bfe357 0xc003bfe358}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wsqcl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wsqcl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.565: INFO: Pod "webserver-deployment-845c8977d9-mzvd5" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-mzvd5 webserver-deployment-845c8977d9- deployment-8506  4f19f779-4056-4062-be5b-098ae8817ff1 1265256 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bfe517 0xc003bfe518}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kv6xd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kv6xd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.566: INFO: Pod "webserver-deployment-845c8977d9-q4kdz" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-q4kdz webserver-deployment-845c8977d9- deployment-8506  9fa6dc36-6146-4952-9350-f71d72bc4baa 1265265 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bfe6d7 0xc003bfe6d8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n8lzf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n8lzf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.566: INFO: Pod "webserver-deployment-845c8977d9-qm4t5" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-qm4t5 webserver-deployment-845c8977d9- deployment-8506  fa670ce2-c2b7-4e91-9a7c-0d361288263f 1265275 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bfe897 0xc003bfe898}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-52nfr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-52nfr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.566: INFO: Pod "webserver-deployment-845c8977d9-vppn7" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-vppn7 webserver-deployment-845c8977d9- deployment-8506  e7e6f448-be86-416d-8a11-701f68142f57 1265063 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bfea57 0xc003bfea58}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.144\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wv7j2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wv7j2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:10.100.4.144,StartTime:2023-08-22 04:41:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://fc9bb901cfffe2e702b4f9314841e6e9d4adabb5f11fabd64da7ad39bd62cd09,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.4.144,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.566: INFO: Pod "webserver-deployment-845c8977d9-w69fz" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-w69fz webserver-deployment-845c8977d9- deployment-8506  94dbc39f-fd3b-4eb5-9bff-89f52fcf21b5 1265032 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bfed07 0xc003bfed08}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.145\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nr52x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nr52x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:10.100.4.145,StartTime:2023-08-22 04:41:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://0f28a6eac57a285492fa0005797252be6293730d2350dcfe815fed2d4072940a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.4.145,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.566: INFO: Pod "webserver-deployment-845c8977d9-wjm2q" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-wjm2q webserver-deployment-845c8977d9- deployment-8506  c97d0c69-a9b6-4a33-af3f-fcda703a59dc 1265197 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bff367 0xc003bff368}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ngzjd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ngzjd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 04:41:24.566: INFO: Pod "webserver-deployment-845c8977d9-wmw58" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-wmw58 webserver-deployment-845c8977d9- deployment-8506  9230b9bc-a559-40d3-bafe-660bd761aa00 1265214 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bff527 0xc003bff528}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qpqx7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qpqx7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 22 04:41:24.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8506" for this suite. 08/22/23 04:41:24.571
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":152,"skipped":2668,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.959 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:41:13.621
    Aug 22 04:41:13.621: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename deployment 08/22/23 04:41:13.621
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:41:13.647
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:41:13.651
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Aug 22 04:41:13.654: INFO: Creating deployment "webserver-deployment"
    Aug 22 04:41:13.661: INFO: Waiting for observed generation 1
    Aug 22 04:41:15.717: INFO: Waiting for all required pods to come up
    Aug 22 04:41:15.723: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 08/22/23 04:41:15.723
    Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-w69fz" in namespace "deployment-8506" to be "running"
    Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-ghqvj" in namespace "deployment-8506" to be "running"
    Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-gz7jl" in namespace "deployment-8506" to be "running"
    Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-hw4zf" in namespace "deployment-8506" to be "running"
    Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-rvd84" in namespace "deployment-8506" to be "running"
    Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-vppn7" in namespace "deployment-8506" to be "running"
    Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-bhnk5" in namespace "deployment-8506" to be "running"
    Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-9k57b" in namespace "deployment-8506" to be "running"
    Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-czr6k" in namespace "deployment-8506" to be "running"
    Aug 22 04:41:15.723: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-fcjvm" in namespace "deployment-8506" to be "running"
    Aug 22 04:41:15.728: INFO: Pod "webserver-deployment-845c8977d9-ghqvj": Phase="Pending", Reason="", readiness=false. Elapsed: 5.489879ms
    Aug 22 04:41:15.729: INFO: Pod "webserver-deployment-845c8977d9-fcjvm": Phase="Pending", Reason="", readiness=false. Elapsed: 5.62902ms
    Aug 22 04:41:15.731: INFO: Pod "webserver-deployment-845c8977d9-hw4zf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012091ms
    Aug 22 04:41:15.731: INFO: Pod "webserver-deployment-845c8977d9-vppn7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.039023ms
    Aug 22 04:41:15.731: INFO: Pod "webserver-deployment-845c8977d9-gz7jl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.284713ms
    Aug 22 04:41:15.731: INFO: Pod "webserver-deployment-845c8977d9-9k57b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.914608ms
    Aug 22 04:41:15.731: INFO: Pod "webserver-deployment-845c8977d9-bhnk5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.239278ms
    Aug 22 04:41:15.732: INFO: Pod "webserver-deployment-845c8977d9-w69fz": Phase="Pending", Reason="", readiness=false. Elapsed: 8.864251ms
    Aug 22 04:41:15.732: INFO: Pod "webserver-deployment-845c8977d9-czr6k": Phase="Pending", Reason="", readiness=false. Elapsed: 8.37381ms
    Aug 22 04:41:15.732: INFO: Pod "webserver-deployment-845c8977d9-rvd84": Phase="Pending", Reason="", readiness=false. Elapsed: 8.75248ms
    Aug 22 04:41:17.732: INFO: Pod "webserver-deployment-845c8977d9-ghqvj": Phase="Running", Reason="", readiness=true. Elapsed: 2.009333775s
    Aug 22 04:41:17.732: INFO: Pod "webserver-deployment-845c8977d9-ghqvj" satisfied condition "running"
    Aug 22 04:41:17.734: INFO: Pod "webserver-deployment-845c8977d9-fcjvm": Phase="Running", Reason="", readiness=true. Elapsed: 2.010781421s
    Aug 22 04:41:17.734: INFO: Pod "webserver-deployment-845c8977d9-fcjvm" satisfied condition "running"
    Aug 22 04:41:17.736: INFO: Pod "webserver-deployment-845c8977d9-czr6k": Phase="Running", Reason="", readiness=true. Elapsed: 2.012349713s
    Aug 22 04:41:17.736: INFO: Pod "webserver-deployment-845c8977d9-czr6k" satisfied condition "running"
    Aug 22 04:41:17.736: INFO: Pod "webserver-deployment-845c8977d9-gz7jl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013400846s
    Aug 22 04:41:17.737: INFO: Pod "webserver-deployment-845c8977d9-w69fz": Phase="Running", Reason="", readiness=true. Elapsed: 2.014134903s
    Aug 22 04:41:17.737: INFO: Pod "webserver-deployment-845c8977d9-w69fz" satisfied condition "running"
    Aug 22 04:41:17.737: INFO: Pod "webserver-deployment-845c8977d9-hw4zf": Phase="Running", Reason="", readiness=true. Elapsed: 2.01387242s
    Aug 22 04:41:17.737: INFO: Pod "webserver-deployment-845c8977d9-hw4zf" satisfied condition "running"
    Aug 22 04:41:17.738: INFO: Pod "webserver-deployment-845c8977d9-rvd84": Phase="Running", Reason="", readiness=true. Elapsed: 2.014383629s
    Aug 22 04:41:17.738: INFO: Pod "webserver-deployment-845c8977d9-rvd84" satisfied condition "running"
    Aug 22 04:41:17.738: INFO: Pod "webserver-deployment-845c8977d9-bhnk5": Phase="Running", Reason="", readiness=true. Elapsed: 2.014514566s
    Aug 22 04:41:17.738: INFO: Pod "webserver-deployment-845c8977d9-bhnk5" satisfied condition "running"
    Aug 22 04:41:17.738: INFO: Pod "webserver-deployment-845c8977d9-9k57b": Phase="Running", Reason="", readiness=true. Elapsed: 2.0146299s
    Aug 22 04:41:17.738: INFO: Pod "webserver-deployment-845c8977d9-9k57b" satisfied condition "running"
    Aug 22 04:41:17.739: INFO: Pod "webserver-deployment-845c8977d9-vppn7": Phase="Running", Reason="", readiness=true. Elapsed: 2.015644936s
    Aug 22 04:41:17.739: INFO: Pod "webserver-deployment-845c8977d9-vppn7" satisfied condition "running"
    Aug 22 04:41:19.735: INFO: Pod "webserver-deployment-845c8977d9-gz7jl": Phase="Running", Reason="", readiness=true. Elapsed: 4.012092074s
    Aug 22 04:41:19.735: INFO: Pod "webserver-deployment-845c8977d9-gz7jl" satisfied condition "running"
    Aug 22 04:41:19.735: INFO: Waiting for deployment "webserver-deployment" to complete
    Aug 22 04:41:19.741: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Aug 22 04:41:20.147: INFO: Updating deployment webserver-deployment
    Aug 22 04:41:20.147: INFO: Waiting for observed generation 2
    Aug 22 04:41:22.156: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Aug 22 04:41:22.159: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Aug 22 04:41:22.162: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Aug 22 04:41:22.169: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Aug 22 04:41:22.169: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Aug 22 04:41:22.173: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Aug 22 04:41:22.177: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Aug 22 04:41:22.177: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Aug 22 04:41:22.448: INFO: Updating deployment webserver-deployment
    Aug 22 04:41:22.448: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Aug 22 04:41:22.461: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Aug 22 04:41:24.528: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 22 04:41:24.551: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-8506  2c3ce498-a57c-4106-b1f5-7c1c67bec240 1265198 3 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034f2f08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-08-22 04:41:22 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-08-22 04:41:22 +0000 UTC,LastTransitionTime:2023-08-22 04:41:13 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Aug 22 04:41:24.554: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-8506  7828c764-5e94-4115-b09d-9a5b580cf2be 1265193 3 2023-08-22 04:41:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 2c3ce498-a57c-4106-b1f5-7c1c67bec240 0xc003a1e397 0xc003a1e398}] [] [{kube-controller-manager Update apps/v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2c3ce498-a57c-4106-b1f5-7c1c67bec240\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a1e438 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 22 04:41:24.554: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Aug 22 04:41:24.554: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-8506  460513dd-7894-48a6-90fa-7f2f381a9687 1265190 3 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 2c3ce498-a57c-4106-b1f5-7c1c67bec240 0xc003a1e497 0xc003a1e498}] [] [{kube-controller-manager Update apps/v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2c3ce498-a57c-4106-b1f5-7c1c67bec240\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003a1e528 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Aug 22 04:41:24.561: INFO: Pod "webserver-deployment-69b7448995-42hdz" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-42hdz webserver-deployment-69b7448995- deployment-8506  a821febc-3f40-4672-9be4-72f4930af952 1265217 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0034f3307 0xc0034f3308}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2r4t5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2r4t5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.561: INFO: Pod "webserver-deployment-69b7448995-7mn6t" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-7mn6t webserver-deployment-69b7448995- deployment-8506  ea10cf7a-08e9-4be4-b69f-fc2468437d32 1265119 0 2023-08-22 04:41:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0034f3497 0xc0034f3498}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9tg8t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9tg8t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.561: INFO: Pod "webserver-deployment-69b7448995-b2vpr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-b2vpr webserver-deployment-69b7448995- deployment-8506  e1c2b012-7f20-4308-9eb9-a364b9929be4 1265140 0 2023-08-22 04:41:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0034f3677 0xc0034f3678}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ff7ng,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ff7ng,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.562: INFO: Pod "webserver-deployment-69b7448995-bfqf7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-bfqf7 webserver-deployment-69b7448995- deployment-8506  1c7b9759-5f10-44a6-ace5-c507ec8baf28 1265125 0 2023-08-22 04:41:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0034f3ae7 0xc0034f3ae8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mfgnp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mfgnp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:,StartTime:2023-08-22 04:41:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.562: INFO: Pod "webserver-deployment-69b7448995-lbttf" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-lbttf webserver-deployment-69b7448995- deployment-8506  dcc90c93-2893-4455-9542-64071a5db1f8 1265127 0 2023-08-22 04:41:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0034f3d17 0xc0034f3d18}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jqsvk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jqsvk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:,StartTime:2023-08-22 04:41:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.562: INFO: Pod "webserver-deployment-69b7448995-llhlk" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-llhlk webserver-deployment-69b7448995- deployment-8506  cd80a801-5bc3-4a0f-b6f4-cabd1b6fd6a1 1265135 0 2023-08-22 04:41:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0034f3f07 0xc0034f3f08}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-569fj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-569fj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:,StartTime:2023-08-22 04:41:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.562: INFO: Pod "webserver-deployment-69b7448995-mkdj7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-mkdj7 webserver-deployment-69b7448995- deployment-8506  7cba9a67-cdb4-470c-ac24-68b2b69e3cd2 1265184 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0037680e7 0xc0037680e8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qfdh8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qfdh8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.562: INFO: Pod "webserver-deployment-69b7448995-n82zv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-n82zv webserver-deployment-69b7448995- deployment-8506  d9df6f2d-98bb-49c4-accf-63eb64310330 1265258 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0037682c7 0xc0037682c8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zcccz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zcccz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.563: INFO: Pod "webserver-deployment-69b7448995-sm6tr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-sm6tr webserver-deployment-69b7448995- deployment-8506  21de2aff-a3f3-4d91-8321-533dd739e5aa 1265222 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc0037684a7 0xc0037684a8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vf4gd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vf4gd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.563: INFO: Pod "webserver-deployment-69b7448995-wm9rr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-wm9rr webserver-deployment-69b7448995- deployment-8506  757ad270-0d43-483f-b7ff-07c8a0a4c022 1265264 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc003768687 0xc003768688}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-49wbc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-49wbc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.563: INFO: Pod "webserver-deployment-69b7448995-wrsdv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-wrsdv webserver-deployment-69b7448995- deployment-8506  c3f48795-0ce9-4830-868e-74846fa66745 1265278 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc003768877 0xc003768878}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8zd6f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8zd6f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.563: INFO: Pod "webserver-deployment-69b7448995-xf24v" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-xf24v webserver-deployment-69b7448995- deployment-8506  645c9ee1-c8c0-4424-81fd-79c342a7b48b 1265241 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc003768a67 0xc003768a68}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7ptg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7ptg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.563: INFO: Pod "webserver-deployment-69b7448995-xj8hw" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-xj8hw webserver-deployment-69b7448995- deployment-8506  f5c10750-4f93-478e-9aa2-aaa983d98afa 1265226 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7828c764-5e94-4115-b09d-9a5b580cf2be 0xc003768c57 0xc003768c58}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7828c764-5e94-4115-b09d-9a5b580cf2be\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t5vf8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t5vf8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.563: INFO: Pod "webserver-deployment-845c8977d9-2fb7d" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2fb7d webserver-deployment-845c8977d9- deployment-8506  bf1126c9-fe75-4582-bc38-22eefb620c71 1265221 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003768dd7 0xc003768dd8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sqpxq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sqpxq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.563: INFO: Pod "webserver-deployment-845c8977d9-2rzzb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2rzzb webserver-deployment-845c8977d9- deployment-8506  91928f55-ddcc-4a97-936a-6e8ff07ee487 1265211 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003768fa7 0xc003768fa8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8j5hv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8j5hv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.564: INFO: Pod "webserver-deployment-845c8977d9-9k57b" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-9k57b webserver-deployment-845c8977d9- deployment-8506  ad638b5f-0ee6-4c3b-8cad-4102c2d987e1 1265034 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769167 0xc003769168}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.5.68\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mpmz2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mpmz2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:10.100.5.68,StartTime:2023-08-22 04:41:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ec364e7611f969eacf34277d0a09288a20dbbd99751db44cfa1d1d7ca8a20820,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.5.68,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.564: INFO: Pod "webserver-deployment-845c8977d9-9lkzx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-9lkzx webserver-deployment-845c8977d9- deployment-8506  4af455be-f6b6-4f71-b685-5faddb709890 1265269 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769347 0xc003769348}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qccwb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qccwb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.564: INFO: Pod "webserver-deployment-845c8977d9-b8dbr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-b8dbr webserver-deployment-845c8977d9- deployment-8506  b2b8a566-1cf7-40e4-8471-7e00979f6ceb 1265225 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769507 0xc003769508}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qjtng,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qjtng,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.564: INFO: Pod "webserver-deployment-845c8977d9-bhnk5" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bhnk5 webserver-deployment-845c8977d9- deployment-8506  d74cc5d3-cd1e-45c2-9350-09b163e1e938 1265047 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769667 0xc003769668}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.3.104\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lx6cc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lx6cc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:10.100.3.104,StartTime:2023-08-22 04:41:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://66ca4ad0437f0da078d8064f02a79dd489bc2f2e21975e1888372a3c44b1f397,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.3.104,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.564: INFO: Pod "webserver-deployment-845c8977d9-bjn6m" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bjn6m webserver-deployment-845c8977d9- deployment-8506  773532ec-644e-4a83-ad48-9c8a9487ea80 1265227 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769847 0xc003769848}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-glg7z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-glg7z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.565: INFO: Pod "webserver-deployment-845c8977d9-czr6k" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-czr6k webserver-deployment-845c8977d9- deployment-8506  aa6ec349-d49c-41b9-8317-141b34d09033 1265061 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769a17 0xc003769a18}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.5.66\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qmxt7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qmxt7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:10.100.5.66,StartTime:2023-08-22 04:41:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://edb8ca63b688e385d70050018a4331b01d13213f9edcb629e733e9c9c37c9ef9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.5.66,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.565: INFO: Pod "webserver-deployment-845c8977d9-fcjvm" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-fcjvm webserver-deployment-845c8977d9- deployment-8506  d406f411-3b98-49cd-bcfd-0f08de1f07c3 1265039 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769bf7 0xc003769bf8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.3.103\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5g79l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5g79l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:10.100.3.103,StartTime:2023-08-22 04:41:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://582a94c8aee41cc8ef20ef394c92a2838a9f2590eae56aa102c279c4a4e91ac4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.3.103,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.565: INFO: Pod "webserver-deployment-845c8977d9-gbq96" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gbq96 webserver-deployment-845c8977d9- deployment-8506  cb27833f-6d0d-4225-812d-291abd5a5cb8 1265272 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769dd7 0xc003769dd8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hd7ml,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hd7ml,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.565: INFO: Pod "webserver-deployment-845c8977d9-ghqvj" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ghqvj webserver-deployment-845c8977d9- deployment-8506  e882f308-bd74-4f4f-9a9f-dc92fc1c326f 1265050 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003769f97 0xc003769f98}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.3.102\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x555z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x555z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:10.100.3.102,StartTime:2023-08-22 04:41:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f5c9482a3baa82c82d00f25a3429e3175af4d7bbb1f2935b103b72445be93f7f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.3.102,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.565: INFO: Pod "webserver-deployment-845c8977d9-hw4zf" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-hw4zf webserver-deployment-845c8977d9- deployment-8506  29de359c-a7de-43e3-be46-9349fbd9dd4c 1265056 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bfe177 0xc003bfe178}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.5.67\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pjclm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pjclm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:10.100.5.67,StartTime:2023-08-22 04:41:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f96b385b935cd33ecb361341105cad245a3edcc35b04f8dfece56115d2eac3a9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.5.67,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.565: INFO: Pod "webserver-deployment-845c8977d9-j2946" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-j2946 webserver-deployment-845c8977d9- deployment-8506  2be97468-d6a4-4a5e-a276-69db274f1d5c 1265195 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bfe357 0xc003bfe358}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wsqcl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wsqcl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.565: INFO: Pod "webserver-deployment-845c8977d9-mzvd5" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-mzvd5 webserver-deployment-845c8977d9- deployment-8506  4f19f779-4056-4062-be5b-098ae8817ff1 1265256 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bfe517 0xc003bfe518}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kv6xd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kv6xd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.566: INFO: Pod "webserver-deployment-845c8977d9-q4kdz" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-q4kdz webserver-deployment-845c8977d9- deployment-8506  9fa6dc36-6146-4952-9350-f71d72bc4baa 1265265 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bfe6d7 0xc003bfe6d8}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n8lzf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n8lzf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.232,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.566: INFO: Pod "webserver-deployment-845c8977d9-qm4t5" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-qm4t5 webserver-deployment-845c8977d9- deployment-8506  fa670ce2-c2b7-4e91-9a7c-0d361288263f 1265275 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bfe897 0xc003bfe898}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-52nfr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-52nfr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.566: INFO: Pod "webserver-deployment-845c8977d9-vppn7" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-vppn7 webserver-deployment-845c8977d9- deployment-8506  e7e6f448-be86-416d-8a11-701f68142f57 1265063 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bfea57 0xc003bfea58}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.144\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wv7j2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wv7j2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:10.100.4.144,StartTime:2023-08-22 04:41:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://fc9bb901cfffe2e702b4f9314841e6e9d4adabb5f11fabd64da7ad39bd62cd09,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.4.144,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.566: INFO: Pod "webserver-deployment-845c8977d9-w69fz" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-w69fz webserver-deployment-845c8977d9- deployment-8506  94dbc39f-fd3b-4eb5-9bff-89f52fcf21b5 1265032 0 2023-08-22 04:41:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bfed07 0xc003bfed08}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.145\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nr52x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nr52x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:10.100.4.145,StartTime:2023-08-22 04:41:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 04:41:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://0f28a6eac57a285492fa0005797252be6293730d2350dcfe815fed2d4072940a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.4.145,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.566: INFO: Pod "webserver-deployment-845c8977d9-wjm2q" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-wjm2q webserver-deployment-845c8977d9- deployment-8506  c97d0c69-a9b6-4a33-af3f-fcda703a59dc 1265197 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bff367 0xc003bff368}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ngzjd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ngzjd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:,StartTime:2023-08-22 04:41:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 04:41:24.566: INFO: Pod "webserver-deployment-845c8977d9-wmw58" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-wmw58 webserver-deployment-845c8977d9- deployment-8506  9230b9bc-a559-40d3-bafe-660bd761aa00 1265214 0 2023-08-22 04:41:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 460513dd-7894-48a6-90fa-7f2f381a9687 0xc003bff527 0xc003bff528}] [] [{kube-controller-manager Update v1 2023-08-22 04:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"460513dd-7894-48a6-90fa-7f2f381a9687\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qpqx7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qpqx7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 04:41:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 22 04:41:24.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8506" for this suite. 08/22/23 04:41:24.571
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:41:24.586
Aug 22 04:41:24.586: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:41:24.587
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:41:24.84
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:41:24.845
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-e73ff916-e2a6-4576-af50-68f934d6ab79 08/22/23 04:41:24.856
STEP: Creating configMap with name cm-test-opt-upd-f53f0c84-be60-48f5-84a5-79a4e2ff9300 08/22/23 04:41:24.861
STEP: Creating the pod 08/22/23 04:41:24.865
Aug 22 04:41:24.878: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a" in namespace "projected-234" to be "running and ready"
Aug 22 04:41:24.883: INFO: Pod "pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.730215ms
Aug 22 04:41:24.883: INFO: The phase of Pod pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:41:26.978: INFO: Pod "pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.099852838s
Aug 22 04:41:26.978: INFO: The phase of Pod pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:41:28.928: INFO: Pod "pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.049806568s
Aug 22 04:41:28.928: INFO: The phase of Pod pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:41:31.260: INFO: Pod "pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a": Phase="Running", Reason="", readiness=true. Elapsed: 6.381451942s
Aug 22 04:41:31.260: INFO: The phase of Pod pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a is Running (Ready = true)
Aug 22 04:41:31.260: INFO: Pod "pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-e73ff916-e2a6-4576-af50-68f934d6ab79 08/22/23 04:41:31.569
STEP: Updating configmap cm-test-opt-upd-f53f0c84-be60-48f5-84a5-79a4e2ff9300 08/22/23 04:41:31.577
STEP: Creating configMap with name cm-test-opt-create-d97d0462-6b8e-43a8-9457-ddb979b688ee 08/22/23 04:41:31.598
STEP: waiting to observe update in volume 08/22/23 04:41:31.625
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 22 04:42:55.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-234" for this suite. 08/22/23 04:42:55.204
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":153,"skipped":2689,"failed":0}
------------------------------
â€¢ [SLOW TEST] [90.630 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:41:24.586
    Aug 22 04:41:24.586: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:41:24.587
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:41:24.84
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:41:24.845
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-e73ff916-e2a6-4576-af50-68f934d6ab79 08/22/23 04:41:24.856
    STEP: Creating configMap with name cm-test-opt-upd-f53f0c84-be60-48f5-84a5-79a4e2ff9300 08/22/23 04:41:24.861
    STEP: Creating the pod 08/22/23 04:41:24.865
    Aug 22 04:41:24.878: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a" in namespace "projected-234" to be "running and ready"
    Aug 22 04:41:24.883: INFO: Pod "pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.730215ms
    Aug 22 04:41:24.883: INFO: The phase of Pod pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:41:26.978: INFO: Pod "pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.099852838s
    Aug 22 04:41:26.978: INFO: The phase of Pod pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:41:28.928: INFO: Pod "pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.049806568s
    Aug 22 04:41:28.928: INFO: The phase of Pod pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:41:31.260: INFO: Pod "pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a": Phase="Running", Reason="", readiness=true. Elapsed: 6.381451942s
    Aug 22 04:41:31.260: INFO: The phase of Pod pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a is Running (Ready = true)
    Aug 22 04:41:31.260: INFO: Pod "pod-projected-configmaps-eaf49a13-c10c-43be-8a63-666b38b7e42a" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-e73ff916-e2a6-4576-af50-68f934d6ab79 08/22/23 04:41:31.569
    STEP: Updating configmap cm-test-opt-upd-f53f0c84-be60-48f5-84a5-79a4e2ff9300 08/22/23 04:41:31.577
    STEP: Creating configMap with name cm-test-opt-create-d97d0462-6b8e-43a8-9457-ddb979b688ee 08/22/23 04:41:31.598
    STEP: waiting to observe update in volume 08/22/23 04:41:31.625
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 22 04:42:55.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-234" for this suite. 08/22/23 04:42:55.204
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:42:55.218
Aug 22 04:42:55.218: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename watch 08/22/23 04:42:55.22
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:42:55.489
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:42:55.493
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 08/22/23 04:42:55.498
STEP: creating a new configmap 08/22/23 04:42:55.5
STEP: modifying the configmap once 08/22/23 04:42:55.505
STEP: changing the label value of the configmap 08/22/23 04:42:55.515
STEP: Expecting to observe a delete notification for the watched object 08/22/23 04:42:55.522
Aug 22 04:42:55.522: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3486  bd887c0b-9f91-4021-b119-ae3e04bc9b94 1265848 0 2023-08-22 04:42:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-08-22 04:42:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 22 04:42:55.522: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3486  bd887c0b-9f91-4021-b119-ae3e04bc9b94 1265849 0 2023-08-22 04:42:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-08-22 04:42:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 22 04:42:55.522: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3486  bd887c0b-9f91-4021-b119-ae3e04bc9b94 1265850 0 2023-08-22 04:42:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-08-22 04:42:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 08/22/23 04:42:55.523
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 08/22/23 04:42:55.529
STEP: changing the label value of the configmap back 08/22/23 04:43:05.53
STEP: modifying the configmap a third time 08/22/23 04:43:05.539
STEP: deleting the configmap 08/22/23 04:43:05.546
STEP: Expecting to observe an add notification for the watched object when the label value was restored 08/22/23 04:43:05.551
Aug 22 04:43:05.551: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3486  bd887c0b-9f91-4021-b119-ae3e04bc9b94 1265904 0 2023-08-22 04:42:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-08-22 04:43:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 22 04:43:05.551: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3486  bd887c0b-9f91-4021-b119-ae3e04bc9b94 1265905 0 2023-08-22 04:42:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-08-22 04:43:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 22 04:43:05.552: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3486  bd887c0b-9f91-4021-b119-ae3e04bc9b94 1265906 0 2023-08-22 04:42:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-08-22 04:43:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 22 04:43:05.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3486" for this suite. 08/22/23 04:43:05.555
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":154,"skipped":2690,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.590 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:42:55.218
    Aug 22 04:42:55.218: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename watch 08/22/23 04:42:55.22
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:42:55.489
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:42:55.493
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 08/22/23 04:42:55.498
    STEP: creating a new configmap 08/22/23 04:42:55.5
    STEP: modifying the configmap once 08/22/23 04:42:55.505
    STEP: changing the label value of the configmap 08/22/23 04:42:55.515
    STEP: Expecting to observe a delete notification for the watched object 08/22/23 04:42:55.522
    Aug 22 04:42:55.522: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3486  bd887c0b-9f91-4021-b119-ae3e04bc9b94 1265848 0 2023-08-22 04:42:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-08-22 04:42:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 22 04:42:55.522: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3486  bd887c0b-9f91-4021-b119-ae3e04bc9b94 1265849 0 2023-08-22 04:42:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-08-22 04:42:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 22 04:42:55.522: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3486  bd887c0b-9f91-4021-b119-ae3e04bc9b94 1265850 0 2023-08-22 04:42:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-08-22 04:42:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 08/22/23 04:42:55.523
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 08/22/23 04:42:55.529
    STEP: changing the label value of the configmap back 08/22/23 04:43:05.53
    STEP: modifying the configmap a third time 08/22/23 04:43:05.539
    STEP: deleting the configmap 08/22/23 04:43:05.546
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 08/22/23 04:43:05.551
    Aug 22 04:43:05.551: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3486  bd887c0b-9f91-4021-b119-ae3e04bc9b94 1265904 0 2023-08-22 04:42:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-08-22 04:43:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 22 04:43:05.551: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3486  bd887c0b-9f91-4021-b119-ae3e04bc9b94 1265905 0 2023-08-22 04:42:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-08-22 04:43:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 22 04:43:05.552: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3486  bd887c0b-9f91-4021-b119-ae3e04bc9b94 1265906 0 2023-08-22 04:42:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-08-22 04:43:05 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 22 04:43:05.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-3486" for this suite. 08/22/23 04:43:05.555
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:43:05.81
Aug 22 04:43:05.811: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pods 08/22/23 04:43:05.812
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:43:06.078
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:43:06.081
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Aug 22 04:43:06.084: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: creating the pod 08/22/23 04:43:06.084
STEP: submitting the pod to kubernetes 08/22/23 04:43:06.084
Aug 22 04:43:06.094: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f" in namespace "pods-8530" to be "running and ready"
Aug 22 04:43:06.129: INFO: Pod "pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f": Phase="Pending", Reason="", readiness=false. Elapsed: 34.322161ms
Aug 22 04:43:06.129: INFO: The phase of Pod pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:43:08.360: INFO: Pod "pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.265386655s
Aug 22 04:43:08.360: INFO: The phase of Pod pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:43:10.226: INFO: Pod "pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f": Phase="Running", Reason="", readiness=true. Elapsed: 4.131291213s
Aug 22 04:43:10.226: INFO: The phase of Pod pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f is Running (Ready = true)
Aug 22 04:43:10.226: INFO: Pod "pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 22 04:43:10.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8530" for this suite. 08/22/23 04:43:10.298
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":155,"skipped":2713,"failed":0}
------------------------------
â€¢ [4.496 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:43:05.81
    Aug 22 04:43:05.811: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pods 08/22/23 04:43:05.812
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:43:06.078
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:43:06.081
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Aug 22 04:43:06.084: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: creating the pod 08/22/23 04:43:06.084
    STEP: submitting the pod to kubernetes 08/22/23 04:43:06.084
    Aug 22 04:43:06.094: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f" in namespace "pods-8530" to be "running and ready"
    Aug 22 04:43:06.129: INFO: Pod "pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f": Phase="Pending", Reason="", readiness=false. Elapsed: 34.322161ms
    Aug 22 04:43:06.129: INFO: The phase of Pod pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:43:08.360: INFO: Pod "pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.265386655s
    Aug 22 04:43:08.360: INFO: The phase of Pod pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:43:10.226: INFO: Pod "pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f": Phase="Running", Reason="", readiness=true. Elapsed: 4.131291213s
    Aug 22 04:43:10.226: INFO: The phase of Pod pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f is Running (Ready = true)
    Aug 22 04:43:10.226: INFO: Pod "pod-logs-websocket-c03d3950-e74b-4ba7-b29f-44f07d54426f" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 22 04:43:10.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8530" for this suite. 08/22/23 04:43:10.298
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:43:10.309
Aug 22 04:43:10.309: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename runtimeclass 08/22/23 04:43:10.31
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:43:10.348
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:43:10.351
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 08/22/23 04:43:10.355
STEP: getting /apis/node.k8s.io 08/22/23 04:43:10.358
STEP: getting /apis/node.k8s.io/v1 08/22/23 04:43:10.359
STEP: creating 08/22/23 04:43:10.361
STEP: watching 08/22/23 04:43:10.528
Aug 22 04:43:10.528: INFO: starting watch
STEP: getting 08/22/23 04:43:10.542
STEP: listing 08/22/23 04:43:10.545
STEP: patching 08/22/23 04:43:10.549
STEP: updating 08/22/23 04:43:10.859
Aug 22 04:43:10.866: INFO: waiting for watch events with expected annotations
STEP: deleting 08/22/23 04:43:10.866
STEP: deleting a collection 08/22/23 04:43:10.879
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 22 04:43:10.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-3847" for this suite. 08/22/23 04:43:10.896
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":156,"skipped":2720,"failed":0}
------------------------------
â€¢ [0.595 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:43:10.309
    Aug 22 04:43:10.309: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename runtimeclass 08/22/23 04:43:10.31
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:43:10.348
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:43:10.351
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 08/22/23 04:43:10.355
    STEP: getting /apis/node.k8s.io 08/22/23 04:43:10.358
    STEP: getting /apis/node.k8s.io/v1 08/22/23 04:43:10.359
    STEP: creating 08/22/23 04:43:10.361
    STEP: watching 08/22/23 04:43:10.528
    Aug 22 04:43:10.528: INFO: starting watch
    STEP: getting 08/22/23 04:43:10.542
    STEP: listing 08/22/23 04:43:10.545
    STEP: patching 08/22/23 04:43:10.549
    STEP: updating 08/22/23 04:43:10.859
    Aug 22 04:43:10.866: INFO: waiting for watch events with expected annotations
    STEP: deleting 08/22/23 04:43:10.866
    STEP: deleting a collection 08/22/23 04:43:10.879
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 22 04:43:10.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-3847" for this suite. 08/22/23 04:43:10.896
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:43:10.908
Aug 22 04:43:10.908: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 04:43:10.908
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:43:10.943
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:43:10.945
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 08/22/23 04:43:10.949
Aug 22 04:43:10.960: INFO: Waiting up to 5m0s for pod "downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc" in namespace "downward-api-6556" to be "Succeeded or Failed"
Aug 22 04:43:10.964: INFO: Pod "downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.725439ms
Aug 22 04:43:12.970: INFO: Pod "downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009862226s
Aug 22 04:43:14.971: INFO: Pod "downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010733143s
Aug 22 04:43:16.970: INFO: Pod "downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009575355s
STEP: Saw pod success 08/22/23 04:43:16.97
Aug 22 04:43:16.970: INFO: Pod "downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc" satisfied condition "Succeeded or Failed"
Aug 22 04:43:16.972: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc container dapi-container: <nil>
STEP: delete the pod 08/22/23 04:43:17.003
Aug 22 04:43:17.172: INFO: Waiting for pod downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc to disappear
Aug 22 04:43:17.176: INFO: Pod downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 22 04:43:17.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6556" for this suite. 08/22/23 04:43:17.179
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":157,"skipped":2735,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.448 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:43:10.908
    Aug 22 04:43:10.908: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 04:43:10.908
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:43:10.943
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:43:10.945
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 08/22/23 04:43:10.949
    Aug 22 04:43:10.960: INFO: Waiting up to 5m0s for pod "downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc" in namespace "downward-api-6556" to be "Succeeded or Failed"
    Aug 22 04:43:10.964: INFO: Pod "downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.725439ms
    Aug 22 04:43:12.970: INFO: Pod "downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009862226s
    Aug 22 04:43:14.971: INFO: Pod "downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010733143s
    Aug 22 04:43:16.970: INFO: Pod "downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009575355s
    STEP: Saw pod success 08/22/23 04:43:16.97
    Aug 22 04:43:16.970: INFO: Pod "downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc" satisfied condition "Succeeded or Failed"
    Aug 22 04:43:16.972: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc container dapi-container: <nil>
    STEP: delete the pod 08/22/23 04:43:17.003
    Aug 22 04:43:17.172: INFO: Waiting for pod downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc to disappear
    Aug 22 04:43:17.176: INFO: Pod downward-api-ab84734d-b233-4002-93ea-1c777f70f1bc no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 22 04:43:17.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6556" for this suite. 08/22/23 04:43:17.179
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:43:17.355
Aug 22 04:43:17.356: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 04:43:17.356
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:43:17.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:43:17.42
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 08/22/23 04:43:17.425
Aug 22 04:43:17.446: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb" in namespace "downward-api-1775" to be "Succeeded or Failed"
Aug 22 04:43:17.480: INFO: Pod "downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb": Phase="Pending", Reason="", readiness=false. Elapsed: 33.80391ms
Aug 22 04:43:19.614: INFO: Pod "downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.167986935s
Aug 22 04:43:21.489: INFO: Pod "downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043065204s
Aug 22 04:43:23.483: INFO: Pod "downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036952488s
STEP: Saw pod success 08/22/23 04:43:23.483
Aug 22 04:43:23.483: INFO: Pod "downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb" satisfied condition "Succeeded or Failed"
Aug 22 04:43:23.485: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb container client-container: <nil>
STEP: delete the pod 08/22/23 04:43:23.493
Aug 22 04:43:23.525: INFO: Waiting for pod downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb to disappear
Aug 22 04:43:23.528: INFO: Pod downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 22 04:43:23.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1775" for this suite. 08/22/23 04:43:23.531
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":158,"skipped":2736,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.182 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:43:17.355
    Aug 22 04:43:17.356: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 04:43:17.356
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:43:17.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:43:17.42
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 08/22/23 04:43:17.425
    Aug 22 04:43:17.446: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb" in namespace "downward-api-1775" to be "Succeeded or Failed"
    Aug 22 04:43:17.480: INFO: Pod "downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb": Phase="Pending", Reason="", readiness=false. Elapsed: 33.80391ms
    Aug 22 04:43:19.614: INFO: Pod "downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.167986935s
    Aug 22 04:43:21.489: INFO: Pod "downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043065204s
    Aug 22 04:43:23.483: INFO: Pod "downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036952488s
    STEP: Saw pod success 08/22/23 04:43:23.483
    Aug 22 04:43:23.483: INFO: Pod "downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb" satisfied condition "Succeeded or Failed"
    Aug 22 04:43:23.485: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb container client-container: <nil>
    STEP: delete the pod 08/22/23 04:43:23.493
    Aug 22 04:43:23.525: INFO: Waiting for pod downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb to disappear
    Aug 22 04:43:23.528: INFO: Pod downwardapi-volume-0defba88-5306-4288-9eaa-e6377d1bdbfb no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 22 04:43:23.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1775" for this suite. 08/22/23 04:43:23.531
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:43:23.539
Aug 22 04:43:23.539: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename endpointslice 08/22/23 04:43:23.54
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:43:23.573
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:43:23.575
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 08/22/23 04:43:28.837
STEP: referencing matching pods with named port 08/22/23 04:43:33.847
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 08/22/23 04:43:38.854
STEP: recreating EndpointSlices after they've been deleted 08/22/23 04:43:43.862
Aug 22 04:43:43.886: INFO: EndpointSlice for Service endpointslice-612/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Aug 22 04:43:53.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-612" for this suite. 08/22/23 04:43:53.9
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":159,"skipped":2806,"failed":0}
------------------------------
â€¢ [SLOW TEST] [30.417 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:43:23.539
    Aug 22 04:43:23.539: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename endpointslice 08/22/23 04:43:23.54
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:43:23.573
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:43:23.575
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 08/22/23 04:43:28.837
    STEP: referencing matching pods with named port 08/22/23 04:43:33.847
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 08/22/23 04:43:38.854
    STEP: recreating EndpointSlices after they've been deleted 08/22/23 04:43:43.862
    Aug 22 04:43:43.886: INFO: EndpointSlice for Service endpointslice-612/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Aug 22 04:43:53.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-612" for this suite. 08/22/23 04:43:53.9
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:43:53.956
Aug 22 04:43:53.956: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename taint-multiple-pods 08/22/23 04:43:53.957
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:43:53.988
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:43:53.99
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Aug 22 04:43:53.993: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 22 04:44:54.019: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Aug 22 04:44:54.024: INFO: Starting informer...
STEP: Starting pods... 08/22/23 04:44:54.024
Aug 22 04:44:54.248: INFO: Pod1 is running on jake-melb-gmyyva4zrlsz-node-2. Tainting Node
Aug 22 04:44:54.554: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-7343" to be "running"
Aug 22 04:44:54.558: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.843011ms
Aug 22 04:44:56.669: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114768061s
Aug 22 04:44:58.563: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 4.008942144s
Aug 22 04:44:58.563: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Aug 22 04:44:58.563: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-7343" to be "running"
Aug 22 04:44:58.566: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 2.512314ms
Aug 22 04:44:58.566: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Aug 22 04:44:58.566: INFO: Pod2 is running on jake-melb-gmyyva4zrlsz-node-2. Tainting Node
STEP: Trying to apply a taint on the Node 08/22/23 04:44:58.566
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/22/23 04:44:58.611
STEP: Waiting for Pod1 and Pod2 to be deleted 08/22/23 04:44:58.625
Aug 22 04:45:05.841: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Aug 22 04:45:24.082: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/22/23 04:45:24.254
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Aug 22 04:45:24.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-7343" for this suite. 08/22/23 04:45:24.265
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":160,"skipped":2809,"failed":0}
------------------------------
â€¢ [SLOW TEST] [90.315 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:43:53.956
    Aug 22 04:43:53.956: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename taint-multiple-pods 08/22/23 04:43:53.957
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:43:53.988
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:43:53.99
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Aug 22 04:43:53.993: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 22 04:44:54.019: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Aug 22 04:44:54.024: INFO: Starting informer...
    STEP: Starting pods... 08/22/23 04:44:54.024
    Aug 22 04:44:54.248: INFO: Pod1 is running on jake-melb-gmyyva4zrlsz-node-2. Tainting Node
    Aug 22 04:44:54.554: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-7343" to be "running"
    Aug 22 04:44:54.558: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.843011ms
    Aug 22 04:44:56.669: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114768061s
    Aug 22 04:44:58.563: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 4.008942144s
    Aug 22 04:44:58.563: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Aug 22 04:44:58.563: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-7343" to be "running"
    Aug 22 04:44:58.566: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 2.512314ms
    Aug 22 04:44:58.566: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Aug 22 04:44:58.566: INFO: Pod2 is running on jake-melb-gmyyva4zrlsz-node-2. Tainting Node
    STEP: Trying to apply a taint on the Node 08/22/23 04:44:58.566
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/22/23 04:44:58.611
    STEP: Waiting for Pod1 and Pod2 to be deleted 08/22/23 04:44:58.625
    Aug 22 04:45:05.841: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Aug 22 04:45:24.082: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/22/23 04:45:24.254
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 04:45:24.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-7343" for this suite. 08/22/23 04:45:24.265
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:45:24.273
Aug 22 04:45:24.273: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename podtemplate 08/22/23 04:45:24.273
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:45:24.315
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:45:24.318
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 08/22/23 04:45:24.322
Aug 22 04:45:24.344: INFO: created test-podtemplate-1
Aug 22 04:45:24.368: INFO: created test-podtemplate-2
Aug 22 04:45:24.379: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 08/22/23 04:45:24.379
STEP: delete collection of pod templates 08/22/23 04:45:24.382
Aug 22 04:45:24.383: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 08/22/23 04:45:24.4
Aug 22 04:45:24.400: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Aug 22 04:45:24.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-134" for this suite. 08/22/23 04:45:24.407
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":161,"skipped":2836,"failed":0}
------------------------------
â€¢ [0.142 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:45:24.273
    Aug 22 04:45:24.273: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename podtemplate 08/22/23 04:45:24.273
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:45:24.315
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:45:24.318
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 08/22/23 04:45:24.322
    Aug 22 04:45:24.344: INFO: created test-podtemplate-1
    Aug 22 04:45:24.368: INFO: created test-podtemplate-2
    Aug 22 04:45:24.379: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 08/22/23 04:45:24.379
    STEP: delete collection of pod templates 08/22/23 04:45:24.382
    Aug 22 04:45:24.383: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 08/22/23 04:45:24.4
    Aug 22 04:45:24.400: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Aug 22 04:45:24.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-134" for this suite. 08/22/23 04:45:24.407
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:45:24.416
Aug 22 04:45:24.416: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 04:45:24.416
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:45:24.771
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:45:24.773
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 08/22/23 04:45:24.777
Aug 22 04:45:24.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-1188 create -f -'
Aug 22 04:45:25.442: INFO: stderr: ""
Aug 22 04:45:25.442: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 08/22/23 04:45:25.442
Aug 22 04:45:26.447: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 04:45:26.447: INFO: Found 0 / 1
Aug 22 04:45:27.446: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 04:45:27.446: INFO: Found 0 / 1
Aug 22 04:45:28.447: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 04:45:28.447: INFO: Found 0 / 1
Aug 22 04:45:29.446: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 04:45:29.446: INFO: Found 1 / 1
Aug 22 04:45:29.446: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 08/22/23 04:45:29.446
Aug 22 04:45:29.449: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 04:45:29.449: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 22 04:45:29.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-1188 patch pod agnhost-primary-tlnxd -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 22 04:45:29.785: INFO: stderr: ""
Aug 22 04:45:29.785: INFO: stdout: "pod/agnhost-primary-tlnxd patched\n"
STEP: checking annotations 08/22/23 04:45:29.785
Aug 22 04:45:29.806: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 04:45:29.806: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 04:45:29.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1188" for this suite. 08/22/23 04:45:29.812
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":162,"skipped":2845,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.402 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:45:24.416
    Aug 22 04:45:24.416: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 04:45:24.416
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:45:24.771
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:45:24.773
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 08/22/23 04:45:24.777
    Aug 22 04:45:24.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-1188 create -f -'
    Aug 22 04:45:25.442: INFO: stderr: ""
    Aug 22 04:45:25.442: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 08/22/23 04:45:25.442
    Aug 22 04:45:26.447: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 04:45:26.447: INFO: Found 0 / 1
    Aug 22 04:45:27.446: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 04:45:27.446: INFO: Found 0 / 1
    Aug 22 04:45:28.447: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 04:45:28.447: INFO: Found 0 / 1
    Aug 22 04:45:29.446: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 04:45:29.446: INFO: Found 1 / 1
    Aug 22 04:45:29.446: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 08/22/23 04:45:29.446
    Aug 22 04:45:29.449: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 04:45:29.449: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Aug 22 04:45:29.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-1188 patch pod agnhost-primary-tlnxd -p {"metadata":{"annotations":{"x":"y"}}}'
    Aug 22 04:45:29.785: INFO: stderr: ""
    Aug 22 04:45:29.785: INFO: stdout: "pod/agnhost-primary-tlnxd patched\n"
    STEP: checking annotations 08/22/23 04:45:29.785
    Aug 22 04:45:29.806: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 04:45:29.806: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 04:45:29.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1188" for this suite. 08/22/23 04:45:29.812
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:45:29.819
Aug 22 04:45:29.819: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename sched-preemption 08/22/23 04:45:29.819
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:45:30.178
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:45:30.181
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug 22 04:45:30.336: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 22 04:46:30.409: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 08/22/23 04:46:30.413
Aug 22 04:46:30.634: INFO: Created pod: pod0-0-sched-preemption-low-priority
Aug 22 04:46:30.652: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Aug 22 04:46:31.026: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Aug 22 04:46:31.421: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Aug 22 04:46:31.686: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Aug 22 04:46:31.827: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 08/22/23 04:46:31.827
Aug 22 04:46:31.827: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-149" to be "running"
Aug 22 04:46:31.833: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 5.846179ms
Aug 22 04:46:33.838: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01126738s
Aug 22 04:46:35.839: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.011600364s
Aug 22 04:46:35.839: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Aug 22 04:46:35.839: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-149" to be "running"
Aug 22 04:46:35.842: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.390941ms
Aug 22 04:46:37.896: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.057323616s
Aug 22 04:46:37.896: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Aug 22 04:46:37.896: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-149" to be "running"
Aug 22 04:46:37.900: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.74229ms
Aug 22 04:46:39.933: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036396915s
Aug 22 04:46:42.027: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.130508228s
Aug 22 04:46:43.904: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007542609s
Aug 22 04:46:45.904: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.007540545s
Aug 22 04:46:45.904: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Aug 22 04:46:45.904: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-149" to be "running"
Aug 22 04:46:45.907: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.39534ms
Aug 22 04:46:45.907: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Aug 22 04:46:45.907: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-149" to be "running"
Aug 22 04:46:45.910: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.091831ms
Aug 22 04:46:45.910: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Aug 22 04:46:45.910: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-149" to be "running"
Aug 22 04:46:45.913: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.484582ms
Aug 22 04:46:45.913: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 08/22/23 04:46:45.913
Aug 22 04:46:45.928: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Aug 22 04:46:45.932: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.865682ms
Aug 22 04:46:47.936: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008422279s
Aug 22 04:46:49.936: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008352459s
Aug 22 04:46:51.936: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.007971305s
Aug 22 04:46:51.936: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Aug 22 04:46:52.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-149" for this suite. 08/22/23 04:46:52.058
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":163,"skipped":2862,"failed":0}
------------------------------
â€¢ [SLOW TEST] [82.318 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:45:29.819
    Aug 22 04:45:29.819: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename sched-preemption 08/22/23 04:45:29.819
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:45:30.178
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:45:30.181
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Aug 22 04:45:30.336: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 22 04:46:30.409: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 08/22/23 04:46:30.413
    Aug 22 04:46:30.634: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Aug 22 04:46:30.652: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Aug 22 04:46:31.026: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Aug 22 04:46:31.421: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Aug 22 04:46:31.686: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Aug 22 04:46:31.827: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 08/22/23 04:46:31.827
    Aug 22 04:46:31.827: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-149" to be "running"
    Aug 22 04:46:31.833: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 5.846179ms
    Aug 22 04:46:33.838: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01126738s
    Aug 22 04:46:35.839: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.011600364s
    Aug 22 04:46:35.839: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Aug 22 04:46:35.839: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-149" to be "running"
    Aug 22 04:46:35.842: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.390941ms
    Aug 22 04:46:37.896: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.057323616s
    Aug 22 04:46:37.896: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Aug 22 04:46:37.896: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-149" to be "running"
    Aug 22 04:46:37.900: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.74229ms
    Aug 22 04:46:39.933: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036396915s
    Aug 22 04:46:42.027: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.130508228s
    Aug 22 04:46:43.904: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007542609s
    Aug 22 04:46:45.904: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.007540545s
    Aug 22 04:46:45.904: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Aug 22 04:46:45.904: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-149" to be "running"
    Aug 22 04:46:45.907: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.39534ms
    Aug 22 04:46:45.907: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Aug 22 04:46:45.907: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-149" to be "running"
    Aug 22 04:46:45.910: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.091831ms
    Aug 22 04:46:45.910: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Aug 22 04:46:45.910: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-149" to be "running"
    Aug 22 04:46:45.913: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.484582ms
    Aug 22 04:46:45.913: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 08/22/23 04:46:45.913
    Aug 22 04:46:45.928: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Aug 22 04:46:45.932: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.865682ms
    Aug 22 04:46:47.936: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008422279s
    Aug 22 04:46:49.936: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008352459s
    Aug 22 04:46:51.936: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.007971305s
    Aug 22 04:46:51.936: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 04:46:52.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-149" for this suite. 08/22/23 04:46:52.058
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:46:52.137
Aug 22 04:46:52.137: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-probe 08/22/23 04:46:52.138
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:46:52.319
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:46:52.323
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Aug 22 04:46:52.347: INFO: Waiting up to 5m0s for pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf" in namespace "container-probe-5256" to be "running and ready"
Aug 22 04:46:52.355: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Pending", Reason="", readiness=false. Elapsed: 7.370438ms
Aug 22 04:46:52.355: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:46:54.462: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114251228s
Aug 22 04:46:54.462: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:46:56.360: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 4.012690197s
Aug 22 04:46:56.360: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
Aug 22 04:46:58.388: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 6.040704677s
Aug 22 04:46:58.388: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
Aug 22 04:47:00.361: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 8.013376185s
Aug 22 04:47:00.361: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
Aug 22 04:47:02.360: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 10.012413028s
Aug 22 04:47:02.360: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
Aug 22 04:47:04.361: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 12.013834807s
Aug 22 04:47:04.361: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
Aug 22 04:47:06.359: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 14.011738975s
Aug 22 04:47:06.359: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
Aug 22 04:47:08.366: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 16.018342802s
Aug 22 04:47:08.366: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
Aug 22 04:47:10.362: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 18.014163885s
Aug 22 04:47:10.362: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
Aug 22 04:47:12.359: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 20.011460572s
Aug 22 04:47:12.359: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
Aug 22 04:47:14.360: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=true. Elapsed: 22.01238201s
Aug 22 04:47:14.360: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = true)
Aug 22 04:47:14.360: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf" satisfied condition "running and ready"
Aug 22 04:47:14.362: INFO: Container started at 2023-08-22 04:46:54 +0000 UTC, pod became ready at 2023-08-22 04:47:12 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 22 04:47:14.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5256" for this suite. 08/22/23 04:47:14.378
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":164,"skipped":2877,"failed":0}
------------------------------
â€¢ [SLOW TEST] [22.253 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:46:52.137
    Aug 22 04:46:52.137: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-probe 08/22/23 04:46:52.138
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:46:52.319
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:46:52.323
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Aug 22 04:46:52.347: INFO: Waiting up to 5m0s for pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf" in namespace "container-probe-5256" to be "running and ready"
    Aug 22 04:46:52.355: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Pending", Reason="", readiness=false. Elapsed: 7.370438ms
    Aug 22 04:46:52.355: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:46:54.462: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114251228s
    Aug 22 04:46:54.462: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:46:56.360: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 4.012690197s
    Aug 22 04:46:56.360: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
    Aug 22 04:46:58.388: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 6.040704677s
    Aug 22 04:46:58.388: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
    Aug 22 04:47:00.361: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 8.013376185s
    Aug 22 04:47:00.361: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
    Aug 22 04:47:02.360: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 10.012413028s
    Aug 22 04:47:02.360: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
    Aug 22 04:47:04.361: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 12.013834807s
    Aug 22 04:47:04.361: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
    Aug 22 04:47:06.359: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 14.011738975s
    Aug 22 04:47:06.359: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
    Aug 22 04:47:08.366: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 16.018342802s
    Aug 22 04:47:08.366: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
    Aug 22 04:47:10.362: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 18.014163885s
    Aug 22 04:47:10.362: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
    Aug 22 04:47:12.359: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=false. Elapsed: 20.011460572s
    Aug 22 04:47:12.359: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = false)
    Aug 22 04:47:14.360: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf": Phase="Running", Reason="", readiness=true. Elapsed: 22.01238201s
    Aug 22 04:47:14.360: INFO: The phase of Pod test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf is Running (Ready = true)
    Aug 22 04:47:14.360: INFO: Pod "test-webserver-fcf8da90-f8bc-4190-bdd8-76076b7ae7bf" satisfied condition "running and ready"
    Aug 22 04:47:14.362: INFO: Container started at 2023-08-22 04:46:54 +0000 UTC, pod became ready at 2023-08-22 04:47:12 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 22 04:47:14.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5256" for this suite. 08/22/23 04:47:14.378
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:47:14.391
Aug 22 04:47:14.392: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 04:47:14.392
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:47:14.409
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:47:14.412
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-6ab0d977-d008-4799-9945-cf957286439f 08/22/23 04:47:14.416
STEP: Creating a pod to test consume configMaps 08/22/23 04:47:14.421
Aug 22 04:47:14.428: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db" in namespace "configmap-1822" to be "Succeeded or Failed"
Aug 22 04:47:14.432: INFO: Pod "pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db": Phase="Pending", Reason="", readiness=false. Elapsed: 3.227154ms
Aug 22 04:47:16.436: INFO: Pod "pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007425311s
Aug 22 04:47:18.436: INFO: Pod "pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007482318s
Aug 22 04:47:20.437: INFO: Pod "pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008407983s
STEP: Saw pod success 08/22/23 04:47:20.437
Aug 22 04:47:20.437: INFO: Pod "pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db" satisfied condition "Succeeded or Failed"
Aug 22 04:47:20.439: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db container agnhost-container: <nil>
STEP: delete the pod 08/22/23 04:47:20.48
Aug 22 04:47:20.494: INFO: Waiting for pod pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db to disappear
Aug 22 04:47:20.497: INFO: Pod pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 04:47:20.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1822" for this suite. 08/22/23 04:47:20.501
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":165,"skipped":2895,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.116 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:47:14.391
    Aug 22 04:47:14.392: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 04:47:14.392
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:47:14.409
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:47:14.412
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-6ab0d977-d008-4799-9945-cf957286439f 08/22/23 04:47:14.416
    STEP: Creating a pod to test consume configMaps 08/22/23 04:47:14.421
    Aug 22 04:47:14.428: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db" in namespace "configmap-1822" to be "Succeeded or Failed"
    Aug 22 04:47:14.432: INFO: Pod "pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db": Phase="Pending", Reason="", readiness=false. Elapsed: 3.227154ms
    Aug 22 04:47:16.436: INFO: Pod "pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007425311s
    Aug 22 04:47:18.436: INFO: Pod "pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007482318s
    Aug 22 04:47:20.437: INFO: Pod "pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008407983s
    STEP: Saw pod success 08/22/23 04:47:20.437
    Aug 22 04:47:20.437: INFO: Pod "pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db" satisfied condition "Succeeded or Failed"
    Aug 22 04:47:20.439: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 04:47:20.48
    Aug 22 04:47:20.494: INFO: Waiting for pod pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db to disappear
    Aug 22 04:47:20.497: INFO: Pod pod-configmaps-8b2d6308-6cff-48f6-b869-765e2a7756db no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 04:47:20.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1822" for this suite. 08/22/23 04:47:20.501
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:47:20.509
Aug 22 04:47:20.509: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename init-container 08/22/23 04:47:20.51
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:47:20.538
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:47:20.542
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 08/22/23 04:47:20.546
Aug 22 04:47:20.546: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 22 04:47:27.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6984" for this suite. 08/22/23 04:47:27.49
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":166,"skipped":2926,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.995 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:47:20.509
    Aug 22 04:47:20.509: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename init-container 08/22/23 04:47:20.51
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:47:20.538
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:47:20.542
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 08/22/23 04:47:20.546
    Aug 22 04:47:20.546: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 22 04:47:27.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-6984" for this suite. 08/22/23 04:47:27.49
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:47:27.506
Aug 22 04:47:27.506: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 04:47:27.507
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:47:27.531
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:47:27.533
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 04:47:27.55
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 04:47:27.912
STEP: Deploying the webhook pod 08/22/23 04:47:28.043
STEP: Wait for the deployment to be ready 08/22/23 04:47:28.164
Aug 22 04:47:28.185: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 04:47:30.195: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 47, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 47, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 47, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 47, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 04:47:32.199
STEP: Verifying the service has paired with the endpoint 08/22/23 04:47:32.256
Aug 22 04:47:33.256: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 08/22/23 04:47:33.668
STEP: Creating a configMap that does not comply to the validation webhook rules 08/22/23 04:47:33.702
STEP: Deleting the collection of validation webhooks 08/22/23 04:47:33.734
STEP: Creating a configMap that does not comply to the validation webhook rules 08/22/23 04:47:34.3
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:47:34.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6560" for this suite. 08/22/23 04:47:34.315
STEP: Destroying namespace "webhook-6560-markers" for this suite. 08/22/23 04:47:34.322
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":167,"skipped":2950,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.085 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:47:27.506
    Aug 22 04:47:27.506: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 04:47:27.507
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:47:27.531
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:47:27.533
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 04:47:27.55
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 04:47:27.912
    STEP: Deploying the webhook pod 08/22/23 04:47:28.043
    STEP: Wait for the deployment to be ready 08/22/23 04:47:28.164
    Aug 22 04:47:28.185: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 04:47:30.195: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 47, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 47, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 47, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 47, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 04:47:32.199
    STEP: Verifying the service has paired with the endpoint 08/22/23 04:47:32.256
    Aug 22 04:47:33.256: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 08/22/23 04:47:33.668
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/22/23 04:47:33.702
    STEP: Deleting the collection of validation webhooks 08/22/23 04:47:33.734
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/22/23 04:47:34.3
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:47:34.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6560" for this suite. 08/22/23 04:47:34.315
    STEP: Destroying namespace "webhook-6560-markers" for this suite. 08/22/23 04:47:34.322
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:47:34.592
Aug 22 04:47:34.593: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename replicaset 08/22/23 04:47:34.593
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:47:34.658
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:47:34.661
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 08/22/23 04:47:34.669
STEP: Verify that the required pods have come up. 08/22/23 04:47:34.702
Aug 22 04:47:34.724: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/22/23 04:47:34.724
Aug 22 04:47:34.724: INFO: Waiting up to 5m0s for pod "test-rs-vjh4m" in namespace "replicaset-4006" to be "running"
Aug 22 04:47:34.730: INFO: Pod "test-rs-vjh4m": Phase="Pending", Reason="", readiness=false. Elapsed: 6.229386ms
Aug 22 04:47:36.735: INFO: Pod "test-rs-vjh4m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010841099s
Aug 22 04:47:38.780: INFO: Pod "test-rs-vjh4m": Phase="Running", Reason="", readiness=true. Elapsed: 4.055817279s
Aug 22 04:47:38.780: INFO: Pod "test-rs-vjh4m" satisfied condition "running"
STEP: Getting /status 08/22/23 04:47:38.78
Aug 22 04:47:38.784: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 08/22/23 04:47:38.784
Aug 22 04:47:38.989: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 08/22/23 04:47:38.989
Aug 22 04:47:38.992: INFO: Observed &ReplicaSet event: ADDED
Aug 22 04:47:38.993: INFO: Observed &ReplicaSet event: MODIFIED
Aug 22 04:47:38.993: INFO: Observed &ReplicaSet event: MODIFIED
Aug 22 04:47:38.993: INFO: Observed &ReplicaSet event: MODIFIED
Aug 22 04:47:38.993: INFO: Found replicaset test-rs in namespace replicaset-4006 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 22 04:47:38.993: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 08/22/23 04:47:38.993
Aug 22 04:47:38.993: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug 22 04:47:39.007: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 08/22/23 04:47:39.007
Aug 22 04:47:39.009: INFO: Observed &ReplicaSet event: ADDED
Aug 22 04:47:39.009: INFO: Observed &ReplicaSet event: MODIFIED
Aug 22 04:47:39.009: INFO: Observed &ReplicaSet event: MODIFIED
Aug 22 04:47:39.010: INFO: Observed &ReplicaSet event: MODIFIED
Aug 22 04:47:39.010: INFO: Observed replicaset test-rs in namespace replicaset-4006 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 22 04:47:39.010: INFO: Observed &ReplicaSet event: MODIFIED
Aug 22 04:47:39.010: INFO: Found replicaset test-rs in namespace replicaset-4006 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Aug 22 04:47:39.010: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 22 04:47:39.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4006" for this suite. 08/22/23 04:47:39.015
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":168,"skipped":2986,"failed":0}
------------------------------
â€¢ [4.432 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:47:34.592
    Aug 22 04:47:34.593: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename replicaset 08/22/23 04:47:34.593
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:47:34.658
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:47:34.661
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 08/22/23 04:47:34.669
    STEP: Verify that the required pods have come up. 08/22/23 04:47:34.702
    Aug 22 04:47:34.724: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/22/23 04:47:34.724
    Aug 22 04:47:34.724: INFO: Waiting up to 5m0s for pod "test-rs-vjh4m" in namespace "replicaset-4006" to be "running"
    Aug 22 04:47:34.730: INFO: Pod "test-rs-vjh4m": Phase="Pending", Reason="", readiness=false. Elapsed: 6.229386ms
    Aug 22 04:47:36.735: INFO: Pod "test-rs-vjh4m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010841099s
    Aug 22 04:47:38.780: INFO: Pod "test-rs-vjh4m": Phase="Running", Reason="", readiness=true. Elapsed: 4.055817279s
    Aug 22 04:47:38.780: INFO: Pod "test-rs-vjh4m" satisfied condition "running"
    STEP: Getting /status 08/22/23 04:47:38.78
    Aug 22 04:47:38.784: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 08/22/23 04:47:38.784
    Aug 22 04:47:38.989: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 08/22/23 04:47:38.989
    Aug 22 04:47:38.992: INFO: Observed &ReplicaSet event: ADDED
    Aug 22 04:47:38.993: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 22 04:47:38.993: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 22 04:47:38.993: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 22 04:47:38.993: INFO: Found replicaset test-rs in namespace replicaset-4006 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Aug 22 04:47:38.993: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 08/22/23 04:47:38.993
    Aug 22 04:47:38.993: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Aug 22 04:47:39.007: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 08/22/23 04:47:39.007
    Aug 22 04:47:39.009: INFO: Observed &ReplicaSet event: ADDED
    Aug 22 04:47:39.009: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 22 04:47:39.009: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 22 04:47:39.010: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 22 04:47:39.010: INFO: Observed replicaset test-rs in namespace replicaset-4006 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Aug 22 04:47:39.010: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 22 04:47:39.010: INFO: Found replicaset test-rs in namespace replicaset-4006 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Aug 22 04:47:39.010: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 22 04:47:39.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4006" for this suite. 08/22/23 04:47:39.015
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:47:39.025
Aug 22 04:47:39.025: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 04:47:39.025
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:47:39.041
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:47:39.044
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216
STEP: creating service in namespace services-9000 08/22/23 04:47:39.046
STEP: creating service affinity-nodeport-transition in namespace services-9000 08/22/23 04:47:39.047
STEP: creating replication controller affinity-nodeport-transition in namespace services-9000 08/22/23 04:47:39.06
I0822 04:47:39.077219      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-9000, replica count: 3
I0822 04:47:42.127862      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 04:47:45.127999      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 22 04:47:45.578: INFO: Creating new exec pod
Aug 22 04:47:45.584: INFO: Waiting up to 5m0s for pod "execpod-affinityvz457" in namespace "services-9000" to be "running"
Aug 22 04:47:45.656: INFO: Pod "execpod-affinityvz457": Phase="Pending", Reason="", readiness=false. Elapsed: 72.123101ms
Aug 22 04:47:47.660: INFO: Pod "execpod-affinityvz457": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075996727s
Aug 22 04:47:49.729: INFO: Pod "execpod-affinityvz457": Phase="Running", Reason="", readiness=true. Elapsed: 4.144914798s
Aug 22 04:47:49.729: INFO: Pod "execpod-affinityvz457" satisfied condition "running"
Aug 22 04:47:50.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-9000 exec execpod-affinityvz457 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Aug 22 04:47:50.890: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Aug 22 04:47:50.890: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 04:47:50.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-9000 exec execpod-affinityvz457 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.248.14 80'
Aug 22 04:47:51.034: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.248.14 80\nConnection to 10.254.248.14 80 port [tcp/http] succeeded!\n"
Aug 22 04:47:51.034: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 04:47:51.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-9000 exec execpod-affinityvz457 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.130 30584'
Aug 22 04:47:51.185: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.0.130 30584\nConnection to 10.0.0.130 30584 port [tcp/*] succeeded!\n"
Aug 22 04:47:51.185: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 04:47:51.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-9000 exec execpod-affinityvz457 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.232 30584'
Aug 22 04:47:51.335: INFO: stderr: "+ nc -v -t -w 2 10.0.0.232 30584\n+ echo hostName\nConnection to 10.0.0.232 30584 port [tcp/*] succeeded!\n"
Aug 22 04:47:51.335: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 04:47:51.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-9000 exec execpod-affinityvz457 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.0.97:30584/ ; done'
Aug 22 04:47:51.587: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n"
Aug 22 04:47:51.587: INFO: stdout: "\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-r9b9p\naffinity-nodeport-transition-wft4p\naffinity-nodeport-transition-wft4p\naffinity-nodeport-transition-wft4p\naffinity-nodeport-transition-wft4p\naffinity-nodeport-transition-r9b9p\naffinity-nodeport-transition-r9b9p\naffinity-nodeport-transition-wft4p\naffinity-nodeport-transition-wft4p\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-r9b9p\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q"
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-r9b9p
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-wft4p
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-wft4p
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-wft4p
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-wft4p
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-r9b9p
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-r9b9p
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-wft4p
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-wft4p
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-r9b9p
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-9000 exec execpod-affinityvz457 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.0.97:30584/ ; done'
Aug 22 04:47:51.929: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n"
Aug 22 04:47:51.929: INFO: stdout: "\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q"
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
Aug 22 04:47:51.929: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-9000, will wait for the garbage collector to delete the pods 08/22/23 04:47:52.024
Aug 22 04:47:52.085: INFO: Deleting ReplicationController affinity-nodeport-transition took: 6.690562ms
Aug 22 04:47:52.585: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 500.084694ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 04:47:55.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9000" for this suite. 08/22/23 04:47:55.558
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":169,"skipped":2987,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.551 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:47:39.025
    Aug 22 04:47:39.025: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 04:47:39.025
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:47:39.041
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:47:39.044
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2216
    STEP: creating service in namespace services-9000 08/22/23 04:47:39.046
    STEP: creating service affinity-nodeport-transition in namespace services-9000 08/22/23 04:47:39.047
    STEP: creating replication controller affinity-nodeport-transition in namespace services-9000 08/22/23 04:47:39.06
    I0822 04:47:39.077219      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-9000, replica count: 3
    I0822 04:47:42.127862      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0822 04:47:45.127999      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 22 04:47:45.578: INFO: Creating new exec pod
    Aug 22 04:47:45.584: INFO: Waiting up to 5m0s for pod "execpod-affinityvz457" in namespace "services-9000" to be "running"
    Aug 22 04:47:45.656: INFO: Pod "execpod-affinityvz457": Phase="Pending", Reason="", readiness=false. Elapsed: 72.123101ms
    Aug 22 04:47:47.660: INFO: Pod "execpod-affinityvz457": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075996727s
    Aug 22 04:47:49.729: INFO: Pod "execpod-affinityvz457": Phase="Running", Reason="", readiness=true. Elapsed: 4.144914798s
    Aug 22 04:47:49.729: INFO: Pod "execpod-affinityvz457" satisfied condition "running"
    Aug 22 04:47:50.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-9000 exec execpod-affinityvz457 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Aug 22 04:47:50.890: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Aug 22 04:47:50.890: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 04:47:50.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-9000 exec execpod-affinityvz457 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.248.14 80'
    Aug 22 04:47:51.034: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.248.14 80\nConnection to 10.254.248.14 80 port [tcp/http] succeeded!\n"
    Aug 22 04:47:51.034: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 04:47:51.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-9000 exec execpod-affinityvz457 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.130 30584'
    Aug 22 04:47:51.185: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.0.130 30584\nConnection to 10.0.0.130 30584 port [tcp/*] succeeded!\n"
    Aug 22 04:47:51.185: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 04:47:51.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-9000 exec execpod-affinityvz457 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.232 30584'
    Aug 22 04:47:51.335: INFO: stderr: "+ nc -v -t -w 2 10.0.0.232 30584\n+ echo hostName\nConnection to 10.0.0.232 30584 port [tcp/*] succeeded!\n"
    Aug 22 04:47:51.335: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 04:47:51.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-9000 exec execpod-affinityvz457 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.0.97:30584/ ; done'
    Aug 22 04:47:51.587: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n"
    Aug 22 04:47:51.587: INFO: stdout: "\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-r9b9p\naffinity-nodeport-transition-wft4p\naffinity-nodeport-transition-wft4p\naffinity-nodeport-transition-wft4p\naffinity-nodeport-transition-wft4p\naffinity-nodeport-transition-r9b9p\naffinity-nodeport-transition-r9b9p\naffinity-nodeport-transition-wft4p\naffinity-nodeport-transition-wft4p\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-r9b9p\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q"
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-r9b9p
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-wft4p
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-wft4p
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-wft4p
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-wft4p
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-r9b9p
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-r9b9p
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-wft4p
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-wft4p
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-r9b9p
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.587: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-9000 exec execpod-affinityvz457 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.0.97:30584/ ; done'
    Aug 22 04:47:51.929: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.0.97:30584/\n"
    Aug 22 04:47:51.929: INFO: stdout: "\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q\naffinity-nodeport-transition-hq77q"
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Received response from host: affinity-nodeport-transition-hq77q
    Aug 22 04:47:51.929: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-9000, will wait for the garbage collector to delete the pods 08/22/23 04:47:52.024
    Aug 22 04:47:52.085: INFO: Deleting ReplicationController affinity-nodeport-transition took: 6.690562ms
    Aug 22 04:47:52.585: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 500.084694ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 04:47:55.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9000" for this suite. 08/22/23 04:47:55.558
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:47:55.576
Aug 22 04:47:55.576: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename var-expansion 08/22/23 04:47:55.577
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:47:55.61
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:47:55.615
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Aug 22 04:47:55.633: INFO: Waiting up to 2m0s for pod "var-expansion-4c199394-8a5f-40cb-8e53-4c90d84af2f7" in namespace "var-expansion-4757" to be "container 0 failed with reason CreateContainerConfigError"
Aug 22 04:47:55.644: INFO: Pod "var-expansion-4c199394-8a5f-40cb-8e53-4c90d84af2f7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.347594ms
Aug 22 04:47:57.649: INFO: Pod "var-expansion-4c199394-8a5f-40cb-8e53-4c90d84af2f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015486235s
Aug 22 04:47:59.648: INFO: Pod "var-expansion-4c199394-8a5f-40cb-8e53-4c90d84af2f7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014941844s
Aug 22 04:47:59.648: INFO: Pod "var-expansion-4c199394-8a5f-40cb-8e53-4c90d84af2f7" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Aug 22 04:47:59.648: INFO: Deleting pod "var-expansion-4c199394-8a5f-40cb-8e53-4c90d84af2f7" in namespace "var-expansion-4757"
Aug 22 04:47:59.749: INFO: Wait up to 5m0s for pod "var-expansion-4c199394-8a5f-40cb-8e53-4c90d84af2f7" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 22 04:48:01.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4757" for this suite. 08/22/23 04:48:01.762
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":170,"skipped":2987,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.194 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:47:55.576
    Aug 22 04:47:55.576: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename var-expansion 08/22/23 04:47:55.577
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:47:55.61
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:47:55.615
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Aug 22 04:47:55.633: INFO: Waiting up to 2m0s for pod "var-expansion-4c199394-8a5f-40cb-8e53-4c90d84af2f7" in namespace "var-expansion-4757" to be "container 0 failed with reason CreateContainerConfigError"
    Aug 22 04:47:55.644: INFO: Pod "var-expansion-4c199394-8a5f-40cb-8e53-4c90d84af2f7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.347594ms
    Aug 22 04:47:57.649: INFO: Pod "var-expansion-4c199394-8a5f-40cb-8e53-4c90d84af2f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015486235s
    Aug 22 04:47:59.648: INFO: Pod "var-expansion-4c199394-8a5f-40cb-8e53-4c90d84af2f7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014941844s
    Aug 22 04:47:59.648: INFO: Pod "var-expansion-4c199394-8a5f-40cb-8e53-4c90d84af2f7" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Aug 22 04:47:59.648: INFO: Deleting pod "var-expansion-4c199394-8a5f-40cb-8e53-4c90d84af2f7" in namespace "var-expansion-4757"
    Aug 22 04:47:59.749: INFO: Wait up to 5m0s for pod "var-expansion-4c199394-8a5f-40cb-8e53-4c90d84af2f7" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 22 04:48:01.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4757" for this suite. 08/22/23 04:48:01.762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:48:01.771
Aug 22 04:48:01.771: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename watch 08/22/23 04:48:01.771
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:48:01.819
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:48:01.821
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 08/22/23 04:48:01.824
STEP: starting a background goroutine to produce watch events 08/22/23 04:48:01.828
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 08/22/23 04:48:01.828
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 22 04:48:05.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2199" for this suite. 08/22/23 04:48:05.037
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":171,"skipped":3000,"failed":0}
------------------------------
â€¢ [3.273 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:48:01.771
    Aug 22 04:48:01.771: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename watch 08/22/23 04:48:01.771
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:48:01.819
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:48:01.821
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 08/22/23 04:48:01.824
    STEP: starting a background goroutine to produce watch events 08/22/23 04:48:01.828
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 08/22/23 04:48:01.828
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 22 04:48:05.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2199" for this suite. 08/22/23 04:48:05.037
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:48:05.044
Aug 22 04:48:05.044: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 04:48:05.045
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:48:05.061
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:48:05.063
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 08/22/23 04:48:05.066
Aug 22 04:48:05.075: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4" in namespace "downward-api-9640" to be "Succeeded or Failed"
Aug 22 04:48:05.090: INFO: Pod "downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.937033ms
Aug 22 04:48:07.093: INFO: Pod "downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018015349s
Aug 22 04:48:09.094: INFO: Pod "downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019159375s
Aug 22 04:48:11.094: INFO: Pod "downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018941326s
STEP: Saw pod success 08/22/23 04:48:11.094
Aug 22 04:48:11.094: INFO: Pod "downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4" satisfied condition "Succeeded or Failed"
Aug 22 04:48:11.096: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4 container client-container: <nil>
STEP: delete the pod 08/22/23 04:48:11.102
Aug 22 04:48:11.274: INFO: Waiting for pod downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4 to disappear
Aug 22 04:48:11.278: INFO: Pod downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 22 04:48:11.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9640" for this suite. 08/22/23 04:48:11.282
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":172,"skipped":3008,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.245 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:48:05.044
    Aug 22 04:48:05.044: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 04:48:05.045
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:48:05.061
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:48:05.063
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 08/22/23 04:48:05.066
    Aug 22 04:48:05.075: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4" in namespace "downward-api-9640" to be "Succeeded or Failed"
    Aug 22 04:48:05.090: INFO: Pod "downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.937033ms
    Aug 22 04:48:07.093: INFO: Pod "downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018015349s
    Aug 22 04:48:09.094: INFO: Pod "downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019159375s
    Aug 22 04:48:11.094: INFO: Pod "downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018941326s
    STEP: Saw pod success 08/22/23 04:48:11.094
    Aug 22 04:48:11.094: INFO: Pod "downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4" satisfied condition "Succeeded or Failed"
    Aug 22 04:48:11.096: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4 container client-container: <nil>
    STEP: delete the pod 08/22/23 04:48:11.102
    Aug 22 04:48:11.274: INFO: Waiting for pod downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4 to disappear
    Aug 22 04:48:11.278: INFO: Pod downwardapi-volume-d3749322-a632-4532-80e4-c8cfc1cad6e4 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 22 04:48:11.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9640" for this suite. 08/22/23 04:48:11.282
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:48:11.291
Aug 22 04:48:11.291: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-lifecycle-hook 08/22/23 04:48:11.291
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:48:11.317
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:48:11.32
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 08/22/23 04:48:11.327
Aug 22 04:48:11.334: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7615" to be "running and ready"
Aug 22 04:48:11.344: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 9.35485ms
Aug 22 04:48:11.344: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:48:13.349: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014432125s
Aug 22 04:48:13.349: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:48:15.347: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.012680059s
Aug 22 04:48:15.347: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Aug 22 04:48:15.347: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 08/22/23 04:48:15.349
Aug 22 04:48:15.359: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-7615" to be "running and ready"
Aug 22 04:48:15.363: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.568301ms
Aug 22 04:48:15.363: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:48:17.369: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010763584s
Aug 22 04:48:17.369: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:48:19.367: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.008237405s
Aug 22 04:48:19.367: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Aug 22 04:48:19.367: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 08/22/23 04:48:19.37
STEP: delete the pod with lifecycle hook 08/22/23 04:48:19.376
Aug 22 04:48:19.432: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 22 04:48:19.437: INFO: Pod pod-with-poststart-http-hook still exists
Aug 22 04:48:21.437: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 22 04:48:21.442: INFO: Pod pod-with-poststart-http-hook still exists
Aug 22 04:48:23.438: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 22 04:48:23.443: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Aug 22 04:48:23.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7615" for this suite. 08/22/23 04:48:23.45
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":173,"skipped":3058,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.168 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:48:11.291
    Aug 22 04:48:11.291: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-lifecycle-hook 08/22/23 04:48:11.291
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:48:11.317
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:48:11.32
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 08/22/23 04:48:11.327
    Aug 22 04:48:11.334: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7615" to be "running and ready"
    Aug 22 04:48:11.344: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 9.35485ms
    Aug 22 04:48:11.344: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:48:13.349: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014432125s
    Aug 22 04:48:13.349: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:48:15.347: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.012680059s
    Aug 22 04:48:15.347: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Aug 22 04:48:15.347: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 08/22/23 04:48:15.349
    Aug 22 04:48:15.359: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-7615" to be "running and ready"
    Aug 22 04:48:15.363: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.568301ms
    Aug 22 04:48:15.363: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:48:17.369: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010763584s
    Aug 22 04:48:17.369: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:48:19.367: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.008237405s
    Aug 22 04:48:19.367: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Aug 22 04:48:19.367: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 08/22/23 04:48:19.37
    STEP: delete the pod with lifecycle hook 08/22/23 04:48:19.376
    Aug 22 04:48:19.432: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Aug 22 04:48:19.437: INFO: Pod pod-with-poststart-http-hook still exists
    Aug 22 04:48:21.437: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Aug 22 04:48:21.442: INFO: Pod pod-with-poststart-http-hook still exists
    Aug 22 04:48:23.438: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Aug 22 04:48:23.443: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Aug 22 04:48:23.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-7615" for this suite. 08/22/23 04:48:23.45
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:48:23.461
Aug 22 04:48:23.461: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename subpath 08/22/23 04:48:23.461
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:48:23.628
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:48:23.631
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/22/23 04:48:23.636
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-ctst 08/22/23 04:48:23.647
STEP: Creating a pod to test atomic-volume-subpath 08/22/23 04:48:23.647
Aug 22 04:48:23.658: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-ctst" in namespace "subpath-4151" to be "Succeeded or Failed"
Aug 22 04:48:23.663: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Pending", Reason="", readiness=false. Elapsed: 5.435167ms
Aug 22 04:48:25.670: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011664814s
Aug 22 04:48:27.669: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 4.011388126s
Aug 22 04:48:29.668: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 6.009934618s
Aug 22 04:48:31.667: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 8.009105242s
Aug 22 04:48:33.670: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 10.012003831s
Aug 22 04:48:35.668: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 12.010253106s
Aug 22 04:48:37.668: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 14.010216597s
Aug 22 04:48:39.668: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 16.01020779s
Aug 22 04:48:41.669: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 18.010686797s
Aug 22 04:48:43.668: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 20.010194225s
Aug 22 04:48:45.669: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 22.011199379s
Aug 22 04:48:47.668: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=false. Elapsed: 24.009873555s
Aug 22 04:48:49.668: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.009730006s
STEP: Saw pod success 08/22/23 04:48:49.668
Aug 22 04:48:49.668: INFO: Pod "pod-subpath-test-secret-ctst" satisfied condition "Succeeded or Failed"
Aug 22 04:48:49.670: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod pod-subpath-test-secret-ctst container test-container-subpath-secret-ctst: <nil>
STEP: delete the pod 08/22/23 04:48:49.701
Aug 22 04:48:49.711: INFO: Waiting for pod pod-subpath-test-secret-ctst to disappear
Aug 22 04:48:49.715: INFO: Pod pod-subpath-test-secret-ctst no longer exists
STEP: Deleting pod pod-subpath-test-secret-ctst 08/22/23 04:48:49.715
Aug 22 04:48:49.715: INFO: Deleting pod "pod-subpath-test-secret-ctst" in namespace "subpath-4151"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 22 04:48:49.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4151" for this suite. 08/22/23 04:48:49.72
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":174,"skipped":3142,"failed":0}
------------------------------
â€¢ [SLOW TEST] [26.267 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:48:23.461
    Aug 22 04:48:23.461: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename subpath 08/22/23 04:48:23.461
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:48:23.628
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:48:23.631
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/22/23 04:48:23.636
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-ctst 08/22/23 04:48:23.647
    STEP: Creating a pod to test atomic-volume-subpath 08/22/23 04:48:23.647
    Aug 22 04:48:23.658: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-ctst" in namespace "subpath-4151" to be "Succeeded or Failed"
    Aug 22 04:48:23.663: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Pending", Reason="", readiness=false. Elapsed: 5.435167ms
    Aug 22 04:48:25.670: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011664814s
    Aug 22 04:48:27.669: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 4.011388126s
    Aug 22 04:48:29.668: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 6.009934618s
    Aug 22 04:48:31.667: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 8.009105242s
    Aug 22 04:48:33.670: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 10.012003831s
    Aug 22 04:48:35.668: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 12.010253106s
    Aug 22 04:48:37.668: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 14.010216597s
    Aug 22 04:48:39.668: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 16.01020779s
    Aug 22 04:48:41.669: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 18.010686797s
    Aug 22 04:48:43.668: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 20.010194225s
    Aug 22 04:48:45.669: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=true. Elapsed: 22.011199379s
    Aug 22 04:48:47.668: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Running", Reason="", readiness=false. Elapsed: 24.009873555s
    Aug 22 04:48:49.668: INFO: Pod "pod-subpath-test-secret-ctst": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.009730006s
    STEP: Saw pod success 08/22/23 04:48:49.668
    Aug 22 04:48:49.668: INFO: Pod "pod-subpath-test-secret-ctst" satisfied condition "Succeeded or Failed"
    Aug 22 04:48:49.670: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod pod-subpath-test-secret-ctst container test-container-subpath-secret-ctst: <nil>
    STEP: delete the pod 08/22/23 04:48:49.701
    Aug 22 04:48:49.711: INFO: Waiting for pod pod-subpath-test-secret-ctst to disappear
    Aug 22 04:48:49.715: INFO: Pod pod-subpath-test-secret-ctst no longer exists
    STEP: Deleting pod pod-subpath-test-secret-ctst 08/22/23 04:48:49.715
    Aug 22 04:48:49.715: INFO: Deleting pod "pod-subpath-test-secret-ctst" in namespace "subpath-4151"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 22 04:48:49.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-4151" for this suite. 08/22/23 04:48:49.72
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:48:49.729
Aug 22 04:48:49.729: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 04:48:49.73
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:48:49.752
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:48:49.755
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Aug 22 04:48:49.759: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 08/22/23 04:48:52.233
Aug 22 04:48:52.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 create -f -'
Aug 22 04:48:52.745: INFO: stderr: ""
Aug 22 04:48:52.745: INFO: stdout: "e2e-test-crd-publish-openapi-5051-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Aug 22 04:48:52.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 delete e2e-test-crd-publish-openapi-5051-crds test-foo'
Aug 22 04:48:52.836: INFO: stderr: ""
Aug 22 04:48:52.837: INFO: stdout: "e2e-test-crd-publish-openapi-5051-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Aug 22 04:48:52.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 apply -f -'
Aug 22 04:48:53.011: INFO: stderr: ""
Aug 22 04:48:53.011: INFO: stdout: "e2e-test-crd-publish-openapi-5051-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Aug 22 04:48:53.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 delete e2e-test-crd-publish-openapi-5051-crds test-foo'
Aug 22 04:48:53.378: INFO: stderr: ""
Aug 22 04:48:53.379: INFO: stdout: "e2e-test-crd-publish-openapi-5051-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 08/22/23 04:48:53.379
Aug 22 04:48:53.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 create -f -'
Aug 22 04:48:53.858: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 08/22/23 04:48:53.858
Aug 22 04:48:53.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 create -f -'
Aug 22 04:48:53.998: INFO: rc: 1
Aug 22 04:48:53.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 apply -f -'
Aug 22 04:48:54.499: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 08/22/23 04:48:54.499
Aug 22 04:48:54.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 create -f -'
Aug 22 04:48:54.641: INFO: rc: 1
Aug 22 04:48:54.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 apply -f -'
Aug 22 04:48:54.781: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 08/22/23 04:48:54.781
Aug 22 04:48:54.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 explain e2e-test-crd-publish-openapi-5051-crds'
Aug 22 04:48:54.924: INFO: stderr: ""
Aug 22 04:48:54.924: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5051-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 08/22/23 04:48:54.924
Aug 22 04:48:54.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 explain e2e-test-crd-publish-openapi-5051-crds.metadata'
Aug 22 04:48:55.054: INFO: stderr: ""
Aug 22 04:48:55.054: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5051-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Aug 22 04:48:55.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 explain e2e-test-crd-publish-openapi-5051-crds.spec'
Aug 22 04:48:55.191: INFO: stderr: ""
Aug 22 04:48:55.191: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5051-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Aug 22 04:48:55.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 explain e2e-test-crd-publish-openapi-5051-crds.spec.bars'
Aug 22 04:48:55.332: INFO: stderr: ""
Aug 22 04:48:55.332: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5051-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 08/22/23 04:48:55.332
Aug 22 04:48:55.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 explain e2e-test-crd-publish-openapi-5051-crds.spec.bars2'
Aug 22 04:48:55.490: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:48:57.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3002" for this suite. 08/22/23 04:48:57.97
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":175,"skipped":3148,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.248 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:48:49.729
    Aug 22 04:48:49.729: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 04:48:49.73
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:48:49.752
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:48:49.755
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Aug 22 04:48:49.759: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 08/22/23 04:48:52.233
    Aug 22 04:48:52.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 create -f -'
    Aug 22 04:48:52.745: INFO: stderr: ""
    Aug 22 04:48:52.745: INFO: stdout: "e2e-test-crd-publish-openapi-5051-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Aug 22 04:48:52.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 delete e2e-test-crd-publish-openapi-5051-crds test-foo'
    Aug 22 04:48:52.836: INFO: stderr: ""
    Aug 22 04:48:52.837: INFO: stdout: "e2e-test-crd-publish-openapi-5051-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Aug 22 04:48:52.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 apply -f -'
    Aug 22 04:48:53.011: INFO: stderr: ""
    Aug 22 04:48:53.011: INFO: stdout: "e2e-test-crd-publish-openapi-5051-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Aug 22 04:48:53.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 delete e2e-test-crd-publish-openapi-5051-crds test-foo'
    Aug 22 04:48:53.378: INFO: stderr: ""
    Aug 22 04:48:53.379: INFO: stdout: "e2e-test-crd-publish-openapi-5051-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 08/22/23 04:48:53.379
    Aug 22 04:48:53.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 create -f -'
    Aug 22 04:48:53.858: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 08/22/23 04:48:53.858
    Aug 22 04:48:53.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 create -f -'
    Aug 22 04:48:53.998: INFO: rc: 1
    Aug 22 04:48:53.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 apply -f -'
    Aug 22 04:48:54.499: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 08/22/23 04:48:54.499
    Aug 22 04:48:54.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 create -f -'
    Aug 22 04:48:54.641: INFO: rc: 1
    Aug 22 04:48:54.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 --namespace=crd-publish-openapi-3002 apply -f -'
    Aug 22 04:48:54.781: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 08/22/23 04:48:54.781
    Aug 22 04:48:54.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 explain e2e-test-crd-publish-openapi-5051-crds'
    Aug 22 04:48:54.924: INFO: stderr: ""
    Aug 22 04:48:54.924: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5051-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 08/22/23 04:48:54.924
    Aug 22 04:48:54.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 explain e2e-test-crd-publish-openapi-5051-crds.metadata'
    Aug 22 04:48:55.054: INFO: stderr: ""
    Aug 22 04:48:55.054: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5051-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Aug 22 04:48:55.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 explain e2e-test-crd-publish-openapi-5051-crds.spec'
    Aug 22 04:48:55.191: INFO: stderr: ""
    Aug 22 04:48:55.191: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5051-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Aug 22 04:48:55.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 explain e2e-test-crd-publish-openapi-5051-crds.spec.bars'
    Aug 22 04:48:55.332: INFO: stderr: ""
    Aug 22 04:48:55.332: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5051-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 08/22/23 04:48:55.332
    Aug 22 04:48:55.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-3002 explain e2e-test-crd-publish-openapi-5051-crds.spec.bars2'
    Aug 22 04:48:55.490: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:48:57.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3002" for this suite. 08/22/23 04:48:57.97
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:48:57.978
Aug 22 04:48:57.978: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-probe 08/22/23 04:48:57.978
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:48:58.015
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:48:58.019
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 22 04:49:58.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4223" for this suite. 08/22/23 04:49:58.073
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":176,"skipped":3153,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.111 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:48:57.978
    Aug 22 04:48:57.978: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-probe 08/22/23 04:48:57.978
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:48:58.015
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:48:58.019
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 22 04:49:58.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4223" for this suite. 08/22/23 04:49:58.073
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:49:58.091
Aug 22 04:49:58.091: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename replicaset 08/22/23 04:49:58.091
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:49:58.296
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:49:58.3
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Aug 22 04:49:58.306: INFO: Creating ReplicaSet my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255
Aug 22 04:49:58.319: INFO: Pod name my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255: Found 0 pods out of 1
Aug 22 04:50:03.323: INFO: Pod name my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255: Found 1 pods out of 1
Aug 22 04:50:03.323: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255" is running
Aug 22 04:50:03.323: INFO: Waiting up to 5m0s for pod "my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255-pmcmg" in namespace "replicaset-452" to be "running"
Aug 22 04:50:03.326: INFO: Pod "my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255-pmcmg": Phase="Running", Reason="", readiness=true. Elapsed: 3.1075ms
Aug 22 04:50:03.326: INFO: Pod "my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255-pmcmg" satisfied condition "running"
Aug 22 04:50:03.326: INFO: Pod "my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255-pmcmg" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 04:49:58 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 04:50:00 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 04:50:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 04:49:58 +0000 UTC Reason: Message:}])
Aug 22 04:50:03.326: INFO: Trying to dial the pod
Aug 22 04:50:08.349: INFO: Controller my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255: Got expected result from replica 1 [my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255-pmcmg]: "my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255-pmcmg", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 22 04:50:08.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-452" for this suite. 08/22/23 04:50:08.353
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":177,"skipped":3180,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.361 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:49:58.091
    Aug 22 04:49:58.091: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename replicaset 08/22/23 04:49:58.091
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:49:58.296
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:49:58.3
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Aug 22 04:49:58.306: INFO: Creating ReplicaSet my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255
    Aug 22 04:49:58.319: INFO: Pod name my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255: Found 0 pods out of 1
    Aug 22 04:50:03.323: INFO: Pod name my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255: Found 1 pods out of 1
    Aug 22 04:50:03.323: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255" is running
    Aug 22 04:50:03.323: INFO: Waiting up to 5m0s for pod "my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255-pmcmg" in namespace "replicaset-452" to be "running"
    Aug 22 04:50:03.326: INFO: Pod "my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255-pmcmg": Phase="Running", Reason="", readiness=true. Elapsed: 3.1075ms
    Aug 22 04:50:03.326: INFO: Pod "my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255-pmcmg" satisfied condition "running"
    Aug 22 04:50:03.326: INFO: Pod "my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255-pmcmg" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 04:49:58 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 04:50:00 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 04:50:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 04:49:58 +0000 UTC Reason: Message:}])
    Aug 22 04:50:03.326: INFO: Trying to dial the pod
    Aug 22 04:50:08.349: INFO: Controller my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255: Got expected result from replica 1 [my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255-pmcmg]: "my-hostname-basic-4d24a2c3-d554-499f-a7df-5bd32dc49255-pmcmg", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 22 04:50:08.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-452" for this suite. 08/22/23 04:50:08.353
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:50:08.452
Aug 22 04:50:08.452: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename replicaset 08/22/23 04:50:08.453
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:50:08.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:50:08.478
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 08/22/23 04:50:08.485
STEP: Verify that the required pods have come up 08/22/23 04:50:08.497
Aug 22 04:50:08.506: INFO: Pod name sample-pod: Found 0 pods out of 3
Aug 22 04:50:13.511: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 08/22/23 04:50:13.511
Aug 22 04:50:13.515: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 08/22/23 04:50:13.515
STEP: DeleteCollection of the ReplicaSets 08/22/23 04:50:13.518
STEP: After DeleteCollection verify that ReplicaSets have been deleted 08/22/23 04:50:13.526
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 22 04:50:13.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4808" for this suite. 08/22/23 04:50:13.542
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":178,"skipped":3196,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.105 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:50:08.452
    Aug 22 04:50:08.452: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename replicaset 08/22/23 04:50:08.453
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:50:08.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:50:08.478
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 08/22/23 04:50:08.485
    STEP: Verify that the required pods have come up 08/22/23 04:50:08.497
    Aug 22 04:50:08.506: INFO: Pod name sample-pod: Found 0 pods out of 3
    Aug 22 04:50:13.511: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 08/22/23 04:50:13.511
    Aug 22 04:50:13.515: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 08/22/23 04:50:13.515
    STEP: DeleteCollection of the ReplicaSets 08/22/23 04:50:13.518
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 08/22/23 04:50:13.526
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 22 04:50:13.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4808" for this suite. 08/22/23 04:50:13.542
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:50:13.559
Aug 22 04:50:13.559: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 04:50:13.56
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:50:13.586
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:50:13.59
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Aug 22 04:50:13.595: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/22/23 04:50:15.983
Aug 22 04:50:15.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-4559 --namespace=crd-publish-openapi-4559 create -f -'
Aug 22 04:50:16.607: INFO: stderr: ""
Aug 22 04:50:16.607: INFO: stdout: "e2e-test-crd-publish-openapi-2644-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Aug 22 04:50:16.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-4559 --namespace=crd-publish-openapi-4559 delete e2e-test-crd-publish-openapi-2644-crds test-cr'
Aug 22 04:50:16.865: INFO: stderr: ""
Aug 22 04:50:16.865: INFO: stdout: "e2e-test-crd-publish-openapi-2644-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Aug 22 04:50:16.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-4559 --namespace=crd-publish-openapi-4559 apply -f -'
Aug 22 04:50:17.333: INFO: stderr: ""
Aug 22 04:50:17.333: INFO: stdout: "e2e-test-crd-publish-openapi-2644-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Aug 22 04:50:17.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-4559 --namespace=crd-publish-openapi-4559 delete e2e-test-crd-publish-openapi-2644-crds test-cr'
Aug 22 04:50:17.506: INFO: stderr: ""
Aug 22 04:50:17.506: INFO: stdout: "e2e-test-crd-publish-openapi-2644-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 08/22/23 04:50:17.506
Aug 22 04:50:17.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-4559 explain e2e-test-crd-publish-openapi-2644-crds'
Aug 22 04:50:17.893: INFO: stderr: ""
Aug 22 04:50:17.893: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2644-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:50:20.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4559" for this suite. 08/22/23 04:50:20.235
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":179,"skipped":3259,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.682 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:50:13.559
    Aug 22 04:50:13.559: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 04:50:13.56
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:50:13.586
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:50:13.59
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Aug 22 04:50:13.595: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/22/23 04:50:15.983
    Aug 22 04:50:15.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-4559 --namespace=crd-publish-openapi-4559 create -f -'
    Aug 22 04:50:16.607: INFO: stderr: ""
    Aug 22 04:50:16.607: INFO: stdout: "e2e-test-crd-publish-openapi-2644-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Aug 22 04:50:16.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-4559 --namespace=crd-publish-openapi-4559 delete e2e-test-crd-publish-openapi-2644-crds test-cr'
    Aug 22 04:50:16.865: INFO: stderr: ""
    Aug 22 04:50:16.865: INFO: stdout: "e2e-test-crd-publish-openapi-2644-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Aug 22 04:50:16.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-4559 --namespace=crd-publish-openapi-4559 apply -f -'
    Aug 22 04:50:17.333: INFO: stderr: ""
    Aug 22 04:50:17.333: INFO: stdout: "e2e-test-crd-publish-openapi-2644-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Aug 22 04:50:17.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-4559 --namespace=crd-publish-openapi-4559 delete e2e-test-crd-publish-openapi-2644-crds test-cr'
    Aug 22 04:50:17.506: INFO: stderr: ""
    Aug 22 04:50:17.506: INFO: stdout: "e2e-test-crd-publish-openapi-2644-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 08/22/23 04:50:17.506
    Aug 22 04:50:17.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-4559 explain e2e-test-crd-publish-openapi-2644-crds'
    Aug 22 04:50:17.893: INFO: stderr: ""
    Aug 22 04:50:17.893: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2644-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:50:20.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4559" for this suite. 08/22/23 04:50:20.235
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:50:20.243
Aug 22 04:50:20.243: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename replication-controller 08/22/23 04:50:20.243
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:50:20.258
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:50:20.26
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 08/22/23 04:50:20.265
Aug 22 04:50:20.273: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-9254" to be "running and ready"
Aug 22 04:50:20.279: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 5.270979ms
Aug 22 04:50:20.279: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:50:22.283: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009297834s
Aug 22 04:50:22.283: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:50:24.285: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 4.011737391s
Aug 22 04:50:24.285: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Aug 22 04:50:24.285: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 08/22/23 04:50:24.289
STEP: Then the orphan pod is adopted 08/22/23 04:50:24.378
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 22 04:50:25.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9254" for this suite. 08/22/23 04:50:25.391
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":180,"skipped":3274,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.157 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:50:20.243
    Aug 22 04:50:20.243: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename replication-controller 08/22/23 04:50:20.243
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:50:20.258
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:50:20.26
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 08/22/23 04:50:20.265
    Aug 22 04:50:20.273: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-9254" to be "running and ready"
    Aug 22 04:50:20.279: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 5.270979ms
    Aug 22 04:50:20.279: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:50:22.283: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009297834s
    Aug 22 04:50:22.283: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:50:24.285: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 4.011737391s
    Aug 22 04:50:24.285: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Aug 22 04:50:24.285: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 08/22/23 04:50:24.289
    STEP: Then the orphan pod is adopted 08/22/23 04:50:24.378
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 22 04:50:25.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-9254" for this suite. 08/22/23 04:50:25.391
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:50:25.4
Aug 22 04:50:25.400: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename security-context-test 08/22/23 04:50:25.401
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:50:25.422
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:50:25.424
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Aug 22 04:50:25.439: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-74946f42-9921-4e2c-8bb0-5a662b5a0636" in namespace "security-context-test-793" to be "Succeeded or Failed"
Aug 22 04:50:25.447: INFO: Pod "busybox-readonly-false-74946f42-9921-4e2c-8bb0-5a662b5a0636": Phase="Pending", Reason="", readiness=false. Elapsed: 7.683086ms
Aug 22 04:50:27.451: INFO: Pod "busybox-readonly-false-74946f42-9921-4e2c-8bb0-5a662b5a0636": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011972794s
Aug 22 04:50:29.451: INFO: Pod "busybox-readonly-false-74946f42-9921-4e2c-8bb0-5a662b5a0636": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011843282s
Aug 22 04:50:31.450: INFO: Pod "busybox-readonly-false-74946f42-9921-4e2c-8bb0-5a662b5a0636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011359634s
Aug 22 04:50:31.450: INFO: Pod "busybox-readonly-false-74946f42-9921-4e2c-8bb0-5a662b5a0636" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 22 04:50:31.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-793" for this suite. 08/22/23 04:50:31.455
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":181,"skipped":3279,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.090 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:50:25.4
    Aug 22 04:50:25.400: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename security-context-test 08/22/23 04:50:25.401
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:50:25.422
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:50:25.424
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Aug 22 04:50:25.439: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-74946f42-9921-4e2c-8bb0-5a662b5a0636" in namespace "security-context-test-793" to be "Succeeded or Failed"
    Aug 22 04:50:25.447: INFO: Pod "busybox-readonly-false-74946f42-9921-4e2c-8bb0-5a662b5a0636": Phase="Pending", Reason="", readiness=false. Elapsed: 7.683086ms
    Aug 22 04:50:27.451: INFO: Pod "busybox-readonly-false-74946f42-9921-4e2c-8bb0-5a662b5a0636": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011972794s
    Aug 22 04:50:29.451: INFO: Pod "busybox-readonly-false-74946f42-9921-4e2c-8bb0-5a662b5a0636": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011843282s
    Aug 22 04:50:31.450: INFO: Pod "busybox-readonly-false-74946f42-9921-4e2c-8bb0-5a662b5a0636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011359634s
    Aug 22 04:50:31.450: INFO: Pod "busybox-readonly-false-74946f42-9921-4e2c-8bb0-5a662b5a0636" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 22 04:50:31.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-793" for this suite. 08/22/23 04:50:31.455
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:50:31.491
Aug 22 04:50:31.491: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename sysctl 08/22/23 04:50:31.491
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:50:31.731
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:50:31.734
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 08/22/23 04:50:31.738
STEP: Watching for error events or started pod 08/22/23 04:50:31.758
STEP: Waiting for pod completion 08/22/23 04:50:35.764
Aug 22 04:50:35.764: INFO: Waiting up to 3m0s for pod "sysctl-498c0ded-4f8a-428c-928c-4ab98540295d" in namespace "sysctl-1937" to be "completed"
Aug 22 04:50:35.768: INFO: Pod "sysctl-498c0ded-4f8a-428c-928c-4ab98540295d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.865964ms
Aug 22 04:50:37.772: INFO: Pod "sysctl-498c0ded-4f8a-428c-928c-4ab98540295d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007816865s
Aug 22 04:50:39.773: INFO: Pod "sysctl-498c0ded-4f8a-428c-928c-4ab98540295d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00837834s
Aug 22 04:50:39.773: INFO: Pod "sysctl-498c0ded-4f8a-428c-928c-4ab98540295d" satisfied condition "completed"
STEP: Checking that the pod succeeded 08/22/23 04:50:39.776
STEP: Getting logs from the pod 08/22/23 04:50:39.776
STEP: Checking that the sysctl is actually updated 08/22/23 04:50:39.805
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 22 04:50:39.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-1937" for this suite. 08/22/23 04:50:39.809
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":182,"skipped":3306,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.325 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:50:31.491
    Aug 22 04:50:31.491: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename sysctl 08/22/23 04:50:31.491
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:50:31.731
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:50:31.734
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 08/22/23 04:50:31.738
    STEP: Watching for error events or started pod 08/22/23 04:50:31.758
    STEP: Waiting for pod completion 08/22/23 04:50:35.764
    Aug 22 04:50:35.764: INFO: Waiting up to 3m0s for pod "sysctl-498c0ded-4f8a-428c-928c-4ab98540295d" in namespace "sysctl-1937" to be "completed"
    Aug 22 04:50:35.768: INFO: Pod "sysctl-498c0ded-4f8a-428c-928c-4ab98540295d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.865964ms
    Aug 22 04:50:37.772: INFO: Pod "sysctl-498c0ded-4f8a-428c-928c-4ab98540295d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007816865s
    Aug 22 04:50:39.773: INFO: Pod "sysctl-498c0ded-4f8a-428c-928c-4ab98540295d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00837834s
    Aug 22 04:50:39.773: INFO: Pod "sysctl-498c0ded-4f8a-428c-928c-4ab98540295d" satisfied condition "completed"
    STEP: Checking that the pod succeeded 08/22/23 04:50:39.776
    STEP: Getting logs from the pod 08/22/23 04:50:39.776
    STEP: Checking that the sysctl is actually updated 08/22/23 04:50:39.805
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 22 04:50:39.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-1937" for this suite. 08/22/23 04:50:39.809
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:50:39.818
Aug 22 04:50:39.818: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 04:50:39.819
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:50:39.852
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:50:39.856
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 08/22/23 04:50:39.862
Aug 22 04:50:39.862: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: rename a version 08/22/23 04:50:45.967
STEP: check the new version name is served 08/22/23 04:50:46.054
STEP: check the old version name is removed 08/22/23 04:50:48.935
STEP: check the other version is not changed 08/22/23 04:50:50.178
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:50:55.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1512" for this suite. 08/22/23 04:50:55.337
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":183,"skipped":3350,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.526 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:50:39.818
    Aug 22 04:50:39.818: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 04:50:39.819
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:50:39.852
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:50:39.856
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 08/22/23 04:50:39.862
    Aug 22 04:50:39.862: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: rename a version 08/22/23 04:50:45.967
    STEP: check the new version name is served 08/22/23 04:50:46.054
    STEP: check the old version name is removed 08/22/23 04:50:48.935
    STEP: check the other version is not changed 08/22/23 04:50:50.178
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:50:55.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1512" for this suite. 08/22/23 04:50:55.337
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:50:55.345
Aug 22 04:50:55.345: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename proxy 08/22/23 04:50:55.345
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:50:55.546
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:50:55.548
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 08/22/23 04:50:55.562
STEP: creating replication controller proxy-service-w777z in namespace proxy-578 08/22/23 04:50:55.562
I0822 04:50:55.575407      19 runners.go:193] Created replication controller with name: proxy-service-w777z, namespace: proxy-578, replica count: 1
I0822 04:50:56.625717      19 runners.go:193] proxy-service-w777z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 04:50:57.626035      19 runners.go:193] proxy-service-w777z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 04:50:58.626333      19 runners.go:193] proxy-service-w777z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0822 04:50:59.627451      19 runners.go:193] proxy-service-w777z Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 22 04:50:59.632: INFO: setup took 4.079409681s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 08/22/23 04:50:59.632
Aug 22 04:50:59.640: INFO: (0) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 8.040084ms)
Aug 22 04:50:59.642: INFO: (0) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 9.490204ms)
Aug 22 04:50:59.646: INFO: (0) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 13.727384ms)
Aug 22 04:50:59.647: INFO: (0) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 15.28674ms)
Aug 22 04:50:59.647: INFO: (0) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 15.180911ms)
Aug 22 04:50:59.648: INFO: (0) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 15.076275ms)
Aug 22 04:50:59.649: INFO: (0) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 16.785422ms)
Aug 22 04:50:59.650: INFO: (0) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 17.178199ms)
Aug 22 04:50:59.650: INFO: (0) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 17.245064ms)
Aug 22 04:50:59.650: INFO: (0) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 17.580663ms)
Aug 22 04:50:59.650: INFO: (0) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 17.501073ms)
Aug 22 04:50:59.650: INFO: (0) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 17.479763ms)
Aug 22 04:50:59.650: INFO: (0) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 17.555466ms)
Aug 22 04:50:59.650: INFO: (0) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 17.66941ms)
Aug 22 04:50:59.651: INFO: (0) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 18.510307ms)
Aug 22 04:50:59.651: INFO: (0) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 19.158885ms)
Aug 22 04:50:59.655: INFO: (1) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 3.669565ms)
Aug 22 04:50:59.656: INFO: (1) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 4.175453ms)
Aug 22 04:50:59.658: INFO: (1) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 6.536614ms)
Aug 22 04:50:59.659: INFO: (1) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 6.793986ms)
Aug 22 04:50:59.659: INFO: (1) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 7.513225ms)
Aug 22 04:50:59.660: INFO: (1) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 7.470115ms)
Aug 22 04:50:59.660: INFO: (1) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 7.67544ms)
Aug 22 04:50:59.660: INFO: (1) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 7.588988ms)
Aug 22 04:50:59.661: INFO: (1) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 8.667301ms)
Aug 22 04:50:59.661: INFO: (1) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 9.243492ms)
Aug 22 04:50:59.662: INFO: (1) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 9.949486ms)
Aug 22 04:50:59.662: INFO: (1) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 10.263075ms)
Aug 22 04:50:59.662: INFO: (1) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 10.516831ms)
Aug 22 04:50:59.662: INFO: (1) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 10.32448ms)
Aug 22 04:50:59.663: INFO: (1) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 10.548962ms)
Aug 22 04:50:59.663: INFO: (1) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 11.59328ms)
Aug 22 04:50:59.670: INFO: (2) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 6.185335ms)
Aug 22 04:50:59.670: INFO: (2) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 6.312864ms)
Aug 22 04:50:59.671: INFO: (2) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 7.076637ms)
Aug 22 04:50:59.671: INFO: (2) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 7.400073ms)
Aug 22 04:50:59.672: INFO: (2) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 7.747015ms)
Aug 22 04:50:59.672: INFO: (2) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 8.164519ms)
Aug 22 04:50:59.672: INFO: (2) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 7.816385ms)
Aug 22 04:50:59.672: INFO: (2) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 8.738754ms)
Aug 22 04:50:59.672: INFO: (2) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 8.309991ms)
Aug 22 04:50:59.672: INFO: (2) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 8.475201ms)
Aug 22 04:50:59.672: INFO: (2) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 8.84812ms)
Aug 22 04:50:59.673: INFO: (2) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 8.69917ms)
Aug 22 04:50:59.673: INFO: (2) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 9.153552ms)
Aug 22 04:50:59.673: INFO: (2) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 8.790403ms)
Aug 22 04:50:59.673: INFO: (2) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 9.437415ms)
Aug 22 04:50:59.674: INFO: (2) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 9.982738ms)
Aug 22 04:50:59.680: INFO: (3) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 5.710593ms)
Aug 22 04:50:59.680: INFO: (3) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 5.698361ms)
Aug 22 04:50:59.681: INFO: (3) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 7.260521ms)
Aug 22 04:50:59.681: INFO: (3) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 7.184579ms)
Aug 22 04:50:59.681: INFO: (3) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 7.498749ms)
Aug 22 04:50:59.681: INFO: (3) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 7.400524ms)
Aug 22 04:50:59.682: INFO: (3) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 8.554629ms)
Aug 22 04:50:59.682: INFO: (3) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 8.348001ms)
Aug 22 04:50:59.683: INFO: (3) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 9.072029ms)
Aug 22 04:50:59.683: INFO: (3) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 9.218324ms)
Aug 22 04:50:59.683: INFO: (3) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 9.363035ms)
Aug 22 04:50:59.683: INFO: (3) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 9.439399ms)
Aug 22 04:50:59.684: INFO: (3) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 9.709125ms)
Aug 22 04:50:59.684: INFO: (3) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 9.925811ms)
Aug 22 04:50:59.684: INFO: (3) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 9.930531ms)
Aug 22 04:50:59.685: INFO: (3) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 10.496612ms)
Aug 22 04:50:59.688: INFO: (4) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 3.790532ms)
Aug 22 04:50:59.690: INFO: (4) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 5.327284ms)
Aug 22 04:50:59.690: INFO: (4) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 5.293442ms)
Aug 22 04:50:59.691: INFO: (4) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 6.459479ms)
Aug 22 04:50:59.694: INFO: (4) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 8.749886ms)
Aug 22 04:50:59.694: INFO: (4) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 8.804048ms)
Aug 22 04:50:59.694: INFO: (4) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 9.168181ms)
Aug 22 04:50:59.694: INFO: (4) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 9.217904ms)
Aug 22 04:50:59.694: INFO: (4) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 9.642381ms)
Aug 22 04:50:59.695: INFO: (4) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 9.788455ms)
Aug 22 04:50:59.695: INFO: (4) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 9.837888ms)
Aug 22 04:50:59.695: INFO: (4) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 9.667708ms)
Aug 22 04:50:59.695: INFO: (4) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 9.593759ms)
Aug 22 04:50:59.695: INFO: (4) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 10.000443ms)
Aug 22 04:50:59.695: INFO: (4) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 10.35121ms)
Aug 22 04:50:59.695: INFO: (4) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 10.378432ms)
Aug 22 04:50:59.704: INFO: (5) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 8.031648ms)
Aug 22 04:50:59.704: INFO: (5) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 8.146534ms)
Aug 22 04:50:59.704: INFO: (5) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 8.42174ms)
Aug 22 04:50:59.704: INFO: (5) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 8.281267ms)
Aug 22 04:50:59.704: INFO: (5) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 8.718657ms)
Aug 22 04:50:59.704: INFO: (5) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 8.665549ms)
Aug 22 04:50:59.705: INFO: (5) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 9.040822ms)
Aug 22 04:50:59.705: INFO: (5) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 9.04ms)
Aug 22 04:50:59.705: INFO: (5) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 9.312091ms)
Aug 22 04:50:59.705: INFO: (5) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 9.298905ms)
Aug 22 04:50:59.705: INFO: (5) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 9.495304ms)
Aug 22 04:50:59.705: INFO: (5) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 9.591375ms)
Aug 22 04:50:59.705: INFO: (5) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 9.862654ms)
Aug 22 04:50:59.706: INFO: (5) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 9.867783ms)
Aug 22 04:50:59.706: INFO: (5) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 9.919791ms)
Aug 22 04:50:59.706: INFO: (5) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 10.515288ms)
Aug 22 04:50:59.712: INFO: (6) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 5.543891ms)
Aug 22 04:50:59.713: INFO: (6) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 6.057835ms)
Aug 22 04:50:59.713: INFO: (6) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 6.258301ms)
Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 9.603998ms)
Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 9.507257ms)
Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 9.520483ms)
Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 9.53506ms)
Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 9.570225ms)
Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 9.601353ms)
Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 9.649524ms)
Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 9.627563ms)
Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 9.638183ms)
Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 9.65264ms)
Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 9.662107ms)
Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 9.690742ms)
Aug 22 04:50:59.717: INFO: (6) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 10.653418ms)
Aug 22 04:50:59.723: INFO: (7) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 5.760988ms)
Aug 22 04:50:59.723: INFO: (7) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 5.899979ms)
Aug 22 04:50:59.724: INFO: (7) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 6.160828ms)
Aug 22 04:50:59.725: INFO: (7) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 7.306337ms)
Aug 22 04:50:59.726: INFO: (7) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 8.559729ms)
Aug 22 04:50:59.726: INFO: (7) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 8.693179ms)
Aug 22 04:50:59.726: INFO: (7) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 8.569286ms)
Aug 22 04:50:59.726: INFO: (7) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 8.973404ms)
Aug 22 04:50:59.727: INFO: (7) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 9.315506ms)
Aug 22 04:50:59.727: INFO: (7) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 9.651677ms)
Aug 22 04:50:59.727: INFO: (7) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 9.944466ms)
Aug 22 04:50:59.727: INFO: (7) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 9.968963ms)
Aug 22 04:50:59.728: INFO: (7) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 10.527271ms)
Aug 22 04:50:59.729: INFO: (7) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 11.175184ms)
Aug 22 04:50:59.729: INFO: (7) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 11.498242ms)
Aug 22 04:50:59.729: INFO: (7) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 11.624819ms)
Aug 22 04:50:59.734: INFO: (8) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 4.819803ms)
Aug 22 04:50:59.735: INFO: (8) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 5.675307ms)
Aug 22 04:50:59.735: INFO: (8) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 6.160107ms)
Aug 22 04:50:59.736: INFO: (8) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 6.579745ms)
Aug 22 04:50:59.737: INFO: (8) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 8.302117ms)
Aug 22 04:50:59.738: INFO: (8) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 8.395381ms)
Aug 22 04:50:59.739: INFO: (8) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 9.616311ms)
Aug 22 04:50:59.739: INFO: (8) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 9.809344ms)
Aug 22 04:50:59.739: INFO: (8) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 10.375755ms)
Aug 22 04:50:59.740: INFO: (8) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 10.264728ms)
Aug 22 04:50:59.740: INFO: (8) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 10.610807ms)
Aug 22 04:50:59.740: INFO: (8) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 10.709182ms)
Aug 22 04:50:59.740: INFO: (8) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 11.005938ms)
Aug 22 04:50:59.740: INFO: (8) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 11.159717ms)
Aug 22 04:50:59.740: INFO: (8) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 11.069509ms)
Aug 22 04:50:59.741: INFO: (8) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 11.594643ms)
Aug 22 04:50:59.754: INFO: (9) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 13.050464ms)
Aug 22 04:50:59.754: INFO: (9) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 12.918486ms)
Aug 22 04:50:59.756: INFO: (9) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 14.949396ms)
Aug 22 04:50:59.756: INFO: (9) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 14.764089ms)
Aug 22 04:50:59.756: INFO: (9) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 15.132178ms)
Aug 22 04:50:59.756: INFO: (9) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 15.032322ms)
Aug 22 04:50:59.757: INFO: (9) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 15.786958ms)
Aug 22 04:50:59.757: INFO: (9) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 15.758685ms)
Aug 22 04:50:59.757: INFO: (9) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 15.935798ms)
Aug 22 04:50:59.757: INFO: (9) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 16.305281ms)
Aug 22 04:50:59.761: INFO: (9) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 20.407396ms)
Aug 22 04:50:59.763: INFO: (9) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 21.813404ms)
Aug 22 04:50:59.763: INFO: (9) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 21.642243ms)
Aug 22 04:50:59.763: INFO: (9) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 22.328542ms)
Aug 22 04:50:59.763: INFO: (9) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 22.293566ms)
Aug 22 04:50:59.763: INFO: (9) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 22.273377ms)
Aug 22 04:50:59.770: INFO: (10) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 6.395058ms)
Aug 22 04:50:59.771: INFO: (10) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 7.938564ms)
Aug 22 04:50:59.771: INFO: (10) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 7.785666ms)
Aug 22 04:50:59.772: INFO: (10) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 8.375734ms)
Aug 22 04:50:59.772: INFO: (10) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 8.846297ms)
Aug 22 04:50:59.772: INFO: (10) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 8.649217ms)
Aug 22 04:50:59.773: INFO: (10) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 9.068855ms)
Aug 22 04:50:59.773: INFO: (10) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 9.073774ms)
Aug 22 04:50:59.773: INFO: (10) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 9.035472ms)
Aug 22 04:50:59.773: INFO: (10) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 9.299978ms)
Aug 22 04:50:59.773: INFO: (10) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 9.353379ms)
Aug 22 04:50:59.774: INFO: (10) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 10.46836ms)
Aug 22 04:50:59.774: INFO: (10) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 10.955584ms)
Aug 22 04:50:59.774: INFO: (10) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 10.926891ms)
Aug 22 04:50:59.775: INFO: (10) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 11.119712ms)
Aug 22 04:50:59.775: INFO: (10) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 11.518049ms)
Aug 22 04:50:59.779: INFO: (11) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 4.19425ms)
Aug 22 04:50:59.781: INFO: (11) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 5.451257ms)
Aug 22 04:50:59.781: INFO: (11) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 6.08245ms)
Aug 22 04:50:59.782: INFO: (11) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 6.94587ms)
Aug 22 04:50:59.782: INFO: (11) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 7.293133ms)
Aug 22 04:50:59.782: INFO: (11) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 7.209596ms)
Aug 22 04:50:59.782: INFO: (11) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 7.290438ms)
Aug 22 04:50:59.783: INFO: (11) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 7.629413ms)
Aug 22 04:50:59.783: INFO: (11) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 7.641747ms)
Aug 22 04:50:59.783: INFO: (11) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 7.81942ms)
Aug 22 04:50:59.784: INFO: (11) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 8.768651ms)
Aug 22 04:50:59.784: INFO: (11) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 9.139537ms)
Aug 22 04:50:59.785: INFO: (11) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 9.454918ms)
Aug 22 04:50:59.785: INFO: (11) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 10.001143ms)
Aug 22 04:50:59.785: INFO: (11) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 10.133241ms)
Aug 22 04:50:59.785: INFO: (11) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 10.163589ms)
Aug 22 04:50:59.791: INFO: (12) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 5.42621ms)
Aug 22 04:50:59.792: INFO: (12) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 6.948898ms)
Aug 22 04:50:59.793: INFO: (12) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 7.743216ms)
Aug 22 04:50:59.793: INFO: (12) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 7.758176ms)
Aug 22 04:50:59.793: INFO: (12) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 8.09085ms)
Aug 22 04:50:59.795: INFO: (12) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 10.061786ms)
Aug 22 04:50:59.795: INFO: (12) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 10.028595ms)
Aug 22 04:50:59.795: INFO: (12) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 10.072878ms)
Aug 22 04:50:59.795: INFO: (12) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 10.134264ms)
Aug 22 04:50:59.796: INFO: (12) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 10.709612ms)
Aug 22 04:50:59.796: INFO: (12) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 11.149838ms)
Aug 22 04:50:59.797: INFO: (12) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 11.151601ms)
Aug 22 04:50:59.797: INFO: (12) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 11.469397ms)
Aug 22 04:50:59.797: INFO: (12) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 11.779189ms)
Aug 22 04:50:59.797: INFO: (12) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 11.856805ms)
Aug 22 04:50:59.797: INFO: (12) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 12.192015ms)
Aug 22 04:50:59.802: INFO: (13) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 4.74415ms)
Aug 22 04:50:59.804: INFO: (13) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 6.025133ms)
Aug 22 04:50:59.804: INFO: (13) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 5.878869ms)
Aug 22 04:50:59.804: INFO: (13) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 5.892014ms)
Aug 22 04:50:59.804: INFO: (13) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 5.937479ms)
Aug 22 04:50:59.804: INFO: (13) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 6.671977ms)
Aug 22 04:50:59.805: INFO: (13) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 7.11018ms)
Aug 22 04:50:59.806: INFO: (13) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 7.963621ms)
Aug 22 04:50:59.806: INFO: (13) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 7.970514ms)
Aug 22 04:50:59.806: INFO: (13) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 8.570289ms)
Aug 22 04:50:59.807: INFO: (13) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 9.269351ms)
Aug 22 04:50:59.807: INFO: (13) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 9.633353ms)
Aug 22 04:50:59.808: INFO: (13) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 9.945088ms)
Aug 22 04:50:59.809: INFO: (13) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 10.71921ms)
Aug 22 04:50:59.809: INFO: (13) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 11.221834ms)
Aug 22 04:50:59.810: INFO: (13) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 12.598046ms)
Aug 22 04:50:59.816: INFO: (14) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 5.579558ms)
Aug 22 04:50:59.817: INFO: (14) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 7.204777ms)
Aug 22 04:50:59.818: INFO: (14) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 7.082537ms)
Aug 22 04:50:59.818: INFO: (14) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 7.666303ms)
Aug 22 04:50:59.818: INFO: (14) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 7.642488ms)
Aug 22 04:50:59.819: INFO: (14) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 8.556533ms)
Aug 22 04:50:59.819: INFO: (14) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 8.615724ms)
Aug 22 04:50:59.819: INFO: (14) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 8.824846ms)
Aug 22 04:50:59.820: INFO: (14) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 9.383223ms)
Aug 22 04:50:59.820: INFO: (14) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 9.536111ms)
Aug 22 04:50:59.821: INFO: (14) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 10.859915ms)
Aug 22 04:50:59.821: INFO: (14) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 11.029632ms)
Aug 22 04:50:59.821: INFO: (14) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 10.858662ms)
Aug 22 04:50:59.822: INFO: (14) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 11.513491ms)
Aug 22 04:50:59.823: INFO: (14) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 12.131169ms)
Aug 22 04:50:59.823: INFO: (14) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 12.349949ms)
Aug 22 04:50:59.827: INFO: (15) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 4.021455ms)
Aug 22 04:50:59.828: INFO: (15) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 4.703455ms)
Aug 22 04:50:59.829: INFO: (15) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 6.030383ms)
Aug 22 04:50:59.831: INFO: (15) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 7.322459ms)
Aug 22 04:50:59.831: INFO: (15) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 7.645975ms)
Aug 22 04:50:59.831: INFO: (15) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 7.562408ms)
Aug 22 04:50:59.832: INFO: (15) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 8.547296ms)
Aug 22 04:50:59.832: INFO: (15) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 9.021937ms)
Aug 22 04:50:59.832: INFO: (15) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 9.095023ms)
Aug 22 04:50:59.833: INFO: (15) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 9.733711ms)
Aug 22 04:50:59.833: INFO: (15) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 9.850281ms)
Aug 22 04:50:59.834: INFO: (15) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 10.531328ms)
Aug 22 04:50:59.834: INFO: (15) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 10.570832ms)
Aug 22 04:50:59.834: INFO: (15) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 11.114372ms)
Aug 22 04:50:59.834: INFO: (15) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 11.000398ms)
Aug 22 04:50:59.834: INFO: (15) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 10.978317ms)
Aug 22 04:50:59.838: INFO: (16) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 3.71018ms)
Aug 22 04:50:59.839: INFO: (16) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 3.996669ms)
Aug 22 04:50:59.840: INFO: (16) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 5.597553ms)
Aug 22 04:50:59.841: INFO: (16) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 6.130382ms)
Aug 22 04:50:59.841: INFO: (16) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 6.515042ms)
Aug 22 04:50:59.842: INFO: (16) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 6.943556ms)
Aug 22 04:50:59.842: INFO: (16) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 7.115068ms)
Aug 22 04:50:59.842: INFO: (16) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 7.140346ms)
Aug 22 04:50:59.843: INFO: (16) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 8.317415ms)
Aug 22 04:50:59.843: INFO: (16) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 8.742012ms)
Aug 22 04:50:59.844: INFO: (16) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 9.746656ms)
Aug 22 04:50:59.845: INFO: (16) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 10.467028ms)
Aug 22 04:50:59.845: INFO: (16) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 10.540285ms)
Aug 22 04:50:59.845: INFO: (16) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 10.503795ms)
Aug 22 04:50:59.845: INFO: (16) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 10.727075ms)
Aug 22 04:50:59.845: INFO: (16) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 10.754055ms)
Aug 22 04:50:59.853: INFO: (17) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 7.094811ms)
Aug 22 04:50:59.853: INFO: (17) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 7.468301ms)
Aug 22 04:50:59.854: INFO: (17) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 7.774015ms)
Aug 22 04:50:59.855: INFO: (17) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 9.063945ms)
Aug 22 04:50:59.856: INFO: (17) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 10.012794ms)
Aug 22 04:50:59.856: INFO: (17) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 10.415512ms)
Aug 22 04:50:59.856: INFO: (17) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 10.015571ms)
Aug 22 04:50:59.859: INFO: (17) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 12.743247ms)
Aug 22 04:50:59.859: INFO: (17) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 12.716488ms)
Aug 22 04:50:59.859: INFO: (17) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 12.893159ms)
Aug 22 04:50:59.859: INFO: (17) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 13.209413ms)
Aug 22 04:50:59.859: INFO: (17) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 13.81061ms)
Aug 22 04:50:59.860: INFO: (17) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 13.458709ms)
Aug 22 04:50:59.860: INFO: (17) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 14.37522ms)
Aug 22 04:50:59.862: INFO: (17) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 15.477959ms)
Aug 22 04:50:59.862: INFO: (17) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 16.167512ms)
Aug 22 04:50:59.874: INFO: (18) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 11.741469ms)
Aug 22 04:50:59.875: INFO: (18) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 12.250865ms)
Aug 22 04:50:59.875: INFO: (18) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 12.672725ms)
Aug 22 04:50:59.879: INFO: (18) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 16.605985ms)
Aug 22 04:50:59.879: INFO: (18) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 16.594212ms)
Aug 22 04:50:59.880: INFO: (18) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 17.403781ms)
Aug 22 04:50:59.880: INFO: (18) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 18.042971ms)
Aug 22 04:50:59.880: INFO: (18) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 18.127499ms)
Aug 22 04:50:59.881: INFO: (18) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 18.413997ms)
Aug 22 04:50:59.881: INFO: (18) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 18.576331ms)
Aug 22 04:50:59.881: INFO: (18) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 18.804178ms)
Aug 22 04:50:59.881: INFO: (18) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 18.797857ms)
Aug 22 04:50:59.882: INFO: (18) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 19.534909ms)
Aug 22 04:50:59.882: INFO: (18) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 19.973112ms)
Aug 22 04:50:59.882: INFO: (18) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 20.075644ms)
Aug 22 04:50:59.883: INFO: (18) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 20.145986ms)
Aug 22 04:50:59.891: INFO: (19) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 8.815699ms)
Aug 22 04:50:59.896: INFO: (19) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 12.959173ms)
Aug 22 04:50:59.896: INFO: (19) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 12.998968ms)
Aug 22 04:50:59.897: INFO: (19) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 14.729634ms)
Aug 22 04:50:59.900: INFO: (19) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 16.832851ms)
Aug 22 04:50:59.900: INFO: (19) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 17.270772ms)
Aug 22 04:50:59.900: INFO: (19) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 17.477529ms)
Aug 22 04:50:59.901: INFO: (19) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 17.823729ms)
Aug 22 04:50:59.901: INFO: (19) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 17.834189ms)
Aug 22 04:50:59.901: INFO: (19) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 17.902006ms)
Aug 22 04:50:59.901: INFO: (19) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 17.817477ms)
Aug 22 04:50:59.901: INFO: (19) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 18.62867ms)
Aug 22 04:50:59.901: INFO: (19) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 18.636575ms)
Aug 22 04:50:59.901: INFO: (19) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 18.731994ms)
Aug 22 04:50:59.902: INFO: (19) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 18.918343ms)
Aug 22 04:50:59.902: INFO: (19) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 19.197787ms)
STEP: deleting ReplicationController proxy-service-w777z in namespace proxy-578, will wait for the garbage collector to delete the pods 08/22/23 04:50:59.902
Aug 22 04:50:59.975: INFO: Deleting ReplicationController proxy-service-w777z took: 9.782904ms
Aug 22 04:51:00.176: INFO: Terminating ReplicationController proxy-service-w777z pods took: 200.7768ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Aug 22 04:51:03.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-578" for this suite. 08/22/23 04:51:03.083
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":184,"skipped":3363,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.746 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:50:55.345
    Aug 22 04:50:55.345: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename proxy 08/22/23 04:50:55.345
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:50:55.546
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:50:55.548
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 08/22/23 04:50:55.562
    STEP: creating replication controller proxy-service-w777z in namespace proxy-578 08/22/23 04:50:55.562
    I0822 04:50:55.575407      19 runners.go:193] Created replication controller with name: proxy-service-w777z, namespace: proxy-578, replica count: 1
    I0822 04:50:56.625717      19 runners.go:193] proxy-service-w777z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0822 04:50:57.626035      19 runners.go:193] proxy-service-w777z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0822 04:50:58.626333      19 runners.go:193] proxy-service-w777z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
    I0822 04:50:59.627451      19 runners.go:193] proxy-service-w777z Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 22 04:50:59.632: INFO: setup took 4.079409681s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 08/22/23 04:50:59.632
    Aug 22 04:50:59.640: INFO: (0) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 8.040084ms)
    Aug 22 04:50:59.642: INFO: (0) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 9.490204ms)
    Aug 22 04:50:59.646: INFO: (0) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 13.727384ms)
    Aug 22 04:50:59.647: INFO: (0) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 15.28674ms)
    Aug 22 04:50:59.647: INFO: (0) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 15.180911ms)
    Aug 22 04:50:59.648: INFO: (0) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 15.076275ms)
    Aug 22 04:50:59.649: INFO: (0) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 16.785422ms)
    Aug 22 04:50:59.650: INFO: (0) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 17.178199ms)
    Aug 22 04:50:59.650: INFO: (0) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 17.245064ms)
    Aug 22 04:50:59.650: INFO: (0) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 17.580663ms)
    Aug 22 04:50:59.650: INFO: (0) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 17.501073ms)
    Aug 22 04:50:59.650: INFO: (0) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 17.479763ms)
    Aug 22 04:50:59.650: INFO: (0) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 17.555466ms)
    Aug 22 04:50:59.650: INFO: (0) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 17.66941ms)
    Aug 22 04:50:59.651: INFO: (0) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 18.510307ms)
    Aug 22 04:50:59.651: INFO: (0) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 19.158885ms)
    Aug 22 04:50:59.655: INFO: (1) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 3.669565ms)
    Aug 22 04:50:59.656: INFO: (1) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 4.175453ms)
    Aug 22 04:50:59.658: INFO: (1) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 6.536614ms)
    Aug 22 04:50:59.659: INFO: (1) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 6.793986ms)
    Aug 22 04:50:59.659: INFO: (1) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 7.513225ms)
    Aug 22 04:50:59.660: INFO: (1) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 7.470115ms)
    Aug 22 04:50:59.660: INFO: (1) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 7.67544ms)
    Aug 22 04:50:59.660: INFO: (1) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 7.588988ms)
    Aug 22 04:50:59.661: INFO: (1) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 8.667301ms)
    Aug 22 04:50:59.661: INFO: (1) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 9.243492ms)
    Aug 22 04:50:59.662: INFO: (1) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 9.949486ms)
    Aug 22 04:50:59.662: INFO: (1) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 10.263075ms)
    Aug 22 04:50:59.662: INFO: (1) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 10.516831ms)
    Aug 22 04:50:59.662: INFO: (1) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 10.32448ms)
    Aug 22 04:50:59.663: INFO: (1) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 10.548962ms)
    Aug 22 04:50:59.663: INFO: (1) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 11.59328ms)
    Aug 22 04:50:59.670: INFO: (2) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 6.185335ms)
    Aug 22 04:50:59.670: INFO: (2) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 6.312864ms)
    Aug 22 04:50:59.671: INFO: (2) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 7.076637ms)
    Aug 22 04:50:59.671: INFO: (2) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 7.400073ms)
    Aug 22 04:50:59.672: INFO: (2) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 7.747015ms)
    Aug 22 04:50:59.672: INFO: (2) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 8.164519ms)
    Aug 22 04:50:59.672: INFO: (2) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 7.816385ms)
    Aug 22 04:50:59.672: INFO: (2) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 8.738754ms)
    Aug 22 04:50:59.672: INFO: (2) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 8.309991ms)
    Aug 22 04:50:59.672: INFO: (2) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 8.475201ms)
    Aug 22 04:50:59.672: INFO: (2) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 8.84812ms)
    Aug 22 04:50:59.673: INFO: (2) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 8.69917ms)
    Aug 22 04:50:59.673: INFO: (2) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 9.153552ms)
    Aug 22 04:50:59.673: INFO: (2) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 8.790403ms)
    Aug 22 04:50:59.673: INFO: (2) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 9.437415ms)
    Aug 22 04:50:59.674: INFO: (2) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 9.982738ms)
    Aug 22 04:50:59.680: INFO: (3) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 5.710593ms)
    Aug 22 04:50:59.680: INFO: (3) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 5.698361ms)
    Aug 22 04:50:59.681: INFO: (3) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 7.260521ms)
    Aug 22 04:50:59.681: INFO: (3) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 7.184579ms)
    Aug 22 04:50:59.681: INFO: (3) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 7.498749ms)
    Aug 22 04:50:59.681: INFO: (3) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 7.400524ms)
    Aug 22 04:50:59.682: INFO: (3) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 8.554629ms)
    Aug 22 04:50:59.682: INFO: (3) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 8.348001ms)
    Aug 22 04:50:59.683: INFO: (3) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 9.072029ms)
    Aug 22 04:50:59.683: INFO: (3) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 9.218324ms)
    Aug 22 04:50:59.683: INFO: (3) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 9.363035ms)
    Aug 22 04:50:59.683: INFO: (3) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 9.439399ms)
    Aug 22 04:50:59.684: INFO: (3) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 9.709125ms)
    Aug 22 04:50:59.684: INFO: (3) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 9.925811ms)
    Aug 22 04:50:59.684: INFO: (3) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 9.930531ms)
    Aug 22 04:50:59.685: INFO: (3) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 10.496612ms)
    Aug 22 04:50:59.688: INFO: (4) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 3.790532ms)
    Aug 22 04:50:59.690: INFO: (4) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 5.327284ms)
    Aug 22 04:50:59.690: INFO: (4) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 5.293442ms)
    Aug 22 04:50:59.691: INFO: (4) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 6.459479ms)
    Aug 22 04:50:59.694: INFO: (4) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 8.749886ms)
    Aug 22 04:50:59.694: INFO: (4) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 8.804048ms)
    Aug 22 04:50:59.694: INFO: (4) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 9.168181ms)
    Aug 22 04:50:59.694: INFO: (4) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 9.217904ms)
    Aug 22 04:50:59.694: INFO: (4) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 9.642381ms)
    Aug 22 04:50:59.695: INFO: (4) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 9.788455ms)
    Aug 22 04:50:59.695: INFO: (4) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 9.837888ms)
    Aug 22 04:50:59.695: INFO: (4) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 9.667708ms)
    Aug 22 04:50:59.695: INFO: (4) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 9.593759ms)
    Aug 22 04:50:59.695: INFO: (4) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 10.000443ms)
    Aug 22 04:50:59.695: INFO: (4) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 10.35121ms)
    Aug 22 04:50:59.695: INFO: (4) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 10.378432ms)
    Aug 22 04:50:59.704: INFO: (5) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 8.031648ms)
    Aug 22 04:50:59.704: INFO: (5) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 8.146534ms)
    Aug 22 04:50:59.704: INFO: (5) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 8.42174ms)
    Aug 22 04:50:59.704: INFO: (5) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 8.281267ms)
    Aug 22 04:50:59.704: INFO: (5) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 8.718657ms)
    Aug 22 04:50:59.704: INFO: (5) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 8.665549ms)
    Aug 22 04:50:59.705: INFO: (5) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 9.040822ms)
    Aug 22 04:50:59.705: INFO: (5) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 9.04ms)
    Aug 22 04:50:59.705: INFO: (5) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 9.312091ms)
    Aug 22 04:50:59.705: INFO: (5) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 9.298905ms)
    Aug 22 04:50:59.705: INFO: (5) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 9.495304ms)
    Aug 22 04:50:59.705: INFO: (5) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 9.591375ms)
    Aug 22 04:50:59.705: INFO: (5) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 9.862654ms)
    Aug 22 04:50:59.706: INFO: (5) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 9.867783ms)
    Aug 22 04:50:59.706: INFO: (5) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 9.919791ms)
    Aug 22 04:50:59.706: INFO: (5) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 10.515288ms)
    Aug 22 04:50:59.712: INFO: (6) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 5.543891ms)
    Aug 22 04:50:59.713: INFO: (6) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 6.057835ms)
    Aug 22 04:50:59.713: INFO: (6) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 6.258301ms)
    Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 9.603998ms)
    Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 9.507257ms)
    Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 9.520483ms)
    Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 9.53506ms)
    Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 9.570225ms)
    Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 9.601353ms)
    Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 9.649524ms)
    Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 9.627563ms)
    Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 9.638183ms)
    Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 9.65264ms)
    Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 9.662107ms)
    Aug 22 04:50:59.716: INFO: (6) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 9.690742ms)
    Aug 22 04:50:59.717: INFO: (6) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 10.653418ms)
    Aug 22 04:50:59.723: INFO: (7) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 5.760988ms)
    Aug 22 04:50:59.723: INFO: (7) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 5.899979ms)
    Aug 22 04:50:59.724: INFO: (7) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 6.160828ms)
    Aug 22 04:50:59.725: INFO: (7) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 7.306337ms)
    Aug 22 04:50:59.726: INFO: (7) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 8.559729ms)
    Aug 22 04:50:59.726: INFO: (7) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 8.693179ms)
    Aug 22 04:50:59.726: INFO: (7) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 8.569286ms)
    Aug 22 04:50:59.726: INFO: (7) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 8.973404ms)
    Aug 22 04:50:59.727: INFO: (7) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 9.315506ms)
    Aug 22 04:50:59.727: INFO: (7) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 9.651677ms)
    Aug 22 04:50:59.727: INFO: (7) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 9.944466ms)
    Aug 22 04:50:59.727: INFO: (7) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 9.968963ms)
    Aug 22 04:50:59.728: INFO: (7) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 10.527271ms)
    Aug 22 04:50:59.729: INFO: (7) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 11.175184ms)
    Aug 22 04:50:59.729: INFO: (7) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 11.498242ms)
    Aug 22 04:50:59.729: INFO: (7) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 11.624819ms)
    Aug 22 04:50:59.734: INFO: (8) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 4.819803ms)
    Aug 22 04:50:59.735: INFO: (8) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 5.675307ms)
    Aug 22 04:50:59.735: INFO: (8) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 6.160107ms)
    Aug 22 04:50:59.736: INFO: (8) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 6.579745ms)
    Aug 22 04:50:59.737: INFO: (8) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 8.302117ms)
    Aug 22 04:50:59.738: INFO: (8) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 8.395381ms)
    Aug 22 04:50:59.739: INFO: (8) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 9.616311ms)
    Aug 22 04:50:59.739: INFO: (8) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 9.809344ms)
    Aug 22 04:50:59.739: INFO: (8) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 10.375755ms)
    Aug 22 04:50:59.740: INFO: (8) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 10.264728ms)
    Aug 22 04:50:59.740: INFO: (8) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 10.610807ms)
    Aug 22 04:50:59.740: INFO: (8) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 10.709182ms)
    Aug 22 04:50:59.740: INFO: (8) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 11.005938ms)
    Aug 22 04:50:59.740: INFO: (8) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 11.159717ms)
    Aug 22 04:50:59.740: INFO: (8) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 11.069509ms)
    Aug 22 04:50:59.741: INFO: (8) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 11.594643ms)
    Aug 22 04:50:59.754: INFO: (9) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 13.050464ms)
    Aug 22 04:50:59.754: INFO: (9) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 12.918486ms)
    Aug 22 04:50:59.756: INFO: (9) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 14.949396ms)
    Aug 22 04:50:59.756: INFO: (9) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 14.764089ms)
    Aug 22 04:50:59.756: INFO: (9) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 15.132178ms)
    Aug 22 04:50:59.756: INFO: (9) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 15.032322ms)
    Aug 22 04:50:59.757: INFO: (9) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 15.786958ms)
    Aug 22 04:50:59.757: INFO: (9) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 15.758685ms)
    Aug 22 04:50:59.757: INFO: (9) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 15.935798ms)
    Aug 22 04:50:59.757: INFO: (9) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 16.305281ms)
    Aug 22 04:50:59.761: INFO: (9) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 20.407396ms)
    Aug 22 04:50:59.763: INFO: (9) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 21.813404ms)
    Aug 22 04:50:59.763: INFO: (9) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 21.642243ms)
    Aug 22 04:50:59.763: INFO: (9) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 22.328542ms)
    Aug 22 04:50:59.763: INFO: (9) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 22.293566ms)
    Aug 22 04:50:59.763: INFO: (9) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 22.273377ms)
    Aug 22 04:50:59.770: INFO: (10) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 6.395058ms)
    Aug 22 04:50:59.771: INFO: (10) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 7.938564ms)
    Aug 22 04:50:59.771: INFO: (10) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 7.785666ms)
    Aug 22 04:50:59.772: INFO: (10) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 8.375734ms)
    Aug 22 04:50:59.772: INFO: (10) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 8.846297ms)
    Aug 22 04:50:59.772: INFO: (10) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 8.649217ms)
    Aug 22 04:50:59.773: INFO: (10) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 9.068855ms)
    Aug 22 04:50:59.773: INFO: (10) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 9.073774ms)
    Aug 22 04:50:59.773: INFO: (10) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 9.035472ms)
    Aug 22 04:50:59.773: INFO: (10) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 9.299978ms)
    Aug 22 04:50:59.773: INFO: (10) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 9.353379ms)
    Aug 22 04:50:59.774: INFO: (10) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 10.46836ms)
    Aug 22 04:50:59.774: INFO: (10) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 10.955584ms)
    Aug 22 04:50:59.774: INFO: (10) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 10.926891ms)
    Aug 22 04:50:59.775: INFO: (10) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 11.119712ms)
    Aug 22 04:50:59.775: INFO: (10) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 11.518049ms)
    Aug 22 04:50:59.779: INFO: (11) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 4.19425ms)
    Aug 22 04:50:59.781: INFO: (11) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 5.451257ms)
    Aug 22 04:50:59.781: INFO: (11) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 6.08245ms)
    Aug 22 04:50:59.782: INFO: (11) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 6.94587ms)
    Aug 22 04:50:59.782: INFO: (11) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 7.293133ms)
    Aug 22 04:50:59.782: INFO: (11) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 7.209596ms)
    Aug 22 04:50:59.782: INFO: (11) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 7.290438ms)
    Aug 22 04:50:59.783: INFO: (11) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 7.629413ms)
    Aug 22 04:50:59.783: INFO: (11) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 7.641747ms)
    Aug 22 04:50:59.783: INFO: (11) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 7.81942ms)
    Aug 22 04:50:59.784: INFO: (11) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 8.768651ms)
    Aug 22 04:50:59.784: INFO: (11) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 9.139537ms)
    Aug 22 04:50:59.785: INFO: (11) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 9.454918ms)
    Aug 22 04:50:59.785: INFO: (11) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 10.001143ms)
    Aug 22 04:50:59.785: INFO: (11) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 10.133241ms)
    Aug 22 04:50:59.785: INFO: (11) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 10.163589ms)
    Aug 22 04:50:59.791: INFO: (12) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 5.42621ms)
    Aug 22 04:50:59.792: INFO: (12) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 6.948898ms)
    Aug 22 04:50:59.793: INFO: (12) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 7.743216ms)
    Aug 22 04:50:59.793: INFO: (12) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 7.758176ms)
    Aug 22 04:50:59.793: INFO: (12) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 8.09085ms)
    Aug 22 04:50:59.795: INFO: (12) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 10.061786ms)
    Aug 22 04:50:59.795: INFO: (12) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 10.028595ms)
    Aug 22 04:50:59.795: INFO: (12) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 10.072878ms)
    Aug 22 04:50:59.795: INFO: (12) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 10.134264ms)
    Aug 22 04:50:59.796: INFO: (12) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 10.709612ms)
    Aug 22 04:50:59.796: INFO: (12) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 11.149838ms)
    Aug 22 04:50:59.797: INFO: (12) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 11.151601ms)
    Aug 22 04:50:59.797: INFO: (12) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 11.469397ms)
    Aug 22 04:50:59.797: INFO: (12) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 11.779189ms)
    Aug 22 04:50:59.797: INFO: (12) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 11.856805ms)
    Aug 22 04:50:59.797: INFO: (12) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 12.192015ms)
    Aug 22 04:50:59.802: INFO: (13) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 4.74415ms)
    Aug 22 04:50:59.804: INFO: (13) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 6.025133ms)
    Aug 22 04:50:59.804: INFO: (13) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 5.878869ms)
    Aug 22 04:50:59.804: INFO: (13) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 5.892014ms)
    Aug 22 04:50:59.804: INFO: (13) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 5.937479ms)
    Aug 22 04:50:59.804: INFO: (13) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 6.671977ms)
    Aug 22 04:50:59.805: INFO: (13) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 7.11018ms)
    Aug 22 04:50:59.806: INFO: (13) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 7.963621ms)
    Aug 22 04:50:59.806: INFO: (13) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 7.970514ms)
    Aug 22 04:50:59.806: INFO: (13) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 8.570289ms)
    Aug 22 04:50:59.807: INFO: (13) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 9.269351ms)
    Aug 22 04:50:59.807: INFO: (13) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 9.633353ms)
    Aug 22 04:50:59.808: INFO: (13) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 9.945088ms)
    Aug 22 04:50:59.809: INFO: (13) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 10.71921ms)
    Aug 22 04:50:59.809: INFO: (13) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 11.221834ms)
    Aug 22 04:50:59.810: INFO: (13) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 12.598046ms)
    Aug 22 04:50:59.816: INFO: (14) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 5.579558ms)
    Aug 22 04:50:59.817: INFO: (14) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 7.204777ms)
    Aug 22 04:50:59.818: INFO: (14) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 7.082537ms)
    Aug 22 04:50:59.818: INFO: (14) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 7.666303ms)
    Aug 22 04:50:59.818: INFO: (14) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 7.642488ms)
    Aug 22 04:50:59.819: INFO: (14) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 8.556533ms)
    Aug 22 04:50:59.819: INFO: (14) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 8.615724ms)
    Aug 22 04:50:59.819: INFO: (14) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 8.824846ms)
    Aug 22 04:50:59.820: INFO: (14) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 9.383223ms)
    Aug 22 04:50:59.820: INFO: (14) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 9.536111ms)
    Aug 22 04:50:59.821: INFO: (14) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 10.859915ms)
    Aug 22 04:50:59.821: INFO: (14) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 11.029632ms)
    Aug 22 04:50:59.821: INFO: (14) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 10.858662ms)
    Aug 22 04:50:59.822: INFO: (14) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 11.513491ms)
    Aug 22 04:50:59.823: INFO: (14) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 12.131169ms)
    Aug 22 04:50:59.823: INFO: (14) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 12.349949ms)
    Aug 22 04:50:59.827: INFO: (15) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 4.021455ms)
    Aug 22 04:50:59.828: INFO: (15) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 4.703455ms)
    Aug 22 04:50:59.829: INFO: (15) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 6.030383ms)
    Aug 22 04:50:59.831: INFO: (15) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 7.322459ms)
    Aug 22 04:50:59.831: INFO: (15) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 7.645975ms)
    Aug 22 04:50:59.831: INFO: (15) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 7.562408ms)
    Aug 22 04:50:59.832: INFO: (15) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 8.547296ms)
    Aug 22 04:50:59.832: INFO: (15) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 9.021937ms)
    Aug 22 04:50:59.832: INFO: (15) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 9.095023ms)
    Aug 22 04:50:59.833: INFO: (15) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 9.733711ms)
    Aug 22 04:50:59.833: INFO: (15) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 9.850281ms)
    Aug 22 04:50:59.834: INFO: (15) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 10.531328ms)
    Aug 22 04:50:59.834: INFO: (15) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 10.570832ms)
    Aug 22 04:50:59.834: INFO: (15) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 11.114372ms)
    Aug 22 04:50:59.834: INFO: (15) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 11.000398ms)
    Aug 22 04:50:59.834: INFO: (15) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 10.978317ms)
    Aug 22 04:50:59.838: INFO: (16) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 3.71018ms)
    Aug 22 04:50:59.839: INFO: (16) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 3.996669ms)
    Aug 22 04:50:59.840: INFO: (16) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 5.597553ms)
    Aug 22 04:50:59.841: INFO: (16) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 6.130382ms)
    Aug 22 04:50:59.841: INFO: (16) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 6.515042ms)
    Aug 22 04:50:59.842: INFO: (16) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 6.943556ms)
    Aug 22 04:50:59.842: INFO: (16) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 7.115068ms)
    Aug 22 04:50:59.842: INFO: (16) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 7.140346ms)
    Aug 22 04:50:59.843: INFO: (16) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 8.317415ms)
    Aug 22 04:50:59.843: INFO: (16) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 8.742012ms)
    Aug 22 04:50:59.844: INFO: (16) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 9.746656ms)
    Aug 22 04:50:59.845: INFO: (16) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 10.467028ms)
    Aug 22 04:50:59.845: INFO: (16) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 10.540285ms)
    Aug 22 04:50:59.845: INFO: (16) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 10.503795ms)
    Aug 22 04:50:59.845: INFO: (16) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 10.727075ms)
    Aug 22 04:50:59.845: INFO: (16) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 10.754055ms)
    Aug 22 04:50:59.853: INFO: (17) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 7.094811ms)
    Aug 22 04:50:59.853: INFO: (17) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 7.468301ms)
    Aug 22 04:50:59.854: INFO: (17) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 7.774015ms)
    Aug 22 04:50:59.855: INFO: (17) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 9.063945ms)
    Aug 22 04:50:59.856: INFO: (17) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 10.012794ms)
    Aug 22 04:50:59.856: INFO: (17) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 10.415512ms)
    Aug 22 04:50:59.856: INFO: (17) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 10.015571ms)
    Aug 22 04:50:59.859: INFO: (17) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 12.743247ms)
    Aug 22 04:50:59.859: INFO: (17) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 12.716488ms)
    Aug 22 04:50:59.859: INFO: (17) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 12.893159ms)
    Aug 22 04:50:59.859: INFO: (17) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 13.209413ms)
    Aug 22 04:50:59.859: INFO: (17) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 13.81061ms)
    Aug 22 04:50:59.860: INFO: (17) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 13.458709ms)
    Aug 22 04:50:59.860: INFO: (17) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 14.37522ms)
    Aug 22 04:50:59.862: INFO: (17) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 15.477959ms)
    Aug 22 04:50:59.862: INFO: (17) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 16.167512ms)
    Aug 22 04:50:59.874: INFO: (18) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 11.741469ms)
    Aug 22 04:50:59.875: INFO: (18) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 12.250865ms)
    Aug 22 04:50:59.875: INFO: (18) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 12.672725ms)
    Aug 22 04:50:59.879: INFO: (18) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 16.605985ms)
    Aug 22 04:50:59.879: INFO: (18) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 16.594212ms)
    Aug 22 04:50:59.880: INFO: (18) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 17.403781ms)
    Aug 22 04:50:59.880: INFO: (18) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 18.042971ms)
    Aug 22 04:50:59.880: INFO: (18) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 18.127499ms)
    Aug 22 04:50:59.881: INFO: (18) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 18.413997ms)
    Aug 22 04:50:59.881: INFO: (18) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 18.576331ms)
    Aug 22 04:50:59.881: INFO: (18) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 18.804178ms)
    Aug 22 04:50:59.881: INFO: (18) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 18.797857ms)
    Aug 22 04:50:59.882: INFO: (18) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 19.534909ms)
    Aug 22 04:50:59.882: INFO: (18) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 19.973112ms)
    Aug 22 04:50:59.882: INFO: (18) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 20.075644ms)
    Aug 22 04:50:59.883: INFO: (18) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 20.145986ms)
    Aug 22 04:50:59.891: INFO: (19) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:1080/proxy/rewriteme">t... (200; 8.815699ms)
    Aug 22 04:50:59.896: INFO: (19) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:162/proxy/: bar (200; 12.959173ms)
    Aug 22 04:50:59.896: INFO: (19) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:462/proxy/: tls qux (200; 12.998968ms)
    Aug 22 04:50:59.897: INFO: (19) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:160/proxy/: foo (200; 14.729634ms)
    Aug 22 04:50:59.900: INFO: (19) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:160/proxy/: foo (200; 16.832851ms)
    Aug 22 04:50:59.900: INFO: (19) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww:1080/proxy/rewriteme">test</... (200; 17.270772ms)
    Aug 22 04:50:59.900: INFO: (19) /api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/proxy-service-w777z-mllww/proxy/rewriteme">test</a> (200; 17.477529ms)
    Aug 22 04:50:59.901: INFO: (19) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname1/proxy/: foo (200; 17.823729ms)
    Aug 22 04:50:59.901: INFO: (19) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:460/proxy/: tls baz (200; 17.834189ms)
    Aug 22 04:50:59.901: INFO: (19) /api/v1/namespaces/proxy-578/pods/http:proxy-service-w777z-mllww:162/proxy/: bar (200; 17.902006ms)
    Aug 22 04:50:59.901: INFO: (19) /api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/: <a href="/api/v1/namespaces/proxy-578/pods/https:proxy-service-w777z-mllww:443/proxy/tlsrewriteme... (200; 17.817477ms)
    Aug 22 04:50:59.901: INFO: (19) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname1/proxy/: foo (200; 18.62867ms)
    Aug 22 04:50:59.901: INFO: (19) /api/v1/namespaces/proxy-578/services/http:proxy-service-w777z:portname2/proxy/: bar (200; 18.636575ms)
    Aug 22 04:50:59.901: INFO: (19) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname2/proxy/: tls qux (200; 18.731994ms)
    Aug 22 04:50:59.902: INFO: (19) /api/v1/namespaces/proxy-578/services/proxy-service-w777z:portname2/proxy/: bar (200; 18.918343ms)
    Aug 22 04:50:59.902: INFO: (19) /api/v1/namespaces/proxy-578/services/https:proxy-service-w777z:tlsportname1/proxy/: tls baz (200; 19.197787ms)
    STEP: deleting ReplicationController proxy-service-w777z in namespace proxy-578, will wait for the garbage collector to delete the pods 08/22/23 04:50:59.902
    Aug 22 04:50:59.975: INFO: Deleting ReplicationController proxy-service-w777z took: 9.782904ms
    Aug 22 04:51:00.176: INFO: Terminating ReplicationController proxy-service-w777z pods took: 200.7768ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Aug 22 04:51:03.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-578" for this suite. 08/22/23 04:51:03.083
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:51:03.095
Aug 22 04:51:03.095: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename runtimeclass 08/22/23 04:51:03.096
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:03.118
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:03.12
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Aug 22 04:51:03.139: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-10 to be scheduled
Aug 22 04:51:03.142: INFO: 1 pods are not scheduled: [runtimeclass-10/test-runtimeclass-runtimeclass-10-preconfigured-handler-dzs8w(65c93703-2269-424a-9b0d-fcdd87bcf7f6)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 22 04:51:05.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-10" for this suite. 08/22/23 04:51:05.239
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":185,"skipped":3440,"failed":0}
------------------------------
â€¢ [2.164 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:51:03.095
    Aug 22 04:51:03.095: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename runtimeclass 08/22/23 04:51:03.096
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:03.118
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:03.12
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Aug 22 04:51:03.139: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-10 to be scheduled
    Aug 22 04:51:03.142: INFO: 1 pods are not scheduled: [runtimeclass-10/test-runtimeclass-runtimeclass-10-preconfigured-handler-dzs8w(65c93703-2269-424a-9b0d-fcdd87bcf7f6)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 22 04:51:05.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-10" for this suite. 08/22/23 04:51:05.239
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:51:05.261
Aug 22 04:51:05.261: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename crd-webhook 08/22/23 04:51:05.262
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:05.277
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:05.279
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 08/22/23 04:51:05.283
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 08/22/23 04:51:05.495
STEP: Deploying the custom resource conversion webhook pod 08/22/23 04:51:05.504
STEP: Wait for the deployment to be ready 08/22/23 04:51:05.708
Aug 22 04:51:05.721: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Aug 22 04:51:07.730: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 51, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 51, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 51, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 51, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 04:51:09.736
STEP: Verifying the service has paired with the endpoint 08/22/23 04:51:09.931
Aug 22 04:51:10.931: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Aug 22 04:51:10.936: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Creating a v1 custom resource 08/22/23 04:51:13.851
STEP: v2 custom resource should be converted 08/22/23 04:51:13.856
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:51:14.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5562" for this suite. 08/22/23 04:51:14.561
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":186,"skipped":3477,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.530 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:51:05.261
    Aug 22 04:51:05.261: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename crd-webhook 08/22/23 04:51:05.262
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:05.277
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:05.279
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 08/22/23 04:51:05.283
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 08/22/23 04:51:05.495
    STEP: Deploying the custom resource conversion webhook pod 08/22/23 04:51:05.504
    STEP: Wait for the deployment to be ready 08/22/23 04:51:05.708
    Aug 22 04:51:05.721: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Aug 22 04:51:07.730: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 51, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 51, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 51, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 51, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 04:51:09.736
    STEP: Verifying the service has paired with the endpoint 08/22/23 04:51:09.931
    Aug 22 04:51:10.931: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Aug 22 04:51:10.936: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Creating a v1 custom resource 08/22/23 04:51:13.851
    STEP: v2 custom resource should be converted 08/22/23 04:51:13.856
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:51:14.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-5562" for this suite. 08/22/23 04:51:14.561
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:51:14.791
Aug 22 04:51:14.791: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename podtemplate 08/22/23 04:51:14.792
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:15.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:15.011
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Aug 22 04:51:15.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-6078" for this suite. 08/22/23 04:51:15.047
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":187,"skipped":3483,"failed":0}
------------------------------
â€¢ [0.262 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:51:14.791
    Aug 22 04:51:14.791: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename podtemplate 08/22/23 04:51:14.792
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:15.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:15.011
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Aug 22 04:51:15.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-6078" for this suite. 08/22/23 04:51:15.047
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:51:15.055
Aug 22 04:51:15.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 04:51:15.055
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:15.07
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:15.072
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 08/22/23 04:51:15.076
Aug 22 04:51:15.085: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f" in namespace "downward-api-3259" to be "Succeeded or Failed"
Aug 22 04:51:15.088: INFO: Pod "downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.889992ms
Aug 22 04:51:17.093: INFO: Pod "downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008059801s
Aug 22 04:51:19.316: INFO: Pod "downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.230428379s
Aug 22 04:51:21.093: INFO: Pod "downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00741035s
STEP: Saw pod success 08/22/23 04:51:21.093
Aug 22 04:51:21.093: INFO: Pod "downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f" satisfied condition "Succeeded or Failed"
Aug 22 04:51:21.096: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f container client-container: <nil>
STEP: delete the pod 08/22/23 04:51:21.126
Aug 22 04:51:21.446: INFO: Waiting for pod downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f to disappear
Aug 22 04:51:21.449: INFO: Pod downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 22 04:51:21.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3259" for this suite. 08/22/23 04:51:21.452
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":188,"skipped":3492,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.404 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:51:15.055
    Aug 22 04:51:15.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 04:51:15.055
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:15.07
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:15.072
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 08/22/23 04:51:15.076
    Aug 22 04:51:15.085: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f" in namespace "downward-api-3259" to be "Succeeded or Failed"
    Aug 22 04:51:15.088: INFO: Pod "downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.889992ms
    Aug 22 04:51:17.093: INFO: Pod "downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008059801s
    Aug 22 04:51:19.316: INFO: Pod "downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.230428379s
    Aug 22 04:51:21.093: INFO: Pod "downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00741035s
    STEP: Saw pod success 08/22/23 04:51:21.093
    Aug 22 04:51:21.093: INFO: Pod "downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f" satisfied condition "Succeeded or Failed"
    Aug 22 04:51:21.096: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f container client-container: <nil>
    STEP: delete the pod 08/22/23 04:51:21.126
    Aug 22 04:51:21.446: INFO: Waiting for pod downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f to disappear
    Aug 22 04:51:21.449: INFO: Pod downwardapi-volume-0ce0accd-d548-486a-8963-ab84c7c81f2f no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 22 04:51:21.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3259" for this suite. 08/22/23 04:51:21.452
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:51:21.462
Aug 22 04:51:21.462: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 04:51:21.463
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:21.524
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:21.527
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-097280ea-fde2-4327-a02d-5faac25228a1 08/22/23 04:51:21.531
STEP: Creating a pod to test consume configMaps 08/22/23 04:51:21.536
Aug 22 04:51:21.910: INFO: Waiting up to 5m0s for pod "pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b" in namespace "configmap-722" to be "Succeeded or Failed"
Aug 22 04:51:21.989: INFO: Pod "pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b": Phase="Pending", Reason="", readiness=false. Elapsed: 78.957774ms
Aug 22 04:51:23.993: INFO: Pod "pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08234509s
Aug 22 04:51:26.124: INFO: Pod "pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.214162502s
Aug 22 04:51:27.994: INFO: Pod "pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.083958362s
STEP: Saw pod success 08/22/23 04:51:27.994
Aug 22 04:51:27.994: INFO: Pod "pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b" satisfied condition "Succeeded or Failed"
Aug 22 04:51:27.997: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b container agnhost-container: <nil>
STEP: delete the pod 08/22/23 04:51:28.004
Aug 22 04:51:28.229: INFO: Waiting for pod pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b to disappear
Aug 22 04:51:28.234: INFO: Pod pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 04:51:28.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-722" for this suite. 08/22/23 04:51:28.24
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":189,"skipped":3537,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.784 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:51:21.462
    Aug 22 04:51:21.462: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 04:51:21.463
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:21.524
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:21.527
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-097280ea-fde2-4327-a02d-5faac25228a1 08/22/23 04:51:21.531
    STEP: Creating a pod to test consume configMaps 08/22/23 04:51:21.536
    Aug 22 04:51:21.910: INFO: Waiting up to 5m0s for pod "pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b" in namespace "configmap-722" to be "Succeeded or Failed"
    Aug 22 04:51:21.989: INFO: Pod "pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b": Phase="Pending", Reason="", readiness=false. Elapsed: 78.957774ms
    Aug 22 04:51:23.993: INFO: Pod "pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08234509s
    Aug 22 04:51:26.124: INFO: Pod "pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.214162502s
    Aug 22 04:51:27.994: INFO: Pod "pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.083958362s
    STEP: Saw pod success 08/22/23 04:51:27.994
    Aug 22 04:51:27.994: INFO: Pod "pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b" satisfied condition "Succeeded or Failed"
    Aug 22 04:51:27.997: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 04:51:28.004
    Aug 22 04:51:28.229: INFO: Waiting for pod pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b to disappear
    Aug 22 04:51:28.234: INFO: Pod pod-configmaps-557afd69-8b19-41ad-82d3-254da0f6879b no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 04:51:28.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-722" for this suite. 08/22/23 04:51:28.24
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:51:28.246
Aug 22 04:51:28.247: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename secrets 08/22/23 04:51:28.247
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:28.264
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:28.266
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-7eaf2677-5c01-47cd-853a-5eda5b341c11 08/22/23 04:51:28.269
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Aug 22 04:51:28.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-319" for this suite. 08/22/23 04:51:28.277
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":190,"skipped":3544,"failed":0}
------------------------------
â€¢ [0.038 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:51:28.246
    Aug 22 04:51:28.247: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename secrets 08/22/23 04:51:28.247
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:28.264
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:28.266
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-7eaf2677-5c01-47cd-853a-5eda5b341c11 08/22/23 04:51:28.269
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Aug 22 04:51:28.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-319" for this suite. 08/22/23 04:51:28.277
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:51:28.287
Aug 22 04:51:28.287: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:51:28.288
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:28.302
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:28.306
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-f221108f-a67e-4a9d-bbfb-ab021c975b79 08/22/23 04:51:28.31
STEP: Creating a pod to test consume secrets 08/22/23 04:51:28.314
Aug 22 04:51:28.326: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115" in namespace "projected-3120" to be "Succeeded or Failed"
Aug 22 04:51:28.332: INFO: Pod "pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115": Phase="Pending", Reason="", readiness=false. Elapsed: 6.551582ms
Aug 22 04:51:30.350: INFO: Pod "pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024435945s
Aug 22 04:51:32.472: INFO: Pod "pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115": Phase="Pending", Reason="", readiness=false. Elapsed: 4.145809303s
Aug 22 04:51:34.336: INFO: Pod "pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010713089s
STEP: Saw pod success 08/22/23 04:51:34.337
Aug 22 04:51:34.337: INFO: Pod "pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115" satisfied condition "Succeeded or Failed"
Aug 22 04:51:34.339: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115 container secret-volume-test: <nil>
STEP: delete the pod 08/22/23 04:51:34.346
Aug 22 04:51:34.514: INFO: Waiting for pod pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115 to disappear
Aug 22 04:51:34.518: INFO: Pod pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 22 04:51:34.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3120" for this suite. 08/22/23 04:51:34.522
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":191,"skipped":3554,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.523 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:51:28.287
    Aug 22 04:51:28.287: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:51:28.288
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:28.302
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:28.306
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-f221108f-a67e-4a9d-bbfb-ab021c975b79 08/22/23 04:51:28.31
    STEP: Creating a pod to test consume secrets 08/22/23 04:51:28.314
    Aug 22 04:51:28.326: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115" in namespace "projected-3120" to be "Succeeded or Failed"
    Aug 22 04:51:28.332: INFO: Pod "pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115": Phase="Pending", Reason="", readiness=false. Elapsed: 6.551582ms
    Aug 22 04:51:30.350: INFO: Pod "pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024435945s
    Aug 22 04:51:32.472: INFO: Pod "pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115": Phase="Pending", Reason="", readiness=false. Elapsed: 4.145809303s
    Aug 22 04:51:34.336: INFO: Pod "pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010713089s
    STEP: Saw pod success 08/22/23 04:51:34.337
    Aug 22 04:51:34.337: INFO: Pod "pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115" satisfied condition "Succeeded or Failed"
    Aug 22 04:51:34.339: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115 container secret-volume-test: <nil>
    STEP: delete the pod 08/22/23 04:51:34.346
    Aug 22 04:51:34.514: INFO: Waiting for pod pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115 to disappear
    Aug 22 04:51:34.518: INFO: Pod pod-projected-secrets-a3da1cb4-b0cf-42d4-a3c9-ba29a51a7115 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 22 04:51:34.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3120" for this suite. 08/22/23 04:51:34.522
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:51:34.811
Aug 22 04:51:34.811: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-probe 08/22/23 04:51:34.812
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:34.917
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:34.921
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2 in namespace container-probe-5505 08/22/23 04:51:34.926
Aug 22 04:51:35.059: INFO: Waiting up to 5m0s for pod "liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2" in namespace "container-probe-5505" to be "not pending"
Aug 22 04:51:35.064: INFO: Pod "liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.488612ms
Aug 22 04:51:37.069: INFO: Pod "liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009149716s
Aug 22 04:51:39.068: INFO: Pod "liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2": Phase="Running", Reason="", readiness=true. Elapsed: 4.008377007s
Aug 22 04:51:39.068: INFO: Pod "liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2" satisfied condition "not pending"
Aug 22 04:51:39.068: INFO: Started pod liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2 in namespace container-probe-5505
STEP: checking the pod's current state and verifying that restartCount is present 08/22/23 04:51:39.068
Aug 22 04:51:39.070: INFO: Initial restart count of pod liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2 is 0
STEP: deleting the pod 08/22/23 04:55:39.421
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 22 04:55:39.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5505" for this suite. 08/22/23 04:55:39.458
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":192,"skipped":3579,"failed":0}
------------------------------
â€¢ [SLOW TEST] [244.655 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:51:34.811
    Aug 22 04:51:34.811: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-probe 08/22/23 04:51:34.812
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:51:34.917
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:51:34.921
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2 in namespace container-probe-5505 08/22/23 04:51:34.926
    Aug 22 04:51:35.059: INFO: Waiting up to 5m0s for pod "liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2" in namespace "container-probe-5505" to be "not pending"
    Aug 22 04:51:35.064: INFO: Pod "liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.488612ms
    Aug 22 04:51:37.069: INFO: Pod "liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009149716s
    Aug 22 04:51:39.068: INFO: Pod "liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2": Phase="Running", Reason="", readiness=true. Elapsed: 4.008377007s
    Aug 22 04:51:39.068: INFO: Pod "liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2" satisfied condition "not pending"
    Aug 22 04:51:39.068: INFO: Started pod liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2 in namespace container-probe-5505
    STEP: checking the pod's current state and verifying that restartCount is present 08/22/23 04:51:39.068
    Aug 22 04:51:39.070: INFO: Initial restart count of pod liveness-4ff65877-276f-4bd7-83bc-ebd845a115f2 is 0
    STEP: deleting the pod 08/22/23 04:55:39.421
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 22 04:55:39.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5505" for this suite. 08/22/23 04:55:39.458
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:55:39.467
Aug 22 04:55:39.467: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:55:39.468
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:55:39.546
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:55:39.551
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-3038ed86-25db-429e-b39d-3302a8db034a 08/22/23 04:55:39.554
STEP: Creating a pod to test consume configMaps 08/22/23 04:55:39.56
Aug 22 04:55:39.571: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab" in namespace "projected-1191" to be "Succeeded or Failed"
Aug 22 04:55:39.576: INFO: Pod "pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab": Phase="Pending", Reason="", readiness=false. Elapsed: 4.213945ms
Aug 22 04:55:41.581: INFO: Pod "pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009359968s
Aug 22 04:55:43.581: INFO: Pod "pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009690665s
Aug 22 04:55:45.580: INFO: Pod "pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008938592s
STEP: Saw pod success 08/22/23 04:55:45.58
Aug 22 04:55:45.580: INFO: Pod "pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab" satisfied condition "Succeeded or Failed"
Aug 22 04:55:45.583: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab container agnhost-container: <nil>
STEP: delete the pod 08/22/23 04:55:45.622
Aug 22 04:55:45.641: INFO: Waiting for pod pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab to disappear
Aug 22 04:55:45.644: INFO: Pod pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 22 04:55:45.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1191" for this suite. 08/22/23 04:55:45.648
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":193,"skipped":3599,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.188 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:55:39.467
    Aug 22 04:55:39.467: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:55:39.468
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:55:39.546
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:55:39.551
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-3038ed86-25db-429e-b39d-3302a8db034a 08/22/23 04:55:39.554
    STEP: Creating a pod to test consume configMaps 08/22/23 04:55:39.56
    Aug 22 04:55:39.571: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab" in namespace "projected-1191" to be "Succeeded or Failed"
    Aug 22 04:55:39.576: INFO: Pod "pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab": Phase="Pending", Reason="", readiness=false. Elapsed: 4.213945ms
    Aug 22 04:55:41.581: INFO: Pod "pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009359968s
    Aug 22 04:55:43.581: INFO: Pod "pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009690665s
    Aug 22 04:55:45.580: INFO: Pod "pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008938592s
    STEP: Saw pod success 08/22/23 04:55:45.58
    Aug 22 04:55:45.580: INFO: Pod "pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab" satisfied condition "Succeeded or Failed"
    Aug 22 04:55:45.583: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 04:55:45.622
    Aug 22 04:55:45.641: INFO: Waiting for pod pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab to disappear
    Aug 22 04:55:45.644: INFO: Pod pod-projected-configmaps-a15aea21-5cc6-4d82-9c2c-36072e64fcab no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 22 04:55:45.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1191" for this suite. 08/22/23 04:55:45.648
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:55:45.656
Aug 22 04:55:45.657: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename dns 08/22/23 04:55:45.657
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:55:45.68
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:55:45.682
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 08/22/23 04:55:45.686
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9111.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9111.svc.cluster.local; sleep 1; done
 08/22/23 04:55:45.694
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9111.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9111.svc.cluster.local; sleep 1; done
 08/22/23 04:55:45.694
STEP: creating a pod to probe DNS 08/22/23 04:55:45.694
STEP: submitting the pod to kubernetes 08/22/23 04:55:45.694
Aug 22 04:55:45.705: INFO: Waiting up to 15m0s for pod "dns-test-667a3cbb-89c5-42f0-9f9f-15af8549d6cb" in namespace "dns-9111" to be "running"
Aug 22 04:55:45.709: INFO: Pod "dns-test-667a3cbb-89c5-42f0-9f9f-15af8549d6cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.538127ms
Aug 22 04:55:47.842: INFO: Pod "dns-test-667a3cbb-89c5-42f0-9f9f-15af8549d6cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.137187867s
Aug 22 04:55:49.715: INFO: Pod "dns-test-667a3cbb-89c5-42f0-9f9f-15af8549d6cb": Phase="Running", Reason="", readiness=true. Elapsed: 4.009615183s
Aug 22 04:55:49.715: INFO: Pod "dns-test-667a3cbb-89c5-42f0-9f9f-15af8549d6cb" satisfied condition "running"
STEP: retrieving the pod 08/22/23 04:55:49.715
STEP: looking for the results for each expected name from probers 08/22/23 04:55:49.718
Aug 22 04:55:49.727: INFO: DNS probes using dns-test-667a3cbb-89c5-42f0-9f9f-15af8549d6cb succeeded

STEP: deleting the pod 08/22/23 04:55:49.727
STEP: changing the externalName to bar.example.com 08/22/23 04:55:49.781
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9111.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9111.svc.cluster.local; sleep 1; done
 08/22/23 04:55:49.794
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9111.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9111.svc.cluster.local; sleep 1; done
 08/22/23 04:55:49.794
STEP: creating a second pod to probe DNS 08/22/23 04:55:49.794
STEP: submitting the pod to kubernetes 08/22/23 04:55:49.794
Aug 22 04:55:49.803: INFO: Waiting up to 15m0s for pod "dns-test-56772f6a-b3b6-469e-ba4c-cbaf2d90c8f6" in namespace "dns-9111" to be "running"
Aug 22 04:55:49.808: INFO: Pod "dns-test-56772f6a-b3b6-469e-ba4c-cbaf2d90c8f6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.828399ms
Aug 22 04:55:51.871: INFO: Pod "dns-test-56772f6a-b3b6-469e-ba4c-cbaf2d90c8f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06798861s
Aug 22 04:55:53.814: INFO: Pod "dns-test-56772f6a-b3b6-469e-ba4c-cbaf2d90c8f6": Phase="Running", Reason="", readiness=true. Elapsed: 4.010611743s
Aug 22 04:55:53.814: INFO: Pod "dns-test-56772f6a-b3b6-469e-ba4c-cbaf2d90c8f6" satisfied condition "running"
STEP: retrieving the pod 08/22/23 04:55:53.814
STEP: looking for the results for each expected name from probers 08/22/23 04:55:53.817
Aug 22 04:55:53.826: INFO: DNS probes using dns-test-56772f6a-b3b6-469e-ba4c-cbaf2d90c8f6 succeeded

STEP: deleting the pod 08/22/23 04:55:53.826
STEP: changing the service to type=ClusterIP 08/22/23 04:55:53.926
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9111.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9111.svc.cluster.local; sleep 1; done
 08/22/23 04:55:54.026
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9111.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9111.svc.cluster.local; sleep 1; done
 08/22/23 04:55:54.026
STEP: creating a third pod to probe DNS 08/22/23 04:55:54.026
STEP: submitting the pod to kubernetes 08/22/23 04:55:54.032
Aug 22 04:55:54.045: INFO: Waiting up to 15m0s for pod "dns-test-ea612956-469f-4273-a1f9-775258a6fe18" in namespace "dns-9111" to be "running"
Aug 22 04:55:54.051: INFO: Pod "dns-test-ea612956-469f-4273-a1f9-775258a6fe18": Phase="Pending", Reason="", readiness=false. Elapsed: 5.497174ms
Aug 22 04:55:56.055: INFO: Pod "dns-test-ea612956-469f-4273-a1f9-775258a6fe18": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010049141s
Aug 22 04:55:58.060: INFO: Pod "dns-test-ea612956-469f-4273-a1f9-775258a6fe18": Phase="Running", Reason="", readiness=true. Elapsed: 4.014788149s
Aug 22 04:55:58.060: INFO: Pod "dns-test-ea612956-469f-4273-a1f9-775258a6fe18" satisfied condition "running"
STEP: retrieving the pod 08/22/23 04:55:58.06
STEP: looking for the results for each expected name from probers 08/22/23 04:55:58.063
Aug 22 04:55:58.071: INFO: DNS probes using dns-test-ea612956-469f-4273-a1f9-775258a6fe18 succeeded

STEP: deleting the pod 08/22/23 04:55:58.071
STEP: deleting the test externalName service 08/22/23 04:55:58.091
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 22 04:55:58.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9111" for this suite. 08/22/23 04:55:58.119
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":194,"skipped":3609,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.470 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:55:45.656
    Aug 22 04:55:45.657: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename dns 08/22/23 04:55:45.657
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:55:45.68
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:55:45.682
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 08/22/23 04:55:45.686
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9111.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9111.svc.cluster.local; sleep 1; done
     08/22/23 04:55:45.694
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9111.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9111.svc.cluster.local; sleep 1; done
     08/22/23 04:55:45.694
    STEP: creating a pod to probe DNS 08/22/23 04:55:45.694
    STEP: submitting the pod to kubernetes 08/22/23 04:55:45.694
    Aug 22 04:55:45.705: INFO: Waiting up to 15m0s for pod "dns-test-667a3cbb-89c5-42f0-9f9f-15af8549d6cb" in namespace "dns-9111" to be "running"
    Aug 22 04:55:45.709: INFO: Pod "dns-test-667a3cbb-89c5-42f0-9f9f-15af8549d6cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.538127ms
    Aug 22 04:55:47.842: INFO: Pod "dns-test-667a3cbb-89c5-42f0-9f9f-15af8549d6cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.137187867s
    Aug 22 04:55:49.715: INFO: Pod "dns-test-667a3cbb-89c5-42f0-9f9f-15af8549d6cb": Phase="Running", Reason="", readiness=true. Elapsed: 4.009615183s
    Aug 22 04:55:49.715: INFO: Pod "dns-test-667a3cbb-89c5-42f0-9f9f-15af8549d6cb" satisfied condition "running"
    STEP: retrieving the pod 08/22/23 04:55:49.715
    STEP: looking for the results for each expected name from probers 08/22/23 04:55:49.718
    Aug 22 04:55:49.727: INFO: DNS probes using dns-test-667a3cbb-89c5-42f0-9f9f-15af8549d6cb succeeded

    STEP: deleting the pod 08/22/23 04:55:49.727
    STEP: changing the externalName to bar.example.com 08/22/23 04:55:49.781
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9111.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9111.svc.cluster.local; sleep 1; done
     08/22/23 04:55:49.794
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9111.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9111.svc.cluster.local; sleep 1; done
     08/22/23 04:55:49.794
    STEP: creating a second pod to probe DNS 08/22/23 04:55:49.794
    STEP: submitting the pod to kubernetes 08/22/23 04:55:49.794
    Aug 22 04:55:49.803: INFO: Waiting up to 15m0s for pod "dns-test-56772f6a-b3b6-469e-ba4c-cbaf2d90c8f6" in namespace "dns-9111" to be "running"
    Aug 22 04:55:49.808: INFO: Pod "dns-test-56772f6a-b3b6-469e-ba4c-cbaf2d90c8f6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.828399ms
    Aug 22 04:55:51.871: INFO: Pod "dns-test-56772f6a-b3b6-469e-ba4c-cbaf2d90c8f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06798861s
    Aug 22 04:55:53.814: INFO: Pod "dns-test-56772f6a-b3b6-469e-ba4c-cbaf2d90c8f6": Phase="Running", Reason="", readiness=true. Elapsed: 4.010611743s
    Aug 22 04:55:53.814: INFO: Pod "dns-test-56772f6a-b3b6-469e-ba4c-cbaf2d90c8f6" satisfied condition "running"
    STEP: retrieving the pod 08/22/23 04:55:53.814
    STEP: looking for the results for each expected name from probers 08/22/23 04:55:53.817
    Aug 22 04:55:53.826: INFO: DNS probes using dns-test-56772f6a-b3b6-469e-ba4c-cbaf2d90c8f6 succeeded

    STEP: deleting the pod 08/22/23 04:55:53.826
    STEP: changing the service to type=ClusterIP 08/22/23 04:55:53.926
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9111.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9111.svc.cluster.local; sleep 1; done
     08/22/23 04:55:54.026
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9111.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9111.svc.cluster.local; sleep 1; done
     08/22/23 04:55:54.026
    STEP: creating a third pod to probe DNS 08/22/23 04:55:54.026
    STEP: submitting the pod to kubernetes 08/22/23 04:55:54.032
    Aug 22 04:55:54.045: INFO: Waiting up to 15m0s for pod "dns-test-ea612956-469f-4273-a1f9-775258a6fe18" in namespace "dns-9111" to be "running"
    Aug 22 04:55:54.051: INFO: Pod "dns-test-ea612956-469f-4273-a1f9-775258a6fe18": Phase="Pending", Reason="", readiness=false. Elapsed: 5.497174ms
    Aug 22 04:55:56.055: INFO: Pod "dns-test-ea612956-469f-4273-a1f9-775258a6fe18": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010049141s
    Aug 22 04:55:58.060: INFO: Pod "dns-test-ea612956-469f-4273-a1f9-775258a6fe18": Phase="Running", Reason="", readiness=true. Elapsed: 4.014788149s
    Aug 22 04:55:58.060: INFO: Pod "dns-test-ea612956-469f-4273-a1f9-775258a6fe18" satisfied condition "running"
    STEP: retrieving the pod 08/22/23 04:55:58.06
    STEP: looking for the results for each expected name from probers 08/22/23 04:55:58.063
    Aug 22 04:55:58.071: INFO: DNS probes using dns-test-ea612956-469f-4273-a1f9-775258a6fe18 succeeded

    STEP: deleting the pod 08/22/23 04:55:58.071
    STEP: deleting the test externalName service 08/22/23 04:55:58.091
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 22 04:55:58.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9111" for this suite. 08/22/23 04:55:58.119
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:55:58.126
Aug 22 04:55:58.127: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 04:55:58.127
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:55:58.159
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:55:58.162
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 08/22/23 04:55:58.166
Aug 22 04:55:58.176: INFO: Waiting up to 5m0s for pod "pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c" in namespace "emptydir-6572" to be "Succeeded or Failed"
Aug 22 04:55:58.179: INFO: Pod "pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.126506ms
Aug 22 04:56:00.279: INFO: Pod "pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.10336929s
Aug 22 04:56:02.184: INFO: Pod "pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008615358s
Aug 22 04:56:04.184: INFO: Pod "pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008151857s
STEP: Saw pod success 08/22/23 04:56:04.184
Aug 22 04:56:04.184: INFO: Pod "pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c" satisfied condition "Succeeded or Failed"
Aug 22 04:56:04.186: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c container test-container: <nil>
STEP: delete the pod 08/22/23 04:56:04.192
Aug 22 04:56:04.371: INFO: Waiting for pod pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c to disappear
Aug 22 04:56:04.374: INFO: Pod pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 04:56:04.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6572" for this suite. 08/22/23 04:56:04.378
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":195,"skipped":3622,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.274 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:55:58.126
    Aug 22 04:55:58.127: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 04:55:58.127
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:55:58.159
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:55:58.162
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 08/22/23 04:55:58.166
    Aug 22 04:55:58.176: INFO: Waiting up to 5m0s for pod "pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c" in namespace "emptydir-6572" to be "Succeeded or Failed"
    Aug 22 04:55:58.179: INFO: Pod "pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.126506ms
    Aug 22 04:56:00.279: INFO: Pod "pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.10336929s
    Aug 22 04:56:02.184: INFO: Pod "pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008615358s
    Aug 22 04:56:04.184: INFO: Pod "pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008151857s
    STEP: Saw pod success 08/22/23 04:56:04.184
    Aug 22 04:56:04.184: INFO: Pod "pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c" satisfied condition "Succeeded or Failed"
    Aug 22 04:56:04.186: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c container test-container: <nil>
    STEP: delete the pod 08/22/23 04:56:04.192
    Aug 22 04:56:04.371: INFO: Waiting for pod pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c to disappear
    Aug 22 04:56:04.374: INFO: Pod pod-5a46ad6c-844e-454b-87e5-dc63a5fcab0c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 04:56:04.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6572" for this suite. 08/22/23 04:56:04.378
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:56:04.403
Aug 22 04:56:04.403: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 04:56:04.403
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:56:04.461
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:56:04.465
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 08/22/23 04:56:04.468
Aug 22 04:56:04.476: INFO: Waiting up to 5m0s for pod "downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db" in namespace "downward-api-1972" to be "Succeeded or Failed"
Aug 22 04:56:04.479: INFO: Pod "downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db": Phase="Pending", Reason="", readiness=false. Elapsed: 3.410578ms
Aug 22 04:56:06.483: INFO: Pod "downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007857337s
Aug 22 04:56:08.483: INFO: Pod "downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007773116s
Aug 22 04:56:10.484: INFO: Pod "downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008297166s
STEP: Saw pod success 08/22/23 04:56:10.484
Aug 22 04:56:10.484: INFO: Pod "downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db" satisfied condition "Succeeded or Failed"
Aug 22 04:56:10.486: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db container client-container: <nil>
STEP: delete the pod 08/22/23 04:56:10.491
Aug 22 04:56:10.528: INFO: Waiting for pod downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db to disappear
Aug 22 04:56:10.532: INFO: Pod downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 22 04:56:10.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1972" for this suite. 08/22/23 04:56:10.536
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":196,"skipped":3723,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.139 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:56:04.403
    Aug 22 04:56:04.403: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 04:56:04.403
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:56:04.461
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:56:04.465
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 08/22/23 04:56:04.468
    Aug 22 04:56:04.476: INFO: Waiting up to 5m0s for pod "downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db" in namespace "downward-api-1972" to be "Succeeded or Failed"
    Aug 22 04:56:04.479: INFO: Pod "downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db": Phase="Pending", Reason="", readiness=false. Elapsed: 3.410578ms
    Aug 22 04:56:06.483: INFO: Pod "downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007857337s
    Aug 22 04:56:08.483: INFO: Pod "downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007773116s
    Aug 22 04:56:10.484: INFO: Pod "downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008297166s
    STEP: Saw pod success 08/22/23 04:56:10.484
    Aug 22 04:56:10.484: INFO: Pod "downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db" satisfied condition "Succeeded or Failed"
    Aug 22 04:56:10.486: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db container client-container: <nil>
    STEP: delete the pod 08/22/23 04:56:10.491
    Aug 22 04:56:10.528: INFO: Waiting for pod downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db to disappear
    Aug 22 04:56:10.532: INFO: Pod downwardapi-volume-faba8081-54ef-4df2-be28-f993abfc04db no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 22 04:56:10.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1972" for this suite. 08/22/23 04:56:10.536
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:56:10.542
Aug 22 04:56:10.542: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename statefulset 08/22/23 04:56:10.543
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:56:10.557
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:56:10.56
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2152 08/22/23 04:56:10.563
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 08/22/23 04:56:10.569
Aug 22 04:56:10.586: INFO: Found 0 stateful pods, waiting for 3
Aug 22 04:56:20.592: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 04:56:20.592: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 04:56:20.592: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 04:56:20.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-2152 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 22 04:56:20.842: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 22 04:56:20.842: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 22 04:56:20.842: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 08/22/23 04:56:30.858
Aug 22 04:56:30.896: INFO: Updating stateful set ss2
STEP: Creating a new revision 08/22/23 04:56:30.896
STEP: Updating Pods in reverse ordinal order 08/22/23 04:56:40.911
Aug 22 04:56:40.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-2152 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 22 04:56:41.063: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 22 04:56:41.063: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 22 04:56:41.063: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 22 04:56:51.081: INFO: Waiting for StatefulSet statefulset-2152/ss2 to complete update
STEP: Rolling back to a previous revision 08/22/23 04:57:01.09
Aug 22 04:57:01.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-2152 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 22 04:57:01.312: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 22 04:57:01.312: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 22 04:57:01.312: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 22 04:57:11.748: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 08/22/23 04:57:22.066
Aug 22 04:57:22.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-2152 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 22 04:57:22.215: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 22 04:57:22.215: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 22 04:57:22.215: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 22 04:57:32.241: INFO: Waiting for StatefulSet statefulset-2152/ss2 to complete update
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 22 04:57:42.250: INFO: Deleting all statefulset in ns statefulset-2152
Aug 22 04:57:42.254: INFO: Scaling statefulset ss2 to 0
Aug 22 04:57:52.345: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 04:57:52.348: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 22 04:57:52.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2152" for this suite. 08/22/23 04:57:52.367
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":197,"skipped":3724,"failed":0}
------------------------------
â€¢ [SLOW TEST] [101.830 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:56:10.542
    Aug 22 04:56:10.542: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename statefulset 08/22/23 04:56:10.543
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:56:10.557
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:56:10.56
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2152 08/22/23 04:56:10.563
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 08/22/23 04:56:10.569
    Aug 22 04:56:10.586: INFO: Found 0 stateful pods, waiting for 3
    Aug 22 04:56:20.592: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 22 04:56:20.592: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 22 04:56:20.592: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Aug 22 04:56:20.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-2152 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 22 04:56:20.842: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 22 04:56:20.842: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 22 04:56:20.842: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 08/22/23 04:56:30.858
    Aug 22 04:56:30.896: INFO: Updating stateful set ss2
    STEP: Creating a new revision 08/22/23 04:56:30.896
    STEP: Updating Pods in reverse ordinal order 08/22/23 04:56:40.911
    Aug 22 04:56:40.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-2152 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 22 04:56:41.063: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 22 04:56:41.063: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 22 04:56:41.063: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 22 04:56:51.081: INFO: Waiting for StatefulSet statefulset-2152/ss2 to complete update
    STEP: Rolling back to a previous revision 08/22/23 04:57:01.09
    Aug 22 04:57:01.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-2152 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 22 04:57:01.312: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 22 04:57:01.312: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 22 04:57:01.312: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 22 04:57:11.748: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 08/22/23 04:57:22.066
    Aug 22 04:57:22.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-2152 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 22 04:57:22.215: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 22 04:57:22.215: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 22 04:57:22.215: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 22 04:57:32.241: INFO: Waiting for StatefulSet statefulset-2152/ss2 to complete update
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 22 04:57:42.250: INFO: Deleting all statefulset in ns statefulset-2152
    Aug 22 04:57:42.254: INFO: Scaling statefulset ss2 to 0
    Aug 22 04:57:52.345: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 22 04:57:52.348: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 22 04:57:52.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2152" for this suite. 08/22/23 04:57:52.367
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:57:52.373
Aug 22 04:57:52.373: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename gc 08/22/23 04:57:52.373
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:57:52.683
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:57:52.688
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 08/22/23 04:57:52.697
STEP: delete the rc 08/22/23 04:57:57.73
STEP: wait for the rc to be deleted 08/22/23 04:57:57.742
Aug 22 04:57:58.764: INFO: 80 pods remaining
Aug 22 04:57:58.764: INFO: 80 pods has nil DeletionTimestamp
Aug 22 04:57:58.764: INFO: 
Aug 22 04:57:59.857: INFO: 72 pods remaining
Aug 22 04:57:59.857: INFO: 72 pods has nil DeletionTimestamp
Aug 22 04:57:59.857: INFO: 
Aug 22 04:58:00.979: INFO: 60 pods remaining
Aug 22 04:58:00.979: INFO: 57 pods has nil DeletionTimestamp
Aug 22 04:58:00.979: INFO: 
Aug 22 04:58:02.032: INFO: 42 pods remaining
Aug 22 04:58:02.032: INFO: 42 pods has nil DeletionTimestamp
Aug 22 04:58:02.032: INFO: 
Aug 22 04:58:02.749: INFO: 32 pods remaining
Aug 22 04:58:02.749: INFO: 32 pods has nil DeletionTimestamp
Aug 22 04:58:02.749: INFO: 
Aug 22 04:58:03.872: INFO: 22 pods remaining
Aug 22 04:58:03.872: INFO: 18 pods has nil DeletionTimestamp
Aug 22 04:58:03.872: INFO: 
STEP: Gathering metrics 08/22/23 04:58:04.949
W0822 04:58:04.959024      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Aug 22 04:58:04.959: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 22 04:58:04.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3585" for this suite. 08/22/23 04:58:04.962
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":198,"skipped":3729,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.595 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:57:52.373
    Aug 22 04:57:52.373: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename gc 08/22/23 04:57:52.373
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:57:52.683
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:57:52.688
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 08/22/23 04:57:52.697
    STEP: delete the rc 08/22/23 04:57:57.73
    STEP: wait for the rc to be deleted 08/22/23 04:57:57.742
    Aug 22 04:57:58.764: INFO: 80 pods remaining
    Aug 22 04:57:58.764: INFO: 80 pods has nil DeletionTimestamp
    Aug 22 04:57:58.764: INFO: 
    Aug 22 04:57:59.857: INFO: 72 pods remaining
    Aug 22 04:57:59.857: INFO: 72 pods has nil DeletionTimestamp
    Aug 22 04:57:59.857: INFO: 
    Aug 22 04:58:00.979: INFO: 60 pods remaining
    Aug 22 04:58:00.979: INFO: 57 pods has nil DeletionTimestamp
    Aug 22 04:58:00.979: INFO: 
    Aug 22 04:58:02.032: INFO: 42 pods remaining
    Aug 22 04:58:02.032: INFO: 42 pods has nil DeletionTimestamp
    Aug 22 04:58:02.032: INFO: 
    Aug 22 04:58:02.749: INFO: 32 pods remaining
    Aug 22 04:58:02.749: INFO: 32 pods has nil DeletionTimestamp
    Aug 22 04:58:02.749: INFO: 
    Aug 22 04:58:03.872: INFO: 22 pods remaining
    Aug 22 04:58:03.872: INFO: 18 pods has nil DeletionTimestamp
    Aug 22 04:58:03.872: INFO: 
    STEP: Gathering metrics 08/22/23 04:58:04.949
    W0822 04:58:04.959024      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Aug 22 04:58:04.959: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 22 04:58:04.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-3585" for this suite. 08/22/23 04:58:04.962
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:58:04.97
Aug 22 04:58:04.970: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 04:58:04.971
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:04.985
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:04.989
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-8003 08/22/23 04:58:04.993
STEP: creating replication controller nodeport-test in namespace services-8003 08/22/23 04:58:05.034
I0822 04:58:05.050262      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-8003, replica count: 2
I0822 04:58:08.101239      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 04:58:11.101470      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 04:58:14.102118      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 22 04:58:14.102: INFO: Creating new exec pod
Aug 22 04:58:14.165: INFO: Waiting up to 5m0s for pod "execpodmr5sq" in namespace "services-8003" to be "running"
Aug 22 04:58:14.172: INFO: Pod "execpodmr5sq": Phase="Pending", Reason="", readiness=false. Elapsed: 6.493963ms
Aug 22 04:58:16.175: INFO: Pod "execpodmr5sq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009886455s
Aug 22 04:58:18.176: INFO: Pod "execpodmr5sq": Phase="Running", Reason="", readiness=true. Elapsed: 4.010591235s
Aug 22 04:58:18.176: INFO: Pod "execpodmr5sq" satisfied condition "running"
Aug 22 04:58:19.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8003 exec execpodmr5sq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Aug 22 04:58:19.322: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Aug 22 04:58:19.322: INFO: stdout: ""
Aug 22 04:58:20.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8003 exec execpodmr5sq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Aug 22 04:58:20.648: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Aug 22 04:58:20.648: INFO: stdout: "nodeport-test-8rsrq"
Aug 22 04:58:20.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8003 exec execpodmr5sq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.174.45 80'
Aug 22 04:58:20.771: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.174.45 80\nConnection to 10.254.174.45 80 port [tcp/http] succeeded!\n"
Aug 22 04:58:20.771: INFO: stdout: "nodeport-test-nsm2d"
Aug 22 04:58:20.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8003 exec execpodmr5sq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.97 31872'
Aug 22 04:58:20.895: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.0.97 31872\nConnection to 10.0.0.97 31872 port [tcp/*] succeeded!\n"
Aug 22 04:58:20.895: INFO: stdout: "nodeport-test-nsm2d"
Aug 22 04:58:20.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8003 exec execpodmr5sq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.130 31872'
Aug 22 04:58:21.020: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.0.130 31872\nConnection to 10.0.0.130 31872 port [tcp/*] succeeded!\n"
Aug 22 04:58:21.020: INFO: stdout: "nodeport-test-nsm2d"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 04:58:21.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8003" for this suite. 08/22/23 04:58:21.024
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":199,"skipped":3746,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.161 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:58:04.97
    Aug 22 04:58:04.970: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 04:58:04.971
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:04.985
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:04.989
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-8003 08/22/23 04:58:04.993
    STEP: creating replication controller nodeport-test in namespace services-8003 08/22/23 04:58:05.034
    I0822 04:58:05.050262      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-8003, replica count: 2
    I0822 04:58:08.101239      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0822 04:58:11.101470      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0822 04:58:14.102118      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 22 04:58:14.102: INFO: Creating new exec pod
    Aug 22 04:58:14.165: INFO: Waiting up to 5m0s for pod "execpodmr5sq" in namespace "services-8003" to be "running"
    Aug 22 04:58:14.172: INFO: Pod "execpodmr5sq": Phase="Pending", Reason="", readiness=false. Elapsed: 6.493963ms
    Aug 22 04:58:16.175: INFO: Pod "execpodmr5sq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009886455s
    Aug 22 04:58:18.176: INFO: Pod "execpodmr5sq": Phase="Running", Reason="", readiness=true. Elapsed: 4.010591235s
    Aug 22 04:58:18.176: INFO: Pod "execpodmr5sq" satisfied condition "running"
    Aug 22 04:58:19.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8003 exec execpodmr5sq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Aug 22 04:58:19.322: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Aug 22 04:58:19.322: INFO: stdout: ""
    Aug 22 04:58:20.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8003 exec execpodmr5sq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Aug 22 04:58:20.648: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Aug 22 04:58:20.648: INFO: stdout: "nodeport-test-8rsrq"
    Aug 22 04:58:20.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8003 exec execpodmr5sq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.174.45 80'
    Aug 22 04:58:20.771: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.174.45 80\nConnection to 10.254.174.45 80 port [tcp/http] succeeded!\n"
    Aug 22 04:58:20.771: INFO: stdout: "nodeport-test-nsm2d"
    Aug 22 04:58:20.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8003 exec execpodmr5sq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.97 31872'
    Aug 22 04:58:20.895: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.0.97 31872\nConnection to 10.0.0.97 31872 port [tcp/*] succeeded!\n"
    Aug 22 04:58:20.895: INFO: stdout: "nodeport-test-nsm2d"
    Aug 22 04:58:20.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8003 exec execpodmr5sq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.130 31872'
    Aug 22 04:58:21.020: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.0.130 31872\nConnection to 10.0.0.130 31872 port [tcp/*] succeeded!\n"
    Aug 22 04:58:21.020: INFO: stdout: "nodeport-test-nsm2d"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 04:58:21.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8003" for this suite. 08/22/23 04:58:21.024
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:58:21.132
Aug 22 04:58:21.132: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 04:58:21.133
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:21.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:21.273
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 08/22/23 04:58:21.276
Aug 22 04:58:21.284: INFO: Waiting up to 5m0s for pod "pod-d06c242f-8be3-4b3c-af26-383c66b83e18" in namespace "emptydir-6956" to be "Succeeded or Failed"
Aug 22 04:58:21.287: INFO: Pod "pod-d06c242f-8be3-4b3c-af26-383c66b83e18": Phase="Pending", Reason="", readiness=false. Elapsed: 3.31495ms
Aug 22 04:58:23.290: INFO: Pod "pod-d06c242f-8be3-4b3c-af26-383c66b83e18": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006544977s
Aug 22 04:58:25.291: INFO: Pod "pod-d06c242f-8be3-4b3c-af26-383c66b83e18": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007671199s
Aug 22 04:58:27.291: INFO: Pod "pod-d06c242f-8be3-4b3c-af26-383c66b83e18": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007675144s
Aug 22 04:58:29.296: INFO: Pod "pod-d06c242f-8be3-4b3c-af26-383c66b83e18": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.01204057s
STEP: Saw pod success 08/22/23 04:58:29.296
Aug 22 04:58:29.296: INFO: Pod "pod-d06c242f-8be3-4b3c-af26-383c66b83e18" satisfied condition "Succeeded or Failed"
Aug 22 04:58:29.299: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-d06c242f-8be3-4b3c-af26-383c66b83e18 container test-container: <nil>
STEP: delete the pod 08/22/23 04:58:29.337
Aug 22 04:58:29.353: INFO: Waiting for pod pod-d06c242f-8be3-4b3c-af26-383c66b83e18 to disappear
Aug 22 04:58:29.356: INFO: Pod pod-d06c242f-8be3-4b3c-af26-383c66b83e18 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 04:58:29.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6956" for this suite. 08/22/23 04:58:29.36
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":200,"skipped":3746,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.234 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:58:21.132
    Aug 22 04:58:21.132: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 04:58:21.133
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:21.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:21.273
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 08/22/23 04:58:21.276
    Aug 22 04:58:21.284: INFO: Waiting up to 5m0s for pod "pod-d06c242f-8be3-4b3c-af26-383c66b83e18" in namespace "emptydir-6956" to be "Succeeded or Failed"
    Aug 22 04:58:21.287: INFO: Pod "pod-d06c242f-8be3-4b3c-af26-383c66b83e18": Phase="Pending", Reason="", readiness=false. Elapsed: 3.31495ms
    Aug 22 04:58:23.290: INFO: Pod "pod-d06c242f-8be3-4b3c-af26-383c66b83e18": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006544977s
    Aug 22 04:58:25.291: INFO: Pod "pod-d06c242f-8be3-4b3c-af26-383c66b83e18": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007671199s
    Aug 22 04:58:27.291: INFO: Pod "pod-d06c242f-8be3-4b3c-af26-383c66b83e18": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007675144s
    Aug 22 04:58:29.296: INFO: Pod "pod-d06c242f-8be3-4b3c-af26-383c66b83e18": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.01204057s
    STEP: Saw pod success 08/22/23 04:58:29.296
    Aug 22 04:58:29.296: INFO: Pod "pod-d06c242f-8be3-4b3c-af26-383c66b83e18" satisfied condition "Succeeded or Failed"
    Aug 22 04:58:29.299: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-d06c242f-8be3-4b3c-af26-383c66b83e18 container test-container: <nil>
    STEP: delete the pod 08/22/23 04:58:29.337
    Aug 22 04:58:29.353: INFO: Waiting for pod pod-d06c242f-8be3-4b3c-af26-383c66b83e18 to disappear
    Aug 22 04:58:29.356: INFO: Pod pod-d06c242f-8be3-4b3c-af26-383c66b83e18 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 04:58:29.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6956" for this suite. 08/22/23 04:58:29.36
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:58:29.367
Aug 22 04:58:29.367: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 04:58:29.367
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:29.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:29.388
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Aug 22 04:58:29.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3073 create -f -'
Aug 22 04:58:30.163: INFO: stderr: ""
Aug 22 04:58:30.163: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Aug 22 04:58:30.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3073 create -f -'
Aug 22 04:58:30.969: INFO: stderr: ""
Aug 22 04:58:30.969: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 08/22/23 04:58:30.969
Aug 22 04:58:31.974: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 04:58:31.974: INFO: Found 0 / 1
Aug 22 04:58:32.974: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 04:58:32.974: INFO: Found 0 / 1
Aug 22 04:58:33.973: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 04:58:33.973: INFO: Found 1 / 1
Aug 22 04:58:33.973: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 22 04:58:33.976: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 04:58:33.976: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 22 04:58:33.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3073 describe pod agnhost-primary-9hkkn'
Aug 22 04:58:34.051: INFO: stderr: ""
Aug 22 04:58:34.051: INFO: stdout: "Name:             agnhost-primary-9hkkn\nNamespace:        kubectl-3073\nPriority:         0\nService Account:  default\nNode:             jake-melb-gmyyva4zrlsz-node-2/10.0.0.130\nStart Time:       Tue, 22 Aug 2023 04:58:30 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.100.4.225\nIPs:\n  IP:           10.100.4.225\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://7bcbc7b7ac903fa2b99585c4354dbc472acaa0a922dd99576f94096c3db255ec\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 22 Aug 2023 04:58:32 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-7c5dc (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-7c5dc:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-3073/agnhost-primary-9hkkn to jake-melb-gmyyva4zrlsz-node-2\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
Aug 22 04:58:34.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3073 describe rc agnhost-primary'
Aug 22 04:58:34.130: INFO: stderr: ""
Aug 22 04:58:34.130: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-3073\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: agnhost-primary-9hkkn\n"
Aug 22 04:58:34.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3073 describe service agnhost-primary'
Aug 22 04:58:34.212: INFO: stderr: ""
Aug 22 04:58:34.213: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-3073\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.254.169.79\nIPs:               10.254.169.79\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.100.4.225:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 22 04:58:34.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3073 describe node jake-melb-gmyyva4zrlsz-master-0'
Aug 22 04:58:34.319: INFO: stderr: ""
Aug 22 04:58:34.319: INFO: stdout: "Name:               jake-melb-gmyyva4zrlsz-master-0\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=uom.general.2c8g\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=Melbourne\n                    failure-domain.beta.kubernetes.io/zone=melbourne-qh2-uom\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=jake-melb-gmyyva4zrlsz-master-0\n                    kubernetes.io/os=linux\n                    magnum.openstack.org/nodegroup=default-master\n                    magnum.openstack.org/role=master\n                    node-role.kubernetes.io/master=\n                    node.kubernetes.io/instance-type=uom.general.2c8g\n                    topology.cinder.csi.openstack.org/zone=melbourne-qh2-uom\n                    topology.kubernetes.io/region=Melbourne\n                    topology.kubernetes.io/zone=melbourne-qh2-uom\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"cinder.csi.openstack.org\":\"326a3f56-5c26-4ee6-af51-9543316a5055\"}\n                    flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"da:a9:3b:75:c3:26\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.0.0.171\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 17 Aug 2023 07:04:32 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  jake-melb-gmyyva4zrlsz-master-0\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 22 Aug 2023 04:58:29 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Thu, 17 Aug 2023 07:05:12 +0000   Thu, 17 Aug 2023 07:05:12 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Tue, 22 Aug 2023 04:57:09 +0000   Thu, 17 Aug 2023 07:04:28 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 22 Aug 2023 04:57:09 +0000   Thu, 17 Aug 2023 07:04:28 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 22 Aug 2023 04:57:09 +0000   Thu, 17 Aug 2023 07:04:28 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 22 Aug 2023 04:57:09 +0000   Thu, 17 Aug 2023 07:05:23 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.0.171\n  Hostname:    jake-melb-gmyyva4zrlsz-master-0\nCapacity:\n  cpu:                2\n  ephemeral-storage:  30866412Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8122492Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  28446485253\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8020092Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 326a3f565c264ee6af519543316a5055\n  System UUID:                326a3f56-5c26-4ee6-af51-9543316a5055\n  Boot ID:                    c35db8c4-71b9-4f84-a905-6cccff504b2e\n  Kernel Version:             6.1.18-200.fc37.x86_64\n  OS Image:                   Fedora CoreOS 37.20230322.3.0\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.20\n  Kubelet Version:            v1.25.9\n  Kube-Proxy Version:         v1.25.9\nPodCIDR:                      10.100.0.0/24\nPodCIDRs:                     10.100.0.0/24\nProviderID:                   openstack:///326a3f56-5c26-4ee6-af51-9543316a5055\nNon-terminated Pods:          (6 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-64b748cb9-jrhg6                                    100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     4d21h\n  kube-system                 csi-cinder-nodeplugin-bx9bt                                20m (1%)      0 (0%)      0 (0%)           0 (0%)         4d21h\n  kube-system                 k8s-keystone-auth-dq66q                                    200m (10%)    0 (0%)      0 (0%)           0 (0%)         4d21h\n  kube-system                 kube-flannel-ds-p7v42                                      100m (5%)     100m (5%)   50Mi (0%)        50Mi (0%)      4d21h\n  kube-system                 openstack-cloud-controller-manager-kx65h                   200m (10%)    0 (0%)      0 (0%)           0 (0%)         4d21h\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-78qxw    0 (0%)        0 (0%)      0 (0%)           0 (0%)         68m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                620m (31%)  100m (5%)\n  memory             120Mi (1%)  220Mi (2%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
Aug 22 04:58:34.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3073 describe namespace kubectl-3073'
Aug 22 04:58:34.405: INFO: stderr: ""
Aug 22 04:58:34.405: INFO: stdout: "Name:         kubectl-3073\nLabels:       e2e-framework=kubectl\n              e2e-run=446d56d2-2673-4aa3-a77e-727529e19729\n              kubernetes.io/metadata.name=kubectl-3073\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 04:58:34.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3073" for this suite. 08/22/23 04:58:34.41
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":201,"skipped":3766,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.051 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:58:29.367
    Aug 22 04:58:29.367: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 04:58:29.367
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:29.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:29.388
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Aug 22 04:58:29.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3073 create -f -'
    Aug 22 04:58:30.163: INFO: stderr: ""
    Aug 22 04:58:30.163: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Aug 22 04:58:30.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3073 create -f -'
    Aug 22 04:58:30.969: INFO: stderr: ""
    Aug 22 04:58:30.969: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 08/22/23 04:58:30.969
    Aug 22 04:58:31.974: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 04:58:31.974: INFO: Found 0 / 1
    Aug 22 04:58:32.974: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 04:58:32.974: INFO: Found 0 / 1
    Aug 22 04:58:33.973: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 04:58:33.973: INFO: Found 1 / 1
    Aug 22 04:58:33.973: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Aug 22 04:58:33.976: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 04:58:33.976: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Aug 22 04:58:33.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3073 describe pod agnhost-primary-9hkkn'
    Aug 22 04:58:34.051: INFO: stderr: ""
    Aug 22 04:58:34.051: INFO: stdout: "Name:             agnhost-primary-9hkkn\nNamespace:        kubectl-3073\nPriority:         0\nService Account:  default\nNode:             jake-melb-gmyyva4zrlsz-node-2/10.0.0.130\nStart Time:       Tue, 22 Aug 2023 04:58:30 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.100.4.225\nIPs:\n  IP:           10.100.4.225\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://7bcbc7b7ac903fa2b99585c4354dbc472acaa0a922dd99576f94096c3db255ec\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 22 Aug 2023 04:58:32 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-7c5dc (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-7c5dc:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-3073/agnhost-primary-9hkkn to jake-melb-gmyyva4zrlsz-node-2\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
    Aug 22 04:58:34.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3073 describe rc agnhost-primary'
    Aug 22 04:58:34.130: INFO: stderr: ""
    Aug 22 04:58:34.130: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-3073\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: agnhost-primary-9hkkn\n"
    Aug 22 04:58:34.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3073 describe service agnhost-primary'
    Aug 22 04:58:34.212: INFO: stderr: ""
    Aug 22 04:58:34.213: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-3073\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.254.169.79\nIPs:               10.254.169.79\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.100.4.225:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Aug 22 04:58:34.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3073 describe node jake-melb-gmyyva4zrlsz-master-0'
    Aug 22 04:58:34.319: INFO: stderr: ""
    Aug 22 04:58:34.319: INFO: stdout: "Name:               jake-melb-gmyyva4zrlsz-master-0\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=uom.general.2c8g\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=Melbourne\n                    failure-domain.beta.kubernetes.io/zone=melbourne-qh2-uom\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=jake-melb-gmyyva4zrlsz-master-0\n                    kubernetes.io/os=linux\n                    magnum.openstack.org/nodegroup=default-master\n                    magnum.openstack.org/role=master\n                    node-role.kubernetes.io/master=\n                    node.kubernetes.io/instance-type=uom.general.2c8g\n                    topology.cinder.csi.openstack.org/zone=melbourne-qh2-uom\n                    topology.kubernetes.io/region=Melbourne\n                    topology.kubernetes.io/zone=melbourne-qh2-uom\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"cinder.csi.openstack.org\":\"326a3f56-5c26-4ee6-af51-9543316a5055\"}\n                    flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"da:a9:3b:75:c3:26\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.0.0.171\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 17 Aug 2023 07:04:32 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  jake-melb-gmyyva4zrlsz-master-0\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 22 Aug 2023 04:58:29 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Thu, 17 Aug 2023 07:05:12 +0000   Thu, 17 Aug 2023 07:05:12 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Tue, 22 Aug 2023 04:57:09 +0000   Thu, 17 Aug 2023 07:04:28 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 22 Aug 2023 04:57:09 +0000   Thu, 17 Aug 2023 07:04:28 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 22 Aug 2023 04:57:09 +0000   Thu, 17 Aug 2023 07:04:28 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 22 Aug 2023 04:57:09 +0000   Thu, 17 Aug 2023 07:05:23 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.0.171\n  Hostname:    jake-melb-gmyyva4zrlsz-master-0\nCapacity:\n  cpu:                2\n  ephemeral-storage:  30866412Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8122492Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  28446485253\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8020092Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 326a3f565c264ee6af519543316a5055\n  System UUID:                326a3f56-5c26-4ee6-af51-9543316a5055\n  Boot ID:                    c35db8c4-71b9-4f84-a905-6cccff504b2e\n  Kernel Version:             6.1.18-200.fc37.x86_64\n  OS Image:                   Fedora CoreOS 37.20230322.3.0\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.20\n  Kubelet Version:            v1.25.9\n  Kube-Proxy Version:         v1.25.9\nPodCIDR:                      10.100.0.0/24\nPodCIDRs:                     10.100.0.0/24\nProviderID:                   openstack:///326a3f56-5c26-4ee6-af51-9543316a5055\nNon-terminated Pods:          (6 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-64b748cb9-jrhg6                                    100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     4d21h\n  kube-system                 csi-cinder-nodeplugin-bx9bt                                20m (1%)      0 (0%)      0 (0%)           0 (0%)         4d21h\n  kube-system                 k8s-keystone-auth-dq66q                                    200m (10%)    0 (0%)      0 (0%)           0 (0%)         4d21h\n  kube-system                 kube-flannel-ds-p7v42                                      100m (5%)     100m (5%)   50Mi (0%)        50Mi (0%)      4d21h\n  kube-system                 openstack-cloud-controller-manager-kx65h                   200m (10%)    0 (0%)      0 (0%)           0 (0%)         4d21h\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-78qxw    0 (0%)        0 (0%)      0 (0%)           0 (0%)         68m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                620m (31%)  100m (5%)\n  memory             120Mi (1%)  220Mi (2%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
    Aug 22 04:58:34.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3073 describe namespace kubectl-3073'
    Aug 22 04:58:34.405: INFO: stderr: ""
    Aug 22 04:58:34.405: INFO: stdout: "Name:         kubectl-3073\nLabels:       e2e-framework=kubectl\n              e2e-run=446d56d2-2673-4aa3-a77e-727529e19729\n              kubernetes.io/metadata.name=kubectl-3073\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 04:58:34.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3073" for this suite. 08/22/23 04:58:34.41
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:58:34.419
Aug 22 04:58:34.419: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 04:58:34.42
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:34.449
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:34.452
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Aug 22 04:58:34.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7750 version'
Aug 22 04:58:34.512: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Aug 22 04:58:34.512: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9\", GitCommit:\"a1a87a0a2bcd605820920c6b0e618a8ab7d117d4\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:16:51Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9\", GitCommit:\"a1a87a0a2bcd605820920c6b0e618a8ab7d117d4\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:08:36Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 04:58:34.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7750" for this suite. 08/22/23 04:58:34.516
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":202,"skipped":3767,"failed":0}
------------------------------
â€¢ [0.103 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:58:34.419
    Aug 22 04:58:34.419: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 04:58:34.42
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:34.449
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:34.452
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Aug 22 04:58:34.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-7750 version'
    Aug 22 04:58:34.512: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Aug 22 04:58:34.512: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9\", GitCommit:\"a1a87a0a2bcd605820920c6b0e618a8ab7d117d4\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:16:51Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9\", GitCommit:\"a1a87a0a2bcd605820920c6b0e618a8ab7d117d4\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:08:36Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 04:58:34.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7750" for this suite. 08/22/23 04:58:34.516
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:58:34.522
Aug 22 04:58:34.523: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 04:58:34.523
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:34.54
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:34.543
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394
STEP: creating a Service 08/22/23 04:58:34.624
STEP: watching for the Service to be added 08/22/23 04:58:34.644
Aug 22 04:58:34.647: INFO: Found Service test-service-g94bv in namespace services-9969 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Aug 22 04:58:34.647: INFO: Service test-service-g94bv created
STEP: Getting /status 08/22/23 04:58:34.647
Aug 22 04:58:34.656: INFO: Service test-service-g94bv has LoadBalancer: {[]}
STEP: patching the ServiceStatus 08/22/23 04:58:34.656
STEP: watching for the Service to be patched 08/22/23 04:58:34.664
Aug 22 04:58:34.666: INFO: observed Service test-service-g94bv in namespace services-9969 with annotations: map[] & LoadBalancer: {[]}
Aug 22 04:58:34.666: INFO: Found Service test-service-g94bv in namespace services-9969 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Aug 22 04:58:34.666: INFO: Service test-service-g94bv has service status patched
STEP: updating the ServiceStatus 08/22/23 04:58:34.666
Aug 22 04:58:34.676: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 08/22/23 04:58:34.676
Aug 22 04:58:34.678: INFO: Observed Service test-service-g94bv in namespace services-9969 with annotations: map[] & Conditions: {[]}
Aug 22 04:58:34.678: INFO: Observed event: &Service{ObjectMeta:{test-service-g94bv  services-9969  a5ddda9b-200e-4b16-a79c-86e612c6a0f3 1272206 0 2023-08-22 04:58:34 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-08-22 04:58:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-08-22 04:58:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.254.218.92,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.254.218.92],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Aug 22 04:58:34.678: INFO: Found Service test-service-g94bv in namespace services-9969 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 22 04:58:34.678: INFO: Service test-service-g94bv has service status updated
STEP: patching the service 08/22/23 04:58:34.678
STEP: watching for the Service to be patched 08/22/23 04:58:34.696
Aug 22 04:58:34.697: INFO: observed Service test-service-g94bv in namespace services-9969 with labels: map[test-service-static:true]
Aug 22 04:58:34.697: INFO: observed Service test-service-g94bv in namespace services-9969 with labels: map[test-service-static:true]
Aug 22 04:58:34.697: INFO: observed Service test-service-g94bv in namespace services-9969 with labels: map[test-service-static:true]
Aug 22 04:58:34.697: INFO: Found Service test-service-g94bv in namespace services-9969 with labels: map[test-service:patched test-service-static:true]
Aug 22 04:58:34.697: INFO: Service test-service-g94bv patched
STEP: deleting the service 08/22/23 04:58:34.697
STEP: watching for the Service to be deleted 08/22/23 04:58:34.727
Aug 22 04:58:34.728: INFO: Observed event: ADDED
Aug 22 04:58:34.728: INFO: Observed event: MODIFIED
Aug 22 04:58:34.729: INFO: Observed event: MODIFIED
Aug 22 04:58:34.729: INFO: Observed event: MODIFIED
Aug 22 04:58:34.729: INFO: Found Service test-service-g94bv in namespace services-9969 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Aug 22 04:58:34.729: INFO: Service test-service-g94bv deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 04:58:34.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9969" for this suite. 08/22/23 04:58:34.734
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":203,"skipped":3776,"failed":0}
------------------------------
â€¢ [0.222 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:58:34.522
    Aug 22 04:58:34.523: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 04:58:34.523
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:34.54
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:34.543
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3394
    STEP: creating a Service 08/22/23 04:58:34.624
    STEP: watching for the Service to be added 08/22/23 04:58:34.644
    Aug 22 04:58:34.647: INFO: Found Service test-service-g94bv in namespace services-9969 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Aug 22 04:58:34.647: INFO: Service test-service-g94bv created
    STEP: Getting /status 08/22/23 04:58:34.647
    Aug 22 04:58:34.656: INFO: Service test-service-g94bv has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 08/22/23 04:58:34.656
    STEP: watching for the Service to be patched 08/22/23 04:58:34.664
    Aug 22 04:58:34.666: INFO: observed Service test-service-g94bv in namespace services-9969 with annotations: map[] & LoadBalancer: {[]}
    Aug 22 04:58:34.666: INFO: Found Service test-service-g94bv in namespace services-9969 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Aug 22 04:58:34.666: INFO: Service test-service-g94bv has service status patched
    STEP: updating the ServiceStatus 08/22/23 04:58:34.666
    Aug 22 04:58:34.676: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 08/22/23 04:58:34.676
    Aug 22 04:58:34.678: INFO: Observed Service test-service-g94bv in namespace services-9969 with annotations: map[] & Conditions: {[]}
    Aug 22 04:58:34.678: INFO: Observed event: &Service{ObjectMeta:{test-service-g94bv  services-9969  a5ddda9b-200e-4b16-a79c-86e612c6a0f3 1272206 0 2023-08-22 04:58:34 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-08-22 04:58:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-08-22 04:58:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.254.218.92,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.254.218.92],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Aug 22 04:58:34.678: INFO: Found Service test-service-g94bv in namespace services-9969 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Aug 22 04:58:34.678: INFO: Service test-service-g94bv has service status updated
    STEP: patching the service 08/22/23 04:58:34.678
    STEP: watching for the Service to be patched 08/22/23 04:58:34.696
    Aug 22 04:58:34.697: INFO: observed Service test-service-g94bv in namespace services-9969 with labels: map[test-service-static:true]
    Aug 22 04:58:34.697: INFO: observed Service test-service-g94bv in namespace services-9969 with labels: map[test-service-static:true]
    Aug 22 04:58:34.697: INFO: observed Service test-service-g94bv in namespace services-9969 with labels: map[test-service-static:true]
    Aug 22 04:58:34.697: INFO: Found Service test-service-g94bv in namespace services-9969 with labels: map[test-service:patched test-service-static:true]
    Aug 22 04:58:34.697: INFO: Service test-service-g94bv patched
    STEP: deleting the service 08/22/23 04:58:34.697
    STEP: watching for the Service to be deleted 08/22/23 04:58:34.727
    Aug 22 04:58:34.728: INFO: Observed event: ADDED
    Aug 22 04:58:34.728: INFO: Observed event: MODIFIED
    Aug 22 04:58:34.729: INFO: Observed event: MODIFIED
    Aug 22 04:58:34.729: INFO: Observed event: MODIFIED
    Aug 22 04:58:34.729: INFO: Found Service test-service-g94bv in namespace services-9969 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Aug 22 04:58:34.729: INFO: Service test-service-g94bv deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 04:58:34.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9969" for this suite. 08/22/23 04:58:34.734
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:58:34.744
Aug 22 04:58:34.745: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 04:58:34.745
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:34.763
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:34.766
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 04:58:34.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1683" for this suite. 08/22/23 04:58:34.81
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":204,"skipped":3780,"failed":0}
------------------------------
â€¢ [0.073 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:58:34.744
    Aug 22 04:58:34.745: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 04:58:34.745
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:34.763
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:34.766
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 04:58:34.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1683" for this suite. 08/22/23 04:58:34.81
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:58:34.822
Aug 22 04:58:34.822: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 04:58:34.823
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:34.845
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:34.847
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 04:58:34.863
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 04:58:35.139
STEP: Deploying the webhook pod 08/22/23 04:58:35.148
STEP: Wait for the deployment to be ready 08/22/23 04:58:35.316
Aug 22 04:58:35.333: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 04:58:37.346: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 58, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 58, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 58, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 58, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 04:58:39.353
STEP: Verifying the service has paired with the endpoint 08/22/23 04:58:39.366
Aug 22 04:58:40.367: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 08/22/23 04:58:40.371
STEP: Creating a custom resource definition that should be denied by the webhook 08/22/23 04:58:40.617
Aug 22 04:58:40.617: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:58:40.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6780" for this suite. 08/22/23 04:58:40.651
STEP: Destroying namespace "webhook-6780-markers" for this suite. 08/22/23 04:58:40.657
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":205,"skipped":3843,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.885 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:58:34.822
    Aug 22 04:58:34.822: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 04:58:34.823
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:34.845
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:34.847
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 04:58:34.863
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 04:58:35.139
    STEP: Deploying the webhook pod 08/22/23 04:58:35.148
    STEP: Wait for the deployment to be ready 08/22/23 04:58:35.316
    Aug 22 04:58:35.333: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 04:58:37.346: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 58, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 58, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 58, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 58, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 04:58:39.353
    STEP: Verifying the service has paired with the endpoint 08/22/23 04:58:39.366
    Aug 22 04:58:40.367: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 08/22/23 04:58:40.371
    STEP: Creating a custom resource definition that should be denied by the webhook 08/22/23 04:58:40.617
    Aug 22 04:58:40.617: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:58:40.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6780" for this suite. 08/22/23 04:58:40.651
    STEP: Destroying namespace "webhook-6780-markers" for this suite. 08/22/23 04:58:40.657
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:58:40.708
Aug 22 04:58:40.708: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 04:58:40.708
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:40.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:40.76
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 04:58:40.779
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 04:58:41.081
STEP: Deploying the webhook pod 08/22/23 04:58:41.104
STEP: Wait for the deployment to be ready 08/22/23 04:58:41.118
Aug 22 04:58:41.128: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 04:58:43.138: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 58, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 58, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 58, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 58, 41, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 04:58:45.142
STEP: Verifying the service has paired with the endpoint 08/22/23 04:58:45.173
Aug 22 04:58:46.173: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Aug 22 04:58:46.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7150-crds.webhook.example.com via the AdmissionRegistration API 08/22/23 04:58:46.886
STEP: Creating a custom resource while v1 is storage version 08/22/23 04:58:46.903
STEP: Patching Custom Resource Definition to set v2 as storage 08/22/23 04:58:49.016
STEP: Patching the custom resource while v2 is storage version 08/22/23 04:58:49.035
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 04:58:49.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-661" for this suite. 08/22/23 04:58:49.725
STEP: Destroying namespace "webhook-661-markers" for this suite. 08/22/23 04:58:49.733
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":206,"skipped":3845,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.155 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:58:40.708
    Aug 22 04:58:40.708: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 04:58:40.708
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:40.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:40.76
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 04:58:40.779
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 04:58:41.081
    STEP: Deploying the webhook pod 08/22/23 04:58:41.104
    STEP: Wait for the deployment to be ready 08/22/23 04:58:41.118
    Aug 22 04:58:41.128: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 04:58:43.138: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 58, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 58, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 58, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 58, 41, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 04:58:45.142
    STEP: Verifying the service has paired with the endpoint 08/22/23 04:58:45.173
    Aug 22 04:58:46.173: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Aug 22 04:58:46.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7150-crds.webhook.example.com via the AdmissionRegistration API 08/22/23 04:58:46.886
    STEP: Creating a custom resource while v1 is storage version 08/22/23 04:58:46.903
    STEP: Patching Custom Resource Definition to set v2 as storage 08/22/23 04:58:49.016
    STEP: Patching the custom resource while v2 is storage version 08/22/23 04:58:49.035
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 04:58:49.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-661" for this suite. 08/22/23 04:58:49.725
    STEP: Destroying namespace "webhook-661-markers" for this suite. 08/22/23 04:58:49.733
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:58:49.864
Aug 22 04:58:49.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 04:58:49.864
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:50.231
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:50.234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 08/22/23 04:58:50.241
Aug 22 04:58:50.258: INFO: Waiting up to 5m0s for pod "annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77" in namespace "projected-3773" to be "running and ready"
Aug 22 04:58:50.262: INFO: Pod "annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77": Phase="Pending", Reason="", readiness=false. Elapsed: 4.461419ms
Aug 22 04:58:50.262: INFO: The phase of Pod annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:58:52.268: INFO: Pod "annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009681732s
Aug 22 04:58:52.268: INFO: The phase of Pod annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 04:58:54.471: INFO: Pod "annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77": Phase="Running", Reason="", readiness=true. Elapsed: 4.21357831s
Aug 22 04:58:54.472: INFO: The phase of Pod annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77 is Running (Ready = true)
Aug 22 04:58:54.472: INFO: Pod "annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77" satisfied condition "running and ready"
Aug 22 04:58:55.030: INFO: Successfully updated pod "annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 22 04:58:57.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3773" for this suite. 08/22/23 04:58:57.046
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":207,"skipped":3854,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.207 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:58:49.864
    Aug 22 04:58:49.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 04:58:49.864
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:50.231
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:50.234
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 08/22/23 04:58:50.241
    Aug 22 04:58:50.258: INFO: Waiting up to 5m0s for pod "annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77" in namespace "projected-3773" to be "running and ready"
    Aug 22 04:58:50.262: INFO: Pod "annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77": Phase="Pending", Reason="", readiness=false. Elapsed: 4.461419ms
    Aug 22 04:58:50.262: INFO: The phase of Pod annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:58:52.268: INFO: Pod "annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009681732s
    Aug 22 04:58:52.268: INFO: The phase of Pod annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 04:58:54.471: INFO: Pod "annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77": Phase="Running", Reason="", readiness=true. Elapsed: 4.21357831s
    Aug 22 04:58:54.472: INFO: The phase of Pod annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77 is Running (Ready = true)
    Aug 22 04:58:54.472: INFO: Pod "annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77" satisfied condition "running and ready"
    Aug 22 04:58:55.030: INFO: Successfully updated pod "annotationupdatefe4a18bb-c942-474b-a6cf-5aa657d12f77"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 22 04:58:57.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3773" for this suite. 08/22/23 04:58:57.046
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:58:57.072
Aug 22 04:58:57.072: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 04:58:57.073
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:57.132
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:57.134
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 08/22/23 04:58:57.138
Aug 22 04:58:57.145: INFO: Waiting up to 5m0s for pod "downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44" in namespace "downward-api-7357" to be "Succeeded or Failed"
Aug 22 04:58:57.149: INFO: Pod "downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44": Phase="Pending", Reason="", readiness=false. Elapsed: 3.865643ms
Aug 22 04:58:59.153: INFO: Pod "downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007747803s
Aug 22 04:59:01.153: INFO: Pod "downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008064615s
Aug 22 04:59:03.152: INFO: Pod "downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006784682s
STEP: Saw pod success 08/22/23 04:59:03.152
Aug 22 04:59:03.153: INFO: Pod "downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44" satisfied condition "Succeeded or Failed"
Aug 22 04:59:03.155: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44 container dapi-container: <nil>
STEP: delete the pod 08/22/23 04:59:03.189
Aug 22 04:59:04.189: INFO: Waiting for pod downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44 to disappear
Aug 22 04:59:04.196: INFO: Pod downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 22 04:59:04.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7357" for this suite. 08/22/23 04:59:04.301
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":208,"skipped":3877,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.824 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:58:57.072
    Aug 22 04:58:57.072: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 04:58:57.073
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:58:57.132
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:58:57.134
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 08/22/23 04:58:57.138
    Aug 22 04:58:57.145: INFO: Waiting up to 5m0s for pod "downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44" in namespace "downward-api-7357" to be "Succeeded or Failed"
    Aug 22 04:58:57.149: INFO: Pod "downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44": Phase="Pending", Reason="", readiness=false. Elapsed: 3.865643ms
    Aug 22 04:58:59.153: INFO: Pod "downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007747803s
    Aug 22 04:59:01.153: INFO: Pod "downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008064615s
    Aug 22 04:59:03.152: INFO: Pod "downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006784682s
    STEP: Saw pod success 08/22/23 04:59:03.152
    Aug 22 04:59:03.153: INFO: Pod "downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44" satisfied condition "Succeeded or Failed"
    Aug 22 04:59:03.155: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44 container dapi-container: <nil>
    STEP: delete the pod 08/22/23 04:59:03.189
    Aug 22 04:59:04.189: INFO: Waiting for pod downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44 to disappear
    Aug 22 04:59:04.196: INFO: Pod downward-api-31cf6d1d-83f9-4b65-b7ee-9cb4ea5d3d44 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 22 04:59:04.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7357" for this suite. 08/22/23 04:59:04.301
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:59:04.898
Aug 22 04:59:04.898: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename job 08/22/23 04:59:04.898
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:59:04.919
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:59:04.923
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 08/22/23 04:59:04.926
STEP: Ensuring job reaches completions 08/22/23 04:59:04.932
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 22 04:59:18.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3097" for this suite. 08/22/23 04:59:18.94
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":209,"skipped":3901,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.077 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:59:04.898
    Aug 22 04:59:04.898: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename job 08/22/23 04:59:04.898
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:59:04.919
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:59:04.923
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 08/22/23 04:59:04.926
    STEP: Ensuring job reaches completions 08/22/23 04:59:04.932
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 22 04:59:18.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3097" for this suite. 08/22/23 04:59:18.94
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:59:18.977
Aug 22 04:59:18.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename namespaces 08/22/23 04:59:18.977
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:59:19.296
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:59:19.299
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 08/22/23 04:59:19.303
STEP: patching the Namespace 08/22/23 04:59:19.336
STEP: get the Namespace and ensuring it has the label 08/22/23 04:59:19.342
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Aug 22 04:59:19.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8134" for this suite. 08/22/23 04:59:19.348
STEP: Destroying namespace "nspatchtest-8b268522-6217-48d3-b086-48d0ea28d969-2829" for this suite. 08/22/23 04:59:19.354
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":210,"skipped":3935,"failed":0}
------------------------------
â€¢ [0.382 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:59:18.977
    Aug 22 04:59:18.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename namespaces 08/22/23 04:59:18.977
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:59:19.296
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:59:19.299
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 08/22/23 04:59:19.303
    STEP: patching the Namespace 08/22/23 04:59:19.336
    STEP: get the Namespace and ensuring it has the label 08/22/23 04:59:19.342
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 04:59:19.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-8134" for this suite. 08/22/23 04:59:19.348
    STEP: Destroying namespace "nspatchtest-8b268522-6217-48d3-b086-48d0ea28d969-2829" for this suite. 08/22/23 04:59:19.354
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:59:19.359
Aug 22 04:59:19.359: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 04:59:19.36
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:59:19.379
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:59:19.382
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 08/22/23 04:59:19.385
Aug 22 04:59:19.396: INFO: Waiting up to 5m0s for pod "downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c" in namespace "downward-api-5224" to be "Succeeded or Failed"
Aug 22 04:59:19.401: INFO: Pod "downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.52167ms
Aug 22 04:59:21.849: INFO: Pod "downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.453447664s
Aug 22 04:59:23.405: INFO: Pod "downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00961916s
Aug 22 04:59:25.410: INFO: Pod "downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014429743s
STEP: Saw pod success 08/22/23 04:59:25.41
Aug 22 04:59:25.410: INFO: Pod "downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c" satisfied condition "Succeeded or Failed"
Aug 22 04:59:25.420: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c container dapi-container: <nil>
STEP: delete the pod 08/22/23 04:59:25.437
Aug 22 04:59:25.544: INFO: Waiting for pod downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c to disappear
Aug 22 04:59:25.559: INFO: Pod downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 22 04:59:25.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5224" for this suite. 08/22/23 04:59:25.57
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":211,"skipped":3936,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.229 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:59:19.359
    Aug 22 04:59:19.359: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 04:59:19.36
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:59:19.379
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:59:19.382
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 08/22/23 04:59:19.385
    Aug 22 04:59:19.396: INFO: Waiting up to 5m0s for pod "downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c" in namespace "downward-api-5224" to be "Succeeded or Failed"
    Aug 22 04:59:19.401: INFO: Pod "downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.52167ms
    Aug 22 04:59:21.849: INFO: Pod "downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.453447664s
    Aug 22 04:59:23.405: INFO: Pod "downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00961916s
    Aug 22 04:59:25.410: INFO: Pod "downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014429743s
    STEP: Saw pod success 08/22/23 04:59:25.41
    Aug 22 04:59:25.410: INFO: Pod "downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c" satisfied condition "Succeeded or Failed"
    Aug 22 04:59:25.420: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c container dapi-container: <nil>
    STEP: delete the pod 08/22/23 04:59:25.437
    Aug 22 04:59:25.544: INFO: Waiting for pod downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c to disappear
    Aug 22 04:59:25.559: INFO: Pod downward-api-b7a4b71b-8572-49e1-a072-f10663f6f09c no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 22 04:59:25.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5224" for this suite. 08/22/23 04:59:25.57
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:59:25.589
Aug 22 04:59:25.589: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename disruption 08/22/23 04:59:25.589
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:59:25.655
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:59:25.669
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 08/22/23 04:59:25.713
STEP: Updating PodDisruptionBudget status 08/22/23 04:59:26.046
STEP: Waiting for all pods to be running 08/22/23 04:59:26.054
Aug 22 04:59:26.058: INFO: running pods: 0 < 1
Aug 22 04:59:28.062: INFO: running pods: 0 < 1
STEP: locating a running pod 08/22/23 04:59:30.062
STEP: Waiting for the pdb to be processed 08/22/23 04:59:30.072
STEP: Patching PodDisruptionBudget status 08/22/23 04:59:30.326
STEP: Waiting for the pdb to be processed 08/22/23 04:59:30.356
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 22 04:59:30.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2332" for this suite. 08/22/23 04:59:30.364
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":212,"skipped":3955,"failed":0}
------------------------------
â€¢ [4.781 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:59:25.589
    Aug 22 04:59:25.589: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename disruption 08/22/23 04:59:25.589
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:59:25.655
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:59:25.669
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 08/22/23 04:59:25.713
    STEP: Updating PodDisruptionBudget status 08/22/23 04:59:26.046
    STEP: Waiting for all pods to be running 08/22/23 04:59:26.054
    Aug 22 04:59:26.058: INFO: running pods: 0 < 1
    Aug 22 04:59:28.062: INFO: running pods: 0 < 1
    STEP: locating a running pod 08/22/23 04:59:30.062
    STEP: Waiting for the pdb to be processed 08/22/23 04:59:30.072
    STEP: Patching PodDisruptionBudget status 08/22/23 04:59:30.326
    STEP: Waiting for the pdb to be processed 08/22/23 04:59:30.356
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 22 04:59:30.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2332" for this suite. 08/22/23 04:59:30.364
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:59:30.37
Aug 22 04:59:30.370: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 04:59:30.371
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:59:30.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:59:30.387
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1601 08/22/23 04:59:30.39
STEP: changing the ExternalName service to type=ClusterIP 08/22/23 04:59:30.395
STEP: creating replication controller externalname-service in namespace services-1601 08/22/23 04:59:30.443
I0822 04:59:30.452507      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-1601, replica count: 2
I0822 04:59:33.504434      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 04:59:36.504783      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 22 04:59:36.504: INFO: Creating new exec pod
Aug 22 04:59:36.536: INFO: Waiting up to 5m0s for pod "execpodv2d2s" in namespace "services-1601" to be "running"
Aug 22 04:59:36.664: INFO: Pod "execpodv2d2s": Phase="Pending", Reason="", readiness=false. Elapsed: 127.874606ms
Aug 22 04:59:38.669: INFO: Pod "execpodv2d2s": Phase="Pending", Reason="", readiness=false. Elapsed: 2.132451609s
Aug 22 04:59:40.671: INFO: Pod "execpodv2d2s": Phase="Running", Reason="", readiness=true. Elapsed: 4.134393141s
Aug 22 04:59:40.671: INFO: Pod "execpodv2d2s" satisfied condition "running"
Aug 22 04:59:41.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1601 exec execpodv2d2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 22 04:59:41.811: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 22 04:59:41.811: INFO: stdout: ""
Aug 22 04:59:42.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1601 exec execpodv2d2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 22 04:59:43.088: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 22 04:59:43.088: INFO: stdout: ""
Aug 22 04:59:43.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1601 exec execpodv2d2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 22 04:59:43.949: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 22 04:59:43.949: INFO: stdout: "externalname-service-n8nq5"
Aug 22 04:59:43.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1601 exec execpodv2d2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.22.90 80'
Aug 22 04:59:44.070: INFO: stderr: "+ nc -v -t -w 2 10.254.22.90 80\n+ echo hostName\nConnection to 10.254.22.90 80 port [tcp/http] succeeded!\n"
Aug 22 04:59:44.070: INFO: stdout: ""
Aug 22 04:59:45.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1601 exec execpodv2d2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.22.90 80'
Aug 22 04:59:45.205: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.22.90 80\nConnection to 10.254.22.90 80 port [tcp/http] succeeded!\n"
Aug 22 04:59:45.205: INFO: stdout: ""
Aug 22 04:59:46.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1601 exec execpodv2d2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.22.90 80'
Aug 22 04:59:46.192: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.22.90 80\nConnection to 10.254.22.90 80 port [tcp/http] succeeded!\n"
Aug 22 04:59:46.192: INFO: stdout: "externalname-service-gxjx4"
Aug 22 04:59:46.192: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 04:59:46.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1601" for this suite. 08/22/23 04:59:46.321
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":213,"skipped":3967,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.958 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:59:30.37
    Aug 22 04:59:30.370: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 04:59:30.371
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:59:30.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:59:30.387
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-1601 08/22/23 04:59:30.39
    STEP: changing the ExternalName service to type=ClusterIP 08/22/23 04:59:30.395
    STEP: creating replication controller externalname-service in namespace services-1601 08/22/23 04:59:30.443
    I0822 04:59:30.452507      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-1601, replica count: 2
    I0822 04:59:33.504434      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0822 04:59:36.504783      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 22 04:59:36.504: INFO: Creating new exec pod
    Aug 22 04:59:36.536: INFO: Waiting up to 5m0s for pod "execpodv2d2s" in namespace "services-1601" to be "running"
    Aug 22 04:59:36.664: INFO: Pod "execpodv2d2s": Phase="Pending", Reason="", readiness=false. Elapsed: 127.874606ms
    Aug 22 04:59:38.669: INFO: Pod "execpodv2d2s": Phase="Pending", Reason="", readiness=false. Elapsed: 2.132451609s
    Aug 22 04:59:40.671: INFO: Pod "execpodv2d2s": Phase="Running", Reason="", readiness=true. Elapsed: 4.134393141s
    Aug 22 04:59:40.671: INFO: Pod "execpodv2d2s" satisfied condition "running"
    Aug 22 04:59:41.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1601 exec execpodv2d2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Aug 22 04:59:41.811: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Aug 22 04:59:41.811: INFO: stdout: ""
    Aug 22 04:59:42.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1601 exec execpodv2d2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Aug 22 04:59:43.088: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Aug 22 04:59:43.088: INFO: stdout: ""
    Aug 22 04:59:43.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1601 exec execpodv2d2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Aug 22 04:59:43.949: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Aug 22 04:59:43.949: INFO: stdout: "externalname-service-n8nq5"
    Aug 22 04:59:43.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1601 exec execpodv2d2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.22.90 80'
    Aug 22 04:59:44.070: INFO: stderr: "+ nc -v -t -w 2 10.254.22.90 80\n+ echo hostName\nConnection to 10.254.22.90 80 port [tcp/http] succeeded!\n"
    Aug 22 04:59:44.070: INFO: stdout: ""
    Aug 22 04:59:45.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1601 exec execpodv2d2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.22.90 80'
    Aug 22 04:59:45.205: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.22.90 80\nConnection to 10.254.22.90 80 port [tcp/http] succeeded!\n"
    Aug 22 04:59:45.205: INFO: stdout: ""
    Aug 22 04:59:46.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-1601 exec execpodv2d2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.22.90 80'
    Aug 22 04:59:46.192: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.22.90 80\nConnection to 10.254.22.90 80 port [tcp/http] succeeded!\n"
    Aug 22 04:59:46.192: INFO: stdout: "externalname-service-gxjx4"
    Aug 22 04:59:46.192: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 04:59:46.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1601" for this suite. 08/22/23 04:59:46.321
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:59:46.328
Aug 22 04:59:46.328: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 04:59:46.33
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:59:47.171
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:59:47.177
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-55bc3db3-118e-4791-afc1-25965b0b3a53 08/22/23 04:59:47.183
STEP: Creating a pod to test consume configMaps 08/22/23 04:59:47.279
Aug 22 04:59:47.294: INFO: Waiting up to 5m0s for pod "pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8" in namespace "configmap-2407" to be "Succeeded or Failed"
Aug 22 04:59:47.305: INFO: Pod "pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.351607ms
Aug 22 04:59:49.327: INFO: Pod "pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032899882s
Aug 22 04:59:51.314: INFO: Pod "pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020463297s
Aug 22 04:59:53.328: INFO: Pod "pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033983049s
STEP: Saw pod success 08/22/23 04:59:53.328
Aug 22 04:59:53.328: INFO: Pod "pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8" satisfied condition "Succeeded or Failed"
Aug 22 04:59:53.331: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8 container agnhost-container: <nil>
STEP: delete the pod 08/22/23 04:59:53.338
Aug 22 04:59:53.442: INFO: Waiting for pod pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8 to disappear
Aug 22 04:59:53.445: INFO: Pod pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 04:59:53.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2407" for this suite. 08/22/23 04:59:53.448
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":214,"skipped":3989,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.125 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:59:46.328
    Aug 22 04:59:46.328: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 04:59:46.33
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:59:47.171
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:59:47.177
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-55bc3db3-118e-4791-afc1-25965b0b3a53 08/22/23 04:59:47.183
    STEP: Creating a pod to test consume configMaps 08/22/23 04:59:47.279
    Aug 22 04:59:47.294: INFO: Waiting up to 5m0s for pod "pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8" in namespace "configmap-2407" to be "Succeeded or Failed"
    Aug 22 04:59:47.305: INFO: Pod "pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.351607ms
    Aug 22 04:59:49.327: INFO: Pod "pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032899882s
    Aug 22 04:59:51.314: INFO: Pod "pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020463297s
    Aug 22 04:59:53.328: INFO: Pod "pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033983049s
    STEP: Saw pod success 08/22/23 04:59:53.328
    Aug 22 04:59:53.328: INFO: Pod "pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8" satisfied condition "Succeeded or Failed"
    Aug 22 04:59:53.331: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8 container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 04:59:53.338
    Aug 22 04:59:53.442: INFO: Waiting for pod pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8 to disappear
    Aug 22 04:59:53.445: INFO: Pod pod-configmaps-eecbfa24-1841-4bfe-acd2-3a130ecddaf8 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 04:59:53.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2407" for this suite. 08/22/23 04:59:53.448
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 04:59:53.455
Aug 22 04:59:53.455: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 04:59:53.455
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:59:53.47
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:59:53.473
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 04:59:53.488
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 04:59:53.868
STEP: Deploying the webhook pod 08/22/23 04:59:54.465
STEP: Wait for the deployment to be ready 08/22/23 04:59:54.55
Aug 22 04:59:54.560: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 04:59:56.569: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 59, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 59, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 59, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 59, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 04:59:59.11
STEP: Verifying the service has paired with the endpoint 08/22/23 04:59:59.124
Aug 22 05:00:00.124: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Aug 22 05:00:00.131: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6170-crds.webhook.example.com via the AdmissionRegistration API 08/22/23 05:00:00.644
STEP: Creating a custom resource that should be mutated by the webhook 08/22/23 05:00:01.059
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:00:04.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7794" for this suite. 08/22/23 05:00:04.152
STEP: Destroying namespace "webhook-7794-markers" for this suite. 08/22/23 05:00:04.16
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":215,"skipped":3989,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.208 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 04:59:53.455
    Aug 22 04:59:53.455: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 04:59:53.455
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 04:59:53.47
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 04:59:53.473
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 04:59:53.488
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 04:59:53.868
    STEP: Deploying the webhook pod 08/22/23 04:59:54.465
    STEP: Wait for the deployment to be ready 08/22/23 04:59:54.55
    Aug 22 04:59:54.560: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 04:59:56.569: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 4, 59, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 59, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 4, 59, 54, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 4, 59, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 04:59:59.11
    STEP: Verifying the service has paired with the endpoint 08/22/23 04:59:59.124
    Aug 22 05:00:00.124: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Aug 22 05:00:00.131: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6170-crds.webhook.example.com via the AdmissionRegistration API 08/22/23 05:00:00.644
    STEP: Creating a custom resource that should be mutated by the webhook 08/22/23 05:00:01.059
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:00:04.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7794" for this suite. 08/22/23 05:00:04.152
    STEP: Destroying namespace "webhook-7794-markers" for this suite. 08/22/23 05:00:04.16
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:00:04.663
Aug 22 05:00:04.664: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pods 08/22/23 05:00:04.664
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:04.904
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:04.907
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 08/22/23 05:00:04.911
Aug 22 05:00:04.919: INFO: created test-pod-1
Aug 22 05:00:04.924: INFO: created test-pod-2
Aug 22 05:00:04.932: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 08/22/23 05:00:04.932
Aug 22 05:00:04.932: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-6723' to be running and ready
Aug 22 05:00:04.946: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 22 05:00:04.946: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 22 05:00:04.946: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 22 05:00:04.946: INFO: 0 / 3 pods in namespace 'pods-6723' are running and ready (0 seconds elapsed)
Aug 22 05:00:04.946: INFO: expected 0 pod replicas in namespace 'pods-6723', 0 are Running and Ready.
Aug 22 05:00:04.946: INFO: POD         NODE                           PHASE    GRACE  CONDITIONS
Aug 22 05:00:04.946: INFO: test-pod-1                                 Pending         []
Aug 22 05:00:04.946: INFO: test-pod-2  jake-melb-gmyyva4zrlsz-node-0  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  }]
Aug 22 05:00:04.946: INFO: test-pod-3  jake-melb-gmyyva4zrlsz-node-2  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  }]
Aug 22 05:00:04.946: INFO: 
Aug 22 05:00:06.961: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 22 05:00:06.962: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 22 05:00:06.962: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 22 05:00:06.962: INFO: 0 / 3 pods in namespace 'pods-6723' are running and ready (2 seconds elapsed)
Aug 22 05:00:06.962: INFO: expected 0 pod replicas in namespace 'pods-6723', 0 are Running and Ready.
Aug 22 05:00:06.962: INFO: POD         NODE                           PHASE    GRACE  CONDITIONS
Aug 22 05:00:06.962: INFO: test-pod-1  jake-melb-gmyyva4zrlsz-node-2  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  }]
Aug 22 05:00:06.962: INFO: test-pod-2  jake-melb-gmyyva4zrlsz-node-0  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  }]
Aug 22 05:00:06.962: INFO: test-pod-3  jake-melb-gmyyva4zrlsz-node-2  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  }]
Aug 22 05:00:06.962: INFO: 
Aug 22 05:00:08.958: INFO: 3 / 3 pods in namespace 'pods-6723' are running and ready (4 seconds elapsed)
Aug 22 05:00:08.958: INFO: expected 0 pod replicas in namespace 'pods-6723', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 08/22/23 05:00:09.244
Aug 22 05:00:09.248: INFO: Pod quantity 3 is different from expected quantity 0
Aug 22 05:00:10.275: INFO: Pod quantity 3 is different from expected quantity 0
Aug 22 05:00:11.253: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 22 05:00:12.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6723" for this suite. 08/22/23 05:00:12.376
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":216,"skipped":3998,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.722 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:00:04.663
    Aug 22 05:00:04.664: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pods 08/22/23 05:00:04.664
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:04.904
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:04.907
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 08/22/23 05:00:04.911
    Aug 22 05:00:04.919: INFO: created test-pod-1
    Aug 22 05:00:04.924: INFO: created test-pod-2
    Aug 22 05:00:04.932: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 08/22/23 05:00:04.932
    Aug 22 05:00:04.932: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-6723' to be running and ready
    Aug 22 05:00:04.946: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 22 05:00:04.946: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 22 05:00:04.946: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 22 05:00:04.946: INFO: 0 / 3 pods in namespace 'pods-6723' are running and ready (0 seconds elapsed)
    Aug 22 05:00:04.946: INFO: expected 0 pod replicas in namespace 'pods-6723', 0 are Running and Ready.
    Aug 22 05:00:04.946: INFO: POD         NODE                           PHASE    GRACE  CONDITIONS
    Aug 22 05:00:04.946: INFO: test-pod-1                                 Pending         []
    Aug 22 05:00:04.946: INFO: test-pod-2  jake-melb-gmyyva4zrlsz-node-0  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  }]
    Aug 22 05:00:04.946: INFO: test-pod-3  jake-melb-gmyyva4zrlsz-node-2  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  }]
    Aug 22 05:00:04.946: INFO: 
    Aug 22 05:00:06.961: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 22 05:00:06.962: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 22 05:00:06.962: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 22 05:00:06.962: INFO: 0 / 3 pods in namespace 'pods-6723' are running and ready (2 seconds elapsed)
    Aug 22 05:00:06.962: INFO: expected 0 pod replicas in namespace 'pods-6723', 0 are Running and Ready.
    Aug 22 05:00:06.962: INFO: POD         NODE                           PHASE    GRACE  CONDITIONS
    Aug 22 05:00:06.962: INFO: test-pod-1  jake-melb-gmyyva4zrlsz-node-2  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  }]
    Aug 22 05:00:06.962: INFO: test-pod-2  jake-melb-gmyyva4zrlsz-node-0  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  }]
    Aug 22 05:00:06.962: INFO: test-pod-3  jake-melb-gmyyva4zrlsz-node-2  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:00:04 +0000 UTC  }]
    Aug 22 05:00:06.962: INFO: 
    Aug 22 05:00:08.958: INFO: 3 / 3 pods in namespace 'pods-6723' are running and ready (4 seconds elapsed)
    Aug 22 05:00:08.958: INFO: expected 0 pod replicas in namespace 'pods-6723', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 08/22/23 05:00:09.244
    Aug 22 05:00:09.248: INFO: Pod quantity 3 is different from expected quantity 0
    Aug 22 05:00:10.275: INFO: Pod quantity 3 is different from expected quantity 0
    Aug 22 05:00:11.253: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 22 05:00:12.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6723" for this suite. 08/22/23 05:00:12.376
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:00:12.387
Aug 22 05:00:12.388: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename crd-webhook 08/22/23 05:00:12.388
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:12.71
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:12.713
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 08/22/23 05:00:12.717
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 08/22/23 05:00:12.884
STEP: Deploying the custom resource conversion webhook pod 08/22/23 05:00:13.19
STEP: Wait for the deployment to be ready 08/22/23 05:00:13.208
Aug 22 05:00:13.224: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Aug 22 05:00:15.235: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 0, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 0, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 0, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 0, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 05:00:17.24
STEP: Verifying the service has paired with the endpoint 08/22/23 05:00:17.401
Aug 22 05:00:18.402: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Aug 22 05:00:18.407: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Creating a v1 custom resource 08/22/23 05:00:21.087
STEP: Create a v2 custom resource 08/22/23 05:00:21.499
STEP: List CRs in v1 08/22/23 05:00:21.537
STEP: List CRs in v2 08/22/23 05:00:21.542
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:00:22.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2299" for this suite. 08/22/23 05:00:22.067
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":217,"skipped":4014,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.819 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:00:12.387
    Aug 22 05:00:12.388: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename crd-webhook 08/22/23 05:00:12.388
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:12.71
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:12.713
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 08/22/23 05:00:12.717
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 08/22/23 05:00:12.884
    STEP: Deploying the custom resource conversion webhook pod 08/22/23 05:00:13.19
    STEP: Wait for the deployment to be ready 08/22/23 05:00:13.208
    Aug 22 05:00:13.224: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Aug 22 05:00:15.235: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 0, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 0, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 0, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 0, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 05:00:17.24
    STEP: Verifying the service has paired with the endpoint 08/22/23 05:00:17.401
    Aug 22 05:00:18.402: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Aug 22 05:00:18.407: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Creating a v1 custom resource 08/22/23 05:00:21.087
    STEP: Create a v2 custom resource 08/22/23 05:00:21.499
    STEP: List CRs in v1 08/22/23 05:00:21.537
    STEP: List CRs in v2 08/22/23 05:00:21.542
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:00:22.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-2299" for this suite. 08/22/23 05:00:22.067
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:00:22.208
Aug 22 05:00:22.208: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 05:00:22.209
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:22.227
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:22.229
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 08/22/23 05:00:22.232
Aug 22 05:00:22.232: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6596 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 08/22/23 05:00:22.264
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 05:00:22.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6596" for this suite. 08/22/23 05:00:22.285
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":218,"skipped":4030,"failed":0}
------------------------------
â€¢ [0.089 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:00:22.208
    Aug 22 05:00:22.208: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 05:00:22.209
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:22.227
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:22.229
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 08/22/23 05:00:22.232
    Aug 22 05:00:22.232: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6596 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 08/22/23 05:00:22.264
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 05:00:22.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6596" for this suite. 08/22/23 05:00:22.285
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:00:22.3
Aug 22 05:00:22.300: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename custom-resource-definition 08/22/23 05:00:22.3
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:22.433
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:22.436
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Aug 22 05:00:22.440: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:00:25.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1121" for this suite. 08/22/23 05:00:25.562
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":219,"skipped":4092,"failed":0}
------------------------------
â€¢ [3.269 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:00:22.3
    Aug 22 05:00:22.300: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename custom-resource-definition 08/22/23 05:00:22.3
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:22.433
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:22.436
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Aug 22 05:00:22.440: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:00:25.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1121" for this suite. 08/22/23 05:00:25.562
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:00:25.57
Aug 22 05:00:25.570: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 05:00:25.571
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:25.584
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:25.587
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 08/22/23 05:00:25.59
Aug 22 05:00:25.691: INFO: Waiting up to 5m0s for pod "pod-bdc38f49-dea7-457f-a901-cde878937b2f" in namespace "emptydir-2743" to be "Succeeded or Failed"
Aug 22 05:00:25.695: INFO: Pod "pod-bdc38f49-dea7-457f-a901-cde878937b2f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.728907ms
Aug 22 05:00:27.698: INFO: Pod "pod-bdc38f49-dea7-457f-a901-cde878937b2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007106622s
Aug 22 05:00:29.701: INFO: Pod "pod-bdc38f49-dea7-457f-a901-cde878937b2f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010358771s
Aug 22 05:00:31.699: INFO: Pod "pod-bdc38f49-dea7-457f-a901-cde878937b2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007673008s
STEP: Saw pod success 08/22/23 05:00:31.699
Aug 22 05:00:31.699: INFO: Pod "pod-bdc38f49-dea7-457f-a901-cde878937b2f" satisfied condition "Succeeded or Failed"
Aug 22 05:00:31.701: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-bdc38f49-dea7-457f-a901-cde878937b2f container test-container: <nil>
STEP: delete the pod 08/22/23 05:00:31.707
Aug 22 05:00:31.739: INFO: Waiting for pod pod-bdc38f49-dea7-457f-a901-cde878937b2f to disappear
Aug 22 05:00:31.742: INFO: Pod pod-bdc38f49-dea7-457f-a901-cde878937b2f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 05:00:31.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2743" for this suite. 08/22/23 05:00:31.748
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":220,"skipped":4110,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.186 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:00:25.57
    Aug 22 05:00:25.570: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 05:00:25.571
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:25.584
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:25.587
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 08/22/23 05:00:25.59
    Aug 22 05:00:25.691: INFO: Waiting up to 5m0s for pod "pod-bdc38f49-dea7-457f-a901-cde878937b2f" in namespace "emptydir-2743" to be "Succeeded or Failed"
    Aug 22 05:00:25.695: INFO: Pod "pod-bdc38f49-dea7-457f-a901-cde878937b2f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.728907ms
    Aug 22 05:00:27.698: INFO: Pod "pod-bdc38f49-dea7-457f-a901-cde878937b2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007106622s
    Aug 22 05:00:29.701: INFO: Pod "pod-bdc38f49-dea7-457f-a901-cde878937b2f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010358771s
    Aug 22 05:00:31.699: INFO: Pod "pod-bdc38f49-dea7-457f-a901-cde878937b2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007673008s
    STEP: Saw pod success 08/22/23 05:00:31.699
    Aug 22 05:00:31.699: INFO: Pod "pod-bdc38f49-dea7-457f-a901-cde878937b2f" satisfied condition "Succeeded or Failed"
    Aug 22 05:00:31.701: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-bdc38f49-dea7-457f-a901-cde878937b2f container test-container: <nil>
    STEP: delete the pod 08/22/23 05:00:31.707
    Aug 22 05:00:31.739: INFO: Waiting for pod pod-bdc38f49-dea7-457f-a901-cde878937b2f to disappear
    Aug 22 05:00:31.742: INFO: Pod pod-bdc38f49-dea7-457f-a901-cde878937b2f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 05:00:31.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2743" for this suite. 08/22/23 05:00:31.748
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:00:31.756
Aug 22 05:00:31.756: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 05:00:31.757
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:31.782
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:31.784
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 05:00:31.8
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:00:32.013
STEP: Deploying the webhook pod 08/22/23 05:00:32.094
STEP: Wait for the deployment to be ready 08/22/23 05:00:32.161
Aug 22 05:00:32.170: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 05:00:34.183: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 05:00:36.191: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 05:00:38.186
STEP: Verifying the service has paired with the endpoint 08/22/23 05:00:38.197
Aug 22 05:00:39.197: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 08/22/23 05:00:39.202
STEP: Creating a configMap that does not comply to the validation webhook rules 08/22/23 05:00:39.265
STEP: Updating a validating webhook configuration's rules to not include the create operation 08/22/23 05:00:39.272
STEP: Creating a configMap that does not comply to the validation webhook rules 08/22/23 05:00:39.281
STEP: Patching a validating webhook configuration's rules to include the create operation 08/22/23 05:00:39.29
STEP: Creating a configMap that does not comply to the validation webhook rules 08/22/23 05:00:39.297
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:00:39.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7259" for this suite. 08/22/23 05:00:39.309
STEP: Destroying namespace "webhook-7259-markers" for this suite. 08/22/23 05:00:39.317
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":221,"skipped":4111,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.628 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:00:31.756
    Aug 22 05:00:31.756: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 05:00:31.757
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:31.782
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:31.784
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 05:00:31.8
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:00:32.013
    STEP: Deploying the webhook pod 08/22/23 05:00:32.094
    STEP: Wait for the deployment to be ready 08/22/23 05:00:32.161
    Aug 22 05:00:32.170: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 05:00:34.183: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 05:00:36.191: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 0, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 05:00:38.186
    STEP: Verifying the service has paired with the endpoint 08/22/23 05:00:38.197
    Aug 22 05:00:39.197: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 08/22/23 05:00:39.202
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/22/23 05:00:39.265
    STEP: Updating a validating webhook configuration's rules to not include the create operation 08/22/23 05:00:39.272
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/22/23 05:00:39.281
    STEP: Patching a validating webhook configuration's rules to include the create operation 08/22/23 05:00:39.29
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/22/23 05:00:39.297
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:00:39.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7259" for this suite. 08/22/23 05:00:39.309
    STEP: Destroying namespace "webhook-7259-markers" for this suite. 08/22/23 05:00:39.317
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:00:39.384
Aug 22 05:00:39.384: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename var-expansion 08/22/23 05:00:39.385
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:39.412
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:39.414
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 08/22/23 05:00:39.419
Aug 22 05:00:39.426: INFO: Waiting up to 5m0s for pod "var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2" in namespace "var-expansion-7917" to be "Succeeded or Failed"
Aug 22 05:00:39.429: INFO: Pod "var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.897026ms
Aug 22 05:00:41.434: INFO: Pod "var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007248736s
Aug 22 05:00:43.433: INFO: Pod "var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006780266s
Aug 22 05:00:45.433: INFO: Pod "var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006445616s
STEP: Saw pod success 08/22/23 05:00:45.433
Aug 22 05:00:45.433: INFO: Pod "var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2" satisfied condition "Succeeded or Failed"
Aug 22 05:00:45.436: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2 container dapi-container: <nil>
STEP: delete the pod 08/22/23 05:00:45.442
Aug 22 05:00:45.600: INFO: Waiting for pod var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2 to disappear
Aug 22 05:00:45.603: INFO: Pod var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 22 05:00:45.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7917" for this suite. 08/22/23 05:00:45.606
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":222,"skipped":4116,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.228 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:00:39.384
    Aug 22 05:00:39.384: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename var-expansion 08/22/23 05:00:39.385
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:39.412
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:39.414
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 08/22/23 05:00:39.419
    Aug 22 05:00:39.426: INFO: Waiting up to 5m0s for pod "var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2" in namespace "var-expansion-7917" to be "Succeeded or Failed"
    Aug 22 05:00:39.429: INFO: Pod "var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.897026ms
    Aug 22 05:00:41.434: INFO: Pod "var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007248736s
    Aug 22 05:00:43.433: INFO: Pod "var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006780266s
    Aug 22 05:00:45.433: INFO: Pod "var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006445616s
    STEP: Saw pod success 08/22/23 05:00:45.433
    Aug 22 05:00:45.433: INFO: Pod "var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2" satisfied condition "Succeeded or Failed"
    Aug 22 05:00:45.436: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2 container dapi-container: <nil>
    STEP: delete the pod 08/22/23 05:00:45.442
    Aug 22 05:00:45.600: INFO: Waiting for pod var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2 to disappear
    Aug 22 05:00:45.603: INFO: Pod var-expansion-b7fcc1db-e40c-42b5-be46-bde41e4976d2 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 22 05:00:45.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7917" for this suite. 08/22/23 05:00:45.606
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:00:45.612
Aug 22 05:00:45.612: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename resourcequota 08/22/23 05:00:45.613
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:45.635
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:45.638
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 08/22/23 05:01:02.648
STEP: Creating a ResourceQuota 08/22/23 05:01:07.652
STEP: Ensuring resource quota status is calculated 08/22/23 05:01:07.66
STEP: Creating a ConfigMap 08/22/23 05:01:09.664
STEP: Ensuring resource quota status captures configMap creation 08/22/23 05:01:09.675
STEP: Deleting a ConfigMap 08/22/23 05:01:11.679
STEP: Ensuring resource quota status released usage 08/22/23 05:01:11.685
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 22 05:01:13.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-821" for this suite. 08/22/23 05:01:13.695
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":223,"skipped":4145,"failed":0}
------------------------------
â€¢ [SLOW TEST] [28.089 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:00:45.612
    Aug 22 05:00:45.612: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename resourcequota 08/22/23 05:00:45.613
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:00:45.635
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:00:45.638
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 08/22/23 05:01:02.648
    STEP: Creating a ResourceQuota 08/22/23 05:01:07.652
    STEP: Ensuring resource quota status is calculated 08/22/23 05:01:07.66
    STEP: Creating a ConfigMap 08/22/23 05:01:09.664
    STEP: Ensuring resource quota status captures configMap creation 08/22/23 05:01:09.675
    STEP: Deleting a ConfigMap 08/22/23 05:01:11.679
    STEP: Ensuring resource quota status released usage 08/22/23 05:01:11.685
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 22 05:01:13.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-821" for this suite. 08/22/23 05:01:13.695
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:01:13.702
Aug 22 05:01:13.702: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-probe 08/22/23 05:01:13.703
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:01:14.035
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:01:14.039
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82 in namespace container-probe-3013 08/22/23 05:01:14.043
Aug 22 05:01:14.059: INFO: Waiting up to 5m0s for pod "busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82" in namespace "container-probe-3013" to be "not pending"
Aug 22 05:01:14.064: INFO: Pod "busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82": Phase="Pending", Reason="", readiness=false. Elapsed: 5.059863ms
Aug 22 05:01:16.069: INFO: Pod "busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010770765s
Aug 22 05:01:18.069: INFO: Pod "busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82": Phase="Running", Reason="", readiness=true. Elapsed: 4.010384949s
Aug 22 05:01:18.069: INFO: Pod "busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82" satisfied condition "not pending"
Aug 22 05:01:18.069: INFO: Started pod busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82 in namespace container-probe-3013
STEP: checking the pod's current state and verifying that restartCount is present 08/22/23 05:01:18.069
Aug 22 05:01:18.072: INFO: Initial restart count of pod busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82 is 0
Aug 22 05:02:06.358: INFO: Restart count of pod container-probe-3013/busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82 is now 1 (48.2859374s elapsed)
STEP: deleting the pod 08/22/23 05:02:06.358
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 22 05:02:06.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3013" for this suite. 08/22/23 05:02:06.391
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":224,"skipped":4171,"failed":0}
------------------------------
â€¢ [SLOW TEST] [52.695 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:01:13.702
    Aug 22 05:01:13.702: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-probe 08/22/23 05:01:13.703
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:01:14.035
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:01:14.039
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82 in namespace container-probe-3013 08/22/23 05:01:14.043
    Aug 22 05:01:14.059: INFO: Waiting up to 5m0s for pod "busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82" in namespace "container-probe-3013" to be "not pending"
    Aug 22 05:01:14.064: INFO: Pod "busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82": Phase="Pending", Reason="", readiness=false. Elapsed: 5.059863ms
    Aug 22 05:01:16.069: INFO: Pod "busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010770765s
    Aug 22 05:01:18.069: INFO: Pod "busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82": Phase="Running", Reason="", readiness=true. Elapsed: 4.010384949s
    Aug 22 05:01:18.069: INFO: Pod "busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82" satisfied condition "not pending"
    Aug 22 05:01:18.069: INFO: Started pod busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82 in namespace container-probe-3013
    STEP: checking the pod's current state and verifying that restartCount is present 08/22/23 05:01:18.069
    Aug 22 05:01:18.072: INFO: Initial restart count of pod busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82 is 0
    Aug 22 05:02:06.358: INFO: Restart count of pod container-probe-3013/busybox-8dd7388b-5a73-4db0-b897-119eb9c9ac82 is now 1 (48.2859374s elapsed)
    STEP: deleting the pod 08/22/23 05:02:06.358
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 22 05:02:06.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3013" for this suite. 08/22/23 05:02:06.391
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:02:06.398
Aug 22 05:02:06.398: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 05:02:06.398
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:02:06.433
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:02:06.435
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8450 08/22/23 05:02:06.438
STEP: changing the ExternalName service to type=NodePort 08/22/23 05:02:06.444
STEP: creating replication controller externalname-service in namespace services-8450 08/22/23 05:02:06.469
I0822 05:02:06.479864      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-8450, replica count: 2
I0822 05:02:09.531079      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 22 05:02:09.531: INFO: Creating new exec pod
Aug 22 05:02:09.771: INFO: Waiting up to 5m0s for pod "execpodpl6mj" in namespace "services-8450" to be "running"
Aug 22 05:02:09.776: INFO: Pod "execpodpl6mj": Phase="Pending", Reason="", readiness=false. Elapsed: 5.077187ms
Aug 22 05:02:11.780: INFO: Pod "execpodpl6mj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009495383s
Aug 22 05:02:13.794: INFO: Pod "execpodpl6mj": Phase="Running", Reason="", readiness=true. Elapsed: 4.023358169s
Aug 22 05:02:13.794: INFO: Pod "execpodpl6mj" satisfied condition "running"
Aug 22 05:02:14.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 22 05:02:14.933: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 22 05:02:14.933: INFO: stdout: "externalname-service-82xj9"
Aug 22 05:02:14.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.193.24 80'
Aug 22 05:02:15.057: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.193.24 80\nConnection to 10.254.193.24 80 port [tcp/http] succeeded!\n"
Aug 22 05:02:15.057: INFO: stdout: ""
Aug 22 05:02:16.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.193.24 80'
Aug 22 05:02:16.406: INFO: stderr: "+ nc -v -t -w 2 10.254.193.24 80\n+ echo hostName\nConnection to 10.254.193.24 80 port [tcp/http] succeeded!\n"
Aug 22 05:02:16.406: INFO: stdout: ""
Aug 22 05:02:17.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.193.24 80'
Aug 22 05:02:17.180: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.193.24 80\nConnection to 10.254.193.24 80 port [tcp/http] succeeded!\n"
Aug 22 05:02:17.181: INFO: stdout: ""
Aug 22 05:02:18.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.193.24 80'
Aug 22 05:02:18.174: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.193.24 80\nConnection to 10.254.193.24 80 port [tcp/http] succeeded!\n"
Aug 22 05:02:18.174: INFO: stdout: ""
Aug 22 05:02:19.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.193.24 80'
Aug 22 05:02:19.172: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.193.24 80\nConnection to 10.254.193.24 80 port [tcp/http] succeeded!\n"
Aug 22 05:02:19.172: INFO: stdout: "externalname-service-82xj9"
Aug 22 05:02:19.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.130 31934'
Aug 22 05:02:19.298: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.0.130 31934\nConnection to 10.0.0.130 31934 port [tcp/*] succeeded!\n"
Aug 22 05:02:19.298: INFO: stdout: ""
Aug 22 05:02:20.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.130 31934'
Aug 22 05:02:20.419: INFO: stderr: "+ nc -v -t -w 2 10.0.0.130 31934\n+ echo hostName\nConnection to 10.0.0.130 31934 port [tcp/*] succeeded!\n"
Aug 22 05:02:20.419: INFO: stdout: "externalname-service-82xj9"
Aug 22 05:02:20.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.232 31934'
Aug 22 05:02:20.535: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.0.232 31934\nConnection to 10.0.0.232 31934 port [tcp/*] succeeded!\n"
Aug 22 05:02:20.535: INFO: stdout: "externalname-service-82xj9"
Aug 22 05:02:20.535: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 05:02:20.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8450" for this suite. 08/22/23 05:02:20.699
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":225,"skipped":4178,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.317 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:02:06.398
    Aug 22 05:02:06.398: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 05:02:06.398
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:02:06.433
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:02:06.435
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-8450 08/22/23 05:02:06.438
    STEP: changing the ExternalName service to type=NodePort 08/22/23 05:02:06.444
    STEP: creating replication controller externalname-service in namespace services-8450 08/22/23 05:02:06.469
    I0822 05:02:06.479864      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-8450, replica count: 2
    I0822 05:02:09.531079      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 22 05:02:09.531: INFO: Creating new exec pod
    Aug 22 05:02:09.771: INFO: Waiting up to 5m0s for pod "execpodpl6mj" in namespace "services-8450" to be "running"
    Aug 22 05:02:09.776: INFO: Pod "execpodpl6mj": Phase="Pending", Reason="", readiness=false. Elapsed: 5.077187ms
    Aug 22 05:02:11.780: INFO: Pod "execpodpl6mj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009495383s
    Aug 22 05:02:13.794: INFO: Pod "execpodpl6mj": Phase="Running", Reason="", readiness=true. Elapsed: 4.023358169s
    Aug 22 05:02:13.794: INFO: Pod "execpodpl6mj" satisfied condition "running"
    Aug 22 05:02:14.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Aug 22 05:02:14.933: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Aug 22 05:02:14.933: INFO: stdout: "externalname-service-82xj9"
    Aug 22 05:02:14.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.193.24 80'
    Aug 22 05:02:15.057: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.193.24 80\nConnection to 10.254.193.24 80 port [tcp/http] succeeded!\n"
    Aug 22 05:02:15.057: INFO: stdout: ""
    Aug 22 05:02:16.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.193.24 80'
    Aug 22 05:02:16.406: INFO: stderr: "+ nc -v -t -w 2 10.254.193.24 80\n+ echo hostName\nConnection to 10.254.193.24 80 port [tcp/http] succeeded!\n"
    Aug 22 05:02:16.406: INFO: stdout: ""
    Aug 22 05:02:17.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.193.24 80'
    Aug 22 05:02:17.180: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.193.24 80\nConnection to 10.254.193.24 80 port [tcp/http] succeeded!\n"
    Aug 22 05:02:17.181: INFO: stdout: ""
    Aug 22 05:02:18.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.193.24 80'
    Aug 22 05:02:18.174: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.193.24 80\nConnection to 10.254.193.24 80 port [tcp/http] succeeded!\n"
    Aug 22 05:02:18.174: INFO: stdout: ""
    Aug 22 05:02:19.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.193.24 80'
    Aug 22 05:02:19.172: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.193.24 80\nConnection to 10.254.193.24 80 port [tcp/http] succeeded!\n"
    Aug 22 05:02:19.172: INFO: stdout: "externalname-service-82xj9"
    Aug 22 05:02:19.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.130 31934'
    Aug 22 05:02:19.298: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.0.130 31934\nConnection to 10.0.0.130 31934 port [tcp/*] succeeded!\n"
    Aug 22 05:02:19.298: INFO: stdout: ""
    Aug 22 05:02:20.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.130 31934'
    Aug 22 05:02:20.419: INFO: stderr: "+ nc -v -t -w 2 10.0.0.130 31934\n+ echo hostName\nConnection to 10.0.0.130 31934 port [tcp/*] succeeded!\n"
    Aug 22 05:02:20.419: INFO: stdout: "externalname-service-82xj9"
    Aug 22 05:02:20.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-8450 exec execpodpl6mj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.0.232 31934'
    Aug 22 05:02:20.535: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.0.232 31934\nConnection to 10.0.0.232 31934 port [tcp/*] succeeded!\n"
    Aug 22 05:02:20.535: INFO: stdout: "externalname-service-82xj9"
    Aug 22 05:02:20.535: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 05:02:20.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8450" for this suite. 08/22/23 05:02:20.699
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:02:20.716
Aug 22 05:02:20.716: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename gc 08/22/23 05:02:20.716
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:02:20.868
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:02:20.871
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 08/22/23 05:02:20.875
STEP: delete the rc 08/22/23 05:02:26.471
STEP: wait for all pods to be garbage collected 08/22/23 05:02:26.594
STEP: Gathering metrics 08/22/23 05:02:31.603
W0822 05:02:31.612155      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Aug 22 05:02:31.612: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 22 05:02:31.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3233" for this suite. 08/22/23 05:02:31.616
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":226,"skipped":4199,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.907 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:02:20.716
    Aug 22 05:02:20.716: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename gc 08/22/23 05:02:20.716
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:02:20.868
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:02:20.871
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 08/22/23 05:02:20.875
    STEP: delete the rc 08/22/23 05:02:26.471
    STEP: wait for all pods to be garbage collected 08/22/23 05:02:26.594
    STEP: Gathering metrics 08/22/23 05:02:31.603
    W0822 05:02:31.612155      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Aug 22 05:02:31.612: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 22 05:02:31.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-3233" for this suite. 08/22/23 05:02:31.616
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:02:31.624
Aug 22 05:02:31.624: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename security-context-test 08/22/23 05:02:31.624
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:02:31.662
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:02:31.665
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Aug 22 05:02:31.705: INFO: Waiting up to 5m0s for pod "busybox-user-65534-3b45f4b0-2158-4357-809b-904714113106" in namespace "security-context-test-8174" to be "Succeeded or Failed"
Aug 22 05:02:31.708: INFO: Pod "busybox-user-65534-3b45f4b0-2158-4357-809b-904714113106": Phase="Pending", Reason="", readiness=false. Elapsed: 3.654767ms
Aug 22 05:02:33.713: INFO: Pod "busybox-user-65534-3b45f4b0-2158-4357-809b-904714113106": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008271234s
Aug 22 05:02:35.713: INFO: Pod "busybox-user-65534-3b45f4b0-2158-4357-809b-904714113106": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008164813s
Aug 22 05:02:37.712: INFO: Pod "busybox-user-65534-3b45f4b0-2158-4357-809b-904714113106": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007663049s
Aug 22 05:02:37.713: INFO: Pod "busybox-user-65534-3b45f4b0-2158-4357-809b-904714113106" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 22 05:02:37.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8174" for this suite. 08/22/23 05:02:37.717
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":227,"skipped":4229,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.098 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:02:31.624
    Aug 22 05:02:31.624: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename security-context-test 08/22/23 05:02:31.624
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:02:31.662
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:02:31.665
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Aug 22 05:02:31.705: INFO: Waiting up to 5m0s for pod "busybox-user-65534-3b45f4b0-2158-4357-809b-904714113106" in namespace "security-context-test-8174" to be "Succeeded or Failed"
    Aug 22 05:02:31.708: INFO: Pod "busybox-user-65534-3b45f4b0-2158-4357-809b-904714113106": Phase="Pending", Reason="", readiness=false. Elapsed: 3.654767ms
    Aug 22 05:02:33.713: INFO: Pod "busybox-user-65534-3b45f4b0-2158-4357-809b-904714113106": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008271234s
    Aug 22 05:02:35.713: INFO: Pod "busybox-user-65534-3b45f4b0-2158-4357-809b-904714113106": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008164813s
    Aug 22 05:02:37.712: INFO: Pod "busybox-user-65534-3b45f4b0-2158-4357-809b-904714113106": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007663049s
    Aug 22 05:02:37.713: INFO: Pod "busybox-user-65534-3b45f4b0-2158-4357-809b-904714113106" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 22 05:02:37.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-8174" for this suite. 08/22/23 05:02:37.717
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:02:37.722
Aug 22 05:02:37.722: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 05:02:37.723
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:02:37.746
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:02:37.749
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 08/22/23 05:02:37.751
Aug 22 05:02:37.758: INFO: Waiting up to 5m0s for pod "pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00" in namespace "emptydir-8045" to be "Succeeded or Failed"
Aug 22 05:02:37.761: INFO: Pod "pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.596963ms
Aug 22 05:02:39.899: INFO: Pod "pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.140736836s
Aug 22 05:02:41.767: INFO: Pod "pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008296982s
Aug 22 05:02:43.764: INFO: Pod "pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006043911s
STEP: Saw pod success 08/22/23 05:02:43.765
Aug 22 05:02:43.765: INFO: Pod "pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00" satisfied condition "Succeeded or Failed"
Aug 22 05:02:43.767: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00 container test-container: <nil>
STEP: delete the pod 08/22/23 05:02:43.799
Aug 22 05:02:44.036: INFO: Waiting for pod pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00 to disappear
Aug 22 05:02:44.040: INFO: Pod pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 05:02:44.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8045" for this suite. 08/22/23 05:02:44.044
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":228,"skipped":4239,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.479 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:02:37.722
    Aug 22 05:02:37.722: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 05:02:37.723
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:02:37.746
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:02:37.749
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 08/22/23 05:02:37.751
    Aug 22 05:02:37.758: INFO: Waiting up to 5m0s for pod "pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00" in namespace "emptydir-8045" to be "Succeeded or Failed"
    Aug 22 05:02:37.761: INFO: Pod "pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.596963ms
    Aug 22 05:02:39.899: INFO: Pod "pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.140736836s
    Aug 22 05:02:41.767: INFO: Pod "pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008296982s
    Aug 22 05:02:43.764: INFO: Pod "pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006043911s
    STEP: Saw pod success 08/22/23 05:02:43.765
    Aug 22 05:02:43.765: INFO: Pod "pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00" satisfied condition "Succeeded or Failed"
    Aug 22 05:02:43.767: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00 container test-container: <nil>
    STEP: delete the pod 08/22/23 05:02:43.799
    Aug 22 05:02:44.036: INFO: Waiting for pod pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00 to disappear
    Aug 22 05:02:44.040: INFO: Pod pod-a4667a8e-a2a9-4f46-80b5-d60c225b9c00 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 05:02:44.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8045" for this suite. 08/22/23 05:02:44.044
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:02:44.202
Aug 22 05:02:44.202: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename dns 08/22/23 05:02:44.203
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:02:44.26
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:02:44.262
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4565.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4565.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 08/22/23 05:02:44.267
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4565.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4565.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 08/22/23 05:02:44.267
STEP: creating a pod to probe /etc/hosts 08/22/23 05:02:44.267
STEP: submitting the pod to kubernetes 08/22/23 05:02:44.267
Aug 22 05:02:44.285: INFO: Waiting up to 15m0s for pod "dns-test-4b73a5d8-e2de-4ba3-b467-755df18aa80f" in namespace "dns-4565" to be "running"
Aug 22 05:02:44.290: INFO: Pod "dns-test-4b73a5d8-e2de-4ba3-b467-755df18aa80f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.725556ms
Aug 22 05:02:46.294: INFO: Pod "dns-test-4b73a5d8-e2de-4ba3-b467-755df18aa80f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008962403s
Aug 22 05:02:48.295: INFO: Pod "dns-test-4b73a5d8-e2de-4ba3-b467-755df18aa80f": Phase="Running", Reason="", readiness=true. Elapsed: 4.010356987s
Aug 22 05:02:48.295: INFO: Pod "dns-test-4b73a5d8-e2de-4ba3-b467-755df18aa80f" satisfied condition "running"
STEP: retrieving the pod 08/22/23 05:02:48.295
STEP: looking for the results for each expected name from probers 08/22/23 05:02:48.301
Aug 22 05:02:48.317: INFO: DNS probes using dns-4565/dns-test-4b73a5d8-e2de-4ba3-b467-755df18aa80f succeeded

STEP: deleting the pod 08/22/23 05:02:48.317
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 22 05:02:48.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4565" for this suite. 08/22/23 05:02:48.334
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":229,"skipped":4242,"failed":0}
------------------------------
â€¢ [4.139 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:02:44.202
    Aug 22 05:02:44.202: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename dns 08/22/23 05:02:44.203
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:02:44.26
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:02:44.262
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4565.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4565.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     08/22/23 05:02:44.267
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4565.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4565.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     08/22/23 05:02:44.267
    STEP: creating a pod to probe /etc/hosts 08/22/23 05:02:44.267
    STEP: submitting the pod to kubernetes 08/22/23 05:02:44.267
    Aug 22 05:02:44.285: INFO: Waiting up to 15m0s for pod "dns-test-4b73a5d8-e2de-4ba3-b467-755df18aa80f" in namespace "dns-4565" to be "running"
    Aug 22 05:02:44.290: INFO: Pod "dns-test-4b73a5d8-e2de-4ba3-b467-755df18aa80f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.725556ms
    Aug 22 05:02:46.294: INFO: Pod "dns-test-4b73a5d8-e2de-4ba3-b467-755df18aa80f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008962403s
    Aug 22 05:02:48.295: INFO: Pod "dns-test-4b73a5d8-e2de-4ba3-b467-755df18aa80f": Phase="Running", Reason="", readiness=true. Elapsed: 4.010356987s
    Aug 22 05:02:48.295: INFO: Pod "dns-test-4b73a5d8-e2de-4ba3-b467-755df18aa80f" satisfied condition "running"
    STEP: retrieving the pod 08/22/23 05:02:48.295
    STEP: looking for the results for each expected name from probers 08/22/23 05:02:48.301
    Aug 22 05:02:48.317: INFO: DNS probes using dns-4565/dns-test-4b73a5d8-e2de-4ba3-b467-755df18aa80f succeeded

    STEP: deleting the pod 08/22/23 05:02:48.317
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 22 05:02:48.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-4565" for this suite. 08/22/23 05:02:48.334
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:02:48.342
Aug 22 05:02:48.342: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-runtime 08/22/23 05:02:48.342
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:02:48.358
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:02:48.362
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 08/22/23 05:02:48.367
STEP: wait for the container to reach Failed 08/22/23 05:02:48.378
STEP: get the container status 08/22/23 05:02:55.616
STEP: the container should be terminated 08/22/23 05:02:55.618
STEP: the termination message should be set 08/22/23 05:02:55.618
Aug 22 05:02:55.618: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 08/22/23 05:02:55.618
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 22 05:02:55.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5076" for this suite. 08/22/23 05:02:55.758
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":230,"skipped":4245,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.424 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:02:48.342
    Aug 22 05:02:48.342: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-runtime 08/22/23 05:02:48.342
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:02:48.358
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:02:48.362
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 08/22/23 05:02:48.367
    STEP: wait for the container to reach Failed 08/22/23 05:02:48.378
    STEP: get the container status 08/22/23 05:02:55.616
    STEP: the container should be terminated 08/22/23 05:02:55.618
    STEP: the termination message should be set 08/22/23 05:02:55.618
    Aug 22 05:02:55.618: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 08/22/23 05:02:55.618
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 22 05:02:55.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5076" for this suite. 08/22/23 05:02:55.758
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:02:55.766
Aug 22 05:02:55.766: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 05:02:55.766
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:02:56.018
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:02:56.021
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 05:02:56.05
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:02:56.386
STEP: Deploying the webhook pod 08/22/23 05:02:56.395
STEP: Wait for the deployment to be ready 08/22/23 05:02:56.571
Aug 22 05:02:56.777: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 05:02:58.787: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 05:03:00.818: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 05:03:02.88
STEP: Verifying the service has paired with the endpoint 08/22/23 05:03:02.908
Aug 22 05:03:03.908: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 08/22/23 05:03:03.912
STEP: create a configmap that should be updated by the webhook 08/22/23 05:03:04.093
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:03:04.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-414" for this suite. 08/22/23 05:03:04.125
STEP: Destroying namespace "webhook-414-markers" for this suite. 08/22/23 05:03:04.133
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":231,"skipped":4248,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.728 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:02:55.766
    Aug 22 05:02:55.766: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 05:02:55.766
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:02:56.018
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:02:56.021
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 05:02:56.05
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:02:56.386
    STEP: Deploying the webhook pod 08/22/23 05:02:56.395
    STEP: Wait for the deployment to be ready 08/22/23 05:02:56.571
    Aug 22 05:02:56.777: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 05:02:58.787: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 05:03:00.818: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 2, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 05:03:02.88
    STEP: Verifying the service has paired with the endpoint 08/22/23 05:03:02.908
    Aug 22 05:03:03.908: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 08/22/23 05:03:03.912
    STEP: create a configmap that should be updated by the webhook 08/22/23 05:03:04.093
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:03:04.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-414" for this suite. 08/22/23 05:03:04.125
    STEP: Destroying namespace "webhook-414-markers" for this suite. 08/22/23 05:03:04.133
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:03:04.493
Aug 22 05:03:04.494: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 05:03:04.494
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:04.516
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:04.518
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 08/22/23 05:03:04.521
Aug 22 05:03:04.529: INFO: Waiting up to 5m0s for pod "downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a" in namespace "downward-api-8911" to be "Succeeded or Failed"
Aug 22 05:03:04.532: INFO: Pod "downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.99029ms
Aug 22 05:03:06.536: INFO: Pod "downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006628803s
Aug 22 05:03:08.536: INFO: Pod "downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007190563s
Aug 22 05:03:10.536: INFO: Pod "downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007396186s
STEP: Saw pod success 08/22/23 05:03:10.536
Aug 22 05:03:10.537: INFO: Pod "downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a" satisfied condition "Succeeded or Failed"
Aug 22 05:03:10.539: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a container client-container: <nil>
STEP: delete the pod 08/22/23 05:03:10.547
Aug 22 05:03:10.803: INFO: Waiting for pod downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a to disappear
Aug 22 05:03:10.806: INFO: Pod downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 22 05:03:10.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8911" for this suite. 08/22/23 05:03:10.811
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":232,"skipped":4254,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.411 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:03:04.493
    Aug 22 05:03:04.494: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 05:03:04.494
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:04.516
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:04.518
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 08/22/23 05:03:04.521
    Aug 22 05:03:04.529: INFO: Waiting up to 5m0s for pod "downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a" in namespace "downward-api-8911" to be "Succeeded or Failed"
    Aug 22 05:03:04.532: INFO: Pod "downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.99029ms
    Aug 22 05:03:06.536: INFO: Pod "downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006628803s
    Aug 22 05:03:08.536: INFO: Pod "downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007190563s
    Aug 22 05:03:10.536: INFO: Pod "downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007396186s
    STEP: Saw pod success 08/22/23 05:03:10.536
    Aug 22 05:03:10.537: INFO: Pod "downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a" satisfied condition "Succeeded or Failed"
    Aug 22 05:03:10.539: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a container client-container: <nil>
    STEP: delete the pod 08/22/23 05:03:10.547
    Aug 22 05:03:10.803: INFO: Waiting for pod downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a to disappear
    Aug 22 05:03:10.806: INFO: Pod downwardapi-volume-705a632c-977b-4657-bb8f-befbf3204f9a no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 22 05:03:10.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8911" for this suite. 08/22/23 05:03:10.811
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:03:10.906
Aug 22 05:03:10.906: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 05:03:10.906
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:10.924
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:10.927
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 05:03:10.943
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:03:11.083
STEP: Deploying the webhook pod 08/22/23 05:03:11.089
STEP: Wait for the deployment to be ready 08/22/23 05:03:11.368
Aug 22 05:03:11.779: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 05:03:13.790: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 3, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 3, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 3, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 3, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 05:03:15.795
STEP: Verifying the service has paired with the endpoint 08/22/23 05:03:15.805
Aug 22 05:03:16.806: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 08/22/23 05:03:16.811
STEP: Registering slow webhook via the AdmissionRegistration API 08/22/23 05:03:16.811
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 08/22/23 05:03:16.929
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 08/22/23 05:03:18.15
STEP: Registering slow webhook via the AdmissionRegistration API 08/22/23 05:03:18.15
STEP: Having no error when timeout is longer than webhook latency 08/22/23 05:03:19.19
STEP: Registering slow webhook via the AdmissionRegistration API 08/22/23 05:03:19.19
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 08/22/23 05:03:24.45
STEP: Registering slow webhook via the AdmissionRegistration API 08/22/23 05:03:24.45
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:03:29.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1219" for this suite. 08/22/23 05:03:29.479
STEP: Destroying namespace "webhook-1219-markers" for this suite. 08/22/23 05:03:29.494
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":233,"skipped":4281,"failed":0}
------------------------------
â€¢ [SLOW TEST] [19.536 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:03:10.906
    Aug 22 05:03:10.906: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 05:03:10.906
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:10.924
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:10.927
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 05:03:10.943
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:03:11.083
    STEP: Deploying the webhook pod 08/22/23 05:03:11.089
    STEP: Wait for the deployment to be ready 08/22/23 05:03:11.368
    Aug 22 05:03:11.779: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 05:03:13.790: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 3, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 3, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 3, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 3, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 05:03:15.795
    STEP: Verifying the service has paired with the endpoint 08/22/23 05:03:15.805
    Aug 22 05:03:16.806: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 08/22/23 05:03:16.811
    STEP: Registering slow webhook via the AdmissionRegistration API 08/22/23 05:03:16.811
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 08/22/23 05:03:16.929
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 08/22/23 05:03:18.15
    STEP: Registering slow webhook via the AdmissionRegistration API 08/22/23 05:03:18.15
    STEP: Having no error when timeout is longer than webhook latency 08/22/23 05:03:19.19
    STEP: Registering slow webhook via the AdmissionRegistration API 08/22/23 05:03:19.19
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 08/22/23 05:03:24.45
    STEP: Registering slow webhook via the AdmissionRegistration API 08/22/23 05:03:24.45
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:03:29.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1219" for this suite. 08/22/23 05:03:29.479
    STEP: Destroying namespace "webhook-1219-markers" for this suite. 08/22/23 05:03:29.494
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:03:30.442
Aug 22 05:03:30.442: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 05:03:30.443
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:30.466
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:30.468
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179
STEP: creating service in namespace services-2427 08/22/23 05:03:30.471
STEP: creating service affinity-clusterip-transition in namespace services-2427 08/22/23 05:03:30.471
STEP: creating replication controller affinity-clusterip-transition in namespace services-2427 08/22/23 05:03:30.483
I0822 05:03:30.492478      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2427, replica count: 3
I0822 05:03:33.543297      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 22 05:03:33.597: INFO: Creating new exec pod
Aug 22 05:03:33.608: INFO: Waiting up to 5m0s for pod "execpod-affinitytwb4k" in namespace "services-2427" to be "running"
Aug 22 05:03:33.614: INFO: Pod "execpod-affinitytwb4k": Phase="Pending", Reason="", readiness=false. Elapsed: 5.87948ms
Aug 22 05:03:35.618: INFO: Pod "execpod-affinitytwb4k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010074997s
Aug 22 05:03:37.618: INFO: Pod "execpod-affinitytwb4k": Phase="Running", Reason="", readiness=true. Elapsed: 4.009792946s
Aug 22 05:03:37.618: INFO: Pod "execpod-affinitytwb4k" satisfied condition "running"
Aug 22 05:03:38.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-2427 exec execpod-affinitytwb4k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Aug 22 05:03:38.761: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Aug 22 05:03:38.761: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 05:03:38.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-2427 exec execpod-affinitytwb4k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.111.107 80'
Aug 22 05:03:38.891: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.111.107 80\nConnection to 10.254.111.107 80 port [tcp/http] succeeded!\n"
Aug 22 05:03:38.891: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 05:03:38.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-2427 exec execpod-affinitytwb4k -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.254.111.107:80/ ; done'
Aug 22 05:03:39.279: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n"
Aug 22 05:03:39.280: INFO: stdout: "\naffinity-clusterip-transition-46njw\naffinity-clusterip-transition-46njw\naffinity-clusterip-transition-46njw\naffinity-clusterip-transition-8pqjc\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-46njw\naffinity-clusterip-transition-8pqjc\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-46njw\naffinity-clusterip-transition-8pqjc\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-46njw\naffinity-clusterip-transition-8pqjc\naffinity-clusterip-transition-8pqjc\naffinity-clusterip-transition-8pqjc\naffinity-clusterip-transition-46njw"
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-46njw
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-46njw
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-46njw
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-8pqjc
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-46njw
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-8pqjc
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-46njw
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-8pqjc
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-46njw
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-8pqjc
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-8pqjc
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-8pqjc
Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-46njw
Aug 22 05:03:39.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-2427 exec execpod-affinitytwb4k -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.254.111.107:80/ ; done'
Aug 22 05:03:39.609: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n"
Aug 22 05:03:39.609: INFO: stdout: "\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b"
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
Aug 22 05:03:39.609: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2427, will wait for the garbage collector to delete the pods 08/22/23 05:03:39.82
Aug 22 05:03:39.885: INFO: Deleting ReplicationController affinity-clusterip-transition took: 10.630103ms
Aug 22 05:03:40.386: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 500.145414ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 05:03:43.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2427" for this suite. 08/22/23 05:03:43.599
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":234,"skipped":4286,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.163 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:03:30.442
    Aug 22 05:03:30.442: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 05:03:30.443
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:30.466
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:30.468
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2179
    STEP: creating service in namespace services-2427 08/22/23 05:03:30.471
    STEP: creating service affinity-clusterip-transition in namespace services-2427 08/22/23 05:03:30.471
    STEP: creating replication controller affinity-clusterip-transition in namespace services-2427 08/22/23 05:03:30.483
    I0822 05:03:30.492478      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2427, replica count: 3
    I0822 05:03:33.543297      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 22 05:03:33.597: INFO: Creating new exec pod
    Aug 22 05:03:33.608: INFO: Waiting up to 5m0s for pod "execpod-affinitytwb4k" in namespace "services-2427" to be "running"
    Aug 22 05:03:33.614: INFO: Pod "execpod-affinitytwb4k": Phase="Pending", Reason="", readiness=false. Elapsed: 5.87948ms
    Aug 22 05:03:35.618: INFO: Pod "execpod-affinitytwb4k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010074997s
    Aug 22 05:03:37.618: INFO: Pod "execpod-affinitytwb4k": Phase="Running", Reason="", readiness=true. Elapsed: 4.009792946s
    Aug 22 05:03:37.618: INFO: Pod "execpod-affinitytwb4k" satisfied condition "running"
    Aug 22 05:03:38.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-2427 exec execpod-affinitytwb4k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Aug 22 05:03:38.761: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Aug 22 05:03:38.761: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 05:03:38.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-2427 exec execpod-affinitytwb4k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.111.107 80'
    Aug 22 05:03:38.891: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.111.107 80\nConnection to 10.254.111.107 80 port [tcp/http] succeeded!\n"
    Aug 22 05:03:38.891: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 05:03:38.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-2427 exec execpod-affinitytwb4k -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.254.111.107:80/ ; done'
    Aug 22 05:03:39.279: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n"
    Aug 22 05:03:39.280: INFO: stdout: "\naffinity-clusterip-transition-46njw\naffinity-clusterip-transition-46njw\naffinity-clusterip-transition-46njw\naffinity-clusterip-transition-8pqjc\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-46njw\naffinity-clusterip-transition-8pqjc\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-46njw\naffinity-clusterip-transition-8pqjc\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-46njw\naffinity-clusterip-transition-8pqjc\naffinity-clusterip-transition-8pqjc\naffinity-clusterip-transition-8pqjc\naffinity-clusterip-transition-46njw"
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-46njw
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-46njw
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-46njw
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-8pqjc
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-46njw
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-8pqjc
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-46njw
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-8pqjc
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-46njw
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-8pqjc
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-8pqjc
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-8pqjc
    Aug 22 05:03:39.280: INFO: Received response from host: affinity-clusterip-transition-46njw
    Aug 22 05:03:39.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-2427 exec execpod-affinitytwb4k -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.254.111.107:80/ ; done'
    Aug 22 05:03:39.609: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.254.111.107:80/\n"
    Aug 22 05:03:39.609: INFO: stdout: "\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b\naffinity-clusterip-transition-85v6b"
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Received response from host: affinity-clusterip-transition-85v6b
    Aug 22 05:03:39.609: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2427, will wait for the garbage collector to delete the pods 08/22/23 05:03:39.82
    Aug 22 05:03:39.885: INFO: Deleting ReplicationController affinity-clusterip-transition took: 10.630103ms
    Aug 22 05:03:40.386: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 500.145414ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 05:03:43.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2427" for this suite. 08/22/23 05:03:43.599
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:03:43.605
Aug 22 05:03:43.606: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename svcaccounts 08/22/23 05:03:43.606
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:43.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:43.693
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Aug 22 05:03:43.715: INFO: created pod pod-service-account-defaultsa
Aug 22 05:03:43.715: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 22 05:03:43.723: INFO: created pod pod-service-account-mountsa
Aug 22 05:03:43.723: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 22 05:03:43.730: INFO: created pod pod-service-account-nomountsa
Aug 22 05:03:43.730: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 22 05:03:43.740: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 22 05:03:43.740: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 22 05:03:43.750: INFO: created pod pod-service-account-mountsa-mountspec
Aug 22 05:03:43.751: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 22 05:03:43.763: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 22 05:03:43.763: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 22 05:03:43.773: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 22 05:03:43.773: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 22 05:03:43.792: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 22 05:03:43.792: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 22 05:03:43.802: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 22 05:03:43.803: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 22 05:03:43.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1146" for this suite. 08/22/23 05:03:43.807
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":235,"skipped":4290,"failed":0}
------------------------------
â€¢ [0.211 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:03:43.605
    Aug 22 05:03:43.606: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename svcaccounts 08/22/23 05:03:43.606
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:43.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:43.693
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Aug 22 05:03:43.715: INFO: created pod pod-service-account-defaultsa
    Aug 22 05:03:43.715: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Aug 22 05:03:43.723: INFO: created pod pod-service-account-mountsa
    Aug 22 05:03:43.723: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Aug 22 05:03:43.730: INFO: created pod pod-service-account-nomountsa
    Aug 22 05:03:43.730: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Aug 22 05:03:43.740: INFO: created pod pod-service-account-defaultsa-mountspec
    Aug 22 05:03:43.740: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Aug 22 05:03:43.750: INFO: created pod pod-service-account-mountsa-mountspec
    Aug 22 05:03:43.751: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Aug 22 05:03:43.763: INFO: created pod pod-service-account-nomountsa-mountspec
    Aug 22 05:03:43.763: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Aug 22 05:03:43.773: INFO: created pod pod-service-account-defaultsa-nomountspec
    Aug 22 05:03:43.773: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Aug 22 05:03:43.792: INFO: created pod pod-service-account-mountsa-nomountspec
    Aug 22 05:03:43.792: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Aug 22 05:03:43.802: INFO: created pod pod-service-account-nomountsa-nomountspec
    Aug 22 05:03:43.803: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 22 05:03:43.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-1146" for this suite. 08/22/23 05:03:43.807
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:03:43.818
Aug 22 05:03:43.818: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename runtimeclass 08/22/23 05:03:43.819
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:43.834
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:43.836
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Aug 22 05:03:43.852: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-1845 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 22 05:03:43.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1845" for this suite. 08/22/23 05:03:43.871
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":236,"skipped":4298,"failed":0}
------------------------------
â€¢ [0.060 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:03:43.818
    Aug 22 05:03:43.818: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename runtimeclass 08/22/23 05:03:43.819
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:43.834
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:43.836
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Aug 22 05:03:43.852: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-1845 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 22 05:03:43.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1845" for this suite. 08/22/23 05:03:43.871
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:03:43.878
Aug 22 05:03:43.878: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename var-expansion 08/22/23 05:03:43.879
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:43.905
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:43.909
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 08/22/23 05:03:43.912
Aug 22 05:03:43.920: INFO: Waiting up to 5m0s for pod "var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa" in namespace "var-expansion-8897" to be "Succeeded or Failed"
Aug 22 05:03:43.924: INFO: Pod "var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa": Phase="Pending", Reason="", readiness=false. Elapsed: 3.2563ms
Aug 22 05:03:45.929: INFO: Pod "var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008585344s
Aug 22 05:03:47.931: INFO: Pod "var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010392721s
Aug 22 05:03:50.407: INFO: Pod "var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.486788754s
STEP: Saw pod success 08/22/23 05:03:50.407
Aug 22 05:03:50.407: INFO: Pod "var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa" satisfied condition "Succeeded or Failed"
Aug 22 05:03:50.410: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa container dapi-container: <nil>
STEP: delete the pod 08/22/23 05:03:50.443
Aug 22 05:03:50.459: INFO: Waiting for pod var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa to disappear
Aug 22 05:03:50.462: INFO: Pod var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 22 05:03:50.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8897" for this suite. 08/22/23 05:03:50.466
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":237,"skipped":4303,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.594 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:03:43.878
    Aug 22 05:03:43.878: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename var-expansion 08/22/23 05:03:43.879
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:43.905
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:43.909
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 08/22/23 05:03:43.912
    Aug 22 05:03:43.920: INFO: Waiting up to 5m0s for pod "var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa" in namespace "var-expansion-8897" to be "Succeeded or Failed"
    Aug 22 05:03:43.924: INFO: Pod "var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa": Phase="Pending", Reason="", readiness=false. Elapsed: 3.2563ms
    Aug 22 05:03:45.929: INFO: Pod "var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008585344s
    Aug 22 05:03:47.931: INFO: Pod "var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010392721s
    Aug 22 05:03:50.407: INFO: Pod "var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.486788754s
    STEP: Saw pod success 08/22/23 05:03:50.407
    Aug 22 05:03:50.407: INFO: Pod "var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa" satisfied condition "Succeeded or Failed"
    Aug 22 05:03:50.410: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa container dapi-container: <nil>
    STEP: delete the pod 08/22/23 05:03:50.443
    Aug 22 05:03:50.459: INFO: Waiting for pod var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa to disappear
    Aug 22 05:03:50.462: INFO: Pod var-expansion-0b95bba7-b7fa-4b55-bb00-c0eeae6f2bfa no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 22 05:03:50.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8897" for this suite. 08/22/23 05:03:50.466
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:03:50.475
Aug 22 05:03:50.475: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 05:03:50.476
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:50.571
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:50.574
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-7f975bdc-4b90-455d-9e7f-0c0e204aafda 08/22/23 05:03:50.577
STEP: Creating a pod to test consume secrets 08/22/23 05:03:50.582
Aug 22 05:03:50.589: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff" in namespace "projected-756" to be "Succeeded or Failed"
Aug 22 05:03:50.592: INFO: Pod "pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff": Phase="Pending", Reason="", readiness=false. Elapsed: 3.027701ms
Aug 22 05:03:52.595: INFO: Pod "pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006072399s
Aug 22 05:03:54.597: INFO: Pod "pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007835362s
Aug 22 05:03:56.596: INFO: Pod "pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007200809s
STEP: Saw pod success 08/22/23 05:03:56.596
Aug 22 05:03:56.596: INFO: Pod "pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff" satisfied condition "Succeeded or Failed"
Aug 22 05:03:56.605: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff container projected-secret-volume-test: <nil>
STEP: delete the pod 08/22/23 05:03:56.611
Aug 22 05:03:57.195: INFO: Waiting for pod pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff to disappear
Aug 22 05:03:57.199: INFO: Pod pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 22 05:03:57.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-756" for this suite. 08/22/23 05:03:57.202
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":238,"skipped":4349,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.733 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:03:50.475
    Aug 22 05:03:50.475: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 05:03:50.476
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:50.571
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:50.574
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-7f975bdc-4b90-455d-9e7f-0c0e204aafda 08/22/23 05:03:50.577
    STEP: Creating a pod to test consume secrets 08/22/23 05:03:50.582
    Aug 22 05:03:50.589: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff" in namespace "projected-756" to be "Succeeded or Failed"
    Aug 22 05:03:50.592: INFO: Pod "pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff": Phase="Pending", Reason="", readiness=false. Elapsed: 3.027701ms
    Aug 22 05:03:52.595: INFO: Pod "pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006072399s
    Aug 22 05:03:54.597: INFO: Pod "pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007835362s
    Aug 22 05:03:56.596: INFO: Pod "pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007200809s
    STEP: Saw pod success 08/22/23 05:03:56.596
    Aug 22 05:03:56.596: INFO: Pod "pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff" satisfied condition "Succeeded or Failed"
    Aug 22 05:03:56.605: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/22/23 05:03:56.611
    Aug 22 05:03:57.195: INFO: Waiting for pod pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff to disappear
    Aug 22 05:03:57.199: INFO: Pod pod-projected-secrets-148e8579-ce0d-4912-bc81-b7ada09f41ff no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 22 05:03:57.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-756" for this suite. 08/22/23 05:03:57.202
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:03:57.209
Aug 22 05:03:57.209: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename resourcequota 08/22/23 05:03:57.209
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:57.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:57.267
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 08/22/23 05:03:57.27
STEP: Creating a ResourceQuota 08/22/23 05:04:02.275
STEP: Ensuring resource quota status is calculated 08/22/23 05:04:02.288
STEP: Creating a Service 08/22/23 05:04:04.293
STEP: Creating a NodePort Service 08/22/23 05:04:04.576
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 08/22/23 05:04:04.618
STEP: Ensuring resource quota status captures service creation 08/22/23 05:04:04.638
STEP: Deleting Services 08/22/23 05:04:06.692
STEP: Ensuring resource quota status released usage 08/22/23 05:04:06.744
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 22 05:04:08.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6356" for this suite. 08/22/23 05:04:08.755
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":239,"skipped":4385,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.553 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:03:57.209
    Aug 22 05:03:57.209: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename resourcequota 08/22/23 05:03:57.209
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:03:57.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:03:57.267
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 08/22/23 05:03:57.27
    STEP: Creating a ResourceQuota 08/22/23 05:04:02.275
    STEP: Ensuring resource quota status is calculated 08/22/23 05:04:02.288
    STEP: Creating a Service 08/22/23 05:04:04.293
    STEP: Creating a NodePort Service 08/22/23 05:04:04.576
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 08/22/23 05:04:04.618
    STEP: Ensuring resource quota status captures service creation 08/22/23 05:04:04.638
    STEP: Deleting Services 08/22/23 05:04:06.692
    STEP: Ensuring resource quota status released usage 08/22/23 05:04:06.744
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 22 05:04:08.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6356" for this suite. 08/22/23 05:04:08.755
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:04:08.762
Aug 22 05:04:08.762: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 05:04:08.763
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:04:08.813
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:04:08.815
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 08/22/23 05:04:08.819
Aug 22 05:04:08.819: INFO: namespace kubectl-8511
Aug 22 05:04:08.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-8511 create -f -'
Aug 22 05:04:09.707: INFO: stderr: ""
Aug 22 05:04:09.707: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 08/22/23 05:04:09.707
Aug 22 05:04:10.712: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 05:04:10.712: INFO: Found 0 / 1
Aug 22 05:04:11.711: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 05:04:11.711: INFO: Found 0 / 1
Aug 22 05:04:13.144: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 05:04:13.144: INFO: Found 0 / 1
Aug 22 05:04:13.822: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 05:04:13.822: INFO: Found 1 / 1
Aug 22 05:04:13.822: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 22 05:04:13.824: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 22 05:04:13.824: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 22 05:04:13.824: INFO: wait on agnhost-primary startup in kubectl-8511 
Aug 22 05:04:13.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-8511 logs agnhost-primary-zrb5r agnhost-primary'
Aug 22 05:04:14.445: INFO: stderr: ""
Aug 22 05:04:14.445: INFO: stdout: "Paused\n"
STEP: exposing RC 08/22/23 05:04:14.446
Aug 22 05:04:14.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-8511 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Aug 22 05:04:14.534: INFO: stderr: ""
Aug 22 05:04:14.534: INFO: stdout: "service/rm2 exposed\n"
Aug 22 05:04:14.543: INFO: Service rm2 in namespace kubectl-8511 found.
STEP: exposing service 08/22/23 05:04:16.549
Aug 22 05:04:16.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-8511 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Aug 22 05:04:16.662: INFO: stderr: ""
Aug 22 05:04:16.662: INFO: stdout: "service/rm3 exposed\n"
Aug 22 05:04:16.670: INFO: Service rm3 in namespace kubectl-8511 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 05:04:18.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8511" for this suite. 08/22/23 05:04:18.681
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":240,"skipped":4413,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.924 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:04:08.762
    Aug 22 05:04:08.762: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 05:04:08.763
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:04:08.813
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:04:08.815
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 08/22/23 05:04:08.819
    Aug 22 05:04:08.819: INFO: namespace kubectl-8511
    Aug 22 05:04:08.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-8511 create -f -'
    Aug 22 05:04:09.707: INFO: stderr: ""
    Aug 22 05:04:09.707: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 08/22/23 05:04:09.707
    Aug 22 05:04:10.712: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 05:04:10.712: INFO: Found 0 / 1
    Aug 22 05:04:11.711: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 05:04:11.711: INFO: Found 0 / 1
    Aug 22 05:04:13.144: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 05:04:13.144: INFO: Found 0 / 1
    Aug 22 05:04:13.822: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 05:04:13.822: INFO: Found 1 / 1
    Aug 22 05:04:13.822: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Aug 22 05:04:13.824: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 22 05:04:13.824: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Aug 22 05:04:13.824: INFO: wait on agnhost-primary startup in kubectl-8511 
    Aug 22 05:04:13.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-8511 logs agnhost-primary-zrb5r agnhost-primary'
    Aug 22 05:04:14.445: INFO: stderr: ""
    Aug 22 05:04:14.445: INFO: stdout: "Paused\n"
    STEP: exposing RC 08/22/23 05:04:14.446
    Aug 22 05:04:14.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-8511 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Aug 22 05:04:14.534: INFO: stderr: ""
    Aug 22 05:04:14.534: INFO: stdout: "service/rm2 exposed\n"
    Aug 22 05:04:14.543: INFO: Service rm2 in namespace kubectl-8511 found.
    STEP: exposing service 08/22/23 05:04:16.549
    Aug 22 05:04:16.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-8511 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Aug 22 05:04:16.662: INFO: stderr: ""
    Aug 22 05:04:16.662: INFO: stdout: "service/rm3 exposed\n"
    Aug 22 05:04:16.670: INFO: Service rm3 in namespace kubectl-8511 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 05:04:18.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8511" for this suite. 08/22/23 05:04:18.681
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:04:18.687
Aug 22 05:04:18.687: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 05:04:18.688
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:04:18.703
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:04:18.705
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 05:04:18.725
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:04:19.036
STEP: Deploying the webhook pod 08/22/23 05:04:19.046
STEP: Wait for the deployment to be ready 08/22/23 05:04:19.135
Aug 22 05:04:19.372: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 05:04:21.379: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 4, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 4, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 4, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 4, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 05:04:23.383
STEP: Verifying the service has paired with the endpoint 08/22/23 05:04:23.602
Aug 22 05:04:24.603: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Aug 22 05:04:24.609: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Registering the custom resource webhook via the AdmissionRegistration API 08/22/23 05:04:25.345
STEP: Creating a custom resource that should be denied by the webhook 08/22/23 05:04:25.537
STEP: Creating a custom resource whose deletion would be denied by the webhook 08/22/23 05:04:27.605
STEP: Updating the custom resource with disallowed data should be denied 08/22/23 05:04:27.613
STEP: Deleting the custom resource should be denied 08/22/23 05:04:27.621
STEP: Remove the offending key and value from the custom resource data 08/22/23 05:04:27.627
STEP: Deleting the updated custom resource should be successful 08/22/23 05:04:27.635
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:04:28.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3766" for this suite. 08/22/23 05:04:28.267
STEP: Destroying namespace "webhook-3766-markers" for this suite. 08/22/23 05:04:28.273
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":241,"skipped":4437,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.990 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:04:18.687
    Aug 22 05:04:18.687: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 05:04:18.688
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:04:18.703
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:04:18.705
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 05:04:18.725
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:04:19.036
    STEP: Deploying the webhook pod 08/22/23 05:04:19.046
    STEP: Wait for the deployment to be ready 08/22/23 05:04:19.135
    Aug 22 05:04:19.372: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 05:04:21.379: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 4, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 4, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 4, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 4, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 05:04:23.383
    STEP: Verifying the service has paired with the endpoint 08/22/23 05:04:23.602
    Aug 22 05:04:24.603: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Aug 22 05:04:24.609: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 08/22/23 05:04:25.345
    STEP: Creating a custom resource that should be denied by the webhook 08/22/23 05:04:25.537
    STEP: Creating a custom resource whose deletion would be denied by the webhook 08/22/23 05:04:27.605
    STEP: Updating the custom resource with disallowed data should be denied 08/22/23 05:04:27.613
    STEP: Deleting the custom resource should be denied 08/22/23 05:04:27.621
    STEP: Remove the offending key and value from the custom resource data 08/22/23 05:04:27.627
    STEP: Deleting the updated custom resource should be successful 08/22/23 05:04:27.635
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:04:28.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3766" for this suite. 08/22/23 05:04:28.267
    STEP: Destroying namespace "webhook-3766-markers" for this suite. 08/22/23 05:04:28.273
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:04:28.678
Aug 22 05:04:28.678: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename sched-pred 08/22/23 05:04:28.679
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:04:29.078
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:04:29.08
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug 22 05:04:29.082: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 22 05:04:29.088: INFO: Waiting for terminating namespaces to be deleted...
Aug 22 05:04:29.091: INFO: 
Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-0 before test
Aug 22 05:04:29.096: INFO: csi-cinder-nodeplugin-zmsc8 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (3 container statuses recorded)
Aug 22 05:04:29.096: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Aug 22 05:04:29.096: INFO: 	Container liveness-probe ready: true, restart count 0
Aug 22 05:04:29.096: INFO: 	Container node-driver-registrar ready: true, restart count 0
Aug 22 05:04:29.096: INFO: kube-dns-autoscaler-96fb49f55-c54df from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
Aug 22 05:04:29.096: INFO: 	Container autoscaler ready: true, restart count 0
Aug 22 05:04:29.096: INFO: kube-flannel-ds-m6hb5 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (1 container statuses recorded)
Aug 22 05:04:29.096: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 22 05:04:29.096: INFO: magnum-metrics-server-758ff97b5-qfdbj from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
Aug 22 05:04:29.096: INFO: 	Container metrics-server ready: true, restart count 0
Aug 22 05:04:29.096: INFO: npd-z88sb from kube-system started at 2023-08-17 07:08:01 +0000 UTC (1 container statuses recorded)
Aug 22 05:04:29.096: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug 22 05:04:29.096: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-gklhn from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 05:04:29.096: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 05:04:29.096: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 05:04:29.096: INFO: pod-service-account-mountsa from svcaccounts-1146 started at 2023-08-22 05:03:43 +0000 UTC (1 container statuses recorded)
Aug 22 05:04:29.096: INFO: 	Container token-test ready: false, restart count 0
Aug 22 05:04:29.096: INFO: pod-service-account-mountsa-mountspec from svcaccounts-1146 started at 2023-08-22 05:03:43 +0000 UTC (1 container statuses recorded)
Aug 22 05:04:29.096: INFO: 	Container token-test ready: false, restart count 0
Aug 22 05:04:29.096: INFO: 
Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-1 before test
Aug 22 05:04:29.102: INFO: csi-cinder-nodeplugin-jmnz5 from kube-system started at 2023-08-22 03:43:22 +0000 UTC (3 container statuses recorded)
Aug 22 05:04:29.102: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Aug 22 05:04:29.102: INFO: 	Container liveness-probe ready: true, restart count 0
Aug 22 05:04:29.102: INFO: 	Container node-driver-registrar ready: true, restart count 0
Aug 22 05:04:29.102: INFO: kube-flannel-ds-pc26k from kube-system started at 2023-08-22 03:43:22 +0000 UTC (1 container statuses recorded)
Aug 22 05:04:29.102: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 22 05:04:29.102: INFO: npd-jxn7d from kube-system started at 2023-08-22 03:43:42 +0000 UTC (1 container statuses recorded)
Aug 22 05:04:29.102: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug 22 05:04:29.102: INFO: sonobuoy-e2e-job-95e99bb4c3804681 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 05:04:29.102: INFO: 	Container e2e ready: true, restart count 0
Aug 22 05:04:29.102: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 05:04:29.102: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-mmzwp from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 05:04:29.102: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 05:04:29.102: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 05:04:29.102: INFO: pod-service-account-defaultsa-mountspec from svcaccounts-1146 started at 2023-08-22 05:03:43 +0000 UTC (1 container statuses recorded)
Aug 22 05:04:29.102: INFO: 	Container token-test ready: false, restart count 0
Aug 22 05:04:29.102: INFO: pod-service-account-nomountsa-mountspec from svcaccounts-1146 started at 2023-08-22 05:03:43 +0000 UTC (1 container statuses recorded)
Aug 22 05:04:29.102: INFO: 	Container token-test ready: false, restart count 0
Aug 22 05:04:29.102: INFO: 
Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-2 before test
Aug 22 05:04:29.107: INFO: csi-cinder-nodeplugin-6xsh5 from kube-system started at 2023-08-22 03:43:15 +0000 UTC (3 container statuses recorded)
Aug 22 05:04:29.107: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Aug 22 05:04:29.107: INFO: 	Container liveness-probe ready: true, restart count 0
Aug 22 05:04:29.107: INFO: 	Container node-driver-registrar ready: true, restart count 0
Aug 22 05:04:29.107: INFO: kube-flannel-ds-trqzn from kube-system started at 2023-08-22 04:45:29 +0000 UTC (1 container statuses recorded)
Aug 22 05:04:29.107: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 22 05:04:29.107: INFO: npd-cwq76 from kube-system started at 2023-08-22 03:43:35 +0000 UTC (1 container statuses recorded)
Aug 22 05:04:29.107: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug 22 05:04:29.107: INFO: sonobuoy from sonobuoy started at 2023-08-22 03:50:01 +0000 UTC (1 container statuses recorded)
Aug 22 05:04:29.107: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 22 05:04:29.107: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-6dms5 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 05:04:29.107: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 05:04:29.107: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 05:04:29.107: INFO: pod-service-account-defaultsa from svcaccounts-1146 started at 2023-08-22 05:03:43 +0000 UTC (1 container statuses recorded)
Aug 22 05:04:29.107: INFO: 	Container token-test ready: false, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node jake-melb-gmyyva4zrlsz-node-0 08/22/23 05:04:29.133
STEP: verifying the node has the label node jake-melb-gmyyva4zrlsz-node-1 08/22/23 05:04:29.162
STEP: verifying the node has the label node jake-melb-gmyyva4zrlsz-node-2 08/22/23 05:04:29.324
Aug 22 05:04:29.337: INFO: Pod csi-cinder-nodeplugin-6xsh5 requesting resource cpu=20m on Node jake-melb-gmyyva4zrlsz-node-2
Aug 22 05:04:29.337: INFO: Pod csi-cinder-nodeplugin-jmnz5 requesting resource cpu=20m on Node jake-melb-gmyyva4zrlsz-node-1
Aug 22 05:04:29.337: INFO: Pod csi-cinder-nodeplugin-zmsc8 requesting resource cpu=20m on Node jake-melb-gmyyva4zrlsz-node-0
Aug 22 05:04:29.337: INFO: Pod kube-dns-autoscaler-96fb49f55-c54df requesting resource cpu=20m on Node jake-melb-gmyyva4zrlsz-node-0
Aug 22 05:04:29.337: INFO: Pod kube-flannel-ds-m6hb5 requesting resource cpu=100m on Node jake-melb-gmyyva4zrlsz-node-0
Aug 22 05:04:29.337: INFO: Pod kube-flannel-ds-pc26k requesting resource cpu=100m on Node jake-melb-gmyyva4zrlsz-node-1
Aug 22 05:04:29.337: INFO: Pod kube-flannel-ds-trqzn requesting resource cpu=100m on Node jake-melb-gmyyva4zrlsz-node-2
Aug 22 05:04:29.337: INFO: Pod magnum-metrics-server-758ff97b5-qfdbj requesting resource cpu=100m on Node jake-melb-gmyyva4zrlsz-node-0
Aug 22 05:04:29.337: INFO: Pod npd-cwq76 requesting resource cpu=20m on Node jake-melb-gmyyva4zrlsz-node-2
Aug 22 05:04:29.337: INFO: Pod npd-jxn7d requesting resource cpu=20m on Node jake-melb-gmyyva4zrlsz-node-1
Aug 22 05:04:29.337: INFO: Pod npd-z88sb requesting resource cpu=20m on Node jake-melb-gmyyva4zrlsz-node-0
Aug 22 05:04:29.337: INFO: Pod sonobuoy requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-2
Aug 22 05:04:29.337: INFO: Pod sonobuoy-e2e-job-95e99bb4c3804681 requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-1
Aug 22 05:04:29.337: INFO: Pod sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-6dms5 requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-2
Aug 22 05:04:29.337: INFO: Pod sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-gklhn requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-0
Aug 22 05:04:29.337: INFO: Pod sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-mmzwp requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-1
Aug 22 05:04:29.337: INFO: Pod pod-service-account-defaultsa requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-2
Aug 22 05:04:29.337: INFO: Pod pod-service-account-defaultsa-mountspec requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-1
Aug 22 05:04:29.337: INFO: Pod pod-service-account-mountsa requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-0
Aug 22 05:04:29.337: INFO: Pod pod-service-account-mountsa-mountspec requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-0
Aug 22 05:04:29.337: INFO: Pod pod-service-account-nomountsa-mountspec requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-1
STEP: Starting Pods to consume most of the cluster CPU. 08/22/23 05:04:29.337
Aug 22 05:04:29.337: INFO: Creating a pod which consumes cpu=1218m on Node jake-melb-gmyyva4zrlsz-node-0
Aug 22 05:04:29.346: INFO: Creating a pod which consumes cpu=1302m on Node jake-melb-gmyyva4zrlsz-node-1
Aug 22 05:04:29.540: INFO: Creating a pod which consumes cpu=1302m on Node jake-melb-gmyyva4zrlsz-node-2
Aug 22 05:04:29.551: INFO: Waiting up to 5m0s for pod "filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393" in namespace "sched-pred-7580" to be "running"
Aug 22 05:04:29.560: INFO: Pod "filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393": Phase="Pending", Reason="", readiness=false. Elapsed: 8.408145ms
Aug 22 05:04:31.562: INFO: Pod "filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011138614s
Aug 22 05:04:33.658: INFO: Pod "filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393": Phase="Running", Reason="", readiness=true. Elapsed: 4.106611427s
Aug 22 05:04:33.658: INFO: Pod "filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393" satisfied condition "running"
Aug 22 05:04:33.658: INFO: Waiting up to 5m0s for pod "filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51" in namespace "sched-pred-7580" to be "running"
Aug 22 05:04:33.661: INFO: Pod "filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51": Phase="Pending", Reason="", readiness=false. Elapsed: 3.477764ms
Aug 22 05:04:35.665: INFO: Pod "filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51": Phase="Running", Reason="", readiness=true. Elapsed: 2.006857411s
Aug 22 05:04:35.665: INFO: Pod "filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51" satisfied condition "running"
Aug 22 05:04:35.665: INFO: Waiting up to 5m0s for pod "filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846" in namespace "sched-pred-7580" to be "running"
Aug 22 05:04:35.668: INFO: Pod "filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846": Phase="Running", Reason="", readiness=true. Elapsed: 3.474038ms
Aug 22 05:04:35.668: INFO: Pod "filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 08/22/23 05:04:35.668
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393.177d9c19bf058d8f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7580/filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393 to jake-melb-gmyyva4zrlsz-node-0] 08/22/23 05:04:35.672
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393.177d9c1a332127c2], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 08/22/23 05:04:35.672
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393.177d9c1a360dceb5], Reason = [Created], Message = [Created container filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393] 08/22/23 05:04:35.672
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393.177d9c1a3962b58f], Reason = [Started], Message = [Started container filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393] 08/22/23 05:04:35.672
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51.177d9c19c03c21c9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7580/filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51 to jake-melb-gmyyva4zrlsz-node-1] 08/22/23 05:04:35.672
STEP: Considering event: 
Type = [Warning], Name = [filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51.177d9c1a12025228], Reason = [FailedMount], Message = [MountVolume.SetUp failed for volume "kube-api-access-ndrd9" : failed to sync configmap cache: timed out waiting for the condition] 08/22/23 05:04:35.672
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51.177d9c1aa6b4768a], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 08/22/23 05:04:35.672
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51.177d9c1aaad7e9e1], Reason = [Created], Message = [Created container filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51] 08/22/23 05:04:35.672
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51.177d9c1ab5f25018], Reason = [Started], Message = [Started container filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51] 08/22/23 05:04:35.672
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846.177d9c19d605d8cb], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7580/filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846 to jake-melb-gmyyva4zrlsz-node-2] 08/22/23 05:04:35.672
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846.177d9c1a3e17119b], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 08/22/23 05:04:35.672
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846.177d9c1a3f72d64f], Reason = [Created], Message = [Created container filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846] 08/22/23 05:04:35.672
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846.177d9c1a43579a88], Reason = [Started], Message = [Started container filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846] 08/22/23 05:04:35.672
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.177d9c1b3e689e1f], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) had untolerated taint {node-role.kubernetes.io/master: }. preemption: 0/6 nodes are available: 3 No preemption victims found for incoming pod, 3 Preemption is not helpful for scheduling.] 08/22/23 05:04:35.812
STEP: removing the label node off the node jake-melb-gmyyva4zrlsz-node-1 08/22/23 05:04:36.705
STEP: verifying the node doesn't have the label node 08/22/23 05:04:36.848
STEP: removing the label node off the node jake-melb-gmyyva4zrlsz-node-2 08/22/23 05:04:36.852
STEP: verifying the node doesn't have the label node 08/22/23 05:04:37.117
STEP: removing the label node off the node jake-melb-gmyyva4zrlsz-node-0 08/22/23 05:04:37.121
STEP: verifying the node doesn't have the label node 08/22/23 05:04:37.134
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Aug 22 05:04:37.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7580" for this suite. 08/22/23 05:04:37.141
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":242,"skipped":4444,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.469 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:04:28.678
    Aug 22 05:04:28.678: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename sched-pred 08/22/23 05:04:28.679
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:04:29.078
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:04:29.08
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Aug 22 05:04:29.082: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Aug 22 05:04:29.088: INFO: Waiting for terminating namespaces to be deleted...
    Aug 22 05:04:29.091: INFO: 
    Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-0 before test
    Aug 22 05:04:29.096: INFO: csi-cinder-nodeplugin-zmsc8 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (3 container statuses recorded)
    Aug 22 05:04:29.096: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
    Aug 22 05:04:29.096: INFO: 	Container liveness-probe ready: true, restart count 0
    Aug 22 05:04:29.096: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Aug 22 05:04:29.096: INFO: kube-dns-autoscaler-96fb49f55-c54df from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
    Aug 22 05:04:29.096: INFO: 	Container autoscaler ready: true, restart count 0
    Aug 22 05:04:29.096: INFO: kube-flannel-ds-m6hb5 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (1 container statuses recorded)
    Aug 22 05:04:29.096: INFO: 	Container kube-flannel ready: true, restart count 0
    Aug 22 05:04:29.096: INFO: magnum-metrics-server-758ff97b5-qfdbj from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
    Aug 22 05:04:29.096: INFO: 	Container metrics-server ready: true, restart count 0
    Aug 22 05:04:29.096: INFO: npd-z88sb from kube-system started at 2023-08-17 07:08:01 +0000 UTC (1 container statuses recorded)
    Aug 22 05:04:29.096: INFO: 	Container node-problem-detector ready: true, restart count 0
    Aug 22 05:04:29.096: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-gklhn from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 05:04:29.096: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 05:04:29.096: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 22 05:04:29.096: INFO: pod-service-account-mountsa from svcaccounts-1146 started at 2023-08-22 05:03:43 +0000 UTC (1 container statuses recorded)
    Aug 22 05:04:29.096: INFO: 	Container token-test ready: false, restart count 0
    Aug 22 05:04:29.096: INFO: pod-service-account-mountsa-mountspec from svcaccounts-1146 started at 2023-08-22 05:03:43 +0000 UTC (1 container statuses recorded)
    Aug 22 05:04:29.096: INFO: 	Container token-test ready: false, restart count 0
    Aug 22 05:04:29.096: INFO: 
    Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-1 before test
    Aug 22 05:04:29.102: INFO: csi-cinder-nodeplugin-jmnz5 from kube-system started at 2023-08-22 03:43:22 +0000 UTC (3 container statuses recorded)
    Aug 22 05:04:29.102: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
    Aug 22 05:04:29.102: INFO: 	Container liveness-probe ready: true, restart count 0
    Aug 22 05:04:29.102: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Aug 22 05:04:29.102: INFO: kube-flannel-ds-pc26k from kube-system started at 2023-08-22 03:43:22 +0000 UTC (1 container statuses recorded)
    Aug 22 05:04:29.102: INFO: 	Container kube-flannel ready: true, restart count 0
    Aug 22 05:04:29.102: INFO: npd-jxn7d from kube-system started at 2023-08-22 03:43:42 +0000 UTC (1 container statuses recorded)
    Aug 22 05:04:29.102: INFO: 	Container node-problem-detector ready: true, restart count 0
    Aug 22 05:04:29.102: INFO: sonobuoy-e2e-job-95e99bb4c3804681 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 05:04:29.102: INFO: 	Container e2e ready: true, restart count 0
    Aug 22 05:04:29.102: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 05:04:29.102: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-mmzwp from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 05:04:29.102: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 05:04:29.102: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 22 05:04:29.102: INFO: pod-service-account-defaultsa-mountspec from svcaccounts-1146 started at 2023-08-22 05:03:43 +0000 UTC (1 container statuses recorded)
    Aug 22 05:04:29.102: INFO: 	Container token-test ready: false, restart count 0
    Aug 22 05:04:29.102: INFO: pod-service-account-nomountsa-mountspec from svcaccounts-1146 started at 2023-08-22 05:03:43 +0000 UTC (1 container statuses recorded)
    Aug 22 05:04:29.102: INFO: 	Container token-test ready: false, restart count 0
    Aug 22 05:04:29.102: INFO: 
    Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-2 before test
    Aug 22 05:04:29.107: INFO: csi-cinder-nodeplugin-6xsh5 from kube-system started at 2023-08-22 03:43:15 +0000 UTC (3 container statuses recorded)
    Aug 22 05:04:29.107: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
    Aug 22 05:04:29.107: INFO: 	Container liveness-probe ready: true, restart count 0
    Aug 22 05:04:29.107: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Aug 22 05:04:29.107: INFO: kube-flannel-ds-trqzn from kube-system started at 2023-08-22 04:45:29 +0000 UTC (1 container statuses recorded)
    Aug 22 05:04:29.107: INFO: 	Container kube-flannel ready: true, restart count 0
    Aug 22 05:04:29.107: INFO: npd-cwq76 from kube-system started at 2023-08-22 03:43:35 +0000 UTC (1 container statuses recorded)
    Aug 22 05:04:29.107: INFO: 	Container node-problem-detector ready: true, restart count 0
    Aug 22 05:04:29.107: INFO: sonobuoy from sonobuoy started at 2023-08-22 03:50:01 +0000 UTC (1 container statuses recorded)
    Aug 22 05:04:29.107: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Aug 22 05:04:29.107: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-6dms5 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 05:04:29.107: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 05:04:29.107: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 22 05:04:29.107: INFO: pod-service-account-defaultsa from svcaccounts-1146 started at 2023-08-22 05:03:43 +0000 UTC (1 container statuses recorded)
    Aug 22 05:04:29.107: INFO: 	Container token-test ready: false, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node jake-melb-gmyyva4zrlsz-node-0 08/22/23 05:04:29.133
    STEP: verifying the node has the label node jake-melb-gmyyva4zrlsz-node-1 08/22/23 05:04:29.162
    STEP: verifying the node has the label node jake-melb-gmyyva4zrlsz-node-2 08/22/23 05:04:29.324
    Aug 22 05:04:29.337: INFO: Pod csi-cinder-nodeplugin-6xsh5 requesting resource cpu=20m on Node jake-melb-gmyyva4zrlsz-node-2
    Aug 22 05:04:29.337: INFO: Pod csi-cinder-nodeplugin-jmnz5 requesting resource cpu=20m on Node jake-melb-gmyyva4zrlsz-node-1
    Aug 22 05:04:29.337: INFO: Pod csi-cinder-nodeplugin-zmsc8 requesting resource cpu=20m on Node jake-melb-gmyyva4zrlsz-node-0
    Aug 22 05:04:29.337: INFO: Pod kube-dns-autoscaler-96fb49f55-c54df requesting resource cpu=20m on Node jake-melb-gmyyva4zrlsz-node-0
    Aug 22 05:04:29.337: INFO: Pod kube-flannel-ds-m6hb5 requesting resource cpu=100m on Node jake-melb-gmyyva4zrlsz-node-0
    Aug 22 05:04:29.337: INFO: Pod kube-flannel-ds-pc26k requesting resource cpu=100m on Node jake-melb-gmyyva4zrlsz-node-1
    Aug 22 05:04:29.337: INFO: Pod kube-flannel-ds-trqzn requesting resource cpu=100m on Node jake-melb-gmyyva4zrlsz-node-2
    Aug 22 05:04:29.337: INFO: Pod magnum-metrics-server-758ff97b5-qfdbj requesting resource cpu=100m on Node jake-melb-gmyyva4zrlsz-node-0
    Aug 22 05:04:29.337: INFO: Pod npd-cwq76 requesting resource cpu=20m on Node jake-melb-gmyyva4zrlsz-node-2
    Aug 22 05:04:29.337: INFO: Pod npd-jxn7d requesting resource cpu=20m on Node jake-melb-gmyyva4zrlsz-node-1
    Aug 22 05:04:29.337: INFO: Pod npd-z88sb requesting resource cpu=20m on Node jake-melb-gmyyva4zrlsz-node-0
    Aug 22 05:04:29.337: INFO: Pod sonobuoy requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-2
    Aug 22 05:04:29.337: INFO: Pod sonobuoy-e2e-job-95e99bb4c3804681 requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-1
    Aug 22 05:04:29.337: INFO: Pod sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-6dms5 requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-2
    Aug 22 05:04:29.337: INFO: Pod sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-gklhn requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-0
    Aug 22 05:04:29.337: INFO: Pod sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-mmzwp requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-1
    Aug 22 05:04:29.337: INFO: Pod pod-service-account-defaultsa requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-2
    Aug 22 05:04:29.337: INFO: Pod pod-service-account-defaultsa-mountspec requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-1
    Aug 22 05:04:29.337: INFO: Pod pod-service-account-mountsa requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-0
    Aug 22 05:04:29.337: INFO: Pod pod-service-account-mountsa-mountspec requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-0
    Aug 22 05:04:29.337: INFO: Pod pod-service-account-nomountsa-mountspec requesting resource cpu=0m on Node jake-melb-gmyyva4zrlsz-node-1
    STEP: Starting Pods to consume most of the cluster CPU. 08/22/23 05:04:29.337
    Aug 22 05:04:29.337: INFO: Creating a pod which consumes cpu=1218m on Node jake-melb-gmyyva4zrlsz-node-0
    Aug 22 05:04:29.346: INFO: Creating a pod which consumes cpu=1302m on Node jake-melb-gmyyva4zrlsz-node-1
    Aug 22 05:04:29.540: INFO: Creating a pod which consumes cpu=1302m on Node jake-melb-gmyyva4zrlsz-node-2
    Aug 22 05:04:29.551: INFO: Waiting up to 5m0s for pod "filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393" in namespace "sched-pred-7580" to be "running"
    Aug 22 05:04:29.560: INFO: Pod "filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393": Phase="Pending", Reason="", readiness=false. Elapsed: 8.408145ms
    Aug 22 05:04:31.562: INFO: Pod "filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011138614s
    Aug 22 05:04:33.658: INFO: Pod "filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393": Phase="Running", Reason="", readiness=true. Elapsed: 4.106611427s
    Aug 22 05:04:33.658: INFO: Pod "filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393" satisfied condition "running"
    Aug 22 05:04:33.658: INFO: Waiting up to 5m0s for pod "filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51" in namespace "sched-pred-7580" to be "running"
    Aug 22 05:04:33.661: INFO: Pod "filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51": Phase="Pending", Reason="", readiness=false. Elapsed: 3.477764ms
    Aug 22 05:04:35.665: INFO: Pod "filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51": Phase="Running", Reason="", readiness=true. Elapsed: 2.006857411s
    Aug 22 05:04:35.665: INFO: Pod "filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51" satisfied condition "running"
    Aug 22 05:04:35.665: INFO: Waiting up to 5m0s for pod "filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846" in namespace "sched-pred-7580" to be "running"
    Aug 22 05:04:35.668: INFO: Pod "filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846": Phase="Running", Reason="", readiness=true. Elapsed: 3.474038ms
    Aug 22 05:04:35.668: INFO: Pod "filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 08/22/23 05:04:35.668
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393.177d9c19bf058d8f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7580/filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393 to jake-melb-gmyyva4zrlsz-node-0] 08/22/23 05:04:35.672
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393.177d9c1a332127c2], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 08/22/23 05:04:35.672
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393.177d9c1a360dceb5], Reason = [Created], Message = [Created container filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393] 08/22/23 05:04:35.672
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393.177d9c1a3962b58f], Reason = [Started], Message = [Started container filler-pod-1e2c9b2e-c8bd-4b91-b46b-f140aa23b393] 08/22/23 05:04:35.672
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51.177d9c19c03c21c9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7580/filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51 to jake-melb-gmyyva4zrlsz-node-1] 08/22/23 05:04:35.672
    STEP: Considering event: 
    Type = [Warning], Name = [filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51.177d9c1a12025228], Reason = [FailedMount], Message = [MountVolume.SetUp failed for volume "kube-api-access-ndrd9" : failed to sync configmap cache: timed out waiting for the condition] 08/22/23 05:04:35.672
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51.177d9c1aa6b4768a], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 08/22/23 05:04:35.672
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51.177d9c1aaad7e9e1], Reason = [Created], Message = [Created container filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51] 08/22/23 05:04:35.672
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51.177d9c1ab5f25018], Reason = [Started], Message = [Started container filler-pod-679ff2a9-9fdf-4e63-891c-1ad082186b51] 08/22/23 05:04:35.672
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846.177d9c19d605d8cb], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7580/filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846 to jake-melb-gmyyva4zrlsz-node-2] 08/22/23 05:04:35.672
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846.177d9c1a3e17119b], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 08/22/23 05:04:35.672
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846.177d9c1a3f72d64f], Reason = [Created], Message = [Created container filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846] 08/22/23 05:04:35.672
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846.177d9c1a43579a88], Reason = [Started], Message = [Started container filler-pod-dc749c46-eea6-4d20-80e9-bfb84384f846] 08/22/23 05:04:35.672
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.177d9c1b3e689e1f], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) had untolerated taint {node-role.kubernetes.io/master: }. preemption: 0/6 nodes are available: 3 No preemption victims found for incoming pod, 3 Preemption is not helpful for scheduling.] 08/22/23 05:04:35.812
    STEP: removing the label node off the node jake-melb-gmyyva4zrlsz-node-1 08/22/23 05:04:36.705
    STEP: verifying the node doesn't have the label node 08/22/23 05:04:36.848
    STEP: removing the label node off the node jake-melb-gmyyva4zrlsz-node-2 08/22/23 05:04:36.852
    STEP: verifying the node doesn't have the label node 08/22/23 05:04:37.117
    STEP: removing the label node off the node jake-melb-gmyyva4zrlsz-node-0 08/22/23 05:04:37.121
    STEP: verifying the node doesn't have the label node 08/22/23 05:04:37.134
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 05:04:37.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-7580" for this suite. 08/22/23 05:04:37.141
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:04:37.147
Aug 22 05:04:37.147: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pod-network-test 08/22/23 05:04:37.148
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:04:37.227
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:04:37.23
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-4108 08/22/23 05:04:37.233
STEP: creating a selector 08/22/23 05:04:37.233
STEP: Creating the service pods in kubernetes 08/22/23 05:04:37.233
Aug 22 05:04:37.233: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 22 05:04:37.258: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4108" to be "running and ready"
Aug 22 05:04:37.261: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.713611ms
Aug 22 05:04:37.261: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:04:39.265: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007401763s
Aug 22 05:04:39.266: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:04:41.264: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.006023693s
Aug 22 05:04:41.264: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:04:43.264: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.006337828s
Aug 22 05:04:43.264: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:04:45.266: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.007792263s
Aug 22 05:04:45.266: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:04:47.264: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.006051843s
Aug 22 05:04:47.264: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:04:49.264: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.006164321s
Aug 22 05:04:49.264: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:04:51.266: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.007840222s
Aug 22 05:04:51.266: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:04:53.265: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.00679646s
Aug 22 05:04:53.265: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:04:55.266: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.007548126s
Aug 22 05:04:55.266: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:04:57.264: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.006336828s
Aug 22 05:04:57.264: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:04:59.265: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.007145854s
Aug 22 05:04:59.265: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Aug 22 05:04:59.265: INFO: Pod "netserver-0" satisfied condition "running and ready"
Aug 22 05:04:59.268: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4108" to be "running and ready"
Aug 22 05:04:59.271: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.010307ms
Aug 22 05:04:59.271: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Aug 22 05:04:59.271: INFO: Pod "netserver-1" satisfied condition "running and ready"
Aug 22 05:04:59.273: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-4108" to be "running and ready"
Aug 22 05:04:59.276: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.438315ms
Aug 22 05:04:59.276: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Aug 22 05:04:59.276: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 08/22/23 05:04:59.278
Aug 22 05:05:00.241: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4108" to be "running"
Aug 22 05:05:00.245: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.366005ms
Aug 22 05:05:02.249: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007374342s
Aug 22 05:05:04.249: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.00787672s
Aug 22 05:05:04.249: INFO: Pod "test-container-pod" satisfied condition "running"
Aug 22 05:05:04.251: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-4108" to be "running"
Aug 22 05:05:04.254: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.863252ms
Aug 22 05:05:04.254: INFO: Pod "host-test-container-pod" satisfied condition "running"
Aug 22 05:05:04.256: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Aug 22 05:05:04.256: INFO: Going to poll 10.100.3.170 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Aug 22 05:05:04.258: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.100.3.170:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4108 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:05:04.258: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:05:04.258: INFO: ExecWithOptions: Clientset creation
Aug 22 05:05:04.259: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-4108/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.100.3.170%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 22 05:05:04.350: INFO: Found all 1 expected endpoints: [netserver-0]
Aug 22 05:05:04.350: INFO: Going to poll 10.100.5.118 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Aug 22 05:05:04.354: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.100.5.118:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4108 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:05:04.354: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:05:04.354: INFO: ExecWithOptions: Clientset creation
Aug 22 05:05:04.354: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-4108/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.100.5.118%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 22 05:05:04.442: INFO: Found all 1 expected endpoints: [netserver-1]
Aug 22 05:05:04.442: INFO: Going to poll 10.100.4.8 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Aug 22 05:05:04.446: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.100.4.8:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4108 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:05:04.446: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:05:04.446: INFO: ExecWithOptions: Clientset creation
Aug 22 05:05:04.446: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-4108/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.100.4.8%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 22 05:05:04.522: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Aug 22 05:05:04.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4108" for this suite. 08/22/23 05:05:04.527
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":243,"skipped":4472,"failed":0}
------------------------------
â€¢ [SLOW TEST] [27.387 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:04:37.147
    Aug 22 05:04:37.147: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pod-network-test 08/22/23 05:04:37.148
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:04:37.227
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:04:37.23
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-4108 08/22/23 05:04:37.233
    STEP: creating a selector 08/22/23 05:04:37.233
    STEP: Creating the service pods in kubernetes 08/22/23 05:04:37.233
    Aug 22 05:04:37.233: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Aug 22 05:04:37.258: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4108" to be "running and ready"
    Aug 22 05:04:37.261: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.713611ms
    Aug 22 05:04:37.261: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:04:39.265: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007401763s
    Aug 22 05:04:39.266: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:04:41.264: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.006023693s
    Aug 22 05:04:41.264: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:04:43.264: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.006337828s
    Aug 22 05:04:43.264: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:04:45.266: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.007792263s
    Aug 22 05:04:45.266: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:04:47.264: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.006051843s
    Aug 22 05:04:47.264: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:04:49.264: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.006164321s
    Aug 22 05:04:49.264: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:04:51.266: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.007840222s
    Aug 22 05:04:51.266: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:04:53.265: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.00679646s
    Aug 22 05:04:53.265: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:04:55.266: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.007548126s
    Aug 22 05:04:55.266: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:04:57.264: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.006336828s
    Aug 22 05:04:57.264: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:04:59.265: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.007145854s
    Aug 22 05:04:59.265: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Aug 22 05:04:59.265: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Aug 22 05:04:59.268: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4108" to be "running and ready"
    Aug 22 05:04:59.271: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.010307ms
    Aug 22 05:04:59.271: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Aug 22 05:04:59.271: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Aug 22 05:04:59.273: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-4108" to be "running and ready"
    Aug 22 05:04:59.276: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.438315ms
    Aug 22 05:04:59.276: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Aug 22 05:04:59.276: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 08/22/23 05:04:59.278
    Aug 22 05:05:00.241: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4108" to be "running"
    Aug 22 05:05:00.245: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.366005ms
    Aug 22 05:05:02.249: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007374342s
    Aug 22 05:05:04.249: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.00787672s
    Aug 22 05:05:04.249: INFO: Pod "test-container-pod" satisfied condition "running"
    Aug 22 05:05:04.251: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-4108" to be "running"
    Aug 22 05:05:04.254: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.863252ms
    Aug 22 05:05:04.254: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Aug 22 05:05:04.256: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Aug 22 05:05:04.256: INFO: Going to poll 10.100.3.170 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Aug 22 05:05:04.258: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.100.3.170:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4108 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:05:04.258: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:05:04.258: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:05:04.259: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-4108/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.100.3.170%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 22 05:05:04.350: INFO: Found all 1 expected endpoints: [netserver-0]
    Aug 22 05:05:04.350: INFO: Going to poll 10.100.5.118 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Aug 22 05:05:04.354: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.100.5.118:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4108 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:05:04.354: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:05:04.354: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:05:04.354: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-4108/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.100.5.118%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 22 05:05:04.442: INFO: Found all 1 expected endpoints: [netserver-1]
    Aug 22 05:05:04.442: INFO: Going to poll 10.100.4.8 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Aug 22 05:05:04.446: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.100.4.8:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4108 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:05:04.446: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:05:04.446: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:05:04.446: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-4108/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.100.4.8%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 22 05:05:04.522: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Aug 22 05:05:04.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-4108" for this suite. 08/22/23 05:05:04.527
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:05:04.536
Aug 22 05:05:04.536: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename resourcequota 08/22/23 05:05:04.536
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:05:05.01
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:05:05.014
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 08/22/23 05:05:05.018
STEP: Creating a ResourceQuota 08/22/23 05:05:10.023
STEP: Ensuring resource quota status is calculated 08/22/23 05:05:10.155
STEP: Creating a ReplicaSet 08/22/23 05:05:12.173
STEP: Ensuring resource quota status captures replicaset creation 08/22/23 05:05:12.354
STEP: Deleting a ReplicaSet 08/22/23 05:05:14.358
STEP: Ensuring resource quota status released usage 08/22/23 05:05:14.381
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 22 05:05:16.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8595" for this suite. 08/22/23 05:05:16.39
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":244,"skipped":4474,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.861 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:05:04.536
    Aug 22 05:05:04.536: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename resourcequota 08/22/23 05:05:04.536
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:05:05.01
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:05:05.014
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 08/22/23 05:05:05.018
    STEP: Creating a ResourceQuota 08/22/23 05:05:10.023
    STEP: Ensuring resource quota status is calculated 08/22/23 05:05:10.155
    STEP: Creating a ReplicaSet 08/22/23 05:05:12.173
    STEP: Ensuring resource quota status captures replicaset creation 08/22/23 05:05:12.354
    STEP: Deleting a ReplicaSet 08/22/23 05:05:14.358
    STEP: Ensuring resource quota status released usage 08/22/23 05:05:14.381
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 22 05:05:16.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8595" for this suite. 08/22/23 05:05:16.39
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:05:16.398
Aug 22 05:05:16.398: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-lifecycle-hook 08/22/23 05:05:16.399
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:05:16.417
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:05:16.42
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 08/22/23 05:05:16.427
Aug 22 05:05:16.436: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2061" to be "running and ready"
Aug 22 05:05:16.440: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.867175ms
Aug 22 05:05:16.440: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:05:18.444: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008399624s
Aug 22 05:05:18.444: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:05:20.445: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.009442107s
Aug 22 05:05:20.445: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Aug 22 05:05:20.445: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 08/22/23 05:05:20.448
Aug 22 05:05:20.536: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-2061" to be "running and ready"
Aug 22 05:05:20.543: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.459168ms
Aug 22 05:05:20.543: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:05:22.547: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010716923s
Aug 22 05:05:22.547: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:05:24.547: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.010210448s
Aug 22 05:05:24.547: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Aug 22 05:05:24.547: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 08/22/23 05:05:24.549
STEP: delete the pod with lifecycle hook 08/22/23 05:05:24.579
Aug 22 05:05:25.084: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 05:05:25.088: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 22 05:05:27.088: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 22 05:05:27.092: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Aug 22 05:05:27.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2061" for this suite. 08/22/23 05:05:27.095
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":245,"skipped":4475,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.704 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:05:16.398
    Aug 22 05:05:16.398: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-lifecycle-hook 08/22/23 05:05:16.399
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:05:16.417
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:05:16.42
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 08/22/23 05:05:16.427
    Aug 22 05:05:16.436: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2061" to be "running and ready"
    Aug 22 05:05:16.440: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.867175ms
    Aug 22 05:05:16.440: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:05:18.444: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008399624s
    Aug 22 05:05:18.444: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:05:20.445: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.009442107s
    Aug 22 05:05:20.445: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Aug 22 05:05:20.445: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 08/22/23 05:05:20.448
    Aug 22 05:05:20.536: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-2061" to be "running and ready"
    Aug 22 05:05:20.543: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.459168ms
    Aug 22 05:05:20.543: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:05:22.547: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010716923s
    Aug 22 05:05:22.547: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:05:24.547: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.010210448s
    Aug 22 05:05:24.547: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Aug 22 05:05:24.547: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 08/22/23 05:05:24.549
    STEP: delete the pod with lifecycle hook 08/22/23 05:05:24.579
    Aug 22 05:05:25.084: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Aug 22 05:05:25.088: INFO: Pod pod-with-poststart-exec-hook still exists
    Aug 22 05:05:27.088: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Aug 22 05:05:27.092: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Aug 22 05:05:27.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-2061" for this suite. 08/22/23 05:05:27.095
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:05:27.103
Aug 22 05:05:27.103: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename events 08/22/23 05:05:27.104
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:05:27.149
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:05:27.153
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 08/22/23 05:05:27.158
Aug 22 05:05:27.165: INFO: created test-event-1
Aug 22 05:05:27.171: INFO: created test-event-2
Aug 22 05:05:27.235: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 08/22/23 05:05:27.236
STEP: delete collection of events 08/22/23 05:05:27.24
Aug 22 05:05:27.240: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 08/22/23 05:05:27.987
Aug 22 05:05:27.987: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Aug 22 05:05:27.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6349" for this suite. 08/22/23 05:05:27.994
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":246,"skipped":4478,"failed":0}
------------------------------
â€¢ [0.896 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:05:27.103
    Aug 22 05:05:27.103: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename events 08/22/23 05:05:27.104
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:05:27.149
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:05:27.153
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 08/22/23 05:05:27.158
    Aug 22 05:05:27.165: INFO: created test-event-1
    Aug 22 05:05:27.171: INFO: created test-event-2
    Aug 22 05:05:27.235: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 08/22/23 05:05:27.236
    STEP: delete collection of events 08/22/23 05:05:27.24
    Aug 22 05:05:27.240: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 08/22/23 05:05:27.987
    Aug 22 05:05:27.987: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Aug 22 05:05:27.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-6349" for this suite. 08/22/23 05:05:27.994
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:05:28
Aug 22 05:05:28.000: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 05:05:28.001
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:05:28.553
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:05:28.557
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 08/22/23 05:05:28.561
Aug 22 05:05:28.602: INFO: Waiting up to 5m0s for pod "pod-007a0f86-80b2-4286-aa49-00186cea74ca" in namespace "emptydir-4938" to be "Succeeded or Failed"
Aug 22 05:05:28.605: INFO: Pod "pod-007a0f86-80b2-4286-aa49-00186cea74ca": Phase="Pending", Reason="", readiness=false. Elapsed: 3.26659ms
Aug 22 05:05:30.611: INFO: Pod "pod-007a0f86-80b2-4286-aa49-00186cea74ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009812958s
Aug 22 05:05:32.817: INFO: Pod "pod-007a0f86-80b2-4286-aa49-00186cea74ca": Phase="Pending", Reason="", readiness=false. Elapsed: 4.215639917s
Aug 22 05:05:34.610: INFO: Pod "pod-007a0f86-80b2-4286-aa49-00186cea74ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008337573s
STEP: Saw pod success 08/22/23 05:05:34.61
Aug 22 05:05:34.610: INFO: Pod "pod-007a0f86-80b2-4286-aa49-00186cea74ca" satisfied condition "Succeeded or Failed"
Aug 22 05:05:34.612: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-007a0f86-80b2-4286-aa49-00186cea74ca container test-container: <nil>
STEP: delete the pod 08/22/23 05:05:34.619
Aug 22 05:05:35.033: INFO: Waiting for pod pod-007a0f86-80b2-4286-aa49-00186cea74ca to disappear
Aug 22 05:05:35.037: INFO: Pod pod-007a0f86-80b2-4286-aa49-00186cea74ca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 05:05:35.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4938" for this suite. 08/22/23 05:05:35.043
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":247,"skipped":4479,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.228 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:05:28
    Aug 22 05:05:28.000: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 05:05:28.001
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:05:28.553
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:05:28.557
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 08/22/23 05:05:28.561
    Aug 22 05:05:28.602: INFO: Waiting up to 5m0s for pod "pod-007a0f86-80b2-4286-aa49-00186cea74ca" in namespace "emptydir-4938" to be "Succeeded or Failed"
    Aug 22 05:05:28.605: INFO: Pod "pod-007a0f86-80b2-4286-aa49-00186cea74ca": Phase="Pending", Reason="", readiness=false. Elapsed: 3.26659ms
    Aug 22 05:05:30.611: INFO: Pod "pod-007a0f86-80b2-4286-aa49-00186cea74ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009812958s
    Aug 22 05:05:32.817: INFO: Pod "pod-007a0f86-80b2-4286-aa49-00186cea74ca": Phase="Pending", Reason="", readiness=false. Elapsed: 4.215639917s
    Aug 22 05:05:34.610: INFO: Pod "pod-007a0f86-80b2-4286-aa49-00186cea74ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008337573s
    STEP: Saw pod success 08/22/23 05:05:34.61
    Aug 22 05:05:34.610: INFO: Pod "pod-007a0f86-80b2-4286-aa49-00186cea74ca" satisfied condition "Succeeded or Failed"
    Aug 22 05:05:34.612: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-007a0f86-80b2-4286-aa49-00186cea74ca container test-container: <nil>
    STEP: delete the pod 08/22/23 05:05:34.619
    Aug 22 05:05:35.033: INFO: Waiting for pod pod-007a0f86-80b2-4286-aa49-00186cea74ca to disappear
    Aug 22 05:05:35.037: INFO: Pod pod-007a0f86-80b2-4286-aa49-00186cea74ca no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 05:05:35.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4938" for this suite. 08/22/23 05:05:35.043
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:05:35.229
Aug 22 05:05:35.229: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename init-container 08/22/23 05:05:35.23
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:05:35.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:05:35.268
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 08/22/23 05:05:35.274
Aug 22 05:05:35.274: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 22 05:05:41.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6638" for this suite. 08/22/23 05:05:41.118
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":248,"skipped":4482,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.896 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:05:35.229
    Aug 22 05:05:35.229: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename init-container 08/22/23 05:05:35.23
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:05:35.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:05:35.268
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 08/22/23 05:05:35.274
    Aug 22 05:05:35.274: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 22 05:05:41.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-6638" for this suite. 08/22/23 05:05:41.118
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:05:41.128
Aug 22 05:05:41.128: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 05:05:41.129
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:05:41.82
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:05:41.824
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 08/22/23 05:05:41.829
Aug 22 05:05:41.894: INFO: Waiting up to 5m0s for pod "downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a" in namespace "projected-3238" to be "Succeeded or Failed"
Aug 22 05:05:41.901: INFO: Pod "downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.147995ms
Aug 22 05:05:44.178: INFO: Pod "downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.283751383s
Aug 22 05:05:46.281: INFO: Pod "downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.386555181s
STEP: Saw pod success 08/22/23 05:05:46.281
Aug 22 05:05:46.281: INFO: Pod "downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a" satisfied condition "Succeeded or Failed"
Aug 22 05:05:46.285: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a container client-container: <nil>
STEP: delete the pod 08/22/23 05:05:46.317
Aug 22 05:05:47.033: INFO: Waiting for pod downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a to disappear
Aug 22 05:05:47.039: INFO: Pod downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 22 05:05:47.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3238" for this suite. 08/22/23 05:05:47.047
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":249,"skipped":4487,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.927 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:05:41.128
    Aug 22 05:05:41.128: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 05:05:41.129
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:05:41.82
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:05:41.824
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 08/22/23 05:05:41.829
    Aug 22 05:05:41.894: INFO: Waiting up to 5m0s for pod "downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a" in namespace "projected-3238" to be "Succeeded or Failed"
    Aug 22 05:05:41.901: INFO: Pod "downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.147995ms
    Aug 22 05:05:44.178: INFO: Pod "downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.283751383s
    Aug 22 05:05:46.281: INFO: Pod "downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.386555181s
    STEP: Saw pod success 08/22/23 05:05:46.281
    Aug 22 05:05:46.281: INFO: Pod "downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a" satisfied condition "Succeeded or Failed"
    Aug 22 05:05:46.285: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a container client-container: <nil>
    STEP: delete the pod 08/22/23 05:05:46.317
    Aug 22 05:05:47.033: INFO: Waiting for pod downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a to disappear
    Aug 22 05:05:47.039: INFO: Pod downwardapi-volume-81381e54-8817-4d45-86a4-27255467264a no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 22 05:05:47.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3238" for this suite. 08/22/23 05:05:47.047
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:05:47.055
Aug 22 05:05:47.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 05:05:47.056
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:05:47.237
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:05:47.24
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-a3d9b6f9-f4a5-4dc5-8630-a9b1d27a7800 08/22/23 05:05:47.249
STEP: Creating configMap with name cm-test-opt-upd-5e7d13b3-7ca8-4b6d-91ba-46e51a15820f 08/22/23 05:05:47.255
STEP: Creating the pod 08/22/23 05:05:47.26
Aug 22 05:05:47.271: INFO: Waiting up to 5m0s for pod "pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5" in namespace "configmap-7800" to be "running and ready"
Aug 22 05:05:47.275: INFO: Pod "pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.28514ms
Aug 22 05:05:47.275: INFO: The phase of Pod pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:05:49.289: INFO: Pod "pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018394487s
Aug 22 05:05:49.289: INFO: The phase of Pod pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:05:51.280: INFO: Pod "pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5": Phase="Running", Reason="", readiness=true. Elapsed: 4.009208449s
Aug 22 05:05:51.280: INFO: The phase of Pod pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5 is Running (Ready = true)
Aug 22 05:05:51.280: INFO: Pod "pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-a3d9b6f9-f4a5-4dc5-8630-a9b1d27a7800 08/22/23 05:05:51.297
STEP: Updating configmap cm-test-opt-upd-5e7d13b3-7ca8-4b6d-91ba-46e51a15820f 08/22/23 05:05:51.302
STEP: Creating configMap with name cm-test-opt-create-ca9ad942-d67f-40a8-9049-555e1f5f3b6f 08/22/23 05:05:51.394
STEP: waiting to observe update in volume 08/22/23 05:05:51.574
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 05:07:16.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7800" for this suite. 08/22/23 05:07:16.489
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":250,"skipped":4488,"failed":0}
------------------------------
â€¢ [SLOW TEST] [89.441 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:05:47.055
    Aug 22 05:05:47.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 05:05:47.056
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:05:47.237
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:05:47.24
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-a3d9b6f9-f4a5-4dc5-8630-a9b1d27a7800 08/22/23 05:05:47.249
    STEP: Creating configMap with name cm-test-opt-upd-5e7d13b3-7ca8-4b6d-91ba-46e51a15820f 08/22/23 05:05:47.255
    STEP: Creating the pod 08/22/23 05:05:47.26
    Aug 22 05:05:47.271: INFO: Waiting up to 5m0s for pod "pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5" in namespace "configmap-7800" to be "running and ready"
    Aug 22 05:05:47.275: INFO: Pod "pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.28514ms
    Aug 22 05:05:47.275: INFO: The phase of Pod pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:05:49.289: INFO: Pod "pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018394487s
    Aug 22 05:05:49.289: INFO: The phase of Pod pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:05:51.280: INFO: Pod "pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5": Phase="Running", Reason="", readiness=true. Elapsed: 4.009208449s
    Aug 22 05:05:51.280: INFO: The phase of Pod pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5 is Running (Ready = true)
    Aug 22 05:05:51.280: INFO: Pod "pod-configmaps-203b5363-63d6-46d9-a2bc-3cbe616777a5" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-a3d9b6f9-f4a5-4dc5-8630-a9b1d27a7800 08/22/23 05:05:51.297
    STEP: Updating configmap cm-test-opt-upd-5e7d13b3-7ca8-4b6d-91ba-46e51a15820f 08/22/23 05:05:51.302
    STEP: Creating configMap with name cm-test-opt-create-ca9ad942-d67f-40a8-9049-555e1f5f3b6f 08/22/23 05:05:51.394
    STEP: waiting to observe update in volume 08/22/23 05:05:51.574
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 05:07:16.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7800" for this suite. 08/22/23 05:07:16.489
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:07:16.497
Aug 22 05:07:16.497: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 05:07:16.497
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:07:16.559
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:07:16.563
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 08/22/23 05:07:16.566
Aug 22 05:07:16.579: INFO: Waiting up to 5m0s for pod "pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6" in namespace "emptydir-6255" to be "Succeeded or Failed"
Aug 22 05:07:16.583: INFO: Pod "pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.059866ms
Aug 22 05:07:18.587: INFO: Pod "pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008254553s
Aug 22 05:07:20.586: INFO: Pod "pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007593559s
Aug 22 05:07:22.587: INFO: Pod "pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007986822s
STEP: Saw pod success 08/22/23 05:07:22.587
Aug 22 05:07:22.587: INFO: Pod "pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6" satisfied condition "Succeeded or Failed"
Aug 22 05:07:22.589: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6 container test-container: <nil>
STEP: delete the pod 08/22/23 05:07:22.62
Aug 22 05:07:22.652: INFO: Waiting for pod pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6 to disappear
Aug 22 05:07:22.656: INFO: Pod pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 05:07:22.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6255" for this suite. 08/22/23 05:07:22.66
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":251,"skipped":4503,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.169 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:07:16.497
    Aug 22 05:07:16.497: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 05:07:16.497
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:07:16.559
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:07:16.563
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 08/22/23 05:07:16.566
    Aug 22 05:07:16.579: INFO: Waiting up to 5m0s for pod "pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6" in namespace "emptydir-6255" to be "Succeeded or Failed"
    Aug 22 05:07:16.583: INFO: Pod "pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.059866ms
    Aug 22 05:07:18.587: INFO: Pod "pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008254553s
    Aug 22 05:07:20.586: INFO: Pod "pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007593559s
    Aug 22 05:07:22.587: INFO: Pod "pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007986822s
    STEP: Saw pod success 08/22/23 05:07:22.587
    Aug 22 05:07:22.587: INFO: Pod "pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6" satisfied condition "Succeeded or Failed"
    Aug 22 05:07:22.589: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6 container test-container: <nil>
    STEP: delete the pod 08/22/23 05:07:22.62
    Aug 22 05:07:22.652: INFO: Waiting for pod pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6 to disappear
    Aug 22 05:07:22.656: INFO: Pod pod-665237eb-42dd-4e33-94b8-3c0e3e2061a6 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 05:07:22.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6255" for this suite. 08/22/23 05:07:22.66
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:07:22.666
Aug 22 05:07:22.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 05:07:22.667
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:07:22.848
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:07:22.853
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 08/22/23 05:07:22.858
Aug 22 05:07:22.878: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4" in namespace "projected-2668" to be "Succeeded or Failed"
Aug 22 05:07:22.882: INFO: Pod "downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.17379ms
Aug 22 05:07:24.970: INFO: Pod "downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.091417706s
Aug 22 05:07:26.886: INFO: Pod "downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008017064s
Aug 22 05:07:28.887: INFO: Pod "downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008347631s
STEP: Saw pod success 08/22/23 05:07:28.887
Aug 22 05:07:28.887: INFO: Pod "downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4" satisfied condition "Succeeded or Failed"
Aug 22 05:07:28.889: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4 container client-container: <nil>
STEP: delete the pod 08/22/23 05:07:28.919
Aug 22 05:07:29.188: INFO: Waiting for pod downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4 to disappear
Aug 22 05:07:29.192: INFO: Pod downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 22 05:07:29.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2668" for this suite. 08/22/23 05:07:29.198
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":252,"skipped":4508,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.540 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:07:22.666
    Aug 22 05:07:22.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 05:07:22.667
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:07:22.848
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:07:22.853
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 08/22/23 05:07:22.858
    Aug 22 05:07:22.878: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4" in namespace "projected-2668" to be "Succeeded or Failed"
    Aug 22 05:07:22.882: INFO: Pod "downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.17379ms
    Aug 22 05:07:24.970: INFO: Pod "downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.091417706s
    Aug 22 05:07:26.886: INFO: Pod "downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008017064s
    Aug 22 05:07:28.887: INFO: Pod "downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008347631s
    STEP: Saw pod success 08/22/23 05:07:28.887
    Aug 22 05:07:28.887: INFO: Pod "downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4" satisfied condition "Succeeded or Failed"
    Aug 22 05:07:28.889: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4 container client-container: <nil>
    STEP: delete the pod 08/22/23 05:07:28.919
    Aug 22 05:07:29.188: INFO: Waiting for pod downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4 to disappear
    Aug 22 05:07:29.192: INFO: Pod downwardapi-volume-f25b036c-199a-4829-9b17-b375ba6400b4 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 22 05:07:29.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2668" for this suite. 08/22/23 05:07:29.198
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:07:29.209
Aug 22 05:07:29.209: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename statefulset 08/22/23 05:07:29.21
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:07:29.226
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:07:29.23
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1117 08/22/23 05:07:29.234
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Aug 22 05:07:29.652: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Aug 22 05:07:39.657: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 08/22/23 05:07:39.663
W0822 05:07:39.787380      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Aug 22 05:07:40.023: INFO: Found 1 stateful pods, waiting for 2
Aug 22 05:07:50.029: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 05:07:50.029: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 08/22/23 05:07:50.033
STEP: Delete all of the StatefulSets 08/22/23 05:07:50.038
STEP: Verify that StatefulSets have been deleted 08/22/23 05:07:50.046
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 22 05:07:50.050: INFO: Deleting all statefulset in ns statefulset-1117
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 22 05:07:50.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1117" for this suite. 08/22/23 05:07:50.063
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":253,"skipped":4521,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.860 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:07:29.209
    Aug 22 05:07:29.209: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename statefulset 08/22/23 05:07:29.21
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:07:29.226
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:07:29.23
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1117 08/22/23 05:07:29.234
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Aug 22 05:07:29.652: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Pending - Ready=false
    Aug 22 05:07:39.657: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 08/22/23 05:07:39.663
    W0822 05:07:39.787380      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Aug 22 05:07:40.023: INFO: Found 1 stateful pods, waiting for 2
    Aug 22 05:07:50.029: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 22 05:07:50.029: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 08/22/23 05:07:50.033
    STEP: Delete all of the StatefulSets 08/22/23 05:07:50.038
    STEP: Verify that StatefulSets have been deleted 08/22/23 05:07:50.046
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 22 05:07:50.050: INFO: Deleting all statefulset in ns statefulset-1117
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 22 05:07:50.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1117" for this suite. 08/22/23 05:07:50.063
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:07:50.072
Aug 22 05:07:50.073: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 05:07:50.073
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:07:50.141
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:07:50.144
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185
STEP: fetching services 08/22/23 05:07:50.147
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 05:07:50.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-647" for this suite. 08/22/23 05:07:50.153
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":254,"skipped":4546,"failed":0}
------------------------------
â€¢ [0.087 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:07:50.072
    Aug 22 05:07:50.073: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 05:07:50.073
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:07:50.141
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:07:50.144
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3185
    STEP: fetching services 08/22/23 05:07:50.147
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 05:07:50.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-647" for this suite. 08/22/23 05:07:50.153
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:07:50.163
Aug 22 05:07:50.163: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-runtime 08/22/23 05:07:50.164
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:07:50.178
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:07:50.181
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 08/22/23 05:07:50.184
STEP: wait for the container to reach Succeeded 08/22/23 05:07:50.191
STEP: get the container status 08/22/23 05:07:55.642
STEP: the container should be terminated 08/22/23 05:07:55.646
STEP: the termination message should be set 08/22/23 05:07:55.646
Aug 22 05:07:55.646: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 08/22/23 05:07:55.646
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 22 05:07:55.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-760" for this suite. 08/22/23 05:07:55.669
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":255,"skipped":4567,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.515 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:07:50.163
    Aug 22 05:07:50.163: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-runtime 08/22/23 05:07:50.164
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:07:50.178
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:07:50.181
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 08/22/23 05:07:50.184
    STEP: wait for the container to reach Succeeded 08/22/23 05:07:50.191
    STEP: get the container status 08/22/23 05:07:55.642
    STEP: the container should be terminated 08/22/23 05:07:55.646
    STEP: the termination message should be set 08/22/23 05:07:55.646
    Aug 22 05:07:55.646: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 08/22/23 05:07:55.646
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 22 05:07:55.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-760" for this suite. 08/22/23 05:07:55.669
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:07:55.679
Aug 22 05:07:55.679: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename cronjob 08/22/23 05:07:55.679
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:07:55.728
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:07:55.731
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 08/22/23 05:07:55.734
STEP: Ensuring no jobs are scheduled 08/22/23 05:07:55.742
STEP: Ensuring no job exists by listing jobs explicitly 08/22/23 05:12:55.749
STEP: Removing cronjob 08/22/23 05:12:55.752
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 22 05:12:55.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6575" for this suite. 08/22/23 05:12:55.761
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":256,"skipped":4619,"failed":0}
------------------------------
â€¢ [SLOW TEST] [300.088 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:07:55.679
    Aug 22 05:07:55.679: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename cronjob 08/22/23 05:07:55.679
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:07:55.728
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:07:55.731
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 08/22/23 05:07:55.734
    STEP: Ensuring no jobs are scheduled 08/22/23 05:07:55.742
    STEP: Ensuring no job exists by listing jobs explicitly 08/22/23 05:12:55.749
    STEP: Removing cronjob 08/22/23 05:12:55.752
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 22 05:12:55.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-6575" for this suite. 08/22/23 05:12:55.761
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:12:55.769
Aug 22 05:12:55.769: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename secrets 08/22/23 05:12:55.77
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:12:55.784
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:12:55.788
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-8218343b-5a20-4ba3-91f6-e102acc68f86 08/22/23 05:12:55.791
STEP: Creating a pod to test consume secrets 08/22/23 05:12:55.795
Aug 22 05:12:55.804: INFO: Waiting up to 5m0s for pod "pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999" in namespace "secrets-6637" to be "Succeeded or Failed"
Aug 22 05:12:55.808: INFO: Pod "pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999": Phase="Pending", Reason="", readiness=false. Elapsed: 3.08098ms
Aug 22 05:12:57.814: INFO: Pod "pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999": Phase="Running", Reason="", readiness=true. Elapsed: 2.009519066s
Aug 22 05:12:59.812: INFO: Pod "pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999": Phase="Running", Reason="", readiness=false. Elapsed: 4.007266977s
Aug 22 05:13:01.813: INFO: Pod "pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008085389s
STEP: Saw pod success 08/22/23 05:13:01.813
Aug 22 05:13:01.813: INFO: Pod "pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999" satisfied condition "Succeeded or Failed"
Aug 22 05:13:01.815: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999 container secret-env-test: <nil>
STEP: delete the pod 08/22/23 05:13:01.844
Aug 22 05:13:01.934: INFO: Waiting for pod pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999 to disappear
Aug 22 05:13:01.937: INFO: Pod pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Aug 22 05:13:01.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6637" for this suite. 08/22/23 05:13:01.94
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":257,"skipped":4676,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.177 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:12:55.769
    Aug 22 05:12:55.769: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename secrets 08/22/23 05:12:55.77
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:12:55.784
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:12:55.788
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-8218343b-5a20-4ba3-91f6-e102acc68f86 08/22/23 05:12:55.791
    STEP: Creating a pod to test consume secrets 08/22/23 05:12:55.795
    Aug 22 05:12:55.804: INFO: Waiting up to 5m0s for pod "pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999" in namespace "secrets-6637" to be "Succeeded or Failed"
    Aug 22 05:12:55.808: INFO: Pod "pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999": Phase="Pending", Reason="", readiness=false. Elapsed: 3.08098ms
    Aug 22 05:12:57.814: INFO: Pod "pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999": Phase="Running", Reason="", readiness=true. Elapsed: 2.009519066s
    Aug 22 05:12:59.812: INFO: Pod "pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999": Phase="Running", Reason="", readiness=false. Elapsed: 4.007266977s
    Aug 22 05:13:01.813: INFO: Pod "pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008085389s
    STEP: Saw pod success 08/22/23 05:13:01.813
    Aug 22 05:13:01.813: INFO: Pod "pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999" satisfied condition "Succeeded or Failed"
    Aug 22 05:13:01.815: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999 container secret-env-test: <nil>
    STEP: delete the pod 08/22/23 05:13:01.844
    Aug 22 05:13:01.934: INFO: Waiting for pod pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999 to disappear
    Aug 22 05:13:01.937: INFO: Pod pod-secrets-60dda6ae-aafd-47bc-9365-5141c84f3999 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Aug 22 05:13:01.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6637" for this suite. 08/22/23 05:13:01.94
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:13:01.949
Aug 22 05:13:01.949: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename cronjob 08/22/23 05:13:01.949
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:01.982
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:01.985
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 08/22/23 05:13:01.988
STEP: creating 08/22/23 05:13:01.988
STEP: getting 08/22/23 05:13:02.012
STEP: listing 08/22/23 05:13:02.015
STEP: watching 08/22/23 05:13:02.018
Aug 22 05:13:02.018: INFO: starting watch
STEP: cluster-wide listing 08/22/23 05:13:02.019
STEP: cluster-wide watching 08/22/23 05:13:02.021
Aug 22 05:13:02.021: INFO: starting watch
STEP: patching 08/22/23 05:13:02.023
STEP: updating 08/22/23 05:13:02.029
Aug 22 05:13:02.038: INFO: waiting for watch events with expected annotations
Aug 22 05:13:02.038: INFO: saw patched and updated annotations
STEP: patching /status 08/22/23 05:13:02.038
STEP: updating /status 08/22/23 05:13:02.044
STEP: get /status 08/22/23 05:13:02.05
STEP: deleting 08/22/23 05:13:02.053
STEP: deleting a collection 08/22/23 05:13:02.066
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 22 05:13:02.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4703" for this suite. 08/22/23 05:13:02.077
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":258,"skipped":4699,"failed":0}
------------------------------
â€¢ [0.136 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:13:01.949
    Aug 22 05:13:01.949: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename cronjob 08/22/23 05:13:01.949
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:01.982
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:01.985
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 08/22/23 05:13:01.988
    STEP: creating 08/22/23 05:13:01.988
    STEP: getting 08/22/23 05:13:02.012
    STEP: listing 08/22/23 05:13:02.015
    STEP: watching 08/22/23 05:13:02.018
    Aug 22 05:13:02.018: INFO: starting watch
    STEP: cluster-wide listing 08/22/23 05:13:02.019
    STEP: cluster-wide watching 08/22/23 05:13:02.021
    Aug 22 05:13:02.021: INFO: starting watch
    STEP: patching 08/22/23 05:13:02.023
    STEP: updating 08/22/23 05:13:02.029
    Aug 22 05:13:02.038: INFO: waiting for watch events with expected annotations
    Aug 22 05:13:02.038: INFO: saw patched and updated annotations
    STEP: patching /status 08/22/23 05:13:02.038
    STEP: updating /status 08/22/23 05:13:02.044
    STEP: get /status 08/22/23 05:13:02.05
    STEP: deleting 08/22/23 05:13:02.053
    STEP: deleting a collection 08/22/23 05:13:02.066
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 22 05:13:02.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-4703" for this suite. 08/22/23 05:13:02.077
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:13:02.085
Aug 22 05:13:02.085: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename deployment 08/22/23 05:13:02.086
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:02.122
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:02.124
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Aug 22 05:13:02.127: INFO: Creating deployment "test-recreate-deployment"
Aug 22 05:13:02.133: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 22 05:13:02.144: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug 22 05:13:04.151: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 22 05:13:04.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 05:13:06.159: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 22 05:13:06.304: INFO: Updating deployment test-recreate-deployment
Aug 22 05:13:06.304: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 22 05:13:06.562: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2413  fda8022e-1329-44d7-8dbf-451b707556e9 1277419 2 2023-08-22 05:13:02 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00401dbb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-08-22 05:13:06 +0000 UTC,LastTransitionTime:2023-08-22 05:13:06 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-08-22 05:13:06 +0000 UTC,LastTransitionTime:2023-08-22 05:13:02 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Aug 22 05:13:06.565: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-2413  e73bb119-3435-400a-af24-4fdfe564011e 1277418 1 2023-08-22 05:13:06 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment fda8022e-1329-44d7-8dbf-451b707556e9 0xc0034b04a0 0xc0034b04a1}] [] [{kube-controller-manager Update apps/v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fda8022e-1329-44d7-8dbf-451b707556e9\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034b0538 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 22 05:13:06.565: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 22 05:13:06.565: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-2413  1f5ac194-0b11-4309-bb4e-5951d252881f 1277408 2 2023-08-22 05:13:02 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment fda8022e-1329-44d7-8dbf-451b707556e9 0xc00401df97 0xc00401df98}] [] [{kube-controller-manager Update apps/v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fda8022e-1329-44d7-8dbf-451b707556e9\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034b0438 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 22 05:13:06.569: INFO: Pod "test-recreate-deployment-9d58999df-j4d7n" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-j4d7n test-recreate-deployment-9d58999df- deployment-2413  4a632bee-7dbb-4d8d-bbe7-243855d43e4a 1277420 0 2023-08-22 05:13:06 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df e73bb119-3435-400a-af24-4fdfe564011e 0xc0034b09c0 0xc0034b09c1}] [] [{kube-controller-manager Update v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e73bb119-3435-400a-af24-4fdfe564011e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pdm5r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pdm5r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:,StartTime:2023-08-22 05:13:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 22 05:13:06.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2413" for this suite. 08/22/23 05:13:06.573
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":259,"skipped":4703,"failed":0}
------------------------------
â€¢ [4.495 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:13:02.085
    Aug 22 05:13:02.085: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename deployment 08/22/23 05:13:02.086
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:02.122
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:02.124
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Aug 22 05:13:02.127: INFO: Creating deployment "test-recreate-deployment"
    Aug 22 05:13:02.133: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Aug 22 05:13:02.144: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Aug 22 05:13:04.151: INFO: Waiting deployment "test-recreate-deployment" to complete
    Aug 22 05:13:04.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 05:13:06.159: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Aug 22 05:13:06.304: INFO: Updating deployment test-recreate-deployment
    Aug 22 05:13:06.304: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 22 05:13:06.562: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-2413  fda8022e-1329-44d7-8dbf-451b707556e9 1277419 2 2023-08-22 05:13:02 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00401dbb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-08-22 05:13:06 +0000 UTC,LastTransitionTime:2023-08-22 05:13:06 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-08-22 05:13:06 +0000 UTC,LastTransitionTime:2023-08-22 05:13:02 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Aug 22 05:13:06.565: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-2413  e73bb119-3435-400a-af24-4fdfe564011e 1277418 1 2023-08-22 05:13:06 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment fda8022e-1329-44d7-8dbf-451b707556e9 0xc0034b04a0 0xc0034b04a1}] [] [{kube-controller-manager Update apps/v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fda8022e-1329-44d7-8dbf-451b707556e9\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034b0538 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 22 05:13:06.565: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Aug 22 05:13:06.565: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-2413  1f5ac194-0b11-4309-bb4e-5951d252881f 1277408 2 2023-08-22 05:13:02 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment fda8022e-1329-44d7-8dbf-451b707556e9 0xc00401df97 0xc00401df98}] [] [{kube-controller-manager Update apps/v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fda8022e-1329-44d7-8dbf-451b707556e9\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034b0438 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 22 05:13:06.569: INFO: Pod "test-recreate-deployment-9d58999df-j4d7n" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-j4d7n test-recreate-deployment-9d58999df- deployment-2413  4a632bee-7dbb-4d8d-bbe7-243855d43e4a 1277420 0 2023-08-22 05:13:06 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df e73bb119-3435-400a-af24-4fdfe564011e 0xc0034b09c0 0xc0034b09c1}] [] [{kube-controller-manager Update v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e73bb119-3435-400a-af24-4fdfe564011e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 05:13:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pdm5r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pdm5r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:,StartTime:2023-08-22 05:13:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 22 05:13:06.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2413" for this suite. 08/22/23 05:13:06.573
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:13:06.583
Aug 22 05:13:06.583: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 05:13:06.583
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:06.598
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:06.6
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/22/23 05:13:06.604
Aug 22 05:13:06.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9884 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Aug 22 05:13:06.748: INFO: stderr: ""
Aug 22 05:13:06.748: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 08/22/23 05:13:06.748
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Aug 22 05:13:06.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9884 delete pods e2e-test-httpd-pod'
Aug 22 05:13:11.811: INFO: stderr: ""
Aug 22 05:13:11.811: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 05:13:11.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9884" for this suite. 08/22/23 05:13:11.825
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":260,"skipped":4752,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.248 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:13:06.583
    Aug 22 05:13:06.583: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 05:13:06.583
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:06.598
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:06.6
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/22/23 05:13:06.604
    Aug 22 05:13:06.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9884 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Aug 22 05:13:06.748: INFO: stderr: ""
    Aug 22 05:13:06.748: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 08/22/23 05:13:06.748
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Aug 22 05:13:06.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-9884 delete pods e2e-test-httpd-pod'
    Aug 22 05:13:11.811: INFO: stderr: ""
    Aug 22 05:13:11.811: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 05:13:11.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9884" for this suite. 08/22/23 05:13:11.825
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:13:11.831
Aug 22 05:13:11.832: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename secrets 08/22/23 05:13:11.832
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:11.861
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:11.864
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-c707a32d-d242-48a1-9905-413693067b64 08/22/23 05:13:11.867
STEP: Creating a pod to test consume secrets 08/22/23 05:13:11.915
Aug 22 05:13:11.927: INFO: Waiting up to 5m0s for pod "pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3" in namespace "secrets-9635" to be "Succeeded or Failed"
Aug 22 05:13:11.930: INFO: Pod "pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.461395ms
Aug 22 05:13:13.934: INFO: Pod "pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006900414s
Aug 22 05:13:15.935: INFO: Pod "pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008040399s
Aug 22 05:13:17.935: INFO: Pod "pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008430226s
STEP: Saw pod success 08/22/23 05:13:17.935
Aug 22 05:13:17.935: INFO: Pod "pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3" satisfied condition "Succeeded or Failed"
Aug 22 05:13:17.937: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3 container secret-volume-test: <nil>
STEP: delete the pod 08/22/23 05:13:17.943
Aug 22 05:13:18.012: INFO: Waiting for pod pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3 to disappear
Aug 22 05:13:18.016: INFO: Pod pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 22 05:13:18.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9635" for this suite. 08/22/23 05:13:18.02
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":261,"skipped":4779,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.198 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:13:11.831
    Aug 22 05:13:11.832: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename secrets 08/22/23 05:13:11.832
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:11.861
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:11.864
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-c707a32d-d242-48a1-9905-413693067b64 08/22/23 05:13:11.867
    STEP: Creating a pod to test consume secrets 08/22/23 05:13:11.915
    Aug 22 05:13:11.927: INFO: Waiting up to 5m0s for pod "pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3" in namespace "secrets-9635" to be "Succeeded or Failed"
    Aug 22 05:13:11.930: INFO: Pod "pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.461395ms
    Aug 22 05:13:13.934: INFO: Pod "pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006900414s
    Aug 22 05:13:15.935: INFO: Pod "pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008040399s
    Aug 22 05:13:17.935: INFO: Pod "pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008430226s
    STEP: Saw pod success 08/22/23 05:13:17.935
    Aug 22 05:13:17.935: INFO: Pod "pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3" satisfied condition "Succeeded or Failed"
    Aug 22 05:13:17.937: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3 container secret-volume-test: <nil>
    STEP: delete the pod 08/22/23 05:13:17.943
    Aug 22 05:13:18.012: INFO: Waiting for pod pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3 to disappear
    Aug 22 05:13:18.016: INFO: Pod pod-secrets-17440c46-1ed1-41ef-9793-fa7a523970e3 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 22 05:13:18.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9635" for this suite. 08/22/23 05:13:18.02
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:13:18.03
Aug 22 05:13:18.030: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename tables 08/22/23 05:13:18.03
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:18.062
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:18.064
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Aug 22 05:13:18.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9123" for this suite. 08/22/23 05:13:18.074
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":262,"skipped":4792,"failed":0}
------------------------------
â€¢ [0.143 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:13:18.03
    Aug 22 05:13:18.030: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename tables 08/22/23 05:13:18.03
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:18.062
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:18.064
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Aug 22 05:13:18.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-9123" for this suite. 08/22/23 05:13:18.074
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:13:18.174
Aug 22 05:13:18.174: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename deployment 08/22/23 05:13:18.175
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:18.271
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:18.274
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Aug 22 05:13:18.290: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 22 05:13:23.293: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/22/23 05:13:23.293
Aug 22 05:13:23.293: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 22 05:13:25.298: INFO: Creating deployment "test-rollover-deployment"
Aug 22 05:13:25.334: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 22 05:13:27.344: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 22 05:13:27.350: INFO: Ensure that both replica sets have 1 created replica
Aug 22 05:13:27.355: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 22 05:13:27.774: INFO: Updating deployment test-rollover-deployment
Aug 22 05:13:27.774: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 22 05:13:29.787: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 22 05:13:29.792: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 22 05:13:29.796: INFO: all replica sets need to contain the pod-template-hash label
Aug 22 05:13:29.796: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 05:13:31.803: INFO: all replica sets need to contain the pod-template-hash label
Aug 22 05:13:31.803: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 05:13:33.802: INFO: all replica sets need to contain the pod-template-hash label
Aug 22 05:13:33.802: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 05:13:35.802: INFO: all replica sets need to contain the pod-template-hash label
Aug 22 05:13:35.802: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 05:13:37.802: INFO: all replica sets need to contain the pod-template-hash label
Aug 22 05:13:37.802: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 05:13:39.803: INFO: all replica sets need to contain the pod-template-hash label
Aug 22 05:13:39.803: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 05:13:42.006: INFO: 
Aug 22 05:13:42.006: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 22 05:13:42.017: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-2122  83fa12c4-86cd-4d0f-9e74-789e5828efde 1277706 2 2023-08-22 05:13:25 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-08-22 05:13:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0060a8548 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-08-22 05:13:25 +0000 UTC,LastTransitionTime:2023-08-22 05:13:25 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-08-22 05:13:40 +0000 UTC,LastTransitionTime:2023-08-22 05:13:25 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 22 05:13:42.019: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-2122  593fa52f-b106-47d5-9e77-0b18f8cac7e5 1277693 2 2023-08-22 05:13:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 83fa12c4-86cd-4d0f-9e74-789e5828efde 0xc003e40b07 0xc003e40b08}] [] [{kube-controller-manager Update apps/v1 2023-08-22 05:13:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83fa12c4-86cd-4d0f-9e74-789e5828efde\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:40 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e40bb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 22 05:13:42.019: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 22 05:13:42.019: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-2122  1607d0c0-9708-46c0-903f-c3a7ad5cacdf 1277705 2 2023-08-22 05:13:18 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 83fa12c4-86cd-4d0f-9e74-789e5828efde 0xc003e408b7 0xc003e408b8}] [] [{e2e.test Update apps/v1 2023-08-22 05:13:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83fa12c4-86cd-4d0f-9e74-789e5828efde\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:40 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003e40978 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 22 05:13:42.020: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-2122  b223cc8b-defb-4865-b130-01e055d5836b 1277638 2 2023-08-22 05:13:25 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 83fa12c4-86cd-4d0f-9e74-789e5828efde 0xc003e409e7 0xc003e409e8}] [] [{kube-controller-manager Update apps/v1 2023-08-22 05:13:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83fa12c4-86cd-4d0f-9e74-789e5828efde\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:27 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e40a98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 22 05:13:42.022: INFO: Pod "test-rollover-deployment-6d45fd857b-7fhf7" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-7fhf7 test-rollover-deployment-6d45fd857b- deployment-2122  8482030c-6661-4b77-9006-3aa24c7cf0c0 1277658 0 2023-08-22 05:13:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 593fa52f-b106-47d5-9e77-0b18f8cac7e5 0xc003e41127 0xc003e41128}] [] [{kube-controller-manager Update v1 2023-08-22 05:13:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"593fa52f-b106-47d5-9e77-0b18f8cac7e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 05:13:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.3.176\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gmjk4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gmjk4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:10.100.3.176,StartTime:2023-08-22 05:13:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 05:13:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://c941933aad2bd1fb28155ea76deb0a89339edaa798dfa5a30080344f20e44de9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.3.176,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 22 05:13:42.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2122" for this suite. 08/22/23 05:13:42.026
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":263,"skipped":4840,"failed":0}
------------------------------
â€¢ [SLOW TEST] [23.857 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:13:18.174
    Aug 22 05:13:18.174: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename deployment 08/22/23 05:13:18.175
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:18.271
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:18.274
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Aug 22 05:13:18.290: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Aug 22 05:13:23.293: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/22/23 05:13:23.293
    Aug 22 05:13:23.293: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Aug 22 05:13:25.298: INFO: Creating deployment "test-rollover-deployment"
    Aug 22 05:13:25.334: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Aug 22 05:13:27.344: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Aug 22 05:13:27.350: INFO: Ensure that both replica sets have 1 created replica
    Aug 22 05:13:27.355: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Aug 22 05:13:27.774: INFO: Updating deployment test-rollover-deployment
    Aug 22 05:13:27.774: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Aug 22 05:13:29.787: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Aug 22 05:13:29.792: INFO: Make sure deployment "test-rollover-deployment" is complete
    Aug 22 05:13:29.796: INFO: all replica sets need to contain the pod-template-hash label
    Aug 22 05:13:29.796: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 05:13:31.803: INFO: all replica sets need to contain the pod-template-hash label
    Aug 22 05:13:31.803: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 05:13:33.802: INFO: all replica sets need to contain the pod-template-hash label
    Aug 22 05:13:33.802: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 05:13:35.802: INFO: all replica sets need to contain the pod-template-hash label
    Aug 22 05:13:35.802: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 05:13:37.802: INFO: all replica sets need to contain the pod-template-hash label
    Aug 22 05:13:37.802: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 05:13:39.803: INFO: all replica sets need to contain the pod-template-hash label
    Aug 22 05:13:39.803: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 13, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 13, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 05:13:42.006: INFO: 
    Aug 22 05:13:42.006: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 22 05:13:42.017: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-2122  83fa12c4-86cd-4d0f-9e74-789e5828efde 1277706 2 2023-08-22 05:13:25 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-08-22 05:13:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0060a8548 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-08-22 05:13:25 +0000 UTC,LastTransitionTime:2023-08-22 05:13:25 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-08-22 05:13:40 +0000 UTC,LastTransitionTime:2023-08-22 05:13:25 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Aug 22 05:13:42.019: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-2122  593fa52f-b106-47d5-9e77-0b18f8cac7e5 1277693 2 2023-08-22 05:13:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 83fa12c4-86cd-4d0f-9e74-789e5828efde 0xc003e40b07 0xc003e40b08}] [] [{kube-controller-manager Update apps/v1 2023-08-22 05:13:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83fa12c4-86cd-4d0f-9e74-789e5828efde\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:40 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e40bb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Aug 22 05:13:42.019: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Aug 22 05:13:42.019: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-2122  1607d0c0-9708-46c0-903f-c3a7ad5cacdf 1277705 2 2023-08-22 05:13:18 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 83fa12c4-86cd-4d0f-9e74-789e5828efde 0xc003e408b7 0xc003e408b8}] [] [{e2e.test Update apps/v1 2023-08-22 05:13:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83fa12c4-86cd-4d0f-9e74-789e5828efde\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:40 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003e40978 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 22 05:13:42.020: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-2122  b223cc8b-defb-4865-b130-01e055d5836b 1277638 2 2023-08-22 05:13:25 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 83fa12c4-86cd-4d0f-9e74-789e5828efde 0xc003e409e7 0xc003e409e8}] [] [{kube-controller-manager Update apps/v1 2023-08-22 05:13:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83fa12c4-86cd-4d0f-9e74-789e5828efde\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:13:27 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e40a98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 22 05:13:42.022: INFO: Pod "test-rollover-deployment-6d45fd857b-7fhf7" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-7fhf7 test-rollover-deployment-6d45fd857b- deployment-2122  8482030c-6661-4b77-9006-3aa24c7cf0c0 1277658 0 2023-08-22 05:13:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 593fa52f-b106-47d5-9e77-0b18f8cac7e5 0xc003e41127 0xc003e41128}] [] [{kube-controller-manager Update v1 2023-08-22 05:13:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"593fa52f-b106-47d5-9e77-0b18f8cac7e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 05:13:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.3.176\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gmjk4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gmjk4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:13:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.97,PodIP:10.100.3.176,StartTime:2023-08-22 05:13:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 05:13:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://c941933aad2bd1fb28155ea76deb0a89339edaa798dfa5a30080344f20e44de9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.3.176,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 22 05:13:42.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2122" for this suite. 08/22/23 05:13:42.026
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:13:42.032
Aug 22 05:13:42.032: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename conformance-tests 08/22/23 05:13:42.032
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:42.048
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:42.05
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 08/22/23 05:13:42.054
Aug 22 05:13:42.054: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Aug 22 05:13:42.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-1663" for this suite. 08/22/23 05:13:42.061
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":264,"skipped":4871,"failed":0}
------------------------------
â€¢ [0.036 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:13:42.032
    Aug 22 05:13:42.032: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename conformance-tests 08/22/23 05:13:42.032
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:42.048
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:42.05
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 08/22/23 05:13:42.054
    Aug 22 05:13:42.054: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Aug 22 05:13:42.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-1663" for this suite. 08/22/23 05:13:42.061
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:13:42.068
Aug 22 05:13:42.069: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename daemonsets 08/22/23 05:13:42.069
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:42.081
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:42.084
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 08/22/23 05:13:42.105
STEP: Check that daemon pods launch on every node of the cluster. 08/22/23 05:13:42.112
Aug 22 05:13:42.117: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:42.117: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:42.117: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:42.121: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 05:13:42.121: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 05:13:43.130: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:43.130: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:43.130: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:43.133: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 05:13:43.133: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 05:13:44.126: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:44.126: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:44.126: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:44.130: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 05:13:44.130: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 05:13:45.130: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:45.130: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:45.130: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:45.133: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 05:13:45.133: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 05:13:46.126: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:46.126: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:46.126: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:46.129: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 22 05:13:46.129: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 08/22/23 05:13:46.133
Aug 22 05:13:46.332: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:46.332: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:46.332: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:46.336: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 05:13:46.336: INFO: Node jake-melb-gmyyva4zrlsz-node-2 is running 0 daemon pod, expected 1
Aug 22 05:13:47.363: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:47.363: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:47.363: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:47.384: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 05:13:47.384: INFO: Node jake-melb-gmyyva4zrlsz-node-2 is running 0 daemon pod, expected 1
Aug 22 05:13:48.342: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:48.342: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:48.343: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:48.345: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 05:13:48.346: INFO: Node jake-melb-gmyyva4zrlsz-node-2 is running 0 daemon pod, expected 1
Aug 22 05:13:49.341: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:49.341: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:49.341: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:13:49.343: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 22 05:13:49.343: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 08/22/23 05:13:49.343
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/22/23 05:13:49.349
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1539, will wait for the garbage collector to delete the pods 08/22/23 05:13:49.349
Aug 22 05:13:49.517: INFO: Deleting DaemonSet.extensions daemon-set took: 115.799211ms
Aug 22 05:13:49.618: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.62371ms
Aug 22 05:13:51.922: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 05:13:51.922: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 22 05:13:51.924: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1277858"},"items":null}

Aug 22 05:13:51.925: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1277858"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 22 05:13:51.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1539" for this suite. 08/22/23 05:13:51.938
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":265,"skipped":4891,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.880 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:13:42.068
    Aug 22 05:13:42.069: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename daemonsets 08/22/23 05:13:42.069
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:42.081
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:42.084
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 08/22/23 05:13:42.105
    STEP: Check that daemon pods launch on every node of the cluster. 08/22/23 05:13:42.112
    Aug 22 05:13:42.117: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:42.117: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:42.117: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:42.121: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 05:13:42.121: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 05:13:43.130: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:43.130: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:43.130: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:43.133: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 05:13:43.133: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 05:13:44.126: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:44.126: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:44.126: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:44.130: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 05:13:44.130: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 05:13:45.130: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:45.130: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:45.130: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:45.133: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 05:13:45.133: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 05:13:46.126: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:46.126: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:46.126: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:46.129: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 22 05:13:46.129: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 08/22/23 05:13:46.133
    Aug 22 05:13:46.332: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:46.332: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:46.332: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:46.336: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 05:13:46.336: INFO: Node jake-melb-gmyyva4zrlsz-node-2 is running 0 daemon pod, expected 1
    Aug 22 05:13:47.363: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:47.363: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:47.363: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:47.384: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 05:13:47.384: INFO: Node jake-melb-gmyyva4zrlsz-node-2 is running 0 daemon pod, expected 1
    Aug 22 05:13:48.342: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:48.342: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:48.343: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:48.345: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 05:13:48.346: INFO: Node jake-melb-gmyyva4zrlsz-node-2 is running 0 daemon pod, expected 1
    Aug 22 05:13:49.341: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:49.341: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:49.341: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:13:49.343: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 22 05:13:49.343: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 08/22/23 05:13:49.343
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/22/23 05:13:49.349
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1539, will wait for the garbage collector to delete the pods 08/22/23 05:13:49.349
    Aug 22 05:13:49.517: INFO: Deleting DaemonSet.extensions daemon-set took: 115.799211ms
    Aug 22 05:13:49.618: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.62371ms
    Aug 22 05:13:51.922: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 05:13:51.922: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 22 05:13:51.924: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1277858"},"items":null}

    Aug 22 05:13:51.925: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1277858"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 05:13:51.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1539" for this suite. 08/22/23 05:13:51.938
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:13:51.949
Aug 22 05:13:51.949: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 05:13:51.949
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:51.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:51.965
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 08/22/23 05:13:51.968
Aug 22 05:13:51.978: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce" in namespace "projected-1665" to be "Succeeded or Failed"
Aug 22 05:13:51.982: INFO: Pod "downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce": Phase="Pending", Reason="", readiness=false. Elapsed: 3.88619ms
Aug 22 05:13:53.985: INFO: Pod "downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007115666s
Aug 22 05:13:55.987: INFO: Pod "downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008910029s
Aug 22 05:13:57.985: INFO: Pod "downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007388952s
STEP: Saw pod success 08/22/23 05:13:57.985
Aug 22 05:13:57.985: INFO: Pod "downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce" satisfied condition "Succeeded or Failed"
Aug 22 05:13:57.987: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce container client-container: <nil>
STEP: delete the pod 08/22/23 05:13:58.004
Aug 22 05:13:58.076: INFO: Waiting for pod downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce to disappear
Aug 22 05:13:58.081: INFO: Pod downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 22 05:13:58.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1665" for this suite. 08/22/23 05:13:58.084
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":266,"skipped":4891,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.141 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:13:51.949
    Aug 22 05:13:51.949: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 05:13:51.949
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:51.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:51.965
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 08/22/23 05:13:51.968
    Aug 22 05:13:51.978: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce" in namespace "projected-1665" to be "Succeeded or Failed"
    Aug 22 05:13:51.982: INFO: Pod "downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce": Phase="Pending", Reason="", readiness=false. Elapsed: 3.88619ms
    Aug 22 05:13:53.985: INFO: Pod "downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007115666s
    Aug 22 05:13:55.987: INFO: Pod "downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008910029s
    Aug 22 05:13:57.985: INFO: Pod "downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007388952s
    STEP: Saw pod success 08/22/23 05:13:57.985
    Aug 22 05:13:57.985: INFO: Pod "downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce" satisfied condition "Succeeded or Failed"
    Aug 22 05:13:57.987: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce container client-container: <nil>
    STEP: delete the pod 08/22/23 05:13:58.004
    Aug 22 05:13:58.076: INFO: Waiting for pod downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce to disappear
    Aug 22 05:13:58.081: INFO: Pod downwardapi-volume-b59decfa-c6f8-473d-a45d-74448874e4ce no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 22 05:13:58.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1665" for this suite. 08/22/23 05:13:58.084
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:13:58.09
Aug 22 05:13:58.090: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 05:13:58.09
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:58.103
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:58.106
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 08/22/23 05:13:58.109
Aug 22 05:13:58.117: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6" in namespace "downward-api-4080" to be "Succeeded or Failed"
Aug 22 05:13:58.120: INFO: Pod "downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.020547ms
Aug 22 05:14:00.123: INFO: Pod "downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006604207s
Aug 22 05:14:02.158: INFO: Pod "downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6": Phase="Running", Reason="", readiness=false. Elapsed: 4.040949087s
Aug 22 05:14:04.124: INFO: Pod "downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007473902s
STEP: Saw pod success 08/22/23 05:14:04.124
Aug 22 05:14:04.124: INFO: Pod "downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6" satisfied condition "Succeeded or Failed"
Aug 22 05:14:04.127: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6 container client-container: <nil>
STEP: delete the pod 08/22/23 05:14:04.132
Aug 22 05:14:04.499: INFO: Waiting for pod downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6 to disappear
Aug 22 05:14:04.504: INFO: Pod downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 22 05:14:04.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4080" for this suite. 08/22/23 05:14:04.507
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":267,"skipped":4891,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.424 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:13:58.09
    Aug 22 05:13:58.090: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 05:13:58.09
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:13:58.103
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:13:58.106
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 08/22/23 05:13:58.109
    Aug 22 05:13:58.117: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6" in namespace "downward-api-4080" to be "Succeeded or Failed"
    Aug 22 05:13:58.120: INFO: Pod "downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.020547ms
    Aug 22 05:14:00.123: INFO: Pod "downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006604207s
    Aug 22 05:14:02.158: INFO: Pod "downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6": Phase="Running", Reason="", readiness=false. Elapsed: 4.040949087s
    Aug 22 05:14:04.124: INFO: Pod "downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007473902s
    STEP: Saw pod success 08/22/23 05:14:04.124
    Aug 22 05:14:04.124: INFO: Pod "downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6" satisfied condition "Succeeded or Failed"
    Aug 22 05:14:04.127: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6 container client-container: <nil>
    STEP: delete the pod 08/22/23 05:14:04.132
    Aug 22 05:14:04.499: INFO: Waiting for pod downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6 to disappear
    Aug 22 05:14:04.504: INFO: Pod downwardapi-volume-aabea85a-4878-430c-88db-c5806c3446f6 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 22 05:14:04.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4080" for this suite. 08/22/23 05:14:04.507
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:14:04.514
Aug 22 05:14:04.514: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename prestop 08/22/23 05:14:04.515
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:14:05.118
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:14:05.121
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-7920 08/22/23 05:14:05.124
STEP: Waiting for pods to come up. 08/22/23 05:14:05.133
Aug 22 05:14:05.134: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-7920" to be "running"
Aug 22 05:14:05.137: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 3.014696ms
Aug 22 05:14:07.142: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008596405s
Aug 22 05:14:09.140: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 4.006430749s
Aug 22 05:14:09.140: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-7920 08/22/23 05:14:09.142
Aug 22 05:14:09.178: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-7920" to be "running"
Aug 22 05:14:09.276: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 97.62795ms
Aug 22 05:14:11.281: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102414618s
Aug 22 05:14:13.280: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 4.101872086s
Aug 22 05:14:13.280: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 08/22/23 05:14:13.28
Aug 22 05:14:18.359: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 08/22/23 05:14:18.359
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Aug 22 05:14:18.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-7920" for this suite. 08/22/23 05:14:18.416
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":268,"skipped":4902,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.909 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:14:04.514
    Aug 22 05:14:04.514: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename prestop 08/22/23 05:14:04.515
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:14:05.118
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:14:05.121
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-7920 08/22/23 05:14:05.124
    STEP: Waiting for pods to come up. 08/22/23 05:14:05.133
    Aug 22 05:14:05.134: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-7920" to be "running"
    Aug 22 05:14:05.137: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 3.014696ms
    Aug 22 05:14:07.142: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008596405s
    Aug 22 05:14:09.140: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 4.006430749s
    Aug 22 05:14:09.140: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-7920 08/22/23 05:14:09.142
    Aug 22 05:14:09.178: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-7920" to be "running"
    Aug 22 05:14:09.276: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 97.62795ms
    Aug 22 05:14:11.281: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102414618s
    Aug 22 05:14:13.280: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 4.101872086s
    Aug 22 05:14:13.280: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 08/22/23 05:14:13.28
    Aug 22 05:14:18.359: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 08/22/23 05:14:18.359
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Aug 22 05:14:18.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-7920" for this suite. 08/22/23 05:14:18.416
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:14:18.424
Aug 22 05:14:18.424: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename resourcequota 08/22/23 05:14:18.424
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:14:18.438
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:14:18.44
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 08/22/23 05:14:18.443
STEP: Getting a ResourceQuota 08/22/23 05:14:18.452
STEP: Updating a ResourceQuota 08/22/23 05:14:18.454
STEP: Verifying a ResourceQuota was modified 08/22/23 05:14:18.459
STEP: Deleting a ResourceQuota 08/22/23 05:14:18.462
STEP: Verifying the deleted ResourceQuota 08/22/23 05:14:18.468
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 22 05:14:18.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5976" for this suite. 08/22/23 05:14:18.474
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":269,"skipped":4909,"failed":0}
------------------------------
â€¢ [0.057 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:14:18.424
    Aug 22 05:14:18.424: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename resourcequota 08/22/23 05:14:18.424
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:14:18.438
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:14:18.44
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 08/22/23 05:14:18.443
    STEP: Getting a ResourceQuota 08/22/23 05:14:18.452
    STEP: Updating a ResourceQuota 08/22/23 05:14:18.454
    STEP: Verifying a ResourceQuota was modified 08/22/23 05:14:18.459
    STEP: Deleting a ResourceQuota 08/22/23 05:14:18.462
    STEP: Verifying the deleted ResourceQuota 08/22/23 05:14:18.468
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 22 05:14:18.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5976" for this suite. 08/22/23 05:14:18.474
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:14:18.482
Aug 22 05:14:18.482: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename svc-latency 08/22/23 05:14:18.482
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:14:18.515
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:14:18.517
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Aug 22 05:14:18.520: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5736 08/22/23 05:14:18.521
I0822 05:14:18.527597      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5736, replica count: 1
I0822 05:14:19.579208      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 05:14:20.579340      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 05:14:21.579553      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 05:14:22.579934      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 22 05:14:22.771: INFO: Created: latency-svc-29lsm
Aug 22 05:14:22.784: INFO: Got endpoints: latency-svc-29lsm [104.245084ms]
Aug 22 05:14:22.804: INFO: Created: latency-svc-mq8hc
Aug 22 05:14:22.808: INFO: Got endpoints: latency-svc-mq8hc [22.869476ms]
Aug 22 05:14:22.818: INFO: Created: latency-svc-8hpfn
Aug 22 05:14:22.828: INFO: Created: latency-svc-m52r2
Aug 22 05:14:22.829: INFO: Got endpoints: latency-svc-8hpfn [43.648649ms]
Aug 22 05:14:22.837: INFO: Got endpoints: latency-svc-m52r2 [51.318209ms]
Aug 22 05:14:22.842: INFO: Created: latency-svc-rsvt2
Aug 22 05:14:22.850: INFO: Got endpoints: latency-svc-rsvt2 [63.915974ms]
Aug 22 05:14:22.854: INFO: Created: latency-svc-tmrqp
Aug 22 05:14:22.861: INFO: Got endpoints: latency-svc-tmrqp [76.002208ms]
Aug 22 05:14:22.866: INFO: Created: latency-svc-6lkgr
Aug 22 05:14:22.872: INFO: Created: latency-svc-gmhdp
Aug 22 05:14:22.877: INFO: Got endpoints: latency-svc-6lkgr [91.035612ms]
Aug 22 05:14:22.879: INFO: Got endpoints: latency-svc-gmhdp [92.715153ms]
Aug 22 05:14:22.881: INFO: Created: latency-svc-xqdhk
Aug 22 05:14:22.894: INFO: Created: latency-svc-wjd7h
Aug 22 05:14:22.894: INFO: Got endpoints: latency-svc-xqdhk [107.944817ms]
Aug 22 05:14:22.903: INFO: Got endpoints: latency-svc-wjd7h [116.915736ms]
Aug 22 05:14:22.906: INFO: Created: latency-svc-g68zj
Aug 22 05:14:22.916: INFO: Got endpoints: latency-svc-g68zj [130.082088ms]
Aug 22 05:14:22.921: INFO: Created: latency-svc-rgrfj
Aug 22 05:14:23.267: INFO: Got endpoints: latency-svc-rgrfj [480.812705ms]
Aug 22 05:14:23.272: INFO: Created: latency-svc-8qxkk
Aug 22 05:14:23.413: INFO: Got endpoints: latency-svc-8qxkk [626.981092ms]
Aug 22 05:14:23.416: INFO: Created: latency-svc-5lsqr
Aug 22 05:14:23.561: INFO: Got endpoints: latency-svc-5lsqr [775.251884ms]
Aug 22 05:14:23.566: INFO: Created: latency-svc-wvnl7
Aug 22 05:14:23.624: INFO: Got endpoints: latency-svc-wvnl7 [837.587661ms]
Aug 22 05:14:23.630: INFO: Created: latency-svc-hl5rr
Aug 22 05:14:23.636: INFO: Got endpoints: latency-svc-hl5rr [849.833425ms]
Aug 22 05:14:23.640: INFO: Created: latency-svc-rj6gn
Aug 22 05:14:23.667: INFO: Got endpoints: latency-svc-rj6gn [859.573848ms]
Aug 22 05:14:23.670: INFO: Created: latency-svc-nd79q
Aug 22 05:14:23.764: INFO: Got endpoints: latency-svc-nd79q [935.103961ms]
Aug 22 05:14:23.768: INFO: Created: latency-svc-pddcn
Aug 22 05:14:23.777: INFO: Got endpoints: latency-svc-pddcn [940.26787ms]
Aug 22 05:14:23.783: INFO: Created: latency-svc-cl7zt
Aug 22 05:14:23.792: INFO: Got endpoints: latency-svc-cl7zt [942.728105ms]
Aug 22 05:14:23.810: INFO: Created: latency-svc-5hv4b
Aug 22 05:14:23.811: INFO: Got endpoints: latency-svc-5hv4b [949.04126ms]
Aug 22 05:14:23.820: INFO: Created: latency-svc-ccv8q
Aug 22 05:14:23.826: INFO: Created: latency-svc-5hz2r
Aug 22 05:14:23.827: INFO: Got endpoints: latency-svc-ccv8q [950.25719ms]
Aug 22 05:14:23.831: INFO: Got endpoints: latency-svc-5hz2r [952.010951ms]
Aug 22 05:14:23.849: INFO: Created: latency-svc-l8drp
Aug 22 05:14:23.857: INFO: Got endpoints: latency-svc-l8drp [963.058147ms]
Aug 22 05:14:23.858: INFO: Created: latency-svc-p44xn
Aug 22 05:14:23.865: INFO: Created: latency-svc-69m9z
Aug 22 05:14:23.874: INFO: Got endpoints: latency-svc-p44xn [971.010375ms]
Aug 22 05:14:23.874: INFO: Got endpoints: latency-svc-69m9z [958.320548ms]
Aug 22 05:14:23.886: INFO: Created: latency-svc-gz78w
Aug 22 05:14:23.903: INFO: Created: latency-svc-rf6lk
Aug 22 05:14:23.904: INFO: Got endpoints: latency-svc-gz78w [637.245087ms]
Aug 22 05:14:23.959: INFO: Got endpoints: latency-svc-rf6lk [545.904844ms]
Aug 22 05:14:23.969: INFO: Created: latency-svc-lphwc
Aug 22 05:14:23.974: INFO: Got endpoints: latency-svc-lphwc [412.488181ms]
Aug 22 05:14:23.982: INFO: Created: latency-svc-2sj4t
Aug 22 05:14:23.988: INFO: Got endpoints: latency-svc-2sj4t [364.77678ms]
Aug 22 05:14:23.991: INFO: Created: latency-svc-xfw7s
Aug 22 05:14:24.069: INFO: Got endpoints: latency-svc-xfw7s [433.103908ms]
Aug 22 05:14:24.075: INFO: Created: latency-svc-2l6k6
Aug 22 05:14:24.082: INFO: Got endpoints: latency-svc-2l6k6 [414.626903ms]
Aug 22 05:14:24.086: INFO: Created: latency-svc-5rfp4
Aug 22 05:14:24.092: INFO: Got endpoints: latency-svc-5rfp4 [327.086197ms]
Aug 22 05:14:24.095: INFO: Created: latency-svc-gxjgl
Aug 22 05:14:24.136: INFO: Created: latency-svc-psk6n
Aug 22 05:14:24.137: INFO: Got endpoints: latency-svc-psk6n [344.397275ms]
Aug 22 05:14:24.137: INFO: Got endpoints: latency-svc-gxjgl [360.270645ms]
Aug 22 05:14:24.167: INFO: Created: latency-svc-xvg4c
Aug 22 05:14:24.167: INFO: Got endpoints: latency-svc-xvg4c [356.303822ms]
Aug 22 05:14:24.195: INFO: Created: latency-svc-r494q
Aug 22 05:14:24.204: INFO: Created: latency-svc-lsghw
Aug 22 05:14:24.208: INFO: Got endpoints: latency-svc-r494q [380.769302ms]
Aug 22 05:14:24.210: INFO: Got endpoints: latency-svc-lsghw [379.079722ms]
Aug 22 05:14:24.212: INFO: Created: latency-svc-rstv2
Aug 22 05:14:24.222: INFO: Created: latency-svc-phjmk
Aug 22 05:14:24.243: INFO: Got endpoints: latency-svc-phjmk [368.621712ms]
Aug 22 05:14:24.243: INFO: Got endpoints: latency-svc-rstv2 [385.57633ms]
Aug 22 05:14:24.514: INFO: Created: latency-svc-9645c
Aug 22 05:14:24.532: INFO: Got endpoints: latency-svc-9645c [657.595557ms]
Aug 22 05:14:24.534: INFO: Created: latency-svc-cmvwz
Aug 22 05:14:24.541: INFO: Got endpoints: latency-svc-cmvwz [637.47019ms]
Aug 22 05:14:24.548: INFO: Created: latency-svc-dk6vc
Aug 22 05:14:24.553: INFO: Created: latency-svc-qp24t
Aug 22 05:14:24.570: INFO: Got endpoints: latency-svc-dk6vc [610.752666ms]
Aug 22 05:14:24.576: INFO: Got endpoints: latency-svc-qp24t [601.492921ms]
Aug 22 05:14:24.579: INFO: Created: latency-svc-9z2zk
Aug 22 05:14:24.586: INFO: Got endpoints: latency-svc-9z2zk [597.440651ms]
Aug 22 05:14:24.593: INFO: Created: latency-svc-knw5j
Aug 22 05:14:24.688: INFO: Created: latency-svc-xnsxk
Aug 22 05:14:24.688: INFO: Got endpoints: latency-svc-xnsxk [605.74071ms]
Aug 22 05:14:24.688: INFO: Got endpoints: latency-svc-knw5j [619.158443ms]
Aug 22 05:14:24.857: INFO: Created: latency-svc-4b7n2
Aug 22 05:14:24.887: INFO: Got endpoints: latency-svc-4b7n2 [795.49988ms]
Aug 22 05:14:25.205: INFO: Created: latency-svc-thd6x
Aug 22 05:14:25.212: INFO: Got endpoints: latency-svc-thd6x [1.07475915s]
Aug 22 05:14:25.216: INFO: Created: latency-svc-dhnlw
Aug 22 05:14:25.222: INFO: Got endpoints: latency-svc-dhnlw [1.084687456s]
Aug 22 05:14:25.226: INFO: Created: latency-svc-drdnl
Aug 22 05:14:25.234: INFO: Got endpoints: latency-svc-drdnl [1.066521986s]
Aug 22 05:14:25.412: INFO: Created: latency-svc-pj4dc
Aug 22 05:14:25.815: INFO: Got endpoints: latency-svc-pj4dc [1.60731571s]
Aug 22 05:14:25.920: INFO: Created: latency-svc-9gq2w
Aug 22 05:14:26.007: INFO: Got endpoints: latency-svc-9gq2w [1.797153546s]
Aug 22 05:14:26.012: INFO: Created: latency-svc-9jhbd
Aug 22 05:14:26.022: INFO: Got endpoints: latency-svc-9jhbd [1.778918056s]
Aug 22 05:14:26.025: INFO: Created: latency-svc-474p4
Aug 22 05:14:26.031: INFO: Got endpoints: latency-svc-474p4 [1.788080174s]
Aug 22 05:14:26.042: INFO: Created: latency-svc-c98wr
Aug 22 05:14:26.043: INFO: Got endpoints: latency-svc-c98wr [1.510500615s]
Aug 22 05:14:26.047: INFO: Created: latency-svc-trk4d
Aug 22 05:14:26.052: INFO: Got endpoints: latency-svc-trk4d [1.51071111s]
Aug 22 05:14:26.057: INFO: Created: latency-svc-2sm26
Aug 22 05:14:26.060: INFO: Got endpoints: latency-svc-2sm26 [1.490382742s]
Aug 22 05:14:26.065: INFO: Created: latency-svc-2mbw2
Aug 22 05:14:26.068: INFO: Got endpoints: latency-svc-2mbw2 [1.492436636s]
Aug 22 05:14:26.072: INFO: Created: latency-svc-rb786
Aug 22 05:14:26.079: INFO: Got endpoints: latency-svc-rb786 [1.492503882s]
Aug 22 05:14:26.079: INFO: Created: latency-svc-f5g7r
Aug 22 05:14:26.086: INFO: Got endpoints: latency-svc-f5g7r [1.397469478s]
Aug 22 05:14:26.090: INFO: Created: latency-svc-7kmd9
Aug 22 05:14:26.734: INFO: Got endpoints: latency-svc-7kmd9 [2.046161031s]
Aug 22 05:14:26.740: INFO: Created: latency-svc-kqhrm
Aug 22 05:14:26.747: INFO: Got endpoints: latency-svc-kqhrm [1.859454349s]
Aug 22 05:14:26.753: INFO: Created: latency-svc-f5g64
Aug 22 05:14:26.757: INFO: Got endpoints: latency-svc-f5g64 [1.544651256s]
Aug 22 05:14:26.775: INFO: Created: latency-svc-lff4g
Aug 22 05:14:26.783: INFO: Got endpoints: latency-svc-lff4g [1.560719622s]
Aug 22 05:14:26.791: INFO: Created: latency-svc-8pgvj
Aug 22 05:14:26.794: INFO: Got endpoints: latency-svc-8pgvj [1.560216108s]
Aug 22 05:14:26.804: INFO: Created: latency-svc-tghgh
Aug 22 05:14:26.815: INFO: Got endpoints: latency-svc-tghgh [999.57164ms]
Aug 22 05:14:26.815: INFO: Created: latency-svc-m5ps5
Aug 22 05:14:26.823: INFO: Created: latency-svc-x9jf8
Aug 22 05:14:26.829: INFO: Got endpoints: latency-svc-m5ps5 [821.656222ms]
Aug 22 05:14:26.834: INFO: Got endpoints: latency-svc-x9jf8 [812.072953ms]
Aug 22 05:14:26.834: INFO: Created: latency-svc-mflns
Aug 22 05:14:26.838: INFO: Created: latency-svc-bvznh
Aug 22 05:14:26.853: INFO: Got endpoints: latency-svc-mflns [822.358189ms]
Aug 22 05:14:26.853: INFO: Got endpoints: latency-svc-bvznh [810.485966ms]
Aug 22 05:14:26.854: INFO: Created: latency-svc-vqb88
Aug 22 05:14:26.890: INFO: Got endpoints: latency-svc-vqb88 [836.918106ms]
Aug 22 05:14:26.903: INFO: Created: latency-svc-cbjll
Aug 22 05:14:26.915: INFO: Got endpoints: latency-svc-cbjll [854.546417ms]
Aug 22 05:14:26.922: INFO: Created: latency-svc-25qwv
Aug 22 05:14:26.930: INFO: Got endpoints: latency-svc-25qwv [862.019227ms]
Aug 22 05:14:26.935: INFO: Created: latency-svc-8gsb2
Aug 22 05:14:26.941: INFO: Got endpoints: latency-svc-8gsb2 [862.490032ms]
Aug 22 05:14:26.947: INFO: Created: latency-svc-dh2l6
Aug 22 05:14:26.950: INFO: Got endpoints: latency-svc-dh2l6 [863.722843ms]
Aug 22 05:14:26.956: INFO: Created: latency-svc-vdmgz
Aug 22 05:14:26.961: INFO: Got endpoints: latency-svc-vdmgz [226.25582ms]
Aug 22 05:14:26.975: INFO: Created: latency-svc-dfhk8
Aug 22 05:14:26.976: INFO: Got endpoints: latency-svc-dfhk8 [229.580507ms]
Aug 22 05:14:27.004: INFO: Created: latency-svc-7rcjm
Aug 22 05:14:27.194: INFO: Got endpoints: latency-svc-7rcjm [437.343802ms]
Aug 22 05:14:27.208: INFO: Created: latency-svc-dpb7s
Aug 22 05:14:27.216: INFO: Got endpoints: latency-svc-dpb7s [432.634568ms]
Aug 22 05:14:27.222: INFO: Created: latency-svc-szgln
Aug 22 05:14:27.233: INFO: Got endpoints: latency-svc-szgln [438.674829ms]
Aug 22 05:14:27.238: INFO: Created: latency-svc-qxhqf
Aug 22 05:14:27.257: INFO: Got endpoints: latency-svc-qxhqf [442.123579ms]
Aug 22 05:14:27.261: INFO: Created: latency-svc-cfnmz
Aug 22 05:14:27.726: INFO: Got endpoints: latency-svc-cfnmz [897.03459ms]
Aug 22 05:14:27.729: INFO: Created: latency-svc-zmtlm
Aug 22 05:14:27.748: INFO: Got endpoints: latency-svc-zmtlm [914.6511ms]
Aug 22 05:14:27.752: INFO: Created: latency-svc-vrkvt
Aug 22 05:14:27.761: INFO: Got endpoints: latency-svc-vrkvt [907.878384ms]
Aug 22 05:14:27.766: INFO: Created: latency-svc-qj8jq
Aug 22 05:14:27.795: INFO: Got endpoints: latency-svc-qj8jq [941.962199ms]
Aug 22 05:14:27.807: INFO: Created: latency-svc-85kj7
Aug 22 05:14:27.817: INFO: Got endpoints: latency-svc-85kj7 [927.120995ms]
Aug 22 05:14:27.830: INFO: Created: latency-svc-lk6bf
Aug 22 05:14:27.831: INFO: Got endpoints: latency-svc-lk6bf [916.061896ms]
Aug 22 05:14:27.840: INFO: Created: latency-svc-wj88z
Aug 22 05:14:27.847: INFO: Got endpoints: latency-svc-wj88z [917.110915ms]
Aug 22 05:14:27.854: INFO: Created: latency-svc-z7j6f
Aug 22 05:14:27.881: INFO: Got endpoints: latency-svc-z7j6f [940.276846ms]
Aug 22 05:14:27.889: INFO: Created: latency-svc-h9bhk
Aug 22 05:14:27.890: INFO: Got endpoints: latency-svc-h9bhk [940.180334ms]
Aug 22 05:14:27.897: INFO: Created: latency-svc-g722z
Aug 22 05:14:27.903: INFO: Got endpoints: latency-svc-g722z [942.407494ms]
Aug 22 05:14:27.909: INFO: Created: latency-svc-q2mms
Aug 22 05:14:27.916: INFO: Got endpoints: latency-svc-q2mms [939.166183ms]
Aug 22 05:14:27.920: INFO: Created: latency-svc-lb2b2
Aug 22 05:14:27.927: INFO: Got endpoints: latency-svc-lb2b2 [732.180817ms]
Aug 22 05:14:27.935: INFO: Created: latency-svc-xxj7g
Aug 22 05:14:27.936: INFO: Got endpoints: latency-svc-xxj7g [720.255283ms]
Aug 22 05:14:27.947: INFO: Created: latency-svc-kdbbb
Aug 22 05:14:27.950: INFO: Got endpoints: latency-svc-kdbbb [717.161969ms]
Aug 22 05:14:27.956: INFO: Created: latency-svc-xf5gw
Aug 22 05:14:27.961: INFO: Got endpoints: latency-svc-xf5gw [703.630174ms]
Aug 22 05:14:27.964: INFO: Created: latency-svc-sbmqb
Aug 22 05:14:27.968: INFO: Got endpoints: latency-svc-sbmqb [241.998905ms]
Aug 22 05:14:27.972: INFO: Created: latency-svc-b6hxx
Aug 22 05:14:27.978: INFO: Got endpoints: latency-svc-b6hxx [229.010187ms]
Aug 22 05:14:27.983: INFO: Created: latency-svc-5czlk
Aug 22 05:14:27.986: INFO: Got endpoints: latency-svc-5czlk [224.114994ms]
Aug 22 05:14:27.991: INFO: Created: latency-svc-hdd8s
Aug 22 05:14:27.997: INFO: Got endpoints: latency-svc-hdd8s [201.095255ms]
Aug 22 05:14:28.001: INFO: Created: latency-svc-fktgw
Aug 22 05:14:28.005: INFO: Got endpoints: latency-svc-fktgw [188.177249ms]
Aug 22 05:14:28.008: INFO: Created: latency-svc-vpcl2
Aug 22 05:14:28.013: INFO: Got endpoints: latency-svc-vpcl2 [182.364965ms]
Aug 22 05:14:28.017: INFO: Created: latency-svc-9vlpt
Aug 22 05:14:28.022: INFO: Got endpoints: latency-svc-9vlpt [174.031301ms]
Aug 22 05:14:28.028: INFO: Created: latency-svc-8zvvx
Aug 22 05:14:28.036: INFO: Got endpoints: latency-svc-8zvvx [154.611517ms]
Aug 22 05:14:28.038: INFO: Created: latency-svc-tmbp4
Aug 22 05:14:28.042: INFO: Got endpoints: latency-svc-tmbp4 [151.549153ms]
Aug 22 05:14:28.049: INFO: Created: latency-svc-8mq74
Aug 22 05:14:28.182: INFO: Created: latency-svc-9srxh
Aug 22 05:14:28.186: INFO: Got endpoints: latency-svc-9srxh [269.862579ms]
Aug 22 05:14:28.186: INFO: Got endpoints: latency-svc-8mq74 [282.439113ms]
Aug 22 05:14:28.218: INFO: Created: latency-svc-6bv4q
Aug 22 05:14:28.224: INFO: Got endpoints: latency-svc-6bv4q [297.28638ms]
Aug 22 05:14:28.228: INFO: Created: latency-svc-7zl27
Aug 22 05:14:28.246: INFO: Got endpoints: latency-svc-7zl27 [309.698495ms]
Aug 22 05:14:28.251: INFO: Created: latency-svc-r22sk
Aug 22 05:14:28.259: INFO: Got endpoints: latency-svc-r22sk [309.425755ms]
Aug 22 05:14:28.264: INFO: Created: latency-svc-7fq47
Aug 22 05:14:28.446: INFO: Got endpoints: latency-svc-7fq47 [485.441737ms]
Aug 22 05:14:28.453: INFO: Created: latency-svc-sk9gs
Aug 22 05:14:28.487: INFO: Got endpoints: latency-svc-sk9gs [519.212115ms]
Aug 22 05:14:28.490: INFO: Created: latency-svc-k7s5g
Aug 22 05:14:28.494: INFO: Created: latency-svc-smpsq
Aug 22 05:14:28.496: INFO: Got endpoints: latency-svc-k7s5g [518.893938ms]
Aug 22 05:14:28.499: INFO: Got endpoints: latency-svc-smpsq [513.357542ms]
Aug 22 05:14:28.503: INFO: Created: latency-svc-ptb9f
Aug 22 05:14:28.511: INFO: Got endpoints: latency-svc-ptb9f [514.776655ms]
Aug 22 05:14:28.514: INFO: Created: latency-svc-bg8h8
Aug 22 05:14:28.520: INFO: Got endpoints: latency-svc-bg8h8 [515.011986ms]
Aug 22 05:14:28.524: INFO: Created: latency-svc-l6g5j
Aug 22 05:14:28.533: INFO: Created: latency-svc-ppssm
Aug 22 05:14:28.534: INFO: Got endpoints: latency-svc-l6g5j [520.457192ms]
Aug 22 05:14:28.539: INFO: Got endpoints: latency-svc-ppssm [517.130831ms]
Aug 22 05:14:28.543: INFO: Created: latency-svc-r4zq2
Aug 22 05:14:28.551: INFO: Got endpoints: latency-svc-r4zq2 [514.841305ms]
Aug 22 05:14:28.554: INFO: Created: latency-svc-f9sfx
Aug 22 05:14:28.560: INFO: Got endpoints: latency-svc-f9sfx [518.246954ms]
Aug 22 05:14:28.563: INFO: Created: latency-svc-6j88b
Aug 22 05:14:28.570: INFO: Got endpoints: latency-svc-6j88b [384.081598ms]
Aug 22 05:14:28.573: INFO: Created: latency-svc-f6hww
Aug 22 05:14:28.583: INFO: Got endpoints: latency-svc-f6hww [396.907089ms]
Aug 22 05:14:28.592: INFO: Created: latency-svc-hf8jt
Aug 22 05:14:28.596: INFO: Got endpoints: latency-svc-hf8jt [371.578099ms]
Aug 22 05:14:28.607: INFO: Created: latency-svc-mcbt5
Aug 22 05:14:28.611: INFO: Got endpoints: latency-svc-mcbt5 [365.439142ms]
Aug 22 05:14:28.618: INFO: Created: latency-svc-bq459
Aug 22 05:14:28.625: INFO: Got endpoints: latency-svc-bq459 [365.79468ms]
Aug 22 05:14:28.630: INFO: Created: latency-svc-m66h7
Aug 22 05:14:28.637: INFO: Got endpoints: latency-svc-m66h7 [191.032519ms]
Aug 22 05:14:28.639: INFO: Created: latency-svc-lfrfk
Aug 22 05:14:28.645: INFO: Got endpoints: latency-svc-lfrfk [158.047764ms]
Aug 22 05:14:28.651: INFO: Created: latency-svc-xv742
Aug 22 05:14:28.657: INFO: Created: latency-svc-jjw6k
Aug 22 05:14:28.660: INFO: Got endpoints: latency-svc-xv742 [163.231319ms]
Aug 22 05:14:28.664: INFO: Got endpoints: latency-svc-jjw6k [164.583595ms]
Aug 22 05:14:28.668: INFO: Created: latency-svc-mx8tw
Aug 22 05:14:28.675: INFO: Created: latency-svc-dpjr7
Aug 22 05:14:28.697: INFO: Got endpoints: latency-svc-mx8tw [185.808486ms]
Aug 22 05:14:28.703: INFO: Created: latency-svc-hr7hq
Aug 22 05:14:28.716: INFO: Created: latency-svc-p9nlp
Aug 22 05:14:28.725: INFO: Created: latency-svc-mmnxk
Aug 22 05:14:28.735: INFO: Created: latency-svc-9zdjh
Aug 22 05:14:28.745: INFO: Created: latency-svc-lzzzk
Aug 22 05:14:28.747: INFO: Got endpoints: latency-svc-dpjr7 [227.075197ms]
Aug 22 05:14:28.762: INFO: Created: latency-svc-qfsj8
Aug 22 05:14:28.766: INFO: Created: latency-svc-ppl7s
Aug 22 05:14:28.771: INFO: Created: latency-svc-5vgcs
Aug 22 05:14:28.895: INFO: Created: latency-svc-k2lwh
Aug 22 05:14:28.908: INFO: Got endpoints: latency-svc-p9nlp [369.382629ms]
Aug 22 05:14:28.908: INFO: Got endpoints: latency-svc-hr7hq [374.558049ms]
Aug 22 05:14:28.914: INFO: Created: latency-svc-d2hgj
Aug 22 05:14:28.928: INFO: Got endpoints: latency-svc-mmnxk [376.516163ms]
Aug 22 05:14:28.933: INFO: Created: latency-svc-6xx84
Aug 22 05:14:28.943: INFO: Created: latency-svc-jp9fd
Aug 22 05:14:28.955: INFO: Got endpoints: latency-svc-9zdjh [395.130986ms]
Aug 22 05:14:28.962: INFO: Created: latency-svc-9jr87
Aug 22 05:14:29.042: INFO: Created: latency-svc-pcfcz
Aug 22 05:14:29.228: INFO: Got endpoints: latency-svc-lzzzk [657.631244ms]
Aug 22 05:14:29.236: INFO: Got endpoints: latency-svc-ppl7s [640.760512ms]
Aug 22 05:14:29.237: INFO: Got endpoints: latency-svc-qfsj8 [653.709637ms]
Aug 22 05:14:29.239: INFO: Got endpoints: latency-svc-k2lwh [613.555082ms]
Aug 22 05:14:29.239: INFO: Got endpoints: latency-svc-5vgcs [627.746447ms]
Aug 22 05:14:29.251: INFO: Got endpoints: latency-svc-d2hgj [613.407937ms]
Aug 22 05:14:29.255: INFO: Created: latency-svc-zs5ht
Aug 22 05:14:29.265: INFO: Created: latency-svc-t8dw8
Aug 22 05:14:29.274: INFO: Created: latency-svc-72447
Aug 22 05:14:29.281: INFO: Created: latency-svc-ctmdk
Aug 22 05:14:29.290: INFO: Created: latency-svc-8xslh
Aug 22 05:14:29.300: INFO: Got endpoints: latency-svc-6xx84 [654.559782ms]
Aug 22 05:14:29.305: INFO: Created: latency-svc-thvzh
Aug 22 05:14:29.314: INFO: Created: latency-svc-f9sb2
Aug 22 05:14:29.915: INFO: Got endpoints: latency-svc-jp9fd [1.255142437s]
Aug 22 05:14:29.922: INFO: Got endpoints: latency-svc-t8dw8 [1.013591272s]
Aug 22 05:14:29.922: INFO: Got endpoints: latency-svc-9jr87 [1.25868845s]
Aug 22 05:14:29.922: INFO: Got endpoints: latency-svc-pcfcz [1.225007751s]
Aug 22 05:14:29.923: INFO: Got endpoints: latency-svc-zs5ht [1.175159319s]
Aug 22 05:14:29.990: INFO: Created: latency-svc-jzddq
Aug 22 05:14:30.058: INFO: Got endpoints: latency-svc-8xslh [1.10308951s]
Aug 22 05:14:30.058: INFO: Got endpoints: latency-svc-72447 [1.15004871s]
Aug 22 05:14:30.060: INFO: Got endpoints: latency-svc-thvzh [832.126745ms]
Aug 22 05:14:30.060: INFO: Got endpoints: latency-svc-f9sb2 [822.825425ms]
Aug 22 05:14:30.060: INFO: Got endpoints: latency-svc-ctmdk [1.131762052s]
Aug 22 05:14:30.084: INFO: Created: latency-svc-wwjfp
Aug 22 05:14:30.088: INFO: Got endpoints: latency-svc-jzddq [851.865348ms]
Aug 22 05:14:30.092: INFO: Got endpoints: latency-svc-wwjfp [852.790775ms]
Aug 22 05:14:30.107: INFO: Created: latency-svc-hm4r4
Aug 22 05:14:30.123: INFO: Got endpoints: latency-svc-hm4r4 [884.244133ms]
Aug 22 05:14:30.150: INFO: Created: latency-svc-m8r5l
Aug 22 05:14:30.176: INFO: Got endpoints: latency-svc-m8r5l [924.706323ms]
Aug 22 05:14:30.180: INFO: Created: latency-svc-7zk5l
Aug 22 05:14:30.192: INFO: Got endpoints: latency-svc-7zk5l [892.35997ms]
Aug 22 05:14:30.387: INFO: Created: latency-svc-rcnrg
Aug 22 05:14:30.451: INFO: Got endpoints: latency-svc-rcnrg [535.676155ms]
Aug 22 05:14:30.494: INFO: Created: latency-svc-86rj8
Aug 22 05:14:30.494: INFO: Got endpoints: latency-svc-86rj8 [572.064773ms]
Aug 22 05:14:30.563: INFO: Created: latency-svc-p7m7s
Aug 22 05:14:30.748: INFO: Got endpoints: latency-svc-p7m7s [825.538465ms]
Aug 22 05:14:30.758: INFO: Created: latency-svc-5dlpj
Aug 22 05:14:31.514: INFO: Got endpoints: latency-svc-5dlpj [1.591637967s]
Aug 22 05:14:31.514: INFO: Created: latency-svc-vdlsb
Aug 22 05:14:31.559: INFO: Got endpoints: latency-svc-vdlsb [1.63628007s]
Aug 22 05:14:31.562: INFO: Created: latency-svc-prl2j
Aug 22 05:14:31.572: INFO: Got endpoints: latency-svc-prl2j [1.513381629s]
Aug 22 05:14:31.577: INFO: Created: latency-svc-dwxs8
Aug 22 05:14:31.582: INFO: Got endpoints: latency-svc-dwxs8 [1.523127595s]
Aug 22 05:14:31.586: INFO: Created: latency-svc-d7tmb
Aug 22 05:14:31.590: INFO: Created: latency-svc-r2z65
Aug 22 05:14:31.595: INFO: Got endpoints: latency-svc-d7tmb [1.535273692s]
Aug 22 05:14:31.596: INFO: Got endpoints: latency-svc-r2z65 [1.535973124s]
Aug 22 05:14:31.604: INFO: Created: latency-svc-7fvvg
Aug 22 05:14:31.610: INFO: Got endpoints: latency-svc-7fvvg [1.550226394s]
Aug 22 05:14:31.617: INFO: Created: latency-svc-qzvtl
Aug 22 05:14:31.622: INFO: Got endpoints: latency-svc-qzvtl [1.5334605s]
Aug 22 05:14:31.625: INFO: Created: latency-svc-jw6qb
Aug 22 05:14:31.630: INFO: Got endpoints: latency-svc-jw6qb [1.537994235s]
Aug 22 05:14:31.634: INFO: Created: latency-svc-zjqm9
Aug 22 05:14:31.639: INFO: Got endpoints: latency-svc-zjqm9 [1.516037363s]
Aug 22 05:14:31.652: INFO: Created: latency-svc-tdgf4
Aug 22 05:14:31.653: INFO: Got endpoints: latency-svc-tdgf4 [1.476714179s]
Aug 22 05:14:31.659: INFO: Created: latency-svc-gk882
Aug 22 05:14:31.668: INFO: Got endpoints: latency-svc-gk882 [1.475821883s]
Aug 22 05:14:31.672: INFO: Created: latency-svc-2z5bj
Aug 22 05:14:31.678: INFO: Got endpoints: latency-svc-2z5bj [1.226906382s]
Aug 22 05:14:31.683: INFO: Created: latency-svc-6zws7
Aug 22 05:14:31.689: INFO: Got endpoints: latency-svc-6zws7 [1.194424202s]
Aug 22 05:14:31.690: INFO: Created: latency-svc-kd7r9
Aug 22 05:14:31.696: INFO: Got endpoints: latency-svc-kd7r9 [947.866417ms]
Aug 22 05:14:31.702: INFO: Created: latency-svc-68jp6
Aug 22 05:14:31.930: INFO: Got endpoints: latency-svc-68jp6 [415.839077ms]
Aug 22 05:14:31.965: INFO: Created: latency-svc-w9cpx
Aug 22 05:14:32.235: INFO: Got endpoints: latency-svc-w9cpx [675.768131ms]
Aug 22 05:14:32.240: INFO: Created: latency-svc-xwrp2
Aug 22 05:14:32.261: INFO: Got endpoints: latency-svc-xwrp2 [689.139185ms]
Aug 22 05:14:32.266: INFO: Created: latency-svc-rc4lv
Aug 22 05:14:32.269: INFO: Got endpoints: latency-svc-rc4lv [687.554775ms]
Aug 22 05:14:32.273: INFO: Created: latency-svc-pwlwv
Aug 22 05:14:32.280: INFO: Got endpoints: latency-svc-pwlwv [684.696332ms]
Aug 22 05:14:32.284: INFO: Created: latency-svc-cr4nv
Aug 22 05:14:32.288: INFO: Got endpoints: latency-svc-cr4nv [693.447239ms]
Aug 22 05:14:32.295: INFO: Created: latency-svc-xx2jj
Aug 22 05:14:32.300: INFO: Got endpoints: latency-svc-xx2jj [689.572099ms]
Aug 22 05:14:32.308: INFO: Created: latency-svc-82jkj
Aug 22 05:14:32.327: INFO: Got endpoints: latency-svc-82jkj [705.106363ms]
Aug 22 05:14:32.332: INFO: Created: latency-svc-mb929
Aug 22 05:14:32.361: INFO: Got endpoints: latency-svc-mb929 [730.757826ms]
Aug 22 05:14:32.365: INFO: Created: latency-svc-7kvb7
Aug 22 05:14:32.377: INFO: Got endpoints: latency-svc-7kvb7 [737.828082ms]
Aug 22 05:14:32.381: INFO: Created: latency-svc-jz8d8
Aug 22 05:14:32.395: INFO: Got endpoints: latency-svc-jz8d8 [742.236081ms]
Aug 22 05:14:32.400: INFO: Created: latency-svc-knx4n
Aug 22 05:14:32.408: INFO: Got endpoints: latency-svc-knx4n [739.84214ms]
Aug 22 05:14:32.411: INFO: Created: latency-svc-n6jv5
Aug 22 05:14:32.416: INFO: Got endpoints: latency-svc-n6jv5 [738.681162ms]
Aug 22 05:14:32.421: INFO: Created: latency-svc-n5d8w
Aug 22 05:14:32.427: INFO: Got endpoints: latency-svc-n5d8w [738.277325ms]
Aug 22 05:14:32.435: INFO: Created: latency-svc-8fr52
Aug 22 05:14:32.440: INFO: Got endpoints: latency-svc-8fr52 [744.176071ms]
Aug 22 05:14:32.444: INFO: Created: latency-svc-8qc76
Aug 22 05:14:32.451: INFO: Got endpoints: latency-svc-8qc76 [520.77651ms]
Aug 22 05:14:32.456: INFO: Created: latency-svc-kmbnw
Aug 22 05:14:32.482: INFO: Got endpoints: latency-svc-kmbnw [247.485628ms]
Aug 22 05:14:32.519: INFO: Created: latency-svc-l42vb
Aug 22 05:14:32.519: INFO: Got endpoints: latency-svc-l42vb [257.948187ms]
Aug 22 05:14:32.771: INFO: Created: latency-svc-86g7w
Aug 22 05:14:32.777: INFO: Got endpoints: latency-svc-86g7w [507.808009ms]
Aug 22 05:14:32.790: INFO: Created: latency-svc-rbnzd
Aug 22 05:14:32.799: INFO: Created: latency-svc-xxzfn
Aug 22 05:14:32.803: INFO: Got endpoints: latency-svc-rbnzd [522.915122ms]
Aug 22 05:14:32.808: INFO: Created: latency-svc-79nzw
Aug 22 05:14:32.808: INFO: Got endpoints: latency-svc-xxzfn [519.856804ms]
Aug 22 05:14:32.816: INFO: Created: latency-svc-grh2z
Aug 22 05:14:32.817: INFO: Got endpoints: latency-svc-79nzw [517.553605ms]
Aug 22 05:14:32.823: INFO: Got endpoints: latency-svc-grh2z [495.454294ms]
Aug 22 05:14:32.826: INFO: Created: latency-svc-ngkx9
Aug 22 05:14:32.833: INFO: Got endpoints: latency-svc-ngkx9 [472.675249ms]
Aug 22 05:14:32.836: INFO: Created: latency-svc-4zmsc
Aug 22 05:14:32.841: INFO: Got endpoints: latency-svc-4zmsc [463.498642ms]
Aug 22 05:14:32.841: INFO: Latencies: [22.869476ms 43.648649ms 51.318209ms 63.915974ms 76.002208ms 91.035612ms 92.715153ms 107.944817ms 116.915736ms 130.082088ms 151.549153ms 154.611517ms 158.047764ms 163.231319ms 164.583595ms 174.031301ms 182.364965ms 185.808486ms 188.177249ms 191.032519ms 201.095255ms 224.114994ms 226.25582ms 227.075197ms 229.010187ms 229.580507ms 241.998905ms 247.485628ms 257.948187ms 269.862579ms 282.439113ms 297.28638ms 309.425755ms 309.698495ms 327.086197ms 344.397275ms 356.303822ms 360.270645ms 364.77678ms 365.439142ms 365.79468ms 368.621712ms 369.382629ms 371.578099ms 374.558049ms 376.516163ms 379.079722ms 380.769302ms 384.081598ms 385.57633ms 395.130986ms 396.907089ms 412.488181ms 414.626903ms 415.839077ms 432.634568ms 433.103908ms 437.343802ms 438.674829ms 442.123579ms 463.498642ms 472.675249ms 480.812705ms 485.441737ms 495.454294ms 507.808009ms 513.357542ms 514.776655ms 514.841305ms 515.011986ms 517.130831ms 517.553605ms 518.246954ms 518.893938ms 519.212115ms 519.856804ms 520.457192ms 520.77651ms 522.915122ms 535.676155ms 545.904844ms 572.064773ms 597.440651ms 601.492921ms 605.74071ms 610.752666ms 613.407937ms 613.555082ms 619.158443ms 626.981092ms 627.746447ms 637.245087ms 637.47019ms 640.760512ms 653.709637ms 654.559782ms 657.595557ms 657.631244ms 675.768131ms 684.696332ms 687.554775ms 689.139185ms 689.572099ms 693.447239ms 703.630174ms 705.106363ms 717.161969ms 720.255283ms 730.757826ms 732.180817ms 737.828082ms 738.277325ms 738.681162ms 739.84214ms 742.236081ms 744.176071ms 775.251884ms 795.49988ms 810.485966ms 812.072953ms 821.656222ms 822.358189ms 822.825425ms 825.538465ms 832.126745ms 836.918106ms 837.587661ms 849.833425ms 851.865348ms 852.790775ms 854.546417ms 859.573848ms 862.019227ms 862.490032ms 863.722843ms 884.244133ms 892.35997ms 897.03459ms 907.878384ms 914.6511ms 916.061896ms 917.110915ms 924.706323ms 927.120995ms 935.103961ms 939.166183ms 940.180334ms 940.26787ms 940.276846ms 941.962199ms 942.407494ms 942.728105ms 947.866417ms 949.04126ms 950.25719ms 952.010951ms 958.320548ms 963.058147ms 971.010375ms 999.57164ms 1.013591272s 1.066521986s 1.07475915s 1.084687456s 1.10308951s 1.131762052s 1.15004871s 1.175159319s 1.194424202s 1.225007751s 1.226906382s 1.255142437s 1.25868845s 1.397469478s 1.475821883s 1.476714179s 1.490382742s 1.492436636s 1.492503882s 1.510500615s 1.51071111s 1.513381629s 1.516037363s 1.523127595s 1.5334605s 1.535273692s 1.535973124s 1.537994235s 1.544651256s 1.550226394s 1.560216108s 1.560719622s 1.591637967s 1.60731571s 1.63628007s 1.778918056s 1.788080174s 1.797153546s 1.859454349s 2.046161031s]
Aug 22 05:14:32.841: INFO: 50 %ile: 687.554775ms
Aug 22 05:14:32.841: INFO: 90 %ile: 1.51071111s
Aug 22 05:14:32.841: INFO: 99 %ile: 1.859454349s
Aug 22 05:14:32.841: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Aug 22 05:14:32.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5736" for this suite. 08/22/23 05:14:32.848
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":270,"skipped":4916,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.373 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:14:18.482
    Aug 22 05:14:18.482: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename svc-latency 08/22/23 05:14:18.482
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:14:18.515
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:14:18.517
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Aug 22 05:14:18.520: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-5736 08/22/23 05:14:18.521
    I0822 05:14:18.527597      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5736, replica count: 1
    I0822 05:14:19.579208      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0822 05:14:20.579340      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0822 05:14:21.579553      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0822 05:14:22.579934      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 22 05:14:22.771: INFO: Created: latency-svc-29lsm
    Aug 22 05:14:22.784: INFO: Got endpoints: latency-svc-29lsm [104.245084ms]
    Aug 22 05:14:22.804: INFO: Created: latency-svc-mq8hc
    Aug 22 05:14:22.808: INFO: Got endpoints: latency-svc-mq8hc [22.869476ms]
    Aug 22 05:14:22.818: INFO: Created: latency-svc-8hpfn
    Aug 22 05:14:22.828: INFO: Created: latency-svc-m52r2
    Aug 22 05:14:22.829: INFO: Got endpoints: latency-svc-8hpfn [43.648649ms]
    Aug 22 05:14:22.837: INFO: Got endpoints: latency-svc-m52r2 [51.318209ms]
    Aug 22 05:14:22.842: INFO: Created: latency-svc-rsvt2
    Aug 22 05:14:22.850: INFO: Got endpoints: latency-svc-rsvt2 [63.915974ms]
    Aug 22 05:14:22.854: INFO: Created: latency-svc-tmrqp
    Aug 22 05:14:22.861: INFO: Got endpoints: latency-svc-tmrqp [76.002208ms]
    Aug 22 05:14:22.866: INFO: Created: latency-svc-6lkgr
    Aug 22 05:14:22.872: INFO: Created: latency-svc-gmhdp
    Aug 22 05:14:22.877: INFO: Got endpoints: latency-svc-6lkgr [91.035612ms]
    Aug 22 05:14:22.879: INFO: Got endpoints: latency-svc-gmhdp [92.715153ms]
    Aug 22 05:14:22.881: INFO: Created: latency-svc-xqdhk
    Aug 22 05:14:22.894: INFO: Created: latency-svc-wjd7h
    Aug 22 05:14:22.894: INFO: Got endpoints: latency-svc-xqdhk [107.944817ms]
    Aug 22 05:14:22.903: INFO: Got endpoints: latency-svc-wjd7h [116.915736ms]
    Aug 22 05:14:22.906: INFO: Created: latency-svc-g68zj
    Aug 22 05:14:22.916: INFO: Got endpoints: latency-svc-g68zj [130.082088ms]
    Aug 22 05:14:22.921: INFO: Created: latency-svc-rgrfj
    Aug 22 05:14:23.267: INFO: Got endpoints: latency-svc-rgrfj [480.812705ms]
    Aug 22 05:14:23.272: INFO: Created: latency-svc-8qxkk
    Aug 22 05:14:23.413: INFO: Got endpoints: latency-svc-8qxkk [626.981092ms]
    Aug 22 05:14:23.416: INFO: Created: latency-svc-5lsqr
    Aug 22 05:14:23.561: INFO: Got endpoints: latency-svc-5lsqr [775.251884ms]
    Aug 22 05:14:23.566: INFO: Created: latency-svc-wvnl7
    Aug 22 05:14:23.624: INFO: Got endpoints: latency-svc-wvnl7 [837.587661ms]
    Aug 22 05:14:23.630: INFO: Created: latency-svc-hl5rr
    Aug 22 05:14:23.636: INFO: Got endpoints: latency-svc-hl5rr [849.833425ms]
    Aug 22 05:14:23.640: INFO: Created: latency-svc-rj6gn
    Aug 22 05:14:23.667: INFO: Got endpoints: latency-svc-rj6gn [859.573848ms]
    Aug 22 05:14:23.670: INFO: Created: latency-svc-nd79q
    Aug 22 05:14:23.764: INFO: Got endpoints: latency-svc-nd79q [935.103961ms]
    Aug 22 05:14:23.768: INFO: Created: latency-svc-pddcn
    Aug 22 05:14:23.777: INFO: Got endpoints: latency-svc-pddcn [940.26787ms]
    Aug 22 05:14:23.783: INFO: Created: latency-svc-cl7zt
    Aug 22 05:14:23.792: INFO: Got endpoints: latency-svc-cl7zt [942.728105ms]
    Aug 22 05:14:23.810: INFO: Created: latency-svc-5hv4b
    Aug 22 05:14:23.811: INFO: Got endpoints: latency-svc-5hv4b [949.04126ms]
    Aug 22 05:14:23.820: INFO: Created: latency-svc-ccv8q
    Aug 22 05:14:23.826: INFO: Created: latency-svc-5hz2r
    Aug 22 05:14:23.827: INFO: Got endpoints: latency-svc-ccv8q [950.25719ms]
    Aug 22 05:14:23.831: INFO: Got endpoints: latency-svc-5hz2r [952.010951ms]
    Aug 22 05:14:23.849: INFO: Created: latency-svc-l8drp
    Aug 22 05:14:23.857: INFO: Got endpoints: latency-svc-l8drp [963.058147ms]
    Aug 22 05:14:23.858: INFO: Created: latency-svc-p44xn
    Aug 22 05:14:23.865: INFO: Created: latency-svc-69m9z
    Aug 22 05:14:23.874: INFO: Got endpoints: latency-svc-p44xn [971.010375ms]
    Aug 22 05:14:23.874: INFO: Got endpoints: latency-svc-69m9z [958.320548ms]
    Aug 22 05:14:23.886: INFO: Created: latency-svc-gz78w
    Aug 22 05:14:23.903: INFO: Created: latency-svc-rf6lk
    Aug 22 05:14:23.904: INFO: Got endpoints: latency-svc-gz78w [637.245087ms]
    Aug 22 05:14:23.959: INFO: Got endpoints: latency-svc-rf6lk [545.904844ms]
    Aug 22 05:14:23.969: INFO: Created: latency-svc-lphwc
    Aug 22 05:14:23.974: INFO: Got endpoints: latency-svc-lphwc [412.488181ms]
    Aug 22 05:14:23.982: INFO: Created: latency-svc-2sj4t
    Aug 22 05:14:23.988: INFO: Got endpoints: latency-svc-2sj4t [364.77678ms]
    Aug 22 05:14:23.991: INFO: Created: latency-svc-xfw7s
    Aug 22 05:14:24.069: INFO: Got endpoints: latency-svc-xfw7s [433.103908ms]
    Aug 22 05:14:24.075: INFO: Created: latency-svc-2l6k6
    Aug 22 05:14:24.082: INFO: Got endpoints: latency-svc-2l6k6 [414.626903ms]
    Aug 22 05:14:24.086: INFO: Created: latency-svc-5rfp4
    Aug 22 05:14:24.092: INFO: Got endpoints: latency-svc-5rfp4 [327.086197ms]
    Aug 22 05:14:24.095: INFO: Created: latency-svc-gxjgl
    Aug 22 05:14:24.136: INFO: Created: latency-svc-psk6n
    Aug 22 05:14:24.137: INFO: Got endpoints: latency-svc-psk6n [344.397275ms]
    Aug 22 05:14:24.137: INFO: Got endpoints: latency-svc-gxjgl [360.270645ms]
    Aug 22 05:14:24.167: INFO: Created: latency-svc-xvg4c
    Aug 22 05:14:24.167: INFO: Got endpoints: latency-svc-xvg4c [356.303822ms]
    Aug 22 05:14:24.195: INFO: Created: latency-svc-r494q
    Aug 22 05:14:24.204: INFO: Created: latency-svc-lsghw
    Aug 22 05:14:24.208: INFO: Got endpoints: latency-svc-r494q [380.769302ms]
    Aug 22 05:14:24.210: INFO: Got endpoints: latency-svc-lsghw [379.079722ms]
    Aug 22 05:14:24.212: INFO: Created: latency-svc-rstv2
    Aug 22 05:14:24.222: INFO: Created: latency-svc-phjmk
    Aug 22 05:14:24.243: INFO: Got endpoints: latency-svc-phjmk [368.621712ms]
    Aug 22 05:14:24.243: INFO: Got endpoints: latency-svc-rstv2 [385.57633ms]
    Aug 22 05:14:24.514: INFO: Created: latency-svc-9645c
    Aug 22 05:14:24.532: INFO: Got endpoints: latency-svc-9645c [657.595557ms]
    Aug 22 05:14:24.534: INFO: Created: latency-svc-cmvwz
    Aug 22 05:14:24.541: INFO: Got endpoints: latency-svc-cmvwz [637.47019ms]
    Aug 22 05:14:24.548: INFO: Created: latency-svc-dk6vc
    Aug 22 05:14:24.553: INFO: Created: latency-svc-qp24t
    Aug 22 05:14:24.570: INFO: Got endpoints: latency-svc-dk6vc [610.752666ms]
    Aug 22 05:14:24.576: INFO: Got endpoints: latency-svc-qp24t [601.492921ms]
    Aug 22 05:14:24.579: INFO: Created: latency-svc-9z2zk
    Aug 22 05:14:24.586: INFO: Got endpoints: latency-svc-9z2zk [597.440651ms]
    Aug 22 05:14:24.593: INFO: Created: latency-svc-knw5j
    Aug 22 05:14:24.688: INFO: Created: latency-svc-xnsxk
    Aug 22 05:14:24.688: INFO: Got endpoints: latency-svc-xnsxk [605.74071ms]
    Aug 22 05:14:24.688: INFO: Got endpoints: latency-svc-knw5j [619.158443ms]
    Aug 22 05:14:24.857: INFO: Created: latency-svc-4b7n2
    Aug 22 05:14:24.887: INFO: Got endpoints: latency-svc-4b7n2 [795.49988ms]
    Aug 22 05:14:25.205: INFO: Created: latency-svc-thd6x
    Aug 22 05:14:25.212: INFO: Got endpoints: latency-svc-thd6x [1.07475915s]
    Aug 22 05:14:25.216: INFO: Created: latency-svc-dhnlw
    Aug 22 05:14:25.222: INFO: Got endpoints: latency-svc-dhnlw [1.084687456s]
    Aug 22 05:14:25.226: INFO: Created: latency-svc-drdnl
    Aug 22 05:14:25.234: INFO: Got endpoints: latency-svc-drdnl [1.066521986s]
    Aug 22 05:14:25.412: INFO: Created: latency-svc-pj4dc
    Aug 22 05:14:25.815: INFO: Got endpoints: latency-svc-pj4dc [1.60731571s]
    Aug 22 05:14:25.920: INFO: Created: latency-svc-9gq2w
    Aug 22 05:14:26.007: INFO: Got endpoints: latency-svc-9gq2w [1.797153546s]
    Aug 22 05:14:26.012: INFO: Created: latency-svc-9jhbd
    Aug 22 05:14:26.022: INFO: Got endpoints: latency-svc-9jhbd [1.778918056s]
    Aug 22 05:14:26.025: INFO: Created: latency-svc-474p4
    Aug 22 05:14:26.031: INFO: Got endpoints: latency-svc-474p4 [1.788080174s]
    Aug 22 05:14:26.042: INFO: Created: latency-svc-c98wr
    Aug 22 05:14:26.043: INFO: Got endpoints: latency-svc-c98wr [1.510500615s]
    Aug 22 05:14:26.047: INFO: Created: latency-svc-trk4d
    Aug 22 05:14:26.052: INFO: Got endpoints: latency-svc-trk4d [1.51071111s]
    Aug 22 05:14:26.057: INFO: Created: latency-svc-2sm26
    Aug 22 05:14:26.060: INFO: Got endpoints: latency-svc-2sm26 [1.490382742s]
    Aug 22 05:14:26.065: INFO: Created: latency-svc-2mbw2
    Aug 22 05:14:26.068: INFO: Got endpoints: latency-svc-2mbw2 [1.492436636s]
    Aug 22 05:14:26.072: INFO: Created: latency-svc-rb786
    Aug 22 05:14:26.079: INFO: Got endpoints: latency-svc-rb786 [1.492503882s]
    Aug 22 05:14:26.079: INFO: Created: latency-svc-f5g7r
    Aug 22 05:14:26.086: INFO: Got endpoints: latency-svc-f5g7r [1.397469478s]
    Aug 22 05:14:26.090: INFO: Created: latency-svc-7kmd9
    Aug 22 05:14:26.734: INFO: Got endpoints: latency-svc-7kmd9 [2.046161031s]
    Aug 22 05:14:26.740: INFO: Created: latency-svc-kqhrm
    Aug 22 05:14:26.747: INFO: Got endpoints: latency-svc-kqhrm [1.859454349s]
    Aug 22 05:14:26.753: INFO: Created: latency-svc-f5g64
    Aug 22 05:14:26.757: INFO: Got endpoints: latency-svc-f5g64 [1.544651256s]
    Aug 22 05:14:26.775: INFO: Created: latency-svc-lff4g
    Aug 22 05:14:26.783: INFO: Got endpoints: latency-svc-lff4g [1.560719622s]
    Aug 22 05:14:26.791: INFO: Created: latency-svc-8pgvj
    Aug 22 05:14:26.794: INFO: Got endpoints: latency-svc-8pgvj [1.560216108s]
    Aug 22 05:14:26.804: INFO: Created: latency-svc-tghgh
    Aug 22 05:14:26.815: INFO: Got endpoints: latency-svc-tghgh [999.57164ms]
    Aug 22 05:14:26.815: INFO: Created: latency-svc-m5ps5
    Aug 22 05:14:26.823: INFO: Created: latency-svc-x9jf8
    Aug 22 05:14:26.829: INFO: Got endpoints: latency-svc-m5ps5 [821.656222ms]
    Aug 22 05:14:26.834: INFO: Got endpoints: latency-svc-x9jf8 [812.072953ms]
    Aug 22 05:14:26.834: INFO: Created: latency-svc-mflns
    Aug 22 05:14:26.838: INFO: Created: latency-svc-bvznh
    Aug 22 05:14:26.853: INFO: Got endpoints: latency-svc-mflns [822.358189ms]
    Aug 22 05:14:26.853: INFO: Got endpoints: latency-svc-bvznh [810.485966ms]
    Aug 22 05:14:26.854: INFO: Created: latency-svc-vqb88
    Aug 22 05:14:26.890: INFO: Got endpoints: latency-svc-vqb88 [836.918106ms]
    Aug 22 05:14:26.903: INFO: Created: latency-svc-cbjll
    Aug 22 05:14:26.915: INFO: Got endpoints: latency-svc-cbjll [854.546417ms]
    Aug 22 05:14:26.922: INFO: Created: latency-svc-25qwv
    Aug 22 05:14:26.930: INFO: Got endpoints: latency-svc-25qwv [862.019227ms]
    Aug 22 05:14:26.935: INFO: Created: latency-svc-8gsb2
    Aug 22 05:14:26.941: INFO: Got endpoints: latency-svc-8gsb2 [862.490032ms]
    Aug 22 05:14:26.947: INFO: Created: latency-svc-dh2l6
    Aug 22 05:14:26.950: INFO: Got endpoints: latency-svc-dh2l6 [863.722843ms]
    Aug 22 05:14:26.956: INFO: Created: latency-svc-vdmgz
    Aug 22 05:14:26.961: INFO: Got endpoints: latency-svc-vdmgz [226.25582ms]
    Aug 22 05:14:26.975: INFO: Created: latency-svc-dfhk8
    Aug 22 05:14:26.976: INFO: Got endpoints: latency-svc-dfhk8 [229.580507ms]
    Aug 22 05:14:27.004: INFO: Created: latency-svc-7rcjm
    Aug 22 05:14:27.194: INFO: Got endpoints: latency-svc-7rcjm [437.343802ms]
    Aug 22 05:14:27.208: INFO: Created: latency-svc-dpb7s
    Aug 22 05:14:27.216: INFO: Got endpoints: latency-svc-dpb7s [432.634568ms]
    Aug 22 05:14:27.222: INFO: Created: latency-svc-szgln
    Aug 22 05:14:27.233: INFO: Got endpoints: latency-svc-szgln [438.674829ms]
    Aug 22 05:14:27.238: INFO: Created: latency-svc-qxhqf
    Aug 22 05:14:27.257: INFO: Got endpoints: latency-svc-qxhqf [442.123579ms]
    Aug 22 05:14:27.261: INFO: Created: latency-svc-cfnmz
    Aug 22 05:14:27.726: INFO: Got endpoints: latency-svc-cfnmz [897.03459ms]
    Aug 22 05:14:27.729: INFO: Created: latency-svc-zmtlm
    Aug 22 05:14:27.748: INFO: Got endpoints: latency-svc-zmtlm [914.6511ms]
    Aug 22 05:14:27.752: INFO: Created: latency-svc-vrkvt
    Aug 22 05:14:27.761: INFO: Got endpoints: latency-svc-vrkvt [907.878384ms]
    Aug 22 05:14:27.766: INFO: Created: latency-svc-qj8jq
    Aug 22 05:14:27.795: INFO: Got endpoints: latency-svc-qj8jq [941.962199ms]
    Aug 22 05:14:27.807: INFO: Created: latency-svc-85kj7
    Aug 22 05:14:27.817: INFO: Got endpoints: latency-svc-85kj7 [927.120995ms]
    Aug 22 05:14:27.830: INFO: Created: latency-svc-lk6bf
    Aug 22 05:14:27.831: INFO: Got endpoints: latency-svc-lk6bf [916.061896ms]
    Aug 22 05:14:27.840: INFO: Created: latency-svc-wj88z
    Aug 22 05:14:27.847: INFO: Got endpoints: latency-svc-wj88z [917.110915ms]
    Aug 22 05:14:27.854: INFO: Created: latency-svc-z7j6f
    Aug 22 05:14:27.881: INFO: Got endpoints: latency-svc-z7j6f [940.276846ms]
    Aug 22 05:14:27.889: INFO: Created: latency-svc-h9bhk
    Aug 22 05:14:27.890: INFO: Got endpoints: latency-svc-h9bhk [940.180334ms]
    Aug 22 05:14:27.897: INFO: Created: latency-svc-g722z
    Aug 22 05:14:27.903: INFO: Got endpoints: latency-svc-g722z [942.407494ms]
    Aug 22 05:14:27.909: INFO: Created: latency-svc-q2mms
    Aug 22 05:14:27.916: INFO: Got endpoints: latency-svc-q2mms [939.166183ms]
    Aug 22 05:14:27.920: INFO: Created: latency-svc-lb2b2
    Aug 22 05:14:27.927: INFO: Got endpoints: latency-svc-lb2b2 [732.180817ms]
    Aug 22 05:14:27.935: INFO: Created: latency-svc-xxj7g
    Aug 22 05:14:27.936: INFO: Got endpoints: latency-svc-xxj7g [720.255283ms]
    Aug 22 05:14:27.947: INFO: Created: latency-svc-kdbbb
    Aug 22 05:14:27.950: INFO: Got endpoints: latency-svc-kdbbb [717.161969ms]
    Aug 22 05:14:27.956: INFO: Created: latency-svc-xf5gw
    Aug 22 05:14:27.961: INFO: Got endpoints: latency-svc-xf5gw [703.630174ms]
    Aug 22 05:14:27.964: INFO: Created: latency-svc-sbmqb
    Aug 22 05:14:27.968: INFO: Got endpoints: latency-svc-sbmqb [241.998905ms]
    Aug 22 05:14:27.972: INFO: Created: latency-svc-b6hxx
    Aug 22 05:14:27.978: INFO: Got endpoints: latency-svc-b6hxx [229.010187ms]
    Aug 22 05:14:27.983: INFO: Created: latency-svc-5czlk
    Aug 22 05:14:27.986: INFO: Got endpoints: latency-svc-5czlk [224.114994ms]
    Aug 22 05:14:27.991: INFO: Created: latency-svc-hdd8s
    Aug 22 05:14:27.997: INFO: Got endpoints: latency-svc-hdd8s [201.095255ms]
    Aug 22 05:14:28.001: INFO: Created: latency-svc-fktgw
    Aug 22 05:14:28.005: INFO: Got endpoints: latency-svc-fktgw [188.177249ms]
    Aug 22 05:14:28.008: INFO: Created: latency-svc-vpcl2
    Aug 22 05:14:28.013: INFO: Got endpoints: latency-svc-vpcl2 [182.364965ms]
    Aug 22 05:14:28.017: INFO: Created: latency-svc-9vlpt
    Aug 22 05:14:28.022: INFO: Got endpoints: latency-svc-9vlpt [174.031301ms]
    Aug 22 05:14:28.028: INFO: Created: latency-svc-8zvvx
    Aug 22 05:14:28.036: INFO: Got endpoints: latency-svc-8zvvx [154.611517ms]
    Aug 22 05:14:28.038: INFO: Created: latency-svc-tmbp4
    Aug 22 05:14:28.042: INFO: Got endpoints: latency-svc-tmbp4 [151.549153ms]
    Aug 22 05:14:28.049: INFO: Created: latency-svc-8mq74
    Aug 22 05:14:28.182: INFO: Created: latency-svc-9srxh
    Aug 22 05:14:28.186: INFO: Got endpoints: latency-svc-9srxh [269.862579ms]
    Aug 22 05:14:28.186: INFO: Got endpoints: latency-svc-8mq74 [282.439113ms]
    Aug 22 05:14:28.218: INFO: Created: latency-svc-6bv4q
    Aug 22 05:14:28.224: INFO: Got endpoints: latency-svc-6bv4q [297.28638ms]
    Aug 22 05:14:28.228: INFO: Created: latency-svc-7zl27
    Aug 22 05:14:28.246: INFO: Got endpoints: latency-svc-7zl27 [309.698495ms]
    Aug 22 05:14:28.251: INFO: Created: latency-svc-r22sk
    Aug 22 05:14:28.259: INFO: Got endpoints: latency-svc-r22sk [309.425755ms]
    Aug 22 05:14:28.264: INFO: Created: latency-svc-7fq47
    Aug 22 05:14:28.446: INFO: Got endpoints: latency-svc-7fq47 [485.441737ms]
    Aug 22 05:14:28.453: INFO: Created: latency-svc-sk9gs
    Aug 22 05:14:28.487: INFO: Got endpoints: latency-svc-sk9gs [519.212115ms]
    Aug 22 05:14:28.490: INFO: Created: latency-svc-k7s5g
    Aug 22 05:14:28.494: INFO: Created: latency-svc-smpsq
    Aug 22 05:14:28.496: INFO: Got endpoints: latency-svc-k7s5g [518.893938ms]
    Aug 22 05:14:28.499: INFO: Got endpoints: latency-svc-smpsq [513.357542ms]
    Aug 22 05:14:28.503: INFO: Created: latency-svc-ptb9f
    Aug 22 05:14:28.511: INFO: Got endpoints: latency-svc-ptb9f [514.776655ms]
    Aug 22 05:14:28.514: INFO: Created: latency-svc-bg8h8
    Aug 22 05:14:28.520: INFO: Got endpoints: latency-svc-bg8h8 [515.011986ms]
    Aug 22 05:14:28.524: INFO: Created: latency-svc-l6g5j
    Aug 22 05:14:28.533: INFO: Created: latency-svc-ppssm
    Aug 22 05:14:28.534: INFO: Got endpoints: latency-svc-l6g5j [520.457192ms]
    Aug 22 05:14:28.539: INFO: Got endpoints: latency-svc-ppssm [517.130831ms]
    Aug 22 05:14:28.543: INFO: Created: latency-svc-r4zq2
    Aug 22 05:14:28.551: INFO: Got endpoints: latency-svc-r4zq2 [514.841305ms]
    Aug 22 05:14:28.554: INFO: Created: latency-svc-f9sfx
    Aug 22 05:14:28.560: INFO: Got endpoints: latency-svc-f9sfx [518.246954ms]
    Aug 22 05:14:28.563: INFO: Created: latency-svc-6j88b
    Aug 22 05:14:28.570: INFO: Got endpoints: latency-svc-6j88b [384.081598ms]
    Aug 22 05:14:28.573: INFO: Created: latency-svc-f6hww
    Aug 22 05:14:28.583: INFO: Got endpoints: latency-svc-f6hww [396.907089ms]
    Aug 22 05:14:28.592: INFO: Created: latency-svc-hf8jt
    Aug 22 05:14:28.596: INFO: Got endpoints: latency-svc-hf8jt [371.578099ms]
    Aug 22 05:14:28.607: INFO: Created: latency-svc-mcbt5
    Aug 22 05:14:28.611: INFO: Got endpoints: latency-svc-mcbt5 [365.439142ms]
    Aug 22 05:14:28.618: INFO: Created: latency-svc-bq459
    Aug 22 05:14:28.625: INFO: Got endpoints: latency-svc-bq459 [365.79468ms]
    Aug 22 05:14:28.630: INFO: Created: latency-svc-m66h7
    Aug 22 05:14:28.637: INFO: Got endpoints: latency-svc-m66h7 [191.032519ms]
    Aug 22 05:14:28.639: INFO: Created: latency-svc-lfrfk
    Aug 22 05:14:28.645: INFO: Got endpoints: latency-svc-lfrfk [158.047764ms]
    Aug 22 05:14:28.651: INFO: Created: latency-svc-xv742
    Aug 22 05:14:28.657: INFO: Created: latency-svc-jjw6k
    Aug 22 05:14:28.660: INFO: Got endpoints: latency-svc-xv742 [163.231319ms]
    Aug 22 05:14:28.664: INFO: Got endpoints: latency-svc-jjw6k [164.583595ms]
    Aug 22 05:14:28.668: INFO: Created: latency-svc-mx8tw
    Aug 22 05:14:28.675: INFO: Created: latency-svc-dpjr7
    Aug 22 05:14:28.697: INFO: Got endpoints: latency-svc-mx8tw [185.808486ms]
    Aug 22 05:14:28.703: INFO: Created: latency-svc-hr7hq
    Aug 22 05:14:28.716: INFO: Created: latency-svc-p9nlp
    Aug 22 05:14:28.725: INFO: Created: latency-svc-mmnxk
    Aug 22 05:14:28.735: INFO: Created: latency-svc-9zdjh
    Aug 22 05:14:28.745: INFO: Created: latency-svc-lzzzk
    Aug 22 05:14:28.747: INFO: Got endpoints: latency-svc-dpjr7 [227.075197ms]
    Aug 22 05:14:28.762: INFO: Created: latency-svc-qfsj8
    Aug 22 05:14:28.766: INFO: Created: latency-svc-ppl7s
    Aug 22 05:14:28.771: INFO: Created: latency-svc-5vgcs
    Aug 22 05:14:28.895: INFO: Created: latency-svc-k2lwh
    Aug 22 05:14:28.908: INFO: Got endpoints: latency-svc-p9nlp [369.382629ms]
    Aug 22 05:14:28.908: INFO: Got endpoints: latency-svc-hr7hq [374.558049ms]
    Aug 22 05:14:28.914: INFO: Created: latency-svc-d2hgj
    Aug 22 05:14:28.928: INFO: Got endpoints: latency-svc-mmnxk [376.516163ms]
    Aug 22 05:14:28.933: INFO: Created: latency-svc-6xx84
    Aug 22 05:14:28.943: INFO: Created: latency-svc-jp9fd
    Aug 22 05:14:28.955: INFO: Got endpoints: latency-svc-9zdjh [395.130986ms]
    Aug 22 05:14:28.962: INFO: Created: latency-svc-9jr87
    Aug 22 05:14:29.042: INFO: Created: latency-svc-pcfcz
    Aug 22 05:14:29.228: INFO: Got endpoints: latency-svc-lzzzk [657.631244ms]
    Aug 22 05:14:29.236: INFO: Got endpoints: latency-svc-ppl7s [640.760512ms]
    Aug 22 05:14:29.237: INFO: Got endpoints: latency-svc-qfsj8 [653.709637ms]
    Aug 22 05:14:29.239: INFO: Got endpoints: latency-svc-k2lwh [613.555082ms]
    Aug 22 05:14:29.239: INFO: Got endpoints: latency-svc-5vgcs [627.746447ms]
    Aug 22 05:14:29.251: INFO: Got endpoints: latency-svc-d2hgj [613.407937ms]
    Aug 22 05:14:29.255: INFO: Created: latency-svc-zs5ht
    Aug 22 05:14:29.265: INFO: Created: latency-svc-t8dw8
    Aug 22 05:14:29.274: INFO: Created: latency-svc-72447
    Aug 22 05:14:29.281: INFO: Created: latency-svc-ctmdk
    Aug 22 05:14:29.290: INFO: Created: latency-svc-8xslh
    Aug 22 05:14:29.300: INFO: Got endpoints: latency-svc-6xx84 [654.559782ms]
    Aug 22 05:14:29.305: INFO: Created: latency-svc-thvzh
    Aug 22 05:14:29.314: INFO: Created: latency-svc-f9sb2
    Aug 22 05:14:29.915: INFO: Got endpoints: latency-svc-jp9fd [1.255142437s]
    Aug 22 05:14:29.922: INFO: Got endpoints: latency-svc-t8dw8 [1.013591272s]
    Aug 22 05:14:29.922: INFO: Got endpoints: latency-svc-9jr87 [1.25868845s]
    Aug 22 05:14:29.922: INFO: Got endpoints: latency-svc-pcfcz [1.225007751s]
    Aug 22 05:14:29.923: INFO: Got endpoints: latency-svc-zs5ht [1.175159319s]
    Aug 22 05:14:29.990: INFO: Created: latency-svc-jzddq
    Aug 22 05:14:30.058: INFO: Got endpoints: latency-svc-8xslh [1.10308951s]
    Aug 22 05:14:30.058: INFO: Got endpoints: latency-svc-72447 [1.15004871s]
    Aug 22 05:14:30.060: INFO: Got endpoints: latency-svc-thvzh [832.126745ms]
    Aug 22 05:14:30.060: INFO: Got endpoints: latency-svc-f9sb2 [822.825425ms]
    Aug 22 05:14:30.060: INFO: Got endpoints: latency-svc-ctmdk [1.131762052s]
    Aug 22 05:14:30.084: INFO: Created: latency-svc-wwjfp
    Aug 22 05:14:30.088: INFO: Got endpoints: latency-svc-jzddq [851.865348ms]
    Aug 22 05:14:30.092: INFO: Got endpoints: latency-svc-wwjfp [852.790775ms]
    Aug 22 05:14:30.107: INFO: Created: latency-svc-hm4r4
    Aug 22 05:14:30.123: INFO: Got endpoints: latency-svc-hm4r4 [884.244133ms]
    Aug 22 05:14:30.150: INFO: Created: latency-svc-m8r5l
    Aug 22 05:14:30.176: INFO: Got endpoints: latency-svc-m8r5l [924.706323ms]
    Aug 22 05:14:30.180: INFO: Created: latency-svc-7zk5l
    Aug 22 05:14:30.192: INFO: Got endpoints: latency-svc-7zk5l [892.35997ms]
    Aug 22 05:14:30.387: INFO: Created: latency-svc-rcnrg
    Aug 22 05:14:30.451: INFO: Got endpoints: latency-svc-rcnrg [535.676155ms]
    Aug 22 05:14:30.494: INFO: Created: latency-svc-86rj8
    Aug 22 05:14:30.494: INFO: Got endpoints: latency-svc-86rj8 [572.064773ms]
    Aug 22 05:14:30.563: INFO: Created: latency-svc-p7m7s
    Aug 22 05:14:30.748: INFO: Got endpoints: latency-svc-p7m7s [825.538465ms]
    Aug 22 05:14:30.758: INFO: Created: latency-svc-5dlpj
    Aug 22 05:14:31.514: INFO: Got endpoints: latency-svc-5dlpj [1.591637967s]
    Aug 22 05:14:31.514: INFO: Created: latency-svc-vdlsb
    Aug 22 05:14:31.559: INFO: Got endpoints: latency-svc-vdlsb [1.63628007s]
    Aug 22 05:14:31.562: INFO: Created: latency-svc-prl2j
    Aug 22 05:14:31.572: INFO: Got endpoints: latency-svc-prl2j [1.513381629s]
    Aug 22 05:14:31.577: INFO: Created: latency-svc-dwxs8
    Aug 22 05:14:31.582: INFO: Got endpoints: latency-svc-dwxs8 [1.523127595s]
    Aug 22 05:14:31.586: INFO: Created: latency-svc-d7tmb
    Aug 22 05:14:31.590: INFO: Created: latency-svc-r2z65
    Aug 22 05:14:31.595: INFO: Got endpoints: latency-svc-d7tmb [1.535273692s]
    Aug 22 05:14:31.596: INFO: Got endpoints: latency-svc-r2z65 [1.535973124s]
    Aug 22 05:14:31.604: INFO: Created: latency-svc-7fvvg
    Aug 22 05:14:31.610: INFO: Got endpoints: latency-svc-7fvvg [1.550226394s]
    Aug 22 05:14:31.617: INFO: Created: latency-svc-qzvtl
    Aug 22 05:14:31.622: INFO: Got endpoints: latency-svc-qzvtl [1.5334605s]
    Aug 22 05:14:31.625: INFO: Created: latency-svc-jw6qb
    Aug 22 05:14:31.630: INFO: Got endpoints: latency-svc-jw6qb [1.537994235s]
    Aug 22 05:14:31.634: INFO: Created: latency-svc-zjqm9
    Aug 22 05:14:31.639: INFO: Got endpoints: latency-svc-zjqm9 [1.516037363s]
    Aug 22 05:14:31.652: INFO: Created: latency-svc-tdgf4
    Aug 22 05:14:31.653: INFO: Got endpoints: latency-svc-tdgf4 [1.476714179s]
    Aug 22 05:14:31.659: INFO: Created: latency-svc-gk882
    Aug 22 05:14:31.668: INFO: Got endpoints: latency-svc-gk882 [1.475821883s]
    Aug 22 05:14:31.672: INFO: Created: latency-svc-2z5bj
    Aug 22 05:14:31.678: INFO: Got endpoints: latency-svc-2z5bj [1.226906382s]
    Aug 22 05:14:31.683: INFO: Created: latency-svc-6zws7
    Aug 22 05:14:31.689: INFO: Got endpoints: latency-svc-6zws7 [1.194424202s]
    Aug 22 05:14:31.690: INFO: Created: latency-svc-kd7r9
    Aug 22 05:14:31.696: INFO: Got endpoints: latency-svc-kd7r9 [947.866417ms]
    Aug 22 05:14:31.702: INFO: Created: latency-svc-68jp6
    Aug 22 05:14:31.930: INFO: Got endpoints: latency-svc-68jp6 [415.839077ms]
    Aug 22 05:14:31.965: INFO: Created: latency-svc-w9cpx
    Aug 22 05:14:32.235: INFO: Got endpoints: latency-svc-w9cpx [675.768131ms]
    Aug 22 05:14:32.240: INFO: Created: latency-svc-xwrp2
    Aug 22 05:14:32.261: INFO: Got endpoints: latency-svc-xwrp2 [689.139185ms]
    Aug 22 05:14:32.266: INFO: Created: latency-svc-rc4lv
    Aug 22 05:14:32.269: INFO: Got endpoints: latency-svc-rc4lv [687.554775ms]
    Aug 22 05:14:32.273: INFO: Created: latency-svc-pwlwv
    Aug 22 05:14:32.280: INFO: Got endpoints: latency-svc-pwlwv [684.696332ms]
    Aug 22 05:14:32.284: INFO: Created: latency-svc-cr4nv
    Aug 22 05:14:32.288: INFO: Got endpoints: latency-svc-cr4nv [693.447239ms]
    Aug 22 05:14:32.295: INFO: Created: latency-svc-xx2jj
    Aug 22 05:14:32.300: INFO: Got endpoints: latency-svc-xx2jj [689.572099ms]
    Aug 22 05:14:32.308: INFO: Created: latency-svc-82jkj
    Aug 22 05:14:32.327: INFO: Got endpoints: latency-svc-82jkj [705.106363ms]
    Aug 22 05:14:32.332: INFO: Created: latency-svc-mb929
    Aug 22 05:14:32.361: INFO: Got endpoints: latency-svc-mb929 [730.757826ms]
    Aug 22 05:14:32.365: INFO: Created: latency-svc-7kvb7
    Aug 22 05:14:32.377: INFO: Got endpoints: latency-svc-7kvb7 [737.828082ms]
    Aug 22 05:14:32.381: INFO: Created: latency-svc-jz8d8
    Aug 22 05:14:32.395: INFO: Got endpoints: latency-svc-jz8d8 [742.236081ms]
    Aug 22 05:14:32.400: INFO: Created: latency-svc-knx4n
    Aug 22 05:14:32.408: INFO: Got endpoints: latency-svc-knx4n [739.84214ms]
    Aug 22 05:14:32.411: INFO: Created: latency-svc-n6jv5
    Aug 22 05:14:32.416: INFO: Got endpoints: latency-svc-n6jv5 [738.681162ms]
    Aug 22 05:14:32.421: INFO: Created: latency-svc-n5d8w
    Aug 22 05:14:32.427: INFO: Got endpoints: latency-svc-n5d8w [738.277325ms]
    Aug 22 05:14:32.435: INFO: Created: latency-svc-8fr52
    Aug 22 05:14:32.440: INFO: Got endpoints: latency-svc-8fr52 [744.176071ms]
    Aug 22 05:14:32.444: INFO: Created: latency-svc-8qc76
    Aug 22 05:14:32.451: INFO: Got endpoints: latency-svc-8qc76 [520.77651ms]
    Aug 22 05:14:32.456: INFO: Created: latency-svc-kmbnw
    Aug 22 05:14:32.482: INFO: Got endpoints: latency-svc-kmbnw [247.485628ms]
    Aug 22 05:14:32.519: INFO: Created: latency-svc-l42vb
    Aug 22 05:14:32.519: INFO: Got endpoints: latency-svc-l42vb [257.948187ms]
    Aug 22 05:14:32.771: INFO: Created: latency-svc-86g7w
    Aug 22 05:14:32.777: INFO: Got endpoints: latency-svc-86g7w [507.808009ms]
    Aug 22 05:14:32.790: INFO: Created: latency-svc-rbnzd
    Aug 22 05:14:32.799: INFO: Created: latency-svc-xxzfn
    Aug 22 05:14:32.803: INFO: Got endpoints: latency-svc-rbnzd [522.915122ms]
    Aug 22 05:14:32.808: INFO: Created: latency-svc-79nzw
    Aug 22 05:14:32.808: INFO: Got endpoints: latency-svc-xxzfn [519.856804ms]
    Aug 22 05:14:32.816: INFO: Created: latency-svc-grh2z
    Aug 22 05:14:32.817: INFO: Got endpoints: latency-svc-79nzw [517.553605ms]
    Aug 22 05:14:32.823: INFO: Got endpoints: latency-svc-grh2z [495.454294ms]
    Aug 22 05:14:32.826: INFO: Created: latency-svc-ngkx9
    Aug 22 05:14:32.833: INFO: Got endpoints: latency-svc-ngkx9 [472.675249ms]
    Aug 22 05:14:32.836: INFO: Created: latency-svc-4zmsc
    Aug 22 05:14:32.841: INFO: Got endpoints: latency-svc-4zmsc [463.498642ms]
    Aug 22 05:14:32.841: INFO: Latencies: [22.869476ms 43.648649ms 51.318209ms 63.915974ms 76.002208ms 91.035612ms 92.715153ms 107.944817ms 116.915736ms 130.082088ms 151.549153ms 154.611517ms 158.047764ms 163.231319ms 164.583595ms 174.031301ms 182.364965ms 185.808486ms 188.177249ms 191.032519ms 201.095255ms 224.114994ms 226.25582ms 227.075197ms 229.010187ms 229.580507ms 241.998905ms 247.485628ms 257.948187ms 269.862579ms 282.439113ms 297.28638ms 309.425755ms 309.698495ms 327.086197ms 344.397275ms 356.303822ms 360.270645ms 364.77678ms 365.439142ms 365.79468ms 368.621712ms 369.382629ms 371.578099ms 374.558049ms 376.516163ms 379.079722ms 380.769302ms 384.081598ms 385.57633ms 395.130986ms 396.907089ms 412.488181ms 414.626903ms 415.839077ms 432.634568ms 433.103908ms 437.343802ms 438.674829ms 442.123579ms 463.498642ms 472.675249ms 480.812705ms 485.441737ms 495.454294ms 507.808009ms 513.357542ms 514.776655ms 514.841305ms 515.011986ms 517.130831ms 517.553605ms 518.246954ms 518.893938ms 519.212115ms 519.856804ms 520.457192ms 520.77651ms 522.915122ms 535.676155ms 545.904844ms 572.064773ms 597.440651ms 601.492921ms 605.74071ms 610.752666ms 613.407937ms 613.555082ms 619.158443ms 626.981092ms 627.746447ms 637.245087ms 637.47019ms 640.760512ms 653.709637ms 654.559782ms 657.595557ms 657.631244ms 675.768131ms 684.696332ms 687.554775ms 689.139185ms 689.572099ms 693.447239ms 703.630174ms 705.106363ms 717.161969ms 720.255283ms 730.757826ms 732.180817ms 737.828082ms 738.277325ms 738.681162ms 739.84214ms 742.236081ms 744.176071ms 775.251884ms 795.49988ms 810.485966ms 812.072953ms 821.656222ms 822.358189ms 822.825425ms 825.538465ms 832.126745ms 836.918106ms 837.587661ms 849.833425ms 851.865348ms 852.790775ms 854.546417ms 859.573848ms 862.019227ms 862.490032ms 863.722843ms 884.244133ms 892.35997ms 897.03459ms 907.878384ms 914.6511ms 916.061896ms 917.110915ms 924.706323ms 927.120995ms 935.103961ms 939.166183ms 940.180334ms 940.26787ms 940.276846ms 941.962199ms 942.407494ms 942.728105ms 947.866417ms 949.04126ms 950.25719ms 952.010951ms 958.320548ms 963.058147ms 971.010375ms 999.57164ms 1.013591272s 1.066521986s 1.07475915s 1.084687456s 1.10308951s 1.131762052s 1.15004871s 1.175159319s 1.194424202s 1.225007751s 1.226906382s 1.255142437s 1.25868845s 1.397469478s 1.475821883s 1.476714179s 1.490382742s 1.492436636s 1.492503882s 1.510500615s 1.51071111s 1.513381629s 1.516037363s 1.523127595s 1.5334605s 1.535273692s 1.535973124s 1.537994235s 1.544651256s 1.550226394s 1.560216108s 1.560719622s 1.591637967s 1.60731571s 1.63628007s 1.778918056s 1.788080174s 1.797153546s 1.859454349s 2.046161031s]
    Aug 22 05:14:32.841: INFO: 50 %ile: 687.554775ms
    Aug 22 05:14:32.841: INFO: 90 %ile: 1.51071111s
    Aug 22 05:14:32.841: INFO: 99 %ile: 1.859454349s
    Aug 22 05:14:32.841: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Aug 22 05:14:32.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-5736" for this suite. 08/22/23 05:14:32.848
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:14:32.858
Aug 22 05:14:32.859: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename subpath 08/22/23 05:14:32.86
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:14:32.987
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:14:32.99
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/22/23 05:14:32.994
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-brcl 08/22/23 05:14:33.005
STEP: Creating a pod to test atomic-volume-subpath 08/22/23 05:14:33.005
Aug 22 05:14:33.014: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-brcl" in namespace "subpath-1452" to be "Succeeded or Failed"
Aug 22 05:14:33.022: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Pending", Reason="", readiness=false. Elapsed: 7.68072ms
Aug 22 05:14:35.171: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.156876873s
Aug 22 05:14:37.024: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 4.010356814s
Aug 22 05:14:39.192: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 6.178291432s
Aug 22 05:14:41.174: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 8.159884435s
Aug 22 05:14:43.125: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 10.110644232s
Aug 22 05:14:45.074: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 12.060126211s
Aug 22 05:14:47.027: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 14.012904554s
Aug 22 05:14:49.027: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 16.012996874s
Aug 22 05:14:51.026: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 18.012067747s
Aug 22 05:14:53.026: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 20.011757833s
Aug 22 05:14:55.028: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 22.0138796s
Aug 22 05:14:57.027: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=false. Elapsed: 24.012994205s
Aug 22 05:14:59.027: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.012856864s
STEP: Saw pod success 08/22/23 05:14:59.027
Aug 22 05:14:59.027: INFO: Pod "pod-subpath-test-configmap-brcl" satisfied condition "Succeeded or Failed"
Aug 22 05:14:59.030: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod pod-subpath-test-configmap-brcl container test-container-subpath-configmap-brcl: <nil>
STEP: delete the pod 08/22/23 05:14:59.063
Aug 22 05:14:59.076: INFO: Waiting for pod pod-subpath-test-configmap-brcl to disappear
Aug 22 05:14:59.079: INFO: Pod pod-subpath-test-configmap-brcl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-brcl 08/22/23 05:14:59.079
Aug 22 05:14:59.079: INFO: Deleting pod "pod-subpath-test-configmap-brcl" in namespace "subpath-1452"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 22 05:14:59.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1452" for this suite. 08/22/23 05:14:59.086
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":271,"skipped":4920,"failed":0}
------------------------------
â€¢ [SLOW TEST] [26.238 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:14:32.858
    Aug 22 05:14:32.859: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename subpath 08/22/23 05:14:32.86
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:14:32.987
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:14:32.99
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/22/23 05:14:32.994
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-brcl 08/22/23 05:14:33.005
    STEP: Creating a pod to test atomic-volume-subpath 08/22/23 05:14:33.005
    Aug 22 05:14:33.014: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-brcl" in namespace "subpath-1452" to be "Succeeded or Failed"
    Aug 22 05:14:33.022: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Pending", Reason="", readiness=false. Elapsed: 7.68072ms
    Aug 22 05:14:35.171: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.156876873s
    Aug 22 05:14:37.024: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 4.010356814s
    Aug 22 05:14:39.192: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 6.178291432s
    Aug 22 05:14:41.174: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 8.159884435s
    Aug 22 05:14:43.125: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 10.110644232s
    Aug 22 05:14:45.074: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 12.060126211s
    Aug 22 05:14:47.027: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 14.012904554s
    Aug 22 05:14:49.027: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 16.012996874s
    Aug 22 05:14:51.026: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 18.012067747s
    Aug 22 05:14:53.026: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 20.011757833s
    Aug 22 05:14:55.028: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=true. Elapsed: 22.0138796s
    Aug 22 05:14:57.027: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Running", Reason="", readiness=false. Elapsed: 24.012994205s
    Aug 22 05:14:59.027: INFO: Pod "pod-subpath-test-configmap-brcl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.012856864s
    STEP: Saw pod success 08/22/23 05:14:59.027
    Aug 22 05:14:59.027: INFO: Pod "pod-subpath-test-configmap-brcl" satisfied condition "Succeeded or Failed"
    Aug 22 05:14:59.030: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod pod-subpath-test-configmap-brcl container test-container-subpath-configmap-brcl: <nil>
    STEP: delete the pod 08/22/23 05:14:59.063
    Aug 22 05:14:59.076: INFO: Waiting for pod pod-subpath-test-configmap-brcl to disappear
    Aug 22 05:14:59.079: INFO: Pod pod-subpath-test-configmap-brcl no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-brcl 08/22/23 05:14:59.079
    Aug 22 05:14:59.079: INFO: Deleting pod "pod-subpath-test-configmap-brcl" in namespace "subpath-1452"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 22 05:14:59.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-1452" for this suite. 08/22/23 05:14:59.086
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:14:59.101
Aug 22 05:14:59.101: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-probe 08/22/23 05:14:59.102
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:14:59.12
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:14:59.122
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c in namespace container-probe-7236 08/22/23 05:14:59.128
Aug 22 05:14:59.140: INFO: Waiting up to 5m0s for pod "busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c" in namespace "container-probe-7236" to be "not pending"
Aug 22 05:14:59.144: INFO: Pod "busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.88031ms
Aug 22 05:15:01.150: INFO: Pod "busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009943942s
Aug 22 05:15:03.173: INFO: Pod "busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c": Phase="Running", Reason="", readiness=true. Elapsed: 4.032770132s
Aug 22 05:15:03.173: INFO: Pod "busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c" satisfied condition "not pending"
Aug 22 05:15:03.173: INFO: Started pod busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c in namespace container-probe-7236
STEP: checking the pod's current state and verifying that restartCount is present 08/22/23 05:15:03.173
Aug 22 05:15:03.184: INFO: Initial restart count of pod busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c is 0
STEP: deleting the pod 08/22/23 05:19:04.577
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 22 05:19:04.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7236" for this suite. 08/22/23 05:19:04.596
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":272,"skipped":4982,"failed":0}
------------------------------
â€¢ [SLOW TEST] [245.500 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:14:59.101
    Aug 22 05:14:59.101: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-probe 08/22/23 05:14:59.102
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:14:59.12
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:14:59.122
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c in namespace container-probe-7236 08/22/23 05:14:59.128
    Aug 22 05:14:59.140: INFO: Waiting up to 5m0s for pod "busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c" in namespace "container-probe-7236" to be "not pending"
    Aug 22 05:14:59.144: INFO: Pod "busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.88031ms
    Aug 22 05:15:01.150: INFO: Pod "busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009943942s
    Aug 22 05:15:03.173: INFO: Pod "busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c": Phase="Running", Reason="", readiness=true. Elapsed: 4.032770132s
    Aug 22 05:15:03.173: INFO: Pod "busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c" satisfied condition "not pending"
    Aug 22 05:15:03.173: INFO: Started pod busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c in namespace container-probe-7236
    STEP: checking the pod's current state and verifying that restartCount is present 08/22/23 05:15:03.173
    Aug 22 05:15:03.184: INFO: Initial restart count of pod busybox-ab12f6f4-a184-421f-9ece-aa8b1fb61e6c is 0
    STEP: deleting the pod 08/22/23 05:19:04.577
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 22 05:19:04.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7236" for this suite. 08/22/23 05:19:04.596
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:19:04.602
Aug 22 05:19:04.602: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename sched-pred 08/22/23 05:19:04.603
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:19:04.616
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:19:04.619
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug 22 05:19:04.623: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 22 05:19:04.628: INFO: Waiting for terminating namespaces to be deleted...
Aug 22 05:19:04.630: INFO: 
Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-0 before test
Aug 22 05:19:04.636: INFO: csi-cinder-nodeplugin-zmsc8 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (3 container statuses recorded)
Aug 22 05:19:04.636: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Aug 22 05:19:04.636: INFO: 	Container liveness-probe ready: true, restart count 0
Aug 22 05:19:04.636: INFO: 	Container node-driver-registrar ready: true, restart count 0
Aug 22 05:19:04.636: INFO: kube-dns-autoscaler-96fb49f55-c54df from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
Aug 22 05:19:04.636: INFO: 	Container autoscaler ready: true, restart count 0
Aug 22 05:19:04.636: INFO: kube-flannel-ds-m6hb5 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (1 container statuses recorded)
Aug 22 05:19:04.636: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 22 05:19:04.636: INFO: magnum-metrics-server-758ff97b5-qfdbj from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
Aug 22 05:19:04.636: INFO: 	Container metrics-server ready: true, restart count 0
Aug 22 05:19:04.636: INFO: npd-z88sb from kube-system started at 2023-08-17 07:08:01 +0000 UTC (1 container statuses recorded)
Aug 22 05:19:04.636: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug 22 05:19:04.636: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-gklhn from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 05:19:04.636: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 05:19:04.636: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 05:19:04.636: INFO: 
Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-1 before test
Aug 22 05:19:04.641: INFO: csi-cinder-nodeplugin-jmnz5 from kube-system started at 2023-08-22 03:43:22 +0000 UTC (3 container statuses recorded)
Aug 22 05:19:04.641: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Aug 22 05:19:04.641: INFO: 	Container liveness-probe ready: true, restart count 0
Aug 22 05:19:04.641: INFO: 	Container node-driver-registrar ready: true, restart count 0
Aug 22 05:19:04.641: INFO: kube-flannel-ds-pc26k from kube-system started at 2023-08-22 03:43:22 +0000 UTC (1 container statuses recorded)
Aug 22 05:19:04.641: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 22 05:19:04.641: INFO: npd-jxn7d from kube-system started at 2023-08-22 03:43:42 +0000 UTC (1 container statuses recorded)
Aug 22 05:19:04.641: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug 22 05:19:04.641: INFO: sonobuoy-e2e-job-95e99bb4c3804681 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 05:19:04.641: INFO: 	Container e2e ready: true, restart count 0
Aug 22 05:19:04.641: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 05:19:04.641: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-mmzwp from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 05:19:04.641: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 05:19:04.642: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 05:19:04.642: INFO: 
Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-2 before test
Aug 22 05:19:04.657: INFO: csi-cinder-nodeplugin-6xsh5 from kube-system started at 2023-08-22 03:43:15 +0000 UTC (3 container statuses recorded)
Aug 22 05:19:04.657: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Aug 22 05:19:04.657: INFO: 	Container liveness-probe ready: true, restart count 0
Aug 22 05:19:04.657: INFO: 	Container node-driver-registrar ready: true, restart count 0
Aug 22 05:19:04.657: INFO: kube-flannel-ds-trqzn from kube-system started at 2023-08-22 04:45:29 +0000 UTC (1 container statuses recorded)
Aug 22 05:19:04.657: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 22 05:19:04.657: INFO: npd-cwq76 from kube-system started at 2023-08-22 03:43:35 +0000 UTC (1 container statuses recorded)
Aug 22 05:19:04.657: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug 22 05:19:04.657: INFO: sonobuoy from sonobuoy started at 2023-08-22 03:50:01 +0000 UTC (1 container statuses recorded)
Aug 22 05:19:04.657: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 22 05:19:04.658: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-6dms5 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 05:19:04.658: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 05:19:04.658: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 08/22/23 05:19:04.658
Aug 22 05:19:04.667: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-2380" to be "running"
Aug 22 05:19:04.670: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.930046ms
Aug 22 05:19:06.674: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.006695057s
Aug 22 05:19:06.674: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 08/22/23 05:19:06.677
STEP: Trying to apply a random label on the found node. 08/22/23 05:19:06.695
STEP: verifying the node has the label kubernetes.io/e2e-78ba3794-8850-4baa-8f81-f8702e3a307a 42 08/22/23 05:19:06.733
STEP: Trying to relaunch the pod, now with labels. 08/22/23 05:19:06.737
Aug 22 05:19:06.742: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-2380" to be "not pending"
Aug 22 05:19:06.745: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.728429ms
Aug 22 05:19:08.750: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007699982s
Aug 22 05:19:10.755: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013276432s
Aug 22 05:19:12.749: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 6.006971369s
Aug 22 05:19:12.749: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-78ba3794-8850-4baa-8f81-f8702e3a307a off the node jake-melb-gmyyva4zrlsz-node-2 08/22/23 05:19:12.752
STEP: verifying the node doesn't have the label kubernetes.io/e2e-78ba3794-8850-4baa-8f81-f8702e3a307a 08/22/23 05:19:12.775
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Aug 22 05:19:12.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2380" for this suite. 08/22/23 05:19:12.783
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":273,"skipped":4985,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.188 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:19:04.602
    Aug 22 05:19:04.602: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename sched-pred 08/22/23 05:19:04.603
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:19:04.616
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:19:04.619
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Aug 22 05:19:04.623: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Aug 22 05:19:04.628: INFO: Waiting for terminating namespaces to be deleted...
    Aug 22 05:19:04.630: INFO: 
    Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-0 before test
    Aug 22 05:19:04.636: INFO: csi-cinder-nodeplugin-zmsc8 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (3 container statuses recorded)
    Aug 22 05:19:04.636: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
    Aug 22 05:19:04.636: INFO: 	Container liveness-probe ready: true, restart count 0
    Aug 22 05:19:04.636: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Aug 22 05:19:04.636: INFO: kube-dns-autoscaler-96fb49f55-c54df from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
    Aug 22 05:19:04.636: INFO: 	Container autoscaler ready: true, restart count 0
    Aug 22 05:19:04.636: INFO: kube-flannel-ds-m6hb5 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (1 container statuses recorded)
    Aug 22 05:19:04.636: INFO: 	Container kube-flannel ready: true, restart count 0
    Aug 22 05:19:04.636: INFO: magnum-metrics-server-758ff97b5-qfdbj from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
    Aug 22 05:19:04.636: INFO: 	Container metrics-server ready: true, restart count 0
    Aug 22 05:19:04.636: INFO: npd-z88sb from kube-system started at 2023-08-17 07:08:01 +0000 UTC (1 container statuses recorded)
    Aug 22 05:19:04.636: INFO: 	Container node-problem-detector ready: true, restart count 0
    Aug 22 05:19:04.636: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-gklhn from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 05:19:04.636: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 05:19:04.636: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 22 05:19:04.636: INFO: 
    Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-1 before test
    Aug 22 05:19:04.641: INFO: csi-cinder-nodeplugin-jmnz5 from kube-system started at 2023-08-22 03:43:22 +0000 UTC (3 container statuses recorded)
    Aug 22 05:19:04.641: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
    Aug 22 05:19:04.641: INFO: 	Container liveness-probe ready: true, restart count 0
    Aug 22 05:19:04.641: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Aug 22 05:19:04.641: INFO: kube-flannel-ds-pc26k from kube-system started at 2023-08-22 03:43:22 +0000 UTC (1 container statuses recorded)
    Aug 22 05:19:04.641: INFO: 	Container kube-flannel ready: true, restart count 0
    Aug 22 05:19:04.641: INFO: npd-jxn7d from kube-system started at 2023-08-22 03:43:42 +0000 UTC (1 container statuses recorded)
    Aug 22 05:19:04.641: INFO: 	Container node-problem-detector ready: true, restart count 0
    Aug 22 05:19:04.641: INFO: sonobuoy-e2e-job-95e99bb4c3804681 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 05:19:04.641: INFO: 	Container e2e ready: true, restart count 0
    Aug 22 05:19:04.641: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 05:19:04.641: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-mmzwp from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 05:19:04.641: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 05:19:04.642: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 22 05:19:04.642: INFO: 
    Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-2 before test
    Aug 22 05:19:04.657: INFO: csi-cinder-nodeplugin-6xsh5 from kube-system started at 2023-08-22 03:43:15 +0000 UTC (3 container statuses recorded)
    Aug 22 05:19:04.657: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
    Aug 22 05:19:04.657: INFO: 	Container liveness-probe ready: true, restart count 0
    Aug 22 05:19:04.657: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Aug 22 05:19:04.657: INFO: kube-flannel-ds-trqzn from kube-system started at 2023-08-22 04:45:29 +0000 UTC (1 container statuses recorded)
    Aug 22 05:19:04.657: INFO: 	Container kube-flannel ready: true, restart count 0
    Aug 22 05:19:04.657: INFO: npd-cwq76 from kube-system started at 2023-08-22 03:43:35 +0000 UTC (1 container statuses recorded)
    Aug 22 05:19:04.657: INFO: 	Container node-problem-detector ready: true, restart count 0
    Aug 22 05:19:04.657: INFO: sonobuoy from sonobuoy started at 2023-08-22 03:50:01 +0000 UTC (1 container statuses recorded)
    Aug 22 05:19:04.657: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Aug 22 05:19:04.658: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-6dms5 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 05:19:04.658: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 05:19:04.658: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 08/22/23 05:19:04.658
    Aug 22 05:19:04.667: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-2380" to be "running"
    Aug 22 05:19:04.670: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.930046ms
    Aug 22 05:19:06.674: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.006695057s
    Aug 22 05:19:06.674: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 08/22/23 05:19:06.677
    STEP: Trying to apply a random label on the found node. 08/22/23 05:19:06.695
    STEP: verifying the node has the label kubernetes.io/e2e-78ba3794-8850-4baa-8f81-f8702e3a307a 42 08/22/23 05:19:06.733
    STEP: Trying to relaunch the pod, now with labels. 08/22/23 05:19:06.737
    Aug 22 05:19:06.742: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-2380" to be "not pending"
    Aug 22 05:19:06.745: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.728429ms
    Aug 22 05:19:08.750: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007699982s
    Aug 22 05:19:10.755: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013276432s
    Aug 22 05:19:12.749: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 6.006971369s
    Aug 22 05:19:12.749: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-78ba3794-8850-4baa-8f81-f8702e3a307a off the node jake-melb-gmyyva4zrlsz-node-2 08/22/23 05:19:12.752
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-78ba3794-8850-4baa-8f81-f8702e3a307a 08/22/23 05:19:12.775
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 05:19:12.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-2380" for this suite. 08/22/23 05:19:12.783
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:19:12.792
Aug 22 05:19:12.792: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename replicaset 08/22/23 05:19:12.792
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:19:12.806
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:19:12.809
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 08/22/23 05:19:12.813
Aug 22 05:19:12.820: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-3522" to be "running and ready"
Aug 22 05:19:12.823: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.729891ms
Aug 22 05:19:12.823: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:19:14.829: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008857273s
Aug 22 05:19:14.829: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:19:16.828: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 4.008388199s
Aug 22 05:19:16.828: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Aug 22 05:19:16.828: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 08/22/23 05:19:16.832
STEP: Then the orphan pod is adopted 08/22/23 05:19:16.838
STEP: When the matched label of one of its pods change 08/22/23 05:19:17.903
Aug 22 05:19:17.907: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 08/22/23 05:19:17.917
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 22 05:19:18.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3522" for this suite. 08/22/23 05:19:18.927
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":274,"skipped":5032,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.142 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:19:12.792
    Aug 22 05:19:12.792: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename replicaset 08/22/23 05:19:12.792
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:19:12.806
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:19:12.809
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 08/22/23 05:19:12.813
    Aug 22 05:19:12.820: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-3522" to be "running and ready"
    Aug 22 05:19:12.823: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.729891ms
    Aug 22 05:19:12.823: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:19:14.829: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008857273s
    Aug 22 05:19:14.829: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:19:16.828: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 4.008388199s
    Aug 22 05:19:16.828: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Aug 22 05:19:16.828: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 08/22/23 05:19:16.832
    STEP: Then the orphan pod is adopted 08/22/23 05:19:16.838
    STEP: When the matched label of one of its pods change 08/22/23 05:19:17.903
    Aug 22 05:19:17.907: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 08/22/23 05:19:17.917
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 22 05:19:18.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-3522" for this suite. 08/22/23 05:19:18.927
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:19:18.935
Aug 22 05:19:18.935: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename resourcequota 08/22/23 05:19:18.935
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:19:18.948
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:19:18.951
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 08/22/23 05:19:18.955
STEP: Creating a ResourceQuota 08/22/23 05:19:23.959
STEP: Ensuring resource quota status is calculated 08/22/23 05:19:24.162
STEP: Creating a ReplicationController 08/22/23 05:19:26.168
STEP: Ensuring resource quota status captures replication controller creation 08/22/23 05:19:26.181
STEP: Deleting a ReplicationController 08/22/23 05:19:28.185
STEP: Ensuring resource quota status released usage 08/22/23 05:19:28.284
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 22 05:19:30.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3919" for this suite. 08/22/23 05:19:30.293
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":275,"skipped":5042,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.366 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:19:18.935
    Aug 22 05:19:18.935: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename resourcequota 08/22/23 05:19:18.935
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:19:18.948
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:19:18.951
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 08/22/23 05:19:18.955
    STEP: Creating a ResourceQuota 08/22/23 05:19:23.959
    STEP: Ensuring resource quota status is calculated 08/22/23 05:19:24.162
    STEP: Creating a ReplicationController 08/22/23 05:19:26.168
    STEP: Ensuring resource quota status captures replication controller creation 08/22/23 05:19:26.181
    STEP: Deleting a ReplicationController 08/22/23 05:19:28.185
    STEP: Ensuring resource quota status released usage 08/22/23 05:19:28.284
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 22 05:19:30.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3919" for this suite. 08/22/23 05:19:30.293
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:19:30.301
Aug 22 05:19:30.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pods 08/22/23 05:19:30.302
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:19:30.332
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:19:30.334
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 08/22/23 05:19:30.337
STEP: submitting the pod to kubernetes 08/22/23 05:19:30.337
Aug 22 05:19:30.352: INFO: Waiting up to 5m0s for pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65" in namespace "pods-9527" to be "running and ready"
Aug 22 05:19:30.355: INFO: Pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65": Phase="Pending", Reason="", readiness=false. Elapsed: 3.050964ms
Aug 22 05:19:30.355: INFO: The phase of Pod pod-update-34e69de8-eede-479f-9d57-9387434efe65 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:19:32.359: INFO: Pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007577703s
Aug 22 05:19:32.359: INFO: The phase of Pod pod-update-34e69de8-eede-479f-9d57-9387434efe65 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:19:34.359: INFO: Pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65": Phase="Running", Reason="", readiness=true. Elapsed: 4.007424873s
Aug 22 05:19:34.359: INFO: The phase of Pod pod-update-34e69de8-eede-479f-9d57-9387434efe65 is Running (Ready = true)
Aug 22 05:19:34.359: INFO: Pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 08/22/23 05:19:34.361
STEP: updating the pod 08/22/23 05:19:34.364
Aug 22 05:19:35.175: INFO: Successfully updated pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65"
Aug 22 05:19:35.175: INFO: Waiting up to 5m0s for pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65" in namespace "pods-9527" to be "running"
Aug 22 05:19:35.365: INFO: Pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65": Phase="Running", Reason="", readiness=true. Elapsed: 190.427961ms
Aug 22 05:19:35.365: INFO: Pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 08/22/23 05:19:35.365
Aug 22 05:19:35.368: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 22 05:19:35.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9527" for this suite. 08/22/23 05:19:35.372
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":276,"skipped":5044,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.076 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:19:30.301
    Aug 22 05:19:30.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pods 08/22/23 05:19:30.302
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:19:30.332
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:19:30.334
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 08/22/23 05:19:30.337
    STEP: submitting the pod to kubernetes 08/22/23 05:19:30.337
    Aug 22 05:19:30.352: INFO: Waiting up to 5m0s for pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65" in namespace "pods-9527" to be "running and ready"
    Aug 22 05:19:30.355: INFO: Pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65": Phase="Pending", Reason="", readiness=false. Elapsed: 3.050964ms
    Aug 22 05:19:30.355: INFO: The phase of Pod pod-update-34e69de8-eede-479f-9d57-9387434efe65 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:19:32.359: INFO: Pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007577703s
    Aug 22 05:19:32.359: INFO: The phase of Pod pod-update-34e69de8-eede-479f-9d57-9387434efe65 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:19:34.359: INFO: Pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65": Phase="Running", Reason="", readiness=true. Elapsed: 4.007424873s
    Aug 22 05:19:34.359: INFO: The phase of Pod pod-update-34e69de8-eede-479f-9d57-9387434efe65 is Running (Ready = true)
    Aug 22 05:19:34.359: INFO: Pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 08/22/23 05:19:34.361
    STEP: updating the pod 08/22/23 05:19:34.364
    Aug 22 05:19:35.175: INFO: Successfully updated pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65"
    Aug 22 05:19:35.175: INFO: Waiting up to 5m0s for pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65" in namespace "pods-9527" to be "running"
    Aug 22 05:19:35.365: INFO: Pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65": Phase="Running", Reason="", readiness=true. Elapsed: 190.427961ms
    Aug 22 05:19:35.365: INFO: Pod "pod-update-34e69de8-eede-479f-9d57-9387434efe65" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 08/22/23 05:19:35.365
    Aug 22 05:19:35.368: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 22 05:19:35.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9527" for this suite. 08/22/23 05:19:35.372
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:19:35.379
Aug 22 05:19:35.379: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename podtemplate 08/22/23 05:19:35.38
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:19:35.397
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:19:35.399
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 08/22/23 05:19:35.403
STEP: Replace a pod template 08/22/23 05:19:35.407
Aug 22 05:19:35.415: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Aug 22 05:19:35.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-5040" for this suite. 08/22/23 05:19:35.418
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":277,"skipped":5086,"failed":0}
------------------------------
â€¢ [0.046 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:19:35.379
    Aug 22 05:19:35.379: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename podtemplate 08/22/23 05:19:35.38
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:19:35.397
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:19:35.399
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 08/22/23 05:19:35.403
    STEP: Replace a pod template 08/22/23 05:19:35.407
    Aug 22 05:19:35.415: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Aug 22 05:19:35.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-5040" for this suite. 08/22/23 05:19:35.418
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:19:35.425
Aug 22 05:19:35.425: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename statefulset 08/22/23 05:19:35.426
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:19:35.798
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:19:35.8
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6121 08/22/23 05:19:35.803
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-6121 08/22/23 05:19:35.817
Aug 22 05:19:35.824: INFO: Found 0 stateful pods, waiting for 1
Aug 22 05:19:45.829: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 08/22/23 05:19:45.834
STEP: Getting /status 08/22/23 05:19:45.876
Aug 22 05:19:45.879: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 08/22/23 05:19:45.879
Aug 22 05:19:46.131: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 08/22/23 05:19:46.131
Aug 22 05:19:46.133: INFO: Observed &StatefulSet event: ADDED
Aug 22 05:19:46.133: INFO: Found Statefulset ss in namespace statefulset-6121 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 22 05:19:46.133: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 08/22/23 05:19:46.133
Aug 22 05:19:46.133: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug 22 05:19:46.385: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 08/22/23 05:19:46.385
Aug 22 05:19:46.387: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 22 05:19:46.387: INFO: Deleting all statefulset in ns statefulset-6121
Aug 22 05:19:46.390: INFO: Scaling statefulset ss to 0
Aug 22 05:19:56.575: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 05:19:56.577: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 22 05:19:56.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6121" for this suite. 08/22/23 05:19:56.883
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":278,"skipped":5087,"failed":0}
------------------------------
â€¢ [SLOW TEST] [21.560 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:19:35.425
    Aug 22 05:19:35.425: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename statefulset 08/22/23 05:19:35.426
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:19:35.798
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:19:35.8
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6121 08/22/23 05:19:35.803
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-6121 08/22/23 05:19:35.817
    Aug 22 05:19:35.824: INFO: Found 0 stateful pods, waiting for 1
    Aug 22 05:19:45.829: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 08/22/23 05:19:45.834
    STEP: Getting /status 08/22/23 05:19:45.876
    Aug 22 05:19:45.879: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 08/22/23 05:19:45.879
    Aug 22 05:19:46.131: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 08/22/23 05:19:46.131
    Aug 22 05:19:46.133: INFO: Observed &StatefulSet event: ADDED
    Aug 22 05:19:46.133: INFO: Found Statefulset ss in namespace statefulset-6121 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Aug 22 05:19:46.133: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 08/22/23 05:19:46.133
    Aug 22 05:19:46.133: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Aug 22 05:19:46.385: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 08/22/23 05:19:46.385
    Aug 22 05:19:46.387: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 22 05:19:46.387: INFO: Deleting all statefulset in ns statefulset-6121
    Aug 22 05:19:46.390: INFO: Scaling statefulset ss to 0
    Aug 22 05:19:56.575: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 22 05:19:56.577: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 22 05:19:56.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6121" for this suite. 08/22/23 05:19:56.883
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:19:56.986
Aug 22 05:19:56.986: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pods 08/22/23 05:19:56.987
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:19:57.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:19:57.004
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Aug 22 05:19:57.014: INFO: Waiting up to 5m0s for pod "server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da" in namespace "pods-36" to be "running and ready"
Aug 22 05:19:57.019: INFO: Pod "server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.812428ms
Aug 22 05:19:57.019: INFO: The phase of Pod server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:19:59.023: INFO: Pod "server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008294588s
Aug 22 05:19:59.023: INFO: The phase of Pod server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:20:01.476: INFO: Pod "server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da": Phase="Running", Reason="", readiness=true. Elapsed: 4.461209888s
Aug 22 05:20:01.476: INFO: The phase of Pod server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da is Running (Ready = true)
Aug 22 05:20:01.476: INFO: Pod "server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da" satisfied condition "running and ready"
Aug 22 05:20:01.523: INFO: Waiting up to 5m0s for pod "client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a" in namespace "pods-36" to be "Succeeded or Failed"
Aug 22 05:20:01.527: INFO: Pod "client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.266385ms
Aug 22 05:20:03.531: INFO: Pod "client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008341962s
Aug 22 05:20:05.532: INFO: Pod "client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a": Phase="Running", Reason="", readiness=false. Elapsed: 4.009442767s
Aug 22 05:20:07.533: INFO: Pod "client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009812442s
STEP: Saw pod success 08/22/23 05:20:07.533
Aug 22 05:20:07.533: INFO: Pod "client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a" satisfied condition "Succeeded or Failed"
Aug 22 05:20:07.535: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a container env3cont: <nil>
STEP: delete the pod 08/22/23 05:20:07.566
Aug 22 05:20:07.579: INFO: Waiting for pod client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a to disappear
Aug 22 05:20:07.583: INFO: Pod client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 22 05:20:07.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-36" for this suite. 08/22/23 05:20:07.587
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":279,"skipped":5095,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.607 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:19:56.986
    Aug 22 05:19:56.986: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pods 08/22/23 05:19:56.987
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:19:57.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:19:57.004
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Aug 22 05:19:57.014: INFO: Waiting up to 5m0s for pod "server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da" in namespace "pods-36" to be "running and ready"
    Aug 22 05:19:57.019: INFO: Pod "server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.812428ms
    Aug 22 05:19:57.019: INFO: The phase of Pod server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:19:59.023: INFO: Pod "server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008294588s
    Aug 22 05:19:59.023: INFO: The phase of Pod server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:20:01.476: INFO: Pod "server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da": Phase="Running", Reason="", readiness=true. Elapsed: 4.461209888s
    Aug 22 05:20:01.476: INFO: The phase of Pod server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da is Running (Ready = true)
    Aug 22 05:20:01.476: INFO: Pod "server-envvars-5a52386b-b138-4e50-8854-e0d9ed3630da" satisfied condition "running and ready"
    Aug 22 05:20:01.523: INFO: Waiting up to 5m0s for pod "client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a" in namespace "pods-36" to be "Succeeded or Failed"
    Aug 22 05:20:01.527: INFO: Pod "client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.266385ms
    Aug 22 05:20:03.531: INFO: Pod "client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008341962s
    Aug 22 05:20:05.532: INFO: Pod "client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a": Phase="Running", Reason="", readiness=false. Elapsed: 4.009442767s
    Aug 22 05:20:07.533: INFO: Pod "client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009812442s
    STEP: Saw pod success 08/22/23 05:20:07.533
    Aug 22 05:20:07.533: INFO: Pod "client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a" satisfied condition "Succeeded or Failed"
    Aug 22 05:20:07.535: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a container env3cont: <nil>
    STEP: delete the pod 08/22/23 05:20:07.566
    Aug 22 05:20:07.579: INFO: Waiting for pod client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a to disappear
    Aug 22 05:20:07.583: INFO: Pod client-envvars-0f987cfa-26dd-4d4b-9795-abcf0021d69a no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 22 05:20:07.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-36" for this suite. 08/22/23 05:20:07.587
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:20:07.595
Aug 22 05:20:07.595: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename cronjob 08/22/23 05:20:07.596
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:20:07.612
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:20:07.614
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 08/22/23 05:20:07.618
STEP: Ensuring a job is scheduled 08/22/23 05:20:07.625
STEP: Ensuring exactly one is scheduled 08/22/23 05:21:01.628
STEP: Ensuring exactly one running job exists by listing jobs explicitly 08/22/23 05:21:01.631
STEP: Ensuring no more jobs are scheduled 08/22/23 05:21:01.634
STEP: Removing cronjob 08/22/23 05:26:01.702
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 22 05:26:01.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5961" for this suite. 08/22/23 05:26:01.717
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":280,"skipped":5123,"failed":0}
------------------------------
â€¢ [SLOW TEST] [354.156 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:20:07.595
    Aug 22 05:20:07.595: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename cronjob 08/22/23 05:20:07.596
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:20:07.612
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:20:07.614
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 08/22/23 05:20:07.618
    STEP: Ensuring a job is scheduled 08/22/23 05:20:07.625
    STEP: Ensuring exactly one is scheduled 08/22/23 05:21:01.628
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 08/22/23 05:21:01.631
    STEP: Ensuring no more jobs are scheduled 08/22/23 05:21:01.634
    STEP: Removing cronjob 08/22/23 05:26:01.702
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 22 05:26:01.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5961" for this suite. 08/22/23 05:26:01.717
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:26:01.753
Aug 22 05:26:01.753: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename sched-pred 08/22/23 05:26:01.755
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:01.894
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:01.897
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug 22 05:26:01.902: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 22 05:26:01.910: INFO: Waiting for terminating namespaces to be deleted...
Aug 22 05:26:01.914: INFO: 
Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-0 before test
Aug 22 05:26:01.922: INFO: csi-cinder-nodeplugin-zmsc8 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (3 container statuses recorded)
Aug 22 05:26:01.922: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Aug 22 05:26:01.922: INFO: 	Container liveness-probe ready: true, restart count 0
Aug 22 05:26:01.922: INFO: 	Container node-driver-registrar ready: true, restart count 0
Aug 22 05:26:01.922: INFO: kube-dns-autoscaler-96fb49f55-c54df from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
Aug 22 05:26:01.922: INFO: 	Container autoscaler ready: true, restart count 0
Aug 22 05:26:01.922: INFO: kube-flannel-ds-m6hb5 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (1 container statuses recorded)
Aug 22 05:26:01.922: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 22 05:26:01.922: INFO: magnum-metrics-server-758ff97b5-qfdbj from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
Aug 22 05:26:01.922: INFO: 	Container metrics-server ready: true, restart count 0
Aug 22 05:26:01.922: INFO: npd-z88sb from kube-system started at 2023-08-17 07:08:01 +0000 UTC (1 container statuses recorded)
Aug 22 05:26:01.922: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug 22 05:26:01.922: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-gklhn from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 05:26:01.922: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 05:26:01.922: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 05:26:01.922: INFO: 
Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-1 before test
Aug 22 05:26:01.929: INFO: csi-cinder-nodeplugin-jmnz5 from kube-system started at 2023-08-22 03:43:22 +0000 UTC (3 container statuses recorded)
Aug 22 05:26:01.929: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Aug 22 05:26:01.929: INFO: 	Container liveness-probe ready: true, restart count 0
Aug 22 05:26:01.929: INFO: 	Container node-driver-registrar ready: true, restart count 0
Aug 22 05:26:01.929: INFO: kube-flannel-ds-pc26k from kube-system started at 2023-08-22 03:43:22 +0000 UTC (1 container statuses recorded)
Aug 22 05:26:01.929: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 22 05:26:01.929: INFO: npd-jxn7d from kube-system started at 2023-08-22 03:43:42 +0000 UTC (1 container statuses recorded)
Aug 22 05:26:01.929: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug 22 05:26:01.929: INFO: sonobuoy-e2e-job-95e99bb4c3804681 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 05:26:01.929: INFO: 	Container e2e ready: true, restart count 0
Aug 22 05:26:01.929: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 05:26:01.929: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-mmzwp from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 05:26:01.929: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 05:26:01.929: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 22 05:26:01.929: INFO: 
Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-2 before test
Aug 22 05:26:01.936: INFO: forbid-28211361-xg9sz from cronjob-5961 started at 2023-08-22 05:21:01 +0000 UTC (1 container statuses recorded)
Aug 22 05:26:01.936: INFO: 	Container c ready: true, restart count 0
Aug 22 05:26:01.936: INFO: csi-cinder-nodeplugin-6xsh5 from kube-system started at 2023-08-22 03:43:15 +0000 UTC (3 container statuses recorded)
Aug 22 05:26:01.936: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Aug 22 05:26:01.936: INFO: 	Container liveness-probe ready: true, restart count 0
Aug 22 05:26:01.936: INFO: 	Container node-driver-registrar ready: true, restart count 0
Aug 22 05:26:01.936: INFO: kube-flannel-ds-trqzn from kube-system started at 2023-08-22 04:45:29 +0000 UTC (1 container statuses recorded)
Aug 22 05:26:01.936: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 22 05:26:01.936: INFO: npd-cwq76 from kube-system started at 2023-08-22 03:43:35 +0000 UTC (1 container statuses recorded)
Aug 22 05:26:01.936: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug 22 05:26:01.936: INFO: sonobuoy from sonobuoy started at 2023-08-22 03:50:01 +0000 UTC (1 container statuses recorded)
Aug 22 05:26:01.936: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 22 05:26:01.936: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-6dms5 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
Aug 22 05:26:01.936: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 22 05:26:01.936: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 08/22/23 05:26:01.936
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.177d9d46b573cce0], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 node(s) didn't match Pod's node affinity/selector, 3 node(s) had untolerated taint {node-role.kubernetes.io/master: }. preemption: 0/6 nodes are available: 6 Preemption is not helpful for scheduling.] 08/22/23 05:26:02.762
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Aug 22 05:26:02.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4930" for this suite. 08/22/23 05:26:02.973
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":281,"skipped":5134,"failed":0}
------------------------------
â€¢ [1.227 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:26:01.753
    Aug 22 05:26:01.753: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename sched-pred 08/22/23 05:26:01.755
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:01.894
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:01.897
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Aug 22 05:26:01.902: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Aug 22 05:26:01.910: INFO: Waiting for terminating namespaces to be deleted...
    Aug 22 05:26:01.914: INFO: 
    Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-0 before test
    Aug 22 05:26:01.922: INFO: csi-cinder-nodeplugin-zmsc8 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (3 container statuses recorded)
    Aug 22 05:26:01.922: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
    Aug 22 05:26:01.922: INFO: 	Container liveness-probe ready: true, restart count 0
    Aug 22 05:26:01.922: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Aug 22 05:26:01.922: INFO: kube-dns-autoscaler-96fb49f55-c54df from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
    Aug 22 05:26:01.922: INFO: 	Container autoscaler ready: true, restart count 0
    Aug 22 05:26:01.922: INFO: kube-flannel-ds-m6hb5 from kube-system started at 2023-08-17 07:07:40 +0000 UTC (1 container statuses recorded)
    Aug 22 05:26:01.922: INFO: 	Container kube-flannel ready: true, restart count 0
    Aug 22 05:26:01.922: INFO: magnum-metrics-server-758ff97b5-qfdbj from kube-system started at 2023-08-17 07:08:00 +0000 UTC (1 container statuses recorded)
    Aug 22 05:26:01.922: INFO: 	Container metrics-server ready: true, restart count 0
    Aug 22 05:26:01.922: INFO: npd-z88sb from kube-system started at 2023-08-17 07:08:01 +0000 UTC (1 container statuses recorded)
    Aug 22 05:26:01.922: INFO: 	Container node-problem-detector ready: true, restart count 0
    Aug 22 05:26:01.922: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-gklhn from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 05:26:01.922: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 05:26:01.922: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 22 05:26:01.922: INFO: 
    Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-1 before test
    Aug 22 05:26:01.929: INFO: csi-cinder-nodeplugin-jmnz5 from kube-system started at 2023-08-22 03:43:22 +0000 UTC (3 container statuses recorded)
    Aug 22 05:26:01.929: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
    Aug 22 05:26:01.929: INFO: 	Container liveness-probe ready: true, restart count 0
    Aug 22 05:26:01.929: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Aug 22 05:26:01.929: INFO: kube-flannel-ds-pc26k from kube-system started at 2023-08-22 03:43:22 +0000 UTC (1 container statuses recorded)
    Aug 22 05:26:01.929: INFO: 	Container kube-flannel ready: true, restart count 0
    Aug 22 05:26:01.929: INFO: npd-jxn7d from kube-system started at 2023-08-22 03:43:42 +0000 UTC (1 container statuses recorded)
    Aug 22 05:26:01.929: INFO: 	Container node-problem-detector ready: true, restart count 0
    Aug 22 05:26:01.929: INFO: sonobuoy-e2e-job-95e99bb4c3804681 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 05:26:01.929: INFO: 	Container e2e ready: true, restart count 0
    Aug 22 05:26:01.929: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 05:26:01.929: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-mmzwp from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 05:26:01.929: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 05:26:01.929: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 22 05:26:01.929: INFO: 
    Logging pods the apiserver thinks is on node jake-melb-gmyyva4zrlsz-node-2 before test
    Aug 22 05:26:01.936: INFO: forbid-28211361-xg9sz from cronjob-5961 started at 2023-08-22 05:21:01 +0000 UTC (1 container statuses recorded)
    Aug 22 05:26:01.936: INFO: 	Container c ready: true, restart count 0
    Aug 22 05:26:01.936: INFO: csi-cinder-nodeplugin-6xsh5 from kube-system started at 2023-08-22 03:43:15 +0000 UTC (3 container statuses recorded)
    Aug 22 05:26:01.936: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
    Aug 22 05:26:01.936: INFO: 	Container liveness-probe ready: true, restart count 0
    Aug 22 05:26:01.936: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Aug 22 05:26:01.936: INFO: kube-flannel-ds-trqzn from kube-system started at 2023-08-22 04:45:29 +0000 UTC (1 container statuses recorded)
    Aug 22 05:26:01.936: INFO: 	Container kube-flannel ready: true, restart count 0
    Aug 22 05:26:01.936: INFO: npd-cwq76 from kube-system started at 2023-08-22 03:43:35 +0000 UTC (1 container statuses recorded)
    Aug 22 05:26:01.936: INFO: 	Container node-problem-detector ready: true, restart count 0
    Aug 22 05:26:01.936: INFO: sonobuoy from sonobuoy started at 2023-08-22 03:50:01 +0000 UTC (1 container statuses recorded)
    Aug 22 05:26:01.936: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Aug 22 05:26:01.936: INFO: sonobuoy-systemd-logs-daemon-set-f867057385cd49dc-6dms5 from sonobuoy started at 2023-08-22 03:50:12 +0000 UTC (2 container statuses recorded)
    Aug 22 05:26:01.936: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 22 05:26:01.936: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 08/22/23 05:26:01.936
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.177d9d46b573cce0], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 node(s) didn't match Pod's node affinity/selector, 3 node(s) had untolerated taint {node-role.kubernetes.io/master: }. preemption: 0/6 nodes are available: 6 Preemption is not helpful for scheduling.] 08/22/23 05:26:02.762
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 05:26:02.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-4930" for this suite. 08/22/23 05:26:02.973
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:26:02.983
Aug 22 05:26:02.983: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename resourcequota 08/22/23 05:26:02.984
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:03.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:03.273
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 08/22/23 05:26:03.277
STEP: Ensuring ResourceQuota status is calculated 08/22/23 05:26:03.283
STEP: Creating a ResourceQuota with not best effort scope 08/22/23 05:26:05.288
STEP: Ensuring ResourceQuota status is calculated 08/22/23 05:26:05.293
STEP: Creating a best-effort pod 08/22/23 05:26:07.937
STEP: Ensuring resource quota with best effort scope captures the pod usage 08/22/23 05:26:08.012
STEP: Ensuring resource quota with not best effort ignored the pod usage 08/22/23 05:26:10.025
STEP: Deleting the pod 08/22/23 05:26:12.028
STEP: Ensuring resource quota status released the pod usage 08/22/23 05:26:12.038
STEP: Creating a not best-effort pod 08/22/23 05:26:14.04
STEP: Ensuring resource quota with not best effort scope captures the pod usage 08/22/23 05:26:14.049
STEP: Ensuring resource quota with best effort scope ignored the pod usage 08/22/23 05:26:16.054
STEP: Deleting the pod 08/22/23 05:26:18.058
STEP: Ensuring resource quota status released the pod usage 08/22/23 05:26:18.18
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 22 05:26:20.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2016" for this suite. 08/22/23 05:26:20.188
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":282,"skipped":5148,"failed":0}
------------------------------
â€¢ [SLOW TEST] [17.521 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:26:02.983
    Aug 22 05:26:02.983: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename resourcequota 08/22/23 05:26:02.984
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:03.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:03.273
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 08/22/23 05:26:03.277
    STEP: Ensuring ResourceQuota status is calculated 08/22/23 05:26:03.283
    STEP: Creating a ResourceQuota with not best effort scope 08/22/23 05:26:05.288
    STEP: Ensuring ResourceQuota status is calculated 08/22/23 05:26:05.293
    STEP: Creating a best-effort pod 08/22/23 05:26:07.937
    STEP: Ensuring resource quota with best effort scope captures the pod usage 08/22/23 05:26:08.012
    STEP: Ensuring resource quota with not best effort ignored the pod usage 08/22/23 05:26:10.025
    STEP: Deleting the pod 08/22/23 05:26:12.028
    STEP: Ensuring resource quota status released the pod usage 08/22/23 05:26:12.038
    STEP: Creating a not best-effort pod 08/22/23 05:26:14.04
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 08/22/23 05:26:14.049
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 08/22/23 05:26:16.054
    STEP: Deleting the pod 08/22/23 05:26:18.058
    STEP: Ensuring resource quota status released the pod usage 08/22/23 05:26:18.18
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 22 05:26:20.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2016" for this suite. 08/22/23 05:26:20.188
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:26:20.505
Aug 22 05:26:20.505: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename server-version 08/22/23 05:26:20.506
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:20.616
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:20.619
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 08/22/23 05:26:20.624
STEP: Confirm major version 08/22/23 05:26:20.625
Aug 22 05:26:20.625: INFO: Major version: 1
STEP: Confirm minor version 08/22/23 05:26:20.625
Aug 22 05:26:20.625: INFO: cleanMinorVersion: 25
Aug 22 05:26:20.625: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Aug 22 05:26:20.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-7947" for this suite. 08/22/23 05:26:20.629
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":283,"skipped":5172,"failed":0}
------------------------------
â€¢ [0.131 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:26:20.505
    Aug 22 05:26:20.505: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename server-version 08/22/23 05:26:20.506
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:20.616
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:20.619
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 08/22/23 05:26:20.624
    STEP: Confirm major version 08/22/23 05:26:20.625
    Aug 22 05:26:20.625: INFO: Major version: 1
    STEP: Confirm minor version 08/22/23 05:26:20.625
    Aug 22 05:26:20.625: INFO: cleanMinorVersion: 25
    Aug 22 05:26:20.625: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Aug 22 05:26:20.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-7947" for this suite. 08/22/23 05:26:20.629
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:26:20.637
Aug 22 05:26:20.637: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename watch 08/22/23 05:26:20.638
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:20.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:20.66
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 08/22/23 05:26:20.664
STEP: modifying the configmap once 08/22/23 05:26:20.669
STEP: modifying the configmap a second time 08/22/23 05:26:20.677
STEP: deleting the configmap 08/22/23 05:26:20.684
STEP: creating a watch on configmaps from the resource version returned by the first update 08/22/23 05:26:20.689
STEP: Expecting to observe notifications for all changes to the configmap after the first update 08/22/23 05:26:20.691
Aug 22 05:26:20.691: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4328  6885ce5e-280e-4048-b9a7-ea6a3456113c 1282491 0 2023-08-22 05:26:20 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-08-22 05:26:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 22 05:26:20.691: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4328  6885ce5e-280e-4048-b9a7-ea6a3456113c 1282492 0 2023-08-22 05:26:20 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-08-22 05:26:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 22 05:26:20.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4328" for this suite. 08/22/23 05:26:20.695
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":284,"skipped":5195,"failed":0}
------------------------------
â€¢ [0.064 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:26:20.637
    Aug 22 05:26:20.637: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename watch 08/22/23 05:26:20.638
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:20.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:20.66
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 08/22/23 05:26:20.664
    STEP: modifying the configmap once 08/22/23 05:26:20.669
    STEP: modifying the configmap a second time 08/22/23 05:26:20.677
    STEP: deleting the configmap 08/22/23 05:26:20.684
    STEP: creating a watch on configmaps from the resource version returned by the first update 08/22/23 05:26:20.689
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 08/22/23 05:26:20.691
    Aug 22 05:26:20.691: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4328  6885ce5e-280e-4048-b9a7-ea6a3456113c 1282491 0 2023-08-22 05:26:20 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-08-22 05:26:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 22 05:26:20.691: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4328  6885ce5e-280e-4048-b9a7-ea6a3456113c 1282492 0 2023-08-22 05:26:20 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-08-22 05:26:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 22 05:26:20.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-4328" for this suite. 08/22/23 05:26:20.695
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:26:20.702
Aug 22 05:26:20.702: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 05:26:20.702
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:20.718
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:20.721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 05:26:20.74
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:26:20.994
STEP: Deploying the webhook pod 08/22/23 05:26:21.283
STEP: Wait for the deployment to be ready 08/22/23 05:26:21.297
Aug 22 05:26:21.698: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 05:26:23.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 22 05:26:25.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 05:26:27.713
STEP: Verifying the service has paired with the endpoint 08/22/23 05:26:27.726
Aug 22 05:26:28.726: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 08/22/23 05:26:28.73
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 08/22/23 05:26:28.774
STEP: Creating a dummy validating-webhook-configuration object 08/22/23 05:26:28.787
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 08/22/23 05:26:28.793
STEP: Creating a dummy mutating-webhook-configuration object 08/22/23 05:26:28.798
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 08/22/23 05:26:28.805
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:26:28.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3422" for this suite. 08/22/23 05:26:28.822
STEP: Destroying namespace "webhook-3422-markers" for this suite. 08/22/23 05:26:28.828
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":285,"skipped":5227,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.394 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:26:20.702
    Aug 22 05:26:20.702: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 05:26:20.702
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:20.718
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:20.721
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 05:26:20.74
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:26:20.994
    STEP: Deploying the webhook pod 08/22/23 05:26:21.283
    STEP: Wait for the deployment to be ready 08/22/23 05:26:21.297
    Aug 22 05:26:21.698: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 05:26:23.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 22 05:26:25.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 05:26:27.713
    STEP: Verifying the service has paired with the endpoint 08/22/23 05:26:27.726
    Aug 22 05:26:28.726: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 08/22/23 05:26:28.73
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 08/22/23 05:26:28.774
    STEP: Creating a dummy validating-webhook-configuration object 08/22/23 05:26:28.787
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 08/22/23 05:26:28.793
    STEP: Creating a dummy mutating-webhook-configuration object 08/22/23 05:26:28.798
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 08/22/23 05:26:28.805
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:26:28.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3422" for this suite. 08/22/23 05:26:28.822
    STEP: Destroying namespace "webhook-3422-markers" for this suite. 08/22/23 05:26:28.828
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:26:29.099
Aug 22 05:26:29.099: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pods 08/22/23 05:26:29.1
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:29.122
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:29.125
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 08/22/23 05:26:29.13
STEP: setting up watch 08/22/23 05:26:29.13
STEP: submitting the pod to kubernetes 08/22/23 05:26:29.234
STEP: verifying the pod is in kubernetes 08/22/23 05:26:29.295
STEP: verifying pod creation was observed 08/22/23 05:26:29.298
Aug 22 05:26:29.298: INFO: Waiting up to 5m0s for pod "pod-submit-remove-bb502a42-8ad4-461c-b144-b84bb89f0d96" in namespace "pods-4271" to be "running"
Aug 22 05:26:29.311: INFO: Pod "pod-submit-remove-bb502a42-8ad4-461c-b144-b84bb89f0d96": Phase="Pending", Reason="", readiness=false. Elapsed: 12.704834ms
Aug 22 05:26:31.316: INFO: Pod "pod-submit-remove-bb502a42-8ad4-461c-b144-b84bb89f0d96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017205129s
Aug 22 05:26:33.321: INFO: Pod "pod-submit-remove-bb502a42-8ad4-461c-b144-b84bb89f0d96": Phase="Running", Reason="", readiness=true. Elapsed: 4.022617082s
Aug 22 05:26:33.321: INFO: Pod "pod-submit-remove-bb502a42-8ad4-461c-b144-b84bb89f0d96" satisfied condition "running"
STEP: deleting the pod gracefully 08/22/23 05:26:33.323
STEP: verifying pod deletion was observed 08/22/23 05:26:33.56
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 22 05:26:35.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4271" for this suite. 08/22/23 05:26:35.443
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":286,"skipped":5256,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.350 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:26:29.099
    Aug 22 05:26:29.099: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pods 08/22/23 05:26:29.1
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:29.122
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:29.125
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 08/22/23 05:26:29.13
    STEP: setting up watch 08/22/23 05:26:29.13
    STEP: submitting the pod to kubernetes 08/22/23 05:26:29.234
    STEP: verifying the pod is in kubernetes 08/22/23 05:26:29.295
    STEP: verifying pod creation was observed 08/22/23 05:26:29.298
    Aug 22 05:26:29.298: INFO: Waiting up to 5m0s for pod "pod-submit-remove-bb502a42-8ad4-461c-b144-b84bb89f0d96" in namespace "pods-4271" to be "running"
    Aug 22 05:26:29.311: INFO: Pod "pod-submit-remove-bb502a42-8ad4-461c-b144-b84bb89f0d96": Phase="Pending", Reason="", readiness=false. Elapsed: 12.704834ms
    Aug 22 05:26:31.316: INFO: Pod "pod-submit-remove-bb502a42-8ad4-461c-b144-b84bb89f0d96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017205129s
    Aug 22 05:26:33.321: INFO: Pod "pod-submit-remove-bb502a42-8ad4-461c-b144-b84bb89f0d96": Phase="Running", Reason="", readiness=true. Elapsed: 4.022617082s
    Aug 22 05:26:33.321: INFO: Pod "pod-submit-remove-bb502a42-8ad4-461c-b144-b84bb89f0d96" satisfied condition "running"
    STEP: deleting the pod gracefully 08/22/23 05:26:33.323
    STEP: verifying pod deletion was observed 08/22/23 05:26:33.56
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 22 05:26:35.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4271" for this suite. 08/22/23 05:26:35.443
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:26:35.452
Aug 22 05:26:35.452: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename daemonsets 08/22/23 05:26:35.453
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:35.503
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:35.506
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 08/22/23 05:26:35.532
STEP: Check that daemon pods launch on every node of the cluster. 08/22/23 05:26:35.599
Aug 22 05:26:35.604: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:35.604: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:35.604: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:35.680: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 05:26:35.680: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 05:26:36.685: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:36.685: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:36.685: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:36.687: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 05:26:36.687: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 05:26:37.686: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:37.686: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:37.686: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:37.689: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 05:26:37.689: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 05:26:38.726: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:38.726: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:38.726: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:38.729: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 05:26:38.729: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
Aug 22 05:26:39.686: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:39.686: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:39.686: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:26:39.689: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 22 05:26:39.689: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 08/22/23 05:26:39.692
Aug 22 05:26:39.695: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 08/22/23 05:26:39.695
Aug 22 05:26:39.703: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 08/22/23 05:26:39.703
Aug 22 05:26:39.705: INFO: Observed &DaemonSet event: ADDED
Aug 22 05:26:39.706: INFO: Observed &DaemonSet event: MODIFIED
Aug 22 05:26:39.706: INFO: Observed &DaemonSet event: MODIFIED
Aug 22 05:26:39.706: INFO: Observed &DaemonSet event: MODIFIED
Aug 22 05:26:39.706: INFO: Observed &DaemonSet event: MODIFIED
Aug 22 05:26:39.706: INFO: Found daemon set daemon-set in namespace daemonsets-8972 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 22 05:26:39.706: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 08/22/23 05:26:39.706
STEP: watching for the daemon set status to be patched 08/22/23 05:26:39.714
Aug 22 05:26:39.716: INFO: Observed &DaemonSet event: ADDED
Aug 22 05:26:39.716: INFO: Observed &DaemonSet event: MODIFIED
Aug 22 05:26:39.716: INFO: Observed &DaemonSet event: MODIFIED
Aug 22 05:26:39.716: INFO: Observed &DaemonSet event: MODIFIED
Aug 22 05:26:39.717: INFO: Observed &DaemonSet event: MODIFIED
Aug 22 05:26:39.717: INFO: Observed daemon set daemon-set in namespace daemonsets-8972 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 22 05:26:39.717: INFO: Observed &DaemonSet event: MODIFIED
Aug 22 05:26:39.717: INFO: Found daemon set daemon-set in namespace daemonsets-8972 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Aug 22 05:26:39.717: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/22/23 05:26:39.721
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8972, will wait for the garbage collector to delete the pods 08/22/23 05:26:39.721
Aug 22 05:26:39.783: INFO: Deleting DaemonSet.extensions daemon-set took: 9.41825ms
Aug 22 05:26:39.884: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.526779ms
Aug 22 05:26:42.188: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 05:26:42.188: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 22 05:26:42.191: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1282732"},"items":null}

Aug 22 05:26:42.193: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1282732"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 22 05:26:42.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8972" for this suite. 08/22/23 05:26:42.208
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":287,"skipped":5291,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.763 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:26:35.452
    Aug 22 05:26:35.452: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename daemonsets 08/22/23 05:26:35.453
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:35.503
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:35.506
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 08/22/23 05:26:35.532
    STEP: Check that daemon pods launch on every node of the cluster. 08/22/23 05:26:35.599
    Aug 22 05:26:35.604: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:35.604: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:35.604: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:35.680: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 05:26:35.680: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 05:26:36.685: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:36.685: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:36.685: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:36.687: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 05:26:36.687: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 05:26:37.686: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:37.686: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:37.686: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:37.689: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 05:26:37.689: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 05:26:38.726: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:38.726: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:38.726: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:38.729: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 05:26:38.729: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
    Aug 22 05:26:39.686: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:39.686: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:39.686: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:26:39.689: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 22 05:26:39.689: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 08/22/23 05:26:39.692
    Aug 22 05:26:39.695: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 08/22/23 05:26:39.695
    Aug 22 05:26:39.703: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 08/22/23 05:26:39.703
    Aug 22 05:26:39.705: INFO: Observed &DaemonSet event: ADDED
    Aug 22 05:26:39.706: INFO: Observed &DaemonSet event: MODIFIED
    Aug 22 05:26:39.706: INFO: Observed &DaemonSet event: MODIFIED
    Aug 22 05:26:39.706: INFO: Observed &DaemonSet event: MODIFIED
    Aug 22 05:26:39.706: INFO: Observed &DaemonSet event: MODIFIED
    Aug 22 05:26:39.706: INFO: Found daemon set daemon-set in namespace daemonsets-8972 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Aug 22 05:26:39.706: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 08/22/23 05:26:39.706
    STEP: watching for the daemon set status to be patched 08/22/23 05:26:39.714
    Aug 22 05:26:39.716: INFO: Observed &DaemonSet event: ADDED
    Aug 22 05:26:39.716: INFO: Observed &DaemonSet event: MODIFIED
    Aug 22 05:26:39.716: INFO: Observed &DaemonSet event: MODIFIED
    Aug 22 05:26:39.716: INFO: Observed &DaemonSet event: MODIFIED
    Aug 22 05:26:39.717: INFO: Observed &DaemonSet event: MODIFIED
    Aug 22 05:26:39.717: INFO: Observed daemon set daemon-set in namespace daemonsets-8972 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Aug 22 05:26:39.717: INFO: Observed &DaemonSet event: MODIFIED
    Aug 22 05:26:39.717: INFO: Found daemon set daemon-set in namespace daemonsets-8972 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Aug 22 05:26:39.717: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/22/23 05:26:39.721
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8972, will wait for the garbage collector to delete the pods 08/22/23 05:26:39.721
    Aug 22 05:26:39.783: INFO: Deleting DaemonSet.extensions daemon-set took: 9.41825ms
    Aug 22 05:26:39.884: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.526779ms
    Aug 22 05:26:42.188: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 05:26:42.188: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 22 05:26:42.191: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1282732"},"items":null}

    Aug 22 05:26:42.193: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1282732"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 05:26:42.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8972" for this suite. 08/22/23 05:26:42.208
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:26:42.219
Aug 22 05:26:42.219: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pod-network-test 08/22/23 05:26:42.22
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:42.309
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:42.312
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-3329 08/22/23 05:26:42.462
STEP: creating a selector 08/22/23 05:26:42.462
STEP: Creating the service pods in kubernetes 08/22/23 05:26:42.463
Aug 22 05:26:42.463: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 22 05:26:42.497: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3329" to be "running and ready"
Aug 22 05:26:42.501: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.27235ms
Aug 22 05:26:42.501: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:26:44.505: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007676953s
Aug 22 05:26:44.505: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:26:46.509: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.011796051s
Aug 22 05:26:46.509: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:26:48.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.00722766s
Aug 22 05:26:48.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:26:50.560: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.062772199s
Aug 22 05:26:50.560: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:26:52.507: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.009619359s
Aug 22 05:26:52.507: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:26:54.573: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.075347191s
Aug 22 05:26:54.573: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:26:56.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.007444788s
Aug 22 05:26:56.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:26:58.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.00754222s
Aug 22 05:26:58.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:27:00.506: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.0081343s
Aug 22 05:27:00.506: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:27:02.504: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.00693889s
Aug 22 05:27:02.504: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:27:04.504: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.006616334s
Aug 22 05:27:04.504: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Aug 22 05:27:04.504: INFO: Pod "netserver-0" satisfied condition "running and ready"
Aug 22 05:27:04.506: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3329" to be "running and ready"
Aug 22 05:27:04.509: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.794783ms
Aug 22 05:27:04.509: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Aug 22 05:27:04.509: INFO: Pod "netserver-1" satisfied condition "running and ready"
Aug 22 05:27:04.511: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3329" to be "running and ready"
Aug 22 05:27:04.517: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 6.069056ms
Aug 22 05:27:04.517: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Aug 22 05:27:04.517: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 08/22/23 05:27:04.52
Aug 22 05:27:04.534: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3329" to be "running"
Aug 22 05:27:04.820: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 286.649026ms
Aug 22 05:27:06.823: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.289836434s
Aug 22 05:27:08.824: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.290514038s
Aug 22 05:27:08.824: INFO: Pod "test-container-pod" satisfied condition "running"
Aug 22 05:27:08.827: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Aug 22 05:27:08.827: INFO: Breadth first check of 10.100.3.183 on host 10.0.0.97...
Aug 22 05:27:08.829: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.4.37:9080/dial?request=hostname&protocol=udp&host=10.100.3.183&port=8081&tries=1'] Namespace:pod-network-test-3329 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:27:08.829: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:27:08.830: INFO: ExecWithOptions: Clientset creation
Aug 22 05:27:08.830: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-3329/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.4.37%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.100.3.183%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 22 05:27:08.908: INFO: Waiting for responses: map[]
Aug 22 05:27:08.909: INFO: reached 10.100.3.183 after 0/1 tries
Aug 22 05:27:08.909: INFO: Breadth first check of 10.100.5.125 on host 10.0.0.232...
Aug 22 05:27:08.911: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.4.37:9080/dial?request=hostname&protocol=udp&host=10.100.5.125&port=8081&tries=1'] Namespace:pod-network-test-3329 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:27:08.911: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:27:08.911: INFO: ExecWithOptions: Clientset creation
Aug 22 05:27:08.911: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-3329/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.4.37%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.100.5.125%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 22 05:27:08.983: INFO: Waiting for responses: map[]
Aug 22 05:27:08.983: INFO: reached 10.100.5.125 after 0/1 tries
Aug 22 05:27:08.983: INFO: Breadth first check of 10.100.4.36 on host 10.0.0.130...
Aug 22 05:27:08.986: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.4.37:9080/dial?request=hostname&protocol=udp&host=10.100.4.36&port=8081&tries=1'] Namespace:pod-network-test-3329 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:27:08.986: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:27:08.986: INFO: ExecWithOptions: Clientset creation
Aug 22 05:27:08.986: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-3329/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.4.37%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.100.4.36%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 22 05:27:09.057: INFO: Waiting for responses: map[]
Aug 22 05:27:09.057: INFO: reached 10.100.4.36 after 0/1 tries
Aug 22 05:27:09.057: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Aug 22 05:27:09.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3329" for this suite. 08/22/23 05:27:09.063
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":288,"skipped":5305,"failed":0}
------------------------------
â€¢ [SLOW TEST] [27.132 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:26:42.219
    Aug 22 05:26:42.219: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pod-network-test 08/22/23 05:26:42.22
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:26:42.309
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:26:42.312
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-3329 08/22/23 05:26:42.462
    STEP: creating a selector 08/22/23 05:26:42.462
    STEP: Creating the service pods in kubernetes 08/22/23 05:26:42.463
    Aug 22 05:26:42.463: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Aug 22 05:26:42.497: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3329" to be "running and ready"
    Aug 22 05:26:42.501: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.27235ms
    Aug 22 05:26:42.501: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:26:44.505: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007676953s
    Aug 22 05:26:44.505: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:26:46.509: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.011796051s
    Aug 22 05:26:46.509: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:26:48.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.00722766s
    Aug 22 05:26:48.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:26:50.560: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.062772199s
    Aug 22 05:26:50.560: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:26:52.507: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.009619359s
    Aug 22 05:26:52.507: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:26:54.573: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.075347191s
    Aug 22 05:26:54.573: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:26:56.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.007444788s
    Aug 22 05:26:56.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:26:58.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.00754222s
    Aug 22 05:26:58.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:27:00.506: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.0081343s
    Aug 22 05:27:00.506: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:27:02.504: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.00693889s
    Aug 22 05:27:02.504: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:27:04.504: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.006616334s
    Aug 22 05:27:04.504: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Aug 22 05:27:04.504: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Aug 22 05:27:04.506: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3329" to be "running and ready"
    Aug 22 05:27:04.509: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.794783ms
    Aug 22 05:27:04.509: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Aug 22 05:27:04.509: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Aug 22 05:27:04.511: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3329" to be "running and ready"
    Aug 22 05:27:04.517: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 6.069056ms
    Aug 22 05:27:04.517: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Aug 22 05:27:04.517: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 08/22/23 05:27:04.52
    Aug 22 05:27:04.534: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3329" to be "running"
    Aug 22 05:27:04.820: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 286.649026ms
    Aug 22 05:27:06.823: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.289836434s
    Aug 22 05:27:08.824: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.290514038s
    Aug 22 05:27:08.824: INFO: Pod "test-container-pod" satisfied condition "running"
    Aug 22 05:27:08.827: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Aug 22 05:27:08.827: INFO: Breadth first check of 10.100.3.183 on host 10.0.0.97...
    Aug 22 05:27:08.829: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.4.37:9080/dial?request=hostname&protocol=udp&host=10.100.3.183&port=8081&tries=1'] Namespace:pod-network-test-3329 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:27:08.829: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:27:08.830: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:27:08.830: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-3329/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.4.37%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.100.3.183%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 22 05:27:08.908: INFO: Waiting for responses: map[]
    Aug 22 05:27:08.909: INFO: reached 10.100.3.183 after 0/1 tries
    Aug 22 05:27:08.909: INFO: Breadth first check of 10.100.5.125 on host 10.0.0.232...
    Aug 22 05:27:08.911: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.4.37:9080/dial?request=hostname&protocol=udp&host=10.100.5.125&port=8081&tries=1'] Namespace:pod-network-test-3329 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:27:08.911: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:27:08.911: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:27:08.911: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-3329/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.4.37%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.100.5.125%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 22 05:27:08.983: INFO: Waiting for responses: map[]
    Aug 22 05:27:08.983: INFO: reached 10.100.5.125 after 0/1 tries
    Aug 22 05:27:08.983: INFO: Breadth first check of 10.100.4.36 on host 10.0.0.130...
    Aug 22 05:27:08.986: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.4.37:9080/dial?request=hostname&protocol=udp&host=10.100.4.36&port=8081&tries=1'] Namespace:pod-network-test-3329 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:27:08.986: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:27:08.986: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:27:08.986: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-3329/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.4.37%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.100.4.36%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 22 05:27:09.057: INFO: Waiting for responses: map[]
    Aug 22 05:27:09.057: INFO: reached 10.100.4.36 after 0/1 tries
    Aug 22 05:27:09.057: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Aug 22 05:27:09.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-3329" for this suite. 08/22/23 05:27:09.063
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:27:09.353
Aug 22 05:27:09.353: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename containers 08/22/23 05:27:09.354
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:27:09.646
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:27:09.649
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 08/22/23 05:27:10.045
Aug 22 05:27:10.057: INFO: Waiting up to 5m0s for pod "client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330" in namespace "containers-7899" to be "Succeeded or Failed"
Aug 22 05:27:10.122: INFO: Pod "client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330": Phase="Pending", Reason="", readiness=false. Elapsed: 64.974761ms
Aug 22 05:27:12.127: INFO: Pod "client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069475495s
Aug 22 05:27:14.126: INFO: Pod "client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068812411s
Aug 22 05:27:16.420: INFO: Pod "client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330": Phase="Pending", Reason="", readiness=false. Elapsed: 6.362793723s
Aug 22 05:27:18.126: INFO: Pod "client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.069099991s
STEP: Saw pod success 08/22/23 05:27:18.126
Aug 22 05:27:18.126: INFO: Pod "client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330" satisfied condition "Succeeded or Failed"
Aug 22 05:27:18.129: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330 container agnhost-container: <nil>
STEP: delete the pod 08/22/23 05:27:18.159
Aug 22 05:27:18.267: INFO: Waiting for pod client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330 to disappear
Aug 22 05:27:18.271: INFO: Pod client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Aug 22 05:27:18.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7899" for this suite. 08/22/23 05:27:18.275
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":289,"skipped":5306,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.929 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:27:09.353
    Aug 22 05:27:09.353: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename containers 08/22/23 05:27:09.354
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:27:09.646
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:27:09.649
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 08/22/23 05:27:10.045
    Aug 22 05:27:10.057: INFO: Waiting up to 5m0s for pod "client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330" in namespace "containers-7899" to be "Succeeded or Failed"
    Aug 22 05:27:10.122: INFO: Pod "client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330": Phase="Pending", Reason="", readiness=false. Elapsed: 64.974761ms
    Aug 22 05:27:12.127: INFO: Pod "client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069475495s
    Aug 22 05:27:14.126: INFO: Pod "client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068812411s
    Aug 22 05:27:16.420: INFO: Pod "client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330": Phase="Pending", Reason="", readiness=false. Elapsed: 6.362793723s
    Aug 22 05:27:18.126: INFO: Pod "client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.069099991s
    STEP: Saw pod success 08/22/23 05:27:18.126
    Aug 22 05:27:18.126: INFO: Pod "client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330" satisfied condition "Succeeded or Failed"
    Aug 22 05:27:18.129: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330 container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 05:27:18.159
    Aug 22 05:27:18.267: INFO: Waiting for pod client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330 to disappear
    Aug 22 05:27:18.271: INFO: Pod client-containers-c33a6e49-de4a-41cc-9fcb-67dfac777330 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Aug 22 05:27:18.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-7899" for this suite. 08/22/23 05:27:18.275
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:27:18.282
Aug 22 05:27:18.282: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename gc 08/22/23 05:27:18.283
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:27:18.305
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:27:18.307
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Aug 22 05:27:18.334: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"f14a4a86-fdd7-4bd1-9608-cd169b125b51", Controller:(*bool)(0xc003bd6daa), BlockOwnerDeletion:(*bool)(0xc003bd6dab)}}
Aug 22 05:27:18.342: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"67549052-cdc4-49b9-b7b7-1c5e93997ef2", Controller:(*bool)(0xc0060a81ba), BlockOwnerDeletion:(*bool)(0xc0060a81bb)}}
Aug 22 05:27:18.515: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"2c4ecc31-b4b2-4766-83c8-d92ff578ee7d", Controller:(*bool)(0xc0060a83d2), BlockOwnerDeletion:(*bool)(0xc0060a83d3)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 22 05:27:23.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6012" for this suite. 08/22/23 05:27:23.613
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":290,"skipped":5311,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.338 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:27:18.282
    Aug 22 05:27:18.282: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename gc 08/22/23 05:27:18.283
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:27:18.305
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:27:18.307
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Aug 22 05:27:18.334: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"f14a4a86-fdd7-4bd1-9608-cd169b125b51", Controller:(*bool)(0xc003bd6daa), BlockOwnerDeletion:(*bool)(0xc003bd6dab)}}
    Aug 22 05:27:18.342: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"67549052-cdc4-49b9-b7b7-1c5e93997ef2", Controller:(*bool)(0xc0060a81ba), BlockOwnerDeletion:(*bool)(0xc0060a81bb)}}
    Aug 22 05:27:18.515: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"2c4ecc31-b4b2-4766-83c8-d92ff578ee7d", Controller:(*bool)(0xc0060a83d2), BlockOwnerDeletion:(*bool)(0xc0060a83d3)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 22 05:27:23.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-6012" for this suite. 08/22/23 05:27:23.613
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:27:23.621
Aug 22 05:27:23.621: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename limitrange 08/22/23 05:27:23.621
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:27:23.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:27:23.791
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 08/22/23 05:27:23.795
STEP: Setting up watch 08/22/23 05:27:23.796
STEP: Submitting a LimitRange 08/22/23 05:27:23.908
STEP: Verifying LimitRange creation was observed 08/22/23 05:27:23.919
STEP: Fetching the LimitRange to ensure it has proper values 08/22/23 05:27:23.919
Aug 22 05:27:23.923: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Aug 22 05:27:23.923: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 08/22/23 05:27:23.923
STEP: Ensuring Pod has resource requirements applied from LimitRange 08/22/23 05:27:23.93
Aug 22 05:27:23.933: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Aug 22 05:27:23.933: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 08/22/23 05:27:23.933
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 08/22/23 05:27:23.94
Aug 22 05:27:23.943: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Aug 22 05:27:23.943: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 08/22/23 05:27:23.943
STEP: Failing to create a Pod with more than max resources 08/22/23 05:27:23.945
STEP: Updating a LimitRange 08/22/23 05:27:23.947
STEP: Verifying LimitRange updating is effective 08/22/23 05:27:23.952
STEP: Creating a Pod with less than former min resources 08/22/23 05:27:25.956
STEP: Failing to create a Pod with more than max resources 08/22/23 05:27:25.963
STEP: Deleting a LimitRange 08/22/23 05:27:25.966
STEP: Verifying the LimitRange was deleted 08/22/23 05:27:25.971
Aug 22 05:27:30.975: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 08/22/23 05:27:30.975
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Aug 22 05:27:30.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-6271" for this suite. 08/22/23 05:27:30.988
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":291,"skipped":5342,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.376 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:27:23.621
    Aug 22 05:27:23.621: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename limitrange 08/22/23 05:27:23.621
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:27:23.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:27:23.791
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 08/22/23 05:27:23.795
    STEP: Setting up watch 08/22/23 05:27:23.796
    STEP: Submitting a LimitRange 08/22/23 05:27:23.908
    STEP: Verifying LimitRange creation was observed 08/22/23 05:27:23.919
    STEP: Fetching the LimitRange to ensure it has proper values 08/22/23 05:27:23.919
    Aug 22 05:27:23.923: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Aug 22 05:27:23.923: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 08/22/23 05:27:23.923
    STEP: Ensuring Pod has resource requirements applied from LimitRange 08/22/23 05:27:23.93
    Aug 22 05:27:23.933: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Aug 22 05:27:23.933: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 08/22/23 05:27:23.933
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 08/22/23 05:27:23.94
    Aug 22 05:27:23.943: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Aug 22 05:27:23.943: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 08/22/23 05:27:23.943
    STEP: Failing to create a Pod with more than max resources 08/22/23 05:27:23.945
    STEP: Updating a LimitRange 08/22/23 05:27:23.947
    STEP: Verifying LimitRange updating is effective 08/22/23 05:27:23.952
    STEP: Creating a Pod with less than former min resources 08/22/23 05:27:25.956
    STEP: Failing to create a Pod with more than max resources 08/22/23 05:27:25.963
    STEP: Deleting a LimitRange 08/22/23 05:27:25.966
    STEP: Verifying the LimitRange was deleted 08/22/23 05:27:25.971
    Aug 22 05:27:30.975: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 08/22/23 05:27:30.975
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Aug 22 05:27:30.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-6271" for this suite. 08/22/23 05:27:30.988
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:27:31
Aug 22 05:27:31.001: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 08/22/23 05:27:31.001
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:27:31.278
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:27:31.282
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 08/22/23 05:27:31.286
STEP: Creating hostNetwork=false pod 08/22/23 05:27:31.286
Aug 22 05:27:31.441: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-5362" to be "running and ready"
Aug 22 05:27:31.446: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.447099ms
Aug 22 05:27:31.446: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:27:33.450: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009428207s
Aug 22 05:27:33.450: INFO: The phase of Pod test-pod is Running (Ready = true)
Aug 22 05:27:33.450: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 08/22/23 05:27:33.938
Aug 22 05:27:33.945: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-5362" to be "running and ready"
Aug 22 05:27:33.948: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.624061ms
Aug 22 05:27:33.948: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:27:35.952: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007768876s
Aug 22 05:27:35.952: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Aug 22 05:27:35.952: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 08/22/23 05:27:35.955
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 08/22/23 05:27:35.955
Aug 22 05:27:35.955: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:27:35.955: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:27:35.956: INFO: ExecWithOptions: Clientset creation
Aug 22 05:27:35.956: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug 22 05:27:36.032: INFO: Exec stderr: ""
Aug 22 05:27:36.032: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:27:36.033: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:27:36.033: INFO: ExecWithOptions: Clientset creation
Aug 22 05:27:36.033: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug 22 05:27:36.100: INFO: Exec stderr: ""
Aug 22 05:27:36.100: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:27:36.100: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:27:36.101: INFO: ExecWithOptions: Clientset creation
Aug 22 05:27:36.101: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug 22 05:27:36.660: INFO: Exec stderr: ""
Aug 22 05:27:36.660: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:27:36.660: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:27:36.660: INFO: ExecWithOptions: Clientset creation
Aug 22 05:27:36.661: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug 22 05:27:36.895: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 08/22/23 05:27:36.895
Aug 22 05:27:36.895: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:27:36.895: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:27:36.895: INFO: ExecWithOptions: Clientset creation
Aug 22 05:27:36.896: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Aug 22 05:27:36.960: INFO: Exec stderr: ""
Aug 22 05:27:36.960: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:27:36.960: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:27:36.960: INFO: ExecWithOptions: Clientset creation
Aug 22 05:27:36.960: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Aug 22 05:27:37.028: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 08/22/23 05:27:37.028
Aug 22 05:27:37.029: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:27:37.029: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:27:37.029: INFO: ExecWithOptions: Clientset creation
Aug 22 05:27:37.029: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug 22 05:27:37.109: INFO: Exec stderr: ""
Aug 22 05:27:37.109: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:27:37.109: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:27:37.109: INFO: ExecWithOptions: Clientset creation
Aug 22 05:27:37.110: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug 22 05:27:37.184: INFO: Exec stderr: ""
Aug 22 05:27:37.184: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:27:37.184: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:27:37.185: INFO: ExecWithOptions: Clientset creation
Aug 22 05:27:37.185: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug 22 05:27:37.251: INFO: Exec stderr: ""
Aug 22 05:27:37.251: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:27:37.251: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:27:37.252: INFO: ExecWithOptions: Clientset creation
Aug 22 05:27:37.252: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug 22 05:27:37.316: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Aug 22 05:27:37.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5362" for this suite. 08/22/23 05:27:37.326
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":292,"skipped":5346,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.522 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:27:31
    Aug 22 05:27:31.001: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 08/22/23 05:27:31.001
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:27:31.278
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:27:31.282
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 08/22/23 05:27:31.286
    STEP: Creating hostNetwork=false pod 08/22/23 05:27:31.286
    Aug 22 05:27:31.441: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-5362" to be "running and ready"
    Aug 22 05:27:31.446: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.447099ms
    Aug 22 05:27:31.446: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:27:33.450: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009428207s
    Aug 22 05:27:33.450: INFO: The phase of Pod test-pod is Running (Ready = true)
    Aug 22 05:27:33.450: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 08/22/23 05:27:33.938
    Aug 22 05:27:33.945: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-5362" to be "running and ready"
    Aug 22 05:27:33.948: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.624061ms
    Aug 22 05:27:33.948: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:27:35.952: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007768876s
    Aug 22 05:27:35.952: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Aug 22 05:27:35.952: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 08/22/23 05:27:35.955
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 08/22/23 05:27:35.955
    Aug 22 05:27:35.955: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:27:35.955: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:27:35.956: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:27:35.956: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Aug 22 05:27:36.032: INFO: Exec stderr: ""
    Aug 22 05:27:36.032: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:27:36.033: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:27:36.033: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:27:36.033: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Aug 22 05:27:36.100: INFO: Exec stderr: ""
    Aug 22 05:27:36.100: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:27:36.100: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:27:36.101: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:27:36.101: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Aug 22 05:27:36.660: INFO: Exec stderr: ""
    Aug 22 05:27:36.660: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:27:36.660: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:27:36.660: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:27:36.661: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Aug 22 05:27:36.895: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 08/22/23 05:27:36.895
    Aug 22 05:27:36.895: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:27:36.895: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:27:36.895: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:27:36.896: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Aug 22 05:27:36.960: INFO: Exec stderr: ""
    Aug 22 05:27:36.960: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:27:36.960: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:27:36.960: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:27:36.960: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Aug 22 05:27:37.028: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 08/22/23 05:27:37.028
    Aug 22 05:27:37.029: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:27:37.029: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:27:37.029: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:27:37.029: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Aug 22 05:27:37.109: INFO: Exec stderr: ""
    Aug 22 05:27:37.109: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:27:37.109: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:27:37.109: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:27:37.110: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Aug 22 05:27:37.184: INFO: Exec stderr: ""
    Aug 22 05:27:37.184: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:27:37.184: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:27:37.185: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:27:37.185: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Aug 22 05:27:37.251: INFO: Exec stderr: ""
    Aug 22 05:27:37.251: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5362 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:27:37.251: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:27:37.252: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:27:37.252: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5362/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Aug 22 05:27:37.316: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Aug 22 05:27:37.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-5362" for this suite. 08/22/23 05:27:37.326
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:27:37.523
Aug 22 05:27:37.523: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename watch 08/22/23 05:27:37.524
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:27:37.536
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:27:37.539
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 08/22/23 05:27:37.542
STEP: creating a new configmap 08/22/23 05:27:37.543
STEP: modifying the configmap once 08/22/23 05:27:37.549
STEP: closing the watch once it receives two notifications 08/22/23 05:27:37.562
Aug 22 05:27:37.563: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8529  59e32021-ed69-4e85-9df2-f2ba78fe146e 1283160 0 2023-08-22 05:27:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-08-22 05:27:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 22 05:27:37.563: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8529  59e32021-ed69-4e85-9df2-f2ba78fe146e 1283161 0 2023-08-22 05:27:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-08-22 05:27:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 08/22/23 05:27:37.563
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 08/22/23 05:27:37.572
STEP: deleting the configmap 08/22/23 05:27:37.573
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 08/22/23 05:27:37.577
Aug 22 05:27:37.577: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8529  59e32021-ed69-4e85-9df2-f2ba78fe146e 1283162 0 2023-08-22 05:27:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-08-22 05:27:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 22 05:27:37.577: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8529  59e32021-ed69-4e85-9df2-f2ba78fe146e 1283163 0 2023-08-22 05:27:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-08-22 05:27:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 22 05:27:37.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8529" for this suite. 08/22/23 05:27:37.581
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":293,"skipped":5373,"failed":0}
------------------------------
â€¢ [0.063 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:27:37.523
    Aug 22 05:27:37.523: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename watch 08/22/23 05:27:37.524
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:27:37.536
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:27:37.539
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 08/22/23 05:27:37.542
    STEP: creating a new configmap 08/22/23 05:27:37.543
    STEP: modifying the configmap once 08/22/23 05:27:37.549
    STEP: closing the watch once it receives two notifications 08/22/23 05:27:37.562
    Aug 22 05:27:37.563: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8529  59e32021-ed69-4e85-9df2-f2ba78fe146e 1283160 0 2023-08-22 05:27:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-08-22 05:27:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 22 05:27:37.563: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8529  59e32021-ed69-4e85-9df2-f2ba78fe146e 1283161 0 2023-08-22 05:27:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-08-22 05:27:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 08/22/23 05:27:37.563
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 08/22/23 05:27:37.572
    STEP: deleting the configmap 08/22/23 05:27:37.573
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 08/22/23 05:27:37.577
    Aug 22 05:27:37.577: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8529  59e32021-ed69-4e85-9df2-f2ba78fe146e 1283162 0 2023-08-22 05:27:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-08-22 05:27:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 22 05:27:37.577: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8529  59e32021-ed69-4e85-9df2-f2ba78fe146e 1283163 0 2023-08-22 05:27:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-08-22 05:27:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 22 05:27:37.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-8529" for this suite. 08/22/23 05:27:37.581
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:27:37.588
Aug 22 05:27:37.588: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename resourcequota 08/22/23 05:27:37.589
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:27:37.822
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:27:37.824
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 08/22/23 05:27:37.83
STEP: Creating a ResourceQuota 08/22/23 05:27:43.04
STEP: Ensuring resource quota status is calculated 08/22/23 05:27:43.156
STEP: Creating a Pod that fits quota 08/22/23 05:27:45.161
STEP: Ensuring ResourceQuota status captures the pod usage 08/22/23 05:27:45.331
STEP: Not allowing a pod to be created that exceeds remaining quota 08/22/23 05:27:47.336
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 08/22/23 05:27:47.338
STEP: Ensuring a pod cannot update its resource requirements 08/22/23 05:27:47.34
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 08/22/23 05:27:47.344
STEP: Deleting the pod 08/22/23 05:27:49.348
STEP: Ensuring resource quota status released the pod usage 08/22/23 05:27:49.452
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 22 05:27:51.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9939" for this suite. 08/22/23 05:27:51.46
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":294,"skipped":5376,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.940 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:27:37.588
    Aug 22 05:27:37.588: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename resourcequota 08/22/23 05:27:37.589
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:27:37.822
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:27:37.824
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 08/22/23 05:27:37.83
    STEP: Creating a ResourceQuota 08/22/23 05:27:43.04
    STEP: Ensuring resource quota status is calculated 08/22/23 05:27:43.156
    STEP: Creating a Pod that fits quota 08/22/23 05:27:45.161
    STEP: Ensuring ResourceQuota status captures the pod usage 08/22/23 05:27:45.331
    STEP: Not allowing a pod to be created that exceeds remaining quota 08/22/23 05:27:47.336
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 08/22/23 05:27:47.338
    STEP: Ensuring a pod cannot update its resource requirements 08/22/23 05:27:47.34
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 08/22/23 05:27:47.344
    STEP: Deleting the pod 08/22/23 05:27:49.348
    STEP: Ensuring resource quota status released the pod usage 08/22/23 05:27:49.452
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 22 05:27:51.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9939" for this suite. 08/22/23 05:27:51.46
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:27:51.529
Aug 22 05:27:51.529: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 05:27:51.53
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:27:51.606
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:27:51.608
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-4206 08/22/23 05:27:51.612
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 08/22/23 05:27:51.698
STEP: creating service externalsvc in namespace services-4206 08/22/23 05:27:51.698
STEP: creating replication controller externalsvc in namespace services-4206 08/22/23 05:27:51.728
I0822 05:27:51.743683      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4206, replica count: 2
I0822 05:27:54.794807      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0822 05:27:57.795725      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 08/22/23 05:27:57.844
Aug 22 05:27:57.965: INFO: Creating new exec pod
Aug 22 05:27:58.113: INFO: Waiting up to 5m0s for pod "execpodj6dz2" in namespace "services-4206" to be "running"
Aug 22 05:27:58.117: INFO: Pod "execpodj6dz2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.727965ms
Aug 22 05:28:00.122: INFO: Pod "execpodj6dz2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008629622s
Aug 22 05:28:02.275: INFO: Pod "execpodj6dz2": Phase="Running", Reason="", readiness=true. Elapsed: 4.161690641s
Aug 22 05:28:02.275: INFO: Pod "execpodj6dz2" satisfied condition "running"
Aug 22 05:28:02.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-4206 exec execpodj6dz2 -- /bin/sh -x -c nslookup nodeport-service.services-4206.svc.cluster.local'
Aug 22 05:28:02.480: INFO: stderr: "+ nslookup nodeport-service.services-4206.svc.cluster.local\n"
Aug 22 05:28:02.480: INFO: stdout: "Server:\t\t10.254.0.10\nAddress:\t10.254.0.10#53\n\nnodeport-service.services-4206.svc.cluster.local\tcanonical name = externalsvc.services-4206.svc.cluster.local.\nName:\texternalsvc.services-4206.svc.cluster.local\nAddress: 10.254.48.47\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4206, will wait for the garbage collector to delete the pods 08/22/23 05:28:02.48
Aug 22 05:28:02.541: INFO: Deleting ReplicationController externalsvc took: 6.465589ms
Aug 22 05:28:02.941: INFO: Terminating ReplicationController externalsvc pods took: 400.122305ms
Aug 22 05:28:05.160: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 05:28:05.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4206" for this suite. 08/22/23 05:28:05.175
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":295,"skipped":5395,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.832 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:27:51.529
    Aug 22 05:27:51.529: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 05:27:51.53
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:27:51.606
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:27:51.608
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-4206 08/22/23 05:27:51.612
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 08/22/23 05:27:51.698
    STEP: creating service externalsvc in namespace services-4206 08/22/23 05:27:51.698
    STEP: creating replication controller externalsvc in namespace services-4206 08/22/23 05:27:51.728
    I0822 05:27:51.743683      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4206, replica count: 2
    I0822 05:27:54.794807      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0822 05:27:57.795725      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 08/22/23 05:27:57.844
    Aug 22 05:27:57.965: INFO: Creating new exec pod
    Aug 22 05:27:58.113: INFO: Waiting up to 5m0s for pod "execpodj6dz2" in namespace "services-4206" to be "running"
    Aug 22 05:27:58.117: INFO: Pod "execpodj6dz2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.727965ms
    Aug 22 05:28:00.122: INFO: Pod "execpodj6dz2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008629622s
    Aug 22 05:28:02.275: INFO: Pod "execpodj6dz2": Phase="Running", Reason="", readiness=true. Elapsed: 4.161690641s
    Aug 22 05:28:02.275: INFO: Pod "execpodj6dz2" satisfied condition "running"
    Aug 22 05:28:02.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-4206 exec execpodj6dz2 -- /bin/sh -x -c nslookup nodeport-service.services-4206.svc.cluster.local'
    Aug 22 05:28:02.480: INFO: stderr: "+ nslookup nodeport-service.services-4206.svc.cluster.local\n"
    Aug 22 05:28:02.480: INFO: stdout: "Server:\t\t10.254.0.10\nAddress:\t10.254.0.10#53\n\nnodeport-service.services-4206.svc.cluster.local\tcanonical name = externalsvc.services-4206.svc.cluster.local.\nName:\texternalsvc.services-4206.svc.cluster.local\nAddress: 10.254.48.47\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-4206, will wait for the garbage collector to delete the pods 08/22/23 05:28:02.48
    Aug 22 05:28:02.541: INFO: Deleting ReplicationController externalsvc took: 6.465589ms
    Aug 22 05:28:02.941: INFO: Terminating ReplicationController externalsvc pods took: 400.122305ms
    Aug 22 05:28:05.160: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 05:28:05.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4206" for this suite. 08/22/23 05:28:05.175
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:28:05.363
Aug 22 05:28:05.363: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubelet-test 08/22/23 05:28:05.363
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:28:05.379
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:28:05.381
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 08/22/23 05:28:05.394
Aug 22 05:28:05.394: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasesf565201b-e370-4873-b78b-57b0b079e9b9" in namespace "kubelet-test-4476" to be "completed"
Aug 22 05:28:05.398: INFO: Pod "agnhost-host-aliasesf565201b-e370-4873-b78b-57b0b079e9b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.526426ms
Aug 22 05:28:07.404: INFO: Pod "agnhost-host-aliasesf565201b-e370-4873-b78b-57b0b079e9b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009538345s
Aug 22 05:28:09.403: INFO: Pod "agnhost-host-aliasesf565201b-e370-4873-b78b-57b0b079e9b9": Phase="Running", Reason="", readiness=true. Elapsed: 4.008776014s
Aug 22 05:28:11.403: INFO: Pod "agnhost-host-aliasesf565201b-e370-4873-b78b-57b0b079e9b9": Phase="Running", Reason="", readiness=false. Elapsed: 6.008699581s
Aug 22 05:28:13.401: INFO: Pod "agnhost-host-aliasesf565201b-e370-4873-b78b-57b0b079e9b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.007033876s
Aug 22 05:28:13.401: INFO: Pod "agnhost-host-aliasesf565201b-e370-4873-b78b-57b0b079e9b9" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 22 05:28:13.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4476" for this suite. 08/22/23 05:28:13.437
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":296,"skipped":5445,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.080 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:28:05.363
    Aug 22 05:28:05.363: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubelet-test 08/22/23 05:28:05.363
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:28:05.379
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:28:05.381
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 08/22/23 05:28:05.394
    Aug 22 05:28:05.394: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasesf565201b-e370-4873-b78b-57b0b079e9b9" in namespace "kubelet-test-4476" to be "completed"
    Aug 22 05:28:05.398: INFO: Pod "agnhost-host-aliasesf565201b-e370-4873-b78b-57b0b079e9b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.526426ms
    Aug 22 05:28:07.404: INFO: Pod "agnhost-host-aliasesf565201b-e370-4873-b78b-57b0b079e9b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009538345s
    Aug 22 05:28:09.403: INFO: Pod "agnhost-host-aliasesf565201b-e370-4873-b78b-57b0b079e9b9": Phase="Running", Reason="", readiness=true. Elapsed: 4.008776014s
    Aug 22 05:28:11.403: INFO: Pod "agnhost-host-aliasesf565201b-e370-4873-b78b-57b0b079e9b9": Phase="Running", Reason="", readiness=false. Elapsed: 6.008699581s
    Aug 22 05:28:13.401: INFO: Pod "agnhost-host-aliasesf565201b-e370-4873-b78b-57b0b079e9b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.007033876s
    Aug 22 05:28:13.401: INFO: Pod "agnhost-host-aliasesf565201b-e370-4873-b78b-57b0b079e9b9" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 22 05:28:13.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-4476" for this suite. 08/22/23 05:28:13.437
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:28:13.443
Aug 22 05:28:13.443: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename disruption 08/22/23 05:28:13.443
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:28:13.458
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:28:13.462
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 08/22/23 05:28:13.465
STEP: Waiting for the pdb to be processed 08/22/23 05:28:13.471
STEP: updating the pdb 08/22/23 05:28:13.476
STEP: Waiting for the pdb to be processed 08/22/23 05:28:13.485
STEP: patching the pdb 08/22/23 05:28:15.494
STEP: Waiting for the pdb to be processed 08/22/23 05:28:15.528
STEP: Waiting for the pdb to be deleted 08/22/23 05:28:15.537
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 22 05:28:15.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8714" for this suite. 08/22/23 05:28:15.543
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":297,"skipped":5451,"failed":0}
------------------------------
â€¢ [2.117 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:28:13.443
    Aug 22 05:28:13.443: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename disruption 08/22/23 05:28:13.443
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:28:13.458
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:28:13.462
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 08/22/23 05:28:13.465
    STEP: Waiting for the pdb to be processed 08/22/23 05:28:13.471
    STEP: updating the pdb 08/22/23 05:28:13.476
    STEP: Waiting for the pdb to be processed 08/22/23 05:28:13.485
    STEP: patching the pdb 08/22/23 05:28:15.494
    STEP: Waiting for the pdb to be processed 08/22/23 05:28:15.528
    STEP: Waiting for the pdb to be deleted 08/22/23 05:28:15.537
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 22 05:28:15.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-8714" for this suite. 08/22/23 05:28:15.543
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:28:15.56
Aug 22 05:28:15.560: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir-wrapper 08/22/23 05:28:15.56
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:28:15.751
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:28:15.754
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 08/22/23 05:28:15.758
STEP: Creating RC which spawns configmap-volume pods 08/22/23 05:28:15.957
Aug 22 05:28:16.268: INFO: Pod name wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5: Found 2 pods out of 5
Aug 22 05:28:21.316: INFO: Pod name wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5: Found 5 pods out of 5
STEP: Ensuring each pod is running 08/22/23 05:28:21.316
Aug 22 05:28:21.316: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:28:21.326: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.655134ms
Aug 22 05:28:23.331: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014469717s
Aug 22 05:28:25.330: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014124339s
Aug 22 05:28:27.331: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014655916s
Aug 22 05:28:29.333: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016891902s
Aug 22 05:28:31.385: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.068734184s
Aug 22 05:28:33.331: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6": Phase="Running", Reason="", readiness=true. Elapsed: 12.014574935s
Aug 22 05:28:33.331: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6" satisfied condition "running"
Aug 22 05:28:33.331: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-kvt9d" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:28:33.335: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-kvt9d": Phase="Running", Reason="", readiness=true. Elapsed: 3.887202ms
Aug 22 05:28:33.335: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-kvt9d" satisfied condition "running"
Aug 22 05:28:33.335: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-lsttz" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:28:33.338: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-lsttz": Phase="Running", Reason="", readiness=true. Elapsed: 3.460714ms
Aug 22 05:28:33.338: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-lsttz" satisfied condition "running"
Aug 22 05:28:33.338: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-rtqvg" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:28:33.342: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-rtqvg": Phase="Running", Reason="", readiness=true. Elapsed: 3.728175ms
Aug 22 05:28:33.342: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-rtqvg" satisfied condition "running"
Aug 22 05:28:33.342: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-wglnq" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:28:33.345: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-wglnq": Phase="Running", Reason="", readiness=true. Elapsed: 2.789464ms
Aug 22 05:28:33.345: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-wglnq" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5 in namespace emptydir-wrapper-2092, will wait for the garbage collector to delete the pods 08/22/23 05:28:33.345
Aug 22 05:28:33.406: INFO: Deleting ReplicationController wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5 took: 7.460417ms
Aug 22 05:28:33.507: INFO: Terminating ReplicationController wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5 pods took: 100.771709ms
STEP: Creating RC which spawns configmap-volume pods 08/22/23 05:28:37.294
Aug 22 05:28:37.328: INFO: Pod name wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91: Found 1 pods out of 5
Aug 22 05:28:42.338: INFO: Pod name wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91: Found 5 pods out of 5
STEP: Ensuring each pod is running 08/22/23 05:28:42.338
Aug 22 05:28:42.338: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:28:42.342: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.940292ms
Aug 22 05:28:44.451: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.113650852s
Aug 22 05:28:46.347: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009003912s
Aug 22 05:28:48.346: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008289902s
Aug 22 05:28:50.349: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011120612s
Aug 22 05:28:52.349: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9": Phase="Running", Reason="", readiness=true. Elapsed: 10.011202327s
Aug 22 05:28:52.349: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9" satisfied condition "running"
Aug 22 05:28:52.349: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-h8nxg" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:28:52.353: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-h8nxg": Phase="Running", Reason="", readiness=true. Elapsed: 3.516978ms
Aug 22 05:28:52.353: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-h8nxg" satisfied condition "running"
Aug 22 05:28:52.353: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-hwnff" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:28:52.356: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-hwnff": Phase="Pending", Reason="", readiness=false. Elapsed: 3.491982ms
Aug 22 05:28:54.361: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-hwnff": Phase="Running", Reason="", readiness=true. Elapsed: 2.008851427s
Aug 22 05:28:54.361: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-hwnff" satisfied condition "running"
Aug 22 05:28:54.361: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-lzc85" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:28:54.365: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-lzc85": Phase="Running", Reason="", readiness=true. Elapsed: 3.052186ms
Aug 22 05:28:54.365: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-lzc85" satisfied condition "running"
Aug 22 05:28:54.365: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-ttspv" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:28:54.368: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-ttspv": Phase="Running", Reason="", readiness=true. Elapsed: 2.946859ms
Aug 22 05:28:54.368: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-ttspv" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91 in namespace emptydir-wrapper-2092, will wait for the garbage collector to delete the pods 08/22/23 05:28:54.369
Aug 22 05:28:54.432: INFO: Deleting ReplicationController wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91 took: 7.10497ms
Aug 22 05:28:54.633: INFO: Terminating ReplicationController wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91 pods took: 200.820582ms
STEP: Creating RC which spawns configmap-volume pods 08/22/23 05:28:57.738
Aug 22 05:28:57.792: INFO: Pod name wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8: Found 0 pods out of 5
Aug 22 05:29:02.994: INFO: Pod name wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8: Found 5 pods out of 5
STEP: Ensuring each pod is running 08/22/23 05:29:02.994
Aug 22 05:29:02.994: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:29:03.002: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.313111ms
Aug 22 05:29:05.142: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.14764025s
Aug 22 05:29:07.008: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013573525s
Aug 22 05:29:09.008: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013470292s
Aug 22 05:29:11.184: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.189617683s
Aug 22 05:29:13.010: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.016044041s
Aug 22 05:29:15.006: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7": Phase="Running", Reason="", readiness=true. Elapsed: 12.012093549s
Aug 22 05:29:15.006: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7" satisfied condition "running"
Aug 22 05:29:15.006: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-fhqf4" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:29:15.011: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-fhqf4": Phase="Running", Reason="", readiness=true. Elapsed: 4.890776ms
Aug 22 05:29:15.011: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-fhqf4" satisfied condition "running"
Aug 22 05:29:15.011: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-nvv7w" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:29:15.015: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-nvv7w": Phase="Running", Reason="", readiness=true. Elapsed: 3.13956ms
Aug 22 05:29:15.015: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-nvv7w" satisfied condition "running"
Aug 22 05:29:15.015: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-qwj6m" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:29:15.018: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-qwj6m": Phase="Running", Reason="", readiness=true. Elapsed: 3.17704ms
Aug 22 05:29:15.018: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-qwj6m" satisfied condition "running"
Aug 22 05:29:15.018: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-xwkn2" in namespace "emptydir-wrapper-2092" to be "running"
Aug 22 05:29:15.021: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-xwkn2": Phase="Running", Reason="", readiness=true. Elapsed: 2.9156ms
Aug 22 05:29:15.021: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-xwkn2" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8 in namespace emptydir-wrapper-2092, will wait for the garbage collector to delete the pods 08/22/23 05:29:15.021
Aug 22 05:29:15.207: INFO: Deleting ReplicationController wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8 took: 131.993715ms
Aug 22 05:29:15.408: INFO: Terminating ReplicationController wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8 pods took: 201.181398ms
STEP: Cleaning up the configMaps 08/22/23 05:29:19.609
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Aug 22 05:29:20.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2092" for this suite. 08/22/23 05:29:20.039
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":298,"skipped":5452,"failed":0}
------------------------------
â€¢ [SLOW TEST] [64.487 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:28:15.56
    Aug 22 05:28:15.560: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir-wrapper 08/22/23 05:28:15.56
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:28:15.751
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:28:15.754
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 08/22/23 05:28:15.758
    STEP: Creating RC which spawns configmap-volume pods 08/22/23 05:28:15.957
    Aug 22 05:28:16.268: INFO: Pod name wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5: Found 2 pods out of 5
    Aug 22 05:28:21.316: INFO: Pod name wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5: Found 5 pods out of 5
    STEP: Ensuring each pod is running 08/22/23 05:28:21.316
    Aug 22 05:28:21.316: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:28:21.326: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.655134ms
    Aug 22 05:28:23.331: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014469717s
    Aug 22 05:28:25.330: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014124339s
    Aug 22 05:28:27.331: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014655916s
    Aug 22 05:28:29.333: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016891902s
    Aug 22 05:28:31.385: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.068734184s
    Aug 22 05:28:33.331: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6": Phase="Running", Reason="", readiness=true. Elapsed: 12.014574935s
    Aug 22 05:28:33.331: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-8xkv6" satisfied condition "running"
    Aug 22 05:28:33.331: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-kvt9d" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:28:33.335: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-kvt9d": Phase="Running", Reason="", readiness=true. Elapsed: 3.887202ms
    Aug 22 05:28:33.335: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-kvt9d" satisfied condition "running"
    Aug 22 05:28:33.335: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-lsttz" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:28:33.338: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-lsttz": Phase="Running", Reason="", readiness=true. Elapsed: 3.460714ms
    Aug 22 05:28:33.338: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-lsttz" satisfied condition "running"
    Aug 22 05:28:33.338: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-rtqvg" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:28:33.342: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-rtqvg": Phase="Running", Reason="", readiness=true. Elapsed: 3.728175ms
    Aug 22 05:28:33.342: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-rtqvg" satisfied condition "running"
    Aug 22 05:28:33.342: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-wglnq" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:28:33.345: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-wglnq": Phase="Running", Reason="", readiness=true. Elapsed: 2.789464ms
    Aug 22 05:28:33.345: INFO: Pod "wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5-wglnq" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5 in namespace emptydir-wrapper-2092, will wait for the garbage collector to delete the pods 08/22/23 05:28:33.345
    Aug 22 05:28:33.406: INFO: Deleting ReplicationController wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5 took: 7.460417ms
    Aug 22 05:28:33.507: INFO: Terminating ReplicationController wrapped-volume-race-0df38ccc-69f2-408c-b259-5f84b4cb94a5 pods took: 100.771709ms
    STEP: Creating RC which spawns configmap-volume pods 08/22/23 05:28:37.294
    Aug 22 05:28:37.328: INFO: Pod name wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91: Found 1 pods out of 5
    Aug 22 05:28:42.338: INFO: Pod name wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91: Found 5 pods out of 5
    STEP: Ensuring each pod is running 08/22/23 05:28:42.338
    Aug 22 05:28:42.338: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:28:42.342: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.940292ms
    Aug 22 05:28:44.451: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.113650852s
    Aug 22 05:28:46.347: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009003912s
    Aug 22 05:28:48.346: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008289902s
    Aug 22 05:28:50.349: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011120612s
    Aug 22 05:28:52.349: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9": Phase="Running", Reason="", readiness=true. Elapsed: 10.011202327s
    Aug 22 05:28:52.349: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-c58m9" satisfied condition "running"
    Aug 22 05:28:52.349: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-h8nxg" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:28:52.353: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-h8nxg": Phase="Running", Reason="", readiness=true. Elapsed: 3.516978ms
    Aug 22 05:28:52.353: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-h8nxg" satisfied condition "running"
    Aug 22 05:28:52.353: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-hwnff" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:28:52.356: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-hwnff": Phase="Pending", Reason="", readiness=false. Elapsed: 3.491982ms
    Aug 22 05:28:54.361: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-hwnff": Phase="Running", Reason="", readiness=true. Elapsed: 2.008851427s
    Aug 22 05:28:54.361: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-hwnff" satisfied condition "running"
    Aug 22 05:28:54.361: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-lzc85" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:28:54.365: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-lzc85": Phase="Running", Reason="", readiness=true. Elapsed: 3.052186ms
    Aug 22 05:28:54.365: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-lzc85" satisfied condition "running"
    Aug 22 05:28:54.365: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-ttspv" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:28:54.368: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-ttspv": Phase="Running", Reason="", readiness=true. Elapsed: 2.946859ms
    Aug 22 05:28:54.368: INFO: Pod "wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91-ttspv" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91 in namespace emptydir-wrapper-2092, will wait for the garbage collector to delete the pods 08/22/23 05:28:54.369
    Aug 22 05:28:54.432: INFO: Deleting ReplicationController wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91 took: 7.10497ms
    Aug 22 05:28:54.633: INFO: Terminating ReplicationController wrapped-volume-race-02b74aa3-8494-4fc3-b21b-61378ff7fb91 pods took: 200.820582ms
    STEP: Creating RC which spawns configmap-volume pods 08/22/23 05:28:57.738
    Aug 22 05:28:57.792: INFO: Pod name wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8: Found 0 pods out of 5
    Aug 22 05:29:02.994: INFO: Pod name wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8: Found 5 pods out of 5
    STEP: Ensuring each pod is running 08/22/23 05:29:02.994
    Aug 22 05:29:02.994: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:29:03.002: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.313111ms
    Aug 22 05:29:05.142: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.14764025s
    Aug 22 05:29:07.008: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013573525s
    Aug 22 05:29:09.008: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013470292s
    Aug 22 05:29:11.184: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.189617683s
    Aug 22 05:29:13.010: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.016044041s
    Aug 22 05:29:15.006: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7": Phase="Running", Reason="", readiness=true. Elapsed: 12.012093549s
    Aug 22 05:29:15.006: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-9wll7" satisfied condition "running"
    Aug 22 05:29:15.006: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-fhqf4" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:29:15.011: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-fhqf4": Phase="Running", Reason="", readiness=true. Elapsed: 4.890776ms
    Aug 22 05:29:15.011: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-fhqf4" satisfied condition "running"
    Aug 22 05:29:15.011: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-nvv7w" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:29:15.015: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-nvv7w": Phase="Running", Reason="", readiness=true. Elapsed: 3.13956ms
    Aug 22 05:29:15.015: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-nvv7w" satisfied condition "running"
    Aug 22 05:29:15.015: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-qwj6m" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:29:15.018: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-qwj6m": Phase="Running", Reason="", readiness=true. Elapsed: 3.17704ms
    Aug 22 05:29:15.018: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-qwj6m" satisfied condition "running"
    Aug 22 05:29:15.018: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-xwkn2" in namespace "emptydir-wrapper-2092" to be "running"
    Aug 22 05:29:15.021: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-xwkn2": Phase="Running", Reason="", readiness=true. Elapsed: 2.9156ms
    Aug 22 05:29:15.021: INFO: Pod "wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8-xwkn2" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8 in namespace emptydir-wrapper-2092, will wait for the garbage collector to delete the pods 08/22/23 05:29:15.021
    Aug 22 05:29:15.207: INFO: Deleting ReplicationController wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8 took: 131.993715ms
    Aug 22 05:29:15.408: INFO: Terminating ReplicationController wrapped-volume-race-c539e962-1afc-427b-9400-20f72f11e1d8 pods took: 201.181398ms
    STEP: Cleaning up the configMaps 08/22/23 05:29:19.609
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Aug 22 05:29:20.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-2092" for this suite. 08/22/23 05:29:20.039
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:29:20.047
Aug 22 05:29:20.047: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename ingress 08/22/23 05:29:20.048
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:20.111
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:20.114
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 08/22/23 05:29:20.117
STEP: getting /apis/networking.k8s.io 08/22/23 05:29:20.12
STEP: getting /apis/networking.k8s.iov1 08/22/23 05:29:20.122
STEP: creating 08/22/23 05:29:20.124
STEP: getting 08/22/23 05:29:20.14
STEP: listing 08/22/23 05:29:20.143
STEP: watching 08/22/23 05:29:20.146
Aug 22 05:29:20.146: INFO: starting watch
STEP: cluster-wide listing 08/22/23 05:29:20.148
STEP: cluster-wide watching 08/22/23 05:29:20.15
Aug 22 05:29:20.151: INFO: starting watch
STEP: patching 08/22/23 05:29:20.152
STEP: updating 08/22/23 05:29:20.16
Aug 22 05:29:20.168: INFO: waiting for watch events with expected annotations
Aug 22 05:29:20.168: INFO: saw patched and updated annotations
STEP: patching /status 08/22/23 05:29:20.168
STEP: updating /status 08/22/23 05:29:20.309
STEP: get /status 08/22/23 05:29:20.323
STEP: deleting 08/22/23 05:29:20.327
STEP: deleting a collection 08/22/23 05:29:20.341
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Aug 22 05:29:20.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-860" for this suite. 08/22/23 05:29:20.361
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":299,"skipped":5463,"failed":0}
------------------------------
â€¢ [0.323 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:29:20.047
    Aug 22 05:29:20.047: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename ingress 08/22/23 05:29:20.048
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:20.111
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:20.114
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 08/22/23 05:29:20.117
    STEP: getting /apis/networking.k8s.io 08/22/23 05:29:20.12
    STEP: getting /apis/networking.k8s.iov1 08/22/23 05:29:20.122
    STEP: creating 08/22/23 05:29:20.124
    STEP: getting 08/22/23 05:29:20.14
    STEP: listing 08/22/23 05:29:20.143
    STEP: watching 08/22/23 05:29:20.146
    Aug 22 05:29:20.146: INFO: starting watch
    STEP: cluster-wide listing 08/22/23 05:29:20.148
    STEP: cluster-wide watching 08/22/23 05:29:20.15
    Aug 22 05:29:20.151: INFO: starting watch
    STEP: patching 08/22/23 05:29:20.152
    STEP: updating 08/22/23 05:29:20.16
    Aug 22 05:29:20.168: INFO: waiting for watch events with expected annotations
    Aug 22 05:29:20.168: INFO: saw patched and updated annotations
    STEP: patching /status 08/22/23 05:29:20.168
    STEP: updating /status 08/22/23 05:29:20.309
    STEP: get /status 08/22/23 05:29:20.323
    STEP: deleting 08/22/23 05:29:20.327
    STEP: deleting a collection 08/22/23 05:29:20.341
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Aug 22 05:29:20.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-860" for this suite. 08/22/23 05:29:20.361
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:29:20.372
Aug 22 05:29:20.372: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 05:29:20.373
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:20.389
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:20.393
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 08/22/23 05:29:20.398
Aug 22 05:29:20.411: INFO: Waiting up to 5m0s for pod "downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435" in namespace "projected-5156" to be "Succeeded or Failed"
Aug 22 05:29:20.416: INFO: Pod "downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435": Phase="Pending", Reason="", readiness=false. Elapsed: 5.093765ms
Aug 22 05:29:22.421: INFO: Pod "downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009402349s
Aug 22 05:29:24.420: INFO: Pod "downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008859631s
Aug 22 05:29:26.423: INFO: Pod "downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012028195s
STEP: Saw pod success 08/22/23 05:29:26.423
Aug 22 05:29:26.424: INFO: Pod "downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435" satisfied condition "Succeeded or Failed"
Aug 22 05:29:26.430: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435 container client-container: <nil>
STEP: delete the pod 08/22/23 05:29:26.445
Aug 22 05:29:26.473: INFO: Waiting for pod downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435 to disappear
Aug 22 05:29:26.480: INFO: Pod downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 22 05:29:26.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5156" for this suite. 08/22/23 05:29:26.486
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":300,"skipped":5491,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.132 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:29:20.372
    Aug 22 05:29:20.372: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 05:29:20.373
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:20.389
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:20.393
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 08/22/23 05:29:20.398
    Aug 22 05:29:20.411: INFO: Waiting up to 5m0s for pod "downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435" in namespace "projected-5156" to be "Succeeded or Failed"
    Aug 22 05:29:20.416: INFO: Pod "downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435": Phase="Pending", Reason="", readiness=false. Elapsed: 5.093765ms
    Aug 22 05:29:22.421: INFO: Pod "downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009402349s
    Aug 22 05:29:24.420: INFO: Pod "downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008859631s
    Aug 22 05:29:26.423: INFO: Pod "downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012028195s
    STEP: Saw pod success 08/22/23 05:29:26.423
    Aug 22 05:29:26.424: INFO: Pod "downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435" satisfied condition "Succeeded or Failed"
    Aug 22 05:29:26.430: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435 container client-container: <nil>
    STEP: delete the pod 08/22/23 05:29:26.445
    Aug 22 05:29:26.473: INFO: Waiting for pod downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435 to disappear
    Aug 22 05:29:26.480: INFO: Pod downwardapi-volume-678da2ef-3dcc-409d-b722-4dac7f99f435 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 22 05:29:26.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5156" for this suite. 08/22/23 05:29:26.486
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:29:26.508
Aug 22 05:29:26.508: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename ingressclass 08/22/23 05:29:26.509
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:26.532
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:26.538
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 08/22/23 05:29:26.541
STEP: getting /apis/networking.k8s.io 08/22/23 05:29:26.543
STEP: getting /apis/networking.k8s.iov1 08/22/23 05:29:26.544
STEP: creating 08/22/23 05:29:26.545
STEP: getting 08/22/23 05:29:26.561
STEP: listing 08/22/23 05:29:26.564
STEP: watching 08/22/23 05:29:26.567
Aug 22 05:29:26.567: INFO: starting watch
STEP: patching 08/22/23 05:29:26.568
STEP: updating 08/22/23 05:29:26.573
Aug 22 05:29:26.577: INFO: waiting for watch events with expected annotations
Aug 22 05:29:26.577: INFO: saw patched and updated annotations
STEP: deleting 08/22/23 05:29:26.577
STEP: deleting a collection 08/22/23 05:29:26.585
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Aug 22 05:29:26.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-501" for this suite. 08/22/23 05:29:26.599
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":301,"skipped":5556,"failed":0}
------------------------------
â€¢ [0.096 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:29:26.508
    Aug 22 05:29:26.508: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename ingressclass 08/22/23 05:29:26.509
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:26.532
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:26.538
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 08/22/23 05:29:26.541
    STEP: getting /apis/networking.k8s.io 08/22/23 05:29:26.543
    STEP: getting /apis/networking.k8s.iov1 08/22/23 05:29:26.544
    STEP: creating 08/22/23 05:29:26.545
    STEP: getting 08/22/23 05:29:26.561
    STEP: listing 08/22/23 05:29:26.564
    STEP: watching 08/22/23 05:29:26.567
    Aug 22 05:29:26.567: INFO: starting watch
    STEP: patching 08/22/23 05:29:26.568
    STEP: updating 08/22/23 05:29:26.573
    Aug 22 05:29:26.577: INFO: waiting for watch events with expected annotations
    Aug 22 05:29:26.577: INFO: saw patched and updated annotations
    STEP: deleting 08/22/23 05:29:26.577
    STEP: deleting a collection 08/22/23 05:29:26.585
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Aug 22 05:29:26.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-501" for this suite. 08/22/23 05:29:26.599
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:29:26.606
Aug 22 05:29:26.606: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pods 08/22/23 05:29:26.607
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:26.621
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:26.623
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 08/22/23 05:29:26.627
STEP: submitting the pod to kubernetes 08/22/23 05:29:26.627
STEP: verifying QOS class is set on the pod 08/22/23 05:29:26.634
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Aug 22 05:29:26.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8840" for this suite. 08/22/23 05:29:26.677
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":302,"skipped":5570,"failed":0}
------------------------------
â€¢ [0.081 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:29:26.606
    Aug 22 05:29:26.606: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pods 08/22/23 05:29:26.607
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:26.621
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:26.623
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 08/22/23 05:29:26.627
    STEP: submitting the pod to kubernetes 08/22/23 05:29:26.627
    STEP: verifying QOS class is set on the pod 08/22/23 05:29:26.634
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Aug 22 05:29:26.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8840" for this suite. 08/22/23 05:29:26.677
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:29:26.69
Aug 22 05:29:26.690: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 05:29:26.691
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:26.707
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:26.709
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Aug 22 05:29:26.712: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/22/23 05:29:29.264
Aug 22 05:29:29.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-1687 --namespace=crd-publish-openapi-1687 create -f -'
Aug 22 05:29:29.898: INFO: stderr: ""
Aug 22 05:29:29.898: INFO: stdout: "e2e-test-crd-publish-openapi-9358-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Aug 22 05:29:29.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-1687 --namespace=crd-publish-openapi-1687 delete e2e-test-crd-publish-openapi-9358-crds test-cr'
Aug 22 05:29:30.002: INFO: stderr: ""
Aug 22 05:29:30.002: INFO: stdout: "e2e-test-crd-publish-openapi-9358-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Aug 22 05:29:30.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-1687 --namespace=crd-publish-openapi-1687 apply -f -'
Aug 22 05:29:30.528: INFO: stderr: ""
Aug 22 05:29:30.528: INFO: stdout: "e2e-test-crd-publish-openapi-9358-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Aug 22 05:29:30.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-1687 --namespace=crd-publish-openapi-1687 delete e2e-test-crd-publish-openapi-9358-crds test-cr'
Aug 22 05:29:30.613: INFO: stderr: ""
Aug 22 05:29:30.613: INFO: stdout: "e2e-test-crd-publish-openapi-9358-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 08/22/23 05:29:30.613
Aug 22 05:29:30.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-1687 explain e2e-test-crd-publish-openapi-9358-crds'
Aug 22 05:29:30.782: INFO: stderr: ""
Aug 22 05:29:30.782: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9358-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:29:33.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1687" for this suite. 08/22/23 05:29:33.283
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":303,"skipped":5608,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.678 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:29:26.69
    Aug 22 05:29:26.690: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 05:29:26.691
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:26.707
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:26.709
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Aug 22 05:29:26.712: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/22/23 05:29:29.264
    Aug 22 05:29:29.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-1687 --namespace=crd-publish-openapi-1687 create -f -'
    Aug 22 05:29:29.898: INFO: stderr: ""
    Aug 22 05:29:29.898: INFO: stdout: "e2e-test-crd-publish-openapi-9358-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Aug 22 05:29:29.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-1687 --namespace=crd-publish-openapi-1687 delete e2e-test-crd-publish-openapi-9358-crds test-cr'
    Aug 22 05:29:30.002: INFO: stderr: ""
    Aug 22 05:29:30.002: INFO: stdout: "e2e-test-crd-publish-openapi-9358-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Aug 22 05:29:30.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-1687 --namespace=crd-publish-openapi-1687 apply -f -'
    Aug 22 05:29:30.528: INFO: stderr: ""
    Aug 22 05:29:30.528: INFO: stdout: "e2e-test-crd-publish-openapi-9358-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Aug 22 05:29:30.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-1687 --namespace=crd-publish-openapi-1687 delete e2e-test-crd-publish-openapi-9358-crds test-cr'
    Aug 22 05:29:30.613: INFO: stderr: ""
    Aug 22 05:29:30.613: INFO: stdout: "e2e-test-crd-publish-openapi-9358-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 08/22/23 05:29:30.613
    Aug 22 05:29:30.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-1687 explain e2e-test-crd-publish-openapi-9358-crds'
    Aug 22 05:29:30.782: INFO: stderr: ""
    Aug 22 05:29:30.782: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9358-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:29:33.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1687" for this suite. 08/22/23 05:29:33.283
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:29:33.37
Aug 22 05:29:33.370: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pods 08/22/23 05:29:33.371
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:33.388
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:33.391
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 08/22/23 05:29:33.395
STEP: submitting the pod to kubernetes 08/22/23 05:29:33.395
Aug 22 05:29:33.401: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361" in namespace "pods-8368" to be "running and ready"
Aug 22 05:29:33.406: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361": Phase="Pending", Reason="", readiness=false. Elapsed: 4.489182ms
Aug 22 05:29:33.406: INFO: The phase of Pod pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:29:35.411: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010092504s
Aug 22 05:29:35.411: INFO: The phase of Pod pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:29:37.409: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361": Phase="Running", Reason="", readiness=true. Elapsed: 4.008085269s
Aug 22 05:29:37.409: INFO: The phase of Pod pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361 is Running (Ready = true)
Aug 22 05:29:37.409: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 08/22/23 05:29:37.411
STEP: updating the pod 08/22/23 05:29:37.418
Aug 22 05:29:37.931: INFO: Successfully updated pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361"
Aug 22 05:29:37.931: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361" in namespace "pods-8368" to be "terminated with reason DeadlineExceeded"
Aug 22 05:29:37.933: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361": Phase="Running", Reason="", readiness=true. Elapsed: 2.069272ms
Aug 22 05:29:39.938: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361": Phase="Running", Reason="", readiness=false. Elapsed: 2.006825453s
Aug 22 05:29:41.938: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007142201s
Aug 22 05:29:41.938: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 22 05:29:41.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8368" for this suite. 08/22/23 05:29:41.942
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":304,"skipped":5654,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.579 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:29:33.37
    Aug 22 05:29:33.370: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pods 08/22/23 05:29:33.371
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:33.388
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:33.391
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 08/22/23 05:29:33.395
    STEP: submitting the pod to kubernetes 08/22/23 05:29:33.395
    Aug 22 05:29:33.401: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361" in namespace "pods-8368" to be "running and ready"
    Aug 22 05:29:33.406: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361": Phase="Pending", Reason="", readiness=false. Elapsed: 4.489182ms
    Aug 22 05:29:33.406: INFO: The phase of Pod pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:29:35.411: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010092504s
    Aug 22 05:29:35.411: INFO: The phase of Pod pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:29:37.409: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361": Phase="Running", Reason="", readiness=true. Elapsed: 4.008085269s
    Aug 22 05:29:37.409: INFO: The phase of Pod pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361 is Running (Ready = true)
    Aug 22 05:29:37.409: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 08/22/23 05:29:37.411
    STEP: updating the pod 08/22/23 05:29:37.418
    Aug 22 05:29:37.931: INFO: Successfully updated pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361"
    Aug 22 05:29:37.931: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361" in namespace "pods-8368" to be "terminated with reason DeadlineExceeded"
    Aug 22 05:29:37.933: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361": Phase="Running", Reason="", readiness=true. Elapsed: 2.069272ms
    Aug 22 05:29:39.938: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361": Phase="Running", Reason="", readiness=false. Elapsed: 2.006825453s
    Aug 22 05:29:41.938: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007142201s
    Aug 22 05:29:41.938: INFO: Pod "pod-update-activedeadlineseconds-635e2eba-cedd-4631-bfbc-9f8eadb67361" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 22 05:29:41.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8368" for this suite. 08/22/23 05:29:41.942
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:29:41.951
Aug 22 05:29:41.951: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 05:29:41.952
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:41.964
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:41.967
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-e8b83c35-3288-4b37-a633-3a48795f9e68 08/22/23 05:29:41.972
STEP: Creating a pod to test consume configMaps 08/22/23 05:29:41.976
Aug 22 05:29:41.991: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35" in namespace "projected-3111" to be "Succeeded or Failed"
Aug 22 05:29:41.994: INFO: Pod "pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35": Phase="Pending", Reason="", readiness=false. Elapsed: 3.15043ms
Aug 22 05:29:43.998: INFO: Pod "pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007222922s
Aug 22 05:29:45.998: INFO: Pod "pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007442513s
Aug 22 05:29:47.998: INFO: Pod "pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006533619s
STEP: Saw pod success 08/22/23 05:29:47.998
Aug 22 05:29:47.998: INFO: Pod "pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35" satisfied condition "Succeeded or Failed"
Aug 22 05:29:48.000: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35 container agnhost-container: <nil>
STEP: delete the pod 08/22/23 05:29:48.027
Aug 22 05:29:48.127: INFO: Waiting for pod pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35 to disappear
Aug 22 05:29:48.130: INFO: Pod pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 22 05:29:48.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3111" for this suite. 08/22/23 05:29:48.135
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":305,"skipped":5674,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.192 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:29:41.951
    Aug 22 05:29:41.951: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 05:29:41.952
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:41.964
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:41.967
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-e8b83c35-3288-4b37-a633-3a48795f9e68 08/22/23 05:29:41.972
    STEP: Creating a pod to test consume configMaps 08/22/23 05:29:41.976
    Aug 22 05:29:41.991: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35" in namespace "projected-3111" to be "Succeeded or Failed"
    Aug 22 05:29:41.994: INFO: Pod "pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35": Phase="Pending", Reason="", readiness=false. Elapsed: 3.15043ms
    Aug 22 05:29:43.998: INFO: Pod "pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007222922s
    Aug 22 05:29:45.998: INFO: Pod "pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007442513s
    Aug 22 05:29:47.998: INFO: Pod "pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006533619s
    STEP: Saw pod success 08/22/23 05:29:47.998
    Aug 22 05:29:47.998: INFO: Pod "pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35" satisfied condition "Succeeded or Failed"
    Aug 22 05:29:48.000: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-0 pod pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35 container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 05:29:48.027
    Aug 22 05:29:48.127: INFO: Waiting for pod pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35 to disappear
    Aug 22 05:29:48.130: INFO: Pod pod-projected-configmaps-2b67f2fe-7440-4f72-8a38-19c66c5d1f35 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 22 05:29:48.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3111" for this suite. 08/22/23 05:29:48.135
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:29:48.148
Aug 22 05:29:48.148: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename events 08/22/23 05:29:48.149
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:48.163
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:48.167
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 08/22/23 05:29:48.17
STEP: listing all events in all namespaces 08/22/23 05:29:48.175
STEP: patching the test event 08/22/23 05:29:48.178
STEP: fetching the test event 08/22/23 05:29:48.184
STEP: updating the test event 08/22/23 05:29:48.186
STEP: getting the test event 08/22/23 05:29:48.192
STEP: deleting the test event 08/22/23 05:29:48.194
STEP: listing all events in all namespaces 08/22/23 05:29:48.199
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Aug 22 05:29:48.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3509" for this suite. 08/22/23 05:29:48.204
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":306,"skipped":5705,"failed":0}
------------------------------
â€¢ [0.062 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:29:48.148
    Aug 22 05:29:48.148: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename events 08/22/23 05:29:48.149
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:48.163
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:48.167
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 08/22/23 05:29:48.17
    STEP: listing all events in all namespaces 08/22/23 05:29:48.175
    STEP: patching the test event 08/22/23 05:29:48.178
    STEP: fetching the test event 08/22/23 05:29:48.184
    STEP: updating the test event 08/22/23 05:29:48.186
    STEP: getting the test event 08/22/23 05:29:48.192
    STEP: deleting the test event 08/22/23 05:29:48.194
    STEP: listing all events in all namespaces 08/22/23 05:29:48.199
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Aug 22 05:29:48.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-3509" for this suite. 08/22/23 05:29:48.204
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:29:48.213
Aug 22 05:29:48.213: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename replication-controller 08/22/23 05:29:48.214
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:48.229
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:48.232
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Aug 22 05:29:48.235: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 08/22/23 05:29:48.246
STEP: Checking rc "condition-test" has the desired failure condition set 08/22/23 05:29:48.251
STEP: Scaling down rc "condition-test" to satisfy pod quota 08/22/23 05:29:49.261
Aug 22 05:29:49.279: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 08/22/23 05:29:49.279
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 22 05:29:50.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1045" for this suite. 08/22/23 05:29:50.354
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":307,"skipped":5743,"failed":0}
------------------------------
â€¢ [2.150 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:29:48.213
    Aug 22 05:29:48.213: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename replication-controller 08/22/23 05:29:48.214
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:48.229
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:48.232
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Aug 22 05:29:48.235: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 08/22/23 05:29:48.246
    STEP: Checking rc "condition-test" has the desired failure condition set 08/22/23 05:29:48.251
    STEP: Scaling down rc "condition-test" to satisfy pod quota 08/22/23 05:29:49.261
    Aug 22 05:29:49.279: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 08/22/23 05:29:49.279
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 22 05:29:50.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1045" for this suite. 08/22/23 05:29:50.354
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:29:50.363
Aug 22 05:29:50.363: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename daemonsets 08/22/23 05:29:50.364
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:50.398
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:50.401
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Aug 22 05:29:50.638: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 08/22/23 05:29:50.717
Aug 22 05:29:50.721: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:50.721: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:50.721: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:50.778: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 05:29:50.778: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 05:29:51.783: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:51.784: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:51.784: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:51.786: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 05:29:51.786: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 05:29:52.786: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:52.786: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:52.786: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:52.789: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 05:29:52.789: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 05:29:53.784: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:53.784: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:53.784: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:53.788: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 22 05:29:53.788: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
Aug 22 05:29:54.783: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:54.784: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:54.784: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:54.786: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 22 05:29:54.786: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 08/22/23 05:29:54.795
STEP: Check that daemon pods images are updated. 08/22/23 05:29:54.808
Aug 22 05:29:54.810: INFO: Wrong image for pod: daemon-set-6kc5g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:29:54.810: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:29:54.810: INFO: Wrong image for pod: daemon-set-zfmlx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:29:54.814: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:54.814: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:54.814: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:55.820: INFO: Wrong image for pod: daemon-set-6kc5g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:29:55.820: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:29:55.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:55.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:55.824: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:56.821: INFO: Wrong image for pod: daemon-set-6kc5g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:29:56.821: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:29:56.825: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:56.825: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:56.825: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:57.819: INFO: Wrong image for pod: daemon-set-6kc5g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:29:57.819: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:29:57.819: INFO: Pod daemon-set-vkdn5 is not available
Aug 22 05:29:57.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:57.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:57.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:58.819: INFO: Wrong image for pod: daemon-set-6kc5g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:29:58.819: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:29:58.819: INFO: Pod daemon-set-vkdn5 is not available
Aug 22 05:29:58.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:58.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:58.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:59.818: INFO: Wrong image for pod: daemon-set-6kc5g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:29:59.818: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:29:59.818: INFO: Pod daemon-set-vkdn5 is not available
Aug 22 05:29:59.821: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:59.821: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:29:59.821: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:00.838: INFO: Wrong image for pod: daemon-set-6kc5g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:30:00.838: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:30:00.844: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:00.844: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:00.844: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:01.819: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:30:01.819: INFO: Pod daemon-set-zpktk is not available
Aug 22 05:30:01.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:01.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:01.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:02.818: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:30:02.818: INFO: Pod daemon-set-zpktk is not available
Aug 22 05:30:02.821: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:02.821: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:02.821: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:03.818: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:30:03.818: INFO: Pod daemon-set-zpktk is not available
Aug 22 05:30:03.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:03.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:03.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:04.819: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 22 05:30:04.819: INFO: Pod daemon-set-zpktk is not available
Aug 22 05:30:04.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:04.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:04.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:05.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:05.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:05.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:06.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:06.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:06.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:07.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:07.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:07.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:08.819: INFO: Pod daemon-set-pjcjl is not available
Aug 22 05:30:08.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:08.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:08.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster. 08/22/23 05:30:08.822
Aug 22 05:30:08.826: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:08.826: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:08.826: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:08.828: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 05:30:08.828: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 05:30:09.834: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:09.834: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:09.835: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:09.837: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 05:30:09.837: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 05:30:10.835: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:10.835: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:10.835: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:10.838: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 22 05:30:10.838: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
Aug 22 05:30:11.835: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:11.835: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:11.835: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 22 05:30:11.838: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 22 05:30:11.838: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/22/23 05:30:11.848
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4943, will wait for the garbage collector to delete the pods 08/22/23 05:30:11.848
Aug 22 05:30:11.905: INFO: Deleting DaemonSet.extensions daemon-set took: 5.259317ms
Aug 22 05:30:12.006: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.152316ms
Aug 22 05:30:14.310: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 22 05:30:14.310: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 22 05:30:14.312: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1285047"},"items":null}

Aug 22 05:30:14.315: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1285047"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 22 05:30:14.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4943" for this suite. 08/22/23 05:30:14.327
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":308,"skipped":5743,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.034 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:29:50.363
    Aug 22 05:29:50.363: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename daemonsets 08/22/23 05:29:50.364
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:29:50.398
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:29:50.401
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Aug 22 05:29:50.638: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 08/22/23 05:29:50.717
    Aug 22 05:29:50.721: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:50.721: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:50.721: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:50.778: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 05:29:50.778: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 05:29:51.783: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:51.784: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:51.784: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:51.786: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 05:29:51.786: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 05:29:52.786: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:52.786: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:52.786: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:52.789: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 05:29:52.789: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 05:29:53.784: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:53.784: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:53.784: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:53.788: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 22 05:29:53.788: INFO: Node jake-melb-gmyyva4zrlsz-node-1 is running 0 daemon pod, expected 1
    Aug 22 05:29:54.783: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:54.784: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:54.784: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:54.786: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 22 05:29:54.786: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 08/22/23 05:29:54.795
    STEP: Check that daemon pods images are updated. 08/22/23 05:29:54.808
    Aug 22 05:29:54.810: INFO: Wrong image for pod: daemon-set-6kc5g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:29:54.810: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:29:54.810: INFO: Wrong image for pod: daemon-set-zfmlx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:29:54.814: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:54.814: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:54.814: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:55.820: INFO: Wrong image for pod: daemon-set-6kc5g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:29:55.820: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:29:55.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:55.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:55.824: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:56.821: INFO: Wrong image for pod: daemon-set-6kc5g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:29:56.821: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:29:56.825: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:56.825: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:56.825: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:57.819: INFO: Wrong image for pod: daemon-set-6kc5g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:29:57.819: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:29:57.819: INFO: Pod daemon-set-vkdn5 is not available
    Aug 22 05:29:57.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:57.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:57.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:58.819: INFO: Wrong image for pod: daemon-set-6kc5g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:29:58.819: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:29:58.819: INFO: Pod daemon-set-vkdn5 is not available
    Aug 22 05:29:58.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:58.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:58.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:59.818: INFO: Wrong image for pod: daemon-set-6kc5g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:29:59.818: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:29:59.818: INFO: Pod daemon-set-vkdn5 is not available
    Aug 22 05:29:59.821: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:59.821: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:29:59.821: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:00.838: INFO: Wrong image for pod: daemon-set-6kc5g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:30:00.838: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:30:00.844: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:00.844: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:00.844: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:01.819: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:30:01.819: INFO: Pod daemon-set-zpktk is not available
    Aug 22 05:30:01.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:01.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:01.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:02.818: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:30:02.818: INFO: Pod daemon-set-zpktk is not available
    Aug 22 05:30:02.821: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:02.821: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:02.821: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:03.818: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:30:03.818: INFO: Pod daemon-set-zpktk is not available
    Aug 22 05:30:03.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:03.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:03.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:04.819: INFO: Wrong image for pod: daemon-set-6nqhj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 22 05:30:04.819: INFO: Pod daemon-set-zpktk is not available
    Aug 22 05:30:04.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:04.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:04.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:05.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:05.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:05.823: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:06.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:06.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:06.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:07.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:07.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:07.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:08.819: INFO: Pod daemon-set-pjcjl is not available
    Aug 22 05:30:08.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:08.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:08.822: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    STEP: Check that daemon pods are still running on every node of the cluster. 08/22/23 05:30:08.822
    Aug 22 05:30:08.826: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:08.826: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:08.826: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:08.828: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 05:30:08.828: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 05:30:09.834: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:09.834: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:09.835: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:09.837: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 05:30:09.837: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 05:30:10.835: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:10.835: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:10.835: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:10.838: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 22 05:30:10.838: INFO: Node jake-melb-gmyyva4zrlsz-node-0 is running 0 daemon pod, expected 1
    Aug 22 05:30:11.835: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:11.835: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:11.835: INFO: DaemonSet pods can't tolerate node jake-melb-gmyyva4zrlsz-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 22 05:30:11.838: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Aug 22 05:30:11.838: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/22/23 05:30:11.848
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4943, will wait for the garbage collector to delete the pods 08/22/23 05:30:11.848
    Aug 22 05:30:11.905: INFO: Deleting DaemonSet.extensions daemon-set took: 5.259317ms
    Aug 22 05:30:12.006: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.152316ms
    Aug 22 05:30:14.310: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 22 05:30:14.310: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 22 05:30:14.312: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1285047"},"items":null}

    Aug 22 05:30:14.315: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1285047"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 05:30:14.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4943" for this suite. 08/22/23 05:30:14.327
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:30:14.399
Aug 22 05:30:14.399: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename container-runtime 08/22/23 05:30:14.4
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:30:14.414
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:30:14.418
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 08/22/23 05:30:14.43
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 08/22/23 05:30:32.538
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 08/22/23 05:30:32.54
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 08/22/23 05:30:32.543
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 08/22/23 05:30:32.543
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 08/22/23 05:30:32.651
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 08/22/23 05:30:37.677
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 08/22/23 05:30:39.688
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 08/22/23 05:30:39.693
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 08/22/23 05:30:39.693
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 08/22/23 05:30:39.911
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 08/22/23 05:30:40.922
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 08/22/23 05:30:46.981
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 08/22/23 05:30:46.987
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 08/22/23 05:30:46.987
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 22 05:30:47.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4876" for this suite. 08/22/23 05:30:47.014
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":309,"skipped":5763,"failed":0}
------------------------------
â€¢ [SLOW TEST] [32.623 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:30:14.399
    Aug 22 05:30:14.399: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename container-runtime 08/22/23 05:30:14.4
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:30:14.414
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:30:14.418
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 08/22/23 05:30:14.43
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 08/22/23 05:30:32.538
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 08/22/23 05:30:32.54
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 08/22/23 05:30:32.543
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 08/22/23 05:30:32.543
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 08/22/23 05:30:32.651
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 08/22/23 05:30:37.677
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 08/22/23 05:30:39.688
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 08/22/23 05:30:39.693
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 08/22/23 05:30:39.693
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 08/22/23 05:30:39.911
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 08/22/23 05:30:40.922
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 08/22/23 05:30:46.981
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 08/22/23 05:30:46.987
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 08/22/23 05:30:46.987
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 22 05:30:47.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-4876" for this suite. 08/22/23 05:30:47.014
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:30:47.024
Aug 22 05:30:47.024: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 05:30:47.025
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:30:47.042
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:30:47.045
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 08/22/23 05:30:47.048
Aug 22 05:30:47.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6092 cluster-info'
Aug 22 05:30:47.105: INFO: stderr: ""
Aug 22 05:30:47.105: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 05:30:47.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6092" for this suite. 08/22/23 05:30:47.109
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":310,"skipped":5793,"failed":0}
------------------------------
â€¢ [0.092 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:30:47.024
    Aug 22 05:30:47.024: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 05:30:47.025
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:30:47.042
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:30:47.045
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 08/22/23 05:30:47.048
    Aug 22 05:30:47.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6092 cluster-info'
    Aug 22 05:30:47.105: INFO: stderr: ""
    Aug 22 05:30:47.105: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 05:30:47.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6092" for this suite. 08/22/23 05:30:47.109
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:30:47.117
Aug 22 05:30:47.117: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename watch 08/22/23 05:30:47.118
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:30:47.261
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:30:47.264
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 08/22/23 05:30:47.268
STEP: creating a watch on configmaps with label B 08/22/23 05:30:47.269
STEP: creating a watch on configmaps with label A or B 08/22/23 05:30:47.27
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 08/22/23 05:30:47.271
Aug 22 05:30:47.275: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285259 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 22 05:30:47.275: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285259 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 08/22/23 05:30:47.275
Aug 22 05:30:47.282: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285260 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 22 05:30:47.282: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285260 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 08/22/23 05:30:47.282
Aug 22 05:30:47.288: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285261 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 22 05:30:47.288: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285261 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 08/22/23 05:30:47.288
Aug 22 05:30:47.293: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285262 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 22 05:30:47.293: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285262 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 08/22/23 05:30:47.293
Aug 22 05:30:47.297: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6132  5d68cc0a-0844-4ad3-ae01-1f1833da5728 1285263 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 22 05:30:47.297: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6132  5d68cc0a-0844-4ad3-ae01-1f1833da5728 1285263 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 08/22/23 05:30:57.298
Aug 22 05:30:57.305: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6132  5d68cc0a-0844-4ad3-ae01-1f1833da5728 1285320 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 22 05:30:57.306: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6132  5d68cc0a-0844-4ad3-ae01-1f1833da5728 1285320 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 22 05:31:07.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6132" for this suite. 08/22/23 05:31:07.315
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":311,"skipped":5799,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.204 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:30:47.117
    Aug 22 05:30:47.117: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename watch 08/22/23 05:30:47.118
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:30:47.261
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:30:47.264
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 08/22/23 05:30:47.268
    STEP: creating a watch on configmaps with label B 08/22/23 05:30:47.269
    STEP: creating a watch on configmaps with label A or B 08/22/23 05:30:47.27
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 08/22/23 05:30:47.271
    Aug 22 05:30:47.275: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285259 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 22 05:30:47.275: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285259 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 08/22/23 05:30:47.275
    Aug 22 05:30:47.282: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285260 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 22 05:30:47.282: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285260 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 08/22/23 05:30:47.282
    Aug 22 05:30:47.288: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285261 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 22 05:30:47.288: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285261 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 08/22/23 05:30:47.288
    Aug 22 05:30:47.293: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285262 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 22 05:30:47.293: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6132  ac271be3-1263-40c5-a9a1-aaafc4925bc8 1285262 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 08/22/23 05:30:47.293
    Aug 22 05:30:47.297: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6132  5d68cc0a-0844-4ad3-ae01-1f1833da5728 1285263 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 22 05:30:47.297: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6132  5d68cc0a-0844-4ad3-ae01-1f1833da5728 1285263 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 08/22/23 05:30:57.298
    Aug 22 05:30:57.305: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6132  5d68cc0a-0844-4ad3-ae01-1f1833da5728 1285320 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 22 05:30:57.306: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6132  5d68cc0a-0844-4ad3-ae01-1f1833da5728 1285320 0 2023-08-22 05:30:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-08-22 05:30:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 22 05:31:07.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-6132" for this suite. 08/22/23 05:31:07.315
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:31:07.322
Aug 22 05:31:07.322: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 05:31:07.323
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:31:07.335
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:31:07.337
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 05:31:07.353
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:31:08.254
STEP: Deploying the webhook pod 08/22/23 05:31:08.314
STEP: Wait for the deployment to be ready 08/22/23 05:31:08.346
Aug 22 05:31:08.355: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 05:31:10.378: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 31, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 31, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 31, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 31, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 05:31:12.382
STEP: Verifying the service has paired with the endpoint 08/22/23 05:31:12.532
Aug 22 05:31:13.532: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 08/22/23 05:31:13.666
STEP: create a pod 08/22/23 05:31:13.689
Aug 22 05:31:13.695: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-4646" to be "running"
Aug 22 05:31:13.701: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.616047ms
Aug 22 05:31:15.705: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010286871s
Aug 22 05:31:17.706: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.011526035s
Aug 22 05:31:17.707: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 08/22/23 05:31:17.707
Aug 22 05:31:17.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=webhook-4646 attach --namespace=webhook-4646 to-be-attached-pod -i -c=container1'
Aug 22 05:31:17.796: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:31:17.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4646" for this suite. 08/22/23 05:31:17.808
STEP: Destroying namespace "webhook-4646-markers" for this suite. 08/22/23 05:31:17.822
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":312,"skipped":5806,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.625 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:31:07.322
    Aug 22 05:31:07.322: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 05:31:07.323
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:31:07.335
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:31:07.337
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 05:31:07.353
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:31:08.254
    STEP: Deploying the webhook pod 08/22/23 05:31:08.314
    STEP: Wait for the deployment to be ready 08/22/23 05:31:08.346
    Aug 22 05:31:08.355: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 05:31:10.378: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 31, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 31, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 31, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 31, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 05:31:12.382
    STEP: Verifying the service has paired with the endpoint 08/22/23 05:31:12.532
    Aug 22 05:31:13.532: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 08/22/23 05:31:13.666
    STEP: create a pod 08/22/23 05:31:13.689
    Aug 22 05:31:13.695: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-4646" to be "running"
    Aug 22 05:31:13.701: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.616047ms
    Aug 22 05:31:15.705: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010286871s
    Aug 22 05:31:17.706: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.011526035s
    Aug 22 05:31:17.707: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 08/22/23 05:31:17.707
    Aug 22 05:31:17.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=webhook-4646 attach --namespace=webhook-4646 to-be-attached-pod -i -c=container1'
    Aug 22 05:31:17.796: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:31:17.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4646" for this suite. 08/22/23 05:31:17.808
    STEP: Destroying namespace "webhook-4646-markers" for this suite. 08/22/23 05:31:17.822
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:31:17.948
Aug 22 05:31:17.948: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename downward-api 08/22/23 05:31:17.949
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:31:17.964
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:31:17.969
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 08/22/23 05:31:17.975
Aug 22 05:31:18.032: INFO: Waiting up to 5m0s for pod "downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6" in namespace "downward-api-4136" to be "Succeeded or Failed"
Aug 22 05:31:18.036: INFO: Pod "downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.581476ms
Aug 22 05:31:20.046: INFO: Pod "downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6": Phase="Running", Reason="", readiness=true. Elapsed: 2.014347018s
Aug 22 05:31:22.042: INFO: Pod "downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6": Phase="Running", Reason="", readiness=false. Elapsed: 4.009905224s
Aug 22 05:31:24.059: INFO: Pod "downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027501767s
STEP: Saw pod success 08/22/23 05:31:24.059
Aug 22 05:31:24.059: INFO: Pod "downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6" satisfied condition "Succeeded or Failed"
Aug 22 05:31:24.064: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6 container client-container: <nil>
STEP: delete the pod 08/22/23 05:31:24.092
Aug 22 05:31:24.271: INFO: Waiting for pod downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6 to disappear
Aug 22 05:31:24.275: INFO: Pod downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 22 05:31:24.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4136" for this suite. 08/22/23 05:31:24.279
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":313,"skipped":5858,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.338 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:31:17.948
    Aug 22 05:31:17.948: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename downward-api 08/22/23 05:31:17.949
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:31:17.964
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:31:17.969
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 08/22/23 05:31:17.975
    Aug 22 05:31:18.032: INFO: Waiting up to 5m0s for pod "downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6" in namespace "downward-api-4136" to be "Succeeded or Failed"
    Aug 22 05:31:18.036: INFO: Pod "downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.581476ms
    Aug 22 05:31:20.046: INFO: Pod "downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6": Phase="Running", Reason="", readiness=true. Elapsed: 2.014347018s
    Aug 22 05:31:22.042: INFO: Pod "downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6": Phase="Running", Reason="", readiness=false. Elapsed: 4.009905224s
    Aug 22 05:31:24.059: INFO: Pod "downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027501767s
    STEP: Saw pod success 08/22/23 05:31:24.059
    Aug 22 05:31:24.059: INFO: Pod "downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6" satisfied condition "Succeeded or Failed"
    Aug 22 05:31:24.064: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6 container client-container: <nil>
    STEP: delete the pod 08/22/23 05:31:24.092
    Aug 22 05:31:24.271: INFO: Waiting for pod downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6 to disappear
    Aug 22 05:31:24.275: INFO: Pod downwardapi-volume-68cbe448-284a-4ec7-967b-65abf71d17c6 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 22 05:31:24.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4136" for this suite. 08/22/23 05:31:24.279
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:31:24.286
Aug 22 05:31:24.287: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename statefulset 08/22/23 05:31:24.287
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:31:24.301
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:31:24.303
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3185 08/22/23 05:31:24.629
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 08/22/23 05:31:24.636
STEP: Creating stateful set ss in namespace statefulset-3185 08/22/23 05:31:24.644
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3185 08/22/23 05:31:24.653
Aug 22 05:31:24.656: INFO: Found 0 stateful pods, waiting for 1
Aug 22 05:31:34.661: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 08/22/23 05:31:34.661
Aug 22 05:31:34.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 22 05:31:34.835: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 22 05:31:34.835: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 22 05:31:34.835: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 22 05:31:34.838: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 22 05:31:44.842: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 05:31:44.842: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 05:31:44.857: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999985s
Aug 22 05:31:45.862: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995337272s
Aug 22 05:31:46.867: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990706034s
Aug 22 05:31:47.872: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.98564009s
Aug 22 05:31:48.875: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.981230516s
Aug 22 05:31:49.880: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.977333365s
Aug 22 05:31:50.884: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.972563096s
Aug 22 05:31:51.887: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.969284714s
Aug 22 05:31:52.892: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.96469321s
Aug 22 05:31:53.897: INFO: Verifying statefulset ss doesn't scale past 1 for another 960.225749ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3185 08/22/23 05:31:54.897
Aug 22 05:31:54.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 22 05:31:55.060: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 22 05:31:55.060: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 22 05:31:55.060: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 22 05:31:55.067: INFO: Found 1 stateful pods, waiting for 3
Aug 22 05:32:05.071: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 05:32:05.071: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 05:32:05.071: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 08/22/23 05:32:05.071
STEP: Scale down will halt with unhealthy stateful pod 08/22/23 05:32:05.071
Aug 22 05:32:05.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 22 05:32:05.223: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 22 05:32:05.223: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 22 05:32:05.223: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 22 05:32:05.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 22 05:32:05.418: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 22 05:32:05.418: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 22 05:32:05.418: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 22 05:32:05.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 22 05:32:05.605: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 22 05:32:05.605: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 22 05:32:05.605: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 22 05:32:05.605: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 05:32:05.609: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Aug 22 05:32:15.623: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 05:32:15.623: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 05:32:15.623: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 05:32:15.636: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999849s
Aug 22 05:32:16.640: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994377491s
Aug 22 05:32:17.645: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990405288s
Aug 22 05:32:18.650: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985344234s
Aug 22 05:32:19.654: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980368649s
Aug 22 05:32:20.659: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975573252s
Aug 22 05:32:21.662: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971274148s
Aug 22 05:32:22.722: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966867849s
Aug 22 05:32:23.726: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.908284973s
Aug 22 05:32:24.730: INFO: Verifying statefulset ss doesn't scale past 3 for another 903.984864ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3185 08/22/23 05:32:25.73
Aug 22 05:32:25.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 22 05:32:25.871: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 22 05:32:25.871: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 22 05:32:25.871: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 22 05:32:25.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 22 05:32:26.029: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 22 05:32:26.029: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 22 05:32:26.029: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 22 05:32:26.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 22 05:32:26.919: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 22 05:32:26.920: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 22 05:32:26.920: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 22 05:32:26.920: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 08/22/23 05:32:36.935
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 22 05:32:36.935: INFO: Deleting all statefulset in ns statefulset-3185
Aug 22 05:32:36.938: INFO: Scaling statefulset ss to 0
Aug 22 05:32:36.946: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 05:32:36.947: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 22 05:32:36.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3185" for this suite. 08/22/23 05:32:36.972
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":314,"skipped":5862,"failed":0}
------------------------------
â€¢ [SLOW TEST] [72.690 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:31:24.286
    Aug 22 05:31:24.287: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename statefulset 08/22/23 05:31:24.287
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:31:24.301
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:31:24.303
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3185 08/22/23 05:31:24.629
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 08/22/23 05:31:24.636
    STEP: Creating stateful set ss in namespace statefulset-3185 08/22/23 05:31:24.644
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3185 08/22/23 05:31:24.653
    Aug 22 05:31:24.656: INFO: Found 0 stateful pods, waiting for 1
    Aug 22 05:31:34.661: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 08/22/23 05:31:34.661
    Aug 22 05:31:34.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 22 05:31:34.835: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 22 05:31:34.835: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 22 05:31:34.835: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 22 05:31:34.838: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Aug 22 05:31:44.842: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Aug 22 05:31:44.842: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 22 05:31:44.857: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999985s
    Aug 22 05:31:45.862: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995337272s
    Aug 22 05:31:46.867: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990706034s
    Aug 22 05:31:47.872: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.98564009s
    Aug 22 05:31:48.875: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.981230516s
    Aug 22 05:31:49.880: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.977333365s
    Aug 22 05:31:50.884: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.972563096s
    Aug 22 05:31:51.887: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.969284714s
    Aug 22 05:31:52.892: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.96469321s
    Aug 22 05:31:53.897: INFO: Verifying statefulset ss doesn't scale past 1 for another 960.225749ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3185 08/22/23 05:31:54.897
    Aug 22 05:31:54.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 22 05:31:55.060: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 22 05:31:55.060: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 22 05:31:55.060: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 22 05:31:55.067: INFO: Found 1 stateful pods, waiting for 3
    Aug 22 05:32:05.071: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 22 05:32:05.071: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 22 05:32:05.071: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 08/22/23 05:32:05.071
    STEP: Scale down will halt with unhealthy stateful pod 08/22/23 05:32:05.071
    Aug 22 05:32:05.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 22 05:32:05.223: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 22 05:32:05.223: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 22 05:32:05.223: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 22 05:32:05.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 22 05:32:05.418: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 22 05:32:05.418: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 22 05:32:05.418: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 22 05:32:05.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 22 05:32:05.605: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 22 05:32:05.605: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 22 05:32:05.605: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 22 05:32:05.605: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 22 05:32:05.609: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Aug 22 05:32:15.623: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Aug 22 05:32:15.623: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Aug 22 05:32:15.623: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Aug 22 05:32:15.636: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999849s
    Aug 22 05:32:16.640: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994377491s
    Aug 22 05:32:17.645: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990405288s
    Aug 22 05:32:18.650: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985344234s
    Aug 22 05:32:19.654: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980368649s
    Aug 22 05:32:20.659: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975573252s
    Aug 22 05:32:21.662: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971274148s
    Aug 22 05:32:22.722: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966867849s
    Aug 22 05:32:23.726: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.908284973s
    Aug 22 05:32:24.730: INFO: Verifying statefulset ss doesn't scale past 3 for another 903.984864ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3185 08/22/23 05:32:25.73
    Aug 22 05:32:25.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 22 05:32:25.871: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 22 05:32:25.871: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 22 05:32:25.871: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 22 05:32:25.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 22 05:32:26.029: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 22 05:32:26.029: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 22 05:32:26.029: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 22 05:32:26.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-3185 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 22 05:32:26.919: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 22 05:32:26.920: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 22 05:32:26.920: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 22 05:32:26.920: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 08/22/23 05:32:36.935
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 22 05:32:36.935: INFO: Deleting all statefulset in ns statefulset-3185
    Aug 22 05:32:36.938: INFO: Scaling statefulset ss to 0
    Aug 22 05:32:36.946: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 22 05:32:36.947: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 22 05:32:36.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3185" for this suite. 08/22/23 05:32:36.972
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:32:36.98
Aug 22 05:32:36.980: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename certificates 08/22/23 05:32:36.981
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:32:37.289
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:32:37.292
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 08/22/23 05:32:37.648
STEP: getting /apis/certificates.k8s.io 08/22/23 05:32:37.657
STEP: getting /apis/certificates.k8s.io/v1 08/22/23 05:32:37.659
STEP: creating 08/22/23 05:32:37.663
STEP: getting 08/22/23 05:32:37.804
STEP: listing 08/22/23 05:32:37.81
STEP: watching 08/22/23 05:32:37.815
Aug 22 05:32:37.815: INFO: starting watch
STEP: patching 08/22/23 05:32:37.818
STEP: updating 08/22/23 05:32:37.83
Aug 22 05:32:37.838: INFO: waiting for watch events with expected annotations
Aug 22 05:32:37.838: INFO: saw patched and updated annotations
STEP: getting /approval 08/22/23 05:32:37.838
STEP: patching /approval 08/22/23 05:32:37.843
STEP: updating /approval 08/22/23 05:32:37.854
STEP: getting /status 08/22/23 05:32:37.864
STEP: patching /status 08/22/23 05:32:37.868
STEP: updating /status 08/22/23 05:32:37.876
STEP: deleting 08/22/23 05:32:37.882
STEP: deleting a collection 08/22/23 05:32:37.898
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:32:37.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-3183" for this suite. 08/22/23 05:32:37.916
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":315,"skipped":5884,"failed":0}
------------------------------
â€¢ [0.946 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:32:36.98
    Aug 22 05:32:36.980: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename certificates 08/22/23 05:32:36.981
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:32:37.289
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:32:37.292
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 08/22/23 05:32:37.648
    STEP: getting /apis/certificates.k8s.io 08/22/23 05:32:37.657
    STEP: getting /apis/certificates.k8s.io/v1 08/22/23 05:32:37.659
    STEP: creating 08/22/23 05:32:37.663
    STEP: getting 08/22/23 05:32:37.804
    STEP: listing 08/22/23 05:32:37.81
    STEP: watching 08/22/23 05:32:37.815
    Aug 22 05:32:37.815: INFO: starting watch
    STEP: patching 08/22/23 05:32:37.818
    STEP: updating 08/22/23 05:32:37.83
    Aug 22 05:32:37.838: INFO: waiting for watch events with expected annotations
    Aug 22 05:32:37.838: INFO: saw patched and updated annotations
    STEP: getting /approval 08/22/23 05:32:37.838
    STEP: patching /approval 08/22/23 05:32:37.843
    STEP: updating /approval 08/22/23 05:32:37.854
    STEP: getting /status 08/22/23 05:32:37.864
    STEP: patching /status 08/22/23 05:32:37.868
    STEP: updating /status 08/22/23 05:32:37.876
    STEP: deleting 08/22/23 05:32:37.882
    STEP: deleting a collection 08/22/23 05:32:37.898
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:32:37.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-3183" for this suite. 08/22/23 05:32:37.916
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:32:37.93
Aug 22 05:32:37.930: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename replication-controller 08/22/23 05:32:37.931
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:32:37.954
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:32:37.959
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f 08/22/23 05:32:37.965
Aug 22 05:32:37.979: INFO: Pod name my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f: Found 0 pods out of 1
Aug 22 05:32:43.095: INFO: Pod name my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f: Found 1 pods out of 1
Aug 22 05:32:43.095: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f" are running
Aug 22 05:32:43.095: INFO: Waiting up to 5m0s for pod "my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f-hjp92" in namespace "replication-controller-4836" to be "running"
Aug 22 05:32:43.100: INFO: Pod "my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f-hjp92": Phase="Running", Reason="", readiness=true. Elapsed: 4.984933ms
Aug 22 05:32:43.100: INFO: Pod "my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f-hjp92" satisfied condition "running"
Aug 22 05:32:43.100: INFO: Pod "my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f-hjp92" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 05:32:38 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 05:32:41 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 05:32:41 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 05:32:38 +0000 UTC Reason: Message:}])
Aug 22 05:32:43.100: INFO: Trying to dial the pod
Aug 22 05:32:48.113: INFO: Controller my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f: Got expected result from replica 1 [my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f-hjp92]: "my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f-hjp92", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 22 05:32:48.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4836" for this suite. 08/22/23 05:32:48.117
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":316,"skipped":5904,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.193 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:32:37.93
    Aug 22 05:32:37.930: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename replication-controller 08/22/23 05:32:37.931
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:32:37.954
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:32:37.959
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f 08/22/23 05:32:37.965
    Aug 22 05:32:37.979: INFO: Pod name my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f: Found 0 pods out of 1
    Aug 22 05:32:43.095: INFO: Pod name my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f: Found 1 pods out of 1
    Aug 22 05:32:43.095: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f" are running
    Aug 22 05:32:43.095: INFO: Waiting up to 5m0s for pod "my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f-hjp92" in namespace "replication-controller-4836" to be "running"
    Aug 22 05:32:43.100: INFO: Pod "my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f-hjp92": Phase="Running", Reason="", readiness=true. Elapsed: 4.984933ms
    Aug 22 05:32:43.100: INFO: Pod "my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f-hjp92" satisfied condition "running"
    Aug 22 05:32:43.100: INFO: Pod "my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f-hjp92" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 05:32:38 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 05:32:41 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 05:32:41 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-08-22 05:32:38 +0000 UTC Reason: Message:}])
    Aug 22 05:32:43.100: INFO: Trying to dial the pod
    Aug 22 05:32:48.113: INFO: Controller my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f: Got expected result from replica 1 [my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f-hjp92]: "my-hostname-basic-323f264c-89c1-49d2-af73-f0b2297ae47f-hjp92", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 22 05:32:48.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-4836" for this suite. 08/22/23 05:32:48.117
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:32:48.125
Aug 22 05:32:48.125: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename containers 08/22/23 05:32:48.126
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:32:48.185
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:32:48.187
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Aug 22 05:32:48.201: INFO: Waiting up to 5m0s for pod "client-containers-a311d802-50b2-4fe7-a7f4-58875a1704bb" in namespace "containers-8887" to be "running"
Aug 22 05:32:48.203: INFO: Pod "client-containers-a311d802-50b2-4fe7-a7f4-58875a1704bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.632267ms
Aug 22 05:32:50.419: INFO: Pod "client-containers-a311d802-50b2-4fe7-a7f4-58875a1704bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.218612439s
Aug 22 05:32:52.208: INFO: Pod "client-containers-a311d802-50b2-4fe7-a7f4-58875a1704bb": Phase="Running", Reason="", readiness=true. Elapsed: 4.007485361s
Aug 22 05:32:52.208: INFO: Pod "client-containers-a311d802-50b2-4fe7-a7f4-58875a1704bb" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Aug 22 05:32:52.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8887" for this suite. 08/22/23 05:32:52.314
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":317,"skipped":5914,"failed":0}
------------------------------
â€¢ [4.197 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:32:48.125
    Aug 22 05:32:48.125: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename containers 08/22/23 05:32:48.126
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:32:48.185
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:32:48.187
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Aug 22 05:32:48.201: INFO: Waiting up to 5m0s for pod "client-containers-a311d802-50b2-4fe7-a7f4-58875a1704bb" in namespace "containers-8887" to be "running"
    Aug 22 05:32:48.203: INFO: Pod "client-containers-a311d802-50b2-4fe7-a7f4-58875a1704bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.632267ms
    Aug 22 05:32:50.419: INFO: Pod "client-containers-a311d802-50b2-4fe7-a7f4-58875a1704bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.218612439s
    Aug 22 05:32:52.208: INFO: Pod "client-containers-a311d802-50b2-4fe7-a7f4-58875a1704bb": Phase="Running", Reason="", readiness=true. Elapsed: 4.007485361s
    Aug 22 05:32:52.208: INFO: Pod "client-containers-a311d802-50b2-4fe7-a7f4-58875a1704bb" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Aug 22 05:32:52.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-8887" for this suite. 08/22/23 05:32:52.314
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:32:52.322
Aug 22 05:32:52.322: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename sched-preemption 08/22/23 05:32:52.323
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:32:52.337
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:32:52.339
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug 22 05:32:52.354: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 22 05:33:52.385: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:33:52.388
Aug 22 05:33:52.388: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename sched-preemption-path 08/22/23 05:33:52.389
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:33:52.401
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:33:52.405
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Aug 22 05:33:52.420: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Aug 22 05:33:52.423: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Aug 22 05:33:52.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-9118" for this suite. 08/22/23 05:33:52.441
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Aug 22 05:33:52.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3454" for this suite. 08/22/23 05:33:52.457
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":318,"skipped":5920,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.190 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:32:52.322
    Aug 22 05:32:52.322: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename sched-preemption 08/22/23 05:32:52.323
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:32:52.337
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:32:52.339
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Aug 22 05:32:52.354: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 22 05:33:52.385: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:33:52.388
    Aug 22 05:33:52.388: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename sched-preemption-path 08/22/23 05:33:52.389
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:33:52.401
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:33:52.405
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Aug 22 05:33:52.420: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Aug 22 05:33:52.423: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Aug 22 05:33:52.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-9118" for this suite. 08/22/23 05:33:52.441
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 05:33:52.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-3454" for this suite. 08/22/23 05:33:52.457
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:33:52.513
Aug 22 05:33:52.513: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename dns 08/22/23 05:33:52.516
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:33:52.577
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:33:52.579
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 08/22/23 05:33:52.584
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 08/22/23 05:33:52.585
STEP: creating a pod to probe DNS 08/22/23 05:33:52.585
STEP: submitting the pod to kubernetes 08/22/23 05:33:52.585
Aug 22 05:33:52.594: INFO: Waiting up to 15m0s for pod "dns-test-3ad3040c-7635-4921-9ccf-066f3983ce6c" in namespace "dns-5207" to be "running"
Aug 22 05:33:52.597: INFO: Pod "dns-test-3ad3040c-7635-4921-9ccf-066f3983ce6c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.016279ms
Aug 22 05:33:54.601: INFO: Pod "dns-test-3ad3040c-7635-4921-9ccf-066f3983ce6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006504123s
Aug 22 05:33:56.601: INFO: Pod "dns-test-3ad3040c-7635-4921-9ccf-066f3983ce6c": Phase="Running", Reason="", readiness=true. Elapsed: 4.006538668s
Aug 22 05:33:56.601: INFO: Pod "dns-test-3ad3040c-7635-4921-9ccf-066f3983ce6c" satisfied condition "running"
STEP: retrieving the pod 08/22/23 05:33:56.601
STEP: looking for the results for each expected name from probers 08/22/23 05:33:56.603
Aug 22 05:33:56.612: INFO: DNS probes using dns-5207/dns-test-3ad3040c-7635-4921-9ccf-066f3983ce6c succeeded

STEP: deleting the pod 08/22/23 05:33:56.612
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 22 05:33:56.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5207" for this suite. 08/22/23 05:33:56.782
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":319,"skipped":5927,"failed":0}
------------------------------
â€¢ [4.276 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:33:52.513
    Aug 22 05:33:52.513: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename dns 08/22/23 05:33:52.516
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:33:52.577
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:33:52.579
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     08/22/23 05:33:52.584
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     08/22/23 05:33:52.585
    STEP: creating a pod to probe DNS 08/22/23 05:33:52.585
    STEP: submitting the pod to kubernetes 08/22/23 05:33:52.585
    Aug 22 05:33:52.594: INFO: Waiting up to 15m0s for pod "dns-test-3ad3040c-7635-4921-9ccf-066f3983ce6c" in namespace "dns-5207" to be "running"
    Aug 22 05:33:52.597: INFO: Pod "dns-test-3ad3040c-7635-4921-9ccf-066f3983ce6c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.016279ms
    Aug 22 05:33:54.601: INFO: Pod "dns-test-3ad3040c-7635-4921-9ccf-066f3983ce6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006504123s
    Aug 22 05:33:56.601: INFO: Pod "dns-test-3ad3040c-7635-4921-9ccf-066f3983ce6c": Phase="Running", Reason="", readiness=true. Elapsed: 4.006538668s
    Aug 22 05:33:56.601: INFO: Pod "dns-test-3ad3040c-7635-4921-9ccf-066f3983ce6c" satisfied condition "running"
    STEP: retrieving the pod 08/22/23 05:33:56.601
    STEP: looking for the results for each expected name from probers 08/22/23 05:33:56.603
    Aug 22 05:33:56.612: INFO: DNS probes using dns-5207/dns-test-3ad3040c-7635-4921-9ccf-066f3983ce6c succeeded

    STEP: deleting the pod 08/22/23 05:33:56.612
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 22 05:33:56.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-5207" for this suite. 08/22/23 05:33:56.782
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:33:56.793
Aug 22 05:33:56.793: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 05:33:56.794
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:33:56.836
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:33:56.839
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/22/23 05:33:56.844
Aug 22 05:33:56.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2284 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Aug 22 05:33:56.926: INFO: stderr: ""
Aug 22 05:33:56.926: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 08/22/23 05:33:56.926
STEP: verifying the pod e2e-test-httpd-pod was created 08/22/23 05:34:01.978
Aug 22 05:34:01.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2284 get pod e2e-test-httpd-pod -o json'
Aug 22 05:34:02.051: INFO: stderr: ""
Aug 22 05:34:02.052: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-08-22T05:33:56Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-2284\",\n        \"resourceVersion\": \"1286381\",\n        \"uid\": \"582ac0e6-4907-4b6e-a63a-8130a9779ef5\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-lcwvt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"jake-melb-gmyyva4zrlsz-node-2\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-lcwvt\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-08-22T05:33:56Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-08-22T05:33:59Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-08-22T05:33:59Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-08-22T05:33:56Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://5da87ae16f554aeb63f4fc8aa59296f13a2dab6d5f2b903c8538d3783cd357c4\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-08-22T05:33:58Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.0.130\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.100.4.49\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.100.4.49\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-08-22T05:33:56Z\"\n    }\n}\n"
STEP: replace the image in the pod 08/22/23 05:34:02.053
Aug 22 05:34:02.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2284 replace -f -'
Aug 22 05:34:02.803: INFO: stderr: ""
Aug 22 05:34:02.803: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 08/22/23 05:34:02.803
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Aug 22 05:34:02.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2284 delete pods e2e-test-httpd-pod'
Aug 22 05:34:05.469: INFO: stderr: ""
Aug 22 05:34:05.469: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 05:34:05.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2284" for this suite. 08/22/23 05:34:05.474
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":320,"skipped":5972,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.700 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:33:56.793
    Aug 22 05:33:56.793: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 05:33:56.794
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:33:56.836
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:33:56.839
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/22/23 05:33:56.844
    Aug 22 05:33:56.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2284 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Aug 22 05:33:56.926: INFO: stderr: ""
    Aug 22 05:33:56.926: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 08/22/23 05:33:56.926
    STEP: verifying the pod e2e-test-httpd-pod was created 08/22/23 05:34:01.978
    Aug 22 05:34:01.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2284 get pod e2e-test-httpd-pod -o json'
    Aug 22 05:34:02.051: INFO: stderr: ""
    Aug 22 05:34:02.052: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-08-22T05:33:56Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-2284\",\n        \"resourceVersion\": \"1286381\",\n        \"uid\": \"582ac0e6-4907-4b6e-a63a-8130a9779ef5\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-lcwvt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"jake-melb-gmyyva4zrlsz-node-2\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-lcwvt\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-08-22T05:33:56Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-08-22T05:33:59Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-08-22T05:33:59Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-08-22T05:33:56Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://5da87ae16f554aeb63f4fc8aa59296f13a2dab6d5f2b903c8538d3783cd357c4\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-08-22T05:33:58Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.0.130\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.100.4.49\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.100.4.49\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-08-22T05:33:56Z\"\n    }\n}\n"
    STEP: replace the image in the pod 08/22/23 05:34:02.053
    Aug 22 05:34:02.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2284 replace -f -'
    Aug 22 05:34:02.803: INFO: stderr: ""
    Aug 22 05:34:02.803: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 08/22/23 05:34:02.803
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Aug 22 05:34:02.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-2284 delete pods e2e-test-httpd-pod'
    Aug 22 05:34:05.469: INFO: stderr: ""
    Aug 22 05:34:05.469: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 05:34:05.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2284" for this suite. 08/22/23 05:34:05.474
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:34:05.495
Aug 22 05:34:05.495: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 05:34:05.496
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:34:05.512
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:34:05.514
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-533 08/22/23 05:34:05.517
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-533 to expose endpoints map[] 08/22/23 05:34:05.53
Aug 22 05:34:05.540: INFO: successfully validated that service multi-endpoint-test in namespace services-533 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-533 08/22/23 05:34:05.541
Aug 22 05:34:05.550: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-533" to be "running and ready"
Aug 22 05:34:05.554: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.220842ms
Aug 22 05:34:05.554: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:34:07.558: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007534324s
Aug 22 05:34:07.558: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:34:09.559: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.008349666s
Aug 22 05:34:09.559: INFO: The phase of Pod pod1 is Running (Ready = true)
Aug 22 05:34:09.559: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-533 to expose endpoints map[pod1:[100]] 08/22/23 05:34:09.561
Aug 22 05:34:09.568: INFO: successfully validated that service multi-endpoint-test in namespace services-533 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-533 08/22/23 05:34:09.568
Aug 22 05:34:09.580: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-533" to be "running and ready"
Aug 22 05:34:09.585: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.00008ms
Aug 22 05:34:09.585: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:34:11.588: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008438701s
Aug 22 05:34:11.588: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:34:13.602: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.022565996s
Aug 22 05:34:13.603: INFO: The phase of Pod pod2 is Running (Ready = true)
Aug 22 05:34:13.603: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-533 to expose endpoints map[pod1:[100] pod2:[101]] 08/22/23 05:34:13.606
Aug 22 05:34:13.618: INFO: successfully validated that service multi-endpoint-test in namespace services-533 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 08/22/23 05:34:13.618
Aug 22 05:34:13.618: INFO: Creating new exec pod
Aug 22 05:34:13.625: INFO: Waiting up to 5m0s for pod "execpodqt8rj" in namespace "services-533" to be "running"
Aug 22 05:34:13.631: INFO: Pod "execpodqt8rj": Phase="Pending", Reason="", readiness=false. Elapsed: 5.565752ms
Aug 22 05:34:15.635: INFO: Pod "execpodqt8rj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009641428s
Aug 22 05:34:17.634: INFO: Pod "execpodqt8rj": Phase="Running", Reason="", readiness=true. Elapsed: 4.008914854s
Aug 22 05:34:17.634: INFO: Pod "execpodqt8rj" satisfied condition "running"
Aug 22 05:34:18.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-533 exec execpodqt8rj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Aug 22 05:34:18.787: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Aug 22 05:34:18.787: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 05:34:18.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-533 exec execpodqt8rj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.176.101 80'
Aug 22 05:34:18.922: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.176.101 80\nConnection to 10.254.176.101 80 port [tcp/http] succeeded!\n"
Aug 22 05:34:18.922: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 05:34:18.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-533 exec execpodqt8rj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Aug 22 05:34:19.062: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Aug 22 05:34:19.063: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 22 05:34:19.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-533 exec execpodqt8rj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.176.101 81'
Aug 22 05:34:19.201: INFO: stderr: "+ + ncecho -v -t hostName -w 2\n 10.254.176.101 81\nConnection to 10.254.176.101 81 port [tcp/*] succeeded!\n"
Aug 22 05:34:19.201: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-533 08/22/23 05:34:19.201
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-533 to expose endpoints map[pod2:[101]] 08/22/23 05:34:19.326
Aug 22 05:34:19.340: INFO: successfully validated that service multi-endpoint-test in namespace services-533 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-533 08/22/23 05:34:19.34
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-533 to expose endpoints map[] 08/22/23 05:34:19.374
Aug 22 05:34:19.384: INFO: successfully validated that service multi-endpoint-test in namespace services-533 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 05:34:19.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-533" for this suite. 08/22/23 05:34:19.44
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":321,"skipped":5972,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.951 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:34:05.495
    Aug 22 05:34:05.495: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 05:34:05.496
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:34:05.512
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:34:05.514
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-533 08/22/23 05:34:05.517
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-533 to expose endpoints map[] 08/22/23 05:34:05.53
    Aug 22 05:34:05.540: INFO: successfully validated that service multi-endpoint-test in namespace services-533 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-533 08/22/23 05:34:05.541
    Aug 22 05:34:05.550: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-533" to be "running and ready"
    Aug 22 05:34:05.554: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.220842ms
    Aug 22 05:34:05.554: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:34:07.558: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007534324s
    Aug 22 05:34:07.558: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:34:09.559: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.008349666s
    Aug 22 05:34:09.559: INFO: The phase of Pod pod1 is Running (Ready = true)
    Aug 22 05:34:09.559: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-533 to expose endpoints map[pod1:[100]] 08/22/23 05:34:09.561
    Aug 22 05:34:09.568: INFO: successfully validated that service multi-endpoint-test in namespace services-533 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-533 08/22/23 05:34:09.568
    Aug 22 05:34:09.580: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-533" to be "running and ready"
    Aug 22 05:34:09.585: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.00008ms
    Aug 22 05:34:09.585: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:34:11.588: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008438701s
    Aug 22 05:34:11.588: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:34:13.602: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.022565996s
    Aug 22 05:34:13.603: INFO: The phase of Pod pod2 is Running (Ready = true)
    Aug 22 05:34:13.603: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-533 to expose endpoints map[pod1:[100] pod2:[101]] 08/22/23 05:34:13.606
    Aug 22 05:34:13.618: INFO: successfully validated that service multi-endpoint-test in namespace services-533 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 08/22/23 05:34:13.618
    Aug 22 05:34:13.618: INFO: Creating new exec pod
    Aug 22 05:34:13.625: INFO: Waiting up to 5m0s for pod "execpodqt8rj" in namespace "services-533" to be "running"
    Aug 22 05:34:13.631: INFO: Pod "execpodqt8rj": Phase="Pending", Reason="", readiness=false. Elapsed: 5.565752ms
    Aug 22 05:34:15.635: INFO: Pod "execpodqt8rj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009641428s
    Aug 22 05:34:17.634: INFO: Pod "execpodqt8rj": Phase="Running", Reason="", readiness=true. Elapsed: 4.008914854s
    Aug 22 05:34:17.634: INFO: Pod "execpodqt8rj" satisfied condition "running"
    Aug 22 05:34:18.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-533 exec execpodqt8rj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Aug 22 05:34:18.787: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Aug 22 05:34:18.787: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 05:34:18.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-533 exec execpodqt8rj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.176.101 80'
    Aug 22 05:34:18.922: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.254.176.101 80\nConnection to 10.254.176.101 80 port [tcp/http] succeeded!\n"
    Aug 22 05:34:18.922: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 05:34:18.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-533 exec execpodqt8rj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Aug 22 05:34:19.062: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Aug 22 05:34:19.063: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 22 05:34:19.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=services-533 exec execpodqt8rj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.254.176.101 81'
    Aug 22 05:34:19.201: INFO: stderr: "+ + ncecho -v -t hostName -w 2\n 10.254.176.101 81\nConnection to 10.254.176.101 81 port [tcp/*] succeeded!\n"
    Aug 22 05:34:19.201: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-533 08/22/23 05:34:19.201
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-533 to expose endpoints map[pod2:[101]] 08/22/23 05:34:19.326
    Aug 22 05:34:19.340: INFO: successfully validated that service multi-endpoint-test in namespace services-533 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-533 08/22/23 05:34:19.34
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-533 to expose endpoints map[] 08/22/23 05:34:19.374
    Aug 22 05:34:19.384: INFO: successfully validated that service multi-endpoint-test in namespace services-533 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 05:34:19.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-533" for this suite. 08/22/23 05:34:19.44
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:34:19.447
Aug 22 05:34:19.447: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename statefulset 08/22/23 05:34:19.448
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:34:19.524
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:34:19.528
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5076 08/22/23 05:34:19.531
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-5076 08/22/23 05:34:19.582
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5076 08/22/23 05:34:19.591
Aug 22 05:34:19.595: INFO: Found 0 stateful pods, waiting for 1
Aug 22 05:34:29.600: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 08/22/23 05:34:29.6
Aug 22 05:34:29.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-5076 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 22 05:34:29.783: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 22 05:34:29.783: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 22 05:34:29.783: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 22 05:34:29.787: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 22 05:34:39.792: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 05:34:39.792: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 05:34:39.823: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Aug 22 05:34:39.823: INFO: ss-0  jake-melb-gmyyva4zrlsz-node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:19 +0000 UTC  }]
Aug 22 05:34:39.823: INFO: 
Aug 22 05:34:39.823: INFO: StatefulSet ss has not reached scale 3, at 1
Aug 22 05:34:40.826: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997001644s
Aug 22 05:34:41.832: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993217765s
Aug 22 05:34:42.837: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986849377s
Aug 22 05:34:43.841: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982804058s
Aug 22 05:34:44.846: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978409373s
Aug 22 05:34:45.853: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973939967s
Aug 22 05:34:46.856: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967210392s
Aug 22 05:34:47.861: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962614653s
Aug 22 05:34:48.865: INFO: Verifying statefulset ss doesn't scale past 3 for another 958.322076ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5076 08/22/23 05:34:49.866
Aug 22 05:34:49.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-5076 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 22 05:34:50.183: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 22 05:34:50.183: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 22 05:34:50.183: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 22 05:34:50.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-5076 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 22 05:34:50.315: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 22 05:34:50.315: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 22 05:34:50.315: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 22 05:34:50.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-5076 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 22 05:34:50.459: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 22 05:34:50.459: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 22 05:34:50.459: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 22 05:34:50.462: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug 22 05:35:00.469: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 05:35:00.469: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 22 05:35:00.469: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 08/22/23 05:35:00.469
Aug 22 05:35:00.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-5076 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 22 05:35:00.622: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 22 05:35:00.622: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 22 05:35:00.622: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 22 05:35:00.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-5076 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 22 05:35:00.774: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 22 05:35:00.774: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 22 05:35:00.774: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 22 05:35:00.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-5076 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 22 05:35:00.941: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 22 05:35:00.941: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 22 05:35:00.941: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 22 05:35:00.941: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 05:35:00.944: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Aug 22 05:35:10.954: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 05:35:10.954: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 05:35:10.954: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 22 05:35:10.966: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Aug 22 05:35:10.966: INFO: ss-0  jake-melb-gmyyva4zrlsz-node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:19 +0000 UTC  }]
Aug 22 05:35:10.966: INFO: ss-1  jake-melb-gmyyva4zrlsz-node-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  }]
Aug 22 05:35:10.966: INFO: ss-2  jake-melb-gmyyva4zrlsz-node-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  }]
Aug 22 05:35:10.966: INFO: 
Aug 22 05:35:10.966: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 22 05:35:11.970: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Aug 22 05:35:11.970: INFO: ss-0  jake-melb-gmyyva4zrlsz-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:19 +0000 UTC  }]
Aug 22 05:35:11.970: INFO: ss-1  jake-melb-gmyyva4zrlsz-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  }]
Aug 22 05:35:11.970: INFO: ss-2  jake-melb-gmyyva4zrlsz-node-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  }]
Aug 22 05:35:11.970: INFO: 
Aug 22 05:35:11.970: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 22 05:35:13.003: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Aug 22 05:35:13.003: INFO: ss-1  jake-melb-gmyyva4zrlsz-node-0  Running  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  }]
Aug 22 05:35:13.003: INFO: 
Aug 22 05:35:13.003: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 22 05:35:14.007: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.958121631s
Aug 22 05:35:15.012: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.954708147s
Aug 22 05:35:16.015: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.949432978s
Aug 22 05:35:17.019: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.946091831s
Aug 22 05:35:18.024: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.942213024s
Aug 22 05:35:19.028: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.936567713s
Aug 22 05:35:20.032: INFO: Verifying statefulset ss doesn't scale past 0 for another 933.409207ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5076 08/22/23 05:35:21.032
Aug 22 05:35:21.036: INFO: Scaling statefulset ss to 0
Aug 22 05:35:21.045: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 22 05:35:21.047: INFO: Deleting all statefulset in ns statefulset-5076
Aug 22 05:35:21.050: INFO: Scaling statefulset ss to 0
Aug 22 05:35:21.057: INFO: Waiting for statefulset status.replicas updated to 0
Aug 22 05:35:21.059: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 22 05:35:21.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5076" for this suite. 08/22/23 05:35:21.085
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":322,"skipped":5985,"failed":0}
------------------------------
â€¢ [SLOW TEST] [61.645 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:34:19.447
    Aug 22 05:34:19.447: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename statefulset 08/22/23 05:34:19.448
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:34:19.524
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:34:19.528
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-5076 08/22/23 05:34:19.531
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-5076 08/22/23 05:34:19.582
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5076 08/22/23 05:34:19.591
    Aug 22 05:34:19.595: INFO: Found 0 stateful pods, waiting for 1
    Aug 22 05:34:29.600: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 08/22/23 05:34:29.6
    Aug 22 05:34:29.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-5076 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 22 05:34:29.783: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 22 05:34:29.783: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 22 05:34:29.783: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 22 05:34:29.787: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Aug 22 05:34:39.792: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Aug 22 05:34:39.792: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 22 05:34:39.823: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
    Aug 22 05:34:39.823: INFO: ss-0  jake-melb-gmyyva4zrlsz-node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:19 +0000 UTC  }]
    Aug 22 05:34:39.823: INFO: 
    Aug 22 05:34:39.823: INFO: StatefulSet ss has not reached scale 3, at 1
    Aug 22 05:34:40.826: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997001644s
    Aug 22 05:34:41.832: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993217765s
    Aug 22 05:34:42.837: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986849377s
    Aug 22 05:34:43.841: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982804058s
    Aug 22 05:34:44.846: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978409373s
    Aug 22 05:34:45.853: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973939967s
    Aug 22 05:34:46.856: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967210392s
    Aug 22 05:34:47.861: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962614653s
    Aug 22 05:34:48.865: INFO: Verifying statefulset ss doesn't scale past 3 for another 958.322076ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5076 08/22/23 05:34:49.866
    Aug 22 05:34:49.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-5076 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 22 05:34:50.183: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 22 05:34:50.183: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 22 05:34:50.183: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 22 05:34:50.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-5076 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 22 05:34:50.315: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Aug 22 05:34:50.315: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 22 05:34:50.315: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 22 05:34:50.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-5076 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 22 05:34:50.459: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Aug 22 05:34:50.459: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 22 05:34:50.459: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 22 05:34:50.462: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
    Aug 22 05:35:00.469: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 22 05:35:00.469: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 22 05:35:00.469: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 08/22/23 05:35:00.469
    Aug 22 05:35:00.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-5076 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 22 05:35:00.622: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 22 05:35:00.622: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 22 05:35:00.622: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 22 05:35:00.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-5076 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 22 05:35:00.774: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 22 05:35:00.774: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 22 05:35:00.774: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 22 05:35:00.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=statefulset-5076 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 22 05:35:00.941: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 22 05:35:00.941: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 22 05:35:00.941: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 22 05:35:00.941: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 22 05:35:00.944: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Aug 22 05:35:10.954: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Aug 22 05:35:10.954: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Aug 22 05:35:10.954: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Aug 22 05:35:10.966: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
    Aug 22 05:35:10.966: INFO: ss-0  jake-melb-gmyyva4zrlsz-node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:19 +0000 UTC  }]
    Aug 22 05:35:10.966: INFO: ss-1  jake-melb-gmyyva4zrlsz-node-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  }]
    Aug 22 05:35:10.966: INFO: ss-2  jake-melb-gmyyva4zrlsz-node-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  }]
    Aug 22 05:35:10.966: INFO: 
    Aug 22 05:35:10.966: INFO: StatefulSet ss has not reached scale 0, at 3
    Aug 22 05:35:11.970: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
    Aug 22 05:35:11.970: INFO: ss-0  jake-melb-gmyyva4zrlsz-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:19 +0000 UTC  }]
    Aug 22 05:35:11.970: INFO: ss-1  jake-melb-gmyyva4zrlsz-node-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  }]
    Aug 22 05:35:11.970: INFO: ss-2  jake-melb-gmyyva4zrlsz-node-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  }]
    Aug 22 05:35:11.970: INFO: 
    Aug 22 05:35:11.970: INFO: StatefulSet ss has not reached scale 0, at 3
    Aug 22 05:35:13.003: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
    Aug 22 05:35:13.003: INFO: ss-1  jake-melb-gmyyva4zrlsz-node-0  Running  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:35:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-08-22 05:34:39 +0000 UTC  }]
    Aug 22 05:35:13.003: INFO: 
    Aug 22 05:35:13.003: INFO: StatefulSet ss has not reached scale 0, at 1
    Aug 22 05:35:14.007: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.958121631s
    Aug 22 05:35:15.012: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.954708147s
    Aug 22 05:35:16.015: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.949432978s
    Aug 22 05:35:17.019: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.946091831s
    Aug 22 05:35:18.024: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.942213024s
    Aug 22 05:35:19.028: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.936567713s
    Aug 22 05:35:20.032: INFO: Verifying statefulset ss doesn't scale past 0 for another 933.409207ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5076 08/22/23 05:35:21.032
    Aug 22 05:35:21.036: INFO: Scaling statefulset ss to 0
    Aug 22 05:35:21.045: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 22 05:35:21.047: INFO: Deleting all statefulset in ns statefulset-5076
    Aug 22 05:35:21.050: INFO: Scaling statefulset ss to 0
    Aug 22 05:35:21.057: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 22 05:35:21.059: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 22 05:35:21.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-5076" for this suite. 08/22/23 05:35:21.085
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:35:21.094
Aug 22 05:35:21.094: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename disruption 08/22/23 05:35:21.095
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:35:21.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:35:21.187
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 08/22/23 05:35:21.191
STEP: Waiting for the pdb to be processed 08/22/23 05:35:21.202
STEP: First trying to evict a pod which shouldn't be evictable 08/22/23 05:35:23.241
STEP: Waiting for all pods to be running 08/22/23 05:35:23.241
Aug 22 05:35:23.249: INFO: pods: 0 < 3
Aug 22 05:35:25.254: INFO: running pods: 0 < 3
STEP: locating a running pod 08/22/23 05:35:27.254
STEP: Updating the pdb to allow a pod to be evicted 08/22/23 05:35:27.261
STEP: Waiting for the pdb to be processed 08/22/23 05:35:27.269
STEP: Trying to evict the same pod we tried earlier which should now be evictable 08/22/23 05:35:29.275
STEP: Waiting for all pods to be running 08/22/23 05:35:29.275
STEP: Waiting for the pdb to observed all healthy pods 08/22/23 05:35:29.277
STEP: Patching the pdb to disallow a pod to be evicted 08/22/23 05:35:29.364
STEP: Waiting for the pdb to be processed 08/22/23 05:35:29.388
STEP: Waiting for all pods to be running 08/22/23 05:35:29.393
Aug 22 05:35:29.397: INFO: running pods: 2 < 3
Aug 22 05:35:31.403: INFO: running pods: 2 < 3
STEP: locating a running pod 08/22/23 05:35:33.405
STEP: Deleting the pdb to allow a pod to be evicted 08/22/23 05:35:33.414
STEP: Waiting for the pdb to be deleted 08/22/23 05:35:33.42
STEP: Trying to evict the same pod we tried earlier which should now be evictable 08/22/23 05:35:33.422
STEP: Waiting for all pods to be running 08/22/23 05:35:33.422
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 22 05:35:33.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2980" for this suite. 08/22/23 05:35:33.449
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":323,"skipped":6085,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.362 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:35:21.094
    Aug 22 05:35:21.094: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename disruption 08/22/23 05:35:21.095
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:35:21.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:35:21.187
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 08/22/23 05:35:21.191
    STEP: Waiting for the pdb to be processed 08/22/23 05:35:21.202
    STEP: First trying to evict a pod which shouldn't be evictable 08/22/23 05:35:23.241
    STEP: Waiting for all pods to be running 08/22/23 05:35:23.241
    Aug 22 05:35:23.249: INFO: pods: 0 < 3
    Aug 22 05:35:25.254: INFO: running pods: 0 < 3
    STEP: locating a running pod 08/22/23 05:35:27.254
    STEP: Updating the pdb to allow a pod to be evicted 08/22/23 05:35:27.261
    STEP: Waiting for the pdb to be processed 08/22/23 05:35:27.269
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 08/22/23 05:35:29.275
    STEP: Waiting for all pods to be running 08/22/23 05:35:29.275
    STEP: Waiting for the pdb to observed all healthy pods 08/22/23 05:35:29.277
    STEP: Patching the pdb to disallow a pod to be evicted 08/22/23 05:35:29.364
    STEP: Waiting for the pdb to be processed 08/22/23 05:35:29.388
    STEP: Waiting for all pods to be running 08/22/23 05:35:29.393
    Aug 22 05:35:29.397: INFO: running pods: 2 < 3
    Aug 22 05:35:31.403: INFO: running pods: 2 < 3
    STEP: locating a running pod 08/22/23 05:35:33.405
    STEP: Deleting the pdb to allow a pod to be evicted 08/22/23 05:35:33.414
    STEP: Waiting for the pdb to be deleted 08/22/23 05:35:33.42
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 08/22/23 05:35:33.422
    STEP: Waiting for all pods to be running 08/22/23 05:35:33.422
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 22 05:35:33.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2980" for this suite. 08/22/23 05:35:33.449
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:35:33.457
Aug 22 05:35:33.458: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 05:35:33.458
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:35:33.493
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:35:33.498
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-f43e173c-1576-4117-be30-9a1d382a7687 08/22/23 05:35:33.502
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 05:35:33.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7046" for this suite. 08/22/23 05:35:33.508
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":324,"skipped":6098,"failed":0}
------------------------------
â€¢ [0.063 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:35:33.457
    Aug 22 05:35:33.458: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 05:35:33.458
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:35:33.493
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:35:33.498
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-f43e173c-1576-4117-be30-9a1d382a7687 08/22/23 05:35:33.502
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 05:35:33.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7046" for this suite. 08/22/23 05:35:33.508
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:35:33.52
Aug 22 05:35:33.520: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename job 08/22/23 05:35:33.521
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:35:33.966
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:35:33.969
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 08/22/23 05:35:33.973
STEP: Ensuring active pods == parallelism 08/22/23 05:35:33.982
STEP: delete a job 08/22/23 05:35:37.986
STEP: deleting Job.batch foo in namespace job-8180, will wait for the garbage collector to delete the pods 08/22/23 05:35:37.986
Aug 22 05:35:38.046: INFO: Deleting Job.batch foo took: 6.57702ms
Aug 22 05:35:38.147: INFO: Terminating Job.batch foo pods took: 100.694444ms
STEP: Ensuring job was deleted 08/22/23 05:36:09.947
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 22 05:36:09.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8180" for this suite. 08/22/23 05:36:09.959
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":325,"skipped":6107,"failed":0}
------------------------------
â€¢ [SLOW TEST] [36.446 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:35:33.52
    Aug 22 05:35:33.520: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename job 08/22/23 05:35:33.521
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:35:33.966
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:35:33.969
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 08/22/23 05:35:33.973
    STEP: Ensuring active pods == parallelism 08/22/23 05:35:33.982
    STEP: delete a job 08/22/23 05:35:37.986
    STEP: deleting Job.batch foo in namespace job-8180, will wait for the garbage collector to delete the pods 08/22/23 05:35:37.986
    Aug 22 05:35:38.046: INFO: Deleting Job.batch foo took: 6.57702ms
    Aug 22 05:35:38.147: INFO: Terminating Job.batch foo pods took: 100.694444ms
    STEP: Ensuring job was deleted 08/22/23 05:36:09.947
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 22 05:36:09.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-8180" for this suite. 08/22/23 05:36:09.959
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:36:09.967
Aug 22 05:36:09.967: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 05:36:09.968
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:09.983
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:09.986
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 08/22/23 05:36:09.991
Aug 22 05:36:09.992: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:36:12.458: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:36:22.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5956" for this suite. 08/22/23 05:36:22.318
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":326,"skipped":6114,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.358 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:36:09.967
    Aug 22 05:36:09.967: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 05:36:09.968
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:09.983
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:09.986
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 08/22/23 05:36:09.991
    Aug 22 05:36:09.992: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:36:12.458: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:36:22.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5956" for this suite. 08/22/23 05:36:22.318
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:36:22.326
Aug 22 05:36:22.326: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename proxy 08/22/23 05:36:22.326
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:22.365
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:22.368
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Aug 22 05:36:22.372: INFO: Creating pod...
Aug 22 05:36:22.381: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-4089" to be "running"
Aug 22 05:36:22.385: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 3.574716ms
Aug 22 05:36:24.389: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007540256s
Aug 22 05:36:26.390: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.009102548s
Aug 22 05:36:26.391: INFO: Pod "agnhost" satisfied condition "running"
Aug 22 05:36:26.391: INFO: Creating service...
Aug 22 05:36:26.459: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/pods/agnhost/proxy/some/path/with/DELETE
Aug 22 05:36:26.470: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug 22 05:36:26.470: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/pods/agnhost/proxy/some/path/with/GET
Aug 22 05:36:26.474: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Aug 22 05:36:26.475: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/pods/agnhost/proxy/some/path/with/HEAD
Aug 22 05:36:26.477: INFO: http.Client request:HEAD | StatusCode:200
Aug 22 05:36:26.477: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/pods/agnhost/proxy/some/path/with/OPTIONS
Aug 22 05:36:26.481: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug 22 05:36:26.481: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/pods/agnhost/proxy/some/path/with/PATCH
Aug 22 05:36:26.485: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug 22 05:36:26.485: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/pods/agnhost/proxy/some/path/with/POST
Aug 22 05:36:26.489: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug 22 05:36:26.489: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/pods/agnhost/proxy/some/path/with/PUT
Aug 22 05:36:26.494: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Aug 22 05:36:26.494: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/services/test-service/proxy/some/path/with/DELETE
Aug 22 05:36:26.500: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug 22 05:36:26.501: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/services/test-service/proxy/some/path/with/GET
Aug 22 05:36:26.506: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Aug 22 05:36:26.506: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/services/test-service/proxy/some/path/with/HEAD
Aug 22 05:36:26.510: INFO: http.Client request:HEAD | StatusCode:200
Aug 22 05:36:26.510: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/services/test-service/proxy/some/path/with/OPTIONS
Aug 22 05:36:26.517: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug 22 05:36:26.518: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/services/test-service/proxy/some/path/with/PATCH
Aug 22 05:36:26.523: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug 22 05:36:26.523: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/services/test-service/proxy/some/path/with/POST
Aug 22 05:36:26.528: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug 22 05:36:26.528: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/services/test-service/proxy/some/path/with/PUT
Aug 22 05:36:26.533: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Aug 22 05:36:26.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4089" for this suite. 08/22/23 05:36:26.537
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":327,"skipped":6123,"failed":0}
------------------------------
â€¢ [4.237 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:36:22.326
    Aug 22 05:36:22.326: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename proxy 08/22/23 05:36:22.326
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:22.365
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:22.368
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Aug 22 05:36:22.372: INFO: Creating pod...
    Aug 22 05:36:22.381: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-4089" to be "running"
    Aug 22 05:36:22.385: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 3.574716ms
    Aug 22 05:36:24.389: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007540256s
    Aug 22 05:36:26.390: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.009102548s
    Aug 22 05:36:26.391: INFO: Pod "agnhost" satisfied condition "running"
    Aug 22 05:36:26.391: INFO: Creating service...
    Aug 22 05:36:26.459: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/pods/agnhost/proxy/some/path/with/DELETE
    Aug 22 05:36:26.470: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Aug 22 05:36:26.470: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/pods/agnhost/proxy/some/path/with/GET
    Aug 22 05:36:26.474: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Aug 22 05:36:26.475: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/pods/agnhost/proxy/some/path/with/HEAD
    Aug 22 05:36:26.477: INFO: http.Client request:HEAD | StatusCode:200
    Aug 22 05:36:26.477: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/pods/agnhost/proxy/some/path/with/OPTIONS
    Aug 22 05:36:26.481: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Aug 22 05:36:26.481: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/pods/agnhost/proxy/some/path/with/PATCH
    Aug 22 05:36:26.485: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Aug 22 05:36:26.485: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/pods/agnhost/proxy/some/path/with/POST
    Aug 22 05:36:26.489: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Aug 22 05:36:26.489: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/pods/agnhost/proxy/some/path/with/PUT
    Aug 22 05:36:26.494: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Aug 22 05:36:26.494: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/services/test-service/proxy/some/path/with/DELETE
    Aug 22 05:36:26.500: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Aug 22 05:36:26.501: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/services/test-service/proxy/some/path/with/GET
    Aug 22 05:36:26.506: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Aug 22 05:36:26.506: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/services/test-service/proxy/some/path/with/HEAD
    Aug 22 05:36:26.510: INFO: http.Client request:HEAD | StatusCode:200
    Aug 22 05:36:26.510: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/services/test-service/proxy/some/path/with/OPTIONS
    Aug 22 05:36:26.517: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Aug 22 05:36:26.518: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/services/test-service/proxy/some/path/with/PATCH
    Aug 22 05:36:26.523: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Aug 22 05:36:26.523: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/services/test-service/proxy/some/path/with/POST
    Aug 22 05:36:26.528: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Aug 22 05:36:26.528: INFO: Starting http.Client for https://10.254.0.1:443/api/v1/namespaces/proxy-4089/services/test-service/proxy/some/path/with/PUT
    Aug 22 05:36:26.533: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Aug 22 05:36:26.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-4089" for this suite. 08/22/23 05:36:26.537
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:36:26.567
Aug 22 05:36:26.568: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 05:36:26.568
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:26.604
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:26.607
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 05:36:26.717
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:36:26.857
STEP: Deploying the webhook pod 08/22/23 05:36:26.866
STEP: Wait for the deployment to be ready 08/22/23 05:36:26.878
Aug 22 05:36:26.893: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 05:36:28.903: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 36, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 36, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 36, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 36, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 05:36:30.912
STEP: Verifying the service has paired with the endpoint 08/22/23 05:36:31.175
Aug 22 05:36:32.175: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Aug 22 05:36:32.180: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6358-crds.webhook.example.com via the AdmissionRegistration API 08/22/23 05:36:32.699
STEP: Creating a custom resource that should be mutated by the webhook 08/22/23 05:36:32.724
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:36:35.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7710" for this suite. 08/22/23 05:36:35.276
STEP: Destroying namespace "webhook-7710-markers" for this suite. 08/22/23 05:36:35.286
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":328,"skipped":6161,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.215 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:36:26.567
    Aug 22 05:36:26.568: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 05:36:26.568
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:26.604
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:26.607
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 05:36:26.717
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:36:26.857
    STEP: Deploying the webhook pod 08/22/23 05:36:26.866
    STEP: Wait for the deployment to be ready 08/22/23 05:36:26.878
    Aug 22 05:36:26.893: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 05:36:28.903: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 36, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 36, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 36, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 36, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 05:36:30.912
    STEP: Verifying the service has paired with the endpoint 08/22/23 05:36:31.175
    Aug 22 05:36:32.175: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Aug 22 05:36:32.180: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6358-crds.webhook.example.com via the AdmissionRegistration API 08/22/23 05:36:32.699
    STEP: Creating a custom resource that should be mutated by the webhook 08/22/23 05:36:32.724
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:36:35.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7710" for this suite. 08/22/23 05:36:35.276
    STEP: Destroying namespace "webhook-7710-markers" for this suite. 08/22/23 05:36:35.286
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:36:35.783
Aug 22 05:36:35.784: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename lease-test 08/22/23 05:36:35.785
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:35.819
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:35.822
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Aug 22 05:36:35.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-7471" for this suite. 08/22/23 05:36:35.874
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":329,"skipped":6180,"failed":0}
------------------------------
â€¢ [0.096 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:36:35.783
    Aug 22 05:36:35.784: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename lease-test 08/22/23 05:36:35.785
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:35.819
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:35.822
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Aug 22 05:36:35.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-7471" for this suite. 08/22/23 05:36:35.874
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:36:35.88
Aug 22 05:36:35.880: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename gc 08/22/23 05:36:35.88
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:35.937
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:35.939
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 08/22/23 05:36:35.946
STEP: create the rc2 08/22/23 05:36:35.96
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 08/22/23 05:36:40.972
STEP: delete the rc simpletest-rc-to-be-deleted 08/22/23 05:36:41.873
STEP: wait for the rc to be deleted 08/22/23 05:36:41.88
Aug 22 05:36:46.897: INFO: 68 pods remaining
Aug 22 05:36:46.897: INFO: 68 pods has nil DeletionTimestamp
Aug 22 05:36:46.897: INFO: 
STEP: Gathering metrics 08/22/23 05:36:51.89
W0822 05:36:51.898764      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Aug 22 05:36:51.898: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Aug 22 05:36:51.898: INFO: Deleting pod "simpletest-rc-to-be-deleted-26ttd" in namespace "gc-1004"
Aug 22 05:36:51.913: INFO: Deleting pod "simpletest-rc-to-be-deleted-2d7dw" in namespace "gc-1004"
Aug 22 05:36:52.058: INFO: Deleting pod "simpletest-rc-to-be-deleted-2dlt5" in namespace "gc-1004"
Aug 22 05:36:52.075: INFO: Deleting pod "simpletest-rc-to-be-deleted-2gxch" in namespace "gc-1004"
Aug 22 05:36:52.096: INFO: Deleting pod "simpletest-rc-to-be-deleted-2s5n2" in namespace "gc-1004"
Aug 22 05:36:52.110: INFO: Deleting pod "simpletest-rc-to-be-deleted-49dg4" in namespace "gc-1004"
Aug 22 05:36:52.121: INFO: Deleting pod "simpletest-rc-to-be-deleted-4jntz" in namespace "gc-1004"
Aug 22 05:36:52.147: INFO: Deleting pod "simpletest-rc-to-be-deleted-4vk5h" in namespace "gc-1004"
Aug 22 05:36:52.160: INFO: Deleting pod "simpletest-rc-to-be-deleted-5mctl" in namespace "gc-1004"
Aug 22 05:36:52.209: INFO: Deleting pod "simpletest-rc-to-be-deleted-5rhv5" in namespace "gc-1004"
Aug 22 05:36:52.321: INFO: Deleting pod "simpletest-rc-to-be-deleted-659cw" in namespace "gc-1004"
Aug 22 05:36:52.331: INFO: Deleting pod "simpletest-rc-to-be-deleted-6gn56" in namespace "gc-1004"
Aug 22 05:36:52.342: INFO: Deleting pod "simpletest-rc-to-be-deleted-6h95w" in namespace "gc-1004"
Aug 22 05:36:52.354: INFO: Deleting pod "simpletest-rc-to-be-deleted-6j229" in namespace "gc-1004"
Aug 22 05:36:52.364: INFO: Deleting pod "simpletest-rc-to-be-deleted-6r4v6" in namespace "gc-1004"
Aug 22 05:36:52.374: INFO: Deleting pod "simpletest-rc-to-be-deleted-78gt7" in namespace "gc-1004"
Aug 22 05:36:52.381: INFO: Deleting pod "simpletest-rc-to-be-deleted-7cg5h" in namespace "gc-1004"
Aug 22 05:36:52.398: INFO: Deleting pod "simpletest-rc-to-be-deleted-7k5x9" in namespace "gc-1004"
Aug 22 05:36:52.412: INFO: Deleting pod "simpletest-rc-to-be-deleted-7lqs9" in namespace "gc-1004"
Aug 22 05:36:52.425: INFO: Deleting pod "simpletest-rc-to-be-deleted-7qt7d" in namespace "gc-1004"
Aug 22 05:36:52.444: INFO: Deleting pod "simpletest-rc-to-be-deleted-7xk5k" in namespace "gc-1004"
Aug 22 05:36:52.456: INFO: Deleting pod "simpletest-rc-to-be-deleted-89rfg" in namespace "gc-1004"
Aug 22 05:36:52.468: INFO: Deleting pod "simpletest-rc-to-be-deleted-8cd5c" in namespace "gc-1004"
Aug 22 05:36:52.480: INFO: Deleting pod "simpletest-rc-to-be-deleted-92kcz" in namespace "gc-1004"
Aug 22 05:36:52.490: INFO: Deleting pod "simpletest-rc-to-be-deleted-95tn2" in namespace "gc-1004"
Aug 22 05:36:52.501: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qssr" in namespace "gc-1004"
Aug 22 05:36:52.514: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rbnc" in namespace "gc-1004"
Aug 22 05:36:52.523: INFO: Deleting pod "simpletest-rc-to-be-deleted-9sqt4" in namespace "gc-1004"
Aug 22 05:36:52.537: INFO: Deleting pod "simpletest-rc-to-be-deleted-9tnwh" in namespace "gc-1004"
Aug 22 05:36:52.552: INFO: Deleting pod "simpletest-rc-to-be-deleted-b9xhr" in namespace "gc-1004"
Aug 22 05:36:52.561: INFO: Deleting pod "simpletest-rc-to-be-deleted-br9bn" in namespace "gc-1004"
Aug 22 05:36:52.573: INFO: Deleting pod "simpletest-rc-to-be-deleted-c42wv" in namespace "gc-1004"
Aug 22 05:36:52.583: INFO: Deleting pod "simpletest-rc-to-be-deleted-c724h" in namespace "gc-1004"
Aug 22 05:36:52.594: INFO: Deleting pod "simpletest-rc-to-be-deleted-c7jjx" in namespace "gc-1004"
Aug 22 05:36:52.607: INFO: Deleting pod "simpletest-rc-to-be-deleted-cg7sl" in namespace "gc-1004"
Aug 22 05:36:52.621: INFO: Deleting pod "simpletest-rc-to-be-deleted-czvxk" in namespace "gc-1004"
Aug 22 05:36:52.635: INFO: Deleting pod "simpletest-rc-to-be-deleted-d9dsx" in namespace "gc-1004"
Aug 22 05:36:52.647: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzmzk" in namespace "gc-1004"
Aug 22 05:36:52.658: INFO: Deleting pod "simpletest-rc-to-be-deleted-f4mcv" in namespace "gc-1004"
Aug 22 05:36:52.670: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjplf" in namespace "gc-1004"
Aug 22 05:36:52.681: INFO: Deleting pod "simpletest-rc-to-be-deleted-fw4zt" in namespace "gc-1004"
Aug 22 05:36:52.692: INFO: Deleting pod "simpletest-rc-to-be-deleted-fwpcp" in namespace "gc-1004"
Aug 22 05:36:52.703: INFO: Deleting pod "simpletest-rc-to-be-deleted-fzxnv" in namespace "gc-1004"
Aug 22 05:36:52.717: INFO: Deleting pod "simpletest-rc-to-be-deleted-gdbw5" in namespace "gc-1004"
Aug 22 05:36:52.738: INFO: Deleting pod "simpletest-rc-to-be-deleted-grztz" in namespace "gc-1004"
Aug 22 05:36:52.750: INFO: Deleting pod "simpletest-rc-to-be-deleted-gxbnr" in namespace "gc-1004"
Aug 22 05:36:52.760: INFO: Deleting pod "simpletest-rc-to-be-deleted-h8mc7" in namespace "gc-1004"
Aug 22 05:36:52.770: INFO: Deleting pod "simpletest-rc-to-be-deleted-h9mj4" in namespace "gc-1004"
Aug 22 05:36:52.784: INFO: Deleting pod "simpletest-rc-to-be-deleted-hn7r2" in namespace "gc-1004"
Aug 22 05:36:52.795: INFO: Deleting pod "simpletest-rc-to-be-deleted-hsrrt" in namespace "gc-1004"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 22 05:36:53.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1004" for this suite. 08/22/23 05:36:53.433
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":330,"skipped":6182,"failed":0}
------------------------------
â€¢ [SLOW TEST] [17.568 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:36:35.88
    Aug 22 05:36:35.880: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename gc 08/22/23 05:36:35.88
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:35.937
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:35.939
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 08/22/23 05:36:35.946
    STEP: create the rc2 08/22/23 05:36:35.96
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 08/22/23 05:36:40.972
    STEP: delete the rc simpletest-rc-to-be-deleted 08/22/23 05:36:41.873
    STEP: wait for the rc to be deleted 08/22/23 05:36:41.88
    Aug 22 05:36:46.897: INFO: 68 pods remaining
    Aug 22 05:36:46.897: INFO: 68 pods has nil DeletionTimestamp
    Aug 22 05:36:46.897: INFO: 
    STEP: Gathering metrics 08/22/23 05:36:51.89
    W0822 05:36:51.898764      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Aug 22 05:36:51.898: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Aug 22 05:36:51.898: INFO: Deleting pod "simpletest-rc-to-be-deleted-26ttd" in namespace "gc-1004"
    Aug 22 05:36:51.913: INFO: Deleting pod "simpletest-rc-to-be-deleted-2d7dw" in namespace "gc-1004"
    Aug 22 05:36:52.058: INFO: Deleting pod "simpletest-rc-to-be-deleted-2dlt5" in namespace "gc-1004"
    Aug 22 05:36:52.075: INFO: Deleting pod "simpletest-rc-to-be-deleted-2gxch" in namespace "gc-1004"
    Aug 22 05:36:52.096: INFO: Deleting pod "simpletest-rc-to-be-deleted-2s5n2" in namespace "gc-1004"
    Aug 22 05:36:52.110: INFO: Deleting pod "simpletest-rc-to-be-deleted-49dg4" in namespace "gc-1004"
    Aug 22 05:36:52.121: INFO: Deleting pod "simpletest-rc-to-be-deleted-4jntz" in namespace "gc-1004"
    Aug 22 05:36:52.147: INFO: Deleting pod "simpletest-rc-to-be-deleted-4vk5h" in namespace "gc-1004"
    Aug 22 05:36:52.160: INFO: Deleting pod "simpletest-rc-to-be-deleted-5mctl" in namespace "gc-1004"
    Aug 22 05:36:52.209: INFO: Deleting pod "simpletest-rc-to-be-deleted-5rhv5" in namespace "gc-1004"
    Aug 22 05:36:52.321: INFO: Deleting pod "simpletest-rc-to-be-deleted-659cw" in namespace "gc-1004"
    Aug 22 05:36:52.331: INFO: Deleting pod "simpletest-rc-to-be-deleted-6gn56" in namespace "gc-1004"
    Aug 22 05:36:52.342: INFO: Deleting pod "simpletest-rc-to-be-deleted-6h95w" in namespace "gc-1004"
    Aug 22 05:36:52.354: INFO: Deleting pod "simpletest-rc-to-be-deleted-6j229" in namespace "gc-1004"
    Aug 22 05:36:52.364: INFO: Deleting pod "simpletest-rc-to-be-deleted-6r4v6" in namespace "gc-1004"
    Aug 22 05:36:52.374: INFO: Deleting pod "simpletest-rc-to-be-deleted-78gt7" in namespace "gc-1004"
    Aug 22 05:36:52.381: INFO: Deleting pod "simpletest-rc-to-be-deleted-7cg5h" in namespace "gc-1004"
    Aug 22 05:36:52.398: INFO: Deleting pod "simpletest-rc-to-be-deleted-7k5x9" in namespace "gc-1004"
    Aug 22 05:36:52.412: INFO: Deleting pod "simpletest-rc-to-be-deleted-7lqs9" in namespace "gc-1004"
    Aug 22 05:36:52.425: INFO: Deleting pod "simpletest-rc-to-be-deleted-7qt7d" in namespace "gc-1004"
    Aug 22 05:36:52.444: INFO: Deleting pod "simpletest-rc-to-be-deleted-7xk5k" in namespace "gc-1004"
    Aug 22 05:36:52.456: INFO: Deleting pod "simpletest-rc-to-be-deleted-89rfg" in namespace "gc-1004"
    Aug 22 05:36:52.468: INFO: Deleting pod "simpletest-rc-to-be-deleted-8cd5c" in namespace "gc-1004"
    Aug 22 05:36:52.480: INFO: Deleting pod "simpletest-rc-to-be-deleted-92kcz" in namespace "gc-1004"
    Aug 22 05:36:52.490: INFO: Deleting pod "simpletest-rc-to-be-deleted-95tn2" in namespace "gc-1004"
    Aug 22 05:36:52.501: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qssr" in namespace "gc-1004"
    Aug 22 05:36:52.514: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rbnc" in namespace "gc-1004"
    Aug 22 05:36:52.523: INFO: Deleting pod "simpletest-rc-to-be-deleted-9sqt4" in namespace "gc-1004"
    Aug 22 05:36:52.537: INFO: Deleting pod "simpletest-rc-to-be-deleted-9tnwh" in namespace "gc-1004"
    Aug 22 05:36:52.552: INFO: Deleting pod "simpletest-rc-to-be-deleted-b9xhr" in namespace "gc-1004"
    Aug 22 05:36:52.561: INFO: Deleting pod "simpletest-rc-to-be-deleted-br9bn" in namespace "gc-1004"
    Aug 22 05:36:52.573: INFO: Deleting pod "simpletest-rc-to-be-deleted-c42wv" in namespace "gc-1004"
    Aug 22 05:36:52.583: INFO: Deleting pod "simpletest-rc-to-be-deleted-c724h" in namespace "gc-1004"
    Aug 22 05:36:52.594: INFO: Deleting pod "simpletest-rc-to-be-deleted-c7jjx" in namespace "gc-1004"
    Aug 22 05:36:52.607: INFO: Deleting pod "simpletest-rc-to-be-deleted-cg7sl" in namespace "gc-1004"
    Aug 22 05:36:52.621: INFO: Deleting pod "simpletest-rc-to-be-deleted-czvxk" in namespace "gc-1004"
    Aug 22 05:36:52.635: INFO: Deleting pod "simpletest-rc-to-be-deleted-d9dsx" in namespace "gc-1004"
    Aug 22 05:36:52.647: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzmzk" in namespace "gc-1004"
    Aug 22 05:36:52.658: INFO: Deleting pod "simpletest-rc-to-be-deleted-f4mcv" in namespace "gc-1004"
    Aug 22 05:36:52.670: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjplf" in namespace "gc-1004"
    Aug 22 05:36:52.681: INFO: Deleting pod "simpletest-rc-to-be-deleted-fw4zt" in namespace "gc-1004"
    Aug 22 05:36:52.692: INFO: Deleting pod "simpletest-rc-to-be-deleted-fwpcp" in namespace "gc-1004"
    Aug 22 05:36:52.703: INFO: Deleting pod "simpletest-rc-to-be-deleted-fzxnv" in namespace "gc-1004"
    Aug 22 05:36:52.717: INFO: Deleting pod "simpletest-rc-to-be-deleted-gdbw5" in namespace "gc-1004"
    Aug 22 05:36:52.738: INFO: Deleting pod "simpletest-rc-to-be-deleted-grztz" in namespace "gc-1004"
    Aug 22 05:36:52.750: INFO: Deleting pod "simpletest-rc-to-be-deleted-gxbnr" in namespace "gc-1004"
    Aug 22 05:36:52.760: INFO: Deleting pod "simpletest-rc-to-be-deleted-h8mc7" in namespace "gc-1004"
    Aug 22 05:36:52.770: INFO: Deleting pod "simpletest-rc-to-be-deleted-h9mj4" in namespace "gc-1004"
    Aug 22 05:36:52.784: INFO: Deleting pod "simpletest-rc-to-be-deleted-hn7r2" in namespace "gc-1004"
    Aug 22 05:36:52.795: INFO: Deleting pod "simpletest-rc-to-be-deleted-hsrrt" in namespace "gc-1004"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 22 05:36:53.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1004" for this suite. 08/22/23 05:36:53.433
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:36:53.448
Aug 22 05:36:53.448: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename endpointslicemirroring 08/22/23 05:36:53.449
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:53.465
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:53.467
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 08/22/23 05:36:53.483
Aug 22 05:36:53.499: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 08/22/23 05:36:55.596
STEP: mirroring deletion of a custom Endpoint 08/22/23 05:36:55.615
Aug 22 05:36:55.631: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Aug 22 05:36:57.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-4757" for this suite. 08/22/23 05:36:57.639
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":331,"skipped":6190,"failed":0}
------------------------------
â€¢ [4.196 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:36:53.448
    Aug 22 05:36:53.448: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename endpointslicemirroring 08/22/23 05:36:53.449
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:53.465
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:53.467
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 08/22/23 05:36:53.483
    Aug 22 05:36:53.499: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 08/22/23 05:36:55.596
    STEP: mirroring deletion of a custom Endpoint 08/22/23 05:36:55.615
    Aug 22 05:36:55.631: INFO: Waiting for 0 EndpointSlices to exist, got 1
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Aug 22 05:36:57.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-4757" for this suite. 08/22/23 05:36:57.639
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:36:57.646
Aug 22 05:36:57.646: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename svcaccounts 08/22/23 05:36:57.647
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:57.659
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:57.663
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 08/22/23 05:36:57.665
STEP: watching for the ServiceAccount to be added 08/22/23 05:36:57.687
STEP: patching the ServiceAccount 08/22/23 05:36:57.689
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 08/22/23 05:36:57.697
STEP: deleting the ServiceAccount 08/22/23 05:36:57.702
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 22 05:36:57.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8423" for this suite. 08/22/23 05:36:57.733
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":332,"skipped":6216,"failed":0}
------------------------------
â€¢ [0.095 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:36:57.646
    Aug 22 05:36:57.646: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename svcaccounts 08/22/23 05:36:57.647
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:57.659
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:57.663
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 08/22/23 05:36:57.665
    STEP: watching for the ServiceAccount to be added 08/22/23 05:36:57.687
    STEP: patching the ServiceAccount 08/22/23 05:36:57.689
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 08/22/23 05:36:57.697
    STEP: deleting the ServiceAccount 08/22/23 05:36:57.702
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 22 05:36:57.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8423" for this suite. 08/22/23 05:36:57.733
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:36:57.742
Aug 22 05:36:57.742: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename replication-controller 08/22/23 05:36:57.742
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:57.757
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:57.762
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 08/22/23 05:36:57.766
STEP: When the matched label of one of its pods change 08/22/23 05:36:57.774
Aug 22 05:36:57.778: INFO: Pod name pod-release: Found 0 pods out of 1
Aug 22 05:37:02.863: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 08/22/23 05:37:02.911
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 22 05:37:02.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3595" for this suite. 08/22/23 05:37:02.933
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":333,"skipped":6225,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.201 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:36:57.742
    Aug 22 05:36:57.742: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename replication-controller 08/22/23 05:36:57.742
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:36:57.757
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:36:57.762
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 08/22/23 05:36:57.766
    STEP: When the matched label of one of its pods change 08/22/23 05:36:57.774
    Aug 22 05:36:57.778: INFO: Pod name pod-release: Found 0 pods out of 1
    Aug 22 05:37:02.863: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 08/22/23 05:37:02.911
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 22 05:37:02.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-3595" for this suite. 08/22/23 05:37:02.933
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:37:02.945
Aug 22 05:37:02.945: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename var-expansion 08/22/23 05:37:02.946
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:02.968
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:02.97
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 08/22/23 05:37:02.975
Aug 22 05:37:02.998: INFO: Waiting up to 5m0s for pod "var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3" in namespace "var-expansion-9439" to be "Succeeded or Failed"
Aug 22 05:37:03.009: INFO: Pod "var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.840047ms
Aug 22 05:37:05.014: INFO: Pod "var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015319852s
Aug 22 05:37:07.015: INFO: Pod "var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016378053s
Aug 22 05:37:09.034: INFO: Pod "var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035890543s
STEP: Saw pod success 08/22/23 05:37:09.034
Aug 22 05:37:09.035: INFO: Pod "var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3" satisfied condition "Succeeded or Failed"
Aug 22 05:37:09.072: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3 container dapi-container: <nil>
STEP: delete the pod 08/22/23 05:37:09.103
Aug 22 05:37:09.226: INFO: Waiting for pod var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3 to disappear
Aug 22 05:37:09.230: INFO: Pod var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 22 05:37:09.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9439" for this suite. 08/22/23 05:37:09.233
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":334,"skipped":6264,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.294 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:37:02.945
    Aug 22 05:37:02.945: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename var-expansion 08/22/23 05:37:02.946
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:02.968
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:02.97
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 08/22/23 05:37:02.975
    Aug 22 05:37:02.998: INFO: Waiting up to 5m0s for pod "var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3" in namespace "var-expansion-9439" to be "Succeeded or Failed"
    Aug 22 05:37:03.009: INFO: Pod "var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.840047ms
    Aug 22 05:37:05.014: INFO: Pod "var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015319852s
    Aug 22 05:37:07.015: INFO: Pod "var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016378053s
    Aug 22 05:37:09.034: INFO: Pod "var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035890543s
    STEP: Saw pod success 08/22/23 05:37:09.034
    Aug 22 05:37:09.035: INFO: Pod "var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3" satisfied condition "Succeeded or Failed"
    Aug 22 05:37:09.072: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-1 pod var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3 container dapi-container: <nil>
    STEP: delete the pod 08/22/23 05:37:09.103
    Aug 22 05:37:09.226: INFO: Waiting for pod var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3 to disappear
    Aug 22 05:37:09.230: INFO: Pod var-expansion-99e86699-68fe-4ab8-b06d-a5f083b0d2c3 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 22 05:37:09.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-9439" for this suite. 08/22/23 05:37:09.233
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:37:09.242
Aug 22 05:37:09.242: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename emptydir 08/22/23 05:37:09.243
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:09.263
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:09.265
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 08/22/23 05:37:09.269
Aug 22 05:37:09.276: INFO: Waiting up to 5m0s for pod "pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6" in namespace "emptydir-1509" to be "Succeeded or Failed"
Aug 22 05:37:09.280: INFO: Pod "pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.838542ms
Aug 22 05:37:11.284: INFO: Pod "pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007760603s
Aug 22 05:37:13.287: INFO: Pod "pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010803264s
Aug 22 05:37:15.284: INFO: Pod "pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008334926s
STEP: Saw pod success 08/22/23 05:37:15.284
Aug 22 05:37:15.284: INFO: Pod "pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6" satisfied condition "Succeeded or Failed"
Aug 22 05:37:15.286: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6 container test-container: <nil>
STEP: delete the pod 08/22/23 05:37:15.316
Aug 22 05:37:15.342: INFO: Waiting for pod pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6 to disappear
Aug 22 05:37:15.345: INFO: Pod pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 22 05:37:15.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1509" for this suite. 08/22/23 05:37:15.349
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":335,"skipped":6284,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.114 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:37:09.242
    Aug 22 05:37:09.242: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename emptydir 08/22/23 05:37:09.243
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:09.263
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:09.265
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 08/22/23 05:37:09.269
    Aug 22 05:37:09.276: INFO: Waiting up to 5m0s for pod "pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6" in namespace "emptydir-1509" to be "Succeeded or Failed"
    Aug 22 05:37:09.280: INFO: Pod "pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.838542ms
    Aug 22 05:37:11.284: INFO: Pod "pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007760603s
    Aug 22 05:37:13.287: INFO: Pod "pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010803264s
    Aug 22 05:37:15.284: INFO: Pod "pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008334926s
    STEP: Saw pod success 08/22/23 05:37:15.284
    Aug 22 05:37:15.284: INFO: Pod "pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6" satisfied condition "Succeeded or Failed"
    Aug 22 05:37:15.286: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6 container test-container: <nil>
    STEP: delete the pod 08/22/23 05:37:15.316
    Aug 22 05:37:15.342: INFO: Waiting for pod pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6 to disappear
    Aug 22 05:37:15.345: INFO: Pod pod-a067e4a6-c5f3-41b9-b614-42f9898e3ea6 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 22 05:37:15.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1509" for this suite. 08/22/23 05:37:15.349
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:37:15.358
Aug 22 05:37:15.358: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 05:37:15.359
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:15.373
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:15.375
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 08/22/23 05:37:15.378
Aug 22 05:37:15.384: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f" in namespace "projected-4968" to be "Succeeded or Failed"
Aug 22 05:37:15.391: INFO: Pod "downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.548812ms
Aug 22 05:37:17.395: INFO: Pod "downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011067296s
Aug 22 05:37:19.396: INFO: Pod "downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01190487s
STEP: Saw pod success 08/22/23 05:37:19.396
Aug 22 05:37:19.396: INFO: Pod "downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f" satisfied condition "Succeeded or Failed"
Aug 22 05:37:19.398: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f container client-container: <nil>
STEP: delete the pod 08/22/23 05:37:19.404
Aug 22 05:37:19.414: INFO: Waiting for pod downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f to disappear
Aug 22 05:37:19.416: INFO: Pod downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 22 05:37:19.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4968" for this suite. 08/22/23 05:37:19.419
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":336,"skipped":6299,"failed":0}
------------------------------
â€¢ [4.067 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:37:15.358
    Aug 22 05:37:15.358: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 05:37:15.359
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:15.373
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:15.375
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 08/22/23 05:37:15.378
    Aug 22 05:37:15.384: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f" in namespace "projected-4968" to be "Succeeded or Failed"
    Aug 22 05:37:15.391: INFO: Pod "downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.548812ms
    Aug 22 05:37:17.395: INFO: Pod "downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011067296s
    Aug 22 05:37:19.396: INFO: Pod "downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01190487s
    STEP: Saw pod success 08/22/23 05:37:19.396
    Aug 22 05:37:19.396: INFO: Pod "downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f" satisfied condition "Succeeded or Failed"
    Aug 22 05:37:19.398: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f container client-container: <nil>
    STEP: delete the pod 08/22/23 05:37:19.404
    Aug 22 05:37:19.414: INFO: Waiting for pod downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f to disappear
    Aug 22 05:37:19.416: INFO: Pod downwardapi-volume-a7ac8eea-86ce-4a73-a31d-635383eebc3f no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 22 05:37:19.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4968" for this suite. 08/22/23 05:37:19.419
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:37:19.426
Aug 22 05:37:19.426: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 05:37:19.427
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:19.444
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:19.446
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-fe7d119b-c8ed-4b60-a7a1-8dc1b7762387 08/22/23 05:37:19.449
STEP: Creating a pod to test consume configMaps 08/22/23 05:37:19.453
Aug 22 05:37:19.461: INFO: Waiting up to 5m0s for pod "pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030" in namespace "configmap-4450" to be "Succeeded or Failed"
Aug 22 05:37:19.464: INFO: Pod "pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030": Phase="Pending", Reason="", readiness=false. Elapsed: 2.699724ms
Aug 22 05:37:21.468: INFO: Pod "pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006600023s
Aug 22 05:37:23.469: INFO: Pod "pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030": Phase="Running", Reason="", readiness=false. Elapsed: 4.007842029s
Aug 22 05:37:25.469: INFO: Pod "pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007550403s
STEP: Saw pod success 08/22/23 05:37:25.469
Aug 22 05:37:25.469: INFO: Pod "pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030" satisfied condition "Succeeded or Failed"
Aug 22 05:37:25.471: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030 container configmap-volume-test: <nil>
STEP: delete the pod 08/22/23 05:37:25.477
Aug 22 05:37:25.632: INFO: Waiting for pod pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030 to disappear
Aug 22 05:37:25.635: INFO: Pod pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 05:37:25.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4450" for this suite. 08/22/23 05:37:25.641
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":337,"skipped":6316,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.221 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:37:19.426
    Aug 22 05:37:19.426: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 05:37:19.427
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:19.444
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:19.446
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-fe7d119b-c8ed-4b60-a7a1-8dc1b7762387 08/22/23 05:37:19.449
    STEP: Creating a pod to test consume configMaps 08/22/23 05:37:19.453
    Aug 22 05:37:19.461: INFO: Waiting up to 5m0s for pod "pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030" in namespace "configmap-4450" to be "Succeeded or Failed"
    Aug 22 05:37:19.464: INFO: Pod "pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030": Phase="Pending", Reason="", readiness=false. Elapsed: 2.699724ms
    Aug 22 05:37:21.468: INFO: Pod "pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006600023s
    Aug 22 05:37:23.469: INFO: Pod "pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030": Phase="Running", Reason="", readiness=false. Elapsed: 4.007842029s
    Aug 22 05:37:25.469: INFO: Pod "pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007550403s
    STEP: Saw pod success 08/22/23 05:37:25.469
    Aug 22 05:37:25.469: INFO: Pod "pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030" satisfied condition "Succeeded or Failed"
    Aug 22 05:37:25.471: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030 container configmap-volume-test: <nil>
    STEP: delete the pod 08/22/23 05:37:25.477
    Aug 22 05:37:25.632: INFO: Waiting for pod pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030 to disappear
    Aug 22 05:37:25.635: INFO: Pod pod-configmaps-31b7d39e-92e1-4259-9243-258fb9634030 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 05:37:25.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4450" for this suite. 08/22/23 05:37:25.641
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:37:25.648
Aug 22 05:37:25.648: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 05:37:25.649
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:25.664
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:25.667
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 05:37:25.683
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:37:25.891
STEP: Deploying the webhook pod 08/22/23 05:37:25.9
STEP: Wait for the deployment to be ready 08/22/23 05:37:26.359
Aug 22 05:37:26.383: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 05:37:28.391: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 37, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 37, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 37, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 37, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 05:37:30.449
STEP: Verifying the service has paired with the endpoint 08/22/23 05:37:30.458
Aug 22 05:37:31.459: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 08/22/23 05:37:31.463
STEP: create a pod that should be updated by the webhook 08/22/23 05:37:31.479
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:37:31.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3856" for this suite. 08/22/23 05:37:31.735
STEP: Destroying namespace "webhook-3856-markers" for this suite. 08/22/23 05:37:31.759
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":338,"skipped":6318,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.361 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:37:25.648
    Aug 22 05:37:25.648: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 05:37:25.649
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:25.664
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:25.667
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 05:37:25.683
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:37:25.891
    STEP: Deploying the webhook pod 08/22/23 05:37:25.9
    STEP: Wait for the deployment to be ready 08/22/23 05:37:26.359
    Aug 22 05:37:26.383: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 05:37:28.391: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 37, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 37, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 37, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 37, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 05:37:30.449
    STEP: Verifying the service has paired with the endpoint 08/22/23 05:37:30.458
    Aug 22 05:37:31.459: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 08/22/23 05:37:31.463
    STEP: create a pod that should be updated by the webhook 08/22/23 05:37:31.479
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:37:31.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3856" for this suite. 08/22/23 05:37:31.735
    STEP: Destroying namespace "webhook-3856-markers" for this suite. 08/22/23 05:37:31.759
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:37:32.009
Aug 22 05:37:32.009: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 05:37:32.01
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:32.024
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:32.027
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Aug 22 05:37:32.031: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/22/23 05:37:34.491
Aug 22 05:37:34.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-9747 --namespace=crd-publish-openapi-9747 create -f -'
Aug 22 05:37:35.362: INFO: stderr: ""
Aug 22 05:37:35.362: INFO: stdout: "e2e-test-crd-publish-openapi-1669-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Aug 22 05:37:35.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-9747 --namespace=crd-publish-openapi-9747 delete e2e-test-crd-publish-openapi-1669-crds test-cr'
Aug 22 05:37:35.508: INFO: stderr: ""
Aug 22 05:37:35.508: INFO: stdout: "e2e-test-crd-publish-openapi-1669-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Aug 22 05:37:35.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-9747 --namespace=crd-publish-openapi-9747 apply -f -'
Aug 22 05:37:35.936: INFO: stderr: ""
Aug 22 05:37:35.936: INFO: stdout: "e2e-test-crd-publish-openapi-1669-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Aug 22 05:37:35.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-9747 --namespace=crd-publish-openapi-9747 delete e2e-test-crd-publish-openapi-1669-crds test-cr'
Aug 22 05:37:36.004: INFO: stderr: ""
Aug 22 05:37:36.004: INFO: stdout: "e2e-test-crd-publish-openapi-1669-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 08/22/23 05:37:36.004
Aug 22 05:37:36.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-9747 explain e2e-test-crd-publish-openapi-1669-crds'
Aug 22 05:37:36.469: INFO: stderr: ""
Aug 22 05:37:36.469: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1669-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:37:38.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9747" for this suite. 08/22/23 05:37:38.873
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":339,"skipped":6318,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.894 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:37:32.009
    Aug 22 05:37:32.009: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename crd-publish-openapi 08/22/23 05:37:32.01
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:32.024
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:32.027
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Aug 22 05:37:32.031: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/22/23 05:37:34.491
    Aug 22 05:37:34.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-9747 --namespace=crd-publish-openapi-9747 create -f -'
    Aug 22 05:37:35.362: INFO: stderr: ""
    Aug 22 05:37:35.362: INFO: stdout: "e2e-test-crd-publish-openapi-1669-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Aug 22 05:37:35.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-9747 --namespace=crd-publish-openapi-9747 delete e2e-test-crd-publish-openapi-1669-crds test-cr'
    Aug 22 05:37:35.508: INFO: stderr: ""
    Aug 22 05:37:35.508: INFO: stdout: "e2e-test-crd-publish-openapi-1669-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Aug 22 05:37:35.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-9747 --namespace=crd-publish-openapi-9747 apply -f -'
    Aug 22 05:37:35.936: INFO: stderr: ""
    Aug 22 05:37:35.936: INFO: stdout: "e2e-test-crd-publish-openapi-1669-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Aug 22 05:37:35.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-9747 --namespace=crd-publish-openapi-9747 delete e2e-test-crd-publish-openapi-1669-crds test-cr'
    Aug 22 05:37:36.004: INFO: stderr: ""
    Aug 22 05:37:36.004: INFO: stdout: "e2e-test-crd-publish-openapi-1669-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 08/22/23 05:37:36.004
    Aug 22 05:37:36.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=crd-publish-openapi-9747 explain e2e-test-crd-publish-openapi-1669-crds'
    Aug 22 05:37:36.469: INFO: stderr: ""
    Aug 22 05:37:36.469: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1669-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:37:38.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9747" for this suite. 08/22/23 05:37:38.873
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:37:38.905
Aug 22 05:37:38.905: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename secrets 08/22/23 05:37:38.906
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:38.919
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:38.922
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-12dc0969-eea4-4e05-a9b2-2b3e9eae2d8f 08/22/23 05:37:38.93
STEP: Creating secret with name s-test-opt-upd-29b01048-7b14-465f-9790-2288175d9b93 08/22/23 05:37:38.935
STEP: Creating the pod 08/22/23 05:37:38.938
Aug 22 05:37:38.948: INFO: Waiting up to 5m0s for pod "pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d" in namespace "secrets-7510" to be "running and ready"
Aug 22 05:37:38.951: INFO: Pod "pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.441838ms
Aug 22 05:37:38.951: INFO: The phase of Pod pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:37:40.955: INFO: Pod "pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00710294s
Aug 22 05:37:40.955: INFO: The phase of Pod pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:37:42.955: INFO: Pod "pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d": Phase="Running", Reason="", readiness=true. Elapsed: 4.007721644s
Aug 22 05:37:42.955: INFO: The phase of Pod pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d is Running (Ready = true)
Aug 22 05:37:42.955: INFO: Pod "pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-12dc0969-eea4-4e05-a9b2-2b3e9eae2d8f 08/22/23 05:37:42.971
STEP: Updating secret s-test-opt-upd-29b01048-7b14-465f-9790-2288175d9b93 08/22/23 05:37:42.977
STEP: Creating secret with name s-test-opt-create-e71ec9a6-c276-48a6-8ba8-e040d9648a63 08/22/23 05:37:42.982
STEP: waiting to observe update in volume 08/22/23 05:37:43.003
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 22 05:37:45.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7510" for this suite. 08/22/23 05:37:45.117
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":340,"skipped":6327,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.241 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:37:38.905
    Aug 22 05:37:38.905: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename secrets 08/22/23 05:37:38.906
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:38.919
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:38.922
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-12dc0969-eea4-4e05-a9b2-2b3e9eae2d8f 08/22/23 05:37:38.93
    STEP: Creating secret with name s-test-opt-upd-29b01048-7b14-465f-9790-2288175d9b93 08/22/23 05:37:38.935
    STEP: Creating the pod 08/22/23 05:37:38.938
    Aug 22 05:37:38.948: INFO: Waiting up to 5m0s for pod "pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d" in namespace "secrets-7510" to be "running and ready"
    Aug 22 05:37:38.951: INFO: Pod "pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.441838ms
    Aug 22 05:37:38.951: INFO: The phase of Pod pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:37:40.955: INFO: Pod "pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00710294s
    Aug 22 05:37:40.955: INFO: The phase of Pod pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:37:42.955: INFO: Pod "pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d": Phase="Running", Reason="", readiness=true. Elapsed: 4.007721644s
    Aug 22 05:37:42.955: INFO: The phase of Pod pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d is Running (Ready = true)
    Aug 22 05:37:42.955: INFO: Pod "pod-secrets-16efe55e-bfb6-4aba-92e3-670b9797970d" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-12dc0969-eea4-4e05-a9b2-2b3e9eae2d8f 08/22/23 05:37:42.971
    STEP: Updating secret s-test-opt-upd-29b01048-7b14-465f-9790-2288175d9b93 08/22/23 05:37:42.977
    STEP: Creating secret with name s-test-opt-create-e71ec9a6-c276-48a6-8ba8-e040d9648a63 08/22/23 05:37:42.982
    STEP: waiting to observe update in volume 08/22/23 05:37:43.003
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 22 05:37:45.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7510" for this suite. 08/22/23 05:37:45.117
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:37:45.146
Aug 22 05:37:45.146: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 05:37:45.147
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:45.164
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:45.166
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 08/22/23 05:37:45.17
Aug 22 05:37:45.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3819 api-versions'
Aug 22 05:37:45.228: INFO: stderr: ""
Aug 22 05:37:45.228: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\ninternal.apiserver.k8s.io/v1alpha1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1alpha1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 05:37:45.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3819" for this suite. 08/22/23 05:37:45.439
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":341,"skipped":6327,"failed":0}
------------------------------
â€¢ [0.302 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:37:45.146
    Aug 22 05:37:45.146: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 05:37:45.147
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:45.164
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:45.166
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 08/22/23 05:37:45.17
    Aug 22 05:37:45.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-3819 api-versions'
    Aug 22 05:37:45.228: INFO: stderr: ""
    Aug 22 05:37:45.228: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\ninternal.apiserver.k8s.io/v1alpha1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1alpha1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 05:37:45.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3819" for this suite. 08/22/23 05:37:45.439
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:37:45.45
Aug 22 05:37:45.450: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename webhook 08/22/23 05:37:45.45
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:45.886
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:45.889
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/22/23 05:37:45.908
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:37:46.288
STEP: Deploying the webhook pod 08/22/23 05:37:46.293
STEP: Wait for the deployment to be ready 08/22/23 05:37:46.345
Aug 22 05:37:46.357: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 22 05:37:48.364: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 37, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 37, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 37, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 37, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/22/23 05:37:50.4
STEP: Verifying the service has paired with the endpoint 08/22/23 05:37:50.419
Aug 22 05:37:51.419: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 08/22/23 05:37:51.424
STEP: create a pod that should be denied by the webhook 08/22/23 05:37:51.491
STEP: create a pod that causes the webhook to hang 08/22/23 05:37:51.497
STEP: create a configmap that should be denied by the webhook 08/22/23 05:38:01.575
STEP: create a configmap that should be admitted by the webhook 08/22/23 05:38:01.583
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 08/22/23 05:38:01.635
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 08/22/23 05:38:01.642
STEP: create a namespace that bypass the webhook 08/22/23 05:38:01.647
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 08/22/23 05:38:01.654
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:38:01.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4229" for this suite. 08/22/23 05:38:01.694
STEP: Destroying namespace "webhook-4229-markers" for this suite. 08/22/23 05:38:01.704
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":342,"skipped":6401,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.331 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:37:45.45
    Aug 22 05:37:45.450: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename webhook 08/22/23 05:37:45.45
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:37:45.886
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:37:45.889
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/22/23 05:37:45.908
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/22/23 05:37:46.288
    STEP: Deploying the webhook pod 08/22/23 05:37:46.293
    STEP: Wait for the deployment to be ready 08/22/23 05:37:46.345
    Aug 22 05:37:46.357: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Aug 22 05:37:48.364: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.August, 22, 5, 37, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 37, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.August, 22, 5, 37, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.August, 22, 5, 37, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/22/23 05:37:50.4
    STEP: Verifying the service has paired with the endpoint 08/22/23 05:37:50.419
    Aug 22 05:37:51.419: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 08/22/23 05:37:51.424
    STEP: create a pod that should be denied by the webhook 08/22/23 05:37:51.491
    STEP: create a pod that causes the webhook to hang 08/22/23 05:37:51.497
    STEP: create a configmap that should be denied by the webhook 08/22/23 05:38:01.575
    STEP: create a configmap that should be admitted by the webhook 08/22/23 05:38:01.583
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 08/22/23 05:38:01.635
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 08/22/23 05:38:01.642
    STEP: create a namespace that bypass the webhook 08/22/23 05:38:01.647
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 08/22/23 05:38:01.654
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:38:01.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4229" for this suite. 08/22/23 05:38:01.694
    STEP: Destroying namespace "webhook-4229-markers" for this suite. 08/22/23 05:38:01.704
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:38:01.782
Aug 22 05:38:01.782: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename secrets 08/22/23 05:38:01.782
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:38:01.804
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:38:01.807
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-4822f1ee-59ce-4525-91b6-403c39ebfcd8 08/22/23 05:38:01.811
STEP: Creating a pod to test consume secrets 08/22/23 05:38:02.04
Aug 22 05:38:02.049: INFO: Waiting up to 5m0s for pod "pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2" in namespace "secrets-2109" to be "Succeeded or Failed"
Aug 22 05:38:02.053: INFO: Pod "pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.720971ms
Aug 22 05:38:04.058: INFO: Pod "pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008905981s
Aug 22 05:38:06.103: INFO: Pod "pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.054364378s
Aug 22 05:38:08.056: INFO: Pod "pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007413967s
STEP: Saw pod success 08/22/23 05:38:08.057
Aug 22 05:38:08.057: INFO: Pod "pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2" satisfied condition "Succeeded or Failed"
Aug 22 05:38:08.059: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2 container secret-volume-test: <nil>
STEP: delete the pod 08/22/23 05:38:08.064
Aug 22 05:38:08.085: INFO: Waiting for pod pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2 to disappear
Aug 22 05:38:08.089: INFO: Pod pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 22 05:38:08.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2109" for this suite. 08/22/23 05:38:08.093
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":343,"skipped":6416,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.316 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:38:01.782
    Aug 22 05:38:01.782: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename secrets 08/22/23 05:38:01.782
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:38:01.804
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:38:01.807
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-4822f1ee-59ce-4525-91b6-403c39ebfcd8 08/22/23 05:38:01.811
    STEP: Creating a pod to test consume secrets 08/22/23 05:38:02.04
    Aug 22 05:38:02.049: INFO: Waiting up to 5m0s for pod "pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2" in namespace "secrets-2109" to be "Succeeded or Failed"
    Aug 22 05:38:02.053: INFO: Pod "pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.720971ms
    Aug 22 05:38:04.058: INFO: Pod "pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008905981s
    Aug 22 05:38:06.103: INFO: Pod "pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.054364378s
    Aug 22 05:38:08.056: INFO: Pod "pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007413967s
    STEP: Saw pod success 08/22/23 05:38:08.057
    Aug 22 05:38:08.057: INFO: Pod "pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2" satisfied condition "Succeeded or Failed"
    Aug 22 05:38:08.059: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2 container secret-volume-test: <nil>
    STEP: delete the pod 08/22/23 05:38:08.064
    Aug 22 05:38:08.085: INFO: Waiting for pod pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2 to disappear
    Aug 22 05:38:08.089: INFO: Pod pod-secrets-25763ee9-7ceb-45d2-8f6e-f8d56cf3aee2 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 22 05:38:08.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2109" for this suite. 08/22/23 05:38:08.093
  << End Captured GinkgoWriter Output
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:38:08.098
Aug 22 05:38:08.099: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename events 08/22/23 05:38:08.1
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:38:08.112
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:38:08.116
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 08/22/23 05:38:08.119
STEP: listing events in all namespaces 08/22/23 05:38:08.125
STEP: listing events in test namespace 08/22/23 05:38:08.129
STEP: listing events with field selection filtering on source 08/22/23 05:38:08.135
STEP: listing events with field selection filtering on reportingController 08/22/23 05:38:08.139
STEP: getting the test event 08/22/23 05:38:08.141
STEP: patching the test event 08/22/23 05:38:08.145
STEP: getting the test event 08/22/23 05:38:08.153
STEP: updating the test event 08/22/23 05:38:08.155
STEP: getting the test event 08/22/23 05:38:08.16
STEP: deleting the test event 08/22/23 05:38:08.162
STEP: listing events in all namespaces 08/22/23 05:38:08.167
STEP: listing events in test namespace 08/22/23 05:38:08.169
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Aug 22 05:38:08.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3572" for this suite. 08/22/23 05:38:08.174
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":344,"skipped":6416,"failed":0}
------------------------------
â€¢ [0.082 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:38:08.098
    Aug 22 05:38:08.099: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename events 08/22/23 05:38:08.1
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:38:08.112
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:38:08.116
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 08/22/23 05:38:08.119
    STEP: listing events in all namespaces 08/22/23 05:38:08.125
    STEP: listing events in test namespace 08/22/23 05:38:08.129
    STEP: listing events with field selection filtering on source 08/22/23 05:38:08.135
    STEP: listing events with field selection filtering on reportingController 08/22/23 05:38:08.139
    STEP: getting the test event 08/22/23 05:38:08.141
    STEP: patching the test event 08/22/23 05:38:08.145
    STEP: getting the test event 08/22/23 05:38:08.153
    STEP: updating the test event 08/22/23 05:38:08.155
    STEP: getting the test event 08/22/23 05:38:08.16
    STEP: deleting the test event 08/22/23 05:38:08.162
    STEP: listing events in all namespaces 08/22/23 05:38:08.167
    STEP: listing events in test namespace 08/22/23 05:38:08.169
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Aug 22 05:38:08.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-3572" for this suite. 08/22/23 05:38:08.174
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:38:08.183
Aug 22 05:38:08.183: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename deployment 08/22/23 05:38:08.184
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:38:08.198
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:38:08.201
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Aug 22 05:38:08.213: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 22 05:38:13.217: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/22/23 05:38:13.217
Aug 22 05:38:13.217: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 08/22/23 05:38:13.235
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 22 05:38:13.250: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-5481  90da6bf3-a550-43e9-89d7-eaa05285c30a 1289705 1 2023-08-22 05:38:13 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-08-22 05:38:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003fbd9f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Aug 22 05:38:13.259: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-5481  8d686f00-8f08-4fba-948f-ad8a399410bd 1289707 1 2023-08-22 05:38:13 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 90da6bf3-a550-43e9-89d7-eaa05285c30a 0xc003ff2d17 0xc003ff2d18}] [] [{kube-controller-manager Update apps/v1 2023-08-22 05:38:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"90da6bf3-a550-43e9-89d7-eaa05285c30a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ff2df8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 22 05:38:13.259: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Aug 22 05:38:13.260: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-5481  36f79fd4-05c6-4aca-8045-764a75bfff3b 1289706 1 2023-08-22 05:38:08 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 90da6bf3-a550-43e9-89d7-eaa05285c30a 0xc003ff2bb7 0xc003ff2bb8}] [] [{e2e.test Update apps/v1 2023-08-22 05:38:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:38:11 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-08-22 05:38:13 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"90da6bf3-a550-43e9-89d7-eaa05285c30a\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003ff2ca8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 22 05:38:13.274: INFO: Pod "test-cleanup-controller-hgq4x" is available:
&Pod{ObjectMeta:{test-cleanup-controller-hgq4x test-cleanup-controller- deployment-5481  8c6aa3b2-caf0-4514-8c3e-cb114a23abb2 1289690 0 2023-08-22 05:38:08 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 36f79fd4-05c6-4aca-8045-764a75bfff3b 0xc003fbddc7 0xc003fbddc8}] [] [{kube-controller-manager Update v1 2023-08-22 05:38:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36f79fd4-05c6-4aca-8045-764a75bfff3b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 05:38:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.95\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2b762,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2b762,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:38:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:38:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:38:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:38:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:10.100.4.95,StartTime:2023-08-22 05:38:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 05:38:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e07f0db4cf8537a8a6cfefbe9ead6d2f49a93ff2da3787bd7caf2291da8d7468,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.4.95,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 22 05:38:13.274: INFO: Pod "test-cleanup-deployment-69cb9c5497-nh9n2" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-nh9n2 test-cleanup-deployment-69cb9c5497- deployment-5481  0a537878-13e8-48cb-9694-b5aa651dd167 1289710 0 2023-08-22 05:38:13 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 8d686f00-8f08-4fba-948f-ad8a399410bd 0xc004030057 0xc004030058}] [] [{kube-controller-manager Update v1 2023-08-22 05:38:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d686f00-8f08-4fba-948f-ad8a399410bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xpccl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xpccl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 22 05:38:13.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5481" for this suite. 08/22/23 05:38:13.285
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":345,"skipped":6423,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.119 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:38:08.183
    Aug 22 05:38:08.183: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename deployment 08/22/23 05:38:08.184
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:38:08.198
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:38:08.201
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Aug 22 05:38:08.213: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Aug 22 05:38:13.217: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/22/23 05:38:13.217
    Aug 22 05:38:13.217: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 08/22/23 05:38:13.235
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 22 05:38:13.250: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-5481  90da6bf3-a550-43e9-89d7-eaa05285c30a 1289705 1 2023-08-22 05:38:13 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-08-22 05:38:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003fbd9f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

    Aug 22 05:38:13.259: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-5481  8d686f00-8f08-4fba-948f-ad8a399410bd 1289707 1 2023-08-22 05:38:13 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 90da6bf3-a550-43e9-89d7-eaa05285c30a 0xc003ff2d17 0xc003ff2d18}] [] [{kube-controller-manager Update apps/v1 2023-08-22 05:38:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"90da6bf3-a550-43e9-89d7-eaa05285c30a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ff2df8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 22 05:38:13.259: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
    Aug 22 05:38:13.260: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-5481  36f79fd4-05c6-4aca-8045-764a75bfff3b 1289706 1 2023-08-22 05:38:08 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 90da6bf3-a550-43e9-89d7-eaa05285c30a 0xc003ff2bb7 0xc003ff2bb8}] [] [{e2e.test Update apps/v1 2023-08-22 05:38:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-08-22 05:38:11 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-08-22 05:38:13 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"90da6bf3-a550-43e9-89d7-eaa05285c30a\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003ff2ca8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Aug 22 05:38:13.274: INFO: Pod "test-cleanup-controller-hgq4x" is available:
    &Pod{ObjectMeta:{test-cleanup-controller-hgq4x test-cleanup-controller- deployment-5481  8c6aa3b2-caf0-4514-8c3e-cb114a23abb2 1289690 0 2023-08-22 05:38:08 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 36f79fd4-05c6-4aca-8045-764a75bfff3b 0xc003fbddc7 0xc003fbddc8}] [] [{kube-controller-manager Update v1 2023-08-22 05:38:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36f79fd4-05c6-4aca-8045-764a75bfff3b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-08-22 05:38:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.100.4.95\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2b762,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2b762,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jake-melb-gmyyva4zrlsz-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:38:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:38:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:38:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-08-22 05:38:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.130,PodIP:10.100.4.95,StartTime:2023-08-22 05:38:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-08-22 05:38:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e07f0db4cf8537a8a6cfefbe9ead6d2f49a93ff2da3787bd7caf2291da8d7468,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.100.4.95,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 22 05:38:13.274: INFO: Pod "test-cleanup-deployment-69cb9c5497-nh9n2" is not available:
    &Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-nh9n2 test-cleanup-deployment-69cb9c5497- deployment-5481  0a537878-13e8-48cb-9694-b5aa651dd167 1289710 0 2023-08-22 05:38:13 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 8d686f00-8f08-4fba-948f-ad8a399410bd 0xc004030057 0xc004030058}] [] [{kube-controller-manager Update v1 2023-08-22 05:38:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d686f00-8f08-4fba-948f-ad8a399410bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xpccl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xpccl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 22 05:38:13.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5481" for this suite. 08/22/23 05:38:13.285
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:38:13.304
Aug 22 05:38:13.304: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 05:38:13.304
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:38:13.339
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:38:13.345
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 08/22/23 05:38:13.349
STEP: fetching the ConfigMap 08/22/23 05:38:13.355
STEP: patching the ConfigMap 08/22/23 05:38:13.36
STEP: listing all ConfigMaps in all namespaces with a label selector 08/22/23 05:38:13.368
STEP: deleting the ConfigMap by collection with a label selector 08/22/23 05:38:13.39
STEP: listing all ConfigMaps in test namespace 08/22/23 05:38:13.399
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 05:38:13.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5321" for this suite. 08/22/23 05:38:13.411
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":346,"skipped":6459,"failed":0}
------------------------------
â€¢ [0.115 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:38:13.304
    Aug 22 05:38:13.304: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 05:38:13.304
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:38:13.339
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:38:13.345
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 08/22/23 05:38:13.349
    STEP: fetching the ConfigMap 08/22/23 05:38:13.355
    STEP: patching the ConfigMap 08/22/23 05:38:13.36
    STEP: listing all ConfigMaps in all namespaces with a label selector 08/22/23 05:38:13.368
    STEP: deleting the ConfigMap by collection with a label selector 08/22/23 05:38:13.39
    STEP: listing all ConfigMaps in test namespace 08/22/23 05:38:13.399
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 05:38:13.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5321" for this suite. 08/22/23 05:38:13.411
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:38:13.419
Aug 22 05:38:13.420: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename kubectl 08/22/23 05:38:13.42
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:38:13.437
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:38:13.44
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 08/22/23 05:38:13.444
Aug 22 05:38:13.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 create -f -'
Aug 22 05:38:13.961: INFO: stderr: ""
Aug 22 05:38:13.961: INFO: stdout: "pod/pause created\n"
Aug 22 05:38:13.961: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 22 05:38:13.961: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6403" to be "running and ready"
Aug 22 05:38:13.967: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.217971ms
Aug 22 05:38:13.967: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'jake-melb-gmyyva4zrlsz-node-1' to be 'Running' but was 'Pending'
Aug 22 05:38:15.970: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008600226s
Aug 22 05:38:15.970: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'jake-melb-gmyyva4zrlsz-node-1' to be 'Running' but was 'Pending'
Aug 22 05:38:17.985: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.023807251s
Aug 22 05:38:17.985: INFO: Pod "pause" satisfied condition "running and ready"
Aug 22 05:38:17.985: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 08/22/23 05:38:17.985
Aug 22 05:38:17.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 label pods pause testing-label=testing-label-value'
Aug 22 05:38:18.065: INFO: stderr: ""
Aug 22 05:38:18.065: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 08/22/23 05:38:18.065
Aug 22 05:38:18.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 get pod pause -L testing-label'
Aug 22 05:38:18.133: INFO: stderr: ""
Aug 22 05:38:18.133: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod 08/22/23 05:38:18.133
Aug 22 05:38:18.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 label pods pause testing-label-'
Aug 22 05:38:18.355: INFO: stderr: ""
Aug 22 05:38:18.355: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 08/22/23 05:38:18.355
Aug 22 05:38:18.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 get pod pause -L testing-label'
Aug 22 05:38:18.421: INFO: stderr: ""
Aug 22 05:38:18.421: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 08/22/23 05:38:18.421
Aug 22 05:38:18.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 delete --grace-period=0 --force -f -'
Aug 22 05:38:18.510: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 22 05:38:18.510: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 22 05:38:18.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 get rc,svc -l name=pause --no-headers'
Aug 22 05:38:18.727: INFO: stderr: "No resources found in kubectl-6403 namespace.\n"
Aug 22 05:38:18.727: INFO: stdout: ""
Aug 22 05:38:18.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 22 05:38:18.936: INFO: stderr: ""
Aug 22 05:38:18.936: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 22 05:38:18.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6403" for this suite. 08/22/23 05:38:18.94
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":347,"skipped":6502,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.528 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:38:13.419
    Aug 22 05:38:13.420: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename kubectl 08/22/23 05:38:13.42
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:38:13.437
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:38:13.44
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 08/22/23 05:38:13.444
    Aug 22 05:38:13.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 create -f -'
    Aug 22 05:38:13.961: INFO: stderr: ""
    Aug 22 05:38:13.961: INFO: stdout: "pod/pause created\n"
    Aug 22 05:38:13.961: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Aug 22 05:38:13.961: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6403" to be "running and ready"
    Aug 22 05:38:13.967: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.217971ms
    Aug 22 05:38:13.967: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'jake-melb-gmyyva4zrlsz-node-1' to be 'Running' but was 'Pending'
    Aug 22 05:38:15.970: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008600226s
    Aug 22 05:38:15.970: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'jake-melb-gmyyva4zrlsz-node-1' to be 'Running' but was 'Pending'
    Aug 22 05:38:17.985: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.023807251s
    Aug 22 05:38:17.985: INFO: Pod "pause" satisfied condition "running and ready"
    Aug 22 05:38:17.985: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 08/22/23 05:38:17.985
    Aug 22 05:38:17.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 label pods pause testing-label=testing-label-value'
    Aug 22 05:38:18.065: INFO: stderr: ""
    Aug 22 05:38:18.065: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 08/22/23 05:38:18.065
    Aug 22 05:38:18.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 get pod pause -L testing-label'
    Aug 22 05:38:18.133: INFO: stderr: ""
    Aug 22 05:38:18.133: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 08/22/23 05:38:18.133
    Aug 22 05:38:18.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 label pods pause testing-label-'
    Aug 22 05:38:18.355: INFO: stderr: ""
    Aug 22 05:38:18.355: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 08/22/23 05:38:18.355
    Aug 22 05:38:18.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 get pod pause -L testing-label'
    Aug 22 05:38:18.421: INFO: stderr: ""
    Aug 22 05:38:18.421: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 08/22/23 05:38:18.421
    Aug 22 05:38:18.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 delete --grace-period=0 --force -f -'
    Aug 22 05:38:18.510: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 22 05:38:18.510: INFO: stdout: "pod \"pause\" force deleted\n"
    Aug 22 05:38:18.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 get rc,svc -l name=pause --no-headers'
    Aug 22 05:38:18.727: INFO: stderr: "No resources found in kubectl-6403 namespace.\n"
    Aug 22 05:38:18.727: INFO: stdout: ""
    Aug 22 05:38:18.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1125186500 --namespace=kubectl-6403 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Aug 22 05:38:18.936: INFO: stderr: ""
    Aug 22 05:38:18.936: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 22 05:38:18.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6403" for this suite. 08/22/23 05:38:18.94
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:38:18.948
Aug 22 05:38:18.948: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename pod-network-test 08/22/23 05:38:18.949
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:38:18.968
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:38:18.971
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-2784 08/22/23 05:38:18.974
STEP: creating a selector 08/22/23 05:38:18.974
STEP: Creating the service pods in kubernetes 08/22/23 05:38:18.974
Aug 22 05:38:18.974: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 22 05:38:19.002: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2784" to be "running and ready"
Aug 22 05:38:19.005: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.517821ms
Aug 22 05:38:19.005: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:38:21.010: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008604666s
Aug 22 05:38:21.010: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:38:23.009: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007601497s
Aug 22 05:38:23.009: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 22 05:38:25.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.008114263s
Aug 22 05:38:25.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:38:27.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.007773727s
Aug 22 05:38:27.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:38:29.009: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.00746948s
Aug 22 05:38:29.009: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:38:31.009: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.007669066s
Aug 22 05:38:31.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:38:33.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.007940989s
Aug 22 05:38:33.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:38:35.011: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.009495077s
Aug 22 05:38:35.011: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:38:37.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.007972132s
Aug 22 05:38:37.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:38:39.009: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.007448554s
Aug 22 05:38:39.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 22 05:38:41.009: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.007516844s
Aug 22 05:38:41.009: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Aug 22 05:38:41.009: INFO: Pod "netserver-0" satisfied condition "running and ready"
Aug 22 05:38:41.012: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2784" to be "running and ready"
Aug 22 05:38:41.015: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.278711ms
Aug 22 05:38:41.015: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Aug 22 05:38:41.015: INFO: Pod "netserver-1" satisfied condition "running and ready"
Aug 22 05:38:41.018: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2784" to be "running and ready"
Aug 22 05:38:41.020: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.599969ms
Aug 22 05:38:41.020: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Aug 22 05:38:41.020: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 08/22/23 05:38:41.022
Aug 22 05:38:41.135: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2784" to be "running"
Aug 22 05:38:41.139: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.675455ms
Aug 22 05:38:43.150: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014949479s
Aug 22 05:38:45.143: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.008480014s
Aug 22 05:38:45.144: INFO: Pod "test-container-pod" satisfied condition "running"
Aug 22 05:38:45.146: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Aug 22 05:38:45.146: INFO: Breadth first check of 10.100.3.247 on host 10.0.0.97...
Aug 22 05:38:45.162: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.4.97:9080/dial?request=hostname&protocol=http&host=10.100.3.247&port=8083&tries=1'] Namespace:pod-network-test-2784 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:38:45.162: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:38:45.163: INFO: ExecWithOptions: Clientset creation
Aug 22 05:38:45.163: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-2784/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.4.97%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.100.3.247%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 22 05:38:45.426: INFO: Waiting for responses: map[]
Aug 22 05:38:45.426: INFO: reached 10.100.3.247 after 0/1 tries
Aug 22 05:38:45.426: INFO: Breadth first check of 10.100.5.176 on host 10.0.0.232...
Aug 22 05:38:45.430: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.4.97:9080/dial?request=hostname&protocol=http&host=10.100.5.176&port=8083&tries=1'] Namespace:pod-network-test-2784 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:38:45.430: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:38:45.430: INFO: ExecWithOptions: Clientset creation
Aug 22 05:38:45.430: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-2784/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.4.97%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.100.5.176%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 22 05:38:45.512: INFO: Waiting for responses: map[]
Aug 22 05:38:45.512: INFO: reached 10.100.5.176 after 0/1 tries
Aug 22 05:38:45.512: INFO: Breadth first check of 10.100.4.96 on host 10.0.0.130...
Aug 22 05:38:45.515: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.4.97:9080/dial?request=hostname&protocol=http&host=10.100.4.96&port=8083&tries=1'] Namespace:pod-network-test-2784 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:38:45.515: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:38:45.516: INFO: ExecWithOptions: Clientset creation
Aug 22 05:38:45.516: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-2784/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.4.97%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.100.4.96%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 22 05:38:45.587: INFO: Waiting for responses: map[]
Aug 22 05:38:45.587: INFO: reached 10.100.4.96 after 0/1 tries
Aug 22 05:38:45.587: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Aug 22 05:38:45.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2784" for this suite. 08/22/23 05:38:45.593
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":348,"skipped":6513,"failed":0}
------------------------------
â€¢ [SLOW TEST] [26.652 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:38:18.948
    Aug 22 05:38:18.948: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename pod-network-test 08/22/23 05:38:18.949
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:38:18.968
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:38:18.971
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-2784 08/22/23 05:38:18.974
    STEP: creating a selector 08/22/23 05:38:18.974
    STEP: Creating the service pods in kubernetes 08/22/23 05:38:18.974
    Aug 22 05:38:18.974: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Aug 22 05:38:19.002: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2784" to be "running and ready"
    Aug 22 05:38:19.005: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.517821ms
    Aug 22 05:38:19.005: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:38:21.010: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008604666s
    Aug 22 05:38:21.010: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:38:23.009: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007601497s
    Aug 22 05:38:23.009: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 22 05:38:25.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.008114263s
    Aug 22 05:38:25.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:38:27.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.007773727s
    Aug 22 05:38:27.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:38:29.009: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.00746948s
    Aug 22 05:38:29.009: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:38:31.009: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.007669066s
    Aug 22 05:38:31.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:38:33.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.007940989s
    Aug 22 05:38:33.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:38:35.011: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.009495077s
    Aug 22 05:38:35.011: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:38:37.010: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.007972132s
    Aug 22 05:38:37.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:38:39.009: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.007448554s
    Aug 22 05:38:39.010: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 22 05:38:41.009: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.007516844s
    Aug 22 05:38:41.009: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Aug 22 05:38:41.009: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Aug 22 05:38:41.012: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2784" to be "running and ready"
    Aug 22 05:38:41.015: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.278711ms
    Aug 22 05:38:41.015: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Aug 22 05:38:41.015: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Aug 22 05:38:41.018: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2784" to be "running and ready"
    Aug 22 05:38:41.020: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.599969ms
    Aug 22 05:38:41.020: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Aug 22 05:38:41.020: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 08/22/23 05:38:41.022
    Aug 22 05:38:41.135: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2784" to be "running"
    Aug 22 05:38:41.139: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.675455ms
    Aug 22 05:38:43.150: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014949479s
    Aug 22 05:38:45.143: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.008480014s
    Aug 22 05:38:45.144: INFO: Pod "test-container-pod" satisfied condition "running"
    Aug 22 05:38:45.146: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Aug 22 05:38:45.146: INFO: Breadth first check of 10.100.3.247 on host 10.0.0.97...
    Aug 22 05:38:45.162: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.4.97:9080/dial?request=hostname&protocol=http&host=10.100.3.247&port=8083&tries=1'] Namespace:pod-network-test-2784 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:38:45.162: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:38:45.163: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:38:45.163: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-2784/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.4.97%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.100.3.247%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 22 05:38:45.426: INFO: Waiting for responses: map[]
    Aug 22 05:38:45.426: INFO: reached 10.100.3.247 after 0/1 tries
    Aug 22 05:38:45.426: INFO: Breadth first check of 10.100.5.176 on host 10.0.0.232...
    Aug 22 05:38:45.430: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.4.97:9080/dial?request=hostname&protocol=http&host=10.100.5.176&port=8083&tries=1'] Namespace:pod-network-test-2784 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:38:45.430: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:38:45.430: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:38:45.430: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-2784/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.4.97%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.100.5.176%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 22 05:38:45.512: INFO: Waiting for responses: map[]
    Aug 22 05:38:45.512: INFO: reached 10.100.5.176 after 0/1 tries
    Aug 22 05:38:45.512: INFO: Breadth first check of 10.100.4.96 on host 10.0.0.130...
    Aug 22 05:38:45.515: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.100.4.97:9080/dial?request=hostname&protocol=http&host=10.100.4.96&port=8083&tries=1'] Namespace:pod-network-test-2784 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:38:45.515: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:38:45.516: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:38:45.516: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/pod-network-test-2784/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.100.4.97%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.100.4.96%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 22 05:38:45.587: INFO: Waiting for responses: map[]
    Aug 22 05:38:45.587: INFO: reached 10.100.4.96 after 0/1 tries
    Aug 22 05:38:45.587: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Aug 22 05:38:45.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-2784" for this suite. 08/22/23 05:38:45.593
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:38:45.601
Aug 22 05:38:45.601: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename var-expansion 08/22/23 05:38:45.602
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:38:45.646
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:38:45.649
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 08/22/23 05:38:45.654
STEP: waiting for pod running 08/22/23 05:38:45.669
Aug 22 05:38:45.669: INFO: Waiting up to 2m0s for pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e" in namespace "var-expansion-5723" to be "running"
Aug 22 05:38:45.674: INFO: Pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.281018ms
Aug 22 05:38:47.813: INFO: Pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.14466314s
Aug 22 05:38:49.679: INFO: Pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e": Phase="Running", Reason="", readiness=true. Elapsed: 4.010280705s
Aug 22 05:38:49.679: INFO: Pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e" satisfied condition "running"
STEP: creating a file in subpath 08/22/23 05:38:49.679
Aug 22 05:38:49.682: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-5723 PodName:var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:38:49.682: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:38:49.683: INFO: ExecWithOptions: Clientset creation
Aug 22 05:38:49.683: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/var-expansion-5723/pods/var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 08/22/23 05:38:49.768
Aug 22 05:38:49.771: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-5723 PodName:var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 22 05:38:49.771: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
Aug 22 05:38:49.772: INFO: ExecWithOptions: Clientset creation
Aug 22 05:38:49.772: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/var-expansion-5723/pods/var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 08/22/23 05:38:49.858
Aug 22 05:38:50.449: INFO: Successfully updated pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e"
STEP: waiting for annotated pod running 08/22/23 05:38:50.449
Aug 22 05:38:50.449: INFO: Waiting up to 2m0s for pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e" in namespace "var-expansion-5723" to be "running"
Aug 22 05:38:50.455: INFO: Pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e": Phase="Running", Reason="", readiness=true. Elapsed: 6.129771ms
Aug 22 05:38:50.455: INFO: Pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e" satisfied condition "running"
STEP: deleting the pod gracefully 08/22/23 05:38:50.455
Aug 22 05:38:50.455: INFO: Deleting pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e" in namespace "var-expansion-5723"
Aug 22 05:38:50.464: INFO: Wait up to 5m0s for pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 22 05:39:24.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5723" for this suite. 08/22/23 05:39:24.476
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":349,"skipped":6524,"failed":0}
------------------------------
â€¢ [SLOW TEST] [38.880 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:38:45.601
    Aug 22 05:38:45.601: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename var-expansion 08/22/23 05:38:45.602
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:38:45.646
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:38:45.649
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 08/22/23 05:38:45.654
    STEP: waiting for pod running 08/22/23 05:38:45.669
    Aug 22 05:38:45.669: INFO: Waiting up to 2m0s for pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e" in namespace "var-expansion-5723" to be "running"
    Aug 22 05:38:45.674: INFO: Pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.281018ms
    Aug 22 05:38:47.813: INFO: Pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.14466314s
    Aug 22 05:38:49.679: INFO: Pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e": Phase="Running", Reason="", readiness=true. Elapsed: 4.010280705s
    Aug 22 05:38:49.679: INFO: Pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e" satisfied condition "running"
    STEP: creating a file in subpath 08/22/23 05:38:49.679
    Aug 22 05:38:49.682: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-5723 PodName:var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:38:49.682: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:38:49.683: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:38:49.683: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/var-expansion-5723/pods/var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 08/22/23 05:38:49.768
    Aug 22 05:38:49.771: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-5723 PodName:var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 22 05:38:49.771: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    Aug 22 05:38:49.772: INFO: ExecWithOptions: Clientset creation
    Aug 22 05:38:49.772: INFO: ExecWithOptions: execute(POST https://10.254.0.1:443/api/v1/namespaces/var-expansion-5723/pods/var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 08/22/23 05:38:49.858
    Aug 22 05:38:50.449: INFO: Successfully updated pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e"
    STEP: waiting for annotated pod running 08/22/23 05:38:50.449
    Aug 22 05:38:50.449: INFO: Waiting up to 2m0s for pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e" in namespace "var-expansion-5723" to be "running"
    Aug 22 05:38:50.455: INFO: Pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e": Phase="Running", Reason="", readiness=true. Elapsed: 6.129771ms
    Aug 22 05:38:50.455: INFO: Pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e" satisfied condition "running"
    STEP: deleting the pod gracefully 08/22/23 05:38:50.455
    Aug 22 05:38:50.455: INFO: Deleting pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e" in namespace "var-expansion-5723"
    Aug 22 05:38:50.464: INFO: Wait up to 5m0s for pod "var-expansion-5b4a4d90-4468-49ae-ac8c-92c33b2f9f0e" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 22 05:39:24.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-5723" for this suite. 08/22/23 05:39:24.476
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:39:24.482
Aug 22 05:39:24.483: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename custom-resource-definition 08/22/23 05:39:24.484
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:39:24.582
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:39:24.586
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Aug 22 05:39:24.590: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:39:25.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4390" for this suite. 08/22/23 05:39:25.973
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":350,"skipped":6529,"failed":0}
------------------------------
â€¢ [1.748 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:39:24.482
    Aug 22 05:39:24.483: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename custom-resource-definition 08/22/23 05:39:24.484
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:39:24.582
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:39:24.586
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Aug 22 05:39:24.590: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:39:25.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-4390" for this suite. 08/22/23 05:39:25.973
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:39:26.235
Aug 22 05:39:26.235: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename services 08/22/23 05:39:26.236
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:39:26.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:39:26.33
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 22 05:39:26.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1874" for this suite. 08/22/23 05:39:26.34
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":351,"skipped":6589,"failed":0}
------------------------------
â€¢ [0.110 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:39:26.235
    Aug 22 05:39:26.235: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename services 08/22/23 05:39:26.236
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:39:26.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:39:26.33
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 22 05:39:26.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1874" for this suite. 08/22/23 05:39:26.34
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:39:26.347
Aug 22 05:39:26.347: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename projected 08/22/23 05:39:26.348
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:39:26.36
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:39:26.363
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 08/22/23 05:39:26.366
Aug 22 05:39:26.374: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98" in namespace "projected-733" to be "Succeeded or Failed"
Aug 22 05:39:26.377: INFO: Pod "downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98": Phase="Pending", Reason="", readiness=false. Elapsed: 3.27271ms
Aug 22 05:39:28.381: INFO: Pod "downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006959318s
Aug 22 05:39:30.380: INFO: Pod "downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006366999s
Aug 22 05:39:32.381: INFO: Pod "downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007581061s
STEP: Saw pod success 08/22/23 05:39:32.381
Aug 22 05:39:32.382: INFO: Pod "downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98" satisfied condition "Succeeded or Failed"
Aug 22 05:39:32.384: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98 container client-container: <nil>
STEP: delete the pod 08/22/23 05:39:32.388
Aug 22 05:39:32.532: INFO: Waiting for pod downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98 to disappear
Aug 22 05:39:32.536: INFO: Pod downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 22 05:39:32.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-733" for this suite. 08/22/23 05:39:32.54
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":352,"skipped":6609,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.203 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:39:26.347
    Aug 22 05:39:26.347: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename projected 08/22/23 05:39:26.348
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:39:26.36
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:39:26.363
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 08/22/23 05:39:26.366
    Aug 22 05:39:26.374: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98" in namespace "projected-733" to be "Succeeded or Failed"
    Aug 22 05:39:26.377: INFO: Pod "downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98": Phase="Pending", Reason="", readiness=false. Elapsed: 3.27271ms
    Aug 22 05:39:28.381: INFO: Pod "downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006959318s
    Aug 22 05:39:30.380: INFO: Pod "downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006366999s
    Aug 22 05:39:32.381: INFO: Pod "downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007581061s
    STEP: Saw pod success 08/22/23 05:39:32.381
    Aug 22 05:39:32.382: INFO: Pod "downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98" satisfied condition "Succeeded or Failed"
    Aug 22 05:39:32.384: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98 container client-container: <nil>
    STEP: delete the pod 08/22/23 05:39:32.388
    Aug 22 05:39:32.532: INFO: Waiting for pod downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98 to disappear
    Aug 22 05:39:32.536: INFO: Pod downwardapi-volume-91d3b82d-26e1-45f0-89b1-11aff4b6fc98 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 22 05:39:32.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-733" for this suite. 08/22/23 05:39:32.54
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:39:32.55
Aug 22 05:39:32.550: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename job 08/22/23 05:39:32.551
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:39:32.642
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:39:32.645
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 08/22/23 05:39:32.648
STEP: Ensuring active pods == parallelism 08/22/23 05:39:32.654
STEP: Orphaning one of the Job's Pods 08/22/23 05:39:36.658
Aug 22 05:39:37.190: INFO: Successfully updated pod "adopt-release-2d877"
STEP: Checking that the Job readopts the Pod 08/22/23 05:39:37.19
Aug 22 05:39:37.190: INFO: Waiting up to 15m0s for pod "adopt-release-2d877" in namespace "job-9307" to be "adopted"
Aug 22 05:39:37.192: INFO: Pod "adopt-release-2d877": Phase="Running", Reason="", readiness=true. Elapsed: 2.523825ms
Aug 22 05:39:39.197: INFO: Pod "adopt-release-2d877": Phase="Running", Reason="", readiness=true. Elapsed: 2.007501687s
Aug 22 05:39:39.198: INFO: Pod "adopt-release-2d877" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 08/22/23 05:39:39.198
Aug 22 05:39:39.711: INFO: Successfully updated pod "adopt-release-2d877"
STEP: Checking that the Job releases the Pod 08/22/23 05:39:39.711
Aug 22 05:39:39.711: INFO: Waiting up to 15m0s for pod "adopt-release-2d877" in namespace "job-9307" to be "released"
Aug 22 05:39:39.713: INFO: Pod "adopt-release-2d877": Phase="Running", Reason="", readiness=true. Elapsed: 2.046399ms
Aug 22 05:39:41.717: INFO: Pod "adopt-release-2d877": Phase="Running", Reason="", readiness=true. Elapsed: 2.005702641s
Aug 22 05:39:41.717: INFO: Pod "adopt-release-2d877" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 22 05:39:41.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9307" for this suite. 08/22/23 05:39:41.721
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":353,"skipped":6618,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.176 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:39:32.55
    Aug 22 05:39:32.550: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename job 08/22/23 05:39:32.551
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:39:32.642
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:39:32.645
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 08/22/23 05:39:32.648
    STEP: Ensuring active pods == parallelism 08/22/23 05:39:32.654
    STEP: Orphaning one of the Job's Pods 08/22/23 05:39:36.658
    Aug 22 05:39:37.190: INFO: Successfully updated pod "adopt-release-2d877"
    STEP: Checking that the Job readopts the Pod 08/22/23 05:39:37.19
    Aug 22 05:39:37.190: INFO: Waiting up to 15m0s for pod "adopt-release-2d877" in namespace "job-9307" to be "adopted"
    Aug 22 05:39:37.192: INFO: Pod "adopt-release-2d877": Phase="Running", Reason="", readiness=true. Elapsed: 2.523825ms
    Aug 22 05:39:39.197: INFO: Pod "adopt-release-2d877": Phase="Running", Reason="", readiness=true. Elapsed: 2.007501687s
    Aug 22 05:39:39.198: INFO: Pod "adopt-release-2d877" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 08/22/23 05:39:39.198
    Aug 22 05:39:39.711: INFO: Successfully updated pod "adopt-release-2d877"
    STEP: Checking that the Job releases the Pod 08/22/23 05:39:39.711
    Aug 22 05:39:39.711: INFO: Waiting up to 15m0s for pod "adopt-release-2d877" in namespace "job-9307" to be "released"
    Aug 22 05:39:39.713: INFO: Pod "adopt-release-2d877": Phase="Running", Reason="", readiness=true. Elapsed: 2.046399ms
    Aug 22 05:39:41.717: INFO: Pod "adopt-release-2d877": Phase="Running", Reason="", readiness=true. Elapsed: 2.005702641s
    Aug 22 05:39:41.717: INFO: Pod "adopt-release-2d877" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 22 05:39:41.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9307" for this suite. 08/22/23 05:39:41.721
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:39:41.727
Aug 22 05:39:41.727: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename configmap 08/22/23 05:39:41.728
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:39:41.743
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:39:41.745
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-732219a4-1ee2-43ff-8f64-a0351dbb4ecd 08/22/23 05:39:41.747
STEP: Creating a pod to test consume configMaps 08/22/23 05:39:41.751
Aug 22 05:39:41.758: INFO: Waiting up to 5m0s for pod "pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6" in namespace "configmap-6661" to be "Succeeded or Failed"
Aug 22 05:39:41.761: INFO: Pod "pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.882488ms
Aug 22 05:39:43.767: INFO: Pod "pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009194533s
Aug 22 05:39:45.766: INFO: Pod "pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007325861s
Aug 22 05:39:47.810: INFO: Pod "pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.052275383s
STEP: Saw pod success 08/22/23 05:39:47.811
Aug 22 05:39:47.811: INFO: Pod "pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6" satisfied condition "Succeeded or Failed"
Aug 22 05:39:47.846: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6 container agnhost-container: <nil>
STEP: delete the pod 08/22/23 05:39:47.856
Aug 22 05:39:47.866: INFO: Waiting for pod pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6 to disappear
Aug 22 05:39:47.870: INFO: Pod pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 22 05:39:47.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6661" for this suite. 08/22/23 05:39:47.874
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":354,"skipped":6633,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.153 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:39:41.727
    Aug 22 05:39:41.727: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename configmap 08/22/23 05:39:41.728
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:39:41.743
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:39:41.745
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-732219a4-1ee2-43ff-8f64-a0351dbb4ecd 08/22/23 05:39:41.747
    STEP: Creating a pod to test consume configMaps 08/22/23 05:39:41.751
    Aug 22 05:39:41.758: INFO: Waiting up to 5m0s for pod "pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6" in namespace "configmap-6661" to be "Succeeded or Failed"
    Aug 22 05:39:41.761: INFO: Pod "pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.882488ms
    Aug 22 05:39:43.767: INFO: Pod "pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009194533s
    Aug 22 05:39:45.766: INFO: Pod "pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007325861s
    Aug 22 05:39:47.810: INFO: Pod "pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.052275383s
    STEP: Saw pod success 08/22/23 05:39:47.811
    Aug 22 05:39:47.811: INFO: Pod "pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6" satisfied condition "Succeeded or Failed"
    Aug 22 05:39:47.846: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6 container agnhost-container: <nil>
    STEP: delete the pod 08/22/23 05:39:47.856
    Aug 22 05:39:47.866: INFO: Waiting for pod pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6 to disappear
    Aug 22 05:39:47.870: INFO: Pod pod-configmaps-2ef1def3-03d8-4b26-9e7a-c9764e7378b6 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 22 05:39:47.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6661" for this suite. 08/22/23 05:39:47.874
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:39:47.882
Aug 22 05:39:47.882: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename init-container 08/22/23 05:39:47.883
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:39:47.922
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:39:47.926
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 08/22/23 05:39:47.931
Aug 22 05:39:47.931: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 22 05:39:55.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7752" for this suite. 08/22/23 05:39:55.598
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":355,"skipped":6642,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.735 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:39:47.882
    Aug 22 05:39:47.882: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename init-container 08/22/23 05:39:47.883
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:39:47.922
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:39:47.926
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 08/22/23 05:39:47.931
    Aug 22 05:39:47.931: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 22 05:39:55.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-7752" for this suite. 08/22/23 05:39:55.598
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:39:55.618
Aug 22 05:39:55.618: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename disruption 08/22/23 05:39:55.619
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:39:55.642
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:39:55.645
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 08/22/23 05:39:55.655
STEP: Waiting for all pods to be running 08/22/23 05:39:57.709
Aug 22 05:39:57.714: INFO: running pods: 0 < 3
Aug 22 05:39:59.720: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 22 05:40:01.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-3450" for this suite. 08/22/23 05:40:01.725
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":356,"skipped":6648,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.113 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:39:55.618
    Aug 22 05:39:55.618: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename disruption 08/22/23 05:39:55.619
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:39:55.642
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:39:55.645
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 08/22/23 05:39:55.655
    STEP: Waiting for all pods to be running 08/22/23 05:39:57.709
    Aug 22 05:39:57.714: INFO: running pods: 0 < 3
    Aug 22 05:39:59.720: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 22 05:40:01.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-3450" for this suite. 08/22/23 05:40:01.725
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:40:01.732
Aug 22 05:40:01.732: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename namespaces 08/22/23 05:40:01.733
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:40:01.828
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:40:01.832
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 08/22/23 05:40:01.836
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:40:02.044
STEP: Creating a pod in the namespace 08/22/23 05:40:02.048
STEP: Waiting for the pod to have running status 08/22/23 05:40:02.055
Aug 22 05:40:02.055: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-194" to be "running"
Aug 22 05:40:02.058: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.251439ms
Aug 22 05:40:04.063: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007856152s
Aug 22 05:40:06.063: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.007741588s
Aug 22 05:40:06.063: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 08/22/23 05:40:06.063
STEP: Waiting for the namespace to be removed. 08/22/23 05:40:06.083
STEP: Recreating the namespace 08/22/23 05:40:17.088
STEP: Verifying there are no pods in the namespace 08/22/23 05:40:17.104
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Aug 22 05:40:17.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7814" for this suite. 08/22/23 05:40:17.286
STEP: Destroying namespace "nsdeletetest-194" for this suite. 08/22/23 05:40:17.291
Aug 22 05:40:17.293: INFO: Namespace nsdeletetest-194 was already deleted
STEP: Destroying namespace "nsdeletetest-178" for this suite. 08/22/23 05:40:17.293
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":357,"skipped":6650,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.570 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:40:01.732
    Aug 22 05:40:01.732: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename namespaces 08/22/23 05:40:01.733
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:40:01.828
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:40:01.832
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 08/22/23 05:40:01.836
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:40:02.044
    STEP: Creating a pod in the namespace 08/22/23 05:40:02.048
    STEP: Waiting for the pod to have running status 08/22/23 05:40:02.055
    Aug 22 05:40:02.055: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-194" to be "running"
    Aug 22 05:40:02.058: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.251439ms
    Aug 22 05:40:04.063: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007856152s
    Aug 22 05:40:06.063: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.007741588s
    Aug 22 05:40:06.063: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 08/22/23 05:40:06.063
    STEP: Waiting for the namespace to be removed. 08/22/23 05:40:06.083
    STEP: Recreating the namespace 08/22/23 05:40:17.088
    STEP: Verifying there are no pods in the namespace 08/22/23 05:40:17.104
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Aug 22 05:40:17.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-7814" for this suite. 08/22/23 05:40:17.286
    STEP: Destroying namespace "nsdeletetest-194" for this suite. 08/22/23 05:40:17.291
    Aug 22 05:40:17.293: INFO: Namespace nsdeletetest-194 was already deleted
    STEP: Destroying namespace "nsdeletetest-178" for this suite. 08/22/23 05:40:17.293
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:40:17.306
Aug 22 05:40:17.306: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename csistoragecapacity 08/22/23 05:40:17.307
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:40:18.055
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:40:18.066
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 08/22/23 05:40:18.072
STEP: getting /apis/storage.k8s.io 08/22/23 05:40:18.075
STEP: getting /apis/storage.k8s.io/v1 08/22/23 05:40:18.076
STEP: creating 08/22/23 05:40:18.077
STEP: watching 08/22/23 05:40:18.111
Aug 22 05:40:18.111: INFO: starting watch
STEP: getting 08/22/23 05:40:18.12
STEP: listing in namespace 08/22/23 05:40:18.126
STEP: listing across namespaces 08/22/23 05:40:18.13
STEP: patching 08/22/23 05:40:18.142
STEP: updating 08/22/23 05:40:18.15
Aug 22 05:40:18.157: INFO: waiting for watch events with expected annotations in namespace
Aug 22 05:40:18.157: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 08/22/23 05:40:18.157
STEP: deleting a collection 08/22/23 05:40:18.17
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Aug 22 05:40:18.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-5799" for this suite. 08/22/23 05:40:18.189
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":358,"skipped":6686,"failed":0}
------------------------------
â€¢ [0.892 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:40:17.306
    Aug 22 05:40:17.306: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename csistoragecapacity 08/22/23 05:40:17.307
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:40:18.055
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:40:18.066
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 08/22/23 05:40:18.072
    STEP: getting /apis/storage.k8s.io 08/22/23 05:40:18.075
    STEP: getting /apis/storage.k8s.io/v1 08/22/23 05:40:18.076
    STEP: creating 08/22/23 05:40:18.077
    STEP: watching 08/22/23 05:40:18.111
    Aug 22 05:40:18.111: INFO: starting watch
    STEP: getting 08/22/23 05:40:18.12
    STEP: listing in namespace 08/22/23 05:40:18.126
    STEP: listing across namespaces 08/22/23 05:40:18.13
    STEP: patching 08/22/23 05:40:18.142
    STEP: updating 08/22/23 05:40:18.15
    Aug 22 05:40:18.157: INFO: waiting for watch events with expected annotations in namespace
    Aug 22 05:40:18.157: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 08/22/23 05:40:18.157
    STEP: deleting a collection 08/22/23 05:40:18.17
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Aug 22 05:40:18.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-5799" for this suite. 08/22/23 05:40:18.189
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:40:18.199
Aug 22 05:40:18.199: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename custom-resource-definition 08/22/23 05:40:18.2
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:40:18.233
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:40:18.238
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 08/22/23 05:40:18.243
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 08/22/23 05:40:18.245
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 08/22/23 05:40:18.245
STEP: fetching the /apis/apiextensions.k8s.io discovery document 08/22/23 05:40:18.245
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 08/22/23 05:40:18.247
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 08/22/23 05:40:18.247
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 08/22/23 05:40:18.249
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 22 05:40:18.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7730" for this suite. 08/22/23 05:40:18.252
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":359,"skipped":6702,"failed":0}
------------------------------
â€¢ [0.061 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:40:18.199
    Aug 22 05:40:18.199: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename custom-resource-definition 08/22/23 05:40:18.2
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:40:18.233
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:40:18.238
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 08/22/23 05:40:18.243
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 08/22/23 05:40:18.245
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 08/22/23 05:40:18.245
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 08/22/23 05:40:18.245
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 08/22/23 05:40:18.247
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 08/22/23 05:40:18.247
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 08/22/23 05:40:18.249
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 22 05:40:18.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-7730" for this suite. 08/22/23 05:40:18.252
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/22/23 05:40:18.261
Aug 22 05:40:18.261: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
STEP: Building a namespace api object, basename secrets 08/22/23 05:40:18.262
STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:40:18.282
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:40:18.285
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-6079/secret-test-9ab77128-8967-4bb2-be24-76de2ba2721c 08/22/23 05:40:18.291
STEP: Creating a pod to test consume secrets 08/22/23 05:40:18.295
Aug 22 05:40:18.302: INFO: Waiting up to 5m0s for pod "pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8" in namespace "secrets-6079" to be "Succeeded or Failed"
Aug 22 05:40:18.305: INFO: Pod "pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.157063ms
Aug 22 05:40:20.309: INFO: Pod "pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006329568s
Aug 22 05:40:22.311: INFO: Pod "pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008883182s
Aug 22 05:40:24.310: INFO: Pod "pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007949893s
STEP: Saw pod success 08/22/23 05:40:24.31
Aug 22 05:40:24.310: INFO: Pod "pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8" satisfied condition "Succeeded or Failed"
Aug 22 05:40:24.312: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8 container env-test: <nil>
STEP: delete the pod 08/22/23 05:40:24.317
Aug 22 05:40:24.369: INFO: Waiting for pod pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8 to disappear
Aug 22 05:40:24.373: INFO: Pod pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Aug 22 05:40:24.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6079" for this suite. 08/22/23 05:40:24.377
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":360,"skipped":6705,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.124 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/22/23 05:40:18.261
    Aug 22 05:40:18.261: INFO: >>> kubeConfig: /tmp/kubeconfig-1125186500
    STEP: Building a namespace api object, basename secrets 08/22/23 05:40:18.262
    STEP: Waiting for a default service account to be provisioned in namespace 08/22/23 05:40:18.282
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/22/23 05:40:18.285
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-6079/secret-test-9ab77128-8967-4bb2-be24-76de2ba2721c 08/22/23 05:40:18.291
    STEP: Creating a pod to test consume secrets 08/22/23 05:40:18.295
    Aug 22 05:40:18.302: INFO: Waiting up to 5m0s for pod "pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8" in namespace "secrets-6079" to be "Succeeded or Failed"
    Aug 22 05:40:18.305: INFO: Pod "pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.157063ms
    Aug 22 05:40:20.309: INFO: Pod "pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006329568s
    Aug 22 05:40:22.311: INFO: Pod "pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008883182s
    Aug 22 05:40:24.310: INFO: Pod "pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007949893s
    STEP: Saw pod success 08/22/23 05:40:24.31
    Aug 22 05:40:24.310: INFO: Pod "pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8" satisfied condition "Succeeded or Failed"
    Aug 22 05:40:24.312: INFO: Trying to get logs from node jake-melb-gmyyva4zrlsz-node-2 pod pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8 container env-test: <nil>
    STEP: delete the pod 08/22/23 05:40:24.317
    Aug 22 05:40:24.369: INFO: Waiting for pod pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8 to disappear
    Aug 22 05:40:24.373: INFO: Pod pod-configmaps-498c3179-dbe6-46f1-9b62-415dbf49afd8 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Aug 22 05:40:24.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6079" for this suite. 08/22/23 05:40:24.377
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":360,"skipped":6706,"failed":0}
Aug 22 05:40:24.386: INFO: Running AfterSuite actions on all nodes
Aug 22 05:40:24.386: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Aug 22 05:40:24.386: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Aug 22 05:40:24.386: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Aug 22 05:40:24.386: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Aug 22 05:40:24.386: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Aug 22 05:40:24.386: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Aug 22 05:40:24.386: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Aug 22 05:40:24.386: INFO: Running AfterSuite actions on node 1
Aug 22 05:40:24.386: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Aug 22 05:40:24.386: INFO: Running AfterSuite actions on all nodes
    Aug 22 05:40:24.386: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Aug 22 05:40:24.386: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Aug 22 05:40:24.386: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Aug 22 05:40:24.386: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Aug 22 05:40:24.386: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Aug 22 05:40:24.386: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Aug 22 05:40:24.386: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Aug 22 05:40:24.386: INFO: Running AfterSuite actions on node 1
    Aug 22 05:40:24.386: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.052 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 360 of 7066 Specs in 6571.583 seconds
SUCCESS! -- 360 Passed | 0 Failed | 0 Pending | 6706 Skipped
PASS

Ginkgo ran 1 suite in 1h49m31.894774437s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

